[{"question": "what kind of dog is this", "gt answer": "retriever(1.00)<br/>labrador(0.60)<br/>mix(0.60)<br/>black lab(0.60)", "pred answer": "lab", "question_id": 3600455, "best approach": "concept", "verif answer": "mix", "anno approach": "concept", "verif wiki answer": "labrador(0.6383)", "verif concept answer": "retriever(0.6315)", "verif image answer": "mix(0.6472)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000360045.jpg"}, {"question": "what is around the horses neck", "gt answer": "bridle(1.00)<br/>harness(0.60)", "pred answer": "tie", "question_id": 4505925, "best approach": "", "verif answer": "rein", "anno approach": "", "verif wiki answer": "rein(0.6863)", "verif concept answer": "rein(0.7108)", "verif image answer": "rein(0.6185)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450592.jpg"}, {"question": "what is the breed of this dog", "gt answer": "pomeranian(1.00)", "pred answer": "husky", "question_id": 2837345, "best approach": "wiki, concept, image", "verif answer": "pomeranian", "anno approach": "wiki", "verif wiki answer": "pomeranian(0.7310)", "verif concept answer": "pomeranian(0.7294)", "verif image answer": "pomeranian(0.7132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283734.jpg"}, {"question": "what type of jellly is shown", "gt answer": "orange(1.00)<br/>jam(0.60)", "pred answer": "espresso", "question_id": 786955, "best approach": "", "verif answer": "blueberry", "anno approach": "", "verif wiki answer": "blueberry(0.6406)", "verif concept answer": "blueberry(0.6184)", "verif image answer": "blueberry(0.6473)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078695.jpg"}, {"question": "what is the smaller item on the floor called", "gt answer": "toilet paper(1.00)", "pred answer": "chair", "question_id": 1394925, "best approach": "", "verif answer": "meter", "anno approach": "", "verif wiki answer": "meter(0.7090)", "verif concept answer": "meter(0.6908)", "verif image answer": "meter(0.6414)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139492.jpg"}, {"question": "what fruits are those", "gt answer": "orange(1.00)<br/>tangerine(1.00)", "pred answer": "orange", "question_id": 5564245, "best approach": "image", "verif answer": "tomato", "anno approach": "image", "verif wiki answer": "tomato(0.6914)", "verif concept answer": "tomato(0.7254)", "verif image answer": "tangerine(0.6954)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556424.jpg"}, {"question": "what outfit do you wear for this sport", "gt answer": "ski suit(1.00)<br/>snowsuit(0.60)", "pred answer": "wet suit", "question_id": 2134055, "best approach": "wiki", "verif answer": "ski suit", "anno approach": "wiki", "verif wiki answer": "ski suit(0.7307)", "verif concept answer": "wet suit(0.7264)", "verif image answer": "wet suit(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000213405.jpg"}, {"question": "what food group makes up this meal", "gt answer": "dairy(1.00)<br/>protein(0.60)", "pred answer": "vegetable", "question_id": 55895, "best approach": "wiki, concept", "verif answer": "protein", "anno approach": "wiki", "verif wiki answer": "protein(0.7088)", "verif concept answer": "protein(0.6060)", "verif image answer": "meat(0.6638)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005589.jpg"}, {"question": "what kind of grass is grown in the field these players are running on", "gt answer": "turf(1.00)", "pred answer": "green grass", "question_id": 164655, "best approach": "wiki, concept, image", "verif answer": "turf", "anno approach": "wiki", "verif wiki answer": "turf(0.6347)", "verif concept answer": "turf(0.6333)", "verif image answer": "turf(0.6524)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016465.jpg"}, {"question": "what activity does it appear the girl is doing", "gt answer": "run(1.00)", "pred answer": "fly kite", "question_id": 4883955, "best approach": "concept", "verif answer": "gallop", "anno approach": "concept", "verif wiki answer": "gallop(0.5425)", "verif concept answer": "run(0.5394)", "verif image answer": "play dead(0.5242)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488395.jpg"}, {"question": "what do you do after you blow out the items in the image", "gt answer": "make wish(1.00)<br/>cake(0.60)<br/>share(0.60)<br/>cut cake(0.60)", "pred answer": "candle", "question_id": 2068415, "best approach": "concept", "verif answer": "make wish", "anno approach": "concept", "verif wiki answer": "birthday(0.5038)", "verif concept answer": "make wish(0.6951)", "verif image answer": "birthday(0.6861)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206841.jpg"}, {"question": "what season do you think it is", "gt answer": "spring(1.00)<br/>summer(0.60)<br/>winter(0.60)", "pred answer": "fall", "question_id": 4048545, "best approach": "image", "verif answer": "fall", "anno approach": "image", "verif wiki answer": "farm(0.6667)", "verif concept answer": "fall(0.7305)", "verif image answer": "spring(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404854.jpg"}, {"question": "what does the bird appear to be doing", "gt answer": "sit(1.00)<br/>scout(0.60)<br/>eat(0.60)", "pred answer": "drink", "question_id": 2807405, "best approach": "concept, image", "verif answer": "drink", "anno approach": "", "verif wiki answer": "drink(0.7310)", "verif concept answer": "eat(0.7305)", "verif image answer": "eat(0.7267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280740.jpg"}, {"question": "in what piazza is the the persons in the costume at", "gt answer": "disney(1.00)<br/>christmas(0.60)", "pred answer": "downtown", "question_id": 1260905, "best approach": "image", "verif answer": "christmas", "anno approach": "image", "verif wiki answer": "christmas(0.6929)", "verif concept answer": "christmas(0.7272)", "verif image answer": "disney(0.6823)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126090.jpg"}, {"question": "what is the yellow substance in the sandwich", "gt answer": "egg(1.00)<br/>egg salad(0.60)", "pred answer": "potato", "question_id": 852815, "best approach": "wiki, concept, image", "verif answer": "egg", "anno approach": "wiki", "verif wiki answer": "egg(0.6718)", "verif concept answer": "egg(0.6496)", "verif image answer": "egg(0.6777)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085281.jpg"}, {"question": "what are the parents risking by using this type of float device", "gt answer": "drown(1.00)", "pred answer": "swim", "question_id": 5080085, "best approach": "wiki, image", "verif answer": "drown", "anno approach": "image, wiki", "verif wiki answer": "drown(0.6564)", "verif concept answer": "wipeout(0.6379)", "verif image answer": "drown(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000508008.jpg"}, {"question": "what would a skydiver need before he jumps out into this view", "gt answer": "parachute(1.00)", "pred answer": "fly", "question_id": 2682125, "best approach": "", "verif answer": "harness", "anno approach": "", "verif wiki answer": "harness(0.5769)", "verif concept answer": "harness(0.5375)", "verif image answer": "harness(0.5094)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268212.jpg"}, {"question": "where is the picture taken from", "gt answer": "car(1.00)", "pred answer": "zebra", "question_id": 1358205, "best approach": "concept", "verif answer": "vehicle", "anno approach": "concept", "verif wiki answer": "truck(0.5004)", "verif concept answer": "car(0.5014)", "verif image answer": "vehicle(0.5054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000135820.jpg"}, {"question": "what was his vest used for", "gt answer": "flotation(1.00)<br/>float(0.60)<br/>storage(0.60)", "pred answer": "neoprene", "question_id": 2809085, "best approach": "concept", "verif answer": "surf", "anno approach": "concept", "verif wiki answer": "float(0.6248)", "verif concept answer": "flotation(0.6222)", "verif image answer": "surf(0.6445)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280908.jpg"}, {"question": "where are these people serving food at", "gt answer": "cafeteria(1.00)<br/>school(0.60)", "pred answer": "restaurant", "question_id": 769785, "best approach": "", "verif answer": "office", "anno approach": "", "verif wiki answer": "office(0.7051)", "verif concept answer": "office(0.6856)", "verif image answer": "office(0.6719)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076978.jpg"}, {"question": "where would you see me", "gt answer": "alaska(1.00)<br/>forest(0.60)<br/>lake(0.60)<br/>arctic(0.60)", "pred answer": "mountain", "question_id": 3532845, "best approach": "wiki, concept, image", "verif answer": "lake", "anno approach": "wiki", "verif wiki answer": "lake(0.7274)", "verif concept answer": "lake(0.6613)", "verif image answer": "lake(0.6677)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353284.jpg"}, {"question": "what kind of flowers are these", "gt answer": "daffodil(1.00)<br/>tulip(1.00)<br/>daisy(0.60)", "pred answer": "rose", "question_id": 3145615, "best approach": "wiki, concept, image", "verif answer": "tulip", "anno approach": "image, wiki", "verif wiki answer": "tulip(0.6776)", "verif concept answer": "daffodil(0.6450)", "verif image answer": "tulip(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314561.jpg"}, {"question": "what is the name of this baseball team", "gt answer": "blue jay(1.00)<br/>red sox(0.60)", "pred answer": "yankees", "question_id": 1409405, "best approach": "wiki, concept, image", "verif answer": "red sox", "anno approach": "image, wiki", "verif wiki answer": "red sox(0.6474)", "verif concept answer": "red sox(0.5865)", "verif image answer": "red sox(0.7096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140940.jpg"}, {"question": "what unit of measure is used by this device", "gt answer": "time(1.00)<br/>roman(0.60)", "pred answer": "h2o", "question_id": 645, "best approach": "wiki, concept, image", "verif answer": "roman", "anno approach": "wiki", "verif wiki answer": "roman(0.5053)", "verif concept answer": "roman(0.5019)", "verif image answer": "roman(0.5128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000064.jpg"}, {"question": "what in the photo suggests the photographer likes farm things", "gt answer": "tractor(1.00)", "pred answer": "time", "question_id": 1189045, "best approach": "", "verif answer": "locomotive", "anno approach": "", "verif wiki answer": "locomotive(0.5059)", "verif concept answer": "locomotive(0.5006)", "verif image answer": "locomotive(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118904.jpg"}, {"question": "what likes honey and lives in the woods", "gt answer": "bear(1.00)", "pred answer": "bear", "question_id": 2028275, "best approach": "wiki, image", "verif answer": "bear", "anno approach": "image, wiki", "verif wiki answer": "bear(0.6885)", "verif concept answer": "polar bear(0.6581)", "verif image answer": "bear(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202827.jpg"}, {"question": "what type of trees are on the right in the foreground", "gt answer": "palm(1.00)<br/>palm tree(0.60)", "pred answer": "oak", "question_id": 2537965, "best approach": "wiki", "verif answer": "mahogany", "anno approach": "wiki", "verif wiki answer": "palm(0.6475)", "verif concept answer": "mahogany(0.7011)", "verif image answer": "mahogany(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253796.jpg"}, {"question": "what is the name of the middle eastern country that the famous cartoon cat colored like this one threatened to ship his rival to", "gt answer": "abu dhabi(1.00)<br/>saudi arabia(0.60)<br/>garfield(0.60)", "pred answer": "united state", "question_id": 1595255, "best approach": "", "verif answer": "chinese", "anno approach": "", "verif wiki answer": "chinese(0.6721)", "verif concept answer": "chinese(0.7025)", "verif image answer": "legal(0.6976)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159525.jpg"}, {"question": "what is the small black portal used for", "gt answer": "cat door(1.00)", "pred answer": "bath", "question_id": 3788905, "best approach": "", "verif answer": "natural", "anno approach": "", "verif wiki answer": "natural(0.5075)", "verif concept answer": "water(0.5054)", "verif image answer": "natural(0.5010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378890.jpg"}, {"question": "what sound does this animal make", "gt answer": "neigh(1.00)<br/>moo(0.60)", "pred answer": "bark", "question_id": 2923565, "best approach": "wiki, concept, image", "verif answer": "neigh", "anno approach": "concept, wiki", "verif wiki answer": "neigh(0.6120)", "verif concept answer": "neigh(0.7115)", "verif image answer": "neigh(0.6377)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292356.jpg"}, {"question": "how will the people get down the mountain", "gt answer": "ski(1.00)<br/>2(0.60)", "pred answer": "ski", "question_id": 2900805, "best approach": "wiki, concept, image", "verif answer": "ski", "anno approach": "image, concept, wiki", "verif wiki answer": "ski(0.6649)", "verif concept answer": "ski(0.7271)", "verif image answer": "ski(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000290080.jpg"}, {"question": "can you guess the car model shown shown in this picture", "gt answer": "ford(1.00)<br/>1930(0.60)", "pred answer": "ford", "question_id": 5601235, "best approach": "wiki, concept, image", "verif answer": "1930", "anno approach": "image, wiki", "verif wiki answer": "1930(0.6944)", "verif concept answer": "1930(0.6363)", "verif image answer": "1930(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560123.jpg"}, {"question": "what is it selling", "gt answer": "ice cream(1.00)<br/>food(0.60)", "pred answer": "food", "question_id": 1075865, "best approach": "wiki, concept, image", "verif answer": "food", "anno approach": "wiki", "verif wiki answer": "food(0.7040)", "verif concept answer": "food(0.6576)", "verif image answer": "food(0.6365)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000107586.jpg"}, {"question": "what condiments are shown here", "gt answer": "ketchup and mustard(1.00)<br/>ketchup(0.60)", "pred answer": "juice", "question_id": 2927305, "best approach": "", "verif answer": "sauce", "anno approach": "", "verif wiki answer": "sauce(0.5361)", "verif concept answer": "sauce(0.5604)", "verif image answer": "sauce(0.5021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292730.jpg"}, {"question": "which item on the table is considered a condiment", "gt answer": "ketchup(1.00)", "pred answer": "tea", "question_id": 1576395, "best approach": "", "verif answer": "onion", "anno approach": "", "verif wiki answer": "onion(0.5003)", "verif concept answer": "onion(0.5011)", "verif image answer": "mustard and ketchup(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157639.jpg"}, {"question": "is this person getting dressed for an interview or a pool party", "gt answer": "interview(1.00)", "pred answer": "meet", "question_id": 5446235, "best approach": "", "verif answer": "meet", "anno approach": "", "verif wiki answer": "meet(0.7304)", "verif concept answer": "meet(0.7297)", "verif image answer": "meet(0.6521)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544623.jpg"}, {"question": "what tools are used to make this knitted object", "gt answer": "knit needle(1.00)<br/>pin(0.60)", "pred answer": "sew", "question_id": 5112455, "best approach": "wiki, concept, image", "verif answer": "knit needle", "anno approach": "concept, wiki", "verif wiki answer": "knit needle(0.7166)", "verif concept answer": "knit needle(0.7183)", "verif image answer": "knit needle(0.6795)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511245.jpg"}, {"question": "is this cooked and how long", "gt answer": "1 hour(1.00)", "pred answer": "1 hour", "question_id": 5629735, "best approach": "", "verif answer": "15 minutes", "anno approach": "", "verif wiki answer": "15 minutes(0.5611)", "verif concept answer": "15 minutes(0.5726)", "verif image answer": "0 minutes(0.5062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000562973.jpg"}, {"question": "what is this park bench famous for", "gt answer": "sit(1.00)<br/>forest gump(0.60)", "pred answer": "wood", "question_id": 3448945, "best approach": "image", "verif answer": "forrest gump", "anno approach": "image", "verif wiki answer": "forrest gump(0.5518)", "verif concept answer": "forrest gump(0.5317)", "verif image answer": "sit(0.5024)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344894.jpg"}, {"question": "when you fill a glass to the top you are also referring to which part of the headgear worn here", "gt answer": "brim(1.00)", "pred answer": "nose", "question_id": 3611395, "best approach": "", "verif answer": "intoxication", "anno approach": "", "verif wiki answer": "intoxication(0.6978)", "verif concept answer": "kickflip(0.6841)", "verif image answer": "intoxication(0.6713)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361139.jpg"}, {"question": "why does it have a tag", "gt answer": "identification(1.00)<br/>food(0.60)", "pred answer": "identification", "question_id": 1726555, "best approach": "wiki, concept, image", "verif answer": "identification", "anno approach": "image, wiki", "verif wiki answer": "identification(0.7149)", "verif concept answer": "identification(0.6728)", "verif image answer": "identification(0.7081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000172655.jpg"}, {"question": "what kind of flowers are in that vase", "gt answer": "tulip(1.00)<br/>rose(1.00)", "pred answer": "rose", "question_id": 1030595, "best approach": "wiki, concept, image", "verif answer": "rose", "anno approach": "wiki", "verif wiki answer": "rose(0.6454)", "verif concept answer": "rose(0.6485)", "verif image answer": "rose(0.6549)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103059.jpg"}, {"question": "the man in this photo is beginning to show which male trait", "gt answer": "bald(1.00)<br/>bad(0.60)", "pred answer": "home", "question_id": 2122715, "best approach": "", "verif answer": "apple", "anno approach": "", "verif wiki answer": "apple(0.6500)", "verif concept answer": "apple(0.6689)", "verif image answer": "apple(0.5032)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212271.jpg"}, {"question": "what is a bulldog", "gt answer": "mascot(1.00)<br/>animal(0.60)", "pred answer": "sign", "question_id": 158305, "best approach": "", "verif answer": "cow", "anno approach": "", "verif wiki answer": "cow(0.7096)", "verif concept answer": "cow(0.7029)", "verif image answer": "cow(0.5601)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015830.jpg"}, {"question": "is this a desktop or laptop computer", "gt answer": "laptop(1.00)", "pred answer": "desktop", "question_id": 3644855, "best approach": "", "verif answer": "desktop", "anno approach": "", "verif wiki answer": "desktop(0.7266)", "verif concept answer": "desktop(0.7310)", "verif image answer": "desktop(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364485.jpg"}, {"question": "what sports team is this mascot for", "gt answer": "football(1.00)<br/>basketball(0.60)<br/>rat(0.60)<br/>shirt(0.60)", "pred answer": "teddy bear", "question_id": 1496025, "best approach": "wiki, image", "verif answer": "rat", "anno approach": "wiki", "verif wiki answer": "rat(0.5960)", "verif concept answer": "soccer(0.5319)", "verif image answer": "shirt(0.5045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149602.jpg"}, {"question": "what healthy drink does he have", "gt answer": "orange juice(1.00)<br/>juice(0.60)", "pred answer": "orange juice", "question_id": 298015, "best approach": "wiki, concept, image", "verif answer": "orange juice", "anno approach": "wiki", "verif wiki answer": "orange juice(0.6991)", "verif concept answer": "orange juice(0.6969)", "verif image answer": "orange juice(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029801.jpg"}, {"question": "what is the name of the object a baseball player wears on their hand to catch a baseball", "gt answer": "glove(1.00)", "pred answer": "glove", "question_id": 493785, "best approach": "wiki, concept, image", "verif answer": "glove", "anno approach": "wiki", "verif wiki answer": "glove(0.7280)", "verif concept answer": "glove(0.7309)", "verif image answer": "glove(0.7142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049378.jpg"}, {"question": "according to nursery lore who lost a baby one of these", "gt answer": "little bo peep(1.00)<br/>little bow peep(0.60)", "pred answer": "sheep", "question_id": 3926485, "best approach": "wiki, concept, image", "verif answer": "little bow peep", "anno approach": "concept, wiki", "verif wiki answer": "little bow peep(0.7063)", "verif concept answer": "little bow peep(0.7189)", "verif image answer": "little bow peep(0.6606)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392648.jpg"}, {"question": "what brand of backpack is being used", "gt answer": "jansport(1.00)<br/>columbia(0.60)", "pred answer": "north face", "question_id": 4260405, "best approach": "", "verif answer": "samsonite", "anno approach": "", "verif wiki answer": "samsonite(0.7301)", "verif concept answer": "samsonite(0.7253)", "verif image answer": "samsonite(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426040.jpg"}, {"question": "based on the scence what country is this photo located", "gt answer": "united kingdom(1.00)<br/>france(0.60)<br/>spain(0.60)<br/>america(0.60)", "pred answer": "england", "question_id": 4716695, "best approach": "wiki", "verif answer": "europe", "anno approach": "wiki", "verif wiki answer": "united kingdom(0.5955)", "verif concept answer": "europe(0.7222)", "verif image answer": "spain(0.5913)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471669.jpg"}, {"question": "during what years was this the most common mode of transportation", "gt answer": "1800s(1.00)<br/>1800's(0.60)<br/>1800(0.60)", "pred answer": "1950", "question_id": 4205295, "best approach": "image", "verif answer": "1800", "anno approach": "image", "verif wiki answer": "1800(0.6565)", "verif concept answer": "1800(0.6282)", "verif image answer": "1800s(0.6409)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420529.jpg"}, {"question": "what do they call those carts", "gt answer": "ski lift(1.00)<br/>lift(0.60)<br/>chair(0.60)", "pred answer": "motorcycle", "question_id": 4616445, "best approach": "image", "verif answer": "ski lift", "anno approach": "image", "verif wiki answer": "roll(0.5169)", "verif concept answer": "roll(0.5622)", "verif image answer": "ski lift(0.7089)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461644.jpg"}, {"question": "where is the man sitting", "gt answer": "garden(1.00)<br/>wood(0.60)<br/>yard(0.60)<br/>outside(0.60)", "pred answer": "bench", "question_id": 4363025, "best approach": "concept", "verif answer": "wood", "anno approach": "concept", "verif wiki answer": "forest(0.5041)", "verif concept answer": "wood(0.5138)", "verif image answer": "forest(0.5018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436302.jpg"}, {"question": "what materials are the suitcase made out of", "gt answer": "canvas(1.00)<br/>polyester(0.60)", "pred answer": "denim", "question_id": 5072875, "best approach": "wiki, concept", "verif answer": "polyester", "anno approach": "wiki", "verif wiki answer": "polyester(0.5049)", "verif concept answer": "polyester(0.5023)", "verif image answer": "nylon(0.5035)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507287.jpg"}, {"question": "what is this sport called", "gt answer": "surf(1.00)", "pred answer": "surf", "question_id": 5356605, "best approach": "wiki, concept, image", "verif answer": "surf", "anno approach": "concept, wiki", "verif wiki answer": "surf(0.6450)", "verif concept answer": "surf(0.7056)", "verif image answer": "surf(0.6281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535660.jpg"}, {"question": "what sport did this originate from", "gt answer": "cricket(1.00)<br/>baseball(1.00)", "pred answer": "baseball", "question_id": 4509755, "best approach": "wiki, concept, image", "verif answer": "baseball", "anno approach": "image, wiki", "verif wiki answer": "cricket(0.6548)", "verif concept answer": "baseball(0.6299)", "verif image answer": "baseball(0.7200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450975.jpg"}, {"question": "what position is the kid playing", "gt answer": "shortstop(1.00)<br/>outfield(0.60)<br/>second base(0.60)", "pred answer": "catcher", "question_id": 4291445, "best approach": "image", "verif answer": "shortstop", "anno approach": "image", "verif wiki answer": "catcher(0.6447)", "verif concept answer": "catcher(0.6443)", "verif image answer": "shortstop(0.6487)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429144.jpg"}, {"question": "what kind of food goes with this vegetables", "gt answer": "steak(1.00)<br/>chinese(0.60)<br/>chicken(0.60)<br/>meat(0.60)", "pred answer": "fiber", "question_id": 3548975, "best approach": "image", "verif answer": "meat", "anno approach": "image", "verif wiki answer": "pork(0.7259)", "verif concept answer": "pork(0.7297)", "verif image answer": "meat(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354897.jpg"}, {"question": "what is the traditional cheese made from this creatures milk", "gt answer": "goat cheese(1.00)<br/>brie(0.60)<br/>feta(0.60)", "pred answer": "mozzarella", "question_id": 891015, "best approach": "", "verif answer": "mozzarella", "anno approach": "", "verif wiki answer": "mozzarella(0.5007)", "verif concept answer": "mozzarella(0.5051)", "verif image answer": "mozzarella(0.5147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089101.jpg"}, {"question": "what kind of desserts are this", "gt answer": "pastry(1.00)<br/>cupcake(0.60)", "pred answer": "pastry", "question_id": 3829975, "best approach": "image", "verif answer": "pastry", "anno approach": "image", "verif wiki answer": "danish(0.6488)", "verif concept answer": "danish(0.6541)", "verif image answer": "pastry(0.6551)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382997.jpg"}, {"question": "how is the blue object on the floor usually cleaned", "gt answer": "vacuum(1.00)<br/>steam(0.60)", "pred answer": "vacuum", "question_id": 930485, "best approach": "wiki, concept, image", "verif answer": "vacuum", "anno approach": "wiki", "verif wiki answer": "vacuum(0.7311)", "verif concept answer": "vacuum(0.7311)", "verif image answer": "vacuum(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093048.jpg"}, {"question": "which fruit is a part of the muffin seen here", "gt answer": "blueberry(1.00)<br/>melon(0.60)", "pred answer": "blueberry", "question_id": 5287645, "best approach": "wiki, concept, image", "verif answer": "blueberry", "anno approach": "wiki", "verif wiki answer": "blueberry(0.7311)", "verif concept answer": "blueberry(0.7311)", "verif image answer": "blueberry(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528764.jpg"}, {"question": "what vitamin do these fruit give", "gt answer": "c(1.00)<br/>vitamin c(1.00)<br/>d(0.60)", "pred answer": "vitamin c", "question_id": 2538905, "best approach": "wiki, concept, image", "verif answer": "vitamin c", "anno approach": "concept, wiki", "verif wiki answer": "vitamin c(0.7120)", "verif concept answer": "vitamin c(0.7230)", "verif image answer": "c(0.6731)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253890.jpg"}, {"question": "what team is the man on first base playing for", "gt answer": "red sox(1.00)<br/>oriole(0.60)<br/>baseball(0.60)", "pred answer": "yankees", "question_id": 2707405, "best approach": "concept, image", "verif answer": "red sox", "anno approach": "", "verif wiki answer": "yankees(0.6458)", "verif concept answer": "red sox(0.6878)", "verif image answer": "red sox(0.6691)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270740.jpg"}, {"question": "what is the average lifespan of this animal", "gt answer": "25 years(1.00)<br/>60 years(0.60)<br/>30 years(0.60)", "pred answer": "20 years", "question_id": 1552125, "best approach": "concept, image", "verif answer": "30 years", "anno approach": "", "verif wiki answer": "40 years(0.5837)", "verif concept answer": "60 years(0.6277)", "verif image answer": "30 years(0.6340)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155212.jpg"}, {"question": "what nutrient is primarily in the frosted covered food", "gt answer": "sugar(1.00)<br/>grain(0.60)<br/>carbohydrate(0.60)", "pred answer": "flour", "question_id": 4745505, "best approach": "concept, image", "verif answer": "grain", "anno approach": "concept", "verif wiki answer": "calcium(0.6593)", "verif concept answer": "grain(0.7131)", "verif image answer": "grain(0.6639)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000474550.jpg"}, {"question": "what are the giraffes doing", "gt answer": "mate(1.00)<br/>run(0.60)<br/>hang out(0.60)", "pred answer": "walk", "question_id": 3954325, "best approach": "wiki, concept, image", "verif answer": "run", "anno approach": "image, concept, wiki", "verif wiki answer": "run(0.6527)", "verif concept answer": "run(0.7091)", "verif image answer": "run(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395432.jpg"}, {"question": "what is the cultural background of people with red hair", "gt answer": "irish(1.00)", "pred answer": "indian", "question_id": 1584205, "best approach": "image", "verif answer": "irish", "anno approach": "image", "verif wiki answer": "indian(0.6562)", "verif concept answer": "indian(0.6576)", "verif image answer": "irish(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000158420.jpg"}, {"question": "what region of the world would you find this bear", "gt answer": "arctic(1.00)<br/>artic(1.00)<br/>north pole(0.60)", "pred answer": "arctic", "question_id": 1760865, "best approach": "wiki, concept", "verif answer": "north pole", "anno approach": "wiki", "verif wiki answer": "north pole(0.7144)", "verif concept answer": "north pole(0.7311)", "verif image answer": "antarctica(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176086.jpg"}, {"question": "what type of outfit is this man wearing", "gt answer": "suit(1.00)", "pred answer": "tuxedo", "question_id": 2016305, "best approach": "", "verif answer": "pant suit", "anno approach": "", "verif wiki answer": "pant suit(0.7310)", "verif concept answer": "tuxedo(0.7297)", "verif image answer": "pant suit(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201630.jpg"}, {"question": "what helps the men glide across the snow", "gt answer": "ski(1.00)<br/>water(0.60)<br/>skiis(0.60)", "pred answer": "ski", "question_id": 2960995, "best approach": "image", "verif answer": "ski", "anno approach": "image", "verif wiki answer": "ski pole(0.6519)", "verif concept answer": "ski pole(0.6471)", "verif image answer": "ski(0.7226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296099.jpg"}, {"question": "what room is this", "gt answer": "live room(1.00)<br/>live(0.60)<br/>lounge(0.60)", "pred answer": "live room", "question_id": 2226955, "best approach": "wiki, image", "verif answer": "live room", "anno approach": "", "verif wiki answer": "live room(0.7303)", "verif concept answer": "live(0.7197)", "verif image answer": "live room(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222695.jpg"}, {"question": "in what kind of vehicle is this bed located", "gt answer": "rv(1.00)<br/>boat(0.60)", "pred answer": "trailer", "question_id": 833865, "best approach": "image", "verif answer": "trailer", "anno approach": "image", "verif wiki answer": "boat(0.6567)", "verif concept answer": "trailer(0.6856)", "verif image answer": "rv(0.6810)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083386.jpg"}, {"question": "which historical figure flew this in a storm", "gt answer": "benjamin franklin(1.00)<br/>ben franklin(0.60)", "pred answer": "benjamin franklin", "question_id": 4358895, "best approach": "wiki, image", "verif answer": "benjamin franklin", "anno approach": "wiki", "verif wiki answer": "benjamin franklin(0.7302)", "verif concept answer": "ben franklin(0.7296)", "verif image answer": "benjamin franklin(0.7118)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435889.jpg"}, {"question": "what is the lifespan of this animal", "gt answer": "10 years(1.00)<br/>15 years(0.60)<br/>18 years(0.60)<br/>25(0.60)", "pred answer": "15 years", "question_id": 2793415, "best approach": "wiki, concept, image", "verif answer": "18 years", "anno approach": "wiki", "verif wiki answer": "18 years(0.6408)", "verif concept answer": "18 years(0.6394)", "verif image answer": "18 years(0.6351)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000279341.jpg"}, {"question": "what is it called when you have no points in this sport", "gt answer": "love(1.00)<br/>foul(0.60)", "pred answer": "strike", "question_id": 4029165, "best approach": "wiki, concept, image", "verif answer": "foul", "anno approach": "image, wiki", "verif wiki answer": "foul(0.6391)", "verif concept answer": "foul(0.5753)", "verif image answer": "foul(0.6536)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402916.jpg"}, {"question": "when was this type of vehicle with two equal sized wheels invented", "gt answer": "1850(1.00)<br/>1900(0.60)<br/>1800s(0.60)", "pred answer": "1940", "question_id": 2774705, "best approach": "", "verif answer": "1950s", "anno approach": "", "verif wiki answer": "1820s(0.6308)", "verif concept answer": "1950s(0.6209)", "verif image answer": "1950s(0.6437)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277470.jpg"}, {"question": "what is the coloring of the lighting used here if you were a professional set designer", "gt answer": "yellow(1.00)", "pred answer": "green", "question_id": 1811365, "best approach": "concept, image", "verif answer": "yellow", "anno approach": "image", "verif wiki answer": "red(0.6554)", "verif concept answer": "yellow(0.6894)", "verif image answer": "yellow(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181136.jpg"}, {"question": "where would you take these", "gt answer": "vacation(1.00)", "pred answer": "america", "question_id": 5035415, "best approach": "wiki, concept, image", "verif answer": "vacation", "anno approach": "wiki", "verif wiki answer": "vacation(0.7260)", "verif concept answer": "vacation(0.7281)", "verif image answer": "vacation(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503541.jpg"}, {"question": "what would someone do here", "gt answer": "pray(1.00)<br/>vacation(0.60)", "pred answer": "tell time", "question_id": 4424735, "best approach": "", "verif answer": "eat", "anno approach": "", "verif wiki answer": "eat(0.7310)", "verif concept answer": "eat(0.7310)", "verif image answer": "tell time(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442473.jpg"}, {"question": "what brand is this clothing accessory", "gt answer": "tie(1.00)<br/>gay(0.60)", "pred answer": "tie", "question_id": 4645935, "best approach": "wiki, concept, image", "verif answer": "tie", "anno approach": "wiki", "verif wiki answer": "tie(0.7310)", "verif concept answer": "tie(0.7310)", "verif image answer": "tie(0.7148)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464593.jpg"}, {"question": "what style bathtub is this", "gt answer": "modern(1.00)", "pred answer": "freestanding", "question_id": 4518365, "best approach": "image", "verif answer": "small", "anno approach": "image", "verif wiki answer": "small(0.7153)", "verif concept answer": "small(0.6485)", "verif image answer": "modern(0.6446)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451836.jpg"}, {"question": "was it clean or do you think it left a trail", "gt answer": "trail(1.00)", "pred answer": "clean", "question_id": 3779735, "best approach": "", "verif answer": "smoke", "anno approach": "", "verif wiki answer": "scratch(0.5000)", "verif concept answer": "scratch(0.5000)", "verif image answer": "smoke(0.5057)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377973.jpg"}, {"question": "what type of tree is shown", "gt answer": "eucalyptus(1.00)<br/>oak(1.00)<br/>pine(0.60)", "pred answer": "oak", "question_id": 1736475, "best approach": "concept, image", "verif answer": "oak", "anno approach": "image", "verif wiki answer": "pine(0.6643)", "verif concept answer": "oak(0.6443)", "verif image answer": "oak(0.7055)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000173647.jpg"}, {"question": "what size is this women 's jacket", "gt answer": "medium(1.00)<br/>36(0.60)", "pred answer": "large", "question_id": 1060255, "best approach": "wiki, concept", "verif answer": "medium", "anno approach": "concept, wiki", "verif wiki answer": "medium(0.5658)", "verif concept answer": "medium(0.6372)", "verif image answer": "lot(0.6071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106025.jpg"}, {"question": "how big is the bed", "gt answer": "king(1.00)<br/>queen(0.60)<br/>full(0.60)", "pred answer": "queen", "question_id": 3800705, "best approach": "concept", "verif answer": "queen", "anno approach": "concept", "verif wiki answer": "queen(0.7305)", "verif concept answer": "king(0.7005)", "verif image answer": "double(0.6721)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000380070.jpg"}, {"question": "which item can you not use with aluminum foil", "gt answer": "microwave(1.00)<br/>metal(0.60)", "pred answer": "refrigerator", "question_id": 9085, "best approach": "image", "verif answer": "microwave", "anno approach": "image", "verif wiki answer": "glass(0.6473)", "verif concept answer": "glass(0.5043)", "verif image answer": "microwave(0.7109)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000908.jpg"}, {"question": "what type of alcohol is advertised here", "gt answer": "cider(1.00)", "pred answer": "wine", "question_id": 251025, "best approach": "", "verif answer": "beer", "anno approach": "", "verif wiki answer": "lot(0.6451)", "verif concept answer": "lot(0.5764)", "verif image answer": "beer(0.6733)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025102.jpg"}, {"question": "what would this animal say if you asked", "gt answer": "meow(1.00)", "pred answer": "bad luck", "question_id": 3168715, "best approach": "", "verif answer": "down", "anno approach": "", "verif wiki answer": "down(0.7285)", "verif concept answer": "down(0.7230)", "verif image answer": "down(0.6764)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316871.jpg"}, {"question": "why do these animals have such long necks", "gt answer": "evolution(1.00)<br/>to eat(0.60)", "pred answer": "to eat", "question_id": 1094245, "best approach": "wiki, concept, image", "verif answer": "to eat", "anno approach": "wiki", "verif wiki answer": "to eat(0.7311)", "verif concept answer": "to eat(0.7310)", "verif image answer": "to eat(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000109424.jpg"}, {"question": "what is hanging from the ring in the picture", "gt answer": "towel(1.00)", "pred answer": "towel", "question_id": 4400035, "best approach": "concept, image", "verif answer": "cloth", "anno approach": "", "verif wiki answer": "cloth(0.7294)", "verif concept answer": "towel(0.7291)", "verif image answer": "towel(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440003.jpg"}, {"question": "what is the gestation period of the white animal", "gt answer": "152 days(1.00)<br/>8 months(0.60)", "pred answer": "sheep", "question_id": 877205, "best approach": "", "verif answer": "sheep", "anno approach": "", "verif wiki answer": "3 months(0.6157)", "verif concept answer": "sheep(0.6313)", "verif image answer": "sheep(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087720.jpg"}, {"question": "is this in a urban or rural area", "gt answer": "urban(1.00)<br/>rural(0.60)", "pred answer": "rural", "question_id": 5244205, "best approach": "wiki, concept, image", "verif answer": "rural", "anno approach": "wiki", "verif wiki answer": "rural(0.7219)", "verif concept answer": "rural(0.7306)", "verif image answer": "rural(0.7131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000524420.jpg"}, {"question": "what is healthy about this photo", "gt answer": "nothing(1.00)<br/>coconut(0.60)<br/>carbohydrate(0.60)", "pred answer": "meat", "question_id": 4035795, "best approach": "wiki, concept, image", "verif answer": "carbohydrate", "anno approach": "image, concept, wiki", "verif wiki answer": "coconut(0.5164)", "verif concept answer": "carbohydrate(0.6341)", "verif image answer": "carbohydrate(0.6186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403579.jpg"}, {"question": "how do you make the fencing in the background", "gt answer": "lattice(1.00)", "pred answer": "metal", "question_id": 5444755, "best approach": "wiki, concept", "verif answer": "lattice", "anno approach": "concept", "verif wiki answer": "lattice(0.5701)", "verif concept answer": "lattice(0.7014)", "verif image answer": "grill(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544475.jpg"}, {"question": "is the skateboarder a professional or amatuer", "gt answer": "amatuer(1.00)<br/>professional(0.60)", "pred answer": "professional", "question_id": 3455315, "best approach": "wiki, concept", "verif answer": "beginner", "anno approach": "", "verif wiki answer": "amatuer(0.7260)", "verif concept answer": "amatuer(0.7277)", "verif image answer": "beginner(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345531.jpg"}, {"question": "what is the brand of jeans this man is wearing", "gt answer": "levis(1.00)", "pred answer": "denim", "question_id": 4305815, "best approach": "", "verif answer": "jean", "anno approach": "", "verif wiki answer": "jean(0.6353)", "verif concept answer": "jean(0.6421)", "verif image answer": "jean(0.6448)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430581.jpg"}, {"question": "what trick is being attempted", "gt answer": "flip(1.00)<br/>kickflip(0.60)", "pred answer": "skateboard", "question_id": 1344945, "best approach": "wiki, concept, image", "verif answer": "kickflip", "anno approach": "image, wiki", "verif wiki answer": "kickflip(0.6489)", "verif concept answer": "kickflip(0.6476)", "verif image answer": "kickflip(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134494.jpg"}, {"question": "what profession do these men seem to belong to", "gt answer": "pilot(1.00)<br/>military(0.60)", "pred answer": "military", "question_id": 3768385, "best approach": "image", "verif answer": "military", "anno approach": "image", "verif wiki answer": "navy(0.6502)", "verif concept answer": "navy(0.6609)", "verif image answer": "military(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376838.jpg"}, {"question": "what is the placemat on the table made from", "gt answer": "bamboo(1.00)<br/>wood(0.60)<br/>wicker(0.60)", "pred answer": "wood", "question_id": 5114615, "best approach": "wiki, concept, image", "verif answer": "wicker", "anno approach": "wiki", "verif wiki answer": "wicker(0.6419)", "verif concept answer": "wood(0.6561)", "verif image answer": "wicker(0.6732)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511461.jpg"}, {"question": "where are these birds migrating to", "gt answer": "south(1.00)<br/>south america(0.60)", "pred answer": "seed", "question_id": 3175575, "best approach": "", "verif answer": "west", "anno approach": "", "verif wiki answer": "west(0.6794)", "verif concept answer": "tropic(0.7082)", "verif image answer": "west(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317557.jpg"}, {"question": "what company manufactured that stove", "gt answer": "maytag(1.00)<br/>general electric(0.60)<br/>kenmore(0.60)", "pred answer": "ge", "question_id": 5394045, "best approach": "concept", "verif answer": "kenmore", "anno approach": "concept", "verif wiki answer": "whirlpool(0.6395)", "verif concept answer": "maytag(0.6545)", "verif image answer": "kenmore(0.6702)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539404.jpg"}, {"question": "what does the double yellow line on the ground signify", "gt answer": "do not pass(1.00)", "pred answer": "crosswalk", "question_id": 3358715, "best approach": "", "verif answer": "no park", "anno approach": "", "verif wiki answer": "no park(0.7310)", "verif concept answer": "no park(0.7271)", "verif image answer": "no park(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335871.jpg"}, {"question": "is the airplane landing or taking off", "gt answer": "take off(1.00)", "pred answer": "take off", "question_id": 130005, "best approach": "wiki, concept, image", "verif answer": "take off", "anno approach": "wiki", "verif wiki answer": "take off(0.7283)", "verif concept answer": "take off(0.7288)", "verif image answer": "take off(0.7174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013000.jpg"}, {"question": "how are the skier going to get back to the top of the slopes", "gt answer": "ski lift(1.00)<br/>lift(0.60)<br/>skilift(0.60)", "pred answer": "ski", "question_id": 2706595, "best approach": "", "verif answer": "skiis", "anno approach": "", "verif wiki answer": "skiis(0.6801)", "verif concept answer": "skiis(0.6446)", "verif image answer": "skiis(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270659.jpg"}, {"question": "what does the white color in the sky mean", "gt answer": "cloud(1.00)", "pred answer": "land", "question_id": 1036995, "best approach": "", "verif answer": "cirrus", "anno approach": "", "verif wiki answer": "cirrus(0.7276)", "verif concept answer": "cirrus(0.7252)", "verif image answer": "cirrus(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103699.jpg"}, {"question": "what shape do the bases form in this sport", "gt answer": "diamond(1.00)", "pred answer": "diamond", "question_id": 1201796, "best approach": "wiki, concept, image", "verif answer": "diamond", "anno approach": "wiki", "verif wiki answer": "diamond(0.7310)", "verif concept answer": "diamond(0.7311)", "verif image answer": "diamond(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000120179.jpg"}, {"question": "what sort of eye wear would be of particular benefit in this scenario", "gt answer": "sunglasses(1.00)<br/>goggle(0.60)", "pred answer": "sunglasses", "question_id": 83145, "best approach": "", "verif answer": "boot", "anno approach": "", "verif wiki answer": "boot(0.6985)", "verif concept answer": "boot(0.6963)", "verif image answer": "boot(0.7184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008314.jpg"}, {"question": "what kind of boat is this", "gt answer": "tanker(1.00)<br/>cruise(0.60)<br/>freight(0.60)", "pred answer": "barge", "question_id": 690435, "best approach": "wiki, concept", "verif answer": "tanker", "anno approach": "wiki", "verif wiki answer": "tanker(0.7011)", "verif concept answer": "tanker(0.7221)", "verif image answer": "freight(0.6387)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069043.jpg"}, {"question": "what kind of truck is crossing the street", "gt answer": "garbage(1.00)<br/>garbage truck(0.60)", "pred answer": "semi", "question_id": 3743575, "best approach": "", "verif answer": "dump", "anno approach": "", "verif wiki answer": "dump(0.7245)", "verif concept answer": "dump(0.6445)", "verif image answer": "dump(0.6435)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374357.jpg"}, {"question": "is this a healthy meal or unhealthy meal", "gt answer": "healthy(1.00)", "pred answer": "healthy", "question_id": 1662965, "best approach": "wiki, concept, image", "verif answer": "healthy", "anno approach": "concept, wiki", "verif wiki answer": "healthy(0.7311)", "verif concept answer": "healthy(0.7311)", "verif image answer": "healthy(0.5004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166296.jpg"}, {"question": "is this an amatuer or professional surfer", "gt answer": "professional(1.00)", "pred answer": "professional", "question_id": 1351715, "best approach": "", "verif answer": "amatuer", "anno approach": "", "verif wiki answer": "amatuer(0.6717)", "verif concept answer": "amatuer(0.7225)", "verif image answer": "amatuer(0.7154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000135171.jpg"}, {"question": "which teddy bear is for girls", "gt answer": "pink 1(1.00)<br/>both(0.60)", "pred answer": "boy", "question_id": 5755945, "best approach": "", "verif answer": "teddy bear", "anno approach": "", "verif wiki answer": "teddy bear(0.6471)", "verif concept answer": "teddy bear(0.6875)", "verif image answer": "teddy bear(0.7048)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575594.jpg"}, {"question": "what sort of predator might there be in an area like this", "gt answer": "shark(1.00)", "pred answer": "shark", "question_id": 3497875, "best approach": "wiki, concept, image", "verif answer": "shark", "anno approach": "concept, wiki", "verif wiki answer": "shark(0.7106)", "verif concept answer": "shark(0.6948)", "verif image answer": "shark(0.6449)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000349787.jpg"}, {"question": "where are these animals most commonly found", "gt answer": "farm(1.00)<br/>north america(0.60)<br/>west(0.60)<br/>america(0.60)", "pred answer": "farm", "question_id": 2043215, "best approach": "wiki, concept, image", "verif answer": "farm", "anno approach": "wiki", "verif wiki answer": "farm(0.6505)", "verif concept answer": "farm(0.6721)", "verif image answer": "farm(0.6709)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000204321.jpg"}, {"question": "what is the international governing body of the sport seen here", "gt answer": "fifa(1.00)", "pred answer": "soccer", "question_id": 4647895, "best approach": "wiki, concept", "verif answer": "fifa", "anno approach": "wiki", "verif wiki answer": "fifa(0.6555)", "verif concept answer": "fifa(0.6471)", "verif image answer": "amatuer(0.6503)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464789.jpg"}, {"question": "what kind of motors do these boats have", "gt answer": "outboard(1.00)", "pred answer": "gas", "question_id": 2987935, "best approach": "wiki, concept, image", "verif answer": "outboard", "anno approach": "image, wiki", "verif wiki answer": "outboard(0.6696)", "verif concept answer": "outboard(0.6174)", "verif image answer": "outboard(0.7053)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000298793.jpg"}, {"question": "what are these two individuals celebrating", "gt answer": "marriage(1.00)<br/>anniversary(0.60)<br/>birthday(0.60)", "pred answer": "protest", "question_id": 1232015, "best approach": "wiki, concept", "verif answer": "birthday", "anno approach": "wiki", "verif wiki answer": "birthday(0.5053)", "verif concept answer": "birthday(0.5013)", "verif image answer": "wed(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123201.jpg"}, {"question": "what types of cheeses are on the platter", "gt answer": "brie(1.00)<br/>french(0.60)", "pred answer": "mozzarella", "question_id": 5056265, "best approach": "wiki, concept", "verif answer": "brie", "anno approach": "wiki", "verif wiki answer": "brie(0.5049)", "verif concept answer": "brie(0.5292)", "verif image answer": "feta(0.5206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505626.jpg"}, {"question": "what is this person about to do", "gt answer": "ride(1.00)", "pred answer": "horse race", "question_id": 2272025, "best approach": "", "verif answer": "horse jump", "anno approach": "", "verif wiki answer": "horse jump(0.7219)", "verif concept answer": "horse jump(0.6249)", "verif image answer": "horse jump(0.5809)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000227202.jpg"}, {"question": "what king of birds fly near the beach", "gt answer": "seagull(1.00)<br/>gull(0.60)", "pred answer": "seagull", "question_id": 4423075, "best approach": "wiki, concept, image", "verif answer": "seagull", "anno approach": "wiki", "verif wiki answer": "seagull(0.7310)", "verif concept answer": "seagull(0.7301)", "verif image answer": "seagull(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442307.jpg"}, {"question": "which tech event is this presenter speaking at", "gt answer": "cellphone(1.00)<br/>cellular(0.60)<br/>apple(0.60)<br/>cell phone(0.60)", "pred answer": "sport", "question_id": 82845, "best approach": "concept, image", "verif answer": "apple", "anno approach": "image", "verif wiki answer": "communication(0.5271)", "verif concept answer": "apple(0.5128)", "verif image answer": "apple(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008284.jpg"}, {"question": "are these people young or old", "gt answer": "old(1.00)<br/>young(0.60)", "pred answer": "60s", "question_id": 1599535, "best approach": "", "verif answer": "elderly", "anno approach": "", "verif wiki answer": "elderly(0.6914)", "verif concept answer": "elderly(0.7134)", "verif image answer": "elderly(0.6470)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159953.jpg"}, {"question": "how much weight can this train pull", "gt answer": "ton(1.00)<br/>thousand(0.60)", "pred answer": "500 lbs", "question_id": 1627475, "best approach": "", "verif answer": "2 tons", "anno approach": "", "verif wiki answer": "million(0.6038)", "verif concept answer": "2 tons(0.6397)", "verif image answer": "million(0.5916)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162747.jpg"}, {"question": "where these red vegetables imported to the us or exported from the us", "gt answer": "imported(1.00)", "pred answer": "america", "question_id": 2257045, "best approach": "", "verif answer": "clock", "anno approach": "", "verif wiki answer": "clock(0.6396)", "verif concept answer": "clock(0.6419)", "verif image answer": "clock(0.6640)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225704.jpg"}, {"question": "what famous female athlete known for this sport lost an arm to a shark attack", "gt answer": "bethany hamilton(1.00)", "pred answer": "apple", "question_id": 97385, "best approach": "wiki, concept, image", "verif answer": "bethany hamilton", "anno approach": "wiki", "verif wiki answer": "bethany hamilton(0.5012)", "verif concept answer": "bethany hamilton(0.5025)", "verif image answer": "bethany hamilton(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009738.jpg"}, {"question": "what is the name of the sandwich", "gt answer": "grilled cheese(1.00)", "pred answer": "french", "question_id": 2885565, "best approach": "", "verif answer": "reuben", "anno approach": "", "verif wiki answer": "reuben(0.6957)", "verif concept answer": "reuben(0.6502)", "verif image answer": "toasted(0.6776)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288556.jpg"}, {"question": "who invented this", "gt answer": "mozi and lu ban(1.00)<br/>benjamin franklin(0.60)<br/>mozi(0.60)", "pred answer": "benjamin franklin", "question_id": 1256935, "best approach": "wiki, concept, image", "verif answer": "mozi", "anno approach": "wiki", "verif wiki answer": "benjamin franklin(0.6560)", "verif concept answer": "mozi(0.6615)", "verif image answer": "benjamin franklin(0.6472)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125693.jpg"}, {"question": "what are the green slices on the plate called", "gt answer": "pickle(1.00)", "pred answer": "spinach", "question_id": 1334365, "best approach": "", "verif answer": "cucumber", "anno approach": "", "verif wiki answer": "cucumber(0.6485)", "verif concept answer": "spinach(0.6433)", "verif image answer": "cucumber(0.7237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000133436.jpg"}, {"question": "what time period was this taken during", "gt answer": "1800s(1.00)", "pred answer": "1940's", "question_id": 1578045, "best approach": "", "verif answer": "1940's", "anno approach": "", "verif wiki answer": "1940's(0.7063)", "verif concept answer": "1940's(0.7094)", "verif image answer": "winter(0.6580)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157804.jpg"}, {"question": "what type of flowers are growing out of the suitcase", "gt answer": "pansy(1.00)<br/>sun(0.60)", "pred answer": "rose", "question_id": 4915165, "best approach": "", "verif answer": "candle", "anno approach": "", "verif wiki answer": "candle(0.5006)", "verif concept answer": "candle(0.5185)", "verif image answer": "daisy(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491516.jpg"}, {"question": "what vitamin does this vegetable contain", "gt answer": "vitamin(1.00)<br/>(0.60)<br/>vitamin k(0.60)", "pred answer": "d", "question_id": 4719055, "best approach": "wiki, concept, image", "verif answer": "", "anno approach": "wiki", "verif wiki answer": "(0.6404)", "verif concept answer": "(0.5930)", "verif image answer": "(0.5862)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471905.jpg"}, {"question": "what do people do with the numerous rectangular objects on the shelf in the back of the picture", "gt answer": "read(1.00)", "pred answer": "read", "question_id": 5185105, "best approach": "", "verif answer": "eat", "anno approach": "", "verif wiki answer": "sleep(0.6290)", "verif concept answer": "eat(0.6626)", "verif image answer": "eat(0.6220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518510.jpg"}, {"question": "what is the title commonly given to the man wearing the red tie and green vest", "gt answer": "bartender(1.00)", "pred answer": "wine taster", "question_id": 314345, "best approach": "", "verif answer": "goalie", "anno approach": "", "verif wiki answer": "goalie(0.6211)", "verif concept answer": "apron(0.5493)", "verif image answer": "goalie(0.7225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000031434.jpg"}, {"question": "how many babies does this animal have on average", "gt answer": "1(1.00)<br/>3(0.60)<br/>2(0.60)<br/>5(0.60)", "pred answer": "6", "question_id": 809825, "best approach": "wiki, concept, image", "verif answer": "3", "anno approach": "image, concept, wiki", "verif wiki answer": "3(0.5999)", "verif concept answer": "3(0.6388)", "verif image answer": "3(0.6392)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080982.jpg"}, {"question": "which stop is this bus heading to next", "gt answer": "epping(1.00)", "pred answer": "tour", "question_id": 4345875, "best approach": "", "verif answer": "san francisco", "anno approach": "", "verif wiki answer": "san francisco(0.6614)", "verif concept answer": "san francisco(0.6637)", "verif image answer": "san francisco(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434587.jpg"}, {"question": "why is the cow sitting where it is", "gt answer": "shade(1.00)<br/>for shade(1.00)", "pred answer": "rest", "question_id": 3429525, "best approach": "wiki, concept, image", "verif answer": "shade", "anno approach": "image, wiki", "verif wiki answer": "shade(0.6518)", "verif concept answer": "shade(0.6737)", "verif image answer": "shade(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342952.jpg"}, {"question": "what are these objects used for", "gt answer": "time(1.00)<br/>tell time(0.60)", "pred answer": "tell time", "question_id": 1805885, "best approach": "wiki, concept, image", "verif answer": "tell time", "anno approach": "", "verif wiki answer": "tell time(0.7311)", "verif concept answer": "tell time(0.7311)", "verif image answer": "tell time(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180588.jpg"}, {"question": "where is fizz soda manufactured", "gt answer": "factory(1.00)<br/>america(1.00)<br/>usa(0.60)", "pred answer": "idaho", "question_id": 4285655, "best approach": "wiki, concept, image", "verif answer": "america", "anno approach": "image, concept, wiki", "verif wiki answer": "america(0.5549)", "verif concept answer": "america(0.6423)", "verif image answer": "america(0.6422)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428565.jpg"}, {"question": "where is this", "gt answer": "lugg valley(1.00)<br/>europe(0.60)<br/>england(0.60)<br/>city(0.60)", "pred answer": "london", "question_id": 4042215, "best approach": "wiki, concept, image", "verif answer": "city", "anno approach": "image, wiki", "verif wiki answer": "city(0.6533)", "verif concept answer": "city(0.6468)", "verif image answer": "city(0.7025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404221.jpg"}, {"question": "what food is in the photo", "gt answer": "egg(1.00)", "pred answer": "turkey", "question_id": 5290195, "best approach": "", "verif answer": "egg salad", "anno approach": "", "verif wiki answer": "sunny side up(0.5816)", "verif concept answer": "sunny side up(0.5586)", "verif image answer": "egg salad(0.6803)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529019.jpg"}, {"question": "what is the shape of the clock in the photo", "gt answer": "round(1.00)<br/>square(0.60)<br/>circle(0.60)", "pred answer": "round", "question_id": 1269925, "best approach": "wiki, concept, image", "verif answer": "circle", "anno approach": "wiki", "verif wiki answer": "circle(0.7308)", "verif concept answer": "circle(0.7301)", "verif image answer": "circle(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126992.jpg"}, {"question": "what software is being shown in the image", "gt answer": "excel(1.00)<br/>microsoft(0.60)", "pred answer": "apple", "question_id": 4780875, "best approach": "", "verif answer": "dell", "anno approach": "", "verif wiki answer": "dell(0.6265)", "verif concept answer": "dell(0.6635)", "verif image answer": "dell(0.5516)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478087.jpg"}, {"question": "what quality of memory are these large animals known to have", "gt answer": "great(1.00)<br/>large(0.60)", "pred answer": "tusk", "question_id": 4336625, "best approach": "wiki, concept, image", "verif answer": "large", "anno approach": "image, wiki", "verif wiki answer": "large(0.6934)", "verif concept answer": "large(0.6683)", "verif image answer": "large(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433662.jpg"}, {"question": "does this image depict a natural or man made environment", "gt answer": "man made(1.00)<br/>manmade(0.60)", "pred answer": "wild", "question_id": 4733485, "best approach": "wiki", "verif answer": "man made", "anno approach": "wiki", "verif wiki answer": "man made(0.7278)", "verif concept answer": "manmade(0.7240)", "verif image answer": "manmade(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473348.jpg"}, {"question": "what is the wingspan of this bird", "gt answer": "3 feet(1.00)<br/>6 feet(0.60)<br/>huge(0.60)", "pred answer": "1 foot", "question_id": 2070055, "best approach": "wiki, concept, image", "verif answer": "6 feet", "anno approach": "concept, wiki", "verif wiki answer": "6 feet(0.7276)", "verif concept answer": "6 feet(0.6748)", "verif image answer": "6 feet(0.6019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207005.jpg"}, {"question": "which item depicted was made with long needles", "gt answer": "hat(1.00)", "pred answer": "candle", "question_id": 3477845, "best approach": "", "verif answer": "coat", "anno approach": "", "verif wiki answer": "bonnet(0.6831)", "verif concept answer": "bonnet(0.7032)", "verif image answer": "coat(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347784.jpg"}, {"question": "the dish in this picture originates from which country", "gt answer": "belgium(1.00)<br/>france(0.60)<br/>england(0.60)<br/>us(0.60)", "pred answer": "united state", "question_id": 3162245, "best approach": "image", "verif answer": "usa", "anno approach": "image", "verif wiki answer": "usa(0.7261)", "verif concept answer": "usa(0.7296)", "verif image answer": "belgium(0.6900)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316224.jpg"}, {"question": "what style of haircut does this man have", "gt answer": "buzz(1.00)<br/>crew cut(0.60)", "pred answer": "short", "question_id": 2534705, "best approach": "image", "verif answer": "crew cut", "anno approach": "image", "verif wiki answer": "tuxedo(0.6632)", "verif concept answer": "tuxedo(0.6740)", "verif image answer": "crew cut(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253470.jpg"}, {"question": "what sort of iconic american west hero is associated with these animals", "gt answer": "cowboy(1.00)", "pred answer": "forest gump", "question_id": 856575, "best approach": "", "verif answer": "farmer", "anno approach": "", "verif wiki answer": "bowler(0.5785)", "verif concept answer": "bowler(0.5238)", "verif image answer": "farmer(0.6416)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085657.jpg"}, {"question": "what bathroom items are along this wall", "gt answer": "toilet(1.00)", "pred answer": "water", "question_id": 4410955, "best approach": "", "verif answer": "toilet seat", "anno approach": "", "verif wiki answer": "toilet seat(0.7228)", "verif concept answer": "toilet seat(0.7264)", "verif image answer": "toilet seat(0.7129)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441095.jpg"}, {"question": "when was this sport invented", "gt answer": "1769(1.00)<br/>1970(0.60)<br/>1960(0.60)", "pred answer": "1965", "question_id": 4032715, "best approach": "wiki, concept, image", "verif answer": "1769", "anno approach": "concept, wiki", "verif wiki answer": "1769(0.7302)", "verif concept answer": "1769(0.7254)", "verif image answer": "1769(0.6750)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403271.jpg"}, {"question": "how long can an elephant go without water", "gt answer": "4 days(1.00)<br/>5 days(1.00)", "pred answer": "2 years", "question_id": 1170625, "best approach": "concept, image", "verif answer": "4 days", "anno approach": "image", "verif wiki answer": "3 days(0.6591)", "verif concept answer": "5 days(0.5514)", "verif image answer": "4 days(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117062.jpg"}, {"question": "what is connected to the pole in the picture", "gt answer": "wire(1.00)<br/>power line(0.60)", "pred answer": "string", "question_id": 679525, "best approach": "wiki, concept, image", "verif answer": "power line", "anno approach": "wiki", "verif wiki answer": "power line(0.7303)", "verif concept answer": "power line(0.7309)", "verif image answer": "power line(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067952.jpg"}, {"question": "what is the outer crust made from", "gt answer": "dough(1.00)<br/>spinach(0.60)<br/>bread(0.60)<br/>flour(0.60)", "pred answer": "dough", "question_id": 2831965, "best approach": "wiki, concept, image", "verif answer": "flour", "anno approach": "image, concept, wiki", "verif wiki answer": "spinach(0.6363)", "verif concept answer": "flour(0.6933)", "verif image answer": "flour(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283196.jpg"}, {"question": "who owns this train", "gt answer": "amtrak(1.00)<br/>government(1.00)<br/>russia(0.60)", "pred answer": "richard trevithick", "question_id": 4348775, "best approach": "wiki, concept", "verif answer": "amtrak", "anno approach": "wiki", "verif wiki answer": "amtrak(0.6831)", "verif concept answer": "amtrak(0.6245)", "verif image answer": "bullet(0.6258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434877.jpg"}, {"question": "is the batter right or left handed", "gt answer": "left(1.00)<br/>right(0.60)", "pred answer": "right", "question_id": 2566435, "best approach": "wiki, concept, image", "verif answer": "right", "anno approach": "wiki", "verif wiki answer": "right(0.7311)", "verif concept answer": "right(0.7311)", "verif image answer": "right(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256643.jpg"}, {"question": "what is used to help the green plant grow", "gt answer": "fertilizer(1.00)<br/>water(0.60)", "pred answer": "grass", "question_id": 3863905, "best approach": "wiki, image", "verif answer": "boogie board", "anno approach": "", "verif wiki answer": "fertilizer(0.6460)", "verif concept answer": "boogie board(0.6488)", "verif image answer": "fertilizer(0.6449)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000386390.jpg"}, {"question": "what is the name brand of this type of transportation", "gt answer": "airfrance(1.00)<br/>boeing(1.00)<br/>airbus(0.60)", "pred answer": "boeing", "question_id": 1133105, "best approach": "wiki, concept, image", "verif answer": "boeing", "anno approach": "image, wiki", "verif wiki answer": "boeing(0.6344)", "verif concept answer": "boeing(0.6170)", "verif image answer": "boeing(0.6879)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113310.jpg"}, {"question": "what might this boy be about to hit", "gt answer": "ball(1.00)", "pred answer": "bat", "question_id": 3804255, "best approach": "wiki, concept, image", "verif answer": "ball", "anno approach": "wiki", "verif wiki answer": "ball(0.7307)", "verif concept answer": "ball(0.7181)", "verif image answer": "ball(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000380425.jpg"}, {"question": "what is it called when a player hits a ball over the wall in this sport", "gt answer": "homerun(1.00)<br/>home run(1.00)<br/>court(0.60)", "pred answer": "strike", "question_id": 5531165, "best approach": "wiki, concept, image", "verif answer": "court", "anno approach": "wiki", "verif wiki answer": "court(0.7305)", "verif concept answer": "court(0.7311)", "verif image answer": "court(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553116.jpg"}, {"question": "what is this room used for", "gt answer": "bath(1.00)<br/>wash hand(0.60)<br/>bathroom(0.60)", "pred answer": "wash", "question_id": 4006195, "best approach": "wiki, image", "verif answer": "bathroom", "anno approach": "image, wiki", "verif wiki answer": "bathroom(0.5522)", "verif concept answer": "wash(0.5460)", "verif image answer": "bathroom(0.6881)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400619.jpg"}, {"question": "what part of the street is this", "gt answer": "intersection(1.00)<br/>hood(0.60)", "pred answer": "street", "question_id": 2666465, "best approach": "concept", "verif answer": "intersection", "anno approach": "concept", "verif wiki answer": "walkway(0.5229)", "verif concept answer": "intersection(0.6567)", "verif image answer": "hood(0.6186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266646.jpg"}, {"question": "how is this food made", "gt answer": "cooked(1.00)", "pred answer": "in oven", "question_id": 3404195, "best approach": "", "verif answer": "fried", "anno approach": "", "verif wiki answer": "fried(0.7288)", "verif concept answer": "fried(0.6900)", "verif image answer": "fried(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340419.jpg"}, {"question": "what does the cake say in english", "gt answer": "happy birthday(1.00)", "pred answer": "hello", "question_id": 1016925, "best approach": "wiki, concept, image", "verif answer": "happy birthday", "anno approach": "", "verif wiki answer": "happy birthday(0.7306)", "verif concept answer": "happy birthday(0.7310)", "verif image answer": "happy birthday(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000101692.jpg"}, {"question": "what is the name of a person who rides these animals in races", "gt answer": "jockey(1.00)", "pred answer": "jockey", "question_id": 758005, "best approach": "wiki, concept, image", "verif answer": "jockey", "anno approach": "concept, wiki", "verif wiki answer": "jockey(0.6629)", "verif concept answer": "jockey(0.6500)", "verif image answer": "jockey(0.5109)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075800.jpg"}, {"question": "what is the green item on this plate for", "gt answer": "garnish(1.00)<br/>decoration(0.60)", "pred answer": "eye", "question_id": 4965135, "best approach": "wiki, concept", "verif answer": "garnish", "anno approach": "wiki", "verif wiki answer": "garnish(0.7304)", "verif concept answer": "garnish(0.6907)", "verif image answer": "paint(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496513.jpg"}, {"question": "what is the common name of the person that polices these", "gt answer": "meter maid(1.00)<br/>maid(0.60)", "pred answer": "steve job", "question_id": 2535285, "best approach": "wiki, concept", "verif answer": "meter maid", "anno approach": "wiki", "verif wiki answer": "meter maid(0.5671)", "verif concept answer": "meter maid(0.5065)", "verif image answer": "baker(0.5611)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253528.jpg"}, {"question": "which type of wood is used to make this bench", "gt answer": "pine(1.00)<br/>oak(0.60)<br/>cedar(0.60)<br/>teak(0.60)", "pred answer": "oak", "question_id": 3060375, "best approach": "wiki, concept, image", "verif answer": "cedar", "anno approach": "wiki", "verif wiki answer": "oak(0.7115)", "verif concept answer": "oak(0.7300)", "verif image answer": "cedar(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306037.jpg"}, {"question": "what kind of outfit is the child wearing", "gt answer": "raincoat(1.00)<br/>rain(0.60)<br/>scarf(0.60)", "pred answer": "button up", "question_id": 2016405, "best approach": "wiki, concept, image", "verif answer": "scarf", "anno approach": "image, wiki", "verif wiki answer": "scarf(0.6195)", "verif concept answer": "scarf(0.6139)", "verif image answer": "scarf(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201640.jpg"}, {"question": "which meal can be eaten in this setting", "gt answer": "picnic(1.00)<br/>lunch(1.00)", "pred answer": "soccer", "question_id": 1251885, "best approach": "", "verif answer": "breakfast", "anno approach": "", "verif wiki answer": "dinner(0.6594)", "verif concept answer": "breakfast(0.7112)", "verif image answer": "dinner(0.6711)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125188.jpg"}, {"question": "what time of day is it", "gt answer": "sunset(1.00)<br/>even(0.60)", "pred answer": "dusk", "question_id": 1708745, "best approach": "wiki, concept", "verif answer": "sunset", "anno approach": "wiki", "verif wiki answer": "sunset(0.7198)", "verif concept answer": "sunset(0.7148)", "verif image answer": "even(0.7183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000170874.jpg"}, {"question": "what kind of bird is this", "gt answer": "toucan(1.00)<br/>parrot(0.60)", "pred answer": "finch", "question_id": 5806525, "best approach": "image", "verif answer": "parrot", "anno approach": "image", "verif wiki answer": "parrot(0.6720)", "verif concept answer": "parrot(0.6849)", "verif image answer": "toucan(0.6726)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580652.jpg"}, {"question": "namw what kind of wood is used to make this table shown in this picture", "gt answer": "oak(1.00)<br/>cherry(0.60)", "pred answer": "oak", "question_id": 5341305, "best approach": "wiki, concept", "verif answer": "mahogany", "anno approach": "wiki", "verif wiki answer": "oak(0.7309)", "verif concept answer": "oak(0.7301)", "verif image answer": "mahogany(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534130.jpg"}, {"question": "which emergency service is in this photo", "gt answer": "tow(1.00)<br/>police(1.00)", "pred answer": "public", "question_id": 2775765, "best approach": "image", "verif answer": "police", "anno approach": "image", "verif wiki answer": "police officer(0.6973)", "verif concept answer": "tow truck(0.6182)", "verif image answer": "police(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277576.jpg"}, {"question": "what is the weather like", "gt answer": "rainy(1.00)<br/>rain(1.00)", "pred answer": "rain", "question_id": 395805, "best approach": "wiki, concept, image", "verif answer": "rain", "anno approach": "image, concept, wiki", "verif wiki answer": "rain(0.5233)", "verif concept answer": "rain(0.5673)", "verif image answer": "rain(0.5526)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039580.jpg"}, {"question": "who is the famous cartoon version of this animal first seen in 1958", "gt answer": "yogi(1.00)", "pred answer": "0", "question_id": 5614485, "best approach": "", "verif answer": "thomas tank engine", "anno approach": "", "verif wiki answer": "thomas tank engine(0.5007)", "verif concept answer": "madagascar(0.5001)", "verif image answer": "thomas tank engine(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561448.jpg"}, {"question": "what might this man collect or repair", "gt answer": "clock(1.00)", "pred answer": "study", "question_id": 4114925, "best approach": "", "verif answer": "tell time", "anno approach": "", "verif wiki answer": "tell time(0.7310)", "verif concept answer": "tell time(0.7306)", "verif image answer": "tell time(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000411492.jpg"}, {"question": "where is the man in the boat", "gt answer": "middle(1.00)<br/>on lake(0.60)", "pred answer": "paddle", "question_id": 4506085, "best approach": "wiki, concept, image", "verif answer": "on lake", "anno approach": "wiki", "verif wiki answer": "on lake(0.7310)", "verif concept answer": "on lake(0.7297)", "verif image answer": "on lake(0.7046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450608.jpg"}, {"question": "who is in this picture", "gt answer": "old woman(1.00)<br/>women(0.60)<br/>seagull(0.60)", "pred answer": "female", "question_id": 1350455, "best approach": "wiki, concept, image", "verif answer": "seagull", "anno approach": "image, wiki", "verif wiki answer": "seagull(0.6855)", "verif concept answer": "seagull(0.6717)", "verif image answer": "seagull(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000135045.jpg"}, {"question": "what model of toyota is shown", "gt answer": "corolla(1.00)", "pred answer": "ford", "question_id": 3027135, "best approach": "", "verif answer": "suv", "anno approach": "", "verif wiki answer": "jeep(0.7064)", "verif concept answer": "jeep(0.7066)", "verif image answer": "suv(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302713.jpg"}, {"question": "who was the first to create one of these signs", "gt answer": "william phelps eno(1.00)", "pred answer": "plumber", "question_id": 4251875, "best approach": "wiki, concept, image", "verif answer": "william phelps eno", "anno approach": "concept, wiki", "verif wiki answer": "william phelps eno(0.6851)", "verif concept answer": "william phelps eno(0.6907)", "verif image answer": "william phelps eno(0.6424)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425187.jpg"}, {"question": "what year did this action figures first get released", "gt answer": "1977(1.00)", "pred answer": "2004", "question_id": 1036765, "best approach": "wiki, concept", "verif answer": "1977", "anno approach": "", "verif wiki answer": "1977(0.6527)", "verif concept answer": "1977(0.6600)", "verif image answer": "1998(0.6359)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103676.jpg"}, {"question": "although this is a british plane which colors shown here are also famously associated with the us", "gt answer": "red white and blue(1.00)", "pred answer": "american", "question_id": 4663015, "best approach": "wiki, concept, image", "verif answer": "red white and blue", "anno approach": "", "verif wiki answer": "red white and blue(0.7310)", "verif concept answer": "red white and blue(0.7132)", "verif image answer": "red white and blue(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466301.jpg"}, {"question": "which zodiac sign is like an animal seen here", "gt answer": "ram(1.00)<br/>aries(0.60)<br/>goat(0.60)", "pred answer": "aries", "question_id": 2492565, "best approach": "wiki, concept, image", "verif answer": "aries", "anno approach": "wiki", "verif wiki answer": "aries(0.7311)", "verif concept answer": "aries(0.7311)", "verif image answer": "aries(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249256.jpg"}, {"question": "what do these animals eat", "gt answer": "cat food(1.00)<br/>meat(1.00)<br/>mice(0.60)", "pred answer": "cat food", "question_id": 924805, "best approach": "", "verif answer": "pet food", "anno approach": "", "verif wiki answer": "pet food(0.7310)", "verif concept answer": "pet food(0.7311)", "verif image answer": "pet food(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092480.jpg"}, {"question": "which company based in finland produces these", "gt answer": "nokia(1.00)", "pred answer": "motorola", "question_id": 1852005, "best approach": "", "verif answer": "motorola", "anno approach": "", "verif wiki answer": "motorola(0.7249)", "verif concept answer": "motorola(0.7290)", "verif image answer": "motorola(0.6703)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185200.jpg"}, {"question": "what are the objects on", "gt answer": "table(1.00)", "pred answer": "desk", "question_id": 5377825, "best approach": "", "verif answer": "counter", "anno approach": "", "verif wiki answer": "bench(0.7252)", "verif concept answer": "counter(0.7310)", "verif image answer": "bench(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537782.jpg"}, {"question": "what are the two players doing by the net", "gt answer": "talk(1.00)<br/>shake hand(1.00)", "pred answer": "play tennis", "question_id": 832545, "best approach": "wiki, concept", "verif answer": "talk", "anno approach": "wiki", "verif wiki answer": "talk(0.6921)", "verif concept answer": "talk(0.7179)", "verif image answer": "play tennis(0.6789)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083254.jpg"}, {"question": "what kind of nuts are on top of this broccoli salad", "gt answer": "sesame(0.60)<br/>pistachio(0.60)<br/>cashew(1.00)<br/>walnut(0.60)", "pred answer": "wheat", "question_id": 3605255, "best approach": "wiki, concept", "verif answer": "cashew", "anno approach": "concept", "verif wiki answer": "cashew(0.5055)", "verif concept answer": "cashew(0.5448)", "verif image answer": "sesame(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000360525.jpg"}, {"question": "what breed of bird is pictured", "gt answer": "hornbill(1.00)", "pred answer": "monkey", "question_id": 2493065, "best approach": "concept, image", "verif answer": "hornbill", "anno approach": "concept", "verif wiki answer": "crow(0.5501)", "verif concept answer": "hornbill(0.5719)", "verif image answer": "hornbill(0.5189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249306.jpg"}, {"question": "what is the name of this water sport", "gt answer": "wakeboarding(1.00)<br/>water ski(0.60)", "pred answer": "water ski", "question_id": 3792305, "best approach": "wiki, concept, image", "verif answer": "water ski", "anno approach": "wiki", "verif wiki answer": "water ski(0.7309)", "verif concept answer": "water ski(0.7285)", "verif image answer": "water ski(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379230.jpg"}, {"question": "what kind of sandwich is this", "gt answer": "hoagie(1.00)<br/>sub(1.00)", "pred answer": "italian", "question_id": 899125, "best approach": "concept, image", "verif answer": "sub", "anno approach": "", "verif wiki answer": "mcrib(0.6454)", "verif concept answer": "sub(0.7089)", "verif image answer": "sub(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089912.jpg"}, {"question": "what kind of picture is the girl on the end taking", "gt answer": "selfie(1.00)", "pred answer": "door", "question_id": 4302575, "best approach": "", "verif answer": "candid", "anno approach": "", "verif wiki answer": "candid(0.6634)", "verif concept answer": "candid(0.7247)", "verif image answer": "candid(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430257.jpg"}, {"question": "what is the larger piece of furniture called", "gt answer": "couch(1.00)<br/>sofa(1.00)", "pred answer": "couch", "question_id": 3468675, "best approach": "wiki, concept, image", "verif answer": "couch", "anno approach": "image, wiki", "verif wiki answer": "couch(0.7205)", "verif concept answer": "couch(0.6554)", "verif image answer": "couch(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346867.jpg"}, {"question": "what do these forms of transportation run off of", "gt answer": "jet fuel(1.00)<br/>fuel(0.60)<br/>runway(0.60)", "pred answer": "cloud", "question_id": 1909645, "best approach": "wiki, concept, image", "verif answer": "runway", "anno approach": "image, wiki", "verif wiki answer": "runway(0.7308)", "verif concept answer": "runway(0.6629)", "verif image answer": "fuel(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190964.jpg"}, {"question": "what color are the round objects", "gt answer": "silver(1.00)", "pred answer": "red", "question_id": 3024435, "best approach": "", "verif answer": "grey", "anno approach": "", "verif wiki answer": "gray(0.6415)", "verif concept answer": "gray(0.6161)", "verif image answer": "grey(0.6841)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302443.jpg"}, {"question": "is this pool inside or outside", "gt answer": "inside(1.00)", "pred answer": "outside", "question_id": 2584005, "best approach": "", "verif answer": "outside", "anno approach": "", "verif wiki answer": "outside(0.7301)", "verif concept answer": "outside(0.7304)", "verif image answer": "outside(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258400.jpg"}, {"question": "what is the batter 's name", "gt answer": "fowler(1.00)<br/>dexter(0.60)", "pred answer": "jackie robinson", "question_id": 3876065, "best approach": "", "verif answer": "babe ruth", "anno approach": "", "verif wiki answer": "babe ruth(0.6218)", "verif concept answer": "babe ruth(0.5711)", "verif image answer": "babe ruth(0.5253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387606.jpg"}, {"question": "is this a competitive or casual game", "gt answer": "casual(1.00)", "pred answer": "tournament", "question_id": 902585, "best approach": "wiki, concept, image", "verif answer": "casual", "anno approach": "concept, wiki", "verif wiki answer": "casual(0.7075)", "verif concept answer": "casual(0.7272)", "verif image answer": "casual(0.6504)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090258.jpg"}, {"question": "which type of meat are in the photo", "gt answer": "hotdogs(1.00)<br/>hotdog(0.60)<br/>hot dog(0.60)", "pred answer": "hotdog", "question_id": 981235, "best approach": "wiki, concept, image", "verif answer": "hotdog", "anno approach": "wiki", "verif wiki answer": "hotdog(0.6516)", "verif concept answer": "hotdog(0.6544)", "verif image answer": "hotdog(0.6432)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098123.jpg"}, {"question": "is this cat relaxing or waiting to ambush human prey", "gt answer": "relax(1.00)", "pred answer": "rest", "question_id": 3630385, "best approach": "", "verif answer": "watch tv", "anno approach": "", "verif wiki answer": "watch tv(0.6849)", "verif concept answer": "watch tv(0.7270)", "verif image answer": "watch tv(0.5350)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363038.jpg"}, {"question": "what brand of chips are on the fridge", "gt answer": "ruffle(1.00)<br/>cracker(0.60)", "pred answer": "oakley", "question_id": 5153775, "best approach": "", "verif answer": "potato", "anno approach": "", "verif wiki answer": "potato(0.5498)", "verif concept answer": "potato(0.5680)", "verif image answer": "potato(0.5543)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515377.jpg"}, {"question": "what country could you find a market like this", "gt answer": "vietnam(1.00)<br/>thailand(0.60)<br/>mexico(0.60)", "pred answer": "thailand", "question_id": 4698515, "best approach": "", "verif answer": "chinese", "anno approach": "", "verif wiki answer": "japan(0.6365)", "verif concept answer": "chinese(0.6645)", "verif image answer": "chinese(0.6505)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469851.jpg"}, {"question": "what is the general purpose of this cutting device", "gt answer": "cut(1.00)", "pred answer": "protection", "question_id": 3671005, "best approach": "", "verif answer": "stab", "anno approach": "", "verif wiki answer": "stab(0.7252)", "verif concept answer": "stab(0.7038)", "verif image answer": "haircut(0.6310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367100.jpg"}, {"question": "how did that woman get her hair to look like the flower", "gt answer": "dye(1.00)", "pred answer": "brush", "question_id": 5157045, "best approach": "concept, image", "verif answer": "dye", "anno approach": "concept", "verif wiki answer": "light(0.5060)", "verif concept answer": "dye(0.5538)", "verif image answer": "dye(0.5027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515704.jpg"}, {"question": "what jewler does the seated woman on the left have on her arm", "gt answer": "bracelet(1.00)<br/>tiffany(0.60)", "pred answer": "napkin", "question_id": 919265, "best approach": "", "verif answer": "ben franklin", "anno approach": "", "verif wiki answer": "ben franklin(0.7208)", "verif concept answer": "ben franklin(0.6993)", "verif image answer": "ben franklin(0.7019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000091926.jpg"}, {"question": "what type of event could this be", "gt answer": "equestrian(1.00)<br/>horse show(0.60)<br/>race(0.60)", "pred answer": "horse race", "question_id": 3839305, "best approach": "", "verif answer": "rodeo", "anno approach": "", "verif wiki answer": "rodeo(0.7301)", "verif concept answer": "rodeo(0.7024)", "verif image answer": "rodeo(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383930.jpg"}, {"question": "name the type of wood used to make this sitting bench shown in this picture", "gt answer": "teak(1.00)<br/>pine(1.00)", "pred answer": "oak", "question_id": 4841365, "best approach": "", "verif answer": "cedar", "anno approach": "", "verif wiki answer": "oak(0.6656)", "verif concept answer": "oak(0.6912)", "verif image answer": "cedar(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484136.jpg"}, {"question": "what does that truck haul", "gt answer": "cement(1.00)", "pred answer": "people", "question_id": 5536595, "best approach": "", "verif answer": "tow", "anno approach": "", "verif wiki answer": "tow(0.7294)", "verif concept answer": "tow(0.7310)", "verif image answer": "tow(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553659.jpg"}, {"question": "if these strangers had a missed connection what section of the news paper would they list it", "gt answer": "classified(1.00)<br/>person(0.60)", "pred answer": "read", "question_id": 2091325, "best approach": "image", "verif answer": "new york", "anno approach": "image", "verif wiki answer": "new york(0.5001)", "verif concept answer": "new york(0.5001)", "verif image answer": "person(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209132.jpg"}, {"question": "what is the distance between this couple and the mountain behind them", "gt answer": "2 miles(1.00)<br/>1 mile(1.00)", "pred answer": "30 feet", "question_id": 391375, "best approach": "wiki, concept, image", "verif answer": "1 mile", "anno approach": "", "verif wiki answer": "1 mile(0.6805)", "verif concept answer": "1 mile(0.6839)", "verif image answer": "1 mile(0.6707)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039137.jpg"}, {"question": "what is the occasion", "gt answer": "wed(1.00)<br/>birthday(0.60)", "pred answer": "birthday", "question_id": 1163565, "best approach": "", "verif answer": "marriage", "anno approach": "", "verif wiki answer": "marriage(0.6924)", "verif concept answer": "party(0.6581)", "verif image answer": "press conference(0.6670)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116356.jpg"}, {"question": "what kind of store are these tools in", "gt answer": "hardware(1.00)<br/>hardware store(0.60)<br/>shoemaker(0.60)", "pred answer": "produce", "question_id": 1831005, "best approach": "wiki, concept, image", "verif answer": "shoemaker", "anno approach": "concept, wiki", "verif wiki answer": "shoemaker(0.7310)", "verif concept answer": "shoemaker(0.7306)", "verif image answer": "shoemaker(0.6927)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183100.jpg"}, {"question": "what action is the person in the picture performing", "gt answer": "clean(1.00)<br/>(0.60)", "pred answer": "swing", "question_id": 1300115, "best approach": "", "verif answer": "messy", "anno approach": "", "verif wiki answer": "messy(0.6458)", "verif concept answer": "messy(0.6811)", "verif image answer": "messy(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130011.jpg"}, {"question": "what meal would this be called", "gt answer": "breakfast(1.00)", "pred answer": "lunch", "question_id": 932675, "best approach": "concept", "verif answer": "egg benedict", "anno approach": "concept", "verif wiki answer": "egg benedict(0.7157)", "verif concept answer": "breakfast(0.7309)", "verif image answer": "egg benedict(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093267.jpg"}, {"question": "what kind of hat is being worn", "gt answer": "bowler(1.00)<br/>fedora(0.60)", "pred answer": "fedora", "question_id": 2791755, "best approach": "wiki, concept, image", "verif answer": "fedora", "anno approach": "wiki", "verif wiki answer": "fedora(0.7210)", "verif concept answer": "fedora(0.7305)", "verif image answer": "fedora(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000279175.jpg"}, {"question": "what brand of car is that", "gt answer": "buick(1.00)<br/>lincoln(1.00)<br/>mercedes(0.60)", "pred answer": "ford", "question_id": 2768945, "best approach": "wiki, concept, image", "verif answer": "buick", "anno approach": "", "verif wiki answer": "buick(0.7278)", "verif concept answer": "buick(0.7292)", "verif image answer": "buick(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276894.jpg"}, {"question": "who sewed the first one of these that are being carried", "gt answer": "betsy ross(1.00)", "pred answer": "schwinn", "question_id": 4612265, "best approach": "", "verif answer": "richard trevithick", "anno approach": "", "verif wiki answer": "richard trevithick(0.7289)", "verif concept answer": "richard trevithick(0.6679)", "verif image answer": "alexander graham bell(0.7110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461226.jpg"}, {"question": "what roles would this train serve", "gt answer": "transportation(1.00)<br/>travel(0.60)<br/>transport(0.60)", "pred answer": "transport", "question_id": 1550615, "best approach": "wiki, image", "verif answer": "transport", "anno approach": "wiki", "verif wiki answer": "transport(0.7031)", "verif concept answer": "fun(0.6721)", "verif image answer": "transport(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155061.jpg"}, {"question": "how much rom does that laptop have", "gt answer": "1 gigabyte(1.00)<br/>8(0.60)", "pred answer": "500", "question_id": 3775705, "best approach": "concept", "verif answer": "2", "anno approach": "concept", "verif wiki answer": "2(0.5553)", "verif concept answer": "1 gigabyte(0.5466)", "verif image answer": "2(0.6062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377570.jpg"}, {"question": "what is the scientific name of the animal on the right", "gt answer": "felis catus(1.00)<br/>feline(1.00)<br/>cat(0.60)", "pred answer": "feline", "question_id": 5279255, "best approach": "wiki, concept, image", "verif answer": "feline", "anno approach": "wiki", "verif wiki answer": "feline(0.7310)", "verif concept answer": "feline(0.7309)", "verif image answer": "feline(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527925.jpg"}, {"question": "what kind of material is the pants of the girl on the right", "gt answer": "denim(1.00)<br/>jean(1.00)", "pred answer": "denim", "question_id": 1550495, "best approach": "wiki, concept, image", "verif answer": "denim", "anno approach": "wiki", "verif wiki answer": "denim(0.7310)", "verif concept answer": "denim(0.7311)", "verif image answer": "denim(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155049.jpg"}, {"question": "what type of pizza is this slice", "gt answer": "supreme(1.00)<br/>veggie(0.60)", "pred answer": "chicago", "question_id": 2164325, "best approach": "image", "verif answer": "supreme", "anno approach": "image", "verif wiki answer": "pepperoni(0.6675)", "verif concept answer": "pepperoni(0.6933)", "verif image answer": "supreme(0.7008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216432.jpg"}, {"question": "is this pollution or clouds", "gt answer": "pollution(1.00)", "pred answer": "land", "question_id": 3704175, "best approach": "image", "verif answer": "light", "anno approach": "image", "verif wiki answer": "light(0.5099)", "verif concept answer": "light(0.5016)", "verif image answer": "pollution(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370417.jpg"}, {"question": "what is this jacket made of", "gt answer": "denim(1.00)<br/>jean(0.60)", "pred answer": "cotton", "question_id": 1711035, "best approach": "concept", "verif answer": "lee", "anno approach": "concept", "verif wiki answer": "lee(0.7282)", "verif concept answer": "jean(0.6725)", "verif image answer": "cotton(0.6410)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171103.jpg"}, {"question": "where are these people located", "gt answer": "hospital(1.00)", "pred answer": "home", "question_id": 5759295, "best approach": "image", "verif answer": "army", "anno approach": "image", "verif wiki answer": "army(0.7267)", "verif concept answer": "army(0.7288)", "verif image answer": "hospital(0.6707)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575929.jpg"}, {"question": "what does this animal produce that people use", "gt answer": "wool(1.00)<br/>milk(0.60)", "pred answer": "grass", "question_id": 1343065, "best approach": "wiki, concept, image", "verif answer": "wool", "anno approach": "wiki", "verif wiki answer": "wool(0.7247)", "verif concept answer": "wool(0.7296)", "verif image answer": "wool(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134306.jpg"}, {"question": "the pictured animals produce what drink", "gt answer": "milk(1.00)", "pred answer": "milk", "question_id": 3771885, "best approach": "", "verif answer": "meat", "anno approach": "", "verif wiki answer": "wool(0.6233)", "verif concept answer": "wool(0.7077)", "verif image answer": "meat(0.7189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377188.jpg"}, {"question": "what makes an apple red instead of green", "gt answer": "ripe(1.00)<br/>beta carotene(0.60)", "pred answer": "tomato", "question_id": 214475, "best approach": "concept, image", "verif answer": "ripe", "anno approach": "concept", "verif wiki answer": "over ripe(0.6280)", "verif concept answer": "ripe(0.6349)", "verif image answer": "ripe(0.5678)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000021447.jpg"}, {"question": "what religion does this family belong to", "gt answer": "christian(1.00)<br/>christianity(0.60)<br/>catholic(0.60)", "pred answer": "catholic", "question_id": 1054705, "best approach": "wiki", "verif answer": "buddhism", "anno approach": "wiki", "verif wiki answer": "catholic(0.5039)", "verif concept answer": "muslim(0.5002)", "verif image answer": "buddhism(0.5117)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105470.jpg"}, {"question": "what type of plane is this", "gt answer": "cessna(1.00)<br/>propeller(0.60)<br/>biplane(0.60)", "pred answer": "jet", "question_id": 3879775, "best approach": "wiki, concept, image", "verif answer": "biplane", "anno approach": "wiki", "verif wiki answer": "biplane(0.7308)", "verif concept answer": "biplane(0.7254)", "verif image answer": "biplane(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387977.jpg"}, {"question": "these types of boats would work well in which type of weather", "gt answer": "windy(1.00)<br/>sunny(1.00)<br/>fish boat(0.60)", "pred answer": "hot", "question_id": 3459445, "best approach": "wiki, concept", "verif answer": "warm", "anno approach": "wiki", "verif wiki answer": "sunny(0.6575)", "verif concept answer": "sunny(0.6795)", "verif image answer": "warm(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345944.jpg"}, {"question": "what food is this", "gt answer": "croissant(1.00)<br/>breakfast(0.60)<br/>tea time(0.60)<br/>pastry(0.60)", "pred answer": "breakfast", "question_id": 4428865, "best approach": "wiki, concept", "verif answer": "tea time", "anno approach": "", "verif wiki answer": "tea time(0.7308)", "verif concept answer": "tea time(0.7308)", "verif image answer": "street(0.6967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442886.jpg"}, {"question": "what type of drink is probably in the glass", "gt answer": "orange juice(1.00)<br/>tea(0.60)", "pred answer": "beer", "question_id": 1068325, "best approach": "wiki, concept, image", "verif answer": "tea", "anno approach": "concept, wiki", "verif wiki answer": "tea(0.6780)", "verif concept answer": "tea(0.7180)", "verif image answer": "tea(0.6926)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106832.jpg"}, {"question": "what game are they playing", "gt answer": "frisbee(1.00)", "pred answer": "frisbee", "question_id": 5562225, "best approach": "", "verif answer": "soccer", "anno approach": "", "verif wiki answer": "picnic(0.6635)", "verif concept answer": "picnic(0.5768)", "verif image answer": "soccer(0.7075)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556222.jpg"}, {"question": "name the dress material type weared by the baby in this picture", "gt answer": "flannel(1.00)<br/>wool(1.00)<br/>cotton(0.60)", "pred answer": "polyester", "question_id": 2361555, "best approach": "concept, image", "verif answer": "fleece", "anno approach": "", "verif wiki answer": "fleece(0.6475)", "verif concept answer": "flannel(0.6426)", "verif image answer": "flannel(0.6399)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236155.jpg"}, {"question": "what is the brown stuff atop the broccoli", "gt answer": "bacon(1.00)<br/>broccoli(0.60)", "pred answer": "tomato", "question_id": 514345, "best approach": "", "verif answer": "tomato", "anno approach": "", "verif wiki answer": "tomato(0.6446)", "verif concept answer": "tomato(0.6478)", "verif image answer": "tomato(0.5466)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000051434.jpg"}, {"question": "what breed of dog is this", "gt answer": "chihuaha(1.00)<br/>chihuahua(0.60)", "pred answer": "collie", "question_id": 5815, "best approach": "", "verif answer": "mutt", "anno approach": "", "verif wiki answer": "mutt(0.7303)", "verif concept answer": "mutt(0.7310)", "verif image answer": "mutt(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000581.jpg"}, {"question": "what is the metal apparatus seen here used for", "gt answer": "water fountain(1.00)<br/>drink water(0.60)<br/>drink(0.60)<br/>water(0.60)", "pred answer": "telephone", "question_id": 4958025, "best approach": "image", "verif answer": "water fountain", "anno approach": "image", "verif wiki answer": "drink(0.5008)", "verif concept answer": "drink(0.5360)", "verif image answer": "water fountain(0.7078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495802.jpg"}, {"question": "on which slope are these skiers and snowboarders", "gt answer": "mountain(1.00)<br/>alpine(0.60)", "pred answer": "alp", "question_id": 96085, "best approach": "", "verif answer": "alp", "anno approach": "", "verif wiki answer": "alp(0.7311)", "verif concept answer": "alp(0.7311)", "verif image answer": "alp(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009608.jpg"}, {"question": "what was the engine of this vehicle made of", "gt answer": "steel(1.00)<br/>metal(1.00)<br/>iron(0.60)", "pred answer": "gasoline", "question_id": 4957565, "best approach": "image", "verif answer": "iron", "anno approach": "image", "verif wiki answer": "aluminum(0.5343)", "verif concept answer": "aluminum(0.5796)", "verif image answer": "iron(0.7239)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495756.jpg"}, {"question": "where is this bus going", "gt answer": "downtown(1.00)<br/>new york(0.60)", "pred answer": "tour", "question_id": 2827895, "best approach": "image", "verif answer": "new york", "anno approach": "image", "verif wiki answer": "london(0.6485)", "verif concept answer": "london(0.5438)", "verif image answer": "new york(0.6672)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282789.jpg"}, {"question": "what type of person drives the yellow train", "gt answer": "engineer(1.00)<br/>conductor(1.00)", "pred answer": "conductor", "question_id": 5691905, "best approach": "wiki, concept, image", "verif answer": "conductor", "anno approach": "concept, wiki", "verif wiki answer": "conductor(0.7310)", "verif concept answer": "conductor(0.7298)", "verif image answer": "conductor(0.6897)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569190.jpg"}, {"question": "where would one go to buy these items", "gt answer": "market(1.00)<br/>supermarket(0.60)<br/>farmer market(0.60)<br/>grocery store(0.60)", "pred answer": "store", "question_id": 1278665, "best approach": "image", "verif answer": "supermarket", "anno approach": "image", "verif wiki answer": "supermarket(0.7294)", "verif concept answer": "farmer market(0.6914)", "verif image answer": "market(0.5597)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127866.jpg"}, {"question": "what type of clouds are these", "gt answer": "cumulus(1.00)", "pred answer": "cumulus", "question_id": 5287615, "best approach": "wiki, concept", "verif answer": "cirrus", "anno approach": "wiki", "verif wiki answer": "cumulus(0.6631)", "verif concept answer": "cumulus(0.6604)", "verif image answer": "cirrus(0.6724)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528761.jpg"}, {"question": "what year was this vehicle in use", "gt answer": "1950(1.00)<br/>1970(0.60)<br/>1940(0.60)", "pred answer": "1965", "question_id": 2937205, "best approach": "concept, image", "verif answer": "1950", "anno approach": "concept", "verif wiki answer": "1940(0.6945)", "verif concept answer": "1950(0.6997)", "verif image answer": "1950(0.6559)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293720.jpg"}, {"question": "what kind of business is this", "gt answer": "sale(1.00)", "pred answer": "computer", "question_id": 5413135, "best approach": "", "verif answer": "litter", "anno approach": "", "verif wiki answer": "litter(0.5002)", "verif concept answer": "litter(0.5015)", "verif image answer": "litter(0.6310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541313.jpg"}, {"question": "what type of picture is on the back wall", "gt answer": "caricature(1.00)", "pred answer": "map", "question_id": 3701455, "best approach": "", "verif answer": "framed", "anno approach": "", "verif wiki answer": "framed(0.6984)", "verif concept answer": "framed(0.6454)", "verif image answer": "framed(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370145.jpg"}, {"question": "which type of wood is used to make this brown chair shown in this photo", "gt answer": "wicker(1.00)<br/>oak(1.00)<br/>mahogany(0.60)", "pred answer": "bamboo", "question_id": 5235715, "best approach": "wiki, concept, image", "verif answer": "oak", "anno approach": "image, wiki", "verif wiki answer": "oak(0.7034)", "verif concept answer": "oak(0.6754)", "verif image answer": "oak(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523571.jpg"}, {"question": "what is the guy wearing a brown shirt doing", "gt answer": "photograph(0.60)<br/>take picture(1.00)<br/>drink(0.60)", "pred answer": "stand", "question_id": 1819295, "best approach": "", "verif answer": "take photo", "anno approach": "", "verif wiki answer": "take photo(0.7274)", "verif concept answer": "take photo(0.7198)", "verif image answer": "take photo(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181929.jpg"}, {"question": "are the carbs shown here processed or unrefined", "gt answer": "processed(1.00)", "pred answer": "raw", "question_id": 753695, "best approach": "", "verif answer": "fresh", "anno approach": "", "verif wiki answer": "fresh(0.5000)", "verif concept answer": "fresh(0.5000)", "verif image answer": "fresh(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075369.jpg"}, {"question": "what cause that fluid to rise that high", "gt answer": "wave(1.00)<br/>moon(0.60)", "pred answer": "wave", "question_id": 160715, "best approach": "wiki", "verif answer": "shark", "anno approach": "wiki", "verif wiki answer": "wave(0.6462)", "verif concept answer": "shark(0.5877)", "verif image answer": "shark(0.6590)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016071.jpg"}, {"question": "where can i buy that chair", "gt answer": "walmart(1.00)<br/>store(0.60)<br/>target(0.60)<br/>online(0.60)", "pred answer": "ikea", "question_id": 3177815, "best approach": "wiki", "verif answer": "online", "anno approach": "wiki", "verif wiki answer": "online(0.6985)", "verif concept answer": "amazon(0.6512)", "verif image answer": "amazon(0.5517)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317781.jpg"}, {"question": "is this person homeless or a pirate", "gt answer": "homeless(1.00)<br/>pirate(1.00)", "pred answer": "illegal", "question_id": 2142525, "best approach": "", "verif answer": "lazy", "anno approach": "", "verif wiki answer": "lazy(0.5131)", "verif concept answer": "lazy(0.5324)", "verif image answer": "lazy(0.5601)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214252.jpg"}, {"question": "what type of lightning technique is used in this kitchen", "gt answer": "track light(1.00)<br/>track(0.60)<br/>overhead(0.60)", "pred answer": "overhead", "question_id": 5451605, "best approach": "", "verif answer": "transportation", "anno approach": "", "verif wiki answer": "transportation(0.5035)", "verif concept answer": "transportation(0.5594)", "verif image answer": "transportation(0.5045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545160.jpg"}, {"question": "what are these people celebrating", "gt answer": "graduation(1.00)<br/>birthday(1.00)", "pred answer": "birthday", "question_id": 5084495, "best approach": "", "verif answer": "mardi gras", "anno approach": "", "verif wiki answer": "mardi gras(0.7260)", "verif concept answer": "gay pride(0.6584)", "verif image answer": "gay pride(0.6735)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000508449.jpg"}, {"question": "what is this structure made of", "gt answer": "steel(1.00)<br/>iron(0.60)", "pred answer": "metal", "question_id": 4636205, "best approach": "wiki, image", "verif answer": "steel", "anno approach": "image, wiki", "verif wiki answer": "steel(0.6470)", "verif concept answer": "iron(0.6656)", "verif image answer": "steel(0.7112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463620.jpg"}, {"question": "what food is this", "gt answer": "crab cake(1.00)<br/>lunch(0.60)", "pred answer": "bread", "question_id": 2498755, "best approach": "image", "verif answer": "crab cake", "anno approach": "image", "verif wiki answer": "breakfast(0.6566)", "verif concept answer": "breakfast(0.6711)", "verif image answer": "crab cake(0.6722)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249875.jpg"}, {"question": "name the material used to make the cot shown in this picture", "gt answer": "metal(1.00)<br/>nylon(0.60)", "pred answer": "cotton", "question_id": 3987725, "best approach": "wiki, concept", "verif answer": "nylon", "anno approach": "wiki", "verif wiki answer": "nylon(0.6928)", "verif concept answer": "nylon(0.6470)", "verif image answer": "steel(0.6640)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398772.jpg"}, {"question": "what type of breed is this", "gt answer": "pony(1.00)<br/>shetland(0.60)<br/>mustang(0.60)", "pred answer": "horse", "question_id": 384875, "best approach": "", "verif answer": "arabian", "anno approach": "", "verif wiki answer": "horse(0.6602)", "verif concept answer": "horse(0.6545)", "verif image answer": "arabian(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038487.jpg"}, {"question": "what us city is famous for this type of pizza", "gt answer": "chicago(1.00)<br/>miami(0.60)<br/>new york(0.60)", "pred answer": "chicago", "question_id": 2087145, "best approach": "concept, image", "verif answer": "chicago", "anno approach": "concept", "verif wiki answer": "new york(0.7204)", "verif concept answer": "chicago(0.7305)", "verif image answer": "chicago(0.6295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208714.jpg"}, {"question": "what time is it on the clock face", "gt answer": "12:24(1.00)", "pred answer": "9:25", "question_id": 1641895, "best approach": "wiki, concept", "verif answer": "12:24", "anno approach": "", "verif wiki answer": "12:24(0.6653)", "verif concept answer": "12:24(0.6462)", "verif image answer": "san francisco(0.6512)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000164189.jpg"}, {"question": "what model of boat is this", "gt answer": "sailboat(1.00)<br/>sail(1.00)", "pred answer": "sail", "question_id": 2927525, "best approach": "wiki, image", "verif answer": "sail", "anno approach": "wiki", "verif wiki answer": "sail(0.7280)", "verif concept answer": "regatta(0.7183)", "verif image answer": "sailboat(0.5888)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292752.jpg"}, {"question": "which pop band from the 1960 's sang about this sport", "gt answer": "beach boy(1.00)", "pred answer": "beach boy", "question_id": 2681925, "best approach": "wiki, concept, image", "verif answer": "beach boy", "anno approach": "wiki", "verif wiki answer": "beach boy(0.7309)", "verif concept answer": "beach boy(0.7310)", "verif image answer": "beach boy(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268192.jpg"}, {"question": "what type of car is the man driving", "gt answer": "suv(1.00)<br/>jeep(1.00)", "pred answer": "pickup", "question_id": 2285195, "best approach": "", "verif answer": "station wagon", "anno approach": "", "verif wiki answer": "station wagon(0.7290)", "verif concept answer": "station wagon(0.7235)", "verif image answer": "station wagon(0.6530)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000228519.jpg"}, {"question": "what hairstyle here is a party in the back and business in the front", "gt answer": "mullet(1.00)", "pred answer": "ponytail", "question_id": 2433045, "best approach": "wiki, concept, image", "verif answer": "mullet", "anno approach": "concept, wiki", "verif wiki answer": "mullet(0.6311)", "verif concept answer": "mullet(0.6181)", "verif image answer": "mullet(0.5652)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243304.jpg"}, {"question": "what kind of shirt does the child wear", "gt answer": "tshirt(1.00)<br/>tee(0.60)<br/>t shirt(0.60)", "pred answer": "button down", "question_id": 459895, "best approach": "", "verif answer": "polo", "anno approach": "", "verif wiki answer": "polo(0.6310)", "verif concept answer": "polo(0.6074)", "verif image answer": "button up(0.6193)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045989.jpg"}, {"question": "how are the drawers of the cabinet next to the sink constructed", "gt answer": "wicker(1.00)<br/>4(0.60)<br/>rattan(0.60)<br/>basket(0.60)", "pred answer": "metal", "question_id": 5790655, "best approach": "wiki, concept, image", "verif answer": "rattan", "anno approach": "concept, wiki", "verif wiki answer": "rattan(0.5994)", "verif concept answer": "rattan(0.5469)", "verif image answer": "basket(0.5014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000579065.jpg"}, {"question": "is this coffee accompaniment baked frozen or both", "gt answer": "baked(1.00)", "pred answer": "bread", "question_id": 1068305, "best approach": "", "verif answer": "bake", "anno approach": "", "verif wiki answer": "bake(0.7310)", "verif concept answer": "bake(0.7310)", "verif image answer": "baked in oven(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106830.jpg"}, {"question": "who wouldn't eat this", "gt answer": "kid(0.60)<br/>vegan(0.60)<br/>vegetarian(1.00)", "pred answer": "italian", "question_id": 282635, "best approach": "wiki, image", "verif answer": "vegetarian", "anno approach": "image, wiki", "verif wiki answer": "vegetarian(0.5002)", "verif concept answer": "vegan(0.5039)", "verif image answer": "vegetarian(0.6202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028263.jpg"}, {"question": "what do people use this for", "gt answer": "play game(0.60)<br/>game(1.00)<br/>video game(0.60)", "pred answer": "game", "question_id": 5610335, "best approach": "wiki, concept, image", "verif answer": "play game", "anno approach": "", "verif wiki answer": "play game(0.6806)", "verif concept answer": "play game(0.6979)", "verif image answer": "play game(0.7145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561033.jpg"}, {"question": "what is the length of that baseball bat", "gt answer": "42 inches(1.00)<br/>4 feet(0.60)", "pred answer": "12 inches", "question_id": 4875895, "best approach": "image", "verif answer": "42 inches", "anno approach": "image", "verif wiki answer": "4 feet(0.6462)", "verif concept answer": "12 inches(0.6279)", "verif image answer": "42 inches(0.6472)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487589.jpg"}, {"question": "what are the things this guy is holding called", "gt answer": "pole(1.00)<br/>stick(1.00)<br/>ski pole(0.60)", "pred answer": "ski pole", "question_id": 4296355, "best approach": "wiki, concept, image", "verif answer": "stick", "anno approach": "concept, wiki", "verif wiki answer": "stick(0.6562)", "verif concept answer": "stick(0.6457)", "verif image answer": "stick(0.5543)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429635.jpg"}, {"question": "what is the maker of this gaming system", "gt answer": "nintendo(1.00)<br/>wii(0.60)", "pred answer": "wii", "question_id": 4015415, "best approach": "wiki, concept, image", "verif answer": "nintendo", "anno approach": "wiki", "verif wiki answer": "nintendo(0.7300)", "verif concept answer": "nintendo(0.7307)", "verif image answer": "nintendo(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401541.jpg"}, {"question": "what materials were used to make the rope", "gt answer": "hemp(1.00)<br/>cotton(0.60)", "pred answer": "fiberglass", "question_id": 3851305, "best approach": "wiki, concept", "verif answer": "polyester", "anno approach": "", "verif wiki answer": "hemp(0.6643)", "verif concept answer": "hemp(0.6470)", "verif image answer": "polyester(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385130.jpg"}, {"question": "are these fruits or veggies", "gt answer": "fruit(1.00)<br/>vegetable(1.00)<br/>veggies(0.60)", "pred answer": "veggies", "question_id": 2887235, "best approach": "wiki, concept, image", "verif answer": "veggies", "anno approach": "image, wiki", "verif wiki answer": "veggies(0.6678)", "verif concept answer": "veggies(0.6477)", "verif image answer": "veggies(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288723.jpg"}, {"question": "which ocean is pictured here", "gt answer": "pacific(1.00)<br/>atlantic(1.00)<br/>pacific ocean(0.60)", "pred answer": "pacific", "question_id": 3448595, "best approach": "wiki, concept, image", "verif answer": "pacific", "anno approach": "wiki", "verif wiki answer": "pacific(0.6876)", "verif concept answer": "pacific(0.6919)", "verif image answer": "pacific(0.6809)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344859.jpg"}, {"question": "the dog is in what part of this motorcycle", "gt answer": "sidecar(1.00)<br/>side car(0.60)<br/>back(0.60)", "pred answer": "sidecar", "question_id": 844795, "best approach": "wiki, concept, image", "verif answer": "sidecar", "anno approach": "wiki", "verif wiki answer": "sidecar(0.7311)", "verif concept answer": "sidecar(0.7310)", "verif image answer": "sidecar(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084479.jpg"}, {"question": "what kind of bread is this", "gt answer": "sourdough(1.00)<br/>bun(0.60)<br/>roll(0.60)<br/>english(0.60)", "pred answer": "pita", "question_id": 297945, "best approach": "wiki, concept, image", "verif answer": "bun", "anno approach": "wiki", "verif wiki answer": "roll(0.6114)", "verif concept answer": "bun(0.6410)", "verif image answer": "bun(0.6407)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029794.jpg"}, {"question": "what is the name of the famous dog competition that takes place after the superbowl every year", "gt answer": "puppy bowl(1.00)<br/>lassie(0.60)", "pred answer": "frisbee", "question_id": 1663285, "best approach": "wiki, concept", "verif answer": "lassie", "anno approach": "", "verif wiki answer": "lassie(0.7311)", "verif concept answer": "lassie(0.7310)", "verif image answer": "frisbee(0.7203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166328.jpg"}, {"question": "what are these types of bears called", "gt answer": "sun bear(1.00)<br/>black(0.60)", "pred answer": "black bear", "question_id": 3829395, "best approach": "wiki, concept, image", "verif answer": "sun bear", "anno approach": "", "verif wiki answer": "sun bear(0.6596)", "verif concept answer": "sun bear(0.6556)", "verif image answer": "sun bear(0.6455)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382939.jpg"}, {"question": "what part of the plane can you see", "gt answer": "engine(1.00)", "pred answer": "propeller", "question_id": 1289575, "best approach": "wiki, concept, image", "verif answer": "engine", "anno approach": "image, wiki", "verif wiki answer": "engine(0.5122)", "verif concept answer": "engine(0.5083)", "verif image answer": "engine(0.5852)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128957.jpg"}, {"question": "what type of milk do babies drink", "gt answer": "breast(1.00)", "pred answer": "milk", "question_id": 2070515, "best approach": "", "verif answer": "0", "anno approach": "", "verif wiki answer": "0(0.6997)", "verif concept answer": "0(0.6404)", "verif image answer": "milk(0.5809)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207051.jpg"}, {"question": "who would sleep here", "gt answer": "student(1.00)", "pred answer": "student", "question_id": 709395, "best approach": "wiki, concept", "verif answer": "student", "anno approach": "wiki", "verif wiki answer": "student(0.5995)", "verif concept answer": "student(0.5465)", "verif image answer": "school kid(0.5038)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070939.jpg"}, {"question": "what is typically stored in the case the man is carrying", "gt answer": "paper(1.00)<br/>cloth(0.60)", "pred answer": "cloth", "question_id": 947665, "best approach": "", "verif answer": "food", "anno approach": "", "verif wiki answer": "food(0.6993)", "verif concept answer": "food(0.7053)", "verif image answer": "food(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094766.jpg"}, {"question": "what could you do in this", "gt answer": "bath(1.00)<br/>relax(0.60)", "pred answer": "pee", "question_id": 4618445, "best approach": "image", "verif answer": "water", "anno approach": "image", "verif wiki answer": "water(0.5077)", "verif concept answer": "water(0.5581)", "verif image answer": "relax(0.5013)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461844.jpg"}, {"question": "where is this taken", "gt answer": "restaurant(1.00)<br/>kitchen(1.00)", "pred answer": "dine room", "question_id": 976605, "best approach": "concept", "verif answer": "dine room", "anno approach": "concept", "verif wiki answer": "dine room(0.7195)", "verif concept answer": "restaurant(0.7019)", "verif image answer": "dine room(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097660.jpg"}, {"question": "", "gt answer": "glaze(0.60)<br/>computer(0.60)<br/>painted(0.60)<br/>paint(0.60)", "pred answer": "stripe", "question_id": 3564025, "best approach": "wiki, concept, image", "verif answer": "glaze", "anno approach": "", "verif wiki answer": "glaze(0.6440)", "verif concept answer": "glaze(0.6541)", "verif image answer": "glaze(0.6356)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356402.jpg"}, {"question": "what species of bird is this", "gt answer": "parrot(1.00)", "pred answer": "parakeet", "question_id": 705585, "best approach": "", "verif answer": "parakeet", "anno approach": "", "verif wiki answer": "parakeet(0.7311)", "verif concept answer": "parakeet(0.7311)", "verif image answer": "parakeet(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070558.jpg"}, {"question": "how does the moon affect these natural phenomenon", "gt answer": "tide(1.00)<br/>wave(0.60)", "pred answer": "wave", "question_id": 1393095, "best approach": "wiki, concept, image", "verif answer": "tide", "anno approach": "concept, wiki", "verif wiki answer": "tide(0.7117)", "verif concept answer": "tide(0.7044)", "verif image answer": "tide(0.6488)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139309.jpg"}, {"question": "what food group is mostly represented", "gt answer": "meat(1.00)<br/>protein(0.60)<br/>carrot(0.60)<br/>chicken(0.60)", "pred answer": "vegetable", "question_id": 1245775, "best approach": "wiki, concept, image", "verif answer": "protein", "anno approach": "", "verif wiki answer": "protein(0.5003)", "verif concept answer": "protein(0.5007)", "verif image answer": "chicken(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000124577.jpg"}, {"question": "what is this room commonly used for", "gt answer": "live(1.00)<br/>eat(0.60)", "pred answer": "sleep", "question_id": 4783065, "best approach": "", "verif answer": "relax", "anno approach": "", "verif wiki answer": "live room(0.6529)", "verif concept answer": "relax(0.6677)", "verif image answer": "relax(0.6331)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478306.jpg"}, {"question": "what season is this", "gt answer": "winter(1.00)", "pred answer": "winter", "question_id": 2216655, "best approach": "wiki, concept, image", "verif answer": "winter", "anno approach": "wiki", "verif wiki answer": "winter(0.7310)", "verif concept answer": "winter(0.7305)", "verif image answer": "winter(0.7041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221665.jpg"}, {"question": "what icing is used to make the cake artsy", "gt answer": "fondant(1.00)", "pred answer": "green", "question_id": 4298585, "best approach": "concept", "verif answer": "vanilla", "anno approach": "concept", "verif wiki answer": "frost(0.5947)", "verif concept answer": "fondant(0.6163)", "verif image answer": "vanilla(0.6526)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429858.jpg"}, {"question": "what 's passing each other in the background", "gt answer": "plane(1.00)<br/>airplane(0.60)", "pred answer": "airplane", "question_id": 2052805, "best approach": "concept, image", "verif answer": "plane", "anno approach": "image", "verif wiki answer": "luggage(0.6205)", "verif concept answer": "plane(0.6418)", "verif image answer": "plane(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205280.jpg"}, {"question": "what are the decorations hanging on the walls", "gt answer": "paint(1.00)<br/>picture(0.60)", "pred answer": "picture", "question_id": 1466205, "best approach": "", "verif answer": "abstract", "anno approach": "", "verif wiki answer": "abstract(0.7297)", "verif concept answer": "abstract(0.7292)", "verif image answer": "abstract(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146620.jpg"}, {"question": "what that a mountain or a volcano in the horizon", "gt answer": "mountain(1.00)", "pred answer": "mountain", "question_id": 3094375, "best approach": "wiki, concept", "verif answer": "hill", "anno approach": "wiki", "verif wiki answer": "mountain(0.6704)", "verif concept answer": "mountain(0.6495)", "verif image answer": "hill(0.6801)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000309437.jpg"}, {"question": "what is the weather like", "gt answer": "rainy(1.00)<br/>rain(0.60)<br/>cold(0.60)", "pred answer": "rain", "question_id": 2770695, "best approach": "wiki, concept, image", "verif answer": "cold", "anno approach": "wiki", "verif wiki answer": "cold(0.6569)", "verif concept answer": "cold(0.6638)", "verif image answer": "cold(0.6519)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277069.jpg"}, {"question": "how would you groom these animals", "gt answer": "brush(1.00)", "pred answer": "fur", "question_id": 4760865, "best approach": "wiki", "verif answer": "brush", "anno approach": "wiki", "verif wiki answer": "brush(0.7280)", "verif concept answer": "brush teeth(0.7260)", "verif image answer": "brush teeth(0.6878)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476086.jpg"}, {"question": "what is the purpose of the vessel that is floating in the ocean", "gt answer": "drill for oil(1.00)<br/>oil(0.60)", "pred answer": "shark", "question_id": 4712105, "best approach": "wiki, concept, image", "verif answer": "drill for oil", "anno approach": "image, wiki", "verif wiki answer": "drill for oil(0.7310)", "verif concept answer": "drill for oil(0.6718)", "verif image answer": "drill for oil(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471210.jpg"}, {"question": "what are the animals doing", "gt answer": "graze(1.00)<br/>compete(0.60)<br/>eat(0.60)", "pred answer": "eat", "question_id": 2965735, "best approach": "wiki, concept, image", "verif answer": "graze", "anno approach": "wiki", "verif wiki answer": "graze(0.7307)", "verif concept answer": "graze(0.7308)", "verif image answer": "graze(0.7172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296573.jpg"}, {"question": "what form of energy makes the train move", "gt answer": "electric(1.00)<br/>electricity(1.00)", "pred answer": "diesel", "question_id": 2736415, "best approach": "wiki, concept, image", "verif answer": "electricity", "anno approach": "wiki", "verif wiki answer": "electricity(0.6411)", "verif concept answer": "electricity(0.5840)", "verif image answer": "electricity(0.5986)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273641.jpg"}, {"question": "what breed of dog is that", "gt answer": "bulldog(1.00)<br/>boxer(0.60)", "pred answer": "collie", "question_id": 3535045, "best approach": "wiki, concept", "verif answer": "pug", "anno approach": "wiki", "verif wiki answer": "boxer(0.6454)", "verif concept answer": "boxer(0.6614)", "verif image answer": "pug(0.6903)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353504.jpg"}, {"question": "how many floors are on the cruise ship", "gt answer": "6(1.00)<br/>9(0.60)<br/>12(0.60)<br/>5(0.60)", "pred answer": "18", "question_id": 2449945, "best approach": "wiki, concept, image", "verif answer": "12", "anno approach": "wiki", "verif wiki answer": "9(0.6449)", "verif concept answer": "9(0.6515)", "verif image answer": "12(0.6665)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244994.jpg"}, {"question": "how could a prism be used to create the image in the window", "gt answer": "rainbow(1.00)<br/>light(0.60)", "pred answer": "light", "question_id": 4465365, "best approach": "", "verif answer": "remote", "anno approach": "", "verif wiki answer": "remote(0.6475)", "verif concept answer": "remote(0.6583)", "verif image answer": "remote(0.5937)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000446536.jpg"}, {"question": "what country is the building in which this woman is standing located", "gt answer": "america(1.00)<br/>london(0.60)<br/>usa(0.60)", "pred answer": "england", "question_id": 2067545, "best approach": "wiki", "verif answer": "china", "anno approach": "wiki", "verif wiki answer": "usa(0.6648)", "verif concept answer": "china(0.6967)", "verif image answer": "china(0.5625)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206754.jpg"}, {"question": "what is grazing", "gt answer": "cow(1.00)<br/>horse(1.00)", "pred answer": "cow", "question_id": 5784395, "best approach": "wiki, concept, image", "verif answer": "cow", "anno approach": "wiki", "verif wiki answer": "cow(0.6704)", "verif concept answer": "cow(0.6207)", "verif image answer": "cow(0.6362)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578439.jpg"}, {"question": "who is this toy named after", "gt answer": "theodore roosevelt(1.00)<br/>ted(0.60)", "pred answer": "bear", "question_id": 5235435, "best approach": "wiki, concept, image", "verif answer": "theodore roosevelt", "anno approach": "wiki", "verif wiki answer": "theodore roosevelt(0.5373)", "verif concept answer": "theodore roosevelt(0.5118)", "verif image answer": "theodore roosevelt(0.5319)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523543.jpg"}, {"question": "what does one suppose is in that can she is holding", "gt answer": "coke(1.00)<br/>soda(1.00)<br/>coca cola(0.60)", "pred answer": "pizza", "question_id": 293285, "best approach": "wiki, concept", "verif answer": "soda", "anno approach": "wiki", "verif wiki answer": "soda(0.6933)", "verif concept answer": "soda(0.6353)", "verif image answer": "beer(0.6054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029328.jpg"}, {"question": "what famous tv series had credits where the main cast members ran down a setting like the one in the photo", "gt answer": "baywatch(1.00)<br/>friend(0.60)", "pred answer": "blue crush", "question_id": 4285035, "best approach": "", "verif answer": "lost", "anno approach": "", "verif wiki answer": "lost(0.5424)", "verif concept answer": "lost(0.5417)", "verif image answer": "lost(0.5858)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428503.jpg"}, {"question": "what type of tennis swing is this", "gt answer": "overhand(1.00)<br/>backhand(0.60)", "pred answer": "backhand", "question_id": 1237315, "best approach": "image", "verif answer": "overhand", "anno approach": "image", "verif wiki answer": "backhand(0.7308)", "verif concept answer": "backhand(0.7303)", "verif image answer": "overhand(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123731.jpg"}, {"question": "which famous breakfast item is also the first part of the name of the asian rolled edible seen here", "gt answer": "egg(1.00)", "pred answer": "bread", "question_id": 5784975, "best approach": "", "verif answer": "salmon", "anno approach": "", "verif wiki answer": "salmon(0.6523)", "verif concept answer": "salmon(0.6803)", "verif image answer": "rice(0.5502)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578497.jpg"}, {"question": "where can this setting usually be seen", "gt answer": "california(0.60)<br/>beach(1.00)", "pred answer": "beach", "question_id": 1464545, "best approach": "wiki, concept", "verif answer": "beach", "anno approach": "wiki", "verif wiki answer": "beach(0.7084)", "verif concept answer": "beach(0.7310)", "verif image answer": "ocean(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146454.jpg"}, {"question": "what type of plant is this", "gt answer": "bush(1.00)<br/>shrub(0.60)<br/>lime(0.60)", "pred answer": "fern", "question_id": 947535, "best approach": "wiki, image", "verif answer": "bush", "anno approach": "wiki", "verif wiki answer": "bush(0.6274)", "verif concept answer": "shrub(0.6163)", "verif image answer": "bush(0.6448)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094753.jpg"}, {"question": "how many calories are in an average one of these", "gt answer": "200(1.00)<br/>300(0.60)<br/>400(0.60)", "pred answer": "500", "question_id": 1178845, "best approach": "wiki, image", "verif answer": "300", "anno approach": "wiki", "verif wiki answer": "300(0.7036)", "verif concept answer": "500(0.6639)", "verif image answer": "400(0.6201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117884.jpg"}, {"question": "what type of surface are they playing on", "gt answer": "clay(1.00)<br/>dirt(0.60)", "pred answer": "concrete", "question_id": 918685, "best approach": "", "verif answer": "tennis court", "anno approach": "", "verif wiki answer": "tennis court(0.6708)", "verif concept answer": "tennis court(0.7017)", "verif image answer": "concrete(0.6773)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000091868.jpg"}, {"question": "how do we know this is not a real bird", "gt answer": "string(1.00)", "pred answer": "wind", "question_id": 4237775, "best approach": "", "verif answer": "kite", "anno approach": "", "verif wiki answer": "kite(0.5717)", "verif concept answer": "kite(0.5668)", "verif image answer": "kite(0.6716)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000423777.jpg"}, {"question": "what kind of venue is this", "gt answer": "skate park(1.00)<br/>skatepark(0.60)<br/>skateboard(0.60)", "pred answer": "skate park", "question_id": 2569685, "best approach": "wiki, concept, image", "verif answer": "skate park", "anno approach": "image, wiki", "verif wiki answer": "skate park(0.6463)", "verif concept answer": "skate park(0.6625)", "verif image answer": "skate park(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256968.jpg"}, {"question": "which famous nursery pair went rolling down an incline like this one", "gt answer": "jack and jill(1.00)", "pred answer": "disney", "question_id": 1814635, "best approach": "wiki, concept, image", "verif answer": "jack and jill", "anno approach": "wiki", "verif wiki answer": "jack and jill(0.7310)", "verif concept answer": "jack and jill(0.7289)", "verif image answer": "jack and jill(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181463.jpg"}, {"question": "what brand of candy is shown here", "gt answer": "mike and ike(1.00)", "pred answer": "dunkin donuts", "question_id": 2402855, "best approach": "", "verif answer": "coca cola", "anno approach": "", "verif wiki answer": "coca cola(0.6409)", "verif concept answer": "walmart(0.5363)", "verif image answer": "walmart(0.5073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240285.jpg"}, {"question": "what corporation uses these as a mascot", "gt answer": "budweiser(1.00)<br/>sport(0.60)", "pred answer": "disney", "question_id": 956115, "best approach": "", "verif answer": "clydesdale", "anno approach": "", "verif wiki answer": "clydesdale(0.6520)", "verif concept answer": "clydesdale(0.7088)", "verif image answer": "football(0.5450)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000095611.jpg"}, {"question": "what does this man have in his mouth", "gt answer": "toothbrush(1.00)", "pred answer": "toothpaste", "question_id": 5634555, "best approach": "", "verif answer": "scissor", "anno approach": "", "verif wiki answer": "scissor(0.6720)", "verif concept answer": "scissor(0.6697)", "verif image answer": "scissor(0.7074)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000563455.jpg"}, {"question": "why are the vehicles stopped", "gt answer": "red light(1.00)<br/>traffic light(0.60)", "pred answer": "broken", "question_id": 3306965, "best approach": "", "verif answer": "no u turn", "anno approach": "", "verif wiki answer": "no u turn(0.7310)", "verif concept answer": "no u turn(0.7309)", "verif image answer": "parked(0.6499)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000330696.jpg"}, {"question": "what animal is the animal in this photo related to", "gt answer": "cow(1.00)", "pred answer": "cow", "question_id": 695105, "best approach": "wiki, image", "verif answer": "bull", "anno approach": "wiki", "verif wiki answer": "cow(0.6547)", "verif concept answer": "bull(0.6899)", "verif image answer": "cow(0.5500)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069510.jpg"}, {"question": "how often will those shears need to be sharpened", "gt answer": "daily(1.00)<br/>monthly(0.60)", "pred answer": "1 hour", "question_id": 464925, "best approach": "", "verif answer": "not often", "anno approach": "", "verif wiki answer": "twice day(0.6497)", "verif concept answer": "twice day(0.6528)", "verif image answer": "not often(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046492.jpg"}, {"question": "what kind of bird is this", "gt answer": "sandpiper(1.00)<br/>seagull(0.60)<br/>gull(0.60)", "pred answer": "seagull", "question_id": 1872685, "best approach": "concept, image", "verif answer": "sandpiper", "anno approach": "image", "verif wiki answer": "seagull(0.6628)", "verif concept answer": "sandpiper(0.6518)", "verif image answer": "sandpiper(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187268.jpg"}, {"question": "what is the hairstyle of the woman with black hair standing next to the mirrored sign called", "gt answer": "bob(1.00)<br/>bun(0.60)", "pred answer": "ponytail", "question_id": 2651585, "best approach": "wiki, concept, image", "verif answer": "bun", "anno approach": "concept, wiki", "verif wiki answer": "bun(0.6508)", "verif concept answer": "bun(0.7153)", "verif image answer": "bun(0.5401)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265158.jpg"}, {"question": "what kind of pizza is this", "gt answer": "pepperoni(1.00)", "pred answer": "supreme", "question_id": 4552225, "best approach": "image", "verif answer": "deep dish", "anno approach": "image", "verif wiki answer": "deep dish(0.6695)", "verif concept answer": "deep dish(0.7225)", "verif image answer": "pepperoni(0.7045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455222.jpg"}, {"question": "what food served on a bun is associated with watching this game", "gt answer": "hot dog(1.00)", "pred answer": "hotdog", "question_id": 2601165, "best approach": "", "verif answer": "hotdog", "anno approach": "", "verif wiki answer": "hotdog(0.6617)", "verif concept answer": "hotdog(0.6664)", "verif image answer": "hotdogs(0.6612)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260116.jpg"}, {"question": "are these people going somewhere or just fishing", "gt answer": "go somewhere(1.00)<br/>fish(0.60)", "pred answer": "fish", "question_id": 3619395, "best approach": "", "verif answer": "sail", "anno approach": "", "verif wiki answer": "sail(0.5611)", "verif concept answer": "sail(0.6161)", "verif image answer": "sail(0.5258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361939.jpg"}, {"question": "what input devices are shown here", "gt answer": "mouse and keyboard(1.00)<br/>mouse(0.60)<br/>keyboard(0.60)", "pred answer": "keyboard", "question_id": 4217945, "best approach": "wiki, image", "verif answer": "keyboard", "anno approach": "", "verif wiki answer": "mouse and keyboard(0.5063)", "verif concept answer": "keyboard(0.5869)", "verif image answer": "mouse and keyboard(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421794.jpg"}, {"question": "in what type of environment would you find this vehicle", "gt answer": "urban(1.00)<br/>city(1.00)", "pred answer": "city", "question_id": 3546265, "best approach": "concept, image", "verif answer": "city", "anno approach": "concept", "verif wiki answer": "tourist(0.6458)", "verif concept answer": "city(0.6868)", "verif image answer": "city(0.6496)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354626.jpg"}, {"question": "what type of street sign is shown in this image", "gt answer": "no turn(1.00)<br/>no left turn(0.60)", "pred answer": "no left turn", "question_id": 3949645, "best approach": "", "verif answer": "no right turn", "anno approach": "", "verif wiki answer": "no park(0.6650)", "verif concept answer": "no park(0.6718)", "verif image answer": "no right turn(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000394964.jpg"}, {"question": "what reading based crime involving the technology featured above occurs in a vehicle", "gt answer": "text(1.00)", "pred answer": "selfie", "question_id": 632095, "best approach": "", "verif answer": "play game", "anno approach": "", "verif wiki answer": "play game(0.7309)", "verif concept answer": "play game(0.7301)", "verif image answer": "play game(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063209.jpg"}, {"question": "what language is on these signs", "gt answer": "spanish(1.00)<br/>italian(0.60)", "pred answer": "french", "question_id": 4140895, "best approach": "", "verif answer": "black and white", "anno approach": "", "verif wiki answer": "black and white(0.7311)", "verif concept answer": "black and white(0.7309)", "verif image answer": "french(0.7037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000414089.jpg"}, {"question": "what is being used to not get wet by rain", "gt answer": "umbrella(1.00)", "pred answer": "umbrella", "question_id": 3890315, "best approach": "wiki", "verif answer": "umbrella", "anno approach": "wiki", "verif wiki answer": "umbrella(0.7193)", "verif concept answer": "string(0.6478)", "verif image answer": "string(0.7068)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389031.jpg"}, {"question": "is the bird near fresh water or salt water", "gt answer": "fresh(1.00)<br/>salt(0.60)", "pred answer": "salty", "question_id": 5592255, "best approach": "concept, image", "verif answer": "salt", "anno approach": "", "verif wiki answer": "salt and pepper(0.7219)", "verif concept answer": "salt(0.7011)", "verif image answer": "salt(0.7245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559225.jpg"}, {"question": "what picture is on the cup", "gt answer": "pear(1.00)", "pred answer": "flower", "question_id": 1301845, "best approach": "", "verif answer": "flower", "anno approach": "", "verif wiki answer": "flower(0.6162)", "verif concept answer": "flower(0.6257)", "verif image answer": "flower(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130184.jpg"}, {"question": "what city in the us gets the most rain fall a year", "gt answer": "seattle(1.00)", "pred answer": "washington", "question_id": 4349915, "best approach": "", "verif answer": "boston", "anno approach": "", "verif wiki answer": "boston(0.5028)", "verif concept answer": "boston(0.5251)", "verif image answer": "boston(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434991.jpg"}, {"question": "who is the manufacturer of this television", "gt answer": "sony(1.00)<br/>lg(0.60)", "pred answer": "toshiba", "question_id": 4102455, "best approach": "concept", "verif answer": "lg", "anno approach": "concept", "verif wiki answer": "lg(0.7165)", "verif concept answer": "sony(0.6680)", "verif image answer": "lg(0.7077)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000410245.jpg"}, {"question": "what is following the elephant", "gt answer": "baby elephant(1.00)<br/>calf(0.60)", "pred answer": "elephant", "question_id": 1989975, "best approach": "wiki, concept, image", "verif answer": "baby elephant", "anno approach": "", "verif wiki answer": "baby elephant(0.7199)", "verif concept answer": "baby elephant(0.7111)", "verif image answer": "baby elephant(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198997.jpg"}, {"question": "what type of writing is this called on the wall", "gt answer": "graffiti(1.00)<br/>grafitti(0.60)", "pred answer": "graffiti", "question_id": 1835885, "best approach": "", "verif answer": "indian", "anno approach": "", "verif wiki answer": "indian(0.7224)", "verif concept answer": "indian(0.7283)", "verif image answer": "indian(0.6683)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183588.jpg"}, {"question": "which of these items depicted grows underground", "gt answer": "potato(1.00)", "pred answer": "meat", "question_id": 2249295, "best approach": "", "verif answer": "french fry", "anno approach": "", "verif wiki answer": "french fry(0.6197)", "verif concept answer": "french fry(0.5754)", "verif image answer": "french fry(0.5446)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224929.jpg"}, {"question": "what brand is this", "gt answer": "audi(1.00)<br/>chrysler(0.60)<br/>fiat(0.60)", "pred answer": "ford", "question_id": 77405, "best approach": "wiki, concept, image", "verif answer": "chrysler", "anno approach": "wiki", "verif wiki answer": "chrysler(0.6200)", "verif concept answer": "chrysler(0.6273)", "verif image answer": "chrysler(0.6341)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007740.jpg"}, {"question": "what parade is being celebrated in the picture", "gt answer": "christmas(1.00)<br/>mardi gras(0.60)", "pred answer": "rally", "question_id": 2698715, "best approach": "wiki, concept, image", "verif answer": "mardi gras", "anno approach": "image", "verif wiki answer": "mardi gras(0.6500)", "verif concept answer": "mardi gras(0.6346)", "verif image answer": "mardi gras(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269871.jpg"}, {"question": "what is the purpose of the green color of these guy 's jackets", "gt answer": "safety(1.00)<br/>art(0.60)", "pred answer": "visibility", "question_id": 1446465, "best approach": "wiki, image", "verif answer": "art", "anno approach": "wiki", "verif wiki answer": "art(0.6413)", "verif concept answer": "artwork(0.5615)", "verif image answer": "art(0.5565)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144646.jpg"}, {"question": "in soccer what is the term to stop the ball", "gt answer": "block(1.00)<br/>dead(0.60)", "pred answer": "goal", "question_id": 4222835, "best approach": "wiki, concept, image", "verif answer": "block", "anno approach": "image, wiki", "verif wiki answer": "block(0.6180)", "verif concept answer": "block(0.5663)", "verif image answer": "block(0.6484)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422283.jpg"}, {"question": "what do these items pull behind them", "gt answer": "car(1.00)<br/>cargo(0.60)", "pred answer": "people", "question_id": 1410085, "best approach": "image", "verif answer": "cargo", "anno approach": "image", "verif wiki answer": "freight(0.6095)", "verif concept answer": "freight(0.6274)", "verif image answer": "cargo(0.7036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000141008.jpg"}, {"question": "what mlb team uses the same colors as the team shown", "gt answer": "cardinal(1.00)<br/>yankees(0.60)", "pred answer": "yankees", "question_id": 3424015, "best approach": "wiki", "verif answer": "red sox", "anno approach": "wiki", "verif wiki answer": "yankees(0.6683)", "verif concept answer": "red sox(0.6755)", "verif image answer": "red sox(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342401.jpg"}, {"question": "homemade or store bought playdough", "gt answer": "store bought(1.00)", "pred answer": "store", "question_id": 4826655, "best approach": "", "verif answer": "pitch", "anno approach": "", "verif wiki answer": "pitch(0.7248)", "verif concept answer": "pitch(0.6142)", "verif image answer": "pitch(0.5175)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482665.jpg"}, {"question": "what 's the best maneuver for this situation", "gt answer": "kick(1.00)<br/>steal(0.60)", "pred answer": "kick", "question_id": 5806955, "best approach": "", "verif answer": "block", "anno approach": "", "verif wiki answer": "block(0.7224)", "verif concept answer": "block(0.7301)", "verif image answer": "block(0.6694)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580695.jpg"}, {"question": "what size is the green hat this man is wearing", "gt answer": "medium(1.00)<br/>adult(0.60)<br/>large(0.60)", "pred answer": "large", "question_id": 5273535, "best approach": "concept", "verif answer": "large", "anno approach": "concept", "verif wiki answer": "large(0.5093)", "verif concept answer": "medium(0.5049)", "verif image answer": "50(0.5004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527353.jpg"}, {"question": "what kind of bread is this", "gt answer": "bagel(1.00)<br/>doughnut(1.00)<br/>sourdough(0.60)", "pred answer": "white", "question_id": 4443375, "best approach": "wiki, concept, image", "verif answer": "bagel", "anno approach": "wiki", "verif wiki answer": "bagel(0.6678)", "verif concept answer": "bagel(0.6624)", "verif image answer": "bagel(0.6631)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000444337.jpg"}, {"question": "is this giraffe lost or with his family", "gt answer": "lost(1.00)<br/>family(0.60)", "pred answer": "safe", "question_id": 5341075, "best approach": "", "verif answer": "lose", "anno approach": "", "verif wiki answer": "lose(0.5704)", "verif concept answer": "lose(0.6106)", "verif image answer": "lose(0.5859)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534107.jpg"}, {"question": "which vehicle could transport more people the one pictured or a car", "gt answer": "car(1.00)", "pred answer": "motorcycle", "question_id": 775695, "best approach": "", "verif answer": "motorcycle", "anno approach": "", "verif wiki answer": "motorcycle(0.7077)", "verif concept answer": "motorcycle(0.6763)", "verif image answer": "motorcycle(0.5664)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077569.jpg"}, {"question": "is this a table or step", "gt answer": "table(1.00)", "pred answer": "dirt", "question_id": 633455, "best approach": "", "verif answer": "live room", "anno approach": "", "verif wiki answer": "live room(0.5882)", "verif concept answer": "live room(0.6196)", "verif image answer": "live room(0.6174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063345.jpg"}, {"question": "what type of bed is in the photo", "gt answer": "canopy(1.00)<br/>king(0.60)", "pred answer": "4 poster", "question_id": 5063275, "best approach": "", "verif answer": "sheet", "anno approach": "", "verif wiki answer": "sheet(0.7236)", "verif concept answer": "sheet(0.7254)", "verif image answer": "sheet(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506327.jpg"}, {"question": "what model of tv is this", "gt answer": "flatscreen(1.00)<br/>flat screen(0.60)<br/>samsung(0.60)", "pred answer": "flat screen", "question_id": 5529905, "best approach": "wiki, concept, image", "verif answer": "flat screen", "anno approach": "wiki", "verif wiki answer": "flat screen(0.7013)", "verif concept answer": "flat screen(0.6983)", "verif image answer": "flat screen(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552990.jpg"}, {"question": "name the type of ceramic used to make this toilet shown in this picture", "gt answer": "porcelain(1.00)<br/>white(0.60)", "pred answer": "porcelain", "question_id": 4374355, "best approach": "wiki, concept, image", "verif answer": "porcelain", "anno approach": "concept, wiki", "verif wiki answer": "porcelain(0.7209)", "verif concept answer": "porcelain(0.7117)", "verif image answer": "porcelain(0.6506)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437435.jpg"}, {"question": "what type of plant is being grown in the vase", "gt answer": "succulent(1.00)<br/>pine(0.60)<br/>aloe(0.60)", "pred answer": "hydrangea", "question_id": 5237425, "best approach": "wiki, concept, image", "verif answer": "succulent", "anno approach": "wiki", "verif wiki answer": "succulent(0.6998)", "verif concept answer": "succulent(0.7149)", "verif image answer": "succulent(0.6974)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523742.jpg"}, {"question": "how healthy is this meal", "gt answer": "very(1.00)<br/>very healthy(0.60)<br/>extremely(0.60)", "pred answer": "very healthy", "question_id": 1191875, "best approach": "", "verif answer": "healthy", "anno approach": "", "verif wiki answer": "healthy(0.7310)", "verif concept answer": "very windy(0.6937)", "verif image answer": "healthy(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119187.jpg"}, {"question": "what is the brand of the drink", "gt answer": "fresca(1.00)<br/>sprite(0.60)", "pred answer": "coca cola", "question_id": 460245, "best approach": "wiki, concept", "verif answer": "sprite", "anno approach": "wiki", "verif wiki answer": "sprite(0.7268)", "verif concept answer": "sprite(0.6586)", "verif image answer": "coca cola(0.6303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046024.jpg"}, {"question": "what kind of pizza is in the photo", "gt answer": "sausage(1.00)", "pred answer": "pizza", "question_id": 3130155, "best approach": "", "verif answer": "beef", "anno approach": "", "verif wiki answer": "beef(0.5575)", "verif concept answer": "meat(0.5397)", "verif image answer": "hotdog(0.5351)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313015.jpg"}, {"question": "from what vegetable does the food come from in the top left of the picture", "gt answer": "potato(1.00)<br/>banana(0.60)", "pred answer": "potato", "question_id": 800525, "best approach": "wiki, concept, image", "verif answer": "potato", "anno approach": "wiki", "verif wiki answer": "potato(0.7244)", "verif concept answer": "potato(0.7096)", "verif image answer": "potato(0.6929)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080052.jpg"}, {"question": "what time does the clock say", "gt answer": "3:52(1.00)", "pred answer": "9:25", "question_id": 5161245, "best approach": "wiki, concept, image", "verif answer": "3:52", "anno approach": "", "verif wiki answer": "3:52(0.6692)", "verif concept answer": "3:52(0.6582)", "verif image answer": "3:52(0.6486)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516124.jpg"}, {"question": "is that a bird if so what kind", "gt answer": "sparrow(1.00)<br/>owl(0.60)", "pred answer": "hawk", "question_id": 5311795, "best approach": "wiki, concept, image", "verif answer": "sparrow", "anno approach": "concept, wiki", "verif wiki answer": "sparrow(0.5606)", "verif concept answer": "sparrow(0.6253)", "verif image answer": "sparrow(0.5054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531179.jpg"}, {"question": "what are these utilized for", "gt answer": "firefight(1.00)<br/>put out fire(1.00)", "pred answer": "fight fire", "question_id": 1154225, "best approach": "", "verif answer": "fire", "anno approach": "", "verif wiki answer": "fire(0.6734)", "verif concept answer": "fight fire(0.6246)", "verif image answer": "fight fire(0.5016)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115422.jpg"}, {"question": "what are they celebrating", "gt answer": "veteran day(1.00)<br/>motorcycle(0.60)", "pred answer": "rally", "question_id": 418905, "best approach": "wiki, concept, image", "verif answer": "veteran day", "anno approach": "concept, wiki", "verif wiki answer": "veteran day(0.7262)", "verif concept answer": "veteran day(0.7245)", "verif image answer": "veteran day(0.6672)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041890.jpg"}, {"question": "why are the men bending down", "gt answer": "to catch ball(1.00)<br/>catch(0.60)", "pred answer": "play", "question_id": 4536825, "best approach": "wiki, concept", "verif answer": "to catch ball", "anno approach": "", "verif wiki answer": "to catch ball(0.7211)", "verif concept answer": "to catch ball(0.7260)", "verif image answer": "catch frisbee(0.6969)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453682.jpg"}, {"question": "what do these guys like to eat", "gt answer": "leaf(1.00)<br/>grass(0.60)<br/>plant(0.60)", "pred answer": "peanut", "question_id": 2715775, "best approach": "wiki, concept, image", "verif answer": "leaf", "anno approach": "image, wiki", "verif wiki answer": "leaf(0.6506)", "verif concept answer": "leaf(0.6597)", "verif image answer": "leaf(0.7193)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000271577.jpg"}, {"question": "what places are famous for this water sport", "gt answer": "beach(1.00)<br/>california hawaii(0.60)", "pred answer": "hawaii", "question_id": 4848325, "best approach": "", "verif answer": "ocean", "anno approach": "", "verif wiki answer": "ocean(0.6790)", "verif concept answer": "surf(0.6444)", "verif image answer": "surf(0.6418)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484832.jpg"}, {"question": "what is the name of this game", "gt answer": "frisbee(1.00)<br/>disc golf(0.60)", "pred answer": "frisbee", "question_id": 1051845, "best approach": "image", "verif answer": "disc golf", "anno approach": "image", "verif wiki answer": "catch(0.6377)", "verif concept answer": "catch(0.6457)", "verif image answer": "disc golf(0.7203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105184.jpg"}, {"question": "what type of dog is this", "gt answer": "border collie(1.00)", "pred answer": "corgi", "question_id": 1331515, "best approach": "wiki, concept, image", "verif answer": "border collie", "anno approach": "wiki", "verif wiki answer": "border collie(0.6387)", "verif concept answer": "border collie(0.6353)", "verif image answer": "border collie(0.6094)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000133151.jpg"}, {"question": "what is this animal 's favorite game", "gt answer": "fetch(1.00)", "pred answer": "fetch", "question_id": 5221955, "best approach": "concept", "verif answer": "fight", "anno approach": "concept", "verif wiki answer": "fight(0.6970)", "verif concept answer": "fetch(0.5785)", "verif image answer": "collar(0.6378)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522195.jpg"}, {"question": "what technique was used to create the artwork on the wall", "gt answer": "shade(0.60)<br/>paint(1.00)", "pred answer": "paint", "question_id": 2381545, "best approach": "concept", "verif answer": "sunset", "anno approach": "concept", "verif wiki answer": "sunset(0.7178)", "verif concept answer": "paint(0.6482)", "verif image answer": "abstract(0.6426)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238154.jpg"}, {"question": "what breed of dog is in the picture", "gt answer": "collie(1.00)<br/>mutt(0.60)<br/>border collie(0.60)", "pred answer": "collie", "question_id": 423555, "best approach": "concept, image", "verif answer": "mutt", "anno approach": "", "verif wiki answer": "mixed(0.6478)", "verif concept answer": "mutt(0.6472)", "verif image answer": "mutt(0.6714)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042355.jpg"}, {"question": "which side of the stop sign is visible", "gt answer": "back(1.00)", "pred answer": "north", "question_id": 5791765, "best approach": "", "verif answer": "behind", "anno approach": "", "verif wiki answer": "behind(0.7305)", "verif concept answer": "behind(0.7310)", "verif image answer": "behind(0.7150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000579176.jpg"}, {"question": "the deck is made from what material", "gt answer": "wood(1.00)<br/>cedar(0.60)", "pred answer": "wood", "question_id": 1062965, "best approach": "wiki, concept", "verif answer": "concrete", "anno approach": "wiki", "verif wiki answer": "wood(0.6511)", "verif concept answer": "wood(0.6649)", "verif image answer": "concrete(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106296.jpg"}, {"question": "when was this object first invented", "gt answer": "1950s(1.00)<br/>1940s(0.60)", "pred answer": "1946", "question_id": 3337105, "best approach": "", "verif answer": "1955", "anno approach": "", "verif wiki answer": "1955(0.6730)", "verif concept answer": "1955(0.6919)", "verif image answer": "1955(0.6690)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333710.jpg"}, {"question": "what activity is this", "gt answer": "motorcycle(1.00)<br/>bike(0.60)<br/>ride(0.60)", "pred answer": "cycling", "question_id": 884015, "best approach": "concept, image", "verif answer": "ride", "anno approach": "concept", "verif wiki answer": "scooter(0.5105)", "verif concept answer": "ride(0.5986)", "verif image answer": "bike(0.5316)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088401.jpg"}, {"question": "what type of meeting is this", "gt answer": "business(1.00)", "pred answer": "business", "question_id": 4164505, "best approach": "", "verif answer": "casual", "anno approach": "", "verif wiki answer": "casual(0.7259)", "verif concept answer": "casual(0.7298)", "verif image answer": "casual(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416450.jpg"}, {"question": "what type of places can these animals live in", "gt answer": "zoo(1.00)<br/>plain(0.60)", "pred answer": "farm", "question_id": 133565, "best approach": "wiki, concept, image", "verif answer": "zoo", "anno approach": "wiki", "verif wiki answer": "zoo(0.7308)", "verif concept answer": "zoo(0.7310)", "verif image answer": "zoo(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013356.jpg"}, {"question": "what technique was used to cut these carrots", "gt answer": "julienne(1.00)", "pred answer": "slice", "question_id": 791465, "best approach": "", "verif answer": "carrot", "anno approach": "", "verif wiki answer": "carrot(0.5136)", "verif concept answer": "sew(0.5003)", "verif image answer": "slice(0.5056)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079146.jpg"}, {"question": "what can this object be used for", "gt answer": "shop(1.00)", "pred answer": "travel", "question_id": 3359865, "best approach": "", "verif answer": "relax", "anno approach": "", "verif wiki answer": "relax(0.6083)", "verif concept answer": "relax(0.5934)", "verif image answer": "relax(0.5131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335986.jpg"}, {"question": "what object would you use to wash your hands", "gt answer": "sink(1.00)", "pred answer": "bleach", "question_id": 2179585, "best approach": "", "verif answer": "towel", "anno approach": "", "verif wiki answer": "towel(0.6988)", "verif concept answer": "towel(0.7109)", "verif image answer": "towel(0.5866)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217958.jpg"}, {"question": "how many stories is the building straight ahead", "gt answer": "3(1.00)<br/>4(0.60)<br/>5(0.60)<br/>2(0.60)", "pred answer": "20", "question_id": 689585, "best approach": "wiki, concept, image", "verif answer": "3", "anno approach": "wiki", "verif wiki answer": "3(0.6465)", "verif concept answer": "3(0.6420)", "verif image answer": "3(0.6216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068958.jpg"}, {"question": "what time of year is it", "gt answer": "fall(1.00)<br/>winter(0.60)", "pred answer": "fall", "question_id": 3812165, "best approach": "wiki, concept, image", "verif answer": "fall", "anno approach": "image, wiki", "verif wiki answer": "fall(0.6691)", "verif concept answer": "fall(0.6044)", "verif image answer": "fall(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381216.jpg"}, {"question": "what material are these toys produced out of", "gt answer": "paper(1.00)<br/>nylon(1.00)<br/>tissue(0.60)", "pred answer": "plastic", "question_id": 2161195, "best approach": "", "verif answer": "cloth", "anno approach": "", "verif wiki answer": "cloth(0.7270)", "verif concept answer": "cloth(0.7160)", "verif image answer": "cloth(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216119.jpg"}, {"question": "why are the bikers stopped", "gt answer": "parade(1.00)<br/>direct traffic(0.60)<br/>light(0.60)", "pred answer": "danger", "question_id": 2492886, "best approach": "wiki, concept, image", "verif answer": "parade", "anno approach": "wiki", "verif wiki answer": "parade(0.6492)", "verif concept answer": "parade(0.6453)", "verif image answer": "parade(0.6352)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249288.jpg"}, {"question": "what toy store used a mascot similar to these animals for many years", "gt answer": "toy r us(1.00)", "pred answer": "toy r us", "question_id": 400855, "best approach": "wiki, concept, image", "verif answer": "toy r us", "anno approach": "", "verif wiki answer": "toy r us(0.7305)", "verif concept answer": "toy r us(0.7300)", "verif image answer": "toy r us(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040085.jpg"}, {"question": "what sort of building is on the horizon", "gt answer": "lighthouse(1.00)", "pred answer": "house", "question_id": 5019025, "best approach": "wiki, concept, image", "verif answer": "lighthouse", "anno approach": "wiki", "verif wiki answer": "lighthouse(0.7311)", "verif concept answer": "lighthouse(0.7311)", "verif image answer": "lighthouse(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501902.jpg"}, {"question": "what is the boat hook to so it doesn't float away", "gt answer": "anchor(1.00)", "pred answer": "boat", "question_id": 5188665, "best approach": "wiki, concept, image", "verif answer": "anchor", "anno approach": "concept, wiki", "verif wiki answer": "anchor(0.5123)", "verif concept answer": "anchor(0.5769)", "verif image answer": "anchor(0.5031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518866.jpg"}, {"question": "what is the burning stick on the cake called", "gt answer": "candle(1.00)", "pred answer": "candle", "question_id": 4801215, "best approach": "wiki, concept, image", "verif answer": "candle", "anno approach": "wiki", "verif wiki answer": "candle(0.7310)", "verif concept answer": "candle(0.7310)", "verif image answer": "candle(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480121.jpg"}, {"question": "what item crossing the ceiling has the same name as an instrument", "gt answer": "pipe(1.00)<br/>cello(0.60)", "pred answer": "blind", "question_id": 3353665, "best approach": "wiki", "verif answer": "pipe", "anno approach": "wiki", "verif wiki answer": "pipe(0.5542)", "verif concept answer": "half pipe(0.5191)", "verif image answer": "hose(0.5089)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335366.jpg"}, {"question": "what is the colloquial name for the breed of dog in this picture", "gt answer": "basset hound(1.00)<br/>hound(0.60)<br/>hotdog(0.60)", "pred answer": "beagle", "question_id": 3986325, "best approach": "", "verif answer": "beagle", "anno approach": "", "verif wiki answer": "beagle(0.6712)", "verif concept answer": "beagle(0.6508)", "verif image answer": "beagle(0.7082)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398632.jpg"}, {"question": "what kind of alcoholic beverage is being advertised on the trailer", "gt answer": "beer(1.00)", "pred answer": "wine", "question_id": 1778325, "best approach": "wiki", "verif answer": "vodka", "anno approach": "wiki", "verif wiki answer": "beer(0.6019)", "verif concept answer": "wine(0.6118)", "verif image answer": "vodka(0.7037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177832.jpg"}, {"question": "which method of transport shown here is statistically the safest method of travel", "gt answer": "car(0.60)<br/>air(0.60)<br/>fly(0.60)<br/>airplane(1.00)", "pred answer": "bus", "question_id": 3021415, "best approach": "wiki, concept", "verif answer": "to fly", "anno approach": "wiki", "verif wiki answer": "airplane(0.5004)", "verif concept answer": "airplane(0.5004)", "verif image answer": "to fly(0.5011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302141.jpg"}, {"question": "what are the small pink squares of paper called", "gt answer": "post it note(1.00)", "pred answer": "tie", "question_id": 1185505, "best approach": "", "verif answer": "counter", "anno approach": "", "verif wiki answer": "counter(0.7310)", "verif concept answer": "counter(0.7145)", "verif image answer": "counter(0.5171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118550.jpg"}, {"question": "what is this used for", "gt answer": "ride(1.00)<br/>transportation(0.60)<br/>cycling(0.60)<br/>race(0.60)", "pred answer": "transportation", "question_id": 28235, "best approach": "wiki, concept, image", "verif answer": "ride", "anno approach": "image, wiki", "verif wiki answer": "ride(0.6332)", "verif concept answer": "ride(0.6340)", "verif image answer": "ride(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002823.jpg"}, {"question": "what are these large white bears called", "gt answer": "polar bear(1.00)<br/>polar(0.60)", "pred answer": "fish", "question_id": 3287435, "best approach": "wiki", "verif answer": "polar", "anno approach": "wiki", "verif wiki answer": "polar(0.6594)", "verif concept answer": "brown(0.6537)", "verif image answer": "brown(0.6322)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328743.jpg"}, {"question": "what is the utensil on the plate used for", "gt answer": "cut(1.00)<br/>slice(0.60)", "pred answer": "cut", "question_id": 3860585, "best approach": "", "verif answer": "chop", "anno approach": "", "verif wiki answer": "chop(0.5930)", "verif concept answer": "chop(0.6479)", "verif image answer": "chop(0.6317)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000386058.jpg"}, {"question": "what does the diet of this animal consist of", "gt answer": "leaf(1.00)<br/>grass(0.60)<br/>plant(0.60)", "pred answer": "grass", "question_id": 4444645, "best approach": "wiki, image", "verif answer": "grass", "anno approach": "wiki", "verif wiki answer": "grass(0.6400)", "verif concept answer": "herbivore(0.6549)", "verif image answer": "grass(0.6607)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000444464.jpg"}, {"question": "who is credited with inventing the game being played here", "gt answer": "abner doubleday(1.00)<br/>women(0.60)<br/>baseball(0.60)", "pred answer": "babe ruth", "question_id": 3091445, "best approach": "wiki, concept, image", "verif answer": "abner doubleday", "anno approach": "", "verif wiki answer": "abner doubleday(0.5307)", "verif concept answer": "abner doubleday(0.5303)", "verif image answer": "abner doubleday(0.5084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000309144.jpg"}, {"question": "what is wrong with this picture", "gt answer": "dog drive(1.00)", "pred answer": "fell", "question_id": 4607025, "best approach": "", "verif answer": "color", "anno approach": "", "verif wiki answer": "color(0.5433)", "verif concept answer": "dog(0.5361)", "verif image answer": "dog(0.5378)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460702.jpg"}, {"question": "what nationality are these art pieces", "gt answer": "american(1.00)<br/>japan(0.60)<br/>egyptian(0.60)", "pred answer": "asian", "question_id": 859605, "best approach": "image", "verif answer": "egyptian", "anno approach": "image", "verif wiki answer": "indian(0.6534)", "verif concept answer": "egyptian(0.6637)", "verif image answer": "american(0.6497)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085960.jpg"}, {"question": "what kind of outfit is needed for this", "gt answer": "wet suit(1.00)<br/>wetsuit(0.60)", "pred answer": "wet suit", "question_id": 4588945, "best approach": "wiki, concept, image", "verif answer": "wet suit", "anno approach": "wiki", "verif wiki answer": "wet suit(0.7311)", "verif concept answer": "wet suit(0.7311)", "verif image answer": "wet suit(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458894.jpg"}, {"question": "what elements make of the elements of the molecules of the white surface that the child is in", "gt answer": "hydrogen and oxygen(1.00)<br/>h2o(0.60)", "pred answer": "polish", "question_id": 1939775, "best approach": "wiki, concept, image", "verif answer": "h2o", "anno approach": "concept, wiki", "verif wiki answer": "h2o(0.6232)", "verif concept answer": "h2o(0.6647)", "verif image answer": "h2o(0.5637)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193977.jpg"}, {"question": "generally how clear is the water in these circumstances", "gt answer": "murky(1.00)", "pred answer": "not at all", "question_id": 1034045, "best approach": "image", "verif answer": "not at all", "anno approach": "image", "verif wiki answer": "not at all(0.6400)", "verif concept answer": "not at all(0.6317)", "verif image answer": "murky(0.5116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103404.jpg"}, {"question": "what kind of bear is this", "gt answer": "stuffed(1.00)<br/>bear(0.60)", "pred answer": "teddy bear", "question_id": 2227605, "best approach": "", "verif answer": "teddy bear", "anno approach": "", "verif wiki answer": "teddy bear(0.6644)", "verif concept answer": "teddy bear(0.6747)", "verif image answer": "teddy bear(0.6571)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222760.jpg"}, {"question": "what is found inside these doors", "gt answer": "toilet(1.00)", "pred answer": "people", "question_id": 3003925, "best approach": "wiki, concept, image", "verif answer": "toilet", "anno approach": "image, concept, wiki", "verif wiki answer": "toilet(0.6557)", "verif concept answer": "toilet(0.7107)", "verif image answer": "toilet(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300392.jpg"}, {"question": "where would a person sit to feed birds", "gt answer": "bench(1.00)<br/>park(0.60)", "pred answer": "bench", "question_id": 2741235, "best approach": "wiki, concept", "verif answer": "bench", "anno approach": "wiki", "verif wiki answer": "bench(0.7223)", "verif concept answer": "bench(0.7310)", "verif image answer": "orange(0.6853)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274123.jpg"}, {"question": "what utensil is on the plate", "gt answer": "spoon(1.00)", "pred answer": "fork", "question_id": 5146665, "best approach": "", "verif answer": "fork", "anno approach": "", "verif wiki answer": "fork(0.7082)", "verif concept answer": "fork(0.6045)", "verif image answer": "fork(0.5388)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514666.jpg"}, {"question": "what model is the model of the computer being shown", "gt answer": "desktop(1.00)<br/>dell(0.60)<br/>ibm(0.60)", "pred answer": "ibm", "question_id": 3655125, "best approach": "image", "verif answer": "hp", "anno approach": "image", "verif wiki answer": "hp(0.6933)", "verif concept answer": "hp(0.6703)", "verif image answer": "ibm(0.6447)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365512.jpg"}, {"question": "what is in the truck", "gt answer": "supply(1.00)<br/>water(1.00)<br/>box(0.60)", "pred answer": "hotdog", "question_id": 3842635, "best approach": "wiki, concept", "verif answer": "supply", "anno approach": "wiki", "verif wiki answer": "supply(0.7047)", "verif concept answer": "water(0.6119)", "verif image answer": "plant(0.6279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384263.jpg"}, {"question": "horns grow on what gender of cow bull", "gt answer": "male(1.00)", "pred answer": "female", "question_id": 5545595, "best approach": "", "verif answer": "female", "anno approach": "", "verif wiki answer": "female(0.6685)", "verif concept answer": "female(0.6705)", "verif image answer": "female(0.6566)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554559.jpg"}, {"question": "where can this food be found", "gt answer": "circle k(1.00)<br/>cafe(0.60)<br/>gas station(0.60)", "pred answer": "japan", "question_id": 4628035, "best approach": "wiki, concept", "verif answer": "gas station", "anno approach": "wiki", "verif wiki answer": "gas station(0.7288)", "verif concept answer": "gas station(0.7244)", "verif image answer": "bakery(0.7095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000462803.jpg"}, {"question": "what kind of get together is this", "gt answer": "tea party(1.00)<br/>dinner(0.60)<br/>birthday party(0.60)<br/>family(0.60)", "pred answer": "breakfast", "question_id": 1538245, "best approach": "image", "verif answer": "tea party", "anno approach": "image", "verif wiki answer": "lunch(0.5015)", "verif concept answer": "family(0.5026)", "verif image answer": "tea party(0.5742)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153824.jpg"}, {"question": "how much would this stamp be worth if it was used to mail a domestic envelop in the usa", "gt answer": ".49(1.00)", "pred answer": "50", "question_id": 5211125, "best approach": "wiki, concept, image", "verif answer": ".49", "anno approach": "", "verif wiki answer": ".49(0.7309)", "verif concept answer": ".49(0.7309)", "verif image answer": ".49(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521112.jpg"}, {"question": "what do you think is the reason for the decoration", "gt answer": "baby shower(1.00)<br/>birthday(0.60)<br/>celebration(0.60)", "pred answer": "decoration", "question_id": 3466725, "best approach": "image", "verif answer": "retirement", "anno approach": "image", "verif wiki answer": "retirement(0.6560)", "verif concept answer": "retirement(0.6617)", "verif image answer": "celebration(0.5905)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346672.jpg"}, {"question": "what kind of pattern is the chair in this photo", "gt answer": "leopard(1.00)", "pred answer": "stripe", "question_id": 2198615, "best approach": "", "verif answer": "flannel", "anno approach": "", "verif wiki answer": "stripe(0.7307)", "verif concept answer": "stripe(0.7304)", "verif image answer": "flannel(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219861.jpg"}, {"question": "what is this man doing with this plane", "gt answer": "signal(1.00)<br/>direct(0.60)", "pred answer": "trick", "question_id": 1900005, "best approach": "", "verif answer": "stop light", "anno approach": "", "verif wiki answer": "stop light(0.6615)", "verif concept answer": "stop light(0.6582)", "verif image answer": "fly(0.6296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190000.jpg"}, {"question": "what 's coming out the back of this vehicle", "gt answer": "exhaust(1.00)<br/>smoke(0.60)", "pred answer": "air", "question_id": 4619405, "best approach": "", "verif answer": "jet", "anno approach": "", "verif wiki answer": "jet(0.6103)", "verif concept answer": "jet(0.6485)", "verif image answer": "jet(0.7024)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461940.jpg"}, {"question": "what is the yellow stuff on this plate", "gt answer": "rice(1.00)<br/>cauliflower(0.60)<br/>bread(0.60)", "pred answer": "potato", "question_id": 1377575, "best approach": "image", "verif answer": "cauliflower", "anno approach": "image", "verif wiki answer": "kale(0.6614)", "verif concept answer": "kale(0.6180)", "verif image answer": "cauliflower(0.6638)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000137757.jpg"}, {"question": "which player of the sport seen here was the first member of the sport 's hall of fame", "gt answer": "babe ruth(1.00)<br/>ty cobb(0.60)", "pred answer": "baseball", "question_id": 2339015, "best approach": "wiki, concept, image", "verif answer": "babe ruth", "anno approach": "image, wiki", "verif wiki answer": "babe ruth(0.6310)", "verif concept answer": "babe ruth(0.6408)", "verif image answer": "babe ruth(0.6911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233901.jpg"}, {"question": "what kitchen appliance is she reaching into", "gt answer": "oven(1.00)", "pred answer": "blender", "question_id": 2229175, "best approach": "image", "verif answer": "in oven", "anno approach": "image", "verif wiki answer": "fryer(0.6276)", "verif concept answer": "in oven(0.6290)", "verif image answer": "oven(0.6282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222917.jpg"}, {"question": "what kind of lighting tool is the man holding", "gt answer": "reflector(1.00)<br/>mirror(0.60)<br/>flash(0.60)", "pred answer": "bat", "question_id": 3296405, "best approach": "", "verif answer": "take picture", "anno approach": "", "verif wiki answer": "take picture(0.5002)", "verif concept answer": "take picture(0.5162)", "verif image answer": "take picture(0.5054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329640.jpg"}, {"question": "what is this plane used for", "gt answer": "military(1.00)<br/>bomb(0.60)<br/>fly(0.60)", "pred answer": "fly", "question_id": 763725, "best approach": "wiki", "verif answer": "haul", "anno approach": "wiki", "verif wiki answer": "fly(0.6557)", "verif concept answer": "haul(0.6592)", "verif image answer": "haul(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076372.jpg"}, {"question": "why are people standing around", "gt answer": "parade(1.00)<br/>motorcycle(1.00)<br/>festival(0.60)", "pred answer": "party", "question_id": 670855, "best approach": "wiki, concept", "verif answer": "parade", "anno approach": "wiki", "verif wiki answer": "parade(0.6678)", "verif concept answer": "parade(0.6476)", "verif image answer": "rally(0.6564)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067085.jpg"}, {"question": "does this look to be landing or ready to take off", "gt answer": "land(1.00)<br/>landed(0.60)<br/>take off(0.60)", "pred answer": "take off", "question_id": 902745, "best approach": "wiki, concept, image", "verif answer": "take off", "anno approach": "wiki", "verif wiki answer": "take off(0.7310)", "verif concept answer": "take off(0.7298)", "verif image answer": "take off(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090274.jpg"}, {"question": "what kind of train is this", "gt answer": "locomotive(1.00)<br/>passenger(0.60)<br/>steam(0.60)", "pred answer": "freight", "question_id": 3059195, "best approach": "wiki", "verif answer": "freight", "anno approach": "wiki", "verif wiki answer": "locomotive(0.6495)", "verif concept answer": "steam(0.6482)", "verif image answer": "freight(0.7093)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305919.jpg"}, {"question": "what kind of motorcycle is this police officer riding", "gt answer": "harley davidson(1.00)<br/>honda(1.00)<br/>bmw(0.60)", "pred answer": "honda", "question_id": 1566825, "best approach": "", "verif answer": "kawasaki", "anno approach": "", "verif wiki answer": "kawasaki(0.6954)", "verif concept answer": "kawasaki(0.6749)", "verif image answer": "kawasaki(0.6161)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000156682.jpg"}, {"question": "what is the name of the man who built the arc in the bible due to this natural catastrophe", "gt answer": "noah(1.00)", "pred answer": "ben franklin", "question_id": 4424315, "best approach": "", "verif answer": "pacific", "anno approach": "", "verif wiki answer": "pacific(0.6498)", "verif concept answer": "pacific(0.6525)", "verif image answer": "pacific(0.5717)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442431.jpg"}, {"question": "what sound is made by this animal", "gt answer": "bark(1.00)", "pred answer": "meow", "question_id": 2675165, "best approach": "concept, image", "verif answer": "bark", "anno approach": "image", "verif wiki answer": "fir(0.5269)", "verif concept answer": "bark(0.5276)", "verif image answer": "bark(0.5590)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000267516.jpg"}, {"question": "what are the round objects that these people are holding in their hands", "gt answer": "umbrella(1.00)", "pred answer": "book", "question_id": 1743995, "best approach": "wiki", "verif answer": "roof", "anno approach": "wiki", "verif wiki answer": "umbrella(0.7137)", "verif concept answer": "rain(0.7172)", "verif image answer": "roof(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174399.jpg"}, {"question": "what type of swing is being used", "gt answer": "bunt(1.00)<br/>homerun(0.60)", "pred answer": "bat", "question_id": 5387475, "best approach": "concept, image", "verif answer": "bunt", "anno approach": "concept", "verif wiki answer": "foul(0.6398)", "verif concept answer": "bunt(0.7156)", "verif image answer": "bunt(0.6574)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538747.jpg"}, {"question": "what is supposed to go here", "gt answer": "dish(1.00)<br/>laundry(0.60)<br/>cloth(0.60)", "pred answer": "travel", "question_id": 4267785, "best approach": "image", "verif answer": "food", "anno approach": "image", "verif wiki answer": "food(0.6319)", "verif concept answer": "food(0.6335)", "verif image answer": "laundry(0.5903)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426778.jpg"}, {"question": "what is this type of clock called", "gt answer": "analog(1.00)", "pred answer": "old", "question_id": 3586075, "best approach": "image", "verif answer": "grandfather clock", "anno approach": "image", "verif wiki answer": "grandfather clock(0.6145)", "verif concept answer": "grandfather clock(0.6110)", "verif image answer": "analog(0.5644)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358607.jpg"}, {"question": "what is it called when the water arches like this", "gt answer": "wave(1.00)", "pred answer": "crash", "question_id": 4008296, "best approach": "", "verif answer": "drown", "anno approach": "", "verif wiki answer": "pacific(0.6567)", "verif concept answer": "drown(0.6728)", "verif image answer": "drown(0.7193)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400829.jpg"}, {"question": "which department in a store are these children in", "gt answer": "children(0.60)<br/>mall(0.60)<br/>toy(1.00)", "pred answer": "teddy bear", "question_id": 5260985, "best approach": "image", "verif answer": "furniture store", "anno approach": "image", "verif wiki answer": "furniture store(0.6368)", "verif concept answer": "furniture store(0.5932)", "verif image answer": "children(0.5213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526098.jpg"}, {"question": "is this woman travelling alone or with friends and family", "gt answer": "alone(1.00)<br/>family(0.60)", "pred answer": "friend", "question_id": 3883415, "best approach": "concept", "verif answer": "alone", "anno approach": "concept", "verif wiki answer": "team(0.7060)", "verif concept answer": "alone(0.7233)", "verif image answer": "team(0.7147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388341.jpg"}, {"question": "how many world cups has this country won", "gt answer": "0(1.00)<br/>4(0.60)<br/>3(0.60)<br/>5(0.60)", "pred answer": "thousand", "question_id": 2591985, "best approach": "image", "verif answer": "2", "anno approach": "image", "verif wiki answer": "2(0.6999)", "verif concept answer": "2(0.6466)", "verif image answer": "3(0.6105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259198.jpg"}, {"question": "is this a large horse or a small pony", "gt answer": "small pony(1.00)<br/>pony(1.00)", "pred answer": "horse", "question_id": 1191085, "best approach": "wiki, concept", "verif answer": "small pony", "anno approach": "", "verif wiki answer": "small pony(0.7116)", "verif concept answer": "small pony(0.7275)", "verif image answer": "horse(0.6153)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119108.jpg"}, {"question": "what position does he play", "gt answer": "batter(1.00)<br/>hitter(0.60)", "pred answer": "catcher", "question_id": 3328125, "best approach": "", "verif answer": "outfield", "anno approach": "", "verif wiki answer": "outfield(0.6372)", "verif concept answer": "outfield(0.6356)", "verif image answer": "outfield(0.7184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332812.jpg"}, {"question": "this man 's suit is made of what material", "gt answer": "neoprene(1.00)<br/>rubber(1.00)", "pred answer": "neoprene", "question_id": 1308885, "best approach": "concept, image", "verif answer": "neoprene", "anno approach": "", "verif wiki answer": "leather(0.6579)", "verif concept answer": "neoprene(0.6986)", "verif image answer": "neoprene(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130888.jpg"}, {"question": "what kind of institution are these people visiting", "gt answer": "zoo(1.00)", "pred answer": "zoo", "question_id": 1429535, "best approach": "wiki, concept, image", "verif answer": "zoo", "anno approach": "wiki", "verif wiki answer": "zoo(0.7310)", "verif concept answer": "zoo(0.7310)", "verif image answer": "zoo(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142953.jpg"}, {"question": "what device are the two men in the photo using", "gt answer": "tablet(1.00)", "pred answer": "laptop", "question_id": 1689275, "best approach": "", "verif answer": "laptop", "anno approach": "", "verif wiki answer": "laptop(0.7311)", "verif concept answer": "laptop(0.7311)", "verif image answer": "laptop(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168927.jpg"}, {"question": "where can you find this animal naturally occurring", "gt answer": "antarctica(1.00)<br/>north pole(0.60)", "pred answer": "north pole", "question_id": 4691815, "best approach": "wiki, image", "verif answer": "north pole", "anno approach": "image, wiki", "verif wiki answer": "north pole(0.6583)", "verif concept answer": "north america(0.6563)", "verif image answer": "north pole(0.7198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469181.jpg"}, {"question": "what movie does this reference", "gt answer": "forrest gump(1.00)<br/>0(0.60)", "pred answer": "beauty and beast", "question_id": 4268295, "best approach": "wiki", "verif answer": "star war", "anno approach": "wiki", "verif wiki answer": "0(0.5001)", "verif concept answer": "star war(0.5001)", "verif image answer": "star war(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426829.jpg"}, {"question": "what is the batter 's dominant hand", "gt answer": "left(1.00)<br/>right(0.60)", "pred answer": "left", "question_id": 5523045, "best approach": "", "verif answer": "batter", "anno approach": "", "verif wiki answer": "batter(0.6744)", "verif concept answer": "coach(0.6263)", "verif image answer": "coach(0.6726)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552304.jpg"}, {"question": "what is the name of this type of watercraft", "gt answer": "canoe(1.00)<br/>row boat(0.60)<br/>fish boat(0.60)", "pred answer": "canoe", "question_id": 5038755, "best approach": "concept", "verif answer": "canoe", "anno approach": "concept", "verif wiki answer": "fish boat(0.6573)", "verif concept answer": "canoe(0.6729)", "verif image answer": "fish boat(0.6380)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503875.jpg"}, {"question": "what type of lighting is above this man 's head", "gt answer": "fluorescent(1.00)<br/>lamp(0.60)<br/>electrical(0.60)", "pred answer": "overhead", "question_id": 4678475, "best approach": "", "verif answer": "led", "anno approach": "", "verif wiki answer": "chandelier(0.6018)", "verif concept answer": "chandelier(0.5050)", "verif image answer": "led(0.6920)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467847.jpg"}, {"question": "what is the service range of a typical modern jet liner", "gt answer": "3000 miles(1.00)", "pred answer": "30000 feet", "question_id": 4881205, "best approach": "", "verif answer": "4300", "anno approach": "", "verif wiki answer": "4300(0.6411)", "verif concept answer": "4300(0.6849)", "verif image answer": "4300(0.6374)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488120.jpg"}, {"question": "what is the purpose of the device the man is holding in his hand", "gt answer": "communication(1.00)<br/>cell phone(0.60)<br/>pager(0.60)", "pred answer": "cellphone", "question_id": 2976325, "best approach": "wiki, concept", "verif answer": "pager", "anno approach": "", "verif wiki answer": "pager(0.6553)", "verif concept answer": "pager(0.6473)", "verif image answer": "cellphone(0.6407)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297632.jpg"}, {"question": "when was this game sold for the first time", "gt answer": "2007(1.00)<br/>2010(0.60)<br/>2008(0.60)", "pred answer": "1973", "question_id": 1251155, "best approach": "wiki, concept", "verif answer": "2008", "anno approach": "wiki", "verif wiki answer": "2008(0.7293)", "verif concept answer": "2008(0.6976)", "verif image answer": "2004(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125115.jpg"}, {"question": "is that a truck or a car", "gt answer": "truck(1.00)", "pred answer": "truck", "question_id": 726065, "best approach": "wiki, concept, image", "verif answer": "truck", "anno approach": "concept, wiki", "verif wiki answer": "truck(0.7309)", "verif concept answer": "truck(0.7203)", "verif image answer": "truck(0.5726)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072606.jpg"}, {"question": "how many of this food item is sold every year", "gt answer": "20 billion(1.00)<br/>million(0.60)", "pred answer": "3", "question_id": 990085, "best approach": "wiki, concept, image", "verif answer": "million", "anno approach": "image, concept, wiki", "verif wiki answer": "million(0.6500)", "verif concept answer": "million(0.6948)", "verif image answer": "million(0.7159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099008.jpg"}, {"question": "what brand of clothing are the women wearing", "gt answer": "adidas(1.00)", "pred answer": "north face", "question_id": 1289635, "best approach": "", "verif answer": "nike", "anno approach": "", "verif wiki answer": "wilson(0.6600)", "verif concept answer": "nike(0.6933)", "verif image answer": "wilson(0.6517)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128963.jpg"}, {"question": "what type of designer would design this environment", "gt answer": "interior(1.00)<br/>traditional(0.60)", "pred answer": "square", "question_id": 5713665, "best approach": "wiki, image", "verif answer": "just dance", "anno approach": "wiki", "verif wiki answer": "interior(0.6527)", "verif concept answer": "just dance(0.6621)", "verif image answer": "interior(0.6565)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571366.jpg"}, {"question": "what are the people doing", "gt answer": "talk(1.00)", "pred answer": "shake hand", "question_id": 3094545, "best approach": "", "verif answer": "play game", "anno approach": "", "verif wiki answer": "call(0.6364)", "verif concept answer": "call(0.7053)", "verif image answer": "play game(0.7125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000309454.jpg"}, {"question": "how far can that animal travel", "gt answer": "mile(1.00)<br/>100 miles(0.60)", "pred answer": "8 feet", "question_id": 842305, "best approach": "", "verif answer": "5 miles", "anno approach": "", "verif wiki answer": "5 miles(0.6478)", "verif concept answer": "2 hours(0.6462)", "verif image answer": "5 miles(0.6633)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084230.jpg"}, {"question": "what is another ingredient someone might add to this", "gt answer": "cheese(1.00)<br/>bacon(0.60)<br/>meat(0.60)", "pred answer": "bread", "question_id": 2888365, "best approach": "wiki, concept", "verif answer": "cheese", "anno approach": "wiki", "verif wiki answer": "cheese(0.6674)", "verif concept answer": "cheese(0.6586)", "verif image answer": "meat(0.5369)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288836.jpg"}, {"question": "what kind of service do you think this is an ad for", "gt answer": "fly(1.00)<br/>jet(0.60)", "pred answer": "boeing", "question_id": 623515, "best approach": "concept", "verif answer": "take off", "anno approach": "concept", "verif wiki answer": "airplane(0.5008)", "verif concept answer": "fly(0.5010)", "verif image answer": "take off(0.5525)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000062351.jpg"}, {"question": "what activity is this", "gt answer": "swim(1.00)<br/>surf(1.00)", "pred answer": "duck", "question_id": 1063875, "best approach": "wiki, concept, image", "verif answer": "swim", "anno approach": "concept", "verif wiki answer": "surf(0.6154)", "verif concept answer": "swim(0.7009)", "verif image answer": "swim(0.6383)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106387.jpg"}, {"question": "what type of jet is this", "gt answer": "fighter jet(1.00)<br/>fighter(0.60)", "pred answer": "private", "question_id": 4970335, "best approach": "wiki, concept, image", "verif answer": "fighter jet", "anno approach": "wiki", "verif wiki answer": "fighter jet(0.7310)", "verif concept answer": "fighter jet(0.7310)", "verif image answer": "fighter jet(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497033.jpg"}, {"question": "what is the green round type vegetable called on this plate", "gt answer": "pea(1.00)", "pred answer": "pickle", "question_id": 3934885, "best approach": "", "verif answer": "pickle", "anno approach": "", "verif wiki answer": "pickle(0.7310)", "verif concept answer": "broccoli(0.7310)", "verif image answer": "pickle(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393488.jpg"}, {"question": "what is the official name for this breakfast item", "gt answer": "bacon(1.00)<br/>croissant(0.60)", "pred answer": "lunch", "question_id": 4012885, "best approach": "image", "verif answer": "breakfast", "anno approach": "image", "verif wiki answer": "breakfast(0.6665)", "verif concept answer": "breakfast(0.6486)", "verif image answer": "croissant(0.5611)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401288.jpg"}, {"question": "", "gt answer": "account(0.60)", "pred answer": "office", "question_id": 1019525, "best approach": "", "verif answer": "cubicle", "anno approach": "", "verif wiki answer": "cubicle(0.5017)", "verif concept answer": "cubicle(0.5011)", "verif image answer": "cubicle(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000101952.jpg"}, {"question": "is that cat real or photo shopped and if it is real is it safe", "gt answer": "photoshopped(1.00)<br/>photoshop(0.60)", "pred answer": "domestic", "question_id": 2166655, "best approach": "", "verif answer": "real", "anno approach": "", "verif wiki answer": "real(0.7158)", "verif concept answer": "real(0.6705)", "verif image answer": "real(0.5149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216665.jpg"}, {"question": "what type of birds are these", "gt answer": "robin(0.60)<br/>sparrow(1.00)<br/>sing(0.60)", "pred answer": "owl", "question_id": 3356155, "best approach": "wiki", "verif answer": "sparrow", "anno approach": "wiki", "verif wiki answer": "sparrow(0.5167)", "verif concept answer": "hummingbird(0.5001)", "verif image answer": "sing(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335615.jpg"}, {"question": "what does this cup look made out of", "gt answer": "glass(1.00)<br/>plastic(0.60)<br/>metal(0.60)<br/>ceramic(0.60)", "pred answer": "ceramic", "question_id": 308055, "best approach": "wiki, concept, image", "verif answer": "glass", "anno approach": "concept, wiki", "verif wiki answer": "glass(0.7292)", "verif concept answer": "glass(0.7306)", "verif image answer": "glass(0.6749)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030805.jpg"}, {"question": "who controls this vehicle", "gt answer": "driver(1.00)<br/>bus driver(1.00)", "pred answer": "bus driver", "question_id": 3650305, "best approach": "concept, image", "verif answer": "bus driver", "anno approach": "concept", "verif wiki answer": "conductor(0.5078)", "verif concept answer": "bus driver(0.5328)", "verif image answer": "driver(0.5064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365030.jpg"}, {"question": "what biker group is shown", "gt answer": "hell angel(1.00)<br/>club(0.60)<br/>biker(0.60)<br/>motorcycle(0.60)", "pred answer": "biker", "question_id": 3143905, "best approach": "wiki, concept, image", "verif answer": "biker", "anno approach": "wiki", "verif wiki answer": "biker(0.5873)", "verif concept answer": "biker(0.5358)", "verif image answer": "biker(0.5481)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314390.jpg"}, {"question": "which animal shown here is associated with delivering babies", "gt answer": "stork(1.00)<br/>swan(0.60)", "pred answer": "duck", "question_id": 3616435, "best approach": "image", "verif answer": "duck", "anno approach": "image", "verif wiki answer": "duck(0.6609)", "verif concept answer": "duck(0.6770)", "verif image answer": "swan(0.6657)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361643.jpg"}, {"question": "what surface is the plane on", "gt answer": "tarmac(1.00)<br/>pavement(0.60)<br/>runway(0.60)", "pred answer": "runway", "question_id": 4994475, "best approach": "wiki, concept, image", "verif answer": "runway", "anno approach": "image, wiki", "verif wiki answer": "runway(0.7240)", "verif concept answer": "runway(0.6502)", "verif image answer": "runway(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499447.jpg"}, {"question": "what is the person with pads doing", "gt answer": "catch(1.00)<br/>catcher(0.60)", "pred answer": "slide", "question_id": 3976055, "best approach": "concept, image", "verif answer": "catch", "anno approach": "", "verif wiki answer": "play baseball(0.7287)", "verif concept answer": "catch(0.7310)", "verif image answer": "catch(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397605.jpg"}, {"question": "what health issues do these veggies help prevent", "gt answer": "cancer(1.00)", "pred answer": "fiber", "question_id": 1035105, "best approach": "", "verif answer": "scurvy", "anno approach": "", "verif wiki answer": "scurvy(0.6670)", "verif concept answer": "scurvy(0.6491)", "verif image answer": "scurvy(0.7223)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103510.jpg"}, {"question": "what gaming console is he playing", "gt answer": "wii(1.00)", "pred answer": "wii", "question_id": 2132145, "best approach": "wiki, concept, image", "verif answer": "wii", "anno approach": "image, wiki", "verif wiki answer": "wii(0.6962)", "verif concept answer": "wii(0.6532)", "verif image answer": "wii(0.7007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000213214.jpg"}, {"question": "what kind of dog is in the photo", "gt answer": "greyhound(1.00)", "pred answer": "border collie", "question_id": 263215, "best approach": "", "verif answer": "city bus", "anno approach": "", "verif wiki answer": "city bus(0.6610)", "verif concept answer": "city bus(0.6600)", "verif image answer": "city bus(0.6495)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000026321.jpg"}, {"question": "what activity are the people taking part in", "gt answer": "horse race(1.00)<br/>chariot race(1.00)", "pred answer": "horse race", "question_id": 1513395, "best approach": "concept, image", "verif answer": "race", "anno approach": "image", "verif wiki answer": "race(0.6875)", "verif concept answer": "horse race(0.6008)", "verif image answer": "horse race(0.6812)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151339.jpg"}, {"question": "what setting was used to take this picture", "gt answer": "blurry(1.00)<br/>instagram(0.60)", "pred answer": "park", "question_id": 5153005, "best approach": "", "verif answer": "outdoor", "anno approach": "", "verif wiki answer": "outdoor(0.7229)", "verif concept answer": "outdoor(0.7020)", "verif image answer": "outdoor(0.5599)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515300.jpg"}, {"question": "what kind of tree is this", "gt answer": "fir(1.00)<br/>pine(1.00)", "pred answer": "pine", "question_id": 568785, "best approach": "", "verif answer": "oak", "anno approach": "", "verif wiki answer": "oak(0.6825)", "verif concept answer": "oak(0.6744)", "verif image answer": "oak(0.6458)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000056878.jpg"}, {"question": "what is it called if you rode this horse as it 's shown", "gt answer": "bareback(1.00)", "pred answer": "commercial", "question_id": 3694995, "best approach": "wiki, concept", "verif answer": "bareback", "anno approach": "", "verif wiki answer": "bareback(0.7285)", "verif concept answer": "bareback(0.7083)", "verif image answer": "saddle(0.6784)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369499.jpg"}, {"question": "what cat food brand that cat has been eating in the basement niche", "gt answer": "purina(1.00)", "pred answer": "purina", "question_id": 193975, "best approach": "wiki, concept", "verif answer": "purina", "anno approach": "wiki", "verif wiki answer": "purina(0.7116)", "verif concept answer": "purina(0.5920)", "verif image answer": "walmart(0.5198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019397.jpg"}, {"question": "is he safe or out", "gt answer": "safe(1.00)", "pred answer": "safe", "question_id": 2361025, "best approach": "", "verif answer": "unsafe", "anno approach": "", "verif wiki answer": "unsafe(0.7295)", "verif concept answer": "unsafe(0.7310)", "verif image answer": "unsafe(0.6854)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236102.jpg"}, {"question": "why do drivers need the sign", "gt answer": "direct(1.00)<br/>direction(0.60)", "pred answer": "red light", "question_id": 4715915, "best approach": "wiki, image", "verif answer": "direct", "anno approach": "wiki", "verif wiki answer": "direct(0.6663)", "verif concept answer": "turn(0.6458)", "verif image answer": "direct(0.6355)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471591.jpg"}, {"question": "is this an organized political event or a sporting event", "gt answer": "sport event(1.00)", "pred answer": "competition", "question_id": 67805, "best approach": "", "verif answer": "festival", "anno approach": "", "verif wiki answer": "festival(0.6802)", "verif concept answer": "festival(0.7285)", "verif image answer": "festival(0.7214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006780.jpg"}, {"question": "what tennis move is this", "gt answer": "backhand(1.00)", "pred answer": "backhand", "question_id": 3715115, "best approach": "image", "verif answer": "backhand", "anno approach": "image", "verif wiki answer": "underhand(0.7176)", "verif concept answer": "underhand(0.7028)", "verif image answer": "backhand(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371511.jpg"}, {"question": "what was the name of the inventor that created the car company shown in this photo", "gt answer": "karl benz(1.00)", "pred answer": "wimbledon", "question_id": 2467975, "best approach": "", "verif answer": "schwinn", "anno approach": "", "verif wiki answer": "schwinn(0.7258)", "verif concept answer": "schwinn(0.6720)", "verif image answer": "schwinn(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246797.jpg"}, {"question": "what kind of instruments are they playing", "gt answer": "tuba(1.00)<br/>brass(1.00)", "pred answer": "guitar", "question_id": 5715755, "best approach": "", "verif answer": "wicker", "anno approach": "", "verif wiki answer": "wicker(0.5084)", "verif concept answer": "wicker(0.5252)", "verif image answer": "wicker(0.5319)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571575.jpg"}, {"question": "which company owns this plane", "gt answer": "fedex(1.00)", "pred answer": "american airline", "question_id": 2938625, "best approach": "", "verif answer": "american airline", "anno approach": "", "verif wiki answer": "boeing(0.6617)", "verif concept answer": "boeing(0.6467)", "verif image answer": "american airline(0.7282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293862.jpg"}, {"question": "what other type of undergarment was replaced by the bra", "gt answer": "corset(1.00)", "pred answer": "dress", "question_id": 3160915, "best approach": "wiki, concept, image", "verif answer": "corset", "anno approach": "", "verif wiki answer": "corset(0.5001)", "verif concept answer": "corset(0.5010)", "verif image answer": "corset(0.5006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316091.jpg"}, {"question": "how cold is that water", "gt answer": "68 degrees(1.00)<br/>80 degrees(0.60)", "pred answer": "warm", "question_id": 5247185, "best approach": "wiki, concept", "verif answer": "68 degrees", "anno approach": "", "verif wiki answer": "68 degrees(0.6493)", "verif concept answer": "68 degrees(0.6410)", "verif image answer": "foam(0.6337)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000524718.jpg"}, {"question": "what is this person looking at", "gt answer": "mirror(1.00)<br/>toothpaste(0.60)", "pred answer": "bathroom", "question_id": 3889475, "best approach": "", "verif answer": "bathroom", "anno approach": "", "verif wiki answer": "bathroom(0.6761)", "verif concept answer": "bathroom(0.6752)", "verif image answer": "reflector(0.6396)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388947.jpg"}, {"question": "what juice is made from these fruits", "gt answer": "grapefruit(1.00)<br/>juice(0.60)<br/>orange(0.60)", "pred answer": "apple", "question_id": 3113265, "best approach": "wiki, concept, image", "verif answer": "grapefruit", "anno approach": "concept, wiki", "verif wiki answer": "grapefruit(0.6171)", "verif concept answer": "grapefruit(0.6217)", "verif image answer": "grapefruit(0.5650)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311326.jpg"}, {"question": "what breed of cat is this", "gt answer": "siamese(1.00)<br/>persian(0.60)<br/>ragdoll(0.60)", "pred answer": "tabby", "question_id": 327385, "best approach": "concept, image", "verif answer": "siamese", "anno approach": "", "verif wiki answer": "ragdoll(0.6436)", "verif concept answer": "siamese(0.6421)", "verif image answer": "siamese(0.6496)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032738.jpg"}, {"question": "what sport is this", "gt answer": "motorcross(1.00)<br/>motocross(0.60)<br/>dirt bike(0.60)", "pred answer": "dirt bike", "question_id": 1310845, "best approach": "wiki, concept, image", "verif answer": "dirt bike", "anno approach": "wiki", "verif wiki answer": "dirt bike(0.7256)", "verif concept answer": "dirt bike(0.7301)", "verif image answer": "dirt bike(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000131084.jpg"}, {"question": "what browser is this computer using", "gt answer": "internet explorer(1.00)<br/>chrome(0.60)<br/>window(0.60)", "pred answer": "chrome", "question_id": 4352105, "best approach": "wiki, concept, image", "verif answer": "chrome", "anno approach": "concept, wiki", "verif wiki answer": "chrome(0.7309)", "verif concept answer": "chrome(0.7308)", "verif image answer": "chrome(0.5519)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435210.jpg"}, {"question": "what do these umbrellas appear to be doing", "gt answer": "float(1.00)<br/>fly(0.60)", "pred answer": "play", "question_id": 1443575, "best approach": "concept", "verif answer": "swim", "anno approach": "concept", "verif wiki answer": "land(0.6524)", "verif concept answer": "float(0.6742)", "verif image answer": "swim(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144357.jpg"}, {"question": "why does the boy in the white play baseball", "gt answer": "for fun(1.00)<br/>fun(1.00)", "pred answer": "uniform", "question_id": 1638285, "best approach": "wiki", "verif answer": "very", "anno approach": "wiki", "verif wiki answer": "for fun(0.6520)", "verif concept answer": "very(0.6477)", "verif image answer": "very(0.6545)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163828.jpg"}, {"question": "is this person a thrill seeker or is he safe", "gt answer": "thrill seeker(1.00)<br/>safe(0.60)", "pred answer": "safe", "question_id": 3502545, "best approach": "wiki, concept, image", "verif answer": "safe", "anno approach": "wiki", "verif wiki answer": "safe(0.7309)", "verif concept answer": "safe(0.7253)", "verif image answer": "safe(0.7282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350254.jpg"}, {"question": "name the ingredients used to make this dish in this picture", "gt answer": "flour(1.00)<br/>sugar(0.60)", "pred answer": "cheese", "question_id": 3664175, "best approach": "wiki, concept", "verif answer": "flour", "anno approach": "wiki", "verif wiki answer": "flour(0.6385)", "verif concept answer": "flour(0.6678)", "verif image answer": "dough spinach cheese(0.5389)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366417.jpg"}, {"question": "what famous person had many video games named after them in the sport pictured", "gt answer": "kelly slater(1.00)<br/>tony hawk(0.60)", "pred answer": "kelly slater", "question_id": 3033305, "best approach": "wiki, concept, image", "verif answer": "kelly slater", "anno approach": "concept, wiki", "verif wiki answer": "kelly slater(0.7025)", "verif concept answer": "kelly slater(0.7265)", "verif image answer": "kelly slater(0.6784)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303330.jpg"}, {"question": "behind the mirrors shown here there is likely what kind of cabinet", "gt answer": "medicine(1.00)<br/>reflection(0.60)", "pred answer": "tile", "question_id": 5754835, "best approach": "wiki, concept, image", "verif answer": "reflection", "anno approach": "concept, wiki", "verif wiki answer": "reflection(0.6494)", "verif concept answer": "reflection(0.6747)", "verif image answer": "reflection(0.6111)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575483.jpg"}, {"question": "how much is the wii nun chuck", "gt answer": "$40(1.00)<br/>15(0.60)<br/>1(0.60)", "pred answer": "100 lbs", "question_id": 1951955, "best approach": "concept", "verif answer": "15", "anno approach": "concept", "verif wiki answer": "15(0.5817)", "verif concept answer": "$40(0.5997)", "verif image answer": "15(0.6438)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195195.jpg"}, {"question": "what do people eat for breakfast that 's made in a pan", "gt answer": "pancake(1.00)", "pred answer": "bread", "question_id": 4413825, "best approach": "wiki, concept, image", "verif answer": "pancake", "anno approach": "concept, wiki", "verif wiki answer": "pancake(0.6953)", "verif concept answer": "pancake(0.6660)", "verif image answer": "pancake(0.5796)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441382.jpg"}, {"question": "why would you use this thing", "gt answer": "fish(1.00)<br/>travel(0.60)", "pred answer": "sail", "question_id": 2692135, "best approach": "", "verif answer": "sail", "anno approach": "", "verif wiki answer": "sail(0.6604)", "verif concept answer": "sail(0.6780)", "verif image answer": "boat(0.6323)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269213.jpg"}, {"question": "what country is this street located in", "gt answer": "poland(1.00)<br/>russia(0.60)<br/>america(0.60)<br/>rome(0.60)", "pred answer": "england", "question_id": 3405235, "best approach": "wiki, image", "verif answer": "europe", "anno approach": "wiki", "verif wiki answer": "rome(0.6807)", "verif concept answer": "europe(0.7282)", "verif image answer": "rome(0.6663)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340523.jpg"}, {"question": "why do people typically visit this location", "gt answer": "vacation(1.00)<br/>walk(0.60)", "pred answer": "beach", "question_id": 4052885, "best approach": "wiki, concept, image", "verif answer": "walk", "anno approach": "image, wiki", "verif wiki answer": "walk(0.6478)", "verif concept answer": "walk(0.6624)", "verif image answer": "walk(0.6915)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405288.jpg"}, {"question": "what type of dog is this", "gt answer": "chihuahua(1.00)<br/>dachshund(0.60)<br/>mutt(0.60)", "pred answer": "bulldog", "question_id": 3850665, "best approach": "", "verif answer": "doberman", "anno approach": "", "verif wiki answer": "doberman(0.7309)", "verif concept answer": "doberman(0.7300)", "verif image answer": "doberman(0.7223)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385066.jpg"}, {"question": "why would we suspect this reader has good eyesight", "gt answer": "no glass(1.00)", "pred answer": "glass", "question_id": 3799805, "best approach": "", "verif answer": "danger", "anno approach": "", "verif wiki answer": "danger(0.5509)", "verif concept answer": "danger(0.5081)", "verif image answer": "danger(0.5004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379980.jpg"}, {"question": "what animal would you find in this house", "gt answer": "bird(1.00)", "pred answer": "bird", "question_id": 5410725, "best approach": "wiki, image", "verif answer": "bird", "anno approach": "image, wiki", "verif wiki answer": "bird(0.6921)", "verif concept answer": "monkey(0.6820)", "verif image answer": "bird(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541072.jpg"}, {"question": "what is faster between this animal and the bicycle", "gt answer": "bicycle(1.00)<br/>bike(0.60)", "pred answer": "transportation", "question_id": 4978155, "best approach": "", "verif answer": "regular", "anno approach": "", "verif wiki answer": "regular(0.6351)", "verif concept answer": "regular(0.6450)", "verif image answer": "(0.6211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497815.jpg"}, {"question": "why are cakes usually eaten at party 's", "gt answer": "celebration(1.00)", "pred answer": "birthday", "question_id": 4213155, "best approach": "", "verif answer": "birthday", "anno approach": "", "verif wiki answer": "birthday(0.6970)", "verif concept answer": "birthday(0.6825)", "verif image answer": "birthday(0.6855)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421315.jpg"}, {"question": "what famous film about an amputee athlete features the sport in the above picture", "gt answer": "soul surfer(1.00)", "pred answer": "water ski", "question_id": 817155, "best approach": "wiki, concept, image", "verif answer": "soul surfer", "anno approach": "concept, wiki", "verif wiki answer": "soul surfer(0.6619)", "verif concept answer": "soul surfer(0.6073)", "verif image answer": "soul surfer(0.5150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081715.jpg"}, {"question": "what company manufactures the device the woman is holding", "gt answer": "nintendo(1.00)", "pred answer": "nintendo", "question_id": 2222625, "best approach": "image", "verif answer": "nintendo", "anno approach": "image", "verif wiki answer": "wii(0.6604)", "verif concept answer": "wii(0.6828)", "verif image answer": "nintendo(0.7077)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222262.jpg"}, {"question": "when do people usually wear this outfit", "gt answer": "wed(1.00)", "pred answer": "business", "question_id": 5658495, "best approach": "wiki", "verif answer": "flower shop", "anno approach": "wiki", "verif wiki answer": "wed(0.6688)", "verif concept answer": "flower shop(0.7062)", "verif image answer": "marriage(0.6278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000565849.jpg"}, {"question": "what is the process of making this pattern on grass called", "gt answer": "mow(1.00)<br/>stripe(0.60)<br/>scratch(0.60)", "pred answer": "pitch", "question_id": 3493585, "best approach": "wiki", "verif answer": "striped", "anno approach": "wiki", "verif wiki answer": "stripe(0.7294)", "verif concept answer": "striped(0.7300)", "verif image answer": "striped(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000349358.jpg"}, {"question": "what is the battery life of that laptop", "gt answer": "8 hours(1.00)<br/>6 hours(0.60)<br/>2 hours(0.60)", "pred answer": "2 days", "question_id": 1911365, "best approach": "wiki", "verif answer": "6 hours", "anno approach": "wiki", "verif wiki answer": "6 hours(0.7002)", "verif concept answer": "10 hours(0.6436)", "verif image answer": "10 hours(0.6480)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191136.jpg"}, {"question": "what is the green stick type vegetables called on this plate", "gt answer": "asparagus(1.00)<br/>fall(0.60)", "pred answer": "broccoli", "question_id": 5313745, "best approach": "", "verif answer": "broccoli", "anno approach": "", "verif wiki answer": "broccoli(0.6941)", "verif concept answer": "broccoli(0.7201)", "verif image answer": "broccoli(0.5670)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531374.jpg"}, {"question": "how many neck vertebrae does this animal have", "gt answer": "7(1.00)<br/>16(0.60)<br/>3(0.60)<br/>many(0.60)", "pred answer": "32", "question_id": 50115, "best approach": "wiki, concept, image", "verif answer": "7", "anno approach": "concept, wiki", "verif wiki answer": "7(0.7041)", "verif concept answer": "7(0.6882)", "verif image answer": "7(0.6418)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005011.jpg"}, {"question": "what event is this", "gt answer": "retirement(1.00)<br/>celebration(0.60)<br/>birthday(0.60)", "pred answer": "birthday", "question_id": 42595, "best approach": "concept", "verif answer": "formal", "anno approach": "concept", "verif wiki answer": "award(0.6358)", "verif concept answer": "celebration(0.6117)", "verif image answer": "formal(0.7020)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004259.jpg"}, {"question": "what is this fixture used for", "gt answer": "heat(1.00)<br/>food(0.60)<br/>cook(0.60)", "pred answer": "cook", "question_id": 4700685, "best approach": "wiki, concept, image", "verif answer": "food", "anno approach": "concept, wiki", "verif wiki answer": "food(0.6147)", "verif concept answer": "food(0.6103)", "verif image answer": "cook(0.5441)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470068.jpg"}, {"question": "is this bowl cast or molded", "gt answer": "cast(1.00)", "pred answer": "fine", "question_id": 4910295, "best approach": "wiki", "verif answer": "custom", "anno approach": "wiki", "verif wiki answer": "cast(0.5002)", "verif concept answer": "custom(0.5001)", "verif image answer": "custom(0.5049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491029.jpg"}, {"question": "which frisbee events are in the olympics", "gt answer": "0(1.00)<br/>frisbee(0.60)<br/>discus(0.60)", "pred answer": "soccer", "question_id": 787815, "best approach": "", "verif answer": "soccer", "anno approach": "", "verif wiki answer": "soccer(0.6389)", "verif concept answer": "soccer(0.6646)", "verif image answer": "golf(0.5930)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078781.jpg"}, {"question": "who is pictured on the banner", "gt answer": "obama(1.00)<br/>barack obama(0.60)", "pred answer": "star", "question_id": 1339815, "best approach": "", "verif answer": "roosevelt", "anno approach": "", "verif wiki answer": "roosevelt(0.7293)", "verif concept answer": "roosevelt(0.7063)", "verif image answer": "roosevelt(0.7016)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000133981.jpg"}, {"question": "what are they drinking with the pizza", "gt answer": "beer(1.00)<br/>wine(1.00)", "pred answer": "wine", "question_id": 5711575, "best approach": "wiki, concept", "verif answer": "beer", "anno approach": "wiki", "verif wiki answer": "beer(0.7207)", "verif concept answer": "wine(0.6869)", "verif image answer": "soda(0.6499)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571157.jpg"}, {"question": "what muscles does this sport particularly help", "gt answer": "leg(1.00)<br/>arm(0.60)", "pred answer": "abdominal", "question_id": 5219235, "best approach": "image", "verif answer": "leg", "anno approach": "image", "verif wiki answer": "stomach(0.6669)", "verif concept answer": "arm(0.6614)", "verif image answer": "leg(0.6702)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521923.jpg"}, {"question": "what sport is this showing", "gt answer": "motorcycle race(1.00)<br/>motorcross(0.60)<br/>race(0.60)", "pred answer": "bike", "question_id": 5270825, "best approach": "", "verif answer": "dirt bike", "anno approach": "", "verif wiki answer": "dirt bike(0.7305)", "verif concept answer": "dirt bike(0.7309)", "verif image answer": "dirt bike(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527082.jpg"}, {"question": "what breed of cat is this", "gt answer": "american shorthair(1.00)<br/>tabby(0.60)<br/>domestic shorthair(0.60)<br/>house cat(0.60)", "pred answer": "calico", "question_id": 1478835, "best approach": "", "verif answer": "calico", "anno approach": "", "verif wiki answer": "calico(0.7068)", "verif concept answer": "calico(0.6705)", "verif image answer": "calico(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147883.jpg"}, {"question": "where would you normally see this", "gt answer": "highway(1.00)", "pred answer": "street", "question_id": 5363185, "best approach": "wiki", "verif answer": "highway", "anno approach": "wiki", "verif wiki answer": "highway(0.7265)", "verif concept answer": "city(0.7000)", "verif image answer": "airport(0.5967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536318.jpg"}, {"question": "what name is given to the area where the pilot sits", "gt answer": "cockpit(1.00)", "pred answer": "cockpit", "question_id": 3781115, "best approach": "", "verif answer": "robin", "anno approach": "", "verif wiki answer": "robin(0.7222)", "verif concept answer": "robin(0.7240)", "verif image answer": "cirrus(0.6874)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378111.jpg"}, {"question": "can you name this famous location", "gt answer": "beach(1.00)", "pred answer": "beach", "question_id": 4049645, "best approach": "wiki, concept", "verif answer": "beach", "anno approach": "wiki", "verif wiki answer": "beach(0.5000)", "verif concept answer": "beach(0.5000)", "verif image answer": "california(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404964.jpg"}, {"question": "what kind of bird is this", "gt answer": "crane(1.00)<br/>pelican(0.60)<br/>stork(0.60)<br/>goose(0.60)", "pred answer": "parakeet", "question_id": 2546455, "best approach": "wiki, concept, image", "verif answer": "pelican", "anno approach": "wiki", "verif wiki answer": "pelican(0.6616)", "verif concept answer": "pelican(0.6834)", "verif image answer": "pelican(0.6594)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000254645.jpg"}, {"question": "what animals are in this picture", "gt answer": "giraffe(1.00)", "pred answer": "giraffe", "question_id": 2230045, "best approach": "wiki, concept, image", "verif answer": "giraffe", "anno approach": "wiki", "verif wiki answer": "giraffe(0.7286)", "verif concept answer": "giraffe(0.7254)", "verif image answer": "giraffe(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223004.jpg"}, {"question": "what is the barrier made out of", "gt answer": "concrete(1.00)<br/>cement(0.60)", "pred answer": "stone", "question_id": 5171605, "best approach": "", "verif answer": "stone", "anno approach": "", "verif wiki answer": "stone(0.7268)", "verif concept answer": "asphalt(0.6568)", "verif image answer": "asphalt(0.7041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517160.jpg"}, {"question": "name an appliance you see in this picture", "gt answer": "wash machine(1.00)<br/>dryer(0.60)<br/>oven(0.60)", "pred answer": "microwave", "question_id": 1832475, "best approach": "wiki, concept", "verif answer": "wash machine", "anno approach": "concept", "verif wiki answer": "wash machine(0.5581)", "verif concept answer": "wash machine(0.6710)", "verif image answer": "oven(0.5773)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183247.jpg"}, {"question": "why is this truck driving by", "gt answer": "parade(1.00)", "pred answer": "tow", "question_id": 2956575, "best approach": "image", "verif answer": "parade", "anno approach": "image", "verif wiki answer": "circus(0.6444)", "verif concept answer": "circus(0.6646)", "verif image answer": "parade(0.6692)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295657.jpg"}, {"question": "how was that item on the leaf made", "gt answer": "poached(1.00)", "pred answer": "slice", "question_id": 1611935, "best approach": "", "verif answer": "steamed", "anno approach": "", "verif wiki answer": "bake(0.6376)", "verif concept answer": "bake(0.6831)", "verif image answer": "steamed(0.6848)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161193.jpg"}, {"question": "what pastry is pictured", "gt answer": "donut(1.00)<br/>doughnut(1.00)", "pred answer": "donut", "question_id": 2346995, "best approach": "wiki, image", "verif answer": "doughnut", "anno approach": "wiki", "verif wiki answer": "doughnut(0.7253)", "verif concept answer": "donuts(0.7140)", "verif image answer": "doughnut(0.5495)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000234699.jpg"}, {"question": "what is the name for what is happening in this picture", "gt answer": "traffic jam(1.00)<br/>traffic(0.60)<br/>rush hour(0.60)", "pred answer": "bus", "question_id": 5269225, "best approach": "", "verif answer": "jam", "anno approach": "", "verif wiki answer": "jam(0.6022)", "verif concept answer": "jam(0.6265)", "verif image answer": "jam(0.5643)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526922.jpg"}, {"question": "what is the jumping man pulling behind him", "gt answer": "suitcase(1.00)<br/>luggage(0.60)", "pred answer": "suitcase", "question_id": 907395, "best approach": "concept", "verif answer": "case", "anno approach": "concept", "verif wiki answer": "luggage(0.5014)", "verif concept answer": "suitcase(0.5011)", "verif image answer": "case(0.5733)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090739.jpg"}, {"question": "what century is this", "gt answer": "19th(1.00)<br/>20th(0.60)<br/>1800's(0.60)<br/>1880(0.60)", "pred answer": "20th", "question_id": 3295435, "best approach": "concept, image", "verif answer": "20th", "anno approach": "", "verif wiki answer": "20th(0.7219)", "verif concept answer": "19th(0.6962)", "verif image answer": "19th(0.6728)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329543.jpg"}, {"question": "are these workers being hygienic or unhygienic in their work", "gt answer": "hygienic(1.00)", "pred answer": "vegan", "question_id": 4558745, "best approach": "", "verif answer": "active", "anno approach": "", "verif wiki answer": "active(0.7213)", "verif concept answer": "active(0.7310)", "verif image answer": "unhygienic(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455874.jpg"}, {"question": "is this artwork or practical", "gt answer": "artwork(1.00)", "pred answer": "paint", "question_id": 3850165, "best approach": "", "verif answer": "art", "anno approach": "", "verif wiki answer": "art(0.7299)", "verif concept answer": "art(0.7309)", "verif image answer": "art(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385016.jpg"}, {"question": "what kind of laptop is pictured", "gt answer": "hp(1.00)<br/>macbook(0.60)<br/>dell(0.60)", "pred answer": "dell", "question_id": 4490375, "best approach": "wiki, concept, image", "verif answer": "hp", "anno approach": "image, wiki", "verif wiki answer": "hp(0.6527)", "verif concept answer": "hp(0.6817)", "verif image answer": "hp(0.7191)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449037.jpg"}, {"question": "which metal object did the dish run away with in the nursery rhyme", "gt answer": "spoon(1.00)", "pred answer": "spoon", "question_id": 4821965, "best approach": "", "verif answer": "chop stick", "anno approach": "", "verif wiki answer": "chopstick(0.6897)", "verif concept answer": "chopstick(0.7237)", "verif image answer": "chop stick(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482196.jpg"}, {"question": "what kind of material is this floor made of", "gt answer": "linoleum(1.00)<br/>tile(0.60)<br/>concrete(0.60)", "pred answer": "wood", "question_id": 1925855, "best approach": "wiki, concept", "verif answer": "tile", "anno approach": "wiki", "verif wiki answer": "tile(0.7311)", "verif concept answer": "tile(0.7309)", "verif image answer": "cement(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000192585.jpg"}, {"question": "what resturant sells this", "gt answer": "fast food(1.00)<br/>hotdog(0.60)", "pred answer": "chicago", "question_id": 2817485, "best approach": "", "verif answer": "italian", "anno approach": "", "verif wiki answer": "italian(0.6648)", "verif concept answer": "italian(0.6336)", "verif image answer": "italian(0.6482)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281748.jpg"}, {"question": "what are these people walking through", "gt answer": "alley(1.00)<br/>street(1.00)", "pred answer": "city", "question_id": 4469715, "best approach": "", "verif answer": "india", "anno approach": "", "verif wiki answer": "india(0.6390)", "verif concept answer": "india(0.6631)", "verif image answer": "india(0.7221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000446971.jpg"}, {"question": "what is this kit used for", "gt answer": "sew(1.00)<br/>school(0.60)", "pred answer": "travel", "question_id": 842835, "best approach": "", "verif answer": "knit", "anno approach": "", "verif wiki answer": "knit(0.6336)", "verif concept answer": "knit(0.6300)", "verif image answer": "knit(0.6510)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084283.jpg"}, {"question": "what are these people about to do", "gt answer": "ski(1.00)", "pred answer": "ski", "question_id": 2969335, "best approach": "wiki, concept, image", "verif answer": "ski", "anno approach": "wiki", "verif wiki answer": "ski(0.7310)", "verif concept answer": "ski(0.7310)", "verif image answer": "ski(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296933.jpg"}, {"question": "what do the red street signs mean", "gt answer": "wrong way(1.00)<br/>stop(1.00)", "pred answer": "turn", "question_id": 5697475, "best approach": "wiki, concept, image", "verif answer": "stop", "anno approach": "image, wiki", "verif wiki answer": "wrong way(0.5621)", "verif concept answer": "wrong way(0.5029)", "verif image answer": "stop(0.5787)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569747.jpg"}, {"question": "the sort of work that this man is doing could lead to trouble with what part of the body later in life", "gt answer": "back(1.00)", "pred answer": "too small", "question_id": 435005, "best approach": "", "verif answer": "behind", "anno approach": "", "verif wiki answer": "behind(0.6387)", "verif concept answer": "behind(0.6556)", "verif image answer": "feet(0.6216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043500.jpg"}, {"question": "what do ships do at this location", "gt answer": "dock(1.00)", "pred answer": "boat", "question_id": 1941595, "best approach": "", "verif answer": "port", "anno approach": "", "verif wiki answer": "port(0.5346)", "verif concept answer": "pier(0.5207)", "verif image answer": "pier(0.5204)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194159.jpg"}, {"question": "how long is this womans hair", "gt answer": "short(1.00)<br/>2 feet(0.60)", "pred answer": "2 feet", "question_id": 324915, "best approach": "concept", "verif answer": "long", "anno approach": "concept", "verif wiki answer": "long(0.6445)", "verif concept answer": "short(0.6429)", "verif image answer": "long(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032491.jpg"}, {"question": "what type of piano is behind the stained glass", "gt answer": "grand(1.00)", "pred answer": "grand", "question_id": 1639655, "best approach": "", "verif answer": "modern", "anno approach": "", "verif wiki answer": "modern(0.5002)", "verif concept answer": "modern(0.5013)", "verif image answer": "modern(0.6006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163965.jpg"}, {"question": "what is pulling this wakeboarder", "gt answer": "boat(1.00)", "pred answer": "boat", "question_id": 3574155, "best approach": "wiki, concept, image", "verif answer": "boat", "anno approach": "image, wiki", "verif wiki answer": "boat(0.6478)", "verif concept answer": "boat(0.6393)", "verif image answer": "boat(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357415.jpg"}, {"question": "what hearty cut of meat lends itself to the name of this version of fried potatoes", "gt answer": "steak(1.00)<br/>pork(0.60)<br/>fry(0.60)", "pred answer": "hotdog", "question_id": 400065, "best approach": "", "verif answer": "beef", "anno approach": "", "verif wiki answer": "beef(0.6051)", "verif concept answer": "beef(0.6310)", "verif image answer": "beef(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040006.jpg"}, {"question": "which wind related activity is the boy participating in", "gt answer": "kite fly(1.00)<br/>kite(0.60)", "pred answer": "fly kite", "question_id": 1069415, "best approach": "", "verif answer": "fly kite", "anno approach": "", "verif wiki answer": "fly kite(0.7310)", "verif concept answer": "fly kite(0.7310)", "verif image answer": "fly kite(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106941.jpg"}, {"question": "is this legal or illegal", "gt answer": "legal(1.00)", "pred answer": "illegal", "question_id": 968205, "best approach": "", "verif answer": "illegal", "anno approach": "", "verif wiki answer": "illegal(0.7282)", "verif concept answer": "illegal(0.7305)", "verif image answer": "illegal(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096820.jpg"}, {"question": "is this a toy or a transportation device", "gt answer": "toy(1.00)", "pred answer": "fight", "question_id": 4261185, "best approach": "", "verif answer": "both", "anno approach": "", "verif wiki answer": "both(0.5010)", "verif concept answer": "both(0.5013)", "verif image answer": "both(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426118.jpg"}, {"question": "who invented the object in this photo", "gt answer": "wright brother(1.00)<br/>wright(0.60)", "pred answer": "wright brother", "question_id": 5572005, "best approach": "image", "verif answer": "wright brother", "anno approach": "image", "verif wiki answer": "boeing(0.6588)", "verif concept answer": "boeing(0.6632)", "verif image answer": "wright brother(0.6691)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557200.jpg"}, {"question": "what is the baseball player doing", "gt answer": "slide(1.00)<br/>steal(0.60)", "pred answer": "pitch", "question_id": 2708095, "best approach": "wiki, concept, image", "verif answer": "steal", "anno approach": "concept, wiki", "verif wiki answer": "steal(0.6583)", "verif concept answer": "steal(0.7307)", "verif image answer": "steal(0.6521)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270809.jpg"}, {"question": "which motorcycle would most likely be more expensive", "gt answer": "left(1.00)<br/>racer(0.60)", "pred answer": "honda", "question_id": 2434435, "best approach": "wiki, concept", "verif answer": "right", "anno approach": "wiki", "verif wiki answer": "racer(0.6706)", "verif concept answer": "racer(0.6993)", "verif image answer": "right(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243443.jpg"}, {"question": "what is the long object that the man is holding used for", "gt answer": "hit baseball(1.00)<br/>bat(0.60)<br/>baseball bat(0.60)", "pred answer": "bat", "question_id": 1492335, "best approach": "wiki, concept, image", "verif answer": "baseball bat", "anno approach": "concept, wiki", "verif wiki answer": "baseball bat(0.7304)", "verif concept answer": "baseball bat(0.7107)", "verif image answer": "baseball bat(0.6583)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149233.jpg"}, {"question": "what vitamins do you get from this food", "gt answer": "c(1.00)<br/>vitamin c(1.00)<br/>d(0.60)", "pred answer": "vitamin c", "question_id": 4398595, "best approach": "wiki, concept", "verif answer": "d", "anno approach": "wiki", "verif wiki answer": "d(0.6386)", "verif concept answer": "d(0.6662)", "verif image answer": "vitamin(0.6403)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439859.jpg"}, {"question": "if this woman is seeking information which famous search engine might she be looking at", "gt answer": "google(1.00)", "pred answer": "apple", "question_id": 5021975, "best approach": "image", "verif answer": "shadow", "anno approach": "image", "verif wiki answer": "central park(0.5208)", "verif concept answer": "shadow(0.5585)", "verif image answer": "google(0.5265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502197.jpg"}, {"question": "is this a meal or snack", "gt answer": "meal(1.00)", "pred answer": "snack", "question_id": 2319965, "best approach": "", "verif answer": "snack", "anno approach": "", "verif wiki answer": "snack(0.7271)", "verif concept answer": "snack(0.7078)", "verif image answer": "snack(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231996.jpg"}, {"question": "where is the fastest one of these in the world", "gt answer": "china(1.00)<br/>japan(0.60)<br/>europe(0.60)<br/>france(0.60)", "pred answer": "train", "question_id": 1279455, "best approach": "wiki, concept, image", "verif answer": "france", "anno approach": "concept, wiki", "verif wiki answer": "france(0.7083)", "verif concept answer": "france(0.6520)", "verif image answer": "france(0.5032)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127945.jpg"}, {"question": "what type of cat is this", "gt answer": "persian(1.00)<br/>tabby(0.60)", "pred answer": "domestic shorthair", "question_id": 2710025, "best approach": "concept, image", "verif answer": "ragdoll", "anno approach": "", "verif wiki answer": "ragdoll(0.6484)", "verif concept answer": "persian(0.6430)", "verif image answer": "persian(0.6461)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000271002.jpg"}, {"question": "is the larger television set in the picture an older or newer model", "gt answer": "older(1.00)", "pred answer": "old", "question_id": 1536205, "best approach": "wiki, image", "verif answer": "younger", "anno approach": "wiki", "verif wiki answer": "older(0.6979)", "verif concept answer": "younger(0.7299)", "verif image answer": "older(0.6409)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153620.jpg"}, {"question": "what method of cooking is used to prepare the filling in this sandwhich", "gt answer": "bbq(0.60)<br/>grill(1.00)<br/>roast(0.60)", "pred answer": "fry", "question_id": 2874005, "best approach": "wiki, concept, image", "verif answer": "grill", "anno approach": "wiki", "verif wiki answer": "grill(0.7308)", "verif concept answer": "grill(0.7270)", "verif image answer": "grill(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287400.jpg"}, {"question": "what does this vehicle usually do", "gt answer": "transport people(1.00)<br/>tour(0.60)<br/>transport(0.60)<br/>ride(0.60)", "pred answer": "tour", "question_id": 1282645, "best approach": "", "verif answer": "passenger", "anno approach": "", "verif wiki answer": "passenger(0.6470)", "verif concept answer": "passenger(0.6578)", "verif image answer": "passenger(0.6557)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128264.jpg"}, {"question": "what do you call the item above the horses head", "gt answer": "saddle(1.00)<br/>wooden(0.60)<br/>bridle(0.60)", "pred answer": "propeller", "question_id": 1550585, "best approach": "wiki, concept, image", "verif answer": "saddle", "anno approach": "concept, wiki", "verif wiki answer": "saddle(0.7215)", "verif concept answer": "saddle(0.7236)", "verif image answer": "saddle(0.6488)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155058.jpg"}, {"question": "what type of hairstyle", "gt answer": "ponytail(1.00)<br/>pony tail(0.60)", "pred answer": "ponytail", "question_id": 1035565, "best approach": "wiki, concept", "verif answer": "ponytail", "anno approach": "wiki", "verif wiki answer": "ponytail(0.6320)", "verif concept answer": "ponytail(0.6403)", "verif image answer": "bun(0.6217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103556.jpg"}, {"question": "what is this lady doing to this kitten", "gt answer": "pet(1.00)", "pred answer": "water", "question_id": 329495, "best approach": "", "verif answer": "wash", "anno approach": "", "verif wiki answer": "feed(0.6346)", "verif concept answer": "feed(0.6236)", "verif image answer": "wash(0.7064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032949.jpg"}, {"question": "how is the cat in this photo keeping cool", "gt answer": "fan(1.00)", "pred answer": "light", "question_id": 3284375, "best approach": "wiki, concept, image", "verif answer": "fan", "anno approach": "image, wiki", "verif wiki answer": "fan(0.5239)", "verif concept answer": "fan(0.5015)", "verif image answer": "fan(0.6882)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328437.jpg"}, {"question": "what type of dog is this", "gt answer": "dalmation(1.00)<br/>dalmatian(0.60)", "pred answer": "collie", "question_id": 1911935, "best approach": "wiki, concept, image", "verif answer": "dalmation", "anno approach": "image", "verif wiki answer": "dalmation(0.6620)", "verif concept answer": "dalmation(0.6596)", "verif image answer": "dalmation(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191193.jpg"}, {"question": "how many calories per piece", "gt answer": "600(1.00)<br/>2000(0.60)<br/>50(0.60)<br/>400(0.60)", "pred answer": "400", "question_id": 5105175, "best approach": "wiki, image", "verif answer": "400", "anno approach": "wiki", "verif wiki answer": "400(0.7209)", "verif concept answer": "500(0.6319)", "verif image answer": "400(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510517.jpg"}, {"question": "what is someone who specializes in this type of tasting called", "gt answer": "sommelier(1.00)<br/>wine taster(0.60)", "pred answer": "wine taster", "question_id": 3314095, "best approach": "wiki, image", "verif answer": "sommelier", "anno approach": "image, wiki", "verif wiki answer": "sommelier(0.6447)", "verif concept answer": "president(0.6487)", "verif image answer": "sommelier(0.6827)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331409.jpg"}, {"question": "what might this citizen be termed", "gt answer": "elderly(1.00)<br/>old(0.60)", "pred answer": "african", "question_id": 2105705, "best approach": "", "verif answer": "floral", "anno approach": "", "verif wiki answer": "floral(0.7208)", "verif concept answer": "floral(0.7278)", "verif image answer": "floral(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210570.jpg"}, {"question": "how many vertebrae does this animal have", "gt answer": "7(1.00)<br/>3(0.60)<br/>100(0.60)", "pred answer": "32", "question_id": 5566225, "best approach": "concept, image", "verif answer": "3", "anno approach": "", "verif wiki answer": "3(0.6501)", "verif concept answer": "7(0.6185)", "verif image answer": "7(0.6464)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556622.jpg"}, {"question": "is it legal or illegal for a car park between the rail and hydrant", "gt answer": "illegal(1.00)", "pred answer": "illegal", "question_id": 5465815, "best approach": "wiki, concept", "verif answer": "illegal", "anno approach": "wiki", "verif wiki answer": "illegal(0.7310)", "verif concept answer": "illegal(0.6855)", "verif image answer": "fire lane(0.7214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546581.jpg"}, {"question": "what is the best kind of sun protection to use for this activity", "gt answer": "sun screen(1.00)<br/>sunscreen(1.00)", "pred answer": "umbrella", "question_id": 5351655, "best approach": "wiki, concept, image", "verif answer": "sunscreen", "anno approach": "wiki", "verif wiki answer": "sunscreen(0.6461)", "verif concept answer": "sunscreen(0.6375)", "verif image answer": "sunscreen(0.6230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535165.jpg"}, {"question": "what type of boat is in the picture", "gt answer": "surf board(1.00)<br/>yacht(0.60)<br/>sailboat(0.60)<br/>surfboard(0.60)", "pred answer": "surfboard", "question_id": 1827285, "best approach": "wiki, concept, image", "verif answer": "surfboard", "anno approach": "concept, wiki", "verif wiki answer": "surfboard(0.6969)", "verif concept answer": "surfboard(0.6402)", "verif image answer": "sailboat(0.5004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182728.jpg"}, {"question": "what is the purpose of the green light", "gt answer": "go(1.00)<br/>move(0.60)", "pred answer": "stop light", "question_id": 322955, "best approach": "concept, image", "verif answer": "move", "anno approach": "concept", "verif wiki answer": "come(0.6570)", "verif concept answer": "move(0.6826)", "verif image answer": "move(0.5970)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032295.jpg"}, {"question": "if the host of this part had it at home what section of the house would they be in", "gt answer": "backyard(1.00)<br/>outdoor(0.60)<br/>kitchen(0.60)", "pred answer": "dine room", "question_id": 1478235, "best approach": "wiki, concept, image", "verif answer": "outdoor", "anno approach": "concept, wiki", "verif wiki answer": "kitchen(0.7139)", "verif concept answer": "outdoor(0.7219)", "verif image answer": "kitchen(0.6221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147823.jpg"}, {"question": "where is this animal most common", "gt answer": "africa(1.00)<br/>india(1.00)", "pred answer": "zoo", "question_id": 2441795, "best approach": "", "verif answer": "hindu", "anno approach": "", "verif wiki answer": "hindu(0.7045)", "verif concept answer": "hindu(0.7256)", "verif image answer": "hindu(0.7222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244179.jpg"}, {"question": "is this a real or a manufactured giraffe", "gt answer": "real(1.00)", "pred answer": "man made", "question_id": 4213895, "best approach": "", "verif answer": "fake", "anno approach": "", "verif wiki answer": "fake(0.7304)", "verif concept answer": "fake(0.7287)", "verif image answer": "photoshopped(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421389.jpg"}, {"question": "why would we suspect this is a store display and not a child 's room", "gt answer": "price(1.00)<br/>price tag(0.60)", "pred answer": "picked up", "question_id": 4783285, "best approach": "wiki, image", "verif answer": "price", "anno approach": "image, wiki", "verif wiki answer": "price(0.5001)", "verif concept answer": "picture(0.5006)", "verif image answer": "price(0.7166)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478328.jpg"}, {"question": "what type of restaurant did the takeout cup come from", "gt answer": "fast food(1.00)", "pred answer": "house", "question_id": 3224025, "best approach": "concept", "verif answer": "chinese", "anno approach": "concept", "verif wiki answer": "chinese(0.6512)", "verif concept answer": "fast food(0.6421)", "verif image answer": "chinese(0.6412)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322402.jpg"}, {"question": "who invested this", "gt answer": "wright brother(1.00)<br/>company(0.60)", "pred answer": "wright brother", "question_id": 2833125, "best approach": "wiki, concept, image", "verif answer": "wright brother", "anno approach": "image, wiki", "verif wiki answer": "wright brother(0.5411)", "verif concept answer": "wright brother(0.5327)", "verif image answer": "wright brother(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283312.jpg"}, {"question": "can you guess clock model shown in this picture", "gt answer": "antique(1.00)", "pred answer": "canon", "question_id": 3755755, "best approach": "image", "verif answer": "wooden", "anno approach": "image", "verif wiki answer": "wooden(0.6492)", "verif concept answer": "wooden(0.5613)", "verif image answer": "antique(0.5645)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375575.jpg"}, {"question": "how many feet deep are these most likely dug", "gt answer": "6(1.00)", "pred answer": "32", "question_id": 1348715, "best approach": "", "verif answer": "5", "anno approach": "", "verif wiki answer": "12(0.7002)", "verif concept answer": "12(0.6241)", "verif image answer": "5(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134871.jpg"}, {"question": "what was the conductors name of this famous kids television show", "gt answer": "thomas(1.00)", "pred answer": "kentucky derby", "question_id": 2467005, "best approach": "", "verif answer": "my little pony", "anno approach": "", "verif wiki answer": "my little pony(0.5018)", "verif concept answer": "my little pony(0.5003)", "verif image answer": "my little pony(0.5386)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246700.jpg"}, {"question": "what material causes those goggles to be reflective", "gt answer": "mirrored(1.00)<br/>plastic(0.60)<br/>wind(0.60)", "pred answer": "plastic", "question_id": 5031505, "best approach": "image", "verif answer": "light", "anno approach": "image", "verif wiki answer": "light(0.5852)", "verif concept answer": "light(0.6016)", "verif image answer": "mirrored(0.5869)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503150.jpg"}, {"question": "what is the name of the object on the man 's wrist that tells the time", "gt answer": "watch(1.00)", "pred answer": "backhand", "question_id": 3830295, "best approach": "", "verif answer": "to tell time", "anno approach": "", "verif wiki answer": "to tell time(0.6460)", "verif concept answer": "to tell time(0.6389)", "verif image answer": "to tell time(0.6386)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383029.jpg"}, {"question": "what shape is on the wall", "gt answer": "star(1.00)", "pred answer": "rectangle", "question_id": 4909935, "best approach": "wiki, concept, image", "verif answer": "star", "anno approach": "wiki", "verif wiki answer": "star(0.7310)", "verif concept answer": "star(0.7304)", "verif image answer": "star(0.6998)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490993.jpg"}, {"question": "what is the best way to clean this", "gt answer": "brush(1.00)<br/>fast(0.60)", "pred answer": "bleach", "question_id": 2036115, "best approach": "", "verif answer": "bleach", "anno approach": "", "verif wiki answer": "bleach(0.6399)", "verif concept answer": "bleach(0.7242)", "verif image answer": "bleach(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203611.jpg"}, {"question": "what type of dog is this", "gt answer": "bulldog(1.00)", "pred answer": "dalmation", "question_id": 1960615, "best approach": "", "verif answer": "pug", "anno approach": "", "verif wiki answer": "saint bernard(0.7306)", "verif concept answer": "saint bernard(0.7307)", "verif image answer": "pug(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196061.jpg"}, {"question": "what is the name of the structure this room is in", "gt answer": "dollhouse(1.00)<br/>house(1.00)", "pred answer": "house", "question_id": 3893365, "best approach": "wiki, image", "verif answer": "house", "anno approach": "wiki", "verif wiki answer": "house(0.6574)", "verif concept answer": "home(0.6467)", "verif image answer": "dollhouse(0.6467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389336.jpg"}, {"question": "what extreme sport is this", "gt answer": "snowboard(1.00)", "pred answer": "ski", "question_id": 1396145, "best approach": "wiki, image", "verif answer": "snowboard", "anno approach": "image, wiki", "verif wiki answer": "snowboard(0.6279)", "verif concept answer": "lift(0.7235)", "verif image answer": "snowboard(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139614.jpg"}, {"question": "what kind of cows are they", "gt answer": "dairy(1.00)<br/>dairy cow(0.60)<br/>holstein(0.60)", "pred answer": "dairy", "question_id": 4171985, "best approach": "wiki", "verif answer": "holstein", "anno approach": "wiki", "verif wiki answer": "dairy(0.6278)", "verif concept answer": "holstein(0.6364)", "verif image answer": "holstein(0.6290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417198.jpg"}, {"question": "", "gt answer": "oakley(0.60)<br/>rayban(0.60)<br/>aspen(0.60)<br/>apollo(0.60)", "pred answer": "burton", "question_id": 3968525, "best approach": "wiki, concept, image", "verif answer": "rayban", "anno approach": "concept, wiki", "verif wiki answer": "rayban(0.6830)", "verif concept answer": "rayban(0.7062)", "verif image answer": "aspen(0.6210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396852.jpg"}, {"question": "why is someone using an umbrella and no rain", "gt answer": "for sun(1.00)", "pred answer": "shade", "question_id": 3548435, "best approach": "", "verif answer": "shade", "anno approach": "", "verif wiki answer": "shade(0.7304)", "verif concept answer": "shade(0.7265)", "verif image answer": "shade(0.6864)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354843.jpg"}, {"question": "what micro nutrients can be found in this dish", "gt answer": "vitamin(1.00)<br/>protein(0.60)", "pred answer": "vitamin", "question_id": 4065435, "best approach": "image", "verif answer": "protein", "anno approach": "image", "verif wiki answer": "protein(0.7279)", "verif concept answer": "protein(0.7126)", "verif image answer": "vitamin(0.7246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000406543.jpg"}, {"question": "what insturments could be used while the man is singing", "gt answer": "guitar(1.00)<br/>microphone(0.60)", "pred answer": "white", "question_id": 4308535, "best approach": "wiki, concept, image", "verif answer": "guitar", "anno approach": "wiki", "verif wiki answer": "guitar(0.7308)", "verif concept answer": "guitar(0.7226)", "verif image answer": "guitar(0.7114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430853.jpg"}, {"question": "how is the drink made", "gt answer": "brew(1.00)<br/>brewed(0.60)", "pred answer": "fried", "question_id": 4162975, "best approach": "concept", "verif answer": "baked", "anno approach": "concept", "verif wiki answer": "baked(0.6599)", "verif concept answer": "brew(0.6238)", "verif image answer": "baked(0.5562)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416297.jpg"}, {"question": "what is that hole in the ground for", "gt answer": "urine(1.00)<br/>toilet(0.60)", "pred answer": "water", "question_id": 2550885, "best approach": "", "verif answer": "urinate", "anno approach": "", "verif wiki answer": "urinate(0.6767)", "verif concept answer": "urinate(0.7116)", "verif image answer": "urinate(0.7046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255088.jpg"}, {"question": "what are these pants referred to as", "gt answer": "overall(1.00)<br/>short(0.60)", "pred answer": "jean", "question_id": 3841605, "best approach": "concept", "verif answer": "cap", "anno approach": "concept", "verif wiki answer": "cap(0.7286)", "verif concept answer": "overall(0.6377)", "verif image answer": "cap(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384160.jpg"}, {"question": "what type plane is this", "gt answer": "747(1.00)<br/>passenger(0.60)<br/>boeing 747(0.60)", "pred answer": "private", "question_id": 2784895, "best approach": "wiki, concept, image", "verif answer": "passenger", "anno approach": "wiki", "verif wiki answer": "passenger(0.6748)", "verif concept answer": "passenger(0.6506)", "verif image answer": "passenger(0.6573)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278489.jpg"}, {"question": "what type of building is this wagon parked outside of", "gt answer": "train station(1.00)<br/>stone(0.60)<br/>concrete(0.60)", "pred answer": "apartment", "question_id": 71395, "best approach": "wiki", "verif answer": "concrete", "anno approach": "wiki", "verif wiki answer": "train station(0.6518)", "verif concept answer": "stone(0.6914)", "verif image answer": "concrete(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007139.jpg"}, {"question": "which brand of shoes are weared by the sports person in this picture", "gt answer": "nike(1.00)<br/>adidas(1.00)", "pred answer": "adidas", "question_id": 2163245, "best approach": "wiki, concept, image", "verif answer": "nike", "anno approach": "image, wiki", "verif wiki answer": "nike(0.5292)", "verif concept answer": "nike(0.5174)", "verif image answer": "nike(0.7165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216324.jpg"}, {"question": "what type of teeth is this child missing", "gt answer": "front(1.00)<br/>baby(0.60)", "pred answer": "mustard", "question_id": 846105, "best approach": "wiki, concept, image", "verif answer": "front", "anno approach": "wiki", "verif wiki answer": "front(0.5001)", "verif concept answer": "front(0.5000)", "verif image answer": "front(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084610.jpg"}, {"question": "what character on the toothbrush", "gt answer": "tigger(1.00)<br/>tiger(1.00)", "pred answer": "mickey mouse", "question_id": 1627805, "best approach": "wiki, concept, image", "verif answer": "tigger", "anno approach": "", "verif wiki answer": "tigger(0.7074)", "verif concept answer": "tigger(0.6880)", "verif image answer": "tigger(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162780.jpg"}, {"question": "what winter activity are these people doing", "gt answer": "ski(1.00)", "pred answer": "ski", "question_id": 820485, "best approach": "", "verif answer": "cross country ski", "anno approach": "", "verif wiki answer": "cross country ski(0.7311)", "verif concept answer": "cross country ski(0.7309)", "verif image answer": "cross country ski(0.7176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082048.jpg"}, {"question": "what part of the horse are the men touching", "gt answer": "mane(1.00)<br/>head(0.60)", "pred answer": "rein", "question_id": 617805, "best approach": "", "verif answer": "short", "anno approach": "", "verif wiki answer": "short(0.5014)", "verif concept answer": "short(0.5067)", "verif image answer": "short(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061780.jpg"}, {"question": "what is the man on", "gt answer": "surfboard(1.00)<br/>paddle board(0.60)", "pred answer": "surf", "question_id": 1490365, "best approach": "wiki, image", "verif answer": "surfboard", "anno approach": "image, wiki", "verif wiki answer": "surfboard(0.6853)", "verif concept answer": "paddle board(0.6937)", "verif image answer": "surfboard(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149036.jpg"}, {"question": "what is the name of a baby that would be made by the animals", "gt answer": "calf(1.00)", "pred answer": "puppy", "question_id": 3787005, "best approach": "wiki, concept", "verif answer": "calf", "anno approach": "wiki", "verif wiki answer": "calf(0.7310)", "verif concept answer": "calf(0.7310)", "verif image answer": "apple(0.6774)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378700.jpg"}, {"question": "what is this device used for", "gt answer": "type(1.00)", "pred answer": "compute", "question_id": 2603995, "best approach": "", "verif answer": "code", "anno approach": "", "verif wiki answer": "code(0.6608)", "verif concept answer": "code(0.6535)", "verif image answer": "code(0.6300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260399.jpg"}, {"question": "the ice skating usedby the boy is of which metal", "gt answer": "aluminum(1.00)<br/>steel(0.60)<br/>ski(0.60)", "pred answer": "aluminum", "question_id": 3301875, "best approach": "wiki, concept, image", "verif answer": "aluminum", "anno approach": "wiki", "verif wiki answer": "aluminum(0.6573)", "verif concept answer": "aluminum(0.6405)", "verif image answer": "aluminum(0.6474)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000330187.jpg"}, {"question": "who prepared this food", "gt answer": "cook(1.00)<br/>restaurant(0.60)<br/>chef(0.60)", "pred answer": "chef", "question_id": 2684065, "best approach": "concept", "verif answer": "cook", "anno approach": "concept", "verif wiki answer": "chef(0.6548)", "verif concept answer": "cook(0.6679)", "verif image answer": "chef(0.6581)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268406.jpg"}, {"question": "what causes the vegetables in the pictures to be green", "gt answer": "chlorophyll(1.00)", "pred answer": "chlorophyll", "question_id": 4169185, "best approach": "concept, image", "verif answer": "chlorophyll", "anno approach": "", "verif wiki answer": "c(0.6408)", "verif concept answer": "chlorophyll(0.6358)", "verif image answer": "chlorophyll(0.6607)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416918.jpg"}, {"question": "what are the hot dogs covered in", "gt answer": "dough(1.00)<br/>pastry(1.00)", "pred answer": "ice", "question_id": 4567195, "best approach": "wiki, concept, image", "verif answer": "dough", "anno approach": "concept, wiki", "verif wiki answer": "dough(0.7310)", "verif concept answer": "dough(0.7302)", "verif image answer": "dough(0.6953)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456719.jpg"}, {"question": "what breed of cows are these", "gt answer": "holstein(1.00)", "pred answer": "dairy", "question_id": 4918505, "best approach": "", "verif answer": "american", "anno approach": "", "verif wiki answer": "dairy(0.6000)", "verif concept answer": "dairy(0.5895)", "verif image answer": "american(0.6367)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491850.jpg"}, {"question": "what language is the text on the bus written in", "gt answer": "english(1.00)", "pred answer": "arabic", "question_id": 4165865, "best approach": "", "verif answer": "arabic", "anno approach": "", "verif wiki answer": "arabic(0.7273)", "verif concept answer": "spanish(0.6630)", "verif image answer": "spanish(0.6263)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416586.jpg"}, {"question": "what type of artist created these works of art", "gt answer": "potter(1.00)<br/>pottery(0.60)", "pred answer": "pottery", "question_id": 4806445, "best approach": "", "verif answer": "glass blower", "anno approach": "", "verif wiki answer": "glass blower(0.7311)", "verif concept answer": "glass blower(0.7311)", "verif image answer": "graffiti(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480644.jpg"}, {"question": "what global issue is the stop sign referring to", "gt answer": "global warm(1.00)<br/>warm(0.60)", "pred answer": "stop", "question_id": 2186475, "best approach": "wiki, concept, image", "verif answer": "warm", "anno approach": "wiki", "verif wiki answer": "warm(0.7060)", "verif concept answer": "warm(0.7159)", "verif image answer": "warm(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218647.jpg"}, {"question": "what powers this model of clock", "gt answer": "battery(1.00)", "pred answer": "electricity", "question_id": 4076935, "best approach": "image", "verif answer": "battery", "anno approach": "image", "verif wiki answer": "electricity(0.6510)", "verif concept answer": "electricity(0.6472)", "verif image answer": "battery(0.6926)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407693.jpg"}, {"question": "what kind of apple is that", "gt answer": "granny smith(1.00)<br/>green(0.60)", "pred answer": "granny smith", "question_id": 618375, "best approach": "wiki, concept", "verif answer": "granny smith", "anno approach": "wiki", "verif wiki answer": "granny smith(0.6332)", "verif concept answer": "granny smith(0.6639)", "verif image answer": "red(0.6172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061837.jpg"}, {"question": "does this bear appear playful or ferocious", "gt answer": "playful(1.00)", "pred answer": "danger", "question_id": 3147105, "best approach": "", "verif answer": "friendly", "anno approach": "", "verif wiki answer": "friendly(0.5003)", "verif concept answer": "friendly(0.5001)", "verif image answer": "friendly(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314710.jpg"}, {"question": "what is the transportation on", "gt answer": "runway(1.00)<br/>tarmac(1.00)<br/>airplane(0.60)", "pred answer": "airport", "question_id": 1735685, "best approach": "", "verif answer": "pavement", "anno approach": "", "verif wiki answer": "pavement(0.7281)", "verif concept answer": "airport(0.6978)", "verif image answer": "airport(0.6696)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000173568.jpg"}, {"question": "why are the buses so close together", "gt answer": "parked(1.00)<br/>park lot(0.60)<br/>storage(0.60)", "pred answer": "transport", "question_id": 2380705, "best approach": "wiki, concept", "verif answer": "parked", "anno approach": "wiki", "verif wiki answer": "parked(0.7251)", "verif concept answer": "parked(0.6535)", "verif image answer": "park lot(0.6560)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238070.jpg"}, {"question": "what do you call these types of ducks", "gt answer": "geese(1.00)<br/>mallard(1.00)", "pred answer": "duck", "question_id": 5657555, "best approach": "", "verif answer": "duck", "anno approach": "", "verif wiki answer": "duck(0.5801)", "verif concept answer": "duck(0.5881)", "verif image answer": "duck(0.6583)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000565755.jpg"}, {"question": "what equipment is the young man utilizing in the ocean", "gt answer": "surf board(1.00)<br/>paddle board(0.60)<br/>board(0.60)<br/>surfboard(0.60)", "pred answer": "surfboard", "question_id": 899155, "best approach": "wiki, concept, image", "verif answer": "surfboard", "anno approach": "image, wiki", "verif wiki answer": "surfboard(0.6521)", "verif concept answer": "surfboard(0.6548)", "verif image answer": "surfboard(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089915.jpg"}, {"question": "is this game being played on natural grass or artificial turf", "gt answer": "natural grass(1.00)<br/>turf(0.60)<br/>natural(0.60)", "pred answer": "manmade", "question_id": 2768545, "best approach": "wiki, concept, image", "verif answer": "turf", "anno approach": "image, concept, wiki", "verif wiki answer": "turf(0.6025)", "verif concept answer": "turf(0.6351)", "verif image answer": "turf(0.6468)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276854.jpg"}, {"question": "how do we know these two aren't opponents", "gt answer": "same side(1.00)", "pred answer": "tennis elbow", "question_id": 3189375, "best approach": "", "verif answer": "serve", "anno approach": "", "verif wiki answer": "serve(0.7310)", "verif concept answer": "serve(0.7158)", "verif image answer": "serve(0.5202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318937.jpg"}, {"question": "what kind of boats are these", "gt answer": "fish(1.00)<br/>fish boat(0.60)", "pred answer": "fish boat", "question_id": 133725, "best approach": "wiki", "verif answer": "tug", "anno approach": "wiki", "verif wiki answer": "fish(0.6456)", "verif concept answer": "tug(0.6516)", "verif image answer": "fish boat(0.5856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013372.jpg"}, {"question": "which utensils did the person use to eat this food", "gt answer": "fork and knife(1.00)<br/>chopstick(0.60)", "pred answer": "fork", "question_id": 4121125, "best approach": "", "verif answer": "fork", "anno approach": "", "verif wiki answer": "fork(0.7216)", "verif concept answer": "fork(0.7309)", "verif image answer": "fork(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412112.jpg"}, {"question": "what kind of oil are doughnuts traditionally fried in", "gt answer": "canola(1.00)<br/>vegetable(0.60)", "pred answer": "lemon", "question_id": 2545565, "best approach": "", "verif answer": "yeast", "anno approach": "", "verif wiki answer": "yeast(0.6484)", "verif concept answer": "yeast(0.6445)", "verif image answer": "yeast(0.6258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000254556.jpg"}, {"question": "what airline is pictured in photo", "gt answer": "eva air(1.00)", "pred answer": "boeing", "question_id": 1007575, "best approach": "", "verif answer": "portland timber", "anno approach": "", "verif wiki answer": "portland timber(0.6480)", "verif concept answer": "polar(0.6089)", "verif image answer": "american airline(0.5071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100757.jpg"}, {"question": "what are those posters of", "gt answer": "movie(1.00)<br/>band(0.60)", "pred answer": "graffiti", "question_id": 4520045, "best approach": "concept", "verif answer": "movie", "anno approach": "concept", "verif wiki answer": "band(0.6814)", "verif concept answer": "movie(0.6816)", "verif image answer": "map(0.6604)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000452004.jpg"}, {"question": "what city and state is this located", "gt answer": "new york new york(1.00)<br/>new york(0.60)", "pred answer": "ohio", "question_id": 3643695, "best approach": "wiki, concept, image", "verif answer": "new york", "anno approach": "image, wiki", "verif wiki answer": "new york(0.6352)", "verif concept answer": "new york(0.6517)", "verif image answer": "new york(0.7053)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364369.jpg"}, {"question": "where are all these boats parked", "gt answer": "marina(1.00)<br/>harbor(0.60)<br/>water(0.60)", "pred answer": "marina", "question_id": 5369295, "best approach": "concept, image", "verif answer": "lake", "anno approach": "", "verif wiki answer": "lake(0.6898)", "verif concept answer": "marina(0.6764)", "verif image answer": "marina(0.6801)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536929.jpg"}, {"question": "what activity are they participating in", "gt answer": "horseback ride(1.00)<br/>run(0.60)<br/>race(0.60)", "pred answer": "horse race", "question_id": 2311945, "best approach": "wiki, concept", "verif answer": "run", "anno approach": "wiki", "verif wiki answer": "run(0.7221)", "verif concept answer": "run(0.6537)", "verif image answer": "equestrian(0.7185)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231194.jpg"}, {"question": "what river is this an image of", "gt answer": "mississippi(1.00)<br/>lazy(0.60)<br/>nile(0.60)<br/>amazon(0.60)", "pred answer": "lake", "question_id": 3003075, "best approach": "", "verif answer": "idaho", "anno approach": "", "verif wiki answer": "idaho(0.5071)", "verif concept answer": "idaho(0.6939)", "verif image answer": "idaho(0.7090)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300307.jpg"}, {"question": "what do these tools help with", "gt answer": "travel(1.00)", "pred answer": "travel", "question_id": 2421455, "best approach": "wiki, concept, image", "verif answer": "travel", "anno approach": "wiki", "verif wiki answer": "travel(0.7309)", "verif concept answer": "travel(0.7309)", "verif image answer": "travel(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000242145.jpg"}, {"question": "what is missing from beneath the mouse", "gt answer": "pad(1.00)<br/>mouse pad(1.00)<br/>mousepad(0.60)", "pred answer": "computer", "question_id": 4669675, "best approach": "", "verif answer": "gun", "anno approach": "", "verif wiki answer": "gun(0.6604)", "verif concept answer": "gun(0.6672)", "verif image answer": "gun(0.5402)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466967.jpg"}, {"question": "what ski resort is this", "gt answer": "aspen(1.00)<br/>vail(0.60)<br/>snowboard(0.60)<br/>colorado(0.60)", "pred answer": "downhill", "question_id": 3447935, "best approach": "wiki, concept, image", "verif answer": "colorado", "anno approach": "image, concept, wiki", "verif wiki answer": "colorado(0.5555)", "verif concept answer": "colorado(0.6965)", "verif image answer": "snowboard(0.6102)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344793.jpg"}, {"question": "what describes that man as a office worker", "gt answer": "suit and tie(1.00)<br/>busy(0.60)<br/>suit(0.60)<br/>tie(0.60)", "pred answer": "tie", "question_id": 5012995, "best approach": "concept", "verif answer": "tie", "anno approach": "concept", "verif wiki answer": "tie(0.5067)", "verif concept answer": "suit and tie(0.5004)", "verif image answer": "tie(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501299.jpg"}, {"question": "how fast does a jet have to go to break the sound barrier", "gt answer": "767 mph(1.00)<br/>1000(0.60)", "pred answer": "fast", "question_id": 694015, "best approach": "wiki, concept", "verif answer": "1000", "anno approach": "", "verif wiki answer": "767 mph(0.6158)", "verif concept answer": "767 mph(0.6043)", "verif image answer": "1000(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069401.jpg"}, {"question": "what material is used to make the vests worn by the people in this photo", "gt answer": "polyester(1.00)<br/>cotton(1.00)", "pred answer": "polyester", "question_id": 277425, "best approach": "wiki, concept", "verif answer": "paper", "anno approach": "wiki", "verif wiki answer": "polyester(0.7257)", "verif concept answer": "polyester(0.7301)", "verif image answer": "paper(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027742.jpg"}, {"question": "what kind of food is in this mans hand", "gt answer": "sandwich(1.00)<br/>cake(0.60)<br/>burger(0.60)", "pred answer": "pizza", "question_id": 2976995, "best approach": "wiki, concept, image", "verif answer": "sandwich", "anno approach": "concept, wiki", "verif wiki answer": "sandwich(0.6486)", "verif concept answer": "sandwich(0.7014)", "verif image answer": "sandwich(0.6405)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297699.jpg"}, {"question": "where is this building", "gt answer": "new york city(1.00)<br/>city(0.60)", "pred answer": "airport", "question_id": 5393715, "best approach": "", "verif answer": "new york", "anno approach": "", "verif wiki answer": "new york(0.5124)", "verif concept answer": "philadelphia(0.5097)", "verif image answer": "new york(0.5994)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539371.jpg"}, {"question": "what are the people wearing on the lower half of their bodies", "gt answer": "short(1.00)", "pred answer": "tank top", "question_id": 5030155, "best approach": "", "verif answer": "skirt", "anno approach": "", "verif wiki answer": "cap(0.5538)", "verif concept answer": "skirt(0.5081)", "verif image answer": "skirt(0.6357)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503015.jpg"}, {"question": "how fast can a baseball be picthed", "gt answer": "100 mph(1.00)<br/>very fast(0.60)", "pred answer": "fast", "question_id": 3394995, "best approach": "", "verif answer": "150", "anno approach": "", "verif wiki answer": "150(0.6491)", "verif concept answer": "150(0.5299)", "verif image answer": "150(0.5434)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000339499.jpg"}, {"question": "what tennis move is being performed in this picture", "gt answer": "serve(1.00)", "pred answer": "backhand", "question_id": 1438115, "best approach": "", "verif answer": "backhand", "anno approach": "", "verif wiki answer": "backhand(0.7244)", "verif concept answer": "backhand(0.7180)", "verif image answer": "backhand(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143811.jpg"}, {"question": "what happened to these scissors", "gt answer": "bent(1.00)<br/>broken(0.60)", "pred answer": "eaten", "question_id": 828605, "best approach": "", "verif answer": "thrown", "anno approach": "", "verif wiki answer": "thrown(0.6377)", "verif concept answer": "thrown(0.6516)", "verif image answer": "thrown(0.6363)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082860.jpg"}, {"question": "what are these kids riding their skateboards through", "gt answer": "puddle(1.00)<br/>park(1.00)", "pred answer": "park", "question_id": 3946915, "best approach": "", "verif answer": "statue", "anno approach": "", "verif wiki answer": "statue(0.7296)", "verif concept answer": "bench(0.6500)", "verif image answer": "skatepark(0.7193)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000394691.jpg"}, {"question": "how was this sidewalk made", "gt answer": "tile(1.00)<br/>concrete(0.60)", "pred answer": "cobblestone", "question_id": 4359085, "best approach": "image", "verif answer": "marble", "anno approach": "image", "verif wiki answer": "marble(0.5595)", "verif concept answer": "marble(0.5801)", "verif image answer": "tile(0.5073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435908.jpg"}, {"question": "who were here but are now gone", "gt answer": "team(1.00)<br/>baseball player(0.60)<br/>player(0.60)", "pred answer": "people", "question_id": 1475685, "best approach": "wiki, concept, image", "verif answer": "baseball player", "anno approach": "concept, wiki", "verif wiki answer": "baseball player(0.5034)", "verif concept answer": "baseball player(0.5383)", "verif image answer": "baseball player(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147568.jpg"}, {"question": "what is the weather", "gt answer": "rainy(1.00)<br/>rain(1.00)", "pred answer": "sunny", "question_id": 4605985, "best approach": "", "verif answer": "sunny", "anno approach": "", "verif wiki answer": "sunny(0.6647)", "verif concept answer": "sunny(0.7024)", "verif image answer": "sunny(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460598.jpg"}, {"question": "what is the man holding the cats relationship status", "gt answer": "married(1.00)<br/>collar(0.60)<br/>owner(0.60)", "pred answer": "friend", "question_id": 4435, "best approach": "wiki, concept, image", "verif answer": "married", "anno approach": "wiki", "verif wiki answer": "married(0.7311)", "verif concept answer": "married(0.7311)", "verif image answer": "married(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000443.jpg"}, {"question": "the knot being tied here is commonly referred to as", "gt answer": "half windsor(1.00)<br/>bow tie(0.60)<br/>windsor(0.60)<br/>marriage(0.60)", "pred answer": "brush", "question_id": 3506445, "best approach": "wiki, concept, image", "verif answer": "windsor", "anno approach": "wiki", "verif wiki answer": "windsor(0.7272)", "verif concept answer": "windsor(0.7297)", "verif image answer": "windsor(0.7241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350644.jpg"}, {"question": "", "gt answer": "$15(0.60)<br/>money(0.60)<br/>15(0.60)", "pred answer": "ticket", "question_id": 1113885, "best approach": "wiki, concept, image", "verif answer": "$15", "anno approach": "", "verif wiki answer": "$15(0.7019)", "verif concept answer": "$15(0.7263)", "verif image answer": "$15(0.7120)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111388.jpg"}, {"question": "what is a famous tournament featuring this sport", "gt answer": "world series(1.00)<br/>major league baseball(0.60)<br/>baseball(0.60)", "pred answer": "world series", "question_id": 2302755, "best approach": "wiki, concept", "verif answer": "world series", "anno approach": "wiki", "verif wiki answer": "world series(0.6307)", "verif concept answer": "world series(0.6396)", "verif image answer": "major league baseball(0.6054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000230275.jpg"}, {"question": "what is the best surface on which to prepare food in this space", "gt answer": "countertop(1.00)<br/>counter(0.60)<br/>island(0.60)<br/>table(0.60)", "pred answer": "board", "question_id": 3853075, "best approach": "wiki, concept", "verif answer": "peninsula", "anno approach": "wiki", "verif wiki answer": "countertop(0.6572)", "verif concept answer": "countertop(0.6362)", "verif image answer": "peninsula(0.6579)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385307.jpg"}, {"question": "what is the specific name of the numbers shown in the picture", "gt answer": "roman numeral(1.00)<br/>numeral(0.60)<br/>hour(0.60)", "pred answer": "roman", "question_id": 5558055, "best approach": "", "verif answer": "roman", "anno approach": "", "verif wiki answer": "roman(0.7308)", "verif concept answer": "roman(0.7304)", "verif image answer": "roman(0.7238)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555805.jpg"}, {"question": "what are these men in the middle of doing", "gt answer": "rugby(1.00)<br/>block(0.60)", "pred answer": "dive", "question_id": 992295, "best approach": "", "verif answer": "soccer", "anno approach": "", "verif wiki answer": "soccer(0.6676)", "verif concept answer": "soccer(0.6978)", "verif image answer": "soccer(0.6498)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099229.jpg"}, {"question": "how old is the baby", "gt answer": "1 year(1.00)<br/>1(0.60)", "pred answer": "6 months", "question_id": 4561615, "best approach": "image", "verif answer": "2", "anno approach": "image", "verif wiki answer": "2(0.7265)", "verif concept answer": "2(0.6728)", "verif image answer": "1(0.7256)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456161.jpg"}, {"question": "what type of pasta noodle is in this image", "gt answer": "penne(1.00)", "pred answer": "lo mein", "question_id": 1775165, "best approach": "", "verif answer": "taxi", "anno approach": "", "verif wiki answer": "taxi(0.6354)", "verif concept answer": "taxi(0.5891)", "verif image answer": "taxi(0.6486)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177516.jpg"}, {"question": "what material are the wheels of this car made from", "gt answer": "rubber(1.00)", "pred answer": "rubber", "question_id": 5592885, "best approach": "", "verif answer": "leather", "anno approach": "", "verif wiki answer": "leather(0.6545)", "verif concept answer": "leather(0.6897)", "verif image answer": "leather(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559288.jpg"}, {"question": "what is the person on", "gt answer": "ski(1.00)<br/>shoulder(0.60)<br/>person(0.60)", "pred answer": "ski", "question_id": 2087235, "best approach": "wiki, concept, image", "verif answer": "ski", "anno approach": "concept, wiki", "verif wiki answer": "ski(0.7310)", "verif concept answer": "ski(0.7177)", "verif image answer": "ski(0.6563)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208723.jpg"}, {"question": "what climate do these environments usually have", "gt answer": "tropical(1.00)", "pred answer": "warm", "question_id": 3116915, "best approach": "", "verif answer": "temperate", "anno approach": "", "verif wiki answer": "grassland(0.6496)", "verif concept answer": "temperate(0.7214)", "verif image answer": "temperate(0.6647)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311691.jpg"}, {"question": "what are the buildings made of", "gt answer": "brick(1.00)", "pred answer": "brick", "question_id": 5251875, "best approach": "", "verif answer": "steel", "anno approach": "", "verif wiki answer": "steel(0.6385)", "verif concept answer": "steel(0.6412)", "verif image answer": "steel(0.6397)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525187.jpg"}, {"question": "what is he dodging", "gt answer": "ball(1.00)<br/>baseball(1.00)", "pred answer": "bat", "question_id": 1125745, "best approach": "wiki, concept, image", "verif answer": "ball", "anno approach": "wiki", "verif wiki answer": "ball(0.6574)", "verif concept answer": "ball(0.6678)", "verif image answer": "ball(0.6620)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000112574.jpg"}, {"question": "what kind of insects do these scooters resemble", "gt answer": "ladybug(1.00)", "pred answer": "bee", "question_id": 3470195, "best approach": "", "verif answer": "dolphin", "anno approach": "", "verif wiki answer": "dolphin(0.5005)", "verif concept answer": "dolphin(0.5006)", "verif image answer": "dolphin(0.5016)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347019.jpg"}, {"question": "does this person have flip flops or high heels with her", "gt answer": "flip flop(1.00)<br/>high heel(0.60)", "pred answer": "bikini", "question_id": 3734155, "best approach": "", "verif answer": "nike", "anno approach": "", "verif wiki answer": "nike(0.5716)", "verif concept answer": "nike(0.5119)", "verif image answer": "sandal(0.5077)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373415.jpg"}, {"question": "how long has toshiba been making laptops like this", "gt answer": "year(1.00)<br/>20 years(0.60)", "pred answer": "5 years", "question_id": 3723815, "best approach": "wiki, concept, image", "verif answer": "20 years", "anno approach": "concept, wiki", "verif wiki answer": "20 years(0.6353)", "verif concept answer": "20 years(0.6433)", "verif image answer": "20 years(0.5897)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372381.jpg"}, {"question": "what type of pepper is in the picture", "gt answer": "jalapeno(1.00)<br/>green(0.60)", "pred answer": "0", "question_id": 5078815, "best approach": "wiki, concept, image", "verif answer": "jalapeno", "anno approach": "image", "verif wiki answer": "jalapeno(0.5872)", "verif concept answer": "jalapeno(0.5677)", "verif image answer": "jalapeno(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507881.jpg"}, {"question": "what is the fence shown in this image called", "gt answer": "bat cage(1.00)<br/>chain link(0.60)", "pred answer": "chain link", "question_id": 613585, "best approach": "wiki", "verif answer": "fence", "anno approach": "wiki", "verif wiki answer": "chain link(0.7158)", "verif concept answer": "fence(0.7299)", "verif image answer": "hit(0.5274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061358.jpg"}, {"question": "what species of bird is this", "gt answer": "hawk(1.00)<br/>falcon(0.60)", "pred answer": "hawk", "question_id": 94745, "best approach": "wiki, concept", "verif answer": "robin", "anno approach": "wiki", "verif wiki answer": "falcon(0.6583)", "verif concept answer": "falcon(0.6877)", "verif image answer": "robin(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009474.jpg"}, {"question": "what is about to happen with these two people", "gt answer": "collision(1.00)<br/>crash(0.60)<br/>fall(0.60)", "pred answer": "catch", "question_id": 1618185, "best approach": "wiki, concept, image", "verif answer": "fall", "anno approach": "wiki", "verif wiki answer": "fall(0.7152)", "verif concept answer": "fall(0.7217)", "verif image answer": "fall(0.7246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161818.jpg"}, {"question": "the open area pictured here is known as what", "gt answer": "courtyard(1.00)<br/>square(1.00)", "pred answer": "court", "question_id": 2576285, "best approach": "concept", "verif answer": "courtyard", "anno approach": "concept", "verif wiki answer": "diamond(0.5041)", "verif concept answer": "courtyard(0.5074)", "verif image answer": "box(0.5011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257628.jpg"}, {"question": "what economic class does the wearer of these glasses belong to", "gt answer": "upper(1.00)", "pred answer": "french", "question_id": 5554705, "best approach": "", "verif answer": "20th", "anno approach": "", "verif wiki answer": "20th(0.6828)", "verif concept answer": "20th(0.7297)", "verif image answer": "20th(0.6503)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555470.jpg"}, {"question": "what type of animal is in the picture", "gt answer": "duck(1.00)<br/>goose(0.60)<br/>swan(0.60)", "pred answer": "duck", "question_id": 2433095, "best approach": "wiki, concept, image", "verif answer": "swan", "anno approach": "image, wiki", "verif wiki answer": "swan(0.6466)", "verif concept answer": "swan(0.6717)", "verif image answer": "swan(0.6796)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243309.jpg"}, {"question": "what is the transportation on", "gt answer": "track(1.00)<br/>rail(0.60)", "pred answer": "track", "question_id": 1192945, "best approach": "wiki, concept, image", "verif answer": "track", "anno approach": "wiki", "verif wiki answer": "track(0.7094)", "verif concept answer": "track(0.6913)", "verif image answer": "track(0.7230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119294.jpg"}, {"question": "what kind of fruits are there", "gt answer": "banana(1.00)", "pred answer": "banana", "question_id": 3026345, "best approach": "concept, image", "verif answer": "banana", "anno approach": "", "verif wiki answer": "apple(0.7203)", "verif concept answer": "banana(0.7234)", "verif image answer": "banana(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302634.jpg"}, {"question": "where can this fruit be found", "gt answer": "tree(1.00)<br/>florida(0.60)", "pred answer": "banana", "question_id": 5313915, "best approach": "concept, image", "verif answer": "tree", "anno approach": "", "verif wiki answer": "orange(0.7007)", "verif concept answer": "tree(0.6817)", "verif image answer": "tree(0.7146)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531391.jpg"}, {"question": "who is most known for doing this act", "gt answer": "tony hawk(1.00)<br/>tony(0.60)<br/>skateboard(0.60)", "pred answer": "tony hawk", "question_id": 5390995, "best approach": "wiki, concept, image", "verif answer": "tony hawk", "anno approach": "wiki", "verif wiki answer": "tony hawk(0.7207)", "verif concept answer": "tony hawk(0.7226)", "verif image answer": "tony hawk(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539099.jpg"}, {"question": "what country is this interior from", "gt answer": "holland(1.00)<br/>russia(0.60)<br/>england(0.60)<br/>france(0.60)", "pred answer": "france", "question_id": 5099335, "best approach": "image", "verif answer": "china", "anno approach": "image", "verif wiki answer": "china(0.6416)", "verif concept answer": "china(0.7164)", "verif image answer": "england(0.6560)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509933.jpg"}, {"question": "what part of the house is through the door", "gt answer": "livingroom(1.00)<br/>dine room(0.60)<br/>kitchen(0.60)<br/>live room(0.60)", "pred answer": "bedroom", "question_id": 5218675, "best approach": "wiki, concept, image", "verif answer": "kitchen", "anno approach": "concept, wiki", "verif wiki answer": "kitchen(0.7310)", "verif concept answer": "kitchen(0.7310)", "verif image answer": "kitchen(0.5704)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521867.jpg"}, {"question": "what country is this", "gt answer": "ireland(1.00)<br/>england(0.60)<br/>scotland(0.60)", "pred answer": "switzerland", "question_id": 4744535, "best approach": "wiki, image", "verif answer": "ireland", "anno approach": "image, wiki", "verif wiki answer": "ireland(0.5131)", "verif concept answer": "switzerland(0.5139)", "verif image answer": "ireland(0.6128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000474453.jpg"}, {"question": "what bird is this", "gt answer": "vulture(1.00)<br/>crow(0.60)", "pred answer": "finch", "question_id": 3879545, "best approach": "wiki, concept, image", "verif answer": "crow", "anno approach": "image, wiki", "verif wiki answer": "crow(0.7310)", "verif concept answer": "crow(0.6628)", "verif image answer": "crow(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387954.jpg"}, {"question": "where can i find a new seat for this", "gt answer": "hardware store(1.00)<br/>store(1.00)<br/>low(0.60)", "pred answer": "sink", "question_id": 963285, "best approach": "wiki, concept, image", "verif answer": "low", "anno approach": "image, wiki", "verif wiki answer": "low(0.5772)", "verif concept answer": "low(0.5338)", "verif image answer": "low(0.6237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096328.jpg"}, {"question": "what important list is this animal known to be on", "gt answer": "endangered(1.00)", "pred answer": "bear", "question_id": 1495835, "best approach": "", "verif answer": "lion", "anno approach": "", "verif wiki answer": "lion(0.6119)", "verif concept answer": "lion(0.5448)", "verif image answer": "lion(0.6161)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149583.jpg"}, {"question": "what are these people inside of", "gt answer": "house(1.00)<br/>room(1.00)", "pred answer": "school", "question_id": 3503135, "best approach": "", "verif answer": "home", "anno approach": "", "verif wiki answer": "hotel(0.7116)", "verif concept answer": "home(0.7222)", "verif image answer": "bedroom(0.7125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350313.jpg"}, {"question": "what type of pattern are the cats on top of", "gt answer": "plaid(1.00)<br/>checkered(0.60)", "pred answer": "floral", "question_id": 5807065, "best approach": "wiki, concept, image", "verif answer": "plaid", "anno approach": "concept, wiki", "verif wiki answer": "plaid(0.7309)", "verif concept answer": "plaid(0.7305)", "verif image answer": "plaid(0.6848)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580706.jpg"}, {"question": "who invented the white obect the man is holding", "gt answer": "walter frederick morrison(1.00)<br/>ben franklin(0.60)", "pred answer": "giant", "question_id": 3794345, "best approach": "", "verif answer": "benjamin franklin", "anno approach": "", "verif wiki answer": "benjamin franklin(0.6246)", "verif concept answer": "benjamin franklin(0.6368)", "verif image answer": "benjamin franklin(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379434.jpg"}, {"question": "which city can i find this storefront", "gt answer": "amsterdam(1.00)<br/>copenhagen(0.60)<br/>new york(0.60)", "pred answer": "new york", "question_id": 1959165, "best approach": "concept", "verif answer": "new york", "anno approach": "concept", "verif wiki answer": "seattle(0.7273)", "verif concept answer": "new york(0.7292)", "verif image answer": "seattle(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195916.jpg"}, {"question": "who is inside of that building", "gt answer": "priest(1.00)", "pred answer": "church", "question_id": 4949405, "best approach": "wiki, concept, image", "verif answer": "priest", "anno approach": "concept, wiki", "verif wiki answer": "priest(0.6719)", "verif concept answer": "priest(0.7224)", "verif image answer": "priest(0.6965)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494940.jpg"}, {"question": "what movie is the elephant from", "gt answer": "dumbo(1.00)", "pred answer": "disney", "question_id": 2475045, "best approach": "wiki, concept", "verif answer": "dumbo", "anno approach": "wiki", "verif wiki answer": "dumbo(0.7111)", "verif concept answer": "dumbo(0.6850)", "verif image answer": "elephant(0.5113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247504.jpg"}, {"question": "which musical genre is often associated with this sport", "gt answer": "rock(1.00)", "pred answer": "skateboard", "question_id": 3387605, "best approach": "", "verif answer": "canvas", "anno approach": "", "verif wiki answer": "concrete(0.5000)", "verif concept answer": "concrete(0.5000)", "verif image answer": "canvas(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338760.jpg"}, {"question": "who is driving the train", "gt answer": "conductor(1.00)", "pred answer": "conductor", "question_id": 424585, "best approach": "wiki, concept, image", "verif answer": "conductor", "anno approach": "concept, wiki", "verif wiki answer": "conductor(0.7311)", "verif concept answer": "conductor(0.7309)", "verif image answer": "conductor(0.6461)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042458.jpg"}, {"question": "what league is this team", "gt answer": "major league(1.00)<br/>baseball(0.60)<br/>mexican(0.60)<br/>mlb(0.60)", "pred answer": "baseball", "question_id": 2296225, "best approach": "wiki, concept", "verif answer": "major league", "anno approach": "wiki", "verif wiki answer": "major league(0.6432)", "verif concept answer": "major league(0.6434)", "verif image answer": "baseball(0.6205)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000229622.jpg"}, {"question": "what character is the man dressed as", "gt answer": "clown(1.00)", "pred answer": "baker", "question_id": 3322275, "best approach": "", "verif answer": "shaun white", "anno approach": "", "verif wiki answer": "shaun white(0.5001)", "verif concept answer": "shaun white(0.5001)", "verif image answer": "shaun white(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332227.jpg"}, {"question": "what type of boat is this called in the water below the plane above", "gt answer": "sailboat(1.00)<br/>sail(0.60)", "pred answer": "sail", "question_id": 2382905, "best approach": "wiki", "verif answer": "canoe", "anno approach": "wiki", "verif wiki answer": "sailboat(0.5006)", "verif concept answer": "canoe(0.5016)", "verif image answer": "canoe(0.5021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238290.jpg"}, {"question": "how does this animal get around", "gt answer": "fly(1.00)<br/>wing(0.60)", "pred answer": "string", "question_id": 3043145, "best approach": "image", "verif answer": "land", "anno approach": "image", "verif wiki answer": "land(0.7222)", "verif concept answer": "land(0.7142)", "verif image answer": "fly(0.6573)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304314.jpg"}, {"question": "what is coming out of the back of this air plane", "gt answer": "smoke(1.00)<br/>contrail(0.60)<br/>gas(0.60)", "pred answer": "air", "question_id": 5340585, "best approach": "wiki", "verif answer": "fire", "anno approach": "wiki", "verif wiki answer": "smoke(0.6457)", "verif concept answer": "fire(0.6553)", "verif image answer": "fire(0.5797)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534058.jpg"}, {"question": "what language is on the sign", "gt answer": "english(1.00)<br/>arabic(0.60)", "pred answer": "english", "question_id": 3616035, "best approach": "wiki, concept", "verif answer": "english", "anno approach": "wiki", "verif wiki answer": "english(0.7311)", "verif concept answer": "english(0.7310)", "verif image answer": "french(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361603.jpg"}, {"question": "which funny performers are found here", "gt answer": "clown(1.00)<br/>circus(0.60)", "pred answer": "elephant", "question_id": 4020415, "best approach": "wiki, image", "verif answer": "clown", "anno approach": "", "verif wiki answer": "clown(0.5383)", "verif concept answer": "dumbo(0.5089)", "verif image answer": "clown(0.5312)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402041.jpg"}, {"question": "what kind of tv remote is that", "gt answer": "universal(1.00)<br/>plastic(0.60)<br/>sky(0.60)", "pred answer": "tv", "question_id": 1284315, "best approach": "wiki, concept, image", "verif answer": "sky", "anno approach": "wiki", "verif wiki answer": "sky(0.5098)", "verif concept answer": "sky(0.5004)", "verif image answer": "sky(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128431.jpg"}, {"question": "what protective equipment should be worn during this activity", "gt answer": "glove(1.00)<br/>helmet(0.60)", "pred answer": "helmet", "question_id": 3689565, "best approach": "wiki, concept, image", "verif answer": "glove", "anno approach": "concept, wiki", "verif wiki answer": "glove(0.6476)", "verif concept answer": "glove(0.6178)", "verif image answer": "glove(0.5098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000368956.jpg"}, {"question": "is this a good example of a sea creature or land creature", "gt answer": "land(1.00)<br/>sea(0.60)<br/>good(0.60)", "pred answer": "prey", "question_id": 2257095, "best approach": "wiki, concept", "verif answer": "land", "anno approach": "wiki", "verif wiki answer": "land(0.6572)", "verif concept answer": "land(0.6356)", "verif image answer": "poor(0.6061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225709.jpg"}, {"question": "what caused the erosion of the ground under the animals", "gt answer": "rain(1.00)<br/>flood(0.60)<br/>walk(0.60)<br/>log(0.60)", "pred answer": "rock", "question_id": 1207345, "best approach": "wiki, concept, image", "verif answer": "walk", "anno approach": "concept, wiki", "verif wiki answer": "walk(0.6422)", "verif concept answer": "walk(0.6345)", "verif image answer": "walk(0.5531)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000120734.jpg"}, {"question": "what is the flavor of the liquid in this jar", "gt answer": "caramel(1.00)<br/>chocolate(1.00)", "pred answer": "sweet", "question_id": 3061135, "best approach": "", "verif answer": "sweet", "anno approach": "", "verif wiki answer": "sweet(0.6969)", "verif concept answer": "sweet(0.7251)", "verif image answer": "sweet(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306113.jpg"}, {"question": "what types of fruits are in the bowl", "gt answer": "apple and orange(1.00)<br/>apple(1.00)", "pred answer": "apple", "question_id": 473885, "best approach": "image", "verif answer": "tomato", "anno approach": "image", "verif wiki answer": "tomato(0.6348)", "verif concept answer": "tomato(0.6622)", "verif image answer": "apple(0.6330)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047388.jpg"}, {"question": "are these wild sheep or are they on a farm", "gt answer": "wild(1.00)<br/>farm(1.00)", "pred answer": "wild", "question_id": 3965505, "best approach": "", "verif answer": "domesticated", "anno approach": "", "verif wiki answer": "field(0.7269)", "verif concept answer": "domesticated(0.7308)", "verif image answer": "domesticated(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396550.jpg"}, {"question": "to what culture does this cuisine belong", "gt answer": "american(1.00)<br/>us(0.60)", "pred answer": "asian", "question_id": 507915, "best approach": "wiki, concept, image", "verif answer": "american", "anno approach": "wiki", "verif wiki answer": "american(0.7077)", "verif concept answer": "american(0.7017)", "verif image answer": "american(0.7184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050791.jpg"}, {"question": "how nutritious is this meal", "gt answer": "very(1.00)<br/>healthy(0.60)<br/>extremely(0.60)", "pred answer": "very", "question_id": 4593105, "best approach": "wiki, image", "verif answer": "healthy", "anno approach": "wiki", "verif wiki answer": "healthy(0.7308)", "verif concept answer": "very healthy(0.7260)", "verif image answer": "extremely(0.6996)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459310.jpg"}, {"question": "what lens is being used here", "gt answer": "wide angle(1.00)", "pred answer": "wide angle", "question_id": 5266635, "best approach": "", "verif answer": "fisheye", "anno approach": "", "verif wiki answer": "fisheye(0.7310)", "verif concept answer": "fisheye(0.7311)", "verif image answer": "fisheye(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526663.jpg"}, {"question": "what airline is that plane from", "gt answer": "southwest(1.00)<br/>delta(0.60)<br/>boeing(0.60)", "pred answer": "united", "question_id": 1671235, "best approach": "wiki, concept, image", "verif answer": "southwest", "anno approach": "concept, wiki", "verif wiki answer": "southwest(0.7311)", "verif concept answer": "southwest(0.7310)", "verif image answer": "southwest(0.6931)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167123.jpg"}, {"question": "which would like this meal a vegan or a vegetarian", "gt answer": "vegetarian(1.00)<br/>vegan(0.60)<br/>both(0.60)", "pred answer": "vegan", "question_id": 2338785, "best approach": "wiki, concept, image", "verif answer": "vegan", "anno approach": "image, wiki", "verif wiki answer": "vegan(0.6784)", "verif concept answer": "vegan(0.6339)", "verif image answer": "vegan(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233878.jpg"}, {"question": "why is the man on a horse", "gt answer": "guard(1.00)<br/>show(0.60)", "pred answer": "rest", "question_id": 3488655, "best approach": "", "verif answer": "herd", "anno approach": "", "verif wiki answer": "herd(0.6479)", "verif concept answer": "herd(0.6996)", "verif image answer": "herd(0.6591)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348865.jpg"}, {"question": "is this item more likely to taste sweet or salty", "gt answer": "sweet(1.00)<br/>salty(0.60)", "pred answer": "sweet", "question_id": 4591525, "best approach": "wiki, concept, image", "verif answer": "sweet", "anno approach": "wiki", "verif wiki answer": "sweet(0.7311)", "verif concept answer": "sweet(0.7311)", "verif image answer": "sweet(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459152.jpg"}, {"question": "what type of fruit is this", "gt answer": "apple(1.00)", "pred answer": "apple", "question_id": 5106805, "best approach": "wiki, concept, image", "verif answer": "apple", "anno approach": "wiki", "verif wiki answer": "apple(0.7095)", "verif concept answer": "apple(0.7061)", "verif image answer": "apple(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510680.jpg"}, {"question": "why do cats perform this action on themselves", "gt answer": "clean(1.00)", "pred answer": "lick", "question_id": 123155, "best approach": "", "verif answer": "", "anno approach": "", "verif wiki answer": "(0.5022)", "verif concept answer": "messy(0.5015)", "verif image answer": "(0.5323)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012315.jpg"}, {"question": "what is the man swinging at", "gt answer": "ball(1.00)<br/>tennis ball(1.00)", "pred answer": "tennis ball", "question_id": 3676055, "best approach": "wiki, concept, image", "verif answer": "tennis ball", "anno approach": "wiki", "verif wiki answer": "tennis ball(0.7304)", "verif concept answer": "tennis ball(0.7309)", "verif image answer": "tennis ball(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367605.jpg"}, {"question": "what type of beer is this", "gt answer": "ale(1.00)<br/>budweiser(0.60)", "pred answer": "budweiser", "question_id": 5217295, "best approach": "", "verif answer": "draft", "anno approach": "", "verif wiki answer": "draft(0.6592)", "verif concept answer": "draft(0.6676)", "verif image answer": "draft(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521729.jpg"}, {"question": "is this a city bus or a tour bus", "gt answer": "tour bus(1.00)<br/>tour(1.00)", "pred answer": "public", "question_id": 4968915, "best approach": "wiki, image", "verif answer": "tour", "anno approach": "wiki", "verif wiki answer": "tour(0.7218)", "verif concept answer": "double decker(0.7144)", "verif image answer": "tour(0.6356)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496891.jpg"}, {"question": "who is on the computer screen", "gt answer": "newscaster(1.00)<br/>man(0.60)", "pred answer": "people", "question_id": 76035, "best approach": "", "verif answer": "person", "anno approach": "", "verif wiki answer": "person(0.7087)", "verif concept answer": "person(0.7295)", "verif image answer": "person(0.7160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007603.jpg"}, {"question": "what part of the world do these bears live", "gt answer": "alaska(1.00)<br/>north america(0.60)<br/>americas(0.60)<br/>america(0.60)", "pred answer": "lake", "question_id": 4660245, "best approach": "concept, image", "verif answer": "north america", "anno approach": "image", "verif wiki answer": "usa(0.6705)", "verif concept answer": "americas(0.6514)", "verif image answer": "north america(0.6898)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466024.jpg"}, {"question": "what might make this animal 's hide a coveted prize", "gt answer": "design(1.00)<br/>fly(0.60)<br/>stripe(0.60)", "pred answer": "protection", "question_id": 155955, "best approach": "wiki, concept, image", "verif answer": "design", "anno approach": "concept, wiki", "verif wiki answer": "design(0.7225)", "verif concept answer": "design(0.6803)", "verif image answer": "design(0.6202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015595.jpg"}, {"question": "what are the horses wearing", "gt answer": "blanket(1.00)", "pred answer": "cotton", "question_id": 1637165, "best approach": "", "verif answer": "quilt", "anno approach": "", "verif wiki answer": "quilt(0.7269)", "verif concept answer": "coat(0.6357)", "verif image answer": "coat(0.6987)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163716.jpg"}, {"question": "what position does she play", "gt answer": "goalie(1.00)", "pred answer": "goalie", "question_id": 648275, "best approach": "wiki, concept, image", "verif answer": "goalie", "anno approach": "wiki", "verif wiki answer": "goalie(0.7310)", "verif concept answer": "goalie(0.7310)", "verif image answer": "goalie(0.7142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064827.jpg"}, {"question": "which of these objects contains freon", "gt answer": "refridgerator(1.00)<br/>refrigerator(1.00)<br/>fridge(0.60)", "pred answer": "right", "question_id": 3882145, "best approach": "wiki, concept, image", "verif answer": "refridgerator", "anno approach": "concept, wiki", "verif wiki answer": "refridgerator(0.7125)", "verif concept answer": "refridgerator(0.6956)", "verif image answer": "refridgerator(0.6349)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388214.jpg"}, {"question": "what style of jet is this", "gt answer": "fighter(1.00)", "pred answer": "jet", "question_id": 5814995, "best approach": "concept", "verif answer": "fighter", "anno approach": "concept", "verif wiki answer": "air(0.6560)", "verif concept answer": "fighter(0.7165)", "verif image answer": "military(0.6325)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000581499.jpg"}, {"question": "what kind of trip would this meal be eaten during", "gt answer": "camp(1.00)", "pred answer": "lunch", "question_id": 3271785, "best approach": "", "verif answer": "hike", "anno approach": "", "verif wiki answer": "hike(0.7309)", "verif concept answer": "hike(0.5999)", "verif image answer": "hike(0.6644)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327178.jpg"}, {"question": "where is this person going", "gt answer": "vacation(1.00)<br/>airport(0.60)", "pred answer": "travel", "question_id": 3951705, "best approach": "wiki, concept, image", "verif answer": "airport", "anno approach": "concept, wiki", "verif wiki answer": "airport(0.6629)", "verif concept answer": "airport(0.6499)", "verif image answer": "airport(0.5856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395170.jpg"}, {"question": "what type of wood is the table made from", "gt answer": "oak(1.00)<br/>maple(0.60)", "pred answer": "oak", "question_id": 3593575, "best approach": "wiki, concept, image", "verif answer": "oak", "anno approach": "wiki", "verif wiki answer": "oak(0.7226)", "verif concept answer": "oak(0.7267)", "verif image answer": "oak(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359357.jpg"}, {"question": "the bird shown is the state bird of which state", "gt answer": "washington(1.00)<br/>pennsylvania(0.60)<br/>0(0.60)", "pred answer": "florida", "question_id": 5298665, "best approach": "wiki, image", "verif answer": "pennsylvania", "anno approach": "wiki", "verif wiki answer": "washington(0.6435)", "verif concept answer": "pennsylvania(0.7235)", "verif image answer": "washington(0.6259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529866.jpg"}, {"question": "what device shown is used to do an ollie", "gt answer": "skateboard(1.00)", "pred answer": "skateboard", "question_id": 5350425, "best approach": "wiki, image", "verif answer": "skateboard", "anno approach": "wiki", "verif wiki answer": "skateboard(0.6846)", "verif concept answer": "skate(0.6664)", "verif image answer": "skateboard(0.6734)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535042.jpg"}, {"question": "what shape would you call this plate", "gt answer": "square(1.00)<br/>diamond(0.60)", "pred answer": "round", "question_id": 428685, "best approach": "wiki, concept", "verif answer": "diamond", "anno approach": "wiki", "verif wiki answer": "diamond(0.6823)", "verif concept answer": "diamond(0.6453)", "verif image answer": "box(0.6562)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042868.jpg"}, {"question": "what is the line of snow coming off behind the snowboard called", "gt answer": "wake(1.00)<br/>trail(0.60)<br/>spray(0.60)", "pred answer": "center", "question_id": 3323225, "best approach": "wiki, concept, image", "verif answer": "wake", "anno approach": "concept, wiki", "verif wiki answer": "wake(0.7291)", "verif concept answer": "wake(0.7184)", "verif image answer": "wake(0.6801)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332322.jpg"}, {"question": "what brand is the hairdryer", "gt answer": "conair(1.00)<br/>brand(0.60)", "pred answer": "nike", "question_id": 3486975, "best approach": "", "verif answer": "new balance", "anno approach": "", "verif wiki answer": "new balance(0.6483)", "verif concept answer": "new balance(0.6497)", "verif image answer": "new balance(0.6668)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348697.jpg"}, {"question": "what kind of structure are the cats on", "gt answer": "ladder(1.00)", "pred answer": "table", "question_id": 531135, "best approach": "", "verif answer": "rope", "anno approach": "", "verif wiki answer": "rope(0.5448)", "verif concept answer": "rope(0.5711)", "verif image answer": "rope(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053113.jpg"}, {"question": "what type of animal is on this windowsill", "gt answer": "bird(1.00)<br/>pigeon(0.60)", "pred answer": "bird", "question_id": 787975, "best approach": "wiki", "verif answer": "bird", "anno approach": "wiki", "verif wiki answer": "bird(0.7080)", "verif concept answer": "monkey(0.6734)", "verif image answer": "kite(0.6648)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078797.jpg"}, {"question": "what do these animals usually build", "gt answer": "nest(1.00)", "pred answer": "nest", "question_id": 3374335, "best approach": "wiki, concept, image", "verif answer": "nest", "anno approach": "wiki", "verif wiki answer": "nest(0.7311)", "verif concept answer": "nest(0.7310)", "verif image answer": "nest(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337433.jpg"}, {"question": "what are some popular toppings for hot dogs", "gt answer": "ketchup(1.00)<br/>onion(0.60)<br/>mustard and ketchup(0.60)", "pred answer": "ketchup", "question_id": 2029185, "best approach": "wiki, concept, image", "verif answer": "ketchup", "anno approach": "concept, wiki", "verif wiki answer": "ketchup(0.6384)", "verif concept answer": "ketchup(0.5911)", "verif image answer": "ketchup(0.5080)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202918.jpg"}, {"question": "what kind of bike is this", "gt answer": "motorbike(1.00)<br/>motorcycle(1.00)", "pred answer": "motorcycle", "question_id": 5751765, "best approach": "wiki, concept, image", "verif answer": "motorbike", "anno approach": "wiki", "verif wiki answer": "motorbike(0.6582)", "verif concept answer": "motorbike(0.6480)", "verif image answer": "motorbike(0.6489)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575176.jpg"}, {"question": "what is in the background above the skyline", "gt answer": "cloud(0.60)<br/>kite(1.00)<br/>city(0.60)<br/>build(0.60)", "pred answer": "sky", "question_id": 970785, "best approach": "wiki, concept, image", "verif answer": "cloud", "anno approach": "wiki", "verif wiki answer": "cloud(0.7311)", "verif concept answer": "city(0.7310)", "verif image answer": "city(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097078.jpg"}, {"question": "what is the name of the airline for this plane", "gt answer": "sunexpress(1.00)", "pred answer": "airbus", "question_id": 3671115, "best approach": "", "verif answer": "manual", "anno approach": "", "verif wiki answer": "manual(0.5003)", "verif concept answer": "manual(0.5027)", "verif image answer": "manual(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367111.jpg"}, {"question": "what can you do to the square screen", "gt answer": "watch(1.00)", "pred answer": "video game", "question_id": 2782305, "best approach": "", "verif answer": "help ship", "anno approach": "", "verif wiki answer": "help ship(0.6977)", "verif concept answer": "help ship(0.7211)", "verif image answer": "help ship(0.5963)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278230.jpg"}, {"question": "what type of body of water is this", "gt answer": "canal(1.00)<br/>lake(1.00)", "pred answer": "lake", "question_id": 433475, "best approach": "image", "verif answer": "lake", "anno approach": "image", "verif wiki answer": "river(0.5937)", "verif concept answer": "river(0.7276)", "verif image answer": "lake(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043347.jpg"}, {"question": "what animal is pictured", "gt answer": "dog(1.00)<br/>chihuahua(0.60)", "pred answer": "dog", "question_id": 4648715, "best approach": "wiki, concept", "verif answer": "dog", "anno approach": "wiki", "verif wiki answer": "dog(0.7262)", "verif concept answer": "dog(0.6829)", "verif image answer": "cat(0.5590)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464871.jpg"}, {"question": "what hardware is this", "gt answer": "mouse(1.00)", "pred answer": "keyboard", "question_id": 2467945, "best approach": "", "verif answer": "keyboard", "anno approach": "", "verif wiki answer": "rat(0.6936)", "verif concept answer": "keyboard(0.7223)", "verif image answer": "rat(0.7090)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246794.jpg"}, {"question": "what is the life span of that animal", "gt answer": "10 years(1.00)<br/>15 years(0.60)<br/>15(0.60)<br/>12 years(0.60)", "pred answer": "10 years", "question_id": 2279475, "best approach": "wiki, concept, image", "verif answer": "10 years", "anno approach": "wiki", "verif wiki answer": "10 years(0.6590)", "verif concept answer": "10 years(0.6670)", "verif image answer": "10 years(0.6422)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000227947.jpg"}, {"question": "why are there umbrellas in this kitchen", "gt answer": "photography(1.00)<br/>take picture(0.60)", "pred answer": "shade", "question_id": 885385, "best approach": "", "verif answer": "wax", "anno approach": "", "verif wiki answer": "wax(0.7301)", "verif concept answer": "wax(0.7306)", "verif image answer": "wax(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088538.jpg"}, {"question": "how many years does a cat live", "gt answer": "14(1.00)<br/>7(0.60)<br/>20 years(0.60)", "pred answer": "5", "question_id": 5054025, "best approach": "wiki, concept, image", "verif answer": "20 years", "anno approach": "wiki", "verif wiki answer": "20 years(0.6410)", "verif concept answer": "20 years(0.6412)", "verif image answer": "7(0.6222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505402.jpg"}, {"question": "what is the main ingredient in this food", "gt answer": "flour(1.00)<br/>yeast(0.60)", "pred answer": "flour", "question_id": 2480025, "best approach": "wiki, concept", "verif answer": "dough", "anno approach": "wiki", "verif wiki answer": "yeast(0.6797)", "verif concept answer": "yeast(0.6627)", "verif image answer": "dough(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248002.jpg"}, {"question": "why do people not ride this type of animal", "gt answer": "wild(1.00)", "pred answer": "wild", "question_id": 4270135, "best approach": "", "verif answer": "danger", "anno approach": "", "verif wiki answer": "danger(0.6970)", "verif concept answer": "danger(0.6768)", "verif image answer": "danger(0.6608)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427013.jpg"}, {"question": "who is the sponsor", "gt answer": "polo(1.00)", "pred answer": "wilson", "question_id": 1005165, "best approach": "wiki", "verif answer": "columbia", "anno approach": "wiki", "verif wiki answer": "polo(0.5005)", "verif concept answer": "columbia(0.5007)", "verif image answer": "columbia(0.5049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100516.jpg"}, {"question": "what do you have to give in exchange for the items displayed here", "gt answer": "money(1.00)<br/>nothing(0.60)<br/>surf board(0.60)", "pred answer": "smoothies", "question_id": 1456905, "best approach": "wiki, concept, image", "verif answer": "surf board", "anno approach": "concept, wiki", "verif wiki answer": "surf board(0.6398)", "verif concept answer": "surf board(0.6496)", "verif image answer": "surf board(0.6089)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145690.jpg"}, {"question": "this animal stays with its babies for how long until they are on their own", "gt answer": "1 year(1.00)<br/>10 months(0.60)", "pred answer": "20 years", "question_id": 733875, "best approach": "", "verif answer": "5 years", "anno approach": "", "verif wiki answer": "5 years(0.6346)", "verif concept answer": "5 years(0.6385)", "verif image answer": "5 years(0.6723)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073387.jpg"}, {"question": "what sport is being advertised on this bench", "gt answer": "bowl(1.00)", "pred answer": "soccer", "question_id": 3011215, "best approach": "", "verif answer": "wii", "anno approach": "", "verif wiki answer": "wii(0.6189)", "verif concept answer": "wii(0.5495)", "verif image answer": "wii(0.5043)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301121.jpg"}, {"question": "what is a baby of this animal called", "gt answer": "kitten(1.00)", "pred answer": "puppy", "question_id": 5537195, "best approach": "", "verif answer": "regular", "anno approach": "", "verif wiki answer": "regular(0.7289)", "verif concept answer": "regular(0.7282)", "verif image answer": "regular(0.6355)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553719.jpg"}, {"question": "what player is ranked highest in this sport", "gt answer": "mike trout(1.00)<br/>pitcher(0.60)", "pred answer": "babe ruth", "question_id": 1721975, "best approach": "", "verif answer": "babe ruth", "anno approach": "", "verif wiki answer": "babe ruth(0.7294)", "verif concept answer": "babe ruth(0.7282)", "verif image answer": "batter(0.7219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000172197.jpg"}, {"question": "what is the medical term for the part of the body that is sticking out of this woman 's mouth", "gt answer": "tongue(1.00)", "pred answer": "muscle", "question_id": 3775785, "best approach": "concept, image", "verif answer": "mouth", "anno approach": "", "verif wiki answer": "mouth(0.5000)", "verif concept answer": "tongue(0.5000)", "verif image answer": "tongue(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377578.jpg"}, {"question": "what 's the name of that type of shirt", "gt answer": "tank top(1.00)<br/>t shirt(0.60)<br/>shirt(0.60)", "pred answer": "tank top", "question_id": 1213665, "best approach": "wiki, concept, image", "verif answer": "tank top", "anno approach": "concept, wiki", "verif wiki answer": "tank top(0.7310)", "verif concept answer": "tank top(0.7234)", "verif image answer": "tank top(0.5035)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000121366.jpg"}, {"question": "what 's a land vehicle form a cartoon names thomas", "gt answer": "train(1.00)<br/>thomas train(0.60)", "pred answer": "bus", "question_id": 4810915, "best approach": "image", "verif answer": "train", "anno approach": "image", "verif wiki answer": "transport(0.5000)", "verif concept answer": "transport(0.5000)", "verif image answer": "train(0.5075)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481091.jpg"}, {"question": "what commonly happens in this room", "gt answer": "shower(1.00)<br/>bath(0.60)", "pred answer": "poop", "question_id": 4794175, "best approach": "", "verif answer": "water", "anno approach": "", "verif wiki answer": "water(0.5569)", "verif concept answer": "water(0.6385)", "verif image answer": "water(0.6529)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479417.jpg"}, {"question": "where is this", "gt answer": "saudi arabia(1.00)<br/>desert(0.60)<br/>dubai(0.60)<br/>beach(0.60)", "pred answer": "city", "question_id": 1967235, "best approach": "wiki, concept, image", "verif answer": "desert", "anno approach": "image, concept, wiki", "verif wiki answer": "beach(0.6376)", "verif concept answer": "beach(0.7086)", "verif image answer": "desert(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196723.jpg"}, {"question": "is she a mother or coach", "gt answer": "mother(1.00)<br/>coach(1.00)", "pred answer": "both", "question_id": 1020245, "best approach": "image", "verif answer": "right", "anno approach": "image", "verif wiki answer": "right(0.5380)", "verif concept answer": "right(0.5209)", "verif image answer": "coach(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000102024.jpg"}, {"question": "why are there so many dogs in one place", "gt answer": "dog walker(1.00)<br/>stray(0.60)", "pred answer": "party", "question_id": 5441175, "best approach": "wiki, concept, image", "verif answer": "stray", "anno approach": "image, wiki", "verif wiki answer": "stray(0.6806)", "verif concept answer": "stray(0.6595)", "verif image answer": "stray(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544117.jpg"}, {"question": "what are the two people doing", "gt answer": "fly kite(1.00)<br/>kite fly(0.60)", "pred answer": "fly kite", "question_id": 5187745, "best approach": "", "verif answer": "frisbee", "anno approach": "", "verif wiki answer": "parasailing(0.7256)", "verif concept answer": "frisbee(0.7299)", "verif image answer": "frisbee(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518774.jpg"}, {"question": "what can this animal do in this place", "gt answer": "swim(1.00)<br/>float(0.60)<br/>fly(0.60)", "pred answer": "fish", "question_id": 3097215, "best approach": "wiki, concept", "verif answer": "surf", "anno approach": "concept, wiki", "verif wiki answer": "fly(0.6069)", "verif concept answer": "fly(0.6514)", "verif image answer": "surf(0.6529)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000309721.jpg"}, {"question": "what loony tune character is in this photo", "gt answer": "tweety(1.00)", "pred answer": "apple", "question_id": 4618785, "best approach": "wiki, concept, image", "verif answer": "tweety", "anno approach": "wiki", "verif wiki answer": "tweety(0.7299)", "verif concept answer": "tweety(0.7309)", "verif image answer": "tweety(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461878.jpg"}, {"question": "what nutrient is received when the food depicted is eaten", "gt answer": "calcium(1.00)<br/>protein(0.60)<br/>carbohydrate(0.60)", "pred answer": "calcium", "question_id": 2677195, "best approach": "wiki, concept", "verif answer": "calcium", "anno approach": "wiki", "verif wiki answer": "calcium(0.6660)", "verif concept answer": "calcium(0.6465)", "verif image answer": "fiber(0.6295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000267719.jpg"}, {"question": "what positons do these baseball players play", "gt answer": "outfield(1.00)<br/>batter(0.60)", "pred answer": "yankees", "question_id": 2996795, "best approach": "image", "verif answer": "batter", "anno approach": "image", "verif wiki answer": "baseball(0.6429)", "verif concept answer": "baseball(0.6403)", "verif image answer": "batter(0.6481)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000299679.jpg"}, {"question": "is this a photo shopped image or a real thing", "gt answer": "real(1.00)<br/>photoshopped(0.60)", "pred answer": "manmade", "question_id": 1239495, "best approach": "wiki, concept, image", "verif answer": "real", "anno approach": "wiki", "verif wiki answer": "real(0.7117)", "verif concept answer": "real(0.7243)", "verif image answer": "real(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123949.jpg"}, {"question": "what does the sign in the reflection say", "gt answer": "1 way(1.00)", "pred answer": "no park", "question_id": 1671185, "best approach": "concept, image", "verif answer": "shop", "anno approach": "", "verif wiki answer": "shop(0.6385)", "verif concept answer": "1 way(0.5762)", "verif image answer": "1 way(0.5685)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167118.jpg"}, {"question": "what region of the world can these animals be found", "gt answer": "arctic(1.00)<br/>norway(0.60)<br/>alaska(0.60)", "pred answer": "africa", "question_id": 3017475, "best approach": "concept, image", "verif answer": "alaska", "anno approach": "image", "verif wiki answer": "cold(0.6420)", "verif concept answer": "norway(0.6398)", "verif image answer": "alaska(0.7246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301747.jpg"}, {"question": "what material are her pants made of", "gt answer": "denim(1.00)<br/>jean(0.60)", "pred answer": "denim", "question_id": 3941515, "best approach": "wiki, image", "verif answer": "denim", "anno approach": "wiki", "verif wiki answer": "denim(0.7053)", "verif concept answer": "polyester(0.6636)", "verif image answer": "denim(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000394151.jpg"}, {"question": "who manufactures this truck", "gt answer": "toyota(1.00)", "pred answer": "ford", "question_id": 3249015, "best approach": "", "verif answer": "lexus", "anno approach": "", "verif wiki answer": "ford(0.7298)", "verif concept answer": "lexus(0.7291)", "verif image answer": "lexus(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324901.jpg"}, {"question": "what ingredient in this tooth paste negatively effects memory", "gt answer": "flouride(1.00)", "pred answer": "bleach", "question_id": 3752085, "best approach": "", "verif answer": "straw", "anno approach": "", "verif wiki answer": "straw(0.5000)", "verif concept answer": "straw(0.5000)", "verif image answer": "straw(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375208.jpg"}, {"question": "what are the people doing", "gt answer": "cycling(1.00)<br/>stand(0.60)", "pred answer": "bike", "question_id": 2767215, "best approach": "", "verif answer": "ride", "anno approach": "", "verif wiki answer": "ride(0.6530)", "verif concept answer": "ride(0.6451)", "verif image answer": "ride(0.6525)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276721.jpg"}, {"question": "the dog is cuddling with what kind of animal", "gt answer": "stuffed(1.00)<br/>tiger(0.60)", "pred answer": "dog", "question_id": 405805, "best approach": "wiki, concept, image", "verif answer": "stuffed", "anno approach": "image", "verif wiki answer": "stuffed(0.5418)", "verif concept answer": "stuffed(0.5389)", "verif image answer": "stuffed(0.6779)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040580.jpg"}, {"question": "what is the dog in this image doing", "gt answer": "read(1.00)", "pred answer": "play", "question_id": 4602875, "best approach": "image", "verif answer": "eat", "anno approach": "image", "verif wiki answer": "eat(0.6881)", "verif concept answer": "eat(0.7286)", "verif image answer": "read(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460287.jpg"}, {"question": "what is the side of this meal", "gt answer": "french fry(1.00)<br/>fry(0.60)", "pred answer": "hotdog", "question_id": 3016145, "best approach": "", "verif answer": "hot dog", "anno approach": "", "verif wiki answer": "hot dog(0.7283)", "verif concept answer": "hot dog(0.7214)", "verif image answer": "hot dog(0.6790)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301614.jpg"}, {"question": "how do the subjects pictured move from one place to another", "gt answer": "swim(1.00)<br/>fly(0.60)", "pred answer": "float", "question_id": 2017225, "best approach": "wiki, image", "verif answer": "float", "anno approach": "wiki", "verif wiki answer": "swim(0.6520)", "verif concept answer": "float(0.7162)", "verif image answer": "swim(0.6534)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201722.jpg"}, {"question": "what is the choking hazard in the image", "gt answer": "orange(1.00)<br/>seed(0.60)", "pred answer": "fall", "question_id": 2826925, "best approach": "", "verif answer": "orange tree", "anno approach": "", "verif wiki answer": "orange tree(0.6874)", "verif concept answer": "orange tree(0.6758)", "verif image answer": "vitamin c(0.5335)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282692.jpg"}, {"question": "what is the main attraction presented in this picture", "gt answer": "lincoln park zoo(1.00)<br/>zoo(1.00)", "pred answer": "elephant", "question_id": 1529135, "best approach": "", "verif answer": "pen", "anno approach": "", "verif wiki answer": "pen(0.6443)", "verif concept answer": "plain(0.5979)", "verif image answer": "african(0.6167)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000152913.jpg"}, {"question": "what kind of building", "gt answer": "train station(1.00)", "pred answer": "station", "question_id": 2299495, "best approach": "wiki", "verif answer": "india", "anno approach": "wiki", "verif wiki answer": "train station(0.6852)", "verif concept answer": "india(0.6922)", "verif image answer": "india(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000229949.jpg"}, {"question": "what kind of artisan makes objects like the two seen on the right side of this table", "gt answer": "glass blower(1.00)<br/>pottery(0.60)", "pred answer": "book", "question_id": 2088155, "best approach": "wiki, concept, image", "verif answer": "glass blower", "anno approach": "", "verif wiki answer": "glass blower(0.6496)", "verif concept answer": "glass blower(0.6446)", "verif image answer": "glass blower(0.6363)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208815.jpg"}, {"question": "what group of people are known for making quilts", "gt answer": "amish(1.00)", "pred answer": "home", "question_id": 1105365, "best approach": "", "verif answer": "store", "anno approach": "", "verif wiki answer": "public(0.6202)", "verif concept answer": "public(0.5975)", "verif image answer": "store(0.6357)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000110536.jpg"}, {"question": "what brand is being advertised", "gt answer": "pepsi(1.00)", "pred answer": "coca cola", "question_id": 5576595, "best approach": "", "verif answer": "adidas", "anno approach": "", "verif wiki answer": "adidas(0.7193)", "verif concept answer": "adidas(0.7259)", "verif image answer": "coca cola(0.7076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557659.jpg"}, {"question": "how can you learn that sport", "gt answer": "practice(1.00)", "pred answer": "ski", "question_id": 1606245, "best approach": "wiki, concept, image", "verif answer": "practice", "anno approach": "concept, wiki", "verif wiki answer": "practice(0.6346)", "verif concept answer": "practice(0.6400)", "verif image answer": "practice(0.5611)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160624.jpg"}, {"question": "what type of fruit is the orange balls in the back", "gt answer": "orange(1.00)", "pred answer": "banana", "question_id": 3967035, "best approach": "", "verif answer": "tangerine", "anno approach": "", "verif wiki answer": "tangerine(0.7185)", "verif concept answer": "tangerine(0.7229)", "verif image answer": "tangerine(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396703.jpg"}, {"question": "what is this used for in a bathroom", "gt answer": "wash hand(1.00)<br/>clean(0.60)<br/>wash(1.00)", "pred answer": "wash hand", "question_id": 5522975, "best approach": "concept", "verif answer": "wash", "anno approach": "concept", "verif wiki answer": "messy(0.6484)", "verif concept answer": "wash(0.6610)", "verif image answer": "shower(0.6441)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552297.jpg"}, {"question": "what company manufactures the devices these people are holding", "gt answer": "nintendo(1.00)<br/>wii(1.00)", "pred answer": "nike", "question_id": 1039325, "best approach": "wiki, concept, image", "verif answer": "nintendo", "anno approach": "wiki", "verif wiki answer": "nintendo(0.7309)", "verif concept answer": "nintendo(0.7308)", "verif image answer": "nintendo(0.7165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103932.jpg"}, {"question": "where are the land formations in the background usually found", "gt answer": "mountain(1.00)<br/>country(0.60)<br/>north america(0.60)", "pred answer": "island", "question_id": 2352175, "best approach": "wiki, concept, image", "verif answer": "mountain", "anno approach": "wiki", "verif wiki answer": "mountain(0.7284)", "verif concept answer": "mountain(0.6983)", "verif image answer": "mountain(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000235217.jpg"}, {"question": "what kind of flowers are these", "gt answer": "lilac(1.00)<br/>daisy(0.60)", "pred answer": "tulip", "question_id": 3119885, "best approach": "image", "verif answer": "tulip", "anno approach": "image", "verif wiki answer": "tulip(0.7302)", "verif concept answer": "tulip(0.7309)", "verif image answer": "lilac(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311988.jpg"}, {"question": "is this a street bike or dirt bike", "gt answer": "dirt(1.00)<br/>dirt bike(1.00)", "pred answer": "dirt bike", "question_id": 733485, "best approach": "wiki, concept", "verif answer": "dirt bike", "anno approach": "wiki", "verif wiki answer": "dirt bike(0.7222)", "verif concept answer": "dirt bike(0.7150)", "verif image answer": "motorbike(0.6525)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073348.jpg"}, {"question": "what is the item name of the object the people are wearing on their head", "gt answer": "cap(0.60)<br/>helmet(0.60)<br/>hat(1.00)", "pred answer": "hat", "question_id": 2746855, "best approach": "wiki, concept", "verif answer": "beanie", "anno approach": "wiki", "verif wiki answer": "hat(0.7294)", "verif concept answer": "hat(0.7304)", "verif image answer": "beanie(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274685.jpg"}, {"question": "what sandwich is that", "gt answer": "steak(1.00)<br/>sub(0.60)", "pred answer": "breakfast", "question_id": 2834455, "best approach": "wiki, concept", "verif answer": "steak", "anno approach": "wiki", "verif wiki answer": "steak(0.6502)", "verif concept answer": "steak(0.6510)", "verif image answer": "chicken(0.6488)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283445.jpg"}, {"question": "is this a meal or snack", "gt answer": "meal(1.00)<br/>snack(0.60)", "pred answer": "snack", "question_id": 49315, "best approach": "wiki, image", "verif answer": "snack", "anno approach": "image, wiki", "verif wiki answer": "snack(0.6569)", "verif concept answer": "breakfast(0.6381)", "verif image answer": "snack(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004931.jpg"}, {"question": "where might the batter be going to next", "gt answer": "first base(1.00)<br/>base(0.60)", "pred answer": "first base", "question_id": 2493625, "best approach": "wiki, concept, image", "verif answer": "first base", "anno approach": "wiki", "verif wiki answer": "first base(0.6578)", "verif concept answer": "first base(0.6561)", "verif image answer": "first base(0.6518)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249362.jpg"}, {"question": "what temperature is the water considered too cold for this activity", "gt answer": "60(1.00)<br/>70(0.60)", "pred answer": "cold", "question_id": 221235, "best approach": "image", "verif answer": "70", "anno approach": "image", "verif wiki answer": "80(0.5414)", "verif concept answer": "80(0.5084)", "verif image answer": "70(0.5687)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000022123.jpg"}, {"question": "what kind of storm threatens areas like the one pictured in the us every year in the late summer and fall", "gt answer": "hurricane(1.00)", "pred answer": "rainy", "question_id": 649485, "best approach": "wiki, concept, image", "verif answer": "hurricane", "anno approach": "wiki", "verif wiki answer": "hurricane(0.5045)", "verif concept answer": "hurricane(0.5049)", "verif image answer": "hurricane(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064948.jpg"}, {"question": "what is the cat standing on", "gt answer": "table(1.00)", "pred answer": "chair", "question_id": 4024485, "best approach": "", "verif answer": "on table", "anno approach": "", "verif wiki answer": "tablecloth(0.5865)", "verif concept answer": "tablecloth(0.5845)", "verif image answer": "on table(0.7098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402448.jpg"}, {"question": "what piece of furniture is this child in", "gt answer": "crib(1.00)", "pred answer": "bed", "question_id": 1950625, "best approach": "image", "verif answer": "sign", "anno approach": "image", "verif wiki answer": "sign(0.6432)", "verif concept answer": "sign(0.5031)", "verif image answer": "crib(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195062.jpg"}, {"question": "is this legal or illegal to ride a skate board", "gt answer": "legal(1.00)", "pred answer": "illegal", "question_id": 4629445, "best approach": "", "verif answer": "illegal", "anno approach": "", "verif wiki answer": "illegal(0.7310)", "verif concept answer": "illegal(0.7310)", "verif image answer": "illegal(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000462944.jpg"}, {"question": "are these zebras free or locked up", "gt answer": "locked up(1.00)", "pred answer": "free", "question_id": 4454275, "best approach": "", "verif answer": "fenced", "anno approach": "", "verif wiki answer": "fenced(0.7305)", "verif concept answer": "fenced(0.7310)", "verif image answer": "lost(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445427.jpg"}, {"question": "how long do the babies of this animal stay with their parent", "gt answer": "16 years(1.00)<br/>2 years(0.60)", "pred answer": "2 years", "question_id": 3809495, "best approach": "wiki, concept", "verif answer": "2 years", "anno approach": "", "verif wiki answer": "2 years(0.6172)", "verif concept answer": "2 years(0.6163)", "verif image answer": "3 years(0.6150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000380949.jpg"}, {"question": "what is on the girl 's neck", "gt answer": "necklace(1.00)", "pred answer": "tie", "question_id": 1514865, "best approach": "", "verif answer": "bridle", "anno approach": "", "verif wiki answer": "bridle(0.7102)", "verif concept answer": "bridle(0.7219)", "verif image answer": "bridle(0.7273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151486.jpg"}, {"question": "what day is it common for people to do the activity that the woman is doing here", "gt answer": "saturday(1.00)<br/>spring(0.60)<br/>windy day(0.60)", "pred answer": "windy", "question_id": 3427045, "best approach": "wiki, concept, image", "verif answer": "windy day", "anno approach": "", "verif wiki answer": "windy day(0.7297)", "verif concept answer": "windy day(0.7068)", "verif image answer": "windy day(0.7152)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342704.jpg"}, {"question": "name the aircraft model shown in this picture", "gt answer": "boeing 737(1.00)<br/>747(0.60)<br/>boeing(0.60)", "pred answer": "airplane", "question_id": 4373555, "best approach": "wiki, concept", "verif answer": "747", "anno approach": "", "verif wiki answer": "boeing 737(0.6573)", "verif concept answer": "boeing 737(0.6445)", "verif image answer": "747(0.6917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437355.jpg"}, {"question": "when this white stuff has not markings and is pristine it is called what kind of snow", "gt answer": "fresh(1.00)<br/>virgin(0.60)", "pred answer": "snow", "question_id": 5404795, "best approach": "wiki, concept, image", "verif answer": "fresh", "anno approach": "concept, wiki", "verif wiki answer": "fresh(0.6600)", "verif concept answer": "fresh(0.6619)", "verif image answer": "fresh(0.5490)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540479.jpg"}, {"question": "what breed of cat is this", "gt answer": "siamese(1.00)", "pred answer": "calico", "question_id": 2089945, "best approach": "image", "verif answer": "siamese", "anno approach": "image", "verif wiki answer": "persian(0.5681)", "verif concept answer": "color(0.6393)", "verif image answer": "siamese(0.6519)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208994.jpg"}, {"question": "what do people usually put into the meters", "gt answer": "coin(1.00)<br/>change(1.00)<br/>money(0.60)", "pred answer": "coin", "question_id": 1676215, "best approach": "wiki, concept, image", "verif answer": "change", "anno approach": "image, wiki", "verif wiki answer": "coin(0.6668)", "verif concept answer": "change(0.5563)", "verif image answer": "change(0.7040)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167621.jpg"}, {"question": "these men are riding on what", "gt answer": "elephant(1.00)<br/>cow(0.60)", "pred answer": "truck", "question_id": 1160435, "best approach": "wiki, image", "verif answer": "cow", "anno approach": "wiki", "verif wiki answer": "cow(0.7111)", "verif concept answer": "trunk(0.5339)", "verif image answer": "cow(0.6617)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116043.jpg"}, {"question": "what animal is this", "gt answer": "cow(1.00)", "pred answer": "cow", "question_id": 1543105, "best approach": "wiki, concept, image", "verif answer": "cow", "anno approach": "wiki", "verif wiki answer": "cow(0.7310)", "verif concept answer": "cow(0.7309)", "verif image answer": "cow(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154310.jpg"}, {"question": "what sport is being played", "gt answer": "tennis(1.00)", "pred answer": "tennis", "question_id": 1680675, "best approach": "wiki, concept, image", "verif answer": "tennis", "anno approach": "wiki", "verif wiki answer": "tennis(0.7234)", "verif concept answer": "tennis(0.7289)", "verif image answer": "tennis(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168067.jpg"}, {"question": "what animal family do these belong to", "gt answer": "zebra(1.00)<br/>mammal(0.60)", "pred answer": "kenya", "question_id": 4169245, "best approach": "image", "verif answer": "lion", "anno approach": "image", "verif wiki answer": "lion(0.6977)", "verif concept answer": "herbivore(0.6915)", "verif image answer": "mammal(0.6262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416924.jpg"}, {"question": "what does the object on the left do", "gt answer": "tell time(1.00)<br/>time(0.60)", "pred answer": "tell time", "question_id": 2013825, "best approach": "wiki, concept, image", "verif answer": "tell time", "anno approach": "concept, wiki", "verif wiki answer": "tell time(0.7308)", "verif concept answer": "tell time(0.7296)", "verif image answer": "tell time(0.5842)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201382.jpg"}, {"question": "what is the make of this motor bike", "gt answer": "honda(1.00)<br/>harley(0.60)", "pred answer": "honda", "question_id": 4748035, "best approach": "", "verif answer": "motorcycle", "anno approach": "", "verif wiki answer": "motorcycle(0.6304)", "verif concept answer": "motorcycle(0.6282)", "verif image answer": "motorcycle(0.6167)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000474803.jpg"}, {"question": "", "gt answer": "nintendo wii(0.60)<br/>wii(0.60)<br/>xbox(0.60)", "pred answer": "wii", "question_id": 767535, "best approach": "wiki, concept, image", "verif answer": "wii", "anno approach": "concept", "verif wiki answer": "wii(0.6541)", "verif concept answer": "wii(0.7292)", "verif image answer": "wii(0.6725)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076753.jpg"}, {"question": "what are the people riding", "gt answer": "elephant(1.00)", "pred answer": "elephant", "question_id": 3281015, "best approach": "wiki, concept, image", "verif answer": "elephant", "anno approach": "image, wiki", "verif wiki answer": "elephant(0.6613)", "verif concept answer": "elephant(0.6541)", "verif image answer": "elephant(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328101.jpg"}, {"question": "what kind of truck is this", "gt answer": "monster truck(1.00)<br/>diesel(0.60)", "pred answer": "truck", "question_id": 958795, "best approach": "", "verif answer": "offroading", "anno approach": "", "verif wiki answer": "offroading(0.7293)", "verif concept answer": "offroading(0.7295)", "verif image answer": "offroading(0.6995)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000095879.jpg"}, {"question": "why would some consider this a sign of bad luck", "gt answer": "superstition(1.00)<br/>black cat(0.60)", "pred answer": "bad", "question_id": 4356985, "best approach": "", "verif answer": "cat", "anno approach": "", "verif wiki answer": "cat(0.6519)", "verif concept answer": "cat(0.6153)", "verif image answer": "cat(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435698.jpg"}, {"question": "what kinds of food does this animal eat", "gt answer": "bug(1.00)", "pred answer": "seed", "question_id": 1884545, "best approach": "", "verif answer": "seed", "anno approach": "", "verif wiki answer": "seed(0.7301)", "verif concept answer": "seed(0.7042)", "verif image answer": "seed(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188454.jpg"}, {"question": "which sport is this", "gt answer": "motocross(1.00)<br/>motorcross(1.00)", "pred answer": "motocross", "question_id": 853835, "best approach": "wiki, concept", "verif answer": "motorcross", "anno approach": "", "verif wiki answer": "motorcross(0.6719)", "verif concept answer": "motorcross(0.6633)", "verif image answer": "bike(0.6479)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085383.jpg"}, {"question": "why skates hobby or work", "gt answer": "hobby(1.00)", "pred answer": "fun", "question_id": 2039895, "best approach": "", "verif answer": "fun", "anno approach": "", "verif wiki answer": "fun(0.7311)", "verif concept answer": "fun(0.7310)", "verif image answer": "fun(0.6978)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203989.jpg"}, {"question": "who invented the vehicles shown here", "gt answer": "blaise pascal(1.00)<br/>engineer(0.60)", "pred answer": "ford", "question_id": 218115, "best approach": "image", "verif answer": "driver", "anno approach": "image", "verif wiki answer": "driver(0.6539)", "verif concept answer": "driver(0.6660)", "verif image answer": "blaise pascal(0.6325)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000021811.jpg"}, {"question": "what brand is this cover", "gt answer": "target(1.00)<br/>quilt(0.60)", "pred answer": "rayban", "question_id": 2967605, "best approach": "", "verif answer": "walmart", "anno approach": "", "verif wiki answer": "amazon(0.5925)", "verif concept answer": "rayban(0.5967)", "verif image answer": "walmart(0.6425)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296760.jpg"}, {"question": "what type of hairstyle is she wearing", "gt answer": "pigtail(1.00)<br/>bun(1.00)", "pred answer": "pigtail", "question_id": 1245015, "best approach": "wiki, concept, image", "verif answer": "bun", "anno approach": "wiki", "verif wiki answer": "pigtail(0.7089)", "verif concept answer": "pigtail(0.7263)", "verif image answer": "bun(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000124501.jpg"}, {"question": "what type of bed is this", "gt answer": "bunk bed(1.00)<br/>bunk(1.00)", "pred answer": "bunk", "question_id": 1825275, "best approach": "wiki, concept, image", "verif answer": "bunk", "anno approach": "wiki", "verif wiki answer": "bunk(0.7277)", "verif concept answer": "bunk(0.7271)", "verif image answer": "bunk(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182527.jpg"}, {"question": "when do you eat this course in a five course meal", "gt answer": "first(1.00)<br/>salad(0.60)", "pred answer": "dinner", "question_id": 3794335, "best approach": "wiki, concept", "verif answer": "pasta", "anno approach": "wiki", "verif wiki answer": "first(0.6674)", "verif concept answer": "first(0.6998)", "verif image answer": "pasta(0.7051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379433.jpg"}, {"question": "what show is this", "gt answer": "circus(1.00)<br/>ballet(0.60)", "pred answer": "elephant", "question_id": 2191695, "best approach": "wiki, concept", "verif answer": "ballet", "anno approach": "wiki", "verif wiki answer": "ballet(0.7294)", "verif concept answer": "ballet(0.7003)", "verif image answer": "elephant(0.7227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219169.jpg"}, {"question": "what was the name of the road build for this vehicle", "gt answer": "railroad(1.00)<br/>bus(0.60)<br/>track(0.60)", "pred answer": "track", "question_id": 3426885, "best approach": "wiki, concept, image", "verif answer": "track", "anno approach": "wiki", "verif wiki answer": "track(0.6581)", "verif concept answer": "track(0.6586)", "verif image answer": "bus(0.6449)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342688.jpg"}, {"question": "which of these two people might be said to be flirting", "gt answer": "woman(1.00)<br/>man(0.60)<br/>female(0.60)<br/>both(0.60)", "pred answer": "friend", "question_id": 5057005, "best approach": "wiki, concept, image", "verif answer": "woman", "anno approach": "image, concept, wiki", "verif wiki answer": "woman(0.6388)", "verif concept answer": "woman(0.7263)", "verif image answer": "woman(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505700.jpg"}, {"question": "what name is on the side of the double decker bus", "gt answer": "simonds(1.00)", "pred answer": "artist", "question_id": 2263265, "best approach": "wiki, image", "verif answer": "simonds", "anno approach": "wiki", "verif wiki answer": "simonds(0.6961)", "verif concept answer": "wheel on bus(0.6011)", "verif image answer": "simonds(0.5167)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226326.jpg"}, {"question": "what vitamins do you get from the fruits", "gt answer": "c(1.00)<br/>vitamin c(0.60)<br/>d(0.60)", "pred answer": "c", "question_id": 4700915, "best approach": "wiki, concept", "verif answer": "c", "anno approach": "wiki", "verif wiki answer": "c(0.7143)", "verif concept answer": "c(0.7151)", "verif image answer": "d(0.6512)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470091.jpg"}, {"question": "what decade would this item have been uses", "gt answer": "1940's(1.00)<br/>1940(0.60)<br/>1930's(0.60)", "pred answer": "1960", "question_id": 429775, "best approach": "wiki, concept", "verif answer": "1800s", "anno approach": "", "verif wiki answer": "1930's(0.6219)", "verif concept answer": "1930's(0.6144)", "verif image answer": "1800s(0.6573)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042977.jpg"}, {"question": "what language is on the street sign", "gt answer": "spanish(1.00)<br/>english(0.60)<br/>french(0.60)", "pred answer": "chinese", "question_id": 5389995, "best approach": "image", "verif answer": "spanish", "anno approach": "image", "verif wiki answer": "english(0.7000)", "verif concept answer": "french(0.5148)", "verif image answer": "spanish(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538999.jpg"}, {"question": "", "gt answer": "minimal for experienced skier(0.60)<br/>very(0.60)<br/>moderately(0.60)", "pred answer": "very", "question_id": 5124495, "best approach": "wiki, concept", "verif answer": "easy", "anno approach": "", "verif wiki answer": "moderately(0.5518)", "verif concept answer": "minimal for experienced skier(0.5770)", "verif image answer": "easy(0.6035)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512449.jpg"}, {"question": "where do you go to get books", "gt answer": "library(1.00)<br/>bookstore(0.60)", "pred answer": "amazon", "question_id": 4070375, "best approach": "wiki, concept, image", "verif answer": "library", "anno approach": "wiki", "verif wiki answer": "library(0.7310)", "verif concept answer": "library(0.7246)", "verif image answer": "library(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407037.jpg"}, {"question": "in what war were airplanes of this type primarily used", "gt answer": "wwii(1.00)<br/>world war 2(1.00)", "pred answer": "ww2", "question_id": 730295, "best approach": "", "verif answer": "ww2", "anno approach": "", "verif wiki answer": "ww2(0.7136)", "verif concept answer": "ww2(0.7095)", "verif image answer": "ww2(0.7071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073029.jpg"}, {"question": "what event is taking place here", "gt answer": "rodeo(1.00)<br/>horse show(0.60)", "pred answer": "horse race", "question_id": 3101565, "best approach": "wiki, concept, image", "verif answer": "rodeo", "anno approach": "wiki", "verif wiki answer": "rodeo(0.7164)", "verif concept answer": "rodeo(0.7070)", "verif image answer": "rodeo(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310156.jpg"}, {"question": "what kind of plant is being covered by the white cloth", "gt answer": "rose bush(1.00)<br/>rose(0.60)", "pred answer": "fern", "question_id": 4705395, "best approach": "", "verif answer": "aloe", "anno approach": "", "verif wiki answer": "tulip(0.7297)", "verif concept answer": "tulip(0.7283)", "verif image answer": "aloe(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470539.jpg"}, {"question": "what type of stone are these walls made of", "gt answer": "limestone(1.00)<br/>brick(0.60)<br/>rock(0.60)<br/>clay(0.60)", "pred answer": "stone", "question_id": 3034535, "best approach": "concept, image", "verif answer": "clay", "anno approach": "image", "verif wiki answer": "cobblestone(0.6619)", "verif concept answer": "brick(0.6544)", "verif image answer": "clay(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303453.jpg"}, {"question": "where is this street located", "gt answer": "druid hill(1.00)<br/>london(0.60)", "pred answer": "london", "question_id": 5048865, "best approach": "image", "verif answer": "dublin", "anno approach": "image", "verif wiki answer": "dublin(0.7154)", "verif concept answer": "dublin(0.7253)", "verif image answer": "london(0.6612)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000504886.jpg"}, {"question": "what cooking method was used to make the brown piece of food", "gt answer": "fry(1.00)", "pred answer": "grilled", "question_id": 2272935, "best approach": "", "verif answer": "grease", "anno approach": "", "verif wiki answer": "grease(0.6347)", "verif concept answer": "grease(0.6280)", "verif image answer": "grease(0.7181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000227293.jpg"}, {"question": "what 's the name of the mountain mountains are in the photo", "gt answer": "alp(1.00)", "pred answer": "rockies", "question_id": 2415655, "best approach": "wiki, concept, image", "verif answer": "alp", "anno approach": "wiki", "verif wiki answer": "alp(0.6645)", "verif concept answer": "alp(0.6190)", "verif image answer": "alp(0.6443)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241565.jpg"}, {"question": "which animals are allowed in this park", "gt answer": "dog(1.00)<br/>desk(0.60)", "pred answer": "dog", "question_id": 964665, "best approach": "wiki, concept, image", "verif answer": "dog", "anno approach": "wiki", "verif wiki answer": "dog(0.7306)", "verif concept answer": "dog(0.7225)", "verif image answer": "dog(0.7275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096466.jpg"}, {"question": "what kind of food is this specifically", "gt answer": "rice(1.00)<br/>corn(0.60)<br/>egg(0.60)", "pred answer": "pizza", "question_id": 1585555, "best approach": "wiki, concept, image", "verif answer": "egg", "anno approach": "wiki", "verif wiki answer": "egg(0.6732)", "verif concept answer": "egg(0.6491)", "verif image answer": "egg(0.6460)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000158555.jpg"}, {"question": "what style of columns are used here", "gt answer": "roman(1.00)<br/>greek(1.00)", "pred answer": "gothic", "question_id": 5322775, "best approach": "", "verif answer": "gothic", "anno approach": "", "verif wiki answer": "gothic(0.5997)", "verif concept answer": "gothic(0.6521)", "verif image answer": "gothic(0.6843)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532277.jpg"}, {"question": "what 's in the sky", "gt answer": "kite(1.00)<br/>parachute(0.60)", "pred answer": "wind", "question_id": 1772805, "best approach": "", "verif answer": "parasailing", "anno approach": "", "verif wiki answer": "wind(0.6230)", "verif concept answer": "wind(0.6432)", "verif image answer": "parasailing(0.6443)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177280.jpg"}, {"question": "what is this dog doing", "gt answer": "smell(1.00)<br/>urine(0.60)", "pred answer": "pee", "question_id": 2230895, "best approach": "wiki, image", "verif answer": "smell", "anno approach": "wiki", "verif wiki answer": "smell(0.6693)", "verif concept answer": "pee(0.6480)", "verif image answer": "smell(0.6354)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223089.jpg"}, {"question": "what type of flowers are in the image", "gt answer": "daisy(1.00)<br/>pansy(0.60)", "pred answer": "tulip", "question_id": 1313525, "best approach": "image", "verif answer": "daffodil", "anno approach": "image", "verif wiki answer": "rose(0.6132)", "verif concept answer": "daffodil(0.6591)", "verif image answer": "daisy(0.6368)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000131352.jpg"}, {"question": "this meal would be high in what kind of fat", "gt answer": "saturated(1.00)<br/>omega 3(0.60)", "pred answer": "meat", "question_id": 3404765, "best approach": "image", "verif answer": "solid", "anno approach": "image", "verif wiki answer": "solid(0.6219)", "verif concept answer": "solid(0.6627)", "verif image answer": "saturated(0.5068)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340476.jpg"}, {"question": "this bench is made from wood partitions that resemble the sticks in what sweet treat", "gt answer": "popsicle(1.00)", "pred answer": "banana", "question_id": 2877185, "best approach": "", "verif answer": "wooden", "anno approach": "", "verif wiki answer": "wooden(0.7308)", "verif concept answer": "wooden(0.7308)", "verif image answer": "violet(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287718.jpg"}, {"question": "what shape would you say the building is", "gt answer": "rectangle(1.00)<br/>square(0.60)", "pred answer": "city", "question_id": 826505, "best approach": "wiki", "verif answer": "diamond", "anno approach": "wiki", "verif wiki answer": "rectangle(0.5005)", "verif concept answer": "diamond(0.5003)", "verif image answer": "diamond(0.5008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082650.jpg"}, {"question": "what are the colored mushrooms from", "gt answer": "mario(1.00)", "pred answer": "california", "question_id": 2731035, "best approach": "", "verif answer": "xbox", "anno approach": "", "verif wiki answer": "amazon(0.6505)", "verif concept answer": "xbox(0.6921)", "verif image answer": "xbox(0.6394)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273103.jpg"}, {"question": "what number format is on this clock", "gt answer": "analog(1.00)<br/>roman numeral(1.00)<br/>roman(0.60)", "pred answer": "roman", "question_id": 737825, "best approach": "wiki, concept, image", "verif answer": "roman", "anno approach": "image, wiki", "verif wiki answer": "roman(0.7211)", "verif concept answer": "roman(0.6626)", "verif image answer": "roman(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073782.jpg"}, {"question": "what is the lady celebrating", "gt answer": "bachelorette(1.00)<br/>birthday(0.60)", "pred answer": "party", "question_id": 5750555, "best approach": "wiki, concept, image", "verif answer": "bachelorette", "anno approach": "image, wiki", "verif wiki answer": "bachelorette(0.6435)", "verif concept answer": "bachelorette(0.6470)", "verif image answer": "bachelorette(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575055.jpg"}, {"question": "what company builds these planes", "gt answer": "boeing(1.00)", "pred answer": "boeing", "question_id": 4811295, "best approach": "wiki, concept, image", "verif answer": "boeing", "anno approach": "concept, wiki", "verif wiki answer": "boeing(0.6731)", "verif concept answer": "boeing(0.6757)", "verif image answer": "boeing(0.6290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481129.jpg"}, {"question": "is this a snack or meal", "gt answer": "meal(1.00)", "pred answer": "snack", "question_id": 5782615, "best approach": "", "verif answer": "snack", "anno approach": "", "verif wiki answer": "snack(0.7300)", "verif concept answer": "snack(0.7310)", "verif image answer": "snack(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578261.jpg"}, {"question": "is she skiing up or down the hill", "gt answer": "down(1.00)<br/>downhill(1.00)", "pred answer": "down", "question_id": 5466775, "best approach": "wiki, concept, image", "verif answer": "down", "anno approach": "concept, wiki", "verif wiki answer": "down(0.7258)", "verif concept answer": "down(0.7111)", "verif image answer": "down(0.5073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546677.jpg"}, {"question": "what is she doing with the animal", "gt answer": "pet(1.00)<br/>wash(1.00)<br/>feed(0.60)", "pred answer": "walk", "question_id": 2630425, "best approach": "wiki, concept, image", "verif answer": "wash", "anno approach": "wiki", "verif wiki answer": "wash(0.6451)", "verif concept answer": "wash(0.6608)", "verif image answer": "wash(0.6620)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263042.jpg"}, {"question": "what alternative to walking is the red and white object", "gt answer": "bike(1.00)<br/>bicycle(0.60)<br/>ride(0.60)", "pred answer": "schwinn", "question_id": 887805, "best approach": "image", "verif answer": "ride", "anno approach": "image", "verif wiki answer": "ride(0.6461)", "verif concept answer": "ride(0.6401)", "verif image answer": "bike(0.5005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088780.jpg"}, {"question": "what healthy vegetable is in this picture", "gt answer": "tomato(1.00)", "pred answer": "carrot", "question_id": 5318125, "best approach": "concept", "verif answer": "tomato", "anno approach": "concept", "verif wiki answer": "cheese(0.5709)", "verif concept answer": "tomato(0.6766)", "verif image answer": "cheese(0.5037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531812.jpg"}, {"question": "what kind of store is this", "gt answer": "mattress(1.00)", "pred answer": "bar", "question_id": 4018385, "best approach": "", "verif answer": "food", "anno approach": "", "verif wiki answer": "furniture(0.6716)", "verif concept answer": "furniture(0.6551)", "verif image answer": "food(0.7030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401838.jpg"}, {"question": "what creature is this kite made in the likeness of", "gt answer": "octopus(1.00)<br/>dragon(0.60)", "pred answer": "stingray", "question_id": 4416195, "best approach": "wiki, concept, image", "verif answer": "dragon", "anno approach": "wiki", "verif wiki answer": "dragon(0.7122)", "verif concept answer": "dragon(0.7186)", "verif image answer": "dragon(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441619.jpg"}, {"question": "what fuel makes this vehicle move", "gt answer": "electricity(1.00)<br/>gas(0.60)", "pred answer": "diesel", "question_id": 2484715, "best approach": "", "verif answer": "kerosene", "anno approach": "", "verif wiki answer": "kerosene(0.7310)", "verif concept answer": "kerosene(0.7310)", "verif image answer": "kerosene(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248471.jpg"}, {"question": "", "gt answer": "confused(0.60)<br/>sad(0.60)", "pred answer": "happiness", "question_id": 5181585, "best approach": "wiki, concept, image", "verif answer": "sad", "anno approach": "concept, wiki", "verif wiki answer": "sad(0.6520)", "verif concept answer": "sad(0.6679)", "verif image answer": "sad(0.6174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518158.jpg"}, {"question": "what does the sign want you to do", "gt answer": "stop(1.00)", "pred answer": "stop", "question_id": 973635, "best approach": "wiki, concept, image", "verif answer": "stop", "anno approach": "concept, wiki", "verif wiki answer": "stop(0.7308)", "verif concept answer": "stop(0.7262)", "verif image answer": "stop(0.6673)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097363.jpg"}, {"question": "what animal is this lady wearing", "gt answer": "fox(1.00)", "pred answer": "tuxedo", "question_id": 707405, "best approach": "", "verif answer": "lion", "anno approach": "", "verif wiki answer": "lion(0.5025)", "verif concept answer": "lion(0.5025)", "verif image answer": "lion(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070740.jpg"}, {"question": "which type of utensil is on top of the white plate", "gt answer": "fork(1.00)", "pred answer": "fork", "question_id": 3232785, "best approach": "", "verif answer": "right fork", "anno approach": "", "verif wiki answer": "fork and knife(0.7298)", "verif concept answer": "right fork(0.7304)", "verif image answer": "fork and knife(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323278.jpg"}, {"question": "to board a train at this station you need a what", "gt answer": "ticket(1.00)<br/>pass(0.60)", "pred answer": "pedal", "question_id": 205175, "best approach": "wiki, concept, image", "verif answer": "pass", "anno approach": "image, wiki", "verif wiki answer": "pass(0.6174)", "verif concept answer": "pass(0.6089)", "verif image answer": "pass(0.6454)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020517.jpg"}, {"question": "what helps direct traffic and prevent accidents", "gt answer": "traffic light(1.00)<br/>stop light(0.60)<br/>light(0.60)<br/>stoplight(0.60)", "pred answer": "stop light", "question_id": 3065355, "best approach": "wiki", "verif answer": "stoplight", "anno approach": "wiki", "verif wiki answer": "stoplight(0.6546)", "verif concept answer": "red light(0.6373)", "verif image answer": "red light(0.5843)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306535.jpg"}, {"question": "what appliance is seen behind the girl", "gt answer": "stove(1.00)<br/>oven(1.00)", "pred answer": "microwave", "question_id": 1399945, "best approach": "wiki", "verif answer": "food", "anno approach": "wiki", "verif wiki answer": "stove(0.5003)", "verif concept answer": "refrigerator(0.5029)", "verif image answer": "food(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139994.jpg"}, {"question": "what is the economic status of this area", "gt answer": "poor(1.00)", "pred answer": "residential", "question_id": 3904945, "best approach": "wiki, concept", "verif answer": "poor", "anno approach": "wiki", "verif wiki answer": "poor(0.6541)", "verif concept answer": "poor(0.6633)", "verif image answer": "dilapidated(0.6177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390494.jpg"}, {"question": "what activity would you wear these shoes for", "gt answer": "run(1.00)", "pred answer": "skateboard", "question_id": 1637155, "best approach": "image", "verif answer": "competition", "anno approach": "image", "verif wiki answer": "turn(0.6240)", "verif concept answer": "competition(0.6400)", "verif image answer": "run(0.5412)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163715.jpg"}, {"question": "what are the blocks used to make that wall made out of", "gt answer": "brick(1.00)<br/>concrete(0.60)<br/>stone(0.60)", "pred answer": "wood", "question_id": 1257745, "best approach": "wiki, concept", "verif answer": "cement", "anno approach": "wiki", "verif wiki answer": "brick(0.7240)", "verif concept answer": "brick(0.7303)", "verif image answer": "cement(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125774.jpg"}, {"question": "where are the planes", "gt answer": "at airport(1.00)<br/>runway(0.60)<br/>airport(0.60)", "pred answer": "airport", "question_id": 4116455, "best approach": "wiki", "verif answer": "at airport", "anno approach": "wiki", "verif wiki answer": "at airport(0.6596)", "verif concept answer": "runway(0.6523)", "verif image answer": "airport(0.6496)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000411645.jpg"}, {"question": "what sound does this animal make", "gt answer": "moo(1.00)", "pred answer": "sad", "question_id": 2196795, "best approach": "", "verif answer": "potassium", "anno approach": "", "verif wiki answer": "potassium(0.5204)", "verif concept answer": "potassium(0.5011)", "verif image answer": "baa(0.5014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219679.jpg"}, {"question": "what is this man doing", "gt answer": "blend(1.00)", "pred answer": "cook", "question_id": 2613055, "best approach": "wiki, concept", "verif answer": "blend", "anno approach": "wiki", "verif wiki answer": "blend(0.6911)", "verif concept answer": "blend(0.6849)", "verif image answer": "eat(0.5695)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261305.jpg"}, {"question": "is this a competition or friendly", "gt answer": "friendly(1.00)<br/>competition(0.60)", "pred answer": "competition", "question_id": 2940345, "best approach": "wiki, concept, image", "verif answer": "competition", "anno approach": "image, wiki", "verif wiki answer": "competition(0.5071)", "verif concept answer": "competition(0.5071)", "verif image answer": "competition(0.5412)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000294034.jpg"}, {"question": "who is the most famous american practitioner of this sport", "gt answer": "shaun white(1.00)<br/>chloe kim(0.60)", "pred answer": "bode miller", "question_id": 3638265, "best approach": "wiki, concept, image", "verif answer": "shaun white", "anno approach": "image, concept, wiki", "verif wiki answer": "shaun white(0.5888)", "verif concept answer": "shaun white(0.6608)", "verif image answer": "shaun white(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363826.jpg"}, {"question": "how many wheels does the device being carried typically have", "gt answer": "2(1.00)<br/>4(1.00)", "pred answer": "18", "question_id": 928795, "best approach": "", "verif answer": "5 years", "anno approach": "", "verif wiki answer": "5 years(0.7310)", "verif concept answer": "5 years(0.7309)", "verif image answer": "5 years(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092879.jpg"}, {"question": "what city is replacing these the fastest", "gt answer": "new york(1.00)<br/>new york city(0.60)<br/>los angeles(0.60)", "pred answer": "new york", "question_id": 2197565, "best approach": "", "verif answer": "pennsylvania", "anno approach": "", "verif wiki answer": "pennsylvania(0.6606)", "verif concept answer": "pennsylvania(0.6841)", "verif image answer": "philadelphia(0.6727)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219756.jpg"}, {"question": "what type of furniture is this", "gt answer": "couch(1.00)<br/>live room(1.00)", "pred answer": "sofa", "question_id": 1528155, "best approach": "image", "verif answer": "live room", "anno approach": "image", "verif wiki answer": "lounge(0.6098)", "verif concept answer": "lounge(0.6427)", "verif image answer": "live room(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000152815.jpg"}, {"question": "can you guess the place where the man is playing", "gt answer": "aspen(0.60)<br/>mountain(1.00)<br/>colorado(0.60)", "pred answer": "mountain", "question_id": 4802085, "best approach": "wiki, concept, image", "verif answer": "aspen", "anno approach": "image, concept, wiki", "verif wiki answer": "aspen(0.6602)", "verif concept answer": "aspen(0.7057)", "verif image answer": "aspen(0.7175)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480208.jpg"}, {"question": "what chores are these tools commonly used for", "gt answer": "garden(1.00)", "pred answer": "travel", "question_id": 85315, "best approach": "", "verif answer": "bench", "anno approach": "", "verif wiki answer": "bench(0.5870)", "verif concept answer": "bench(0.5450)", "verif image answer": "yard(0.5017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008531.jpg"}, {"question": "what five sided object is the man headed towards", "gt answer": "home plate(1.00)", "pred answer": "home run", "question_id": 4590785, "best approach": "", "verif answer": "base", "anno approach": "", "verif wiki answer": "outfield(0.6508)", "verif concept answer": "outfield(0.5916)", "verif image answer": "base(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459078.jpg"}, {"question": "name the type of wood used to make this table in this picture", "gt answer": "mahogany(1.00)<br/>wood(0.60)<br/>oak(0.60)", "pred answer": "oak", "question_id": 1467605, "best approach": "wiki, image", "verif answer": "mahogany", "anno approach": "wiki", "verif wiki answer": "mahogany(0.7109)", "verif concept answer": "wood(0.6413)", "verif image answer": "mahogany(0.6573)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146760.jpg"}, {"question": "what food is this", "gt answer": "ramen(1.00)<br/>pasta(1.00)", "pred answer": "stir fry", "question_id": 2999685, "best approach": "", "verif answer": "lo mein", "anno approach": "", "verif wiki answer": "stir fry(0.7304)", "verif concept answer": "stir fry(0.7192)", "verif image answer": "lo mein(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000299968.jpg"}, {"question": "what sport is this for", "gt answer": "bike(1.00)<br/>cycling(1.00)", "pred answer": "bike", "question_id": 154865, "best approach": "concept", "verif answer": "walk", "anno approach": "concept", "verif wiki answer": "ride(0.6219)", "verif concept answer": "cycling(0.6135)", "verif image answer": "walk(0.6476)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015486.jpg"}, {"question": "what language is this", "gt answer": "german(1.00)<br/>french(0.60)", "pred answer": "english", "question_id": 3350905, "best approach": "wiki", "verif answer": "english", "anno approach": "wiki", "verif wiki answer": "german(0.7310)", "verif concept answer": "english(0.7233)", "verif image answer": "english(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335090.jpg"}, {"question": "what is the shape of the third building from the left", "gt answer": "rectangle(1.00)", "pred answer": "heart", "question_id": 4750195, "best approach": "", "verif answer": "kangaroo", "anno approach": "", "verif wiki answer": "kangaroo(0.7307)", "verif concept answer": "kangaroo(0.7305)", "verif image answer": "kangaroo(0.7126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475019.jpg"}, {"question": "in what desert are these horses", "gt answer": "sahara(1.00)<br/>egyptian(0.60)", "pred answer": "mountain", "question_id": 5660605, "best approach": "wiki, image", "verif answer": "sahara", "anno approach": "wiki", "verif wiki answer": "sahara(0.7272)", "verif concept answer": "indian(0.6764)", "verif image answer": "sahara(0.7134)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566060.jpg"}, {"question": "what does the yellow m stand for", "gt answer": "mcdonalds(1.00)<br/>mcdonald's(0.60)", "pred answer": "stop", "question_id": 186615, "best approach": "image", "verif answer": "mcdonalds", "anno approach": "image", "verif wiki answer": "hotdog(0.5909)", "verif concept answer": "hotdog(0.5329)", "verif image answer": "mcdonalds(0.6326)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000018661.jpg"}, {"question": "what shape is on the women hat", "gt answer": "triangle(1.00)<br/>adidas(0.60)", "pred answer": "rectangle", "question_id": 499335, "best approach": "", "verif answer": "in half", "anno approach": "", "verif wiki answer": "in half(0.7311)", "verif concept answer": "in half(0.7311)", "verif image answer": "in half(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049933.jpg"}, {"question": "where would you see this many picnic tables", "gt answer": "park(1.00)", "pred answer": "forest", "question_id": 4737055, "best approach": "", "verif answer": "skate park", "anno approach": "", "verif wiki answer": "skate park(0.7189)", "verif concept answer": "bench(0.6411)", "verif image answer": "skate park(0.7117)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473705.jpg"}, {"question": "what do you commonly do near this body of water", "gt answer": "tan(1.00)<br/>swim(1.00)<br/>golf(0.60)", "pred answer": "swim", "question_id": 3343525, "best approach": "wiki, concept, image", "verif answer": "swim", "anno approach": "image, concept, wiki", "verif wiki answer": "swim(0.6655)", "verif concept answer": "swim(0.7304)", "verif image answer": "swim(0.7148)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334352.jpg"}, {"question": "what type of hat is the gentleman on the right wearing", "gt answer": "fedora(1.00)<br/>bowler(0.60)", "pred answer": "fedora", "question_id": 1349145, "best approach": "", "verif answer": "cowboy", "anno approach": "", "verif wiki answer": "cowboy(0.7064)", "verif concept answer": "cowboy(0.7054)", "verif image answer": "cowboy(0.6655)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134914.jpg"}, {"question": "what is the woman holding in her left hand", "gt answer": "tennis racket(1.00)<br/>racket(0.60)", "pred answer": "tennis", "question_id": 2824735, "best approach": "wiki, concept, image", "verif answer": "tennis racket", "anno approach": "wiki", "verif wiki answer": "tennis racket(0.7310)", "verif concept answer": "tennis racket(0.7310)", "verif image answer": "tennis racket(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282473.jpg"}, {"question": "what is this bird looking for to eat", "gt answer": "fish(1.00)<br/>crab(0.60)", "pred answer": "seed", "question_id": 4021125, "best approach": "wiki, image", "verif answer": "crab", "anno approach": "wiki", "verif wiki answer": "crab(0.6503)", "verif concept answer": "bug(0.6319)", "verif image answer": "crab(0.6789)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402112.jpg"}, {"question": "where can this meal be purchased", "gt answer": "restaurant(1.00)", "pred answer": "ikea", "question_id": 4124005, "best approach": "", "verif answer": "cafe", "anno approach": "", "verif wiki answer": "cafe(0.7309)", "verif concept answer": "cafe(0.7181)", "verif image answer": "cafe(0.6824)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412400.jpg"}, {"question": "what kind of material is the building made out", "gt answer": "brick(1.00)", "pred answer": "stone", "question_id": 1601035, "best approach": "wiki, concept", "verif answer": "stone", "anno approach": "wiki", "verif wiki answer": "brick(0.6475)", "verif concept answer": "brick(0.6458)", "verif image answer": "stone(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160103.jpg"}, {"question": "", "gt answer": "dachsund(0.60)<br/>black labrador(0.60)<br/>labrador(0.60)", "pred answer": "shepherd", "question_id": 792445, "best approach": "", "verif answer": "black lab", "anno approach": "", "verif wiki answer": "black lab(0.6416)", "verif concept answer": "black lab(0.6551)", "verif image answer": "black lab(0.6383)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079244.jpg"}, {"question": "what emotion are the people in the photo experiencing towards each other", "gt answer": "love(1.00)", "pred answer": "happiness", "question_id": 2615215, "best approach": "wiki, concept, image", "verif answer": "love", "anno approach": "wiki", "verif wiki answer": "love(0.7308)", "verif concept answer": "love(0.7304)", "verif image answer": "love(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261521.jpg"}, {"question": "what does this animal have in common with the country of thailand", "gt answer": "siamese(1.00)<br/>color(0.60)", "pred answer": "cat", "question_id": 4055415, "best approach": "concept", "verif answer": "siamese", "anno approach": "concept", "verif wiki answer": "domestic shorthair(0.6539)", "verif concept answer": "siamese(0.6558)", "verif image answer": "persian(0.6558)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405541.jpg"}, {"question": "where can i buy bags like this dog is wearing", "gt answer": "amazon(1.00)<br/>store(0.60)<br/>pet store(0.60)", "pred answer": "store", "question_id": 3743726, "best approach": "concept", "verif answer": "amazon", "anno approach": "concept", "verif wiki answer": "pet store(0.7055)", "verif concept answer": "amazon(0.7204)", "verif image answer": "pet store(0.6547)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374372.jpg"}, {"question": "how much does this creature weigh on average", "gt answer": "ton(1.00)<br/>1000(0.60)<br/>500 lbs(0.60)", "pred answer": "100 lbs", "question_id": 4646165, "best approach": "image", "verif answer": "500 lbs", "anno approach": "image", "verif wiki answer": "500 pounds(0.6341)", "verif concept answer": "500 pounds(0.6543)", "verif image answer": "500 lbs(0.6730)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464616.jpg"}, {"question": "what is the truck transporting", "gt answer": "garbage(1.00)<br/>furniture(0.60)<br/>good(0.60)<br/>food(0.60)", "pred answer": "people", "question_id": 2533325, "best approach": "wiki, concept, image", "verif answer": "garbage", "anno approach": "wiki", "verif wiki answer": "garbage(0.6379)", "verif concept answer": "garbage(0.6682)", "verif image answer": "garbage(0.6442)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253332.jpg"}, {"question": "how often do these bathrooms get cleaned", "gt answer": "never(1.00)<br/>once(0.60)<br/>rarely(0.60)", "pred answer": "very", "question_id": 1497375, "best approach": "wiki, image", "verif answer": "yearly", "anno approach": "wiki", "verif wiki answer": "once(0.6170)", "verif concept answer": "yearly(0.6280)", "verif image answer": "once(0.5431)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149737.jpg"}, {"question": "what will happen after the person push the button", "gt answer": "blend(1.00)", "pred answer": "eat", "question_id": 4019815, "best approach": "wiki, concept, image", "verif answer": "blend", "anno approach": "concept, wiki", "verif wiki answer": "blend(0.6566)", "verif concept answer": "blend(0.7202)", "verif image answer": "blend(0.6350)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401981.jpg"}, {"question": "what type of eyewear is this person wearing in this image", "gt answer": "goggle(1.00)", "pred answer": "beanie", "question_id": 1619585, "best approach": "wiki, concept", "verif answer": "sunglasses", "anno approach": "wiki", "verif wiki answer": "goggle(0.6230)", "verif concept answer": "goggle(0.5675)", "verif image answer": "sunglasses(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161958.jpg"}, {"question": "where in the supermarket would you find the vegetables depicted", "gt answer": "produce(1.00)<br/>produce department(0.60)", "pred answer": "supermarket", "question_id": 3555895, "best approach": "", "verif answer": "fruit", "anno approach": "", "verif wiki answer": "fruit(0.7311)", "verif concept answer": "fruit(0.7311)", "verif image answer": "fruit(0.7141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355589.jpg"}, {"question": "what is the name of this style of rug", "gt answer": "oriental(1.00)", "pred answer": "checkered", "question_id": 1478565, "best approach": "wiki, concept, image", "verif answer": "oriental", "anno approach": "wiki", "verif wiki answer": "oriental(0.7308)", "verif concept answer": "oriental(0.7293)", "verif image answer": "oriental(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147856.jpg"}, {"question": "what country might this be", "gt answer": "vietnam(1.00)<br/>japan(0.60)", "pred answer": "america", "question_id": 4693015, "best approach": "", "verif answer": "thailand", "anno approach": "", "verif wiki answer": "thailand(0.6537)", "verif concept answer": "thailand(0.6602)", "verif image answer": "thailand(0.7162)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469301.jpg"}, {"question": "what is the name of this object that the dog is lying on", "gt answer": "pillow(1.00)<br/>bed(0.60)<br/>mattress(0.60)", "pred answer": "chair", "question_id": 1918055, "best approach": "wiki", "verif answer": "bed", "anno approach": "wiki", "verif wiki answer": "pillow(0.5218)", "verif concept answer": "bed(0.5329)", "verif image answer": "bed(0.6126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191805.jpg"}, {"question": "what type of lights are on the ceiling", "gt answer": "track(0.60)<br/>spot light(1.00)", "pred answer": "overhead", "question_id": 1174285, "best approach": "wiki, concept, image", "verif answer": "track", "anno approach": "concept, wiki", "verif wiki answer": "track(0.6283)", "verif concept answer": "track(0.6759)", "verif image answer": "track(0.6546)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117428.jpg"}, {"question": "how is the machine in this photo operated", "gt answer": "engine(1.00)<br/>motor(0.60)<br/>gas(0.60)", "pred answer": "gasoline", "question_id": 4248205, "best approach": "", "verif answer": "track", "anno approach": "", "verif wiki answer": "track(0.6433)", "verif concept answer": "track(0.6189)", "verif image answer": "track(0.6283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424820.jpg"}, {"question": "in what type of location is this scene", "gt answer": "farm(1.00)", "pred answer": "farm", "question_id": 2207995, "best approach": "", "verif answer": "stable", "anno approach": "", "verif wiki answer": "stable(0.7185)", "verif concept answer": "stable(0.7220)", "verif image answer": "stable(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220799.jpg"}, {"question": "what channel is likely broadcasting this game", "gt answer": "espn(1.00)", "pred answer": "major league", "question_id": 833325, "best approach": "", "verif answer": "ride", "anno approach": "", "verif wiki answer": "ride(0.7309)", "verif concept answer": "youtube(0.6303)", "verif image answer": "youtube(0.6064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083332.jpg"}, {"question": "in children 's readers this dog would be named spot and be accompanied by a girl and boy named what", "gt answer": "dick and jane(1.00)<br/>jack and jill(0.60)", "pred answer": "friend", "question_id": 4352945, "best approach": "concept", "verif answer": "dick and jane", "anno approach": "concept", "verif wiki answer": "puppy(0.5226)", "verif concept answer": "dick and jane(0.5948)", "verif image answer": "puppy(0.5005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435294.jpg"}, {"question": "what is on the laptop", "gt answer": "paper(1.00)", "pred answer": "hp", "question_id": 2197525, "best approach": "", "verif answer": "ceramic", "anno approach": "", "verif wiki answer": "ceramic(0.5125)", "verif concept answer": "ceramic(0.5244)", "verif image answer": "tissue(0.5117)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219752.jpg"}, {"question": "why is this a comfortable situation", "gt answer": "sunlight(1.00)<br/>warm(0.60)", "pred answer": "sheet", "question_id": 5167265, "best approach": "image", "verif answer": "sun", "anno approach": "image", "verif wiki answer": "sun(0.6373)", "verif concept answer": "sun(0.6382)", "verif image answer": "warm(0.6304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516726.jpg"}, {"question": "what activity did this person do to receive that item", "gt answer": "cut hair(1.00)<br/>haircut(0.60)<br/>cut(0.60)<br/>hair(0.60)", "pred answer": "hike", "question_id": 4894635, "best approach": "wiki, concept", "verif answer": "shave", "anno approach": "wiki", "verif wiki answer": "cut hair(0.6656)", "verif concept answer": "cut hair(0.6623)", "verif image answer": "shave(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489463.jpg"}, {"question": "where will the zookeeper place the food", "gt answer": "basket(1.00)<br/>umbrella(0.60)", "pred answer": "home", "question_id": 345315, "best approach": "wiki, concept, image", "verif answer": "umbrella", "anno approach": "concept, wiki", "verif wiki answer": "umbrella(0.7170)", "verif concept answer": "umbrella(0.6683)", "verif image answer": "umbrella(0.6301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000034531.jpg"}, {"question": "what kinds of birds are these", "gt answer": "parrot(1.00)<br/>parakeet(1.00)", "pred answer": "parakeet", "question_id": 3312255, "best approach": "", "verif answer": "toucan", "anno approach": "", "verif wiki answer": "toucan(0.5666)", "verif concept answer": "toucan(0.6352)", "verif image answer": "toucan(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331225.jpg"}, {"question": "what causes the black areas on the side of the house", "gt answer": "shadow(1.00)", "pred answer": "light", "question_id": 4133605, "best approach": "concept, image", "verif answer": "sunset", "anno approach": "", "verif wiki answer": "sunset(0.6861)", "verif concept answer": "shadow(0.6448)", "verif image answer": "shadow(0.6459)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000413360.jpg"}, {"question": "what type of energy can be used for measuring the rate of a reaction", "gt answer": "microwave(1.00)<br/>kinetic(0.60)<br/>electron(0.60)<br/>electric(0.60)", "pred answer": "microwave", "question_id": 4317085, "best approach": "image", "verif answer": "computer", "anno approach": "image", "verif wiki answer": "computer(0.5697)", "verif concept answer": "computer(0.6323)", "verif image answer": "kinetic(0.5017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431708.jpg"}, {"question": "what beer maker is famous for the use of the animals in the image", "gt answer": "budweiser(1.00)<br/>clydesdale(0.60)", "pred answer": "horse", "question_id": 24445, "best approach": "wiki", "verif answer": "clydesdale", "anno approach": "wiki", "verif wiki answer": "budweiser(0.6191)", "verif concept answer": "clydesdale(0.6495)", "verif image answer": "clydesdale(0.6211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002444.jpg"}, {"question": "what type of pitch is he throwing", "gt answer": "overhand(1.00)<br/>fastball(1.00)", "pred answer": "backhand", "question_id": 4508605, "best approach": "concept, image", "verif answer": "backhand", "anno approach": "", "verif wiki answer": "backhand(0.7250)", "verif concept answer": "overhand(0.7210)", "verif image answer": "overhand(0.6963)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450860.jpg"}, {"question": "what is in the sky", "gt answer": "cloud(1.00)<br/>kite(0.60)<br/>bird(0.60)<br/>helicopter(0.60)", "pred answer": "storm", "question_id": 333595, "best approach": "wiki, concept", "verif answer": "bird", "anno approach": "concept, wiki", "verif wiki answer": "bird(0.5722)", "verif concept answer": "bird(0.6213)", "verif image answer": "plane(0.5551)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033359.jpg"}, {"question": "what activity is happening", "gt answer": "play(1.00)<br/>dance(0.60)<br/>parade(0.60)", "pred answer": "party", "question_id": 3949005, "best approach": "image", "verif answer": "play game", "anno approach": "image", "verif wiki answer": "play game(0.6679)", "verif concept answer": "play game(0.6569)", "verif image answer": "play(0.6538)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000394900.jpg"}, {"question": "upscale or slovenly interior", "gt answer": "upscale(1.00)", "pred answer": "casual", "question_id": 3410705, "best approach": "wiki, concept, image", "verif answer": "upscale", "anno approach": "wiki", "verif wiki answer": "upscale(0.7309)", "verif concept answer": "upscale(0.7275)", "verif image answer": "upscale(0.7077)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341070.jpg"}, {"question": "what type of animal is this", "gt answer": "polar bear(1.00)<br/>elephant(0.60)<br/>sheep(0.60)", "pred answer": "bear", "question_id": 5293605, "best approach": "", "verif answer": "bear", "anno approach": "", "verif wiki answer": "bear(0.7310)", "verif concept answer": "bear(0.7305)", "verif image answer": "bear(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529360.jpg"}, {"question": "what class of animal do these belong", "gt answer": "bovine(1.00)<br/>cow(0.60)", "pred answer": "sheep", "question_id": 5304605, "best approach": "", "verif answer": "calf", "anno approach": "", "verif wiki answer": "sheep(0.6497)", "verif concept answer": "calf(0.7108)", "verif image answer": "calf(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000530460.jpg"}, {"question": "what did the plane just do", "gt answer": "land(1.00)", "pred answer": "take off", "question_id": 4688465, "best approach": "", "verif answer": "take off", "anno approach": "", "verif wiki answer": "take off(0.7307)", "verif concept answer": "take off(0.7233)", "verif image answer": "take off(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000468846.jpg"}, {"question": "what are the items called that are stuck to this fridge", "gt answer": "magnet(1.00)", "pred answer": "fruit", "question_id": 1137255, "best approach": "", "verif answer": "refrigerator", "anno approach": "", "verif wiki answer": "refrigerator(0.7311)", "verif concept answer": "refrigerator(0.7310)", "verif image answer": "refrigerator(0.5409)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113725.jpg"}, {"question": "how long does it take that seed to grow", "gt answer": "4 months(1.00)<br/>2 months(0.60)<br/>3 months(0.60)", "pred answer": "2 weeks", "question_id": 5734795, "best approach": "image", "verif answer": "3 months", "anno approach": "image", "verif wiki answer": "3 months(0.6191)", "verif concept answer": "2 months(0.6070)", "verif image answer": "4 months(0.5837)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000573479.jpg"}, {"question": "what activity was the sign made for", "gt answer": "drive(1.00)<br/>stop(1.00)", "pred answer": "construction", "question_id": 1256845, "best approach": "", "verif answer": "walk", "anno approach": "", "verif wiki answer": "walk(0.6493)", "verif concept answer": "walk(0.6557)", "verif image answer": "walk(0.6552)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125684.jpg"}, {"question": "what kind of bear is this", "gt answer": "grizzly bear(1.00)<br/>brown bear(0.60)<br/>brown(0.60)", "pred answer": "grizzly", "question_id": 2241935, "best approach": "", "verif answer": "grizzly", "anno approach": "", "verif wiki answer": "grizzly(0.7254)", "verif concept answer": "grizzly(0.7269)", "verif image answer": "grizzly(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224193.jpg"}, {"question": "what type of bike is this", "gt answer": "girl bike(1.00)<br/>women(0.60)<br/>bicycle(0.60)", "pred answer": "bicycle", "question_id": 3149835, "best approach": "", "verif answer": "schwinn", "anno approach": "", "verif wiki answer": "schwinn(0.6522)", "verif concept answer": "schwinn(0.6365)", "verif image answer": "schwinn(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314983.jpg"}, {"question": "what type of game is being played", "gt answer": "box(1.00)<br/>wii(1.00)<br/>video(0.60)", "pred answer": "wii", "question_id": 1119225, "best approach": "wiki, concept, image", "verif answer": "wii", "anno approach": "concept, wiki", "verif wiki answer": "wii(0.7090)", "verif concept answer": "wii(0.7051)", "verif image answer": "wii(0.5531)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111922.jpg"}, {"question": "how is this roof fastened to the ground at the four points", "gt answer": "anchor(1.00)<br/>cable(1.00)", "pred answer": "canvas", "question_id": 1003195, "best approach": "", "verif answer": "pole", "anno approach": "", "verif wiki answer": "pole(0.7247)", "verif concept answer": "pole(0.7286)", "verif image answer": "pole(0.6597)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100319.jpg"}, {"question": "where is this taken", "gt answer": "on street(1.00)<br/>london(0.60)<br/>street(0.60)<br/>england(0.60)", "pred answer": "city", "question_id": 4342215, "best approach": "", "verif answer": "city", "anno approach": "", "verif wiki answer": "city(0.6599)", "verif concept answer": "city(0.6973)", "verif image answer": "city(0.6514)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434221.jpg"}, {"question": "what sport is this", "gt answer": "wind surf(1.00)<br/>water ski(0.60)<br/>wakeboarding(0.60)", "pred answer": "water ski", "question_id": 4334545, "best approach": "wiki", "verif answer": "water ski", "anno approach": "wiki", "verif wiki answer": "water ski(0.7311)", "verif concept answer": "kiteboarding(0.7308)", "verif image answer": "kiteboarding(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433454.jpg"}, {"question": "what is in the oven", "gt answer": "doll(1.00)<br/>stuffed animal(0.60)<br/>toy(0.60)", "pred answer": "chicken", "question_id": 5715355, "best approach": "", "verif answer": "baby", "anno approach": "", "verif wiki answer": "baby(0.6421)", "verif concept answer": "baby(0.6432)", "verif image answer": "baby(0.6285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571535.jpg"}, {"question": "which dish is normally the most expensive", "gt answer": "shrimp(1.00)", "pred answer": "bread", "question_id": 1899575, "best approach": "", "verif answer": "seafood", "anno approach": "", "verif wiki answer": "bbq(0.6206)", "verif concept answer": "seafood(0.6693)", "verif image answer": "bbq(0.6153)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000189957.jpg"}, {"question": "what type of cell phone is shown in the picture", "gt answer": "flip phone(1.00)<br/>flip(0.60)<br/>sony(0.60)<br/>motorola(0.60)", "pred answer": "motorola", "question_id": 657325, "best approach": "wiki", "verif answer": "motorola", "anno approach": "wiki", "verif wiki answer": "flip phone(0.5495)", "verif concept answer": "samsung(0.5248)", "verif image answer": "motorola(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065732.jpg"}, {"question": "what part of the body is being stretched out in this image", "gt answer": "arm(1.00)<br/>neck(1.00)", "pred answer": "stomach", "question_id": 2879225, "best approach": "wiki, concept", "verif answer": "neck", "anno approach": "wiki", "verif wiki answer": "neck(0.6520)", "verif concept answer": "neck(0.6388)", "verif image answer": "log(0.6367)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287922.jpg"}, {"question": "what brand of pants is the man wearing", "gt answer": "levis(1.00)<br/>jean(0.60)<br/>gap(0.60)", "pred answer": "denim", "question_id": 4274945, "best approach": "wiki, concept, image", "verif answer": "jean", "anno approach": "wiki", "verif wiki answer": "jean(0.7230)", "verif concept answer": "jean(0.7123)", "verif image answer": "jean(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427494.jpg"}, {"question": "who is in charge of this operating this vehicle", "gt answer": "pilot(1.00)", "pred answer": "engineer", "question_id": 5209425, "best approach": "", "verif answer": "military", "anno approach": "", "verif wiki answer": "military(0.6248)", "verif concept answer": "military(0.6367)", "verif image answer": "military(0.5416)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520942.jpg"}, {"question": "what kind of flower is this", "gt answer": "cactus(0.60)<br/>yellow flower(1.00)", "pred answer": "tulip", "question_id": 1678485, "best approach": "image", "verif answer": "daffodil", "anno approach": "image", "verif wiki answer": "daffodil(0.5181)", "verif concept answer": "daffodil(0.6345)", "verif image answer": "yellow flower(0.5381)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167848.jpg"}, {"question": "when was this sport invented", "gt answer": "1968(1.00)<br/>1948(1.00)", "pred answer": "1948", "question_id": 3055275, "best approach": "wiki, concept", "verif answer": "1968", "anno approach": "", "verif wiki answer": "1968(0.7213)", "verif concept answer": "1968(0.7167)", "verif image answer": "1946(0.7114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305527.jpg"}, {"question": "how often does this animal need flea treatment", "gt answer": "monthly(1.00)<br/>yearly(0.60)", "pred answer": "20 hours", "question_id": 5324915, "best approach": "image", "verif answer": "daily", "anno approach": "image", "verif wiki answer": "daily(0.6886)", "verif concept answer": "yearly(0.6632)", "verif image answer": "monthly(0.5725)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532491.jpg"}, {"question": "what animal stereotypically eats these", "gt answer": "monkey(1.00)<br/>shark(0.60)", "pred answer": "monkey", "question_id": 484745, "best approach": "wiki, concept, image", "verif answer": "monkey", "anno approach": "wiki", "verif wiki answer": "monkey(0.7310)", "verif concept answer": "monkey(0.7192)", "verif image answer": "monkey(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048474.jpg"}, {"question": "in which type of location are all these people located", "gt answer": "stadium(1.00)<br/>baseball stadium(0.60)<br/>baseball field(0.60)<br/>baseball game(0.60)", "pred answer": "baseball field", "question_id": 4155695, "best approach": "image", "verif answer": "baseball field", "anno approach": "image", "verif wiki answer": "baseball field(0.7278)", "verif concept answer": "baseball field(0.7291)", "verif image answer": "stadium(0.7085)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415569.jpg"}, {"question": "during what season would people be found here", "gt answer": "summer(1.00)", "pred answer": "summer", "question_id": 5653815, "best approach": "wiki, concept", "verif answer": "summer", "anno approach": "wiki", "verif wiki answer": "summer(0.7310)", "verif concept answer": "summer(0.7294)", "verif image answer": "sunny(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000565381.jpg"}, {"question": "which tooth is named after this animal", "gt answer": "canine(1.00)", "pred answer": "canine", "question_id": 1165185, "best approach": "wiki, concept, image", "verif answer": "canine", "anno approach": "wiki", "verif wiki answer": "canine(0.7307)", "verif concept answer": "canine(0.7298)", "verif image answer": "canine(0.7226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116518.jpg"}, {"question": "how many people rent one of these trucks in the us annually", "gt answer": "million(1.00)<br/>20000(0.60)", "pred answer": "6", "question_id": 370625, "best approach": "concept, image", "verif answer": "million", "anno approach": "", "verif wiki answer": "thousand(0.6364)", "verif concept answer": "million(0.6413)", "verif image answer": "million(0.6509)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000037062.jpg"}, {"question": "who invented the object featured prominently in this picture", "gt answer": "samuel fox(1.00)", "pred answer": "samuel fox", "question_id": 3558665, "best approach": "wiki, concept, image", "verif answer": "samuel fox", "anno approach": "concept, wiki", "verif wiki answer": "samuel fox(0.7307)", "verif concept answer": "samuel fox(0.7309)", "verif image answer": "samuel fox(0.6804)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355866.jpg"}, {"question": "what is this animal 's popular characteristic", "gt answer": "long neck(1.00)<br/>neck(1.00)", "pred answer": "neck", "question_id": 4849735, "best approach": "wiki, concept, image", "verif answer": "neck", "anno approach": "wiki", "verif wiki answer": "neck(0.7122)", "verif concept answer": "neck(0.7220)", "verif image answer": "neck(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484973.jpg"}, {"question": "how does this object stay aloft", "gt answer": "air(1.00)<br/>wind(0.60)<br/>gravity(0.60)<br/>aerodynamic(0.60)", "pred answer": "engine", "question_id": 3906105, "best approach": "wiki, image", "verif answer": "propeller", "anno approach": "wiki", "verif wiki answer": "aerodynamic(0.5860)", "verif concept answer": "propeller(0.6225)", "verif image answer": "gravity(0.5507)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390610.jpg"}, {"question": "what is keeping the dog from sinking", "gt answer": "float(1.00)<br/>surfboard(0.60)", "pred answer": "boat", "question_id": 3134735, "best approach": "", "verif answer": "boat", "anno approach": "", "verif wiki answer": "boat(0.5347)", "verif concept answer": "boat(0.5116)", "verif image answer": "surf board(0.5005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313473.jpg"}, {"question": "why would we suspect that there is a ski lodge near by", "gt answer": "skier(1.00)", "pred answer": "slope", "question_id": 524725, "best approach": "", "verif answer": "person", "anno approach": "", "verif wiki answer": "person(0.5331)", "verif concept answer": "person(0.5554)", "verif image answer": "person(0.6738)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052472.jpg"}, {"question": "what are the people riding on", "gt answer": "carriage(1.00)<br/>buggy(0.60)", "pred answer": "horse", "question_id": 3673755, "best approach": "wiki, image", "verif answer": "carriage", "anno approach": "image, wiki", "verif wiki answer": "carriage(0.5030)", "verif concept answer": "buggy(0.5015)", "verif image answer": "carriage(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367375.jpg"}, {"question": "what kind of machine is this", "gt answer": "speaker(1.00)<br/>radio(1.00)", "pred answer": "phone", "question_id": 5460215, "best approach": "", "verif answer": "phone", "anno approach": "", "verif wiki answer": "phone(0.5413)", "verif concept answer": "phone(0.5003)", "verif image answer": "phone(0.5072)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546021.jpg"}, {"question": "what does this horse have on its back", "gt answer": "blanket(1.00)<br/>coat(0.60)", "pred answer": "saddle", "question_id": 5276245, "best approach": "wiki, concept, image", "verif answer": "coat", "anno approach": "image, wiki", "verif wiki answer": "coat(0.5238)", "verif concept answer": "coat(0.5105)", "verif image answer": "coat(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527624.jpg"}, {"question": "are horses allowed or not allowed on the road like that", "gt answer": "allowed(1.00)", "pred answer": "danger", "question_id": 644555, "best approach": "image", "verif answer": "1800s", "anno approach": "image", "verif wiki answer": "1800s(0.5362)", "verif concept answer": "1800s(0.5175)", "verif image answer": "allowed(0.5008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064455.jpg"}, {"question": "what standard size bed does this look like", "gt answer": "queen(1.00)<br/>full(1.00)", "pred answer": "queen", "question_id": 1382765, "best approach": "image", "verif answer": "queen", "anno approach": "image", "verif wiki answer": "king(0.7303)", "verif concept answer": "king(0.7305)", "verif image answer": "queen(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138276.jpg"}, {"question": "what is pulling this airplane", "gt answer": "tug(1.00)<br/>vehicle(0.60)<br/>tow(0.60)", "pred answer": "fly", "question_id": 22585, "best approach": "image", "verif answer": "vehicle", "anno approach": "image", "verif wiki answer": "truck(0.6512)", "verif concept answer": "truck(0.6485)", "verif image answer": "vehicle(0.6935)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002258.jpg"}, {"question": "what name do you give to a boat dockage", "gt answer": "dock(1.00)<br/>port(0.60)", "pred answer": "dock", "question_id": 2930865, "best approach": "image", "verif answer": "pier", "anno approach": "image", "verif wiki answer": "pier(0.6591)", "verif concept answer": "pier(0.6876)", "verif image answer": "port(0.6510)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293086.jpg"}, {"question": "what are the kids riding on", "gt answer": "skateboard(1.00)", "pred answer": "skateboard", "question_id": 4458575, "best approach": "concept, image", "verif answer": "skate", "anno approach": "", "verif wiki answer": "skate(0.7177)", "verif concept answer": "skateboard(0.6993)", "verif image answer": "skateboard(0.7068)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445857.jpg"}, {"question": "this small domestic cat is actually related to what large maned animal", "gt answer": "lion(1.00)", "pred answer": "feline", "question_id": 1781785, "best approach": "", "verif answer": "feline", "anno approach": "", "verif wiki answer": "feline(0.7310)", "verif concept answer": "feline(0.7310)", "verif image answer": "feline(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178178.jpg"}, {"question": "what does the cellphone have that current cellphones don't", "gt answer": "button(1.00)<br/>flip(0.60)", "pred answer": "hp", "question_id": 1838825, "best approach": "image", "verif answer": "button", "anno approach": "image", "verif wiki answer": "phone(0.6710)", "verif concept answer": "flip(0.6698)", "verif image answer": "button(0.6803)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183882.jpg"}, {"question": "what appliance would be used to dry these clothes quickly", "gt answer": "dryer(1.00)", "pred answer": "heater", "question_id": 463565, "best approach": "wiki, concept, image", "verif answer": "dryer", "anno approach": "image, wiki", "verif wiki answer": "dryer(0.5585)", "verif concept answer": "dryer(0.5422)", "verif image answer": "dryer(0.5824)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046356.jpg"}, {"question": "what sort of animals would enjoy grazing on this mountainside", "gt answer": "goat(1.00)<br/>sheep(0.60)", "pred answer": "horse", "question_id": 2637705, "best approach": "wiki, concept, image", "verif answer": "goat", "anno approach": "wiki", "verif wiki answer": "goat(0.7197)", "verif concept answer": "goat(0.7297)", "verif image answer": "goat(0.7125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263770.jpg"}, {"question": "what sport is being simulated", "gt answer": "golf(1.00)<br/>cricket(0.60)", "pred answer": "box", "question_id": 4302445, "best approach": "concept, image", "verif answer": "cricket", "anno approach": "", "verif wiki answer": "wii(0.5007)", "verif concept answer": "cricket(0.5001)", "verif image answer": "cricket(0.5021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430244.jpg"}, {"question": "what airline does the plane belong to", "gt answer": "air canada(1.00)", "pred answer": "boeing", "question_id": 3476525, "best approach": "", "verif answer": "virgin", "anno approach": "", "verif wiki answer": "maple leaf(0.6810)", "verif concept answer": "maple leaf(0.6837)", "verif image answer": "virgin(0.6976)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347652.jpg"}, {"question": "what shape is floating in the air", "gt answer": "circle(1.00)<br/>round(1.00)<br/>ball(0.60)", "pred answer": "diamond", "question_id": 4876425, "best approach": "wiki, concept, image", "verif answer": "circle", "anno approach": "concept, wiki", "verif wiki answer": "circle(0.7122)", "verif concept answer": "circle(0.7120)", "verif image answer": "circle(0.6517)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487642.jpg"}, {"question": "a knife that has a blade like this one is called a what kind of knife", "gt answer": "serrated(1.00)", "pred answer": "knife", "question_id": 3043845, "best approach": "wiki, concept, image", "verif answer": "serrated", "anno approach": "concept, wiki", "verif wiki answer": "serrated(0.7033)", "verif concept answer": "serrated(0.7296)", "verif image answer": "serrated(0.6503)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304384.jpg"}, {"question": "how long will the batteries inside this remote last", "gt answer": "3 months(1.00)<br/>1 year(0.60)<br/>4 months(0.60)<br/>2 weeks(0.60)", "pred answer": "5 years", "question_id": 196655, "best approach": "wiki", "verif answer": "1 year", "anno approach": "wiki", "verif wiki answer": "3 months(0.6259)", "verif concept answer": "1 year(0.6353)", "verif image answer": "1 year(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019665.jpg"}, {"question": "what is the brand name of the coffee creamer are they using", "gt answer": "coffee mate(1.00)", "pred answer": "blackberry", "question_id": 5490035, "best approach": "", "verif answer": "dunkin donuts", "anno approach": "", "verif wiki answer": "dunkin donuts(0.5001)", "verif concept answer": "dunkin donuts(0.5001)", "verif image answer": "dunkin donuts(0.5068)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000549003.jpg"}, {"question": "how often do you water these plants", "gt answer": "daily(1.00)", "pred answer": "daily", "question_id": 111885, "best approach": "wiki, concept, image", "verif answer": "daily", "anno approach": "wiki", "verif wiki answer": "daily(0.6944)", "verif concept answer": "daily(0.6500)", "verif image answer": "daily(0.6584)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011188.jpg"}, {"question": "what is the approximate age of this man", "gt answer": "forty(1.00)<br/>50(1.00)<br/>45(0.60)", "pred answer": "12 years", "question_id": 5524615, "best approach": "wiki, concept, image", "verif answer": "50", "anno approach": "wiki", "verif wiki answer": "50(0.6377)", "verif concept answer": "50(0.6360)", "verif image answer": "50(0.6558)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552461.jpg"}, {"question": "what season do you think this is", "gt answer": "autumn(1.00)<br/>fall(1.00)<br/>spring(0.60)", "pred answer": "spring", "question_id": 686365, "best approach": "wiki, concept, image", "verif answer": "fall", "anno approach": "wiki", "verif wiki answer": "fall(0.6515)", "verif concept answer": "fall(0.6599)", "verif image answer": "fall(0.6521)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068636.jpg"}, {"question": "why might someone prefer the health impact of the bread on this sandwich to white bread", "gt answer": "whole grain(1.00)", "pred answer": "0", "question_id": 4013905, "best approach": "wiki, concept", "verif answer": "white", "anno approach": "wiki", "verif wiki answer": "whole grain(0.5020)", "verif concept answer": "whole grain(0.5010)", "verif image answer": "white(0.5103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401390.jpg"}, {"question": "what are those buildings likely for", "gt answer": "apart(1.00)<br/>live(0.60)", "pred answer": "church", "question_id": 2993945, "best approach": "wiki, concept, image", "verif answer": "apart", "anno approach": "image, concept, wiki", "verif wiki answer": "apart(0.6337)", "verif concept answer": "apart(0.6746)", "verif image answer": "apart(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000299394.jpg"}, {"question": "what part of this object will be raised during descent", "gt answer": "wing(0.60)<br/>flap(1.00)", "pred answer": "tail", "question_id": 84535, "best approach": "", "verif answer": "lift", "anno approach": "", "verif wiki answer": "lift(0.5278)", "verif concept answer": "lift(0.5202)", "verif image answer": "lift(0.6943)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008453.jpg"}, {"question": "the feet of animals like these are called what", "gt answer": "paw(1.00)", "pred answer": "bear", "question_id": 2953705, "best approach": "", "verif answer": "canine", "anno approach": "", "verif wiki answer": "canine(0.7311)", "verif concept answer": "canine(0.7311)", "verif image answer": "canine(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295370.jpg"}, {"question": "what brand is the soap on the sink", "gt answer": "dove(1.00)<br/>aloe(0.60)", "pred answer": "crest", "question_id": 4120905, "best approach": "image", "verif answer": "parakeet", "anno approach": "image", "verif wiki answer": "parakeet(0.5028)", "verif concept answer": "parakeet(0.5011)", "verif image answer": "dove(0.5009)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412090.jpg"}, {"question": "what is the best way to ride one of these", "gt answer": "with saddle(1.00)<br/>gallop(0.60)<br/>saddle(0.60)", "pred answer": "row", "question_id": 4586645, "best approach": "", "verif answer": "run", "anno approach": "", "verif wiki answer": "run(0.6786)", "verif concept answer": "run(0.6679)", "verif image answer": "run(0.7006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458664.jpg"}, {"question": "who invented this famous form of transportation", "gt answer": "wright brother(1.00)", "pred answer": "boeing", "question_id": 5727815, "best approach": "", "verif answer": "boeing", "anno approach": "", "verif wiki answer": "boeing(0.7235)", "verif concept answer": "boeing(0.7303)", "verif image answer": "boeing(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572781.jpg"}, {"question": "how often should you do this each day", "gt answer": "twice(1.00)<br/>2(0.60)", "pred answer": "6 months", "question_id": 4156695, "best approach": "wiki, concept", "verif answer": "12", "anno approach": "wiki", "verif wiki answer": "twice(0.5027)", "verif concept answer": "twice(0.5093)", "verif image answer": "12(0.6428)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415669.jpg"}, {"question": "dwhat do these animals do in the winter", "gt answer": "hibernate(1.00)", "pred answer": "hibernate", "question_id": 4433085, "best approach": "wiki, concept, image", "verif answer": "hibernate", "anno approach": "wiki", "verif wiki answer": "hibernate(0.7287)", "verif concept answer": "hibernate(0.7306)", "verif image answer": "hibernate(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443308.jpg"}, {"question": "where can i buy this meal", "gt answer": "cafe(1.00)<br/>diner(0.60)<br/>restaurant(0.60)", "pred answer": "bakery", "question_id": 590365, "best approach": "wiki, concept", "verif answer": "diner", "anno approach": "wiki", "verif wiki answer": "diner(0.7309)", "verif concept answer": "diner(0.7267)", "verif image answer": "deli(0.6615)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059036.jpg"}, {"question": "how many people can this vehicle carry", "gt answer": "12(1.00)<br/>20(1.00)", "pred answer": "many", "question_id": 2073785, "best approach": "", "verif answer": "5", "anno approach": "", "verif wiki answer": "5(0.6348)", "verif concept answer": "5(0.6001)", "verif image answer": "5(0.7213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207378.jpg"}, {"question": "what is the name of this sporting event", "gt answer": "luge(1.00)", "pred answer": "rally", "question_id": 3952165, "best approach": "concept, image", "verif answer": "dirt bike", "anno approach": "concept", "verif wiki answer": "dirt bike(0.7235)", "verif concept answer": "luge(0.7185)", "verif image answer": "luge(0.6841)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395216.jpg"}, {"question": "wow what kind of lense is this", "gt answer": "wide angle(1.00)<br/>clear(0.60)<br/>wide(0.60)", "pred answer": "small", "question_id": 5288495, "best approach": "wiki, concept, image", "verif answer": "wide angle", "anno approach": "concept, wiki", "verif wiki answer": "wide angle(0.6920)", "verif concept answer": "wide angle(0.7275)", "verif image answer": "wide angle(0.6484)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528849.jpg"}, {"question": "can you tell me the dishes before you are good for which parst of the body", "gt answer": "heart(1.00)", "pred answer": "stomach", "question_id": 3172275, "best approach": "wiki", "verif answer": "stomach", "anno approach": "wiki", "verif wiki answer": "heart(0.6620)", "verif concept answer": "stomach(0.7146)", "verif image answer": "stomach(0.7023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317227.jpg"}, {"question": "what type of clouds are those", "gt answer": "cumulus(1.00)<br/>rain(0.60)<br/>stratus(0.60)", "pred answer": "cirrus", "question_id": 3623955, "best approach": "", "verif answer": "cirrus", "anno approach": "", "verif wiki answer": "cirrus(0.7310)", "verif concept answer": "cirrus(0.6887)", "verif image answer": "cirrus(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362395.jpg"}, {"question": "what could this truck be used for", "gt answer": "military(1.00)<br/>transportation(0.60)<br/>haul(0.60)<br/>move(0.60)", "pred answer": "transport", "question_id": 4055055, "best approach": "wiki, concept, image", "verif answer": "haul", "anno approach": "wiki", "verif wiki answer": "move(0.7276)", "verif concept answer": "move(0.7292)", "verif image answer": "haul(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405505.jpg"}, {"question": "what kind of liquid is in the bottles", "gt answer": "wine(1.00)<br/>alcohol(0.60)<br/>beer(0.60)", "pred answer": "wine", "question_id": 4969425, "best approach": "wiki, concept", "verif answer": "wine", "anno approach": "concept, wiki", "verif wiki answer": "wine(0.6832)", "verif concept answer": "wine(0.7237)", "verif image answer": "grape(0.5889)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496942.jpg"}, {"question": "what is the man riding on", "gt answer": "kayak(1.00)<br/>surfboard(0.60)<br/>paddleboard(0.60)", "pred answer": "surfboard", "question_id": 1679635, "best approach": "", "verif answer": "surf board", "anno approach": "", "verif wiki answer": "surf board(0.6484)", "verif concept answer": "surf board(0.6435)", "verif image answer": "row(0.5035)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167963.jpg"}, {"question": "what countries you can find these animals", "gt answer": "africa(1.00)", "pred answer": "kenya", "question_id": 3448175, "best approach": "image", "verif answer": "africa", "anno approach": "image", "verif wiki answer": "north america(0.6708)", "verif concept answer": "kenya(0.7233)", "verif image answer": "africa(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344817.jpg"}, {"question": "", "gt answer": "toaster(0.60)<br/>fried(0.60)<br/>grill(0.60)<br/>grilled(0.60)", "pred answer": "grilled", "question_id": 3908845, "best approach": "wiki, image", "verif answer": "grilled", "anno approach": "", "verif wiki answer": "grilled(0.6479)", "verif concept answer": "fry(0.6309)", "verif image answer": "grilled(0.6302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390884.jpg"}, {"question": "what are the traffic rules when there are four signs like these at each road of crossroads", "gt answer": "4 way stop(1.00)<br/>stop(1.00)", "pred answer": "electric", "question_id": 2531095, "best approach": "", "verif answer": "stop sign", "anno approach": "", "verif wiki answer": "stop sign(0.5014)", "verif concept answer": "stop sign(0.5003)", "verif image answer": "stop sign(0.5012)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253109.jpg"}, {"question": "why is this person holding an umbrella", "gt answer": "rain(1.00)", "pred answer": "rain", "question_id": 155545, "best approach": "", "verif answer": "protection", "anno approach": "", "verif wiki answer": "protection(0.6248)", "verif concept answer": "protection(0.6314)", "verif image answer": "protection(0.6297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015554.jpg"}, {"question": "are these people on vacation or working", "gt answer": "vacation(1.00)<br/>work(0.60)", "pred answer": "fun", "question_id": 3684395, "best approach": "", "verif answer": "wed", "anno approach": "", "verif wiki answer": "study(0.6373)", "verif concept answer": "study(0.6405)", "verif image answer": "wed(0.6869)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000368439.jpg"}, {"question": "what kind of robot is this", "gt answer": "c3po(1.00)", "pred answer": "metal", "question_id": 5010565, "best approach": "", "verif answer": "chimney sweep", "anno approach": "", "verif wiki answer": "chimney sweep(0.7310)", "verif concept answer": "chimney sweep(0.7301)", "verif image answer": "chimney sweep(0.6852)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501056.jpg"}, {"question": "what does the rope on the end of the surfboard do", "gt answer": "attach to surfer(1.00)<br/>tie(0.60)", "pred answer": "longboard", "question_id": 145465, "best approach": "wiki, concept, image", "verif answer": "attach to surfer", "anno approach": "concept, wiki", "verif wiki answer": "attach to surfer(0.7307)", "verif concept answer": "attach to surfer(0.7149)", "verif image answer": "attach to surfer(0.6611)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000014546.jpg"}, {"question": "what job title might you give the woman in this picture", "gt answer": "cook(1.00)<br/>chef(0.60)", "pred answer": "chef", "question_id": 5812835, "best approach": "concept, image", "verif answer": "chef", "anno approach": "", "verif wiki answer": "restaurant(0.5004)", "verif concept answer": "chef(0.5009)", "verif image answer": "chef(0.5014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000581283.jpg"}, {"question": "is the window square or rectangle", "gt answer": "rectangle(1.00)<br/>square(0.60)", "pred answer": "larger", "question_id": 666965, "best approach": "", "verif answer": "round", "anno approach": "", "verif wiki answer": "round(0.5039)", "verif concept answer": "round(0.5031)", "verif image answer": "round(0.5008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000066696.jpg"}, {"question": "what show is the character on the brush in", "gt answer": "high school musical(1.00)<br/>bieber(0.60)", "pred answer": "looney tune", "question_id": 2452045, "best approach": "", "verif answer": "alexis ohanian", "anno approach": "", "verif wiki answer": "alexis ohanian(0.5978)", "verif concept answer": "alexis ohanian(0.5733)", "verif image answer": "alexis ohanian(0.5156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245204.jpg"}, {"question": "what are they making", "gt answer": "salsa(1.00)<br/>food(0.60)<br/>soup(0.60)<br/>salad(0.60)", "pred answer": "apple", "question_id": 1181585, "best approach": "concept, image", "verif answer": "food", "anno approach": "", "verif wiki answer": "stirfry(0.6352)", "verif concept answer": "food(0.6392)", "verif image answer": "food(0.6524)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118158.jpg"}, {"question": "what food group is pictured here", "gt answer": "fruit(1.00)", "pred answer": "market", "question_id": 3440655, "best approach": "", "verif answer": "vegetable", "anno approach": "", "verif wiki answer": "vegetable(0.6367)", "verif concept answer": "vegetable(0.7308)", "verif image answer": "vegetable(0.7115)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344065.jpg"}, {"question": "what vehicle is this", "gt answer": "police car(1.00)<br/>car(0.60)", "pred answer": "truck", "question_id": 2767035, "best approach": "", "verif answer": "audi", "anno approach": "", "verif wiki answer": "audi(0.5925)", "verif concept answer": "truck(0.6447)", "verif image answer": "audi(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276703.jpg"}, {"question": "what manufacture popularized very small mobile phones", "gt answer": "nokia(1.00)", "pred answer": "iphone", "question_id": 1391735, "best approach": "", "verif answer": "razor", "anno approach": "", "verif wiki answer": "razor(0.6677)", "verif concept answer": "razor(0.6629)", "verif image answer": "razor(0.6633)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139173.jpg"}, {"question": "why are there two spoons in the bowl", "gt answer": "share(1.00)", "pred answer": "hungry", "question_id": 5227045, "best approach": "", "verif answer": "make wish", "anno approach": "", "verif wiki answer": "make wish(0.6918)", "verif concept answer": "make wish(0.7225)", "verif image answer": "make wish(0.7213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522704.jpg"}, {"question": "what store is this", "gt answer": "grocery(1.00)", "pred answer": "farmer market", "question_id": 2208235, "best approach": "", "verif answer": "farmer market", "anno approach": "", "verif wiki answer": "farmer market(0.7254)", "verif concept answer": "farmer market(0.7305)", "verif image answer": "farmer market(0.6913)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220823.jpg"}, {"question": "what sport is being shown", "gt answer": "rodeo(1.00)", "pred answer": "horse race", "question_id": 4670635, "best approach": "wiki, concept", "verif answer": "herd", "anno approach": "wiki", "verif wiki answer": "rodeo(0.5966)", "verif concept answer": "rodeo(0.5881)", "verif image answer": "herd(0.6816)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467063.jpg"}, {"question": "what is the blue colored food", "gt answer": "cabbage(1.00)<br/>eggplant(1.00)", "pred answer": "carrot", "question_id": 4822655, "best approach": "", "verif answer": "spinach", "anno approach": "", "verif wiki answer": "spinach(0.5012)", "verif concept answer": "spinach(0.5087)", "verif image answer": "spinach(0.5116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482265.jpg"}, {"question": "who are these people", "gt answer": "president(1.00)", "pred answer": "pilot", "question_id": 2237265, "best approach": "wiki, concept", "verif answer": "president", "anno approach": "wiki", "verif wiki answer": "president(0.6199)", "verif concept answer": "president(0.6140)", "verif image answer": "model(0.5398)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223726.jpg"}, {"question": "what are people called that watch sports from these seats", "gt answer": "fan(1.00)", "pred answer": "stadium", "question_id": 3596865, "best approach": "image", "verif answer": "human", "anno approach": "image", "verif wiki answer": "human(0.6016)", "verif concept answer": "human(0.6009)", "verif image answer": "fan(0.5971)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359686.jpg"}, {"question": "what age child would play with this toy", "gt answer": "3(1.00)<br/>4(1.00)<br/>6(0.60)", "pred answer": "2", "question_id": 794715, "best approach": "", "verif answer": "5", "anno approach": "", "verif wiki answer": "5(0.7299)", "verif concept answer": "5(0.6756)", "verif image answer": "5(0.5614)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079471.jpg"}, {"question": "what time of the day was this picture taken", "gt answer": "morn(1.00)<br/>day(0.60)<br/>afternoon(0.60)", "pred answer": "morn", "question_id": 3401195, "best approach": "wiki", "verif answer": "morn", "anno approach": "wiki", "verif wiki answer": "morn(0.7267)", "verif concept answer": "noon(0.7137)", "verif image answer": "noon(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340119.jpg"}, {"question": "what kind of visual effect has been used on this picture", "gt answer": "black and white(1.00)<br/>shadow(0.60)", "pred answer": "black and white", "question_id": 3265985, "best approach": "", "verif answer": "long exposure", "anno approach": "", "verif wiki answer": "long exposure(0.7224)", "verif concept answer": "ansel adams(0.6509)", "verif image answer": "long exposure(0.6816)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000326598.jpg"}, {"question": "what are they celebrating", "gt answer": "birthday(1.00)", "pred answer": "july 4th", "question_id": 921885, "best approach": "", "verif answer": "birthday cake", "anno approach": "", "verif wiki answer": "birthday cake(0.7167)", "verif concept answer": "birthday cake(0.7249)", "verif image answer": "birthday cake(0.6650)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092188.jpg"}, {"question": "what continent is this", "gt answer": "north america(1.00)<br/>africa(0.60)<br/>america(0.60)", "pred answer": "lake", "question_id": 2585185, "best approach": "wiki, concept, image", "verif answer": "north america", "anno approach": "concept, wiki", "verif wiki answer": "north america(0.7178)", "verif concept answer": "north america(0.7310)", "verif image answer": "north america(0.6552)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258518.jpg"}, {"question": "what was the use of that thing beside the window", "gt answer": "cat toy(1.00)<br/>cat(0.60)", "pred answer": "light", "question_id": 1473925, "best approach": "", "verif answer": "picture", "anno approach": "", "verif wiki answer": "picture(0.5005)", "verif concept answer": "picture(0.5007)", "verif image answer": "bed(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147392.jpg"}, {"question": "what electric instrument is shown", "gt answer": "microphone(1.00)", "pred answer": "amplifier", "question_id": 5150535, "best approach": "", "verif answer": "guitar", "anno approach": "", "verif wiki answer": "guitar(0.7226)", "verif concept answer": "guitar(0.7216)", "verif image answer": "guitar(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515053.jpg"}, {"question": "what other tool may be used to style the hair", "gt answer": "comb(1.00)", "pred answer": "brush", "question_id": 1979175, "best approach": "", "verif answer": "chimney", "anno approach": "", "verif wiki answer": "chimney(0.5009)", "verif concept answer": "chimney(0.5001)", "verif image answer": "bamboo(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197917.jpg"}, {"question": "what do you do when you see this street sign", "gt answer": "stop(1.00)", "pred answer": "stop", "question_id": 5349015, "best approach": "wiki, concept, image", "verif answer": "stop", "anno approach": "concept, wiki", "verif wiki answer": "stop(0.6546)", "verif concept answer": "stop(0.6405)", "verif image answer": "stop(0.5812)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534901.jpg"}, {"question": "which organization owns the local land", "gt answer": "nasa(1.00)", "pred answer": "american", "question_id": 2668095, "best approach": "", "verif answer": "mercedes", "anno approach": "", "verif wiki answer": "mercedes(0.6195)", "verif concept answer": "mercedes(0.6550)", "verif image answer": "mercedes(0.5693)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266809.jpg"}, {"question": "where would you dry your wet hands here", "gt answer": "towel(1.00)", "pred answer": "towel", "question_id": 1787855, "best approach": "wiki, concept", "verif answer": "towel", "anno approach": "wiki", "verif wiki answer": "towel(0.7307)", "verif concept answer": "towel(0.7291)", "verif image answer": "bathroom(0.6182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178785.jpg"}, {"question": "what does the sign depicted mean", "gt answer": "no park(1.00)<br/>no turn(0.60)", "pred answer": "no park", "question_id": 2480665, "best approach": "wiki, concept", "verif answer": "no park", "anno approach": "", "verif wiki answer": "no park(0.7310)", "verif concept answer": "no park(0.7311)", "verif image answer": "do not turn(0.7081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248066.jpg"}, {"question": "where is that train traveling to", "gt answer": "paris(1.00)<br/>chicago(0.60)<br/>city(0.60)", "pred answer": "usa", "question_id": 3639355, "best approach": "wiki, concept", "verif answer": "germany", "anno approach": "wiki", "verif wiki answer": "paris(0.7160)", "verif concept answer": "paris(0.7304)", "verif image answer": "germany(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363935.jpg"}, {"question": "what type of material is this counter made of", "gt answer": "granite(1.00)<br/>marble(1.00)<br/>formica(0.60)", "pred answer": "marble", "question_id": 5099865, "best approach": "wiki, concept, image", "verif answer": "granite", "anno approach": "wiki", "verif wiki answer": "granite(0.7253)", "verif concept answer": "granite(0.7162)", "verif image answer": "granite(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509986.jpg"}, {"question": "how many plants are there", "gt answer": "5(1.00)<br/>0(1.00)", "pred answer": "6", "question_id": 3465475, "best approach": "", "verif answer": "10", "anno approach": "", "verif wiki answer": "10(0.5060)", "verif concept answer": "10(0.6253)", "verif image answer": "4(0.6008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346547.jpg"}, {"question": "what kind of topping is on the donut", "gt answer": "sprinkle(1.00)", "pred answer": "sprinkle", "question_id": 384265, "best approach": "wiki, concept, image", "verif answer": "sprinkle", "anno approach": "image, wiki", "verif wiki answer": "sprinkle(0.6873)", "verif concept answer": "sprinkle(0.6310)", "verif image answer": "sprinkle(0.6824)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038426.jpg"}, {"question": "", "gt answer": "grill(0.60)<br/>oven(0.60)<br/>grilled(0.60)", "pred answer": "grilled", "question_id": 1398655, "best approach": "wiki, concept, image", "verif answer": "grill", "anno approach": "concept", "verif wiki answer": "grill(0.6636)", "verif concept answer": "grill(0.7173)", "verif image answer": "grill(0.6666)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139865.jpg"}, {"question": "what kind of landscape is this", "gt answer": "mountain(1.00)", "pred answer": "mountain", "question_id": 186015, "best approach": "wiki, concept", "verif answer": "alaska", "anno approach": "wiki", "verif wiki answer": "mountain(0.7136)", "verif concept answer": "mountain(0.6906)", "verif image answer": "alaska(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000018601.jpg"}, {"question": "what brand of soda is shown", "gt answer": "coke(1.00)<br/>coca cola(1.00)", "pred answer": "coca cola", "question_id": 1996785, "best approach": "wiki, concept, image", "verif answer": "coca cola", "anno approach": "concept, wiki", "verif wiki answer": "coca cola(0.7299)", "verif concept answer": "coca cola(0.7215)", "verif image answer": "coca cola(0.6759)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199678.jpg"}, {"question": "how fast can the machine the man is in travel", "gt answer": "5 mph(1.00)", "pred answer": "fast", "question_id": 4403105, "best approach": "", "verif answer": "not at all", "anno approach": "", "verif wiki answer": "not at all(0.7259)", "verif concept answer": "not at all(0.7310)", "verif image answer": "not at all(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440310.jpg"}, {"question": "what is the name of the popular confectionery named after the animal in this picture", "gt answer": "gummi bear(1.00)<br/>bear(0.60)", "pred answer": "bear", "question_id": 1153315, "best approach": "wiki, concept, image", "verif answer": "gummi bear", "anno approach": "", "verif wiki answer": "gummi bear(0.7294)", "verif concept answer": "gummi bear(0.7074)", "verif image answer": "gummi bear(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115331.jpg"}, {"question": "is it safe or unsafe to drink the water here", "gt answer": "unsafe(1.00)", "pred answer": "unsafe", "question_id": 2395285, "best approach": "wiki, concept, image", "verif answer": "unsafe", "anno approach": "image, wiki", "verif wiki answer": "unsafe(0.6800)", "verif concept answer": "unsafe(0.6921)", "verif image answer": "unsafe(0.7157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000239528.jpg"}, {"question": "what breed of cat is this", "gt answer": "persian(1.00)<br/>domestic(0.60)<br/>siamese(0.60)", "pred answer": "calico", "question_id": 3107805, "best approach": "wiki, concept", "verif answer": "domestic shorthair", "anno approach": "wiki", "verif wiki answer": "persian(0.6419)", "verif concept answer": "persian(0.6408)", "verif image answer": "domestic shorthair(0.6459)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310780.jpg"}, {"question": "how deep is this place", "gt answer": "1 mile(1.00)", "pred answer": "3 feet", "question_id": 4783515, "best approach": "concept, image", "verif answer": "1 mile", "anno approach": "", "verif wiki answer": "30 feet(0.7286)", "verif concept answer": "1 mile(0.7248)", "verif image answer": "1 mile(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478351.jpg"}, {"question": "", "gt answer": "tabby(0.60)<br/>american longhair(0.60)<br/>house(0.60)", "pred answer": "domestic shorthair", "question_id": 4192735, "best approach": "wiki, concept, image", "verif answer": "american longhair", "anno approach": "wiki", "verif wiki answer": "american longhair(0.7290)", "verif concept answer": "american longhair(0.7030)", "verif image answer": "american longhair(0.6937)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419273.jpg"}, {"question": "the babies of these animals are called what", "gt answer": "calf(1.00)", "pred answer": "foal", "question_id": 1591965, "best approach": "wiki, concept, image", "verif answer": "calf", "anno approach": "wiki", "verif wiki answer": "calf(0.7230)", "verif concept answer": "calf(0.7309)", "verif image answer": "calf(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159196.jpg"}, {"question": "what type of light bulbs are the christmas tree being lit by", "gt answer": "led(1.00)<br/>string(0.60)", "pred answer": "chandelier", "question_id": 2094285, "best approach": "", "verif answer": "wind", "anno approach": "", "verif wiki answer": "wind(0.6232)", "verif concept answer": "wind(0.6379)", "verif image answer": "wind(0.5272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209428.jpg"}, {"question": "what brand of chips are shown in the background", "gt answer": "lay(1.00)", "pred answer": "adidas", "question_id": 891475, "best approach": "", "verif answer": "ruffle", "anno approach": "", "verif wiki answer": "ruffle(0.5493)", "verif concept answer": "ruffle(0.5012)", "verif image answer": "ruffle(0.5442)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089147.jpg"}, {"question": "what long items are used to make this objects move", "gt answer": "oar(1.00)", "pred answer": "motorcycle", "question_id": 738265, "best approach": "wiki, concept, image", "verif answer": "oar", "anno approach": "concept, wiki", "verif wiki answer": "oar(0.7144)", "verif concept answer": "oar(0.7267)", "verif image answer": "oar(0.6692)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073826.jpg"}, {"question": "is the picture taken before or after 1999", "gt answer": "before(1.00)", "pred answer": "after", "question_id": 5093585, "best approach": "", "verif answer": "after", "anno approach": "", "verif wiki answer": "informal(0.6835)", "verif concept answer": "after(0.5999)", "verif image answer": "after(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509358.jpg"}, {"question": "how much effort went into making this scene", "gt answer": "lot(1.00)<br/>3 hours(0.60)<br/>medium(0.60)", "pred answer": "lot", "question_id": 655865, "best approach": "wiki, image", "verif answer": "10 gallons", "anno approach": "wiki", "verif wiki answer": "medium(0.6339)", "verif concept answer": "10 gallons(0.6789)", "verif image answer": "3 hours(0.6337)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065586.jpg"}, {"question": "why might we suspect this plate is served at a restaurant", "gt answer": "presentation(1.00)<br/>lunch(0.60)", "pred answer": "kitchen", "question_id": 4276105, "best approach": "concept, image", "verif answer": "lunch", "anno approach": "concept", "verif wiki answer": "lunch(0.5891)", "verif concept answer": "presentation(0.5816)", "verif image answer": "presentation(0.5463)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427610.jpg"}, {"question": "how was the texture created on the glass used to make this table", "gt answer": "heat(1.00)<br/>blow(0.60)<br/>hammer(0.60)", "pred answer": "calm", "question_id": 4318205, "best approach": "wiki, concept, image", "verif answer": "heat", "anno approach": "concept, wiki", "verif wiki answer": "heat(0.7214)", "verif concept answer": "heat(0.6689)", "verif image answer": "heat(0.6219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431820.jpg"}, {"question": "the batter is now headed to where", "gt answer": "first base(1.00)", "pred answer": "first base", "question_id": 5641835, "best approach": "wiki, concept, image", "verif answer": "first base", "anno approach": "concept, wiki", "verif wiki answer": "first base(0.6729)", "verif concept answer": "first base(0.6960)", "verif image answer": "first base(0.6321)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564183.jpg"}, {"question": "what trick is being performed", "gt answer": "jump(1.00)<br/>skateboard(0.60)", "pred answer": "skateboard", "question_id": 4476945, "best approach": "wiki, image", "verif answer": "skateboard", "anno approach": "image, wiki", "verif wiki answer": "skateboard(0.6454)", "verif concept answer": "jumped(0.6484)", "verif image answer": "skateboard(0.6823)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447694.jpg"}, {"question": "why is the man near anothers neck", "gt answer": "tie(1.00)", "pred answer": "clean teeth", "question_id": 5436635, "best approach": "", "verif answer": "silk", "anno approach": "", "verif wiki answer": "silk(0.6029)", "verif concept answer": "silk(0.6628)", "verif image answer": "windsor(0.6069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543663.jpg"}, {"question": "how many hours on average do these animals sleep daily", "gt answer": "16(1.00)<br/>10(0.60)", "pred answer": "5", "question_id": 1156425, "best approach": "concept", "verif answer": "18", "anno approach": "concept", "verif wiki answer": "12(0.6124)", "verif concept answer": "10(0.6295)", "verif image answer": "18(0.6419)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115642.jpg"}, {"question": "what is a predator of this species", "gt answer": "lion(1.00)<br/>wolf(0.60)", "pred answer": "lion", "question_id": 1928165, "best approach": "wiki, concept, image", "verif answer": "lion", "anno approach": "image, concept, wiki", "verif wiki answer": "lion(0.6398)", "verif concept answer": "lion(0.7305)", "verif image answer": "lion(0.7248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000192816.jpg"}, {"question": "what train company is this", "gt answer": "canadian pacific(1.00)<br/>santa fe(0.60)", "pred answer": "steam", "question_id": 5156555, "best approach": "wiki, concept, image", "verif answer": "santa fe", "anno approach": "", "verif wiki answer": "santa fe(0.7292)", "verif concept answer": "santa fe(0.7309)", "verif image answer": "santa fe(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515655.jpg"}, {"question": "what is this baby dressed as", "gt answer": "lion(1.00)<br/>dog(0.60)<br/>bear(0.60)", "pred answer": "teddy bear", "question_id": 410565, "best approach": "wiki", "verif answer": "lion", "anno approach": "wiki", "verif wiki answer": "lion(0.5645)", "verif concept answer": "bear(0.5241)", "verif image answer": "teddy bear(0.5595)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041056.jpg"}, {"question": "who is the world leader in this sport", "gt answer": "bode miller(1.00)<br/>sweden(0.60)", "pred answer": "shaun white", "question_id": 4854845, "best approach": "wiki, concept", "verif answer": "bode miller", "anno approach": "wiki", "verif wiki answer": "bode miller(0.5237)", "verif concept answer": "bode miller(0.5033)", "verif image answer": "sweden(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485484.jpg"}, {"question": "what company does this plane belong to", "gt answer": "csa(1.00)", "pred answer": "american", "question_id": 5749445, "best approach": "wiki, concept", "verif answer": "delta", "anno approach": "", "verif wiki answer": "csa(0.7085)", "verif concept answer": "csa(0.7087)", "verif image answer": "delta(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000574944.jpg"}, {"question": "how long does yellow fruit last before going bad", "gt answer": "4 days(1.00)<br/>1 week(1.00)", "pred answer": "2 weeks", "question_id": 4815155, "best approach": "", "verif answer": "1 month", "anno approach": "", "verif wiki answer": "1 month(0.6827)", "verif concept answer": "1 month(0.6992)", "verif image answer": "1 month(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481515.jpg"}, {"question": "what are the boats tied to", "gt answer": "dock(1.00)<br/>pier(0.60)", "pred answer": "anchor", "question_id": 5669355, "best approach": "", "verif answer": "perch", "anno approach": "", "verif wiki answer": "fish(0.5000)", "verif concept answer": "fish(0.5001)", "verif image answer": "perch(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566935.jpg"}, {"question": "what meal is this typically eaten for", "gt answer": "lunch(1.00)", "pred answer": "lunch", "question_id": 2418365, "best approach": "", "verif answer": "breakfast", "anno approach": "", "verif wiki answer": "breakfast(0.7305)", "verif concept answer": "breakfast(0.6926)", "verif image answer": "breakfast(0.6023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241836.jpg"}, {"question": "in this sport what type of shirt is this person wearing", "gt answer": "t shirt(1.00)<br/>jersey(0.60)<br/>tennis(0.60)", "pred answer": "button down", "question_id": 1690035, "best approach": "wiki, concept, image", "verif answer": "t shirt", "anno approach": "wiki", "verif wiki answer": "t shirt(0.5959)", "verif concept answer": "t shirt(0.5076)", "verif image answer": "t shirt(0.5006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169003.jpg"}, {"question": "how many liquid gallons can those blue barrels hold", "gt answer": "30(1.00)<br/>40(0.60)<br/>50(0.60)", "pred answer": "lot", "question_id": 3222685, "best approach": "wiki, concept, image", "verif answer": "30", "anno approach": "wiki", "verif wiki answer": "30(0.7266)", "verif concept answer": "30(0.6568)", "verif image answer": "30(0.6411)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322268.jpg"}, {"question": "what kind of day is this", "gt answer": "overcast(1.00)<br/>cloudy(1.00)<br/>rainy(0.60)", "pred answer": "cloudy", "question_id": 707025, "best approach": "wiki, concept, image", "verif answer": "cloudy", "anno approach": "wiki", "verif wiki answer": "cloudy(0.7310)", "verif concept answer": "cloudy(0.7310)", "verif image answer": "cloudy(0.7194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070702.jpg"}, {"question": "how is the person in the bed feeling", "gt answer": "sick(1.00)<br/>tired(0.60)", "pred answer": "happy", "question_id": 5408315, "best approach": "wiki", "verif answer": "sleep", "anno approach": "wiki", "verif wiki answer": "tired(0.6817)", "verif concept answer": "sleep(0.6939)", "verif image answer": "sleep(0.7225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540831.jpg"}, {"question": "what shape is the shelter over the riders heads", "gt answer": "dome(1.00)<br/>arch(0.60)", "pred answer": "round", "question_id": 4854915, "best approach": "", "verif answer": "red", "anno approach": "", "verif wiki answer": "red(0.7310)", "verif concept answer": "cloud(0.7151)", "verif image answer": "cloud(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485491.jpg"}, {"question": "what is the red piece of furniture called", "gt answer": "couch(1.00)<br/>sofa(0.60)<br/>loveseat(0.60)", "pred answer": "couch", "question_id": 2083795, "best approach": "wiki, concept", "verif answer": "couch", "anno approach": "concept, wiki", "verif wiki answer": "couch(0.5987)", "verif concept answer": "couch(0.7232)", "verif image answer": "loveseat(0.7198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208379.jpg"}, {"question": "what is the object in the woman 's hand used for", "gt answer": "kid(0.60)<br/>comfort(1.00)", "pred answer": "brush", "question_id": 158975, "best approach": "wiki, concept, image", "verif answer": "comfort", "anno approach": "image, wiki", "verif wiki answer": "comfort(0.6485)", "verif concept answer": "comfort(0.6428)", "verif image answer": "comfort(0.7177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015897.jpg"}, {"question": "cat gut is an item used to make what thing seen here", "gt answer": "tennis racket(1.00)<br/>string(0.60)", "pred answer": "tennis ball", "question_id": 4539685, "best approach": "concept", "verif answer": "string", "anno approach": "concept", "verif wiki answer": "string(0.6351)", "verif concept answer": "tennis racket(0.6309)", "verif image answer": "string(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453968.jpg"}, {"question": "this speicies of animal is famous for what", "gt answer": "be tall(1.00)<br/>long neck(1.00)", "pred answer": "giraffe", "question_id": 1762635, "best approach": "concept", "verif answer": "neck", "anno approach": "concept", "verif wiki answer": "neck(0.7279)", "verif concept answer": "be tall(0.6636)", "verif image answer": "neck(0.7248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176263.jpg"}, {"question": "what type of flowers are in the pot", "gt answer": "pansy(0.60)<br/>daffodil(0.60)<br/>daisy(1.00)", "pred answer": "rose", "question_id": 2148345, "best approach": "", "verif answer": "marigold", "anno approach": "", "verif wiki answer": "marigold(0.5012)", "verif concept answer": "marigold(0.5008)", "verif image answer": "sunflower(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214834.jpg"}, {"question": "what kind of train is this", "gt answer": "trolley(1.00)<br/>passenger(0.60)<br/>commuter(0.60)", "pred answer": "double decker", "question_id": 2502785, "best approach": "concept, image", "verif answer": "commuter", "anno approach": "image", "verif wiki answer": "trolly(0.7037)", "verif concept answer": "passenger(0.6629)", "verif image answer": "commuter(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250278.jpg"}, {"question": "how are these vehicles powered", "gt answer": "gas(1.00)<br/>diesel(0.60)<br/>engine(0.60)", "pred answer": "diesel", "question_id": 1297165, "best approach": "concept, image", "verif answer": "diesel", "anno approach": "", "verif wiki answer": "gasoline(0.6794)", "verif concept answer": "diesel(0.7220)", "verif image answer": "diesel(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129716.jpg"}, {"question": "what brand is this blender", "gt answer": "oster(1.00)<br/>whirlpool(0.60)", "pred answer": "delta", "question_id": 710055, "best approach": "wiki, concept", "verif answer": "oster", "anno approach": "wiki", "verif wiki answer": "oster(0.7309)", "verif concept answer": "oster(0.7293)", "verif image answer": "maytag(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071005.jpg"}, {"question": "", "gt answer": "dock(0.60)<br/>fish(0.60)", "pred answer": "boat", "question_id": 4696395, "best approach": "", "verif answer": "row", "anno approach": "", "verif wiki answer": "row(0.6297)", "verif concept answer": "row(0.6629)", "verif image answer": "row(0.6183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469639.jpg"}, {"question": "what are those colorful items to be used for", "gt answer": "canoe(1.00)<br/>surf(1.00)", "pred answer": "knit", "question_id": 4088545, "best approach": "concept", "verif answer": "row", "anno approach": "concept", "verif wiki answer": "row(0.7101)", "verif concept answer": "surf(0.7075)", "verif image answer": "row(0.7095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408854.jpg"}, {"question": "what is this room used for", "gt answer": "work(0.60)<br/>sleep(1.00)<br/>study(0.60)<br/>office(0.60)", "pred answer": "work", "question_id": 3404405, "best approach": "concept, image", "verif answer": "sleep", "anno approach": "image", "verif wiki answer": "work(0.6811)", "verif concept answer": "sleep(0.6948)", "verif image answer": "sleep(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340440.jpg"}, {"question": "who makes that microwave", "gt answer": "ge(1.00)<br/>general electric(0.60)<br/>factory(0.60)<br/>sharp(0.60)", "pred answer": "ge", "question_id": 475445, "best approach": "wiki, concept, image", "verif answer": "ge", "anno approach": "wiki", "verif wiki answer": "ge(0.7231)", "verif concept answer": "ge(0.7235)", "verif image answer": "ge(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047544.jpg"}, {"question": "what kind of grass is the field these men are standing on called", "gt answer": "turf(1.00)<br/>park(0.60)", "pred answer": "field", "question_id": 1937095, "best approach": "wiki, concept, image", "verif answer": "turf", "anno approach": "wiki", "verif wiki answer": "turf(0.6445)", "verif concept answer": "turf(0.6263)", "verif image answer": "turf(0.6548)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193709.jpg"}, {"question": "what type of fish bait do these flying objects look like", "gt answer": "worm(1.00)", "pred answer": "geese", "question_id": 2401985, "best approach": "", "verif answer": "seed", "anno approach": "", "verif wiki answer": "mice(0.6240)", "verif concept answer": "seed(0.6316)", "verif image answer": "seed(0.6350)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240198.jpg"}, {"question": "what type of pitch is the pitcher throwing", "gt answer": "curve ball(1.00)<br/>baseball(0.60)<br/>fastball(0.60)", "pred answer": "forehand", "question_id": 1808185, "best approach": "wiki", "verif answer": "curve ball", "anno approach": "wiki", "verif wiki answer": "curve ball(0.7310)", "verif concept answer": "fastball(0.7307)", "verif image answer": "overhand(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180818.jpg"}, {"question": "what is this object used for", "gt answer": "sleep(1.00)<br/>hotel(0.60)", "pred answer": "sleep", "question_id": 4793605, "best approach": "wiki, concept, image", "verif answer": "sleep", "anno approach": "wiki", "verif wiki answer": "sleep(0.7209)", "verif concept answer": "sleep(0.6775)", "verif image answer": "sleep(0.7002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479360.jpg"}, {"question": "what fairy tale would you find these characters in that has a girl with goldilocks", "gt answer": "goldilocks and 3 bears(1.00)", "pred answer": "mary had little lamb", "question_id": 5297955, "best approach": "image", "verif answer": "double decker", "anno approach": "image", "verif wiki answer": "double decker(0.5036)", "verif concept answer": "double decker(0.5012)", "verif image answer": "goldilocks and 3 bears(0.5007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529795.jpg"}, {"question": "the red and white pole design seen here is also associated with which profession", "gt answer": "barber(1.00)<br/>santa(0.60)", "pred answer": "internet", "question_id": 5546885, "best approach": "", "verif answer": "military", "anno approach": "", "verif wiki answer": "military(0.6566)", "verif concept answer": "military(0.6614)", "verif image answer": "military(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554688.jpg"}, {"question": "what fruit is this beverage made from", "gt answer": "grape(1.00)", "pred answer": "lemonade", "question_id": 3540705, "best approach": "", "verif answer": "alcohol", "anno approach": "", "verif wiki answer": "alcohol(0.6399)", "verif concept answer": "alcohol(0.5920)", "verif image answer": "alcohol(0.6332)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354070.jpg"}, {"question": "what type of food does this animal eat", "gt answer": "berry(1.00)<br/>fish(0.60)<br/>meat(0.60)<br/>omnivore(0.60)", "pred answer": "berry", "question_id": 274395, "best approach": "wiki, concept, image", "verif answer": "berry", "anno approach": "image, wiki", "verif wiki answer": "berry(0.6846)", "verif concept answer": "berry(0.6613)", "verif image answer": "berry(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027439.jpg"}, {"question": "what sports could this man play at this location", "gt answer": "volleyball(1.00)", "pred answer": "skateboard", "question_id": 4787415, "best approach": "wiki, concept, image", "verif answer": "volleyball", "anno approach": "image, wiki", "verif wiki answer": "volleyball(0.6841)", "verif concept answer": "volleyball(0.5209)", "verif image answer": "volleyball(0.7147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478741.jpg"}, {"question": "what does one need to fly this vehicle", "gt answer": "license(1.00)<br/>pilot(0.60)<br/>engine(0.60)", "pred answer": "fly", "question_id": 1797535, "best approach": "wiki, concept, image", "verif answer": "pilot", "anno approach": "image, wiki", "verif wiki answer": "pilot(0.6373)", "verif concept answer": "engine(0.5796)", "verif image answer": "engine(0.6116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000179753.jpg"}, {"question": "the tiled area behind the stove is referred to as the what", "gt answer": "backsplash(1.00)", "pred answer": "tile", "question_id": 4504785, "best approach": "", "verif answer": "tile", "anno approach": "", "verif wiki answer": "tile(0.7271)", "verif concept answer": "tile(0.7287)", "verif image answer": "contemporary(0.7110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450478.jpg"}, {"question": "what is this room used for", "gt answer": "shower(1.00)<br/>bath(0.60)<br/>bathroom(0.60)", "pred answer": "wash", "question_id": 3271915, "best approach": "image", "verif answer": "shower", "anno approach": "image", "verif wiki answer": "bath(0.5004)", "verif concept answer": "bath(0.5006)", "verif image answer": "shower(0.5069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327191.jpg"}, {"question": "what is the name of the bird with two legs", "gt answer": "ostrich(1.00)", "pred answer": "pelican", "question_id": 2594465, "best approach": "wiki, concept, image", "verif answer": "ostrich", "anno approach": "concept, wiki", "verif wiki answer": "ostrich(0.6669)", "verif concept answer": "ostrich(0.6995)", "verif image answer": "ostrich(0.6648)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259446.jpg"}, {"question": "how is this item prepared", "gt answer": "baked(1.00)", "pred answer": "oven", "question_id": 1786375, "best approach": "wiki", "verif answer": "baked", "anno approach": "wiki", "verif wiki answer": "baked(0.7309)", "verif concept answer": "steamed(0.6949)", "verif image answer": "oven(0.6626)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178637.jpg"}, {"question": "what type of drinking vessel is that bear pushing", "gt answer": "coffee cup(1.00)<br/>mug(0.60)<br/>cup(0.60)", "pred answer": "mug", "question_id": 1230285, "best approach": "wiki, concept, image", "verif answer": "mug", "anno approach": "concept, wiki", "verif wiki answer": "mug(0.7296)", "verif concept answer": "mug(0.7306)", "verif image answer": "mug(0.6539)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123028.jpg"}, {"question": "what city is this from", "gt answer": "philadelphia(1.00)<br/>london(0.60)", "pred answer": "london", "question_id": 1960495, "best approach": "wiki, image", "verif answer": "london", "anno approach": "wiki", "verif wiki answer": "philadelphia(0.6320)", "verif concept answer": "london(0.6531)", "verif image answer": "philadelphia(0.6483)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196049.jpg"}, {"question": "what is the olympic version of this called", "gt answer": "slalom(1.00)<br/>downhill(0.60)<br/>cross country(0.60)", "pred answer": "ski", "question_id": 4826945, "best approach": "wiki, concept, image", "verif answer": "downhill", "anno approach": "concept, wiki", "verif wiki answer": "downhill(0.5531)", "verif concept answer": "downhill(0.5788)", "verif image answer": "downhill(0.5017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482694.jpg"}, {"question": "where are they laying", "gt answer": "bed(1.00)", "pred answer": "mattress", "question_id": 1316655, "best approach": "wiki, concept", "verif answer": "bed", "anno approach": "concept, wiki", "verif wiki answer": "bed(0.5847)", "verif concept answer": "bed(0.7129)", "verif image answer": "bunk bed(0.5041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000131665.jpg"}, {"question": "what type of bear is this", "gt answer": "teddy(1.00)<br/>teddy bear(0.60)<br/>stuffed(0.60)", "pred answer": "teddy bear", "question_id": 2502045, "best approach": "wiki, concept, image", "verif answer": "teddy bear", "anno approach": "wiki", "verif wiki answer": "teddy bear(0.6374)", "verif concept answer": "teddy bear(0.6364)", "verif image answer": "teddy bear(0.6516)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250204.jpg"}, {"question": "what is the gestation period of this animal", "gt answer": "13 months(1.00)<br/>10 months(0.60)<br/>year(0.60)<br/>3 months(0.60)", "pred answer": "22 months", "question_id": 4536465, "best approach": "wiki, concept", "verif answer": "13 months", "anno approach": "wiki", "verif wiki answer": "13 months(0.6362)", "verif concept answer": "13 months(0.6498)", "verif image answer": "2 months(0.6460)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453646.jpg"}, {"question": "what is the name of the garment this individual is wearing", "gt answer": "wetsuit(1.00)", "pred answer": "wet suit", "question_id": 608735, "best approach": "", "verif answer": "wet suit", "anno approach": "", "verif wiki answer": "wet suit(0.7280)", "verif concept answer": "wet suit(0.7250)", "verif image answer": "wet suit(0.6929)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060873.jpg"}, {"question": "is this sort of carpet usually associated with the western or eastern hemisphere", "gt answer": "eastern(1.00)<br/>western(0.60)", "pred answer": "right", "question_id": 3026805, "best approach": "wiki", "verif answer": "western", "anno approach": "wiki", "verif wiki answer": "eastern(0.6751)", "verif concept answer": "west(0.5181)", "verif image answer": "western(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302680.jpg"}, {"question": "is the scene in a rural or urban area", "gt answer": "rural(1.00)", "pred answer": "rural", "question_id": 2959405, "best approach": "wiki, concept, image", "verif answer": "rural", "anno approach": "concept, wiki", "verif wiki answer": "rural(0.7154)", "verif concept answer": "rural(0.7308)", "verif image answer": "rural(0.6917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295940.jpg"}, {"question": "what comes out of the black box with the green screen", "gt answer": "music(1.00)<br/>air(0.60)<br/>cd(0.60)", "pred answer": "coin", "question_id": 5501815, "best approach": "", "verif answer": "headphone", "anno approach": "", "verif wiki answer": "headphone(0.7294)", "verif concept answer": "headphone(0.7310)", "verif image answer": "headphone(0.6792)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550181.jpg"}, {"question": "what is the weather", "gt answer": "foggy(1.00)<br/>storm(0.60)<br/>wood(0.60)", "pred answer": "cloudy", "question_id": 760015, "best approach": "wiki, concept, image", "verif answer": "storm", "anno approach": "image, concept, wiki", "verif wiki answer": "wood(0.6824)", "verif concept answer": "storm(0.7295)", "verif image answer": "wood(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076001.jpg"}, {"question": "which brand of computer is this", "gt answer": "ibm(1.00)<br/>dell(0.60)<br/>mac(0.60)", "pred answer": "ibm", "question_id": 5513445, "best approach": "wiki, concept", "verif answer": "apple", "anno approach": "wiki", "verif wiki answer": "mac(0.6531)", "verif concept answer": "mac(0.6821)", "verif image answer": "apple(0.7108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000551344.jpg"}, {"question": "what is the fixture on the table used for", "gt answer": "light(1.00)", "pred answer": "sit", "question_id": 5489645, "best approach": "wiki, concept, image", "verif answer": "light", "anno approach": "image, wiki", "verif wiki answer": "light(0.5333)", "verif concept answer": "light(0.5324)", "verif image answer": "light(0.5693)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548964.jpg"}, {"question": "what profession would make these", "gt answer": "baker(1.00)", "pred answer": "baker", "question_id": 3164075, "best approach": "concept", "verif answer": "cook", "anno approach": "concept", "verif wiki answer": "cook(0.5006)", "verif concept answer": "baker(0.5001)", "verif image answer": "cook(0.7114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316407.jpg"}, {"question": "does this train carry freight or passengers", "gt answer": "passenger(1.00)<br/>freight(0.60)", "pred answer": "passenger", "question_id": 3151045, "best approach": "wiki", "verif answer": "freight", "anno approach": "wiki", "verif wiki answer": "freight(0.7308)", "verif concept answer": "people(0.6975)", "verif image answer": "people(0.6011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315104.jpg"}, {"question": "what kind of building is at the far left of this picture", "gt answer": "church(1.00)<br/>clock(0.60)", "pred answer": "court", "question_id": 5644755, "best approach": "", "verif answer": "clock tower", "anno approach": "", "verif wiki answer": "clock tower(0.7310)", "verif concept answer": "clock tower(0.7296)", "verif image answer": "clock tower(0.6880)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564475.jpg"}, {"question": "what is the man putting on", "gt answer": "cloth(1.00)<br/>coat(0.60)<br/>shirt(0.60)", "pred answer": "trunk", "question_id": 2527595, "best approach": "image", "verif answer": "cloth", "anno approach": "image", "verif wiki answer": "wool(0.5053)", "verif concept answer": "wool(0.5114)", "verif image answer": "cloth(0.5947)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252759.jpg"}]
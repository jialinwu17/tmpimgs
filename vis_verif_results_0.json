[{"question": "is this country rich or poor", "gt answer": "poor(1.00)", "pred answer": "poor", "question_id": 698095, "best approach": "wiki, concept, image", "verif answer": "poor", "anno approach": "wiki", "verif wiki answer": "poor(0.7311)", "verif concept answer": "poor(0.7311)", "verif image answer": "poor(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069809.jpg"}, {"question": "what sport is being played", "gt answer": "hockey(1.00)", "pred answer": "baseball", "question_id": 3557865, "best approach": "", "verif answer": "basketball", "anno approach": "", "verif wiki answer": "basketball(0.5002)", "verif concept answer": "basketball(0.5003)", "verif image answer": "basketball(0.5649)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355786.jpg"}, {"question": "is he riding fast or slow", "gt answer": "fast(1.00)", "pred answer": "fast", "question_id": 2741605, "best approach": "wiki, concept, image", "verif answer": "fast", "anno approach": "wiki", "verif wiki answer": "fast(0.6412)", "verif concept answer": "fast(0.6489)", "verif image answer": "fast(0.6259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274160.jpg"}, {"question": "why might one assume that at least some of these people listened to a weather forecast before going out", "gt answer": "they have umbrella(1.00)<br/>umbrella(0.60)", "pred answer": "rain", "question_id": 4048525, "best approach": "image", "verif answer": "rain", "anno approach": "image", "verif wiki answer": "rain(0.7311)", "verif concept answer": "rain(0.7311)", "verif image answer": "umbrella(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404852.jpg"}, {"question": "how windy was it to turn this umbrella inside out", "gt answer": "very windy(1.00)<br/>extremely(0.60)<br/>very(0.60)", "pred answer": "fast", "question_id": 5776535, "best approach": "wiki, concept, image", "verif answer": "very windy", "anno approach": "", "verif wiki answer": "very windy(0.6987)", "verif concept answer": "very windy(0.7307)", "verif image answer": "very windy(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000577653.jpg"}, {"question": "what is the purpose of the hanging object", "gt answer": "light(1.00)", "pred answer": "tell time", "question_id": 5317255, "best approach": "", "verif answer": "filter", "anno approach": "", "verif wiki answer": "filter(0.6208)", "verif concept answer": "filter(0.6523)", "verif image answer": "filter(0.6199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531725.jpg"}, {"question": "what makes that liquid look blue", "gt answer": "algae(1.00)<br/>light(0.60)<br/>reflection of sky(0.60)", "pred answer": "algae", "question_id": 1833215, "best approach": "wiki, concept", "verif answer": "algae", "anno approach": "wiki", "verif wiki answer": "algae(0.7049)", "verif concept answer": "algae(0.7143)", "verif image answer": "sun(0.6569)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183321.jpg"}, {"question": "what type of shirt is the blue one known as", "gt answer": "button up(1.00)<br/>flannel(0.60)", "pred answer": "jean", "question_id": 5016255, "best approach": "", "verif answer": "jean", "anno approach": "", "verif wiki answer": "jean(0.6550)", "verif concept answer": "jean(0.7194)", "verif image answer": "jean(0.5336)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501625.jpg"}, {"question": "can you guess what operating system this laptop runs on", "gt answer": "ios(1.00)<br/>mac(0.60)<br/>window(0.60)", "pred answer": "window", "question_id": 1147295, "best approach": "wiki, concept, image", "verif answer": "mac", "anno approach": "image, wiki", "verif wiki answer": "mac(0.5247)", "verif concept answer": "mac(0.5090)", "verif image answer": "mac(0.6371)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114729.jpg"}, {"question": "what breed of cat is this", "gt answer": "ragdoll(1.00)<br/>persian(0.60)", "pred answer": "calico", "question_id": 2736075, "best approach": "", "verif answer": "calico", "anno approach": "", "verif wiki answer": "calico(0.7303)", "verif concept answer": "calico(0.7310)", "verif image answer": "calico(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273607.jpg"}, {"question": "is the dog sad or just sleepy", "gt answer": "sleepy(1.00)<br/>sad(0.60)", "pred answer": "tired", "question_id": 4999305, "best approach": "", "verif answer": "tired", "anno approach": "", "verif wiki answer": "tired(0.7310)", "verif concept answer": "tired(0.7311)", "verif image answer": "tired(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499930.jpg"}, {"question": "what kitchen machine is being used to make food", "gt answer": "blender(1.00)<br/>chopper(0.60)<br/>mixer(0.60)", "pred answer": "oven", "question_id": 1144685, "best approach": "wiki, image", "verif answer": "mixer", "anno approach": "image", "verif wiki answer": "mixer(0.6416)", "verif concept answer": "stove(0.6204)", "verif image answer": "mixer(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114468.jpg"}, {"question": "what quadruped has lent a part of its body to furnish the name of this hairdo", "gt answer": "pony tail(1.00)<br/>pony(1.00)<br/>horse(0.60)", "pred answer": "head", "question_id": 1378295, "best approach": "wiki, concept, image", "verif answer": "pony", "anno approach": "concept, wiki", "verif wiki answer": "pony(0.6491)", "verif concept answer": "pony(0.6496)", "verif image answer": "pony(0.5016)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000137829.jpg"}, {"question": "when was the first of these lights installed", "gt answer": "1914(1.00)<br/>1912(0.60)", "pred answer": "1970", "question_id": 533305, "best approach": "wiki, concept", "verif answer": "1914", "anno approach": "wiki", "verif wiki answer": "1914(0.7296)", "verif concept answer": "1914(0.7296)", "verif image answer": "1912(0.7055)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053330.jpg"}, {"question": "what is the relationship between these two animals", "gt answer": "family(1.00)<br/>mother and child(1.00)", "pred answer": "mother and son", "question_id": 1889225, "best approach": "", "verif answer": "0", "anno approach": "", "verif wiki answer": "0(0.5359)", "verif concept answer": "0(0.5110)", "verif image answer": "close(0.5014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188922.jpg"}, {"question": "where do you think we are", "gt answer": "baseball stadium(1.00)<br/>school(0.60)<br/>texas(0.60)<br/>america(0.60)", "pred answer": "street", "question_id": 829805, "best approach": "wiki, concept, image", "verif answer": "texas", "anno approach": "concept, wiki", "verif wiki answer": "texas(0.6870)", "verif concept answer": "texas(0.7200)", "verif image answer": "texas(0.6431)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082980.jpg"}, {"question": "what type of exercises can you do to work out this portion of the body", "gt answer": "pushups(1.00)", "pred answer": "brush", "question_id": 85925, "best approach": "wiki, concept, image", "verif answer": "pushups", "anno approach": "image, concept", "verif wiki answer": "pushups(0.6731)", "verif concept answer": "pushups(0.7281)", "verif image answer": "pushups(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008592.jpg"}, {"question": "what are the boxes for", "gt answer": "storage(1.00)", "pred answer": "travel", "question_id": 4293185, "best approach": "", "verif answer": "cook", "anno approach": "", "verif wiki answer": "repair(0.7273)", "verif concept answer": "repair(0.7186)", "verif image answer": "cook(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429318.jpg"}, {"question": "what process is used to make most of the foods in this image", "gt answer": "fermentation(1.00)<br/>age(0.60)<br/>mix(0.60)", "pred answer": "bake", "question_id": 586095, "best approach": "", "verif answer": "bake", "anno approach": "", "verif wiki answer": "bake(0.6646)", "verif concept answer": "bake(0.6309)", "verif image answer": "bake(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058609.jpg"}, {"question": "what year is this plane", "gt answer": "1945(1.00)<br/>1946(0.60)<br/>1948(0.60)", "pred answer": "1940", "question_id": 5265065, "best approach": "wiki, concept, image", "verif answer": "1945", "anno approach": "wiki", "verif wiki answer": "1945(0.7225)", "verif concept answer": "1945(0.7049)", "verif image answer": "1945(0.6889)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526506.jpg"}, {"question": "what buildings are surmounted by steeples", "gt answer": "church(1.00)", "pred answer": "court", "question_id": 749275, "best approach": "wiki, concept, image", "verif answer": "church", "anno approach": "image, wiki", "verif wiki answer": "church(0.6909)", "verif concept answer": "church(0.7218)", "verif image answer": "church(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074927.jpg"}, {"question": "what do you put in this machine", "gt answer": "coin(1.00)<br/>money(0.60)<br/>quarter(0.60)", "pred answer": "coin", "question_id": 5431665, "best approach": "wiki, concept, image", "verif answer": "coin", "anno approach": "concept, wiki", "verif wiki answer": "coin(0.6454)", "verif concept answer": "coin(0.7025)", "verif image answer": "coin(0.6150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543166.jpg"}, {"question": "what mountain ridge are they near", "gt answer": "alp(1.00)", "pred answer": "rockies", "question_id": 3246695, "best approach": "", "verif answer": "rockies", "anno approach": "", "verif wiki answer": "rockies(0.6236)", "verif concept answer": "rockies(0.6609)", "verif image answer": "rockies(0.5783)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324669.jpg"}, {"question": "what kind of truck is that and what is in the truck", "gt answer": "sushi(1.00)<br/>food(0.60)<br/>ice cream(0.60)", "pred answer": "food", "question_id": 5150205, "best approach": "wiki, concept, image", "verif answer": "food", "anno approach": "image, wiki", "verif wiki answer": "food(0.6453)", "verif concept answer": "food(0.6407)", "verif image answer": "food(0.7136)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515020.jpg"}, {"question": "can you guess the place name shown in this picture where these sheeps are standing", "gt answer": "scotland(1.00)<br/>pasture(0.60)<br/>ireland(0.60)", "pred answer": "wood", "question_id": 2533075, "best approach": "wiki", "verif answer": "ireland", "anno approach": "wiki", "verif wiki answer": "scotland(0.6495)", "verif concept answer": "ireland(0.6521)", "verif image answer": "ireland(0.6417)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253307.jpg"}, {"question": "what is the man in the white shirt doing", "gt answer": "dive(1.00)<br/>fall(0.60)", "pred answer": "catch", "question_id": 2664415, "best approach": "", "verif answer": "catch", "anno approach": "", "verif wiki answer": "catch(0.6616)", "verif concept answer": "catch(0.6995)", "verif image answer": "play soccer(0.6565)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266441.jpg"}, {"question": "is this a custom car or a restoration", "gt answer": "restoration(1.00)<br/>custom(0.60)", "pred answer": "ford", "question_id": 5789455, "best approach": "", "verif answer": "modern", "anno approach": "", "verif wiki answer": "modern(0.7310)", "verif concept answer": "modern(0.7310)", "verif image answer": "modern(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578945.jpg"}, {"question": "what religion is being catered to at the stores shown", "gt answer": "catholic(1.00)<br/>christianity(0.60)<br/>buddhism(0.60)", "pred answer": "chinese", "question_id": 3001985, "best approach": "wiki, concept", "verif answer": "catholic", "anno approach": "concept, wiki", "verif wiki answer": "catholic(0.6430)", "verif concept answer": "catholic(0.7106)", "verif image answer": "christian(0.5096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300198.jpg"}, {"question": "what type of veggies was used in this dish", "gt answer": "kale(1.00)<br/>broccoli(0.60)<br/>spinach(0.60)<br/>green(0.60)", "pred answer": "spinach", "question_id": 982205, "best approach": "wiki, concept, image", "verif answer": "broccoli", "anno approach": "image, concept, wiki", "verif wiki answer": "spinach(0.5040)", "verif concept answer": "broccoli(0.6702)", "verif image answer": "green(0.6011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098220.jpg"}, {"question": "what event is he skiing for", "gt answer": "race(1.00)<br/>downhill(0.60)<br/>competition(0.60)<br/>cross country(0.60)", "pred answer": "race", "question_id": 1197995, "best approach": "wiki, concept, image", "verif answer": "cross country", "anno approach": "wiki", "verif wiki answer": "cross country(0.6589)", "verif concept answer": "downhill(0.6418)", "verif image answer": "cross country(0.6495)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119799.jpg"}, {"question": "who is credited with creating the first of this object", "gt answer": "frederick graff(1.00)<br/>frederick graff sr(0.60)", "pred answer": "samuel fox", "question_id": 5560885, "best approach": "wiki, concept, image", "verif answer": "frederick graff", "anno approach": "wiki", "verif wiki answer": "frederick graff(0.7311)", "verif concept answer": "frederick graff(0.7310)", "verif image answer": "frederick graff(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556088.jpg"}, {"question": "what type of cuisine are they eating", "gt answer": "french(1.00)<br/>cheese(0.60)<br/>asian(0.60)<br/>american(0.60)", "pred answer": "dinner", "question_id": 627435, "best approach": "wiki, concept, image", "verif answer": "american", "anno approach": "image, wiki", "verif wiki answer": "cheese(0.6649)", "verif concept answer": "cheese(0.6697)", "verif image answer": "american(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000062743.jpg"}, {"question": "first car of this is also called a", "gt answer": "engine(1.00)", "pred answer": "steam", "question_id": 4074665, "best approach": "", "verif answer": "track", "anno approach": "", "verif wiki answer": "motor(0.6428)", "verif concept answer": "track(0.6561)", "verif image answer": "fly(0.6430)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407466.jpg"}, {"question": "what is the name of this flower", "gt answer": "daffodil(1.00)", "pred answer": "daffodil", "question_id": 3175215, "best approach": "wiki, concept", "verif answer": "daffodil", "anno approach": "wiki", "verif wiki answer": "daffodil(0.7013)", "verif concept answer": "daffodil(0.6576)", "verif image answer": "rose(0.6494)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317521.jpg"}, {"question": "what genus of trees shown in the image", "gt answer": "birch(1.00)<br/>pine(0.60)", "pred answer": "oak", "question_id": 4575215, "best approach": "wiki, concept", "verif answer": "birch", "anno approach": "wiki", "verif wiki answer": "birch(0.7297)", "verif concept answer": "birch(0.7306)", "verif image answer": "oak(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457521.jpg"}, {"question": "what is the name of the vehicle generically featured above that made history by being made of wood", "gt answer": "airplane(1.00)<br/>jet(0.60)", "pred answer": "airplane", "question_id": 3095995, "best approach": "", "verif answer": "glider", "anno approach": "", "verif wiki answer": "glider(0.7111)", "verif concept answer": "plane(0.6695)", "verif image answer": "glider(0.7150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000309599.jpg"}, {"question": "what kind of macaroni is this", "gt answer": "elbow(1.00)<br/>kraft(0.60)", "pred answer": "yellow", "question_id": 3732945, "best approach": "wiki, concept, image", "verif answer": "elbow", "anno approach": "", "verif wiki answer": "elbow(0.6498)", "verif concept answer": "elbow(0.6582)", "verif image answer": "elbow(0.6506)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373294.jpg"}, {"question": "are the sinks in this photo manual or automatic", "gt answer": "automatic(1.00)<br/>manual(0.60)", "pred answer": "manual", "question_id": 4407385, "best approach": "wiki, concept, image", "verif answer": "manual", "anno approach": "concept, wiki", "verif wiki answer": "manual(0.5546)", "verif concept answer": "manual(0.5337)", "verif image answer": "manual(0.5010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440738.jpg"}, {"question": "what cleaning products do you use in the bathroom", "gt answer": "bleach(1.00)", "pred answer": "bleach", "question_id": 854595, "best approach": "wiki, concept", "verif answer": "bleach", "anno approach": "wiki", "verif wiki answer": "bleach(0.7159)", "verif concept answer": "bleach(0.6930)", "verif image answer": "soap(0.6408)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085459.jpg"}, {"question": "what kind of phone is this", "gt answer": "flip phone(1.00)<br/>smartphone(0.60)<br/>cellphone(0.60)", "pred answer": "flip phone", "question_id": 1622835, "best approach": "wiki, concept, image", "verif answer": "flip phone", "anno approach": "wiki", "verif wiki answer": "flip phone(0.6594)", "verif concept answer": "flip phone(0.6814)", "verif image answer": "flip phone(0.6515)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162283.jpg"}, {"question": "what brand of shoes is the white woman wearing", "gt answer": "converse(1.00)<br/>new balance(0.60)", "pred answer": "nike", "question_id": 3704935, "best approach": "", "verif answer": "sneaker", "anno approach": "", "verif wiki answer": "sneaker(0.7278)", "verif concept answer": "sneaker(0.7115)", "verif image answer": "sneaker(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370493.jpg"}, {"question": "why are people holding umbrellas", "gt answer": "rain(1.00)<br/>shade(0.60)", "pred answer": "rain", "question_id": 2707155, "best approach": "wiki, concept", "verif answer": "shade", "anno approach": "wiki", "verif wiki answer": "rain(0.6458)", "verif concept answer": "rain(0.6455)", "verif image answer": "shade(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270715.jpg"}, {"question": "what activity do the objects in this picture suggest is taking place", "gt answer": "homework(1.00)<br/>study(1.00)", "pred answer": "type", "question_id": 2905495, "best approach": "", "verif answer": "laptop", "anno approach": "", "verif wiki answer": "work(0.6334)", "verif concept answer": "work(0.6266)", "verif image answer": "laptop(0.6760)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000290549.jpg"}, {"question": "is the horse pulling people or resting", "gt answer": "rest(1.00)", "pred answer": "parked", "question_id": 3129585, "best approach": "", "verif answer": "tired", "anno approach": "", "verif wiki answer": "tired(0.7165)", "verif concept answer": "tired(0.7307)", "verif image answer": "tired(0.6973)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312958.jpg"}, {"question": "what type of herb is on top of this slice", "gt answer": "basil(1.00)<br/>spinach(0.60)<br/>parsley(0.60)", "pred answer": "basil", "question_id": 615025, "best approach": "wiki, concept", "verif answer": "basil", "anno approach": "wiki", "verif wiki answer": "basil(0.6245)", "verif concept answer": "basil(0.6382)", "verif image answer": "pepper(0.5073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061502.jpg"}, {"question": "what fruit is this beverage made of", "gt answer": "grape(1.00)", "pred answer": "grape", "question_id": 5635255, "best approach": "wiki, concept, image", "verif answer": "grape", "anno approach": "concept, wiki", "verif wiki answer": "grape(0.7186)", "verif concept answer": "grape(0.7279)", "verif image answer": "grape(0.6652)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000563525.jpg"}, {"question": "what olympic event is this person participating in", "gt answer": "ski(1.00)<br/>slalom(0.60)", "pred answer": "downhill", "question_id": 3725115, "best approach": "wiki, concept, image", "verif answer": "ski", "anno approach": "concept, wiki", "verif wiki answer": "ski(0.6681)", "verif concept answer": "ski(0.7305)", "verif image answer": "ski(0.6957)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372511.jpg"}, {"question": "where would you typically eat this in the house", "gt answer": "dine room(1.00)<br/>kitchen(1.00)<br/>live room(0.60)", "pred answer": "restaurant", "question_id": 5509605, "best approach": "wiki, concept", "verif answer": "live room", "anno approach": "", "verif wiki answer": "live room(0.6462)", "verif concept answer": "live room(0.6481)", "verif image answer": "dine(0.6456)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550960.jpg"}, {"question": "in what cultural did the decoration hanging on the wall originate", "gt answer": "native american(1.00)<br/>china(0.60)", "pred answer": "identification", "question_id": 5577685, "best approach": "", "verif answer": "indian", "anno approach": "", "verif wiki answer": "indian(0.6796)", "verif concept answer": "indian(0.7044)", "verif image answer": "indian(0.5358)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557768.jpg"}, {"question": "what other kind of food could you pour this sauce on", "gt answer": "turkey(1.00)<br/>potato(0.60)", "pred answer": "steak", "question_id": 4913305, "best approach": "", "verif answer": "chicken", "anno approach": "", "verif wiki answer": "chicken(0.5803)", "verif concept answer": "chicken(0.6482)", "verif image answer": "cow(0.6023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491330.jpg"}, {"question": "what type of tree is growing behind this couple", "gt answer": "fir(1.00)<br/>pine(1.00)", "pred answer": "pine", "question_id": 3636565, "best approach": "wiki, concept, image", "verif answer": "pine", "anno approach": "image, wiki", "verif wiki answer": "pine(0.6739)", "verif concept answer": "pine(0.6643)", "verif image answer": "pine(0.7197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363656.jpg"}, {"question": "the metal object over the stove goes by what name similar to a garment", "gt answer": "hood(1.00)<br/>pan(0.60)", "pred answer": "glass", "question_id": 2901535, "best approach": "wiki, concept, image", "verif answer": "pan", "anno approach": "wiki", "verif wiki answer": "pan(0.6198)", "verif concept answer": "pan(0.5999)", "verif image answer": "pan(0.5998)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000290153.jpg"}, {"question": "who rides in this", "gt answer": "firemen(1.00)<br/>passenger(0.60)<br/>firefight(0.60)", "pred answer": "driver", "question_id": 1331455, "best approach": "wiki, concept, image", "verif answer": "firemen", "anno approach": "image, wiki", "verif wiki answer": "firemen(0.6313)", "verif concept answer": "firemen(0.5905)", "verif image answer": "firemen(0.6293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000133145.jpg"}, {"question": "where is this", "gt answer": "city(1.00)<br/>rome(0.60)<br/>outdoor(0.60)", "pred answer": "london", "question_id": 1415195, "best approach": "wiki, concept", "verif answer": "city", "anno approach": "wiki", "verif wiki answer": "city(0.6489)", "verif concept answer": "city(0.6453)", "verif image answer": "outdoor(0.6468)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000141519.jpg"}, {"question": "what kind of truck is this", "gt answer": "fire truck(1.00)<br/>firetruck(1.00)<br/>fire(0.60)", "pred answer": "tow truck", "question_id": 1164625, "best approach": "wiki, concept", "verif answer": "fire truck", "anno approach": "wiki", "verif wiki answer": "fire truck(0.7133)", "verif concept answer": "fire truck(0.7247)", "verif image answer": "fire(0.7133)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116462.jpg"}, {"question": "which item depicted here is also associated with lattes", "gt answer": "whipped cream(1.00)<br/>cream(1.00)", "pred answer": "cheesecake", "question_id": 2195905, "best approach": "wiki, concept", "verif answer": "whipped cream", "anno approach": "", "verif wiki answer": "whipped cream(0.7004)", "verif concept answer": "whipped cream(0.7074)", "verif image answer": "pie(0.6473)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219590.jpg"}, {"question": "what kind of glasses is the man in the photo wearing", "gt answer": "sunglasses(1.00)<br/>sun(0.60)", "pred answer": "rayban", "question_id": 3744055, "best approach": "wiki, concept, image", "verif answer": "sunglasses", "anno approach": "image, wiki", "verif wiki answer": "sunglasses(0.5514)", "verif concept answer": "sunglasses(0.5074)", "verif image answer": "sunglasses(0.6094)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374405.jpg"}, {"question": "for what reason the yellow colored lines are painted", "gt answer": "boundary(1.00)<br/>basketball(0.60)", "pred answer": "safety", "question_id": 3412065, "best approach": "wiki, concept, image", "verif answer": "boundary", "anno approach": "", "verif wiki answer": "boundary(0.7054)", "verif concept answer": "boundary(0.7028)", "verif image answer": "boundary(0.6908)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341206.jpg"}, {"question": "what is the man putting in the microwave", "gt answer": "bowl(1.00)<br/>soup(0.60)", "pred answer": "cloth", "question_id": 3747265, "best approach": "", "verif answer": "juice", "anno approach": "", "verif wiki answer": "juice(0.6769)", "verif concept answer": "juice(0.6934)", "verif image answer": "juice(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374726.jpg"}, {"question": "what is the food primarily eaten by this animal", "gt answer": "tuna(1.00)<br/>cat food(0.60)<br/>chicken(0.60)", "pred answer": "cat food", "question_id": 825685, "best approach": "wiki, concept, image", "verif answer": "cat food", "anno approach": "wiki", "verif wiki answer": "cat food(0.7311)", "verif concept answer": "cat food(0.7311)", "verif image answer": "cat food(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082568.jpg"}, {"question": "how often would these bowls need food in them", "gt answer": "twice day(1.00)<br/>daily(1.00)", "pred answer": "daily", "question_id": 2661655, "best approach": "wiki, concept", "verif answer": "daily", "anno approach": "concept, wiki", "verif wiki answer": "daily(0.6396)", "verif concept answer": "daily(0.6924)", "verif image answer": "baked(0.6607)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266165.jpg"}, {"question": "what breed of dog is this", "gt answer": "terrier(1.00)<br/>sheep(0.60)<br/>schnauzer(0.60)", "pred answer": "retriever", "question_id": 2925875, "best approach": "", "verif answer": "labradoodle", "anno approach": "", "verif wiki answer": "labradoodle(0.6600)", "verif concept answer": "labradoodle(0.6629)", "verif image answer": "labradoodle(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292587.jpg"}, {"question": "what is the white part of this water called", "gt answer": "foam(1.00)<br/>tide(0.60)<br/>surf(0.60)", "pred answer": "wave", "question_id": 5766535, "best approach": "wiki, concept", "verif answer": "foam", "anno approach": "wiki", "verif wiki answer": "foam(0.7305)", "verif concept answer": "foam(0.7262)", "verif image answer": "wave(0.6526)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000576653.jpg"}, {"question": "what type of airplane is shown in this image", "gt answer": "biplane(1.00)<br/>prop(0.60)", "pred answer": "biplane", "question_id": 5276375, "best approach": "", "verif answer": "glider", "anno approach": "", "verif wiki answer": "glider(0.6826)", "verif concept answer": "private(0.6498)", "verif image answer": "glider(0.6320)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527637.jpg"}, {"question": "where is this vegetable found", "gt answer": "garden(1.00)<br/>outside(0.60)<br/>united state(0.60)", "pred answer": "tropic", "question_id": 1241325, "best approach": "concept", "verif answer": "outside", "anno approach": "concept", "verif wiki answer": "table(0.6500)", "verif concept answer": "outside(0.6667)", "verif image answer": "table(0.6543)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000124132.jpg"}, {"question": "where is this animal found in the wild", "gt answer": "wood(1.00)<br/>mountain(0.60)<br/>bear(0.60)", "pred answer": "north pole", "question_id": 1365875, "best approach": "", "verif answer": "zoo", "anno approach": "", "verif wiki answer": "zoo(0.7309)", "verif concept answer": "zoo(0.7304)", "verif image answer": "forest(0.7059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136587.jpg"}, {"question": "from what animal does this meat come from", "gt answer": "pig(1.00)<br/>lamb(1.00)", "pred answer": "pork", "question_id": 1256895, "best approach": "", "verif answer": "sheep", "anno approach": "", "verif wiki answer": "sheep(0.6267)", "verif concept answer": "sheep(0.6346)", "verif image answer": "sheep(0.5411)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125689.jpg"}, {"question": "what company manufactured this skateboard", "gt answer": "hasbro(1.00)", "pred answer": "skateboard", "question_id": 1272675, "best approach": "image", "verif answer": "hasbro", "anno approach": "image", "verif wiki answer": "wilson(0.6538)", "verif concept answer": "build bear(0.6921)", "verif image answer": "hasbro(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127267.jpg"}, {"question": "what kind of bird is in this picture", "gt answer": "seagull(1.00)<br/>pelican(0.60)", "pred answer": "seagull", "question_id": 234195, "best approach": "wiki, concept, image", "verif answer": "pelican", "anno approach": "wiki", "verif wiki answer": "pelican(0.7305)", "verif concept answer": "pelican(0.7143)", "verif image answer": "pelican(0.6845)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023419.jpg"}, {"question": "what kind of material are the players jerseys made of", "gt answer": "polyester(1.00)<br/>cotton(0.60)", "pred answer": "rubber", "question_id": 193185, "best approach": "", "verif answer": "neoprene", "anno approach": "", "verif wiki answer": "neoprene(0.7309)", "verif concept answer": "neoprene(0.7041)", "verif image answer": "neoprene(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019318.jpg"}, {"question": "who was the gold metal winner of the last winter olympic", "gt answer": "shaun white(1.00)", "pred answer": "shaun white", "question_id": 2943605, "best approach": "wiki, concept, image", "verif answer": "shaun white", "anno approach": "concept, wiki", "verif wiki answer": "shaun white(0.6715)", "verif concept answer": "shaun white(0.6220)", "verif image answer": "shaun white(0.5504)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000294360.jpg"}, {"question": "what common drink is made from the yellow fruit in this picture", "gt answer": "lemonade(1.00)", "pred answer": "orange", "question_id": 4450075, "best approach": "wiki", "verif answer": "lemonade", "anno approach": "wiki", "verif wiki answer": "lemonade(0.7271)", "verif concept answer": "orange(0.6725)", "verif image answer": "juice(0.7196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445007.jpg"}, {"question": "what object is this", "gt answer": "lighthouse(1.00)<br/>clock(1.00)<br/>light house(0.60)", "pred answer": "clock", "question_id": 29315, "best approach": "wiki, concept, image", "verif answer": "clock", "anno approach": "concept, wiki", "verif wiki answer": "clock(0.6014)", "verif concept answer": "clock(0.6135)", "verif image answer": "clock(0.5822)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002931.jpg"}, {"question": "what city does the team in blue play for", "gt answer": "cleveland(1.00)<br/>los angeles(0.60)", "pred answer": "baltimore", "question_id": 527515, "best approach": "", "verif answer": "ohio", "anno approach": "", "verif wiki answer": "ohio(0.7310)", "verif concept answer": "ohio(0.7311)", "verif image answer": "philadelphia(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052751.jpg"}, {"question": "what does this womans hand gesture mean", "gt answer": "peace(1.00)", "pred answer": "peace", "question_id": 2770385, "best approach": "", "verif answer": "flag", "anno approach": "", "verif wiki answer": "happiness(0.6506)", "verif concept answer": "flag(0.6795)", "verif image answer": "happiness(0.6499)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277038.jpg"}, {"question": "what powers the front most vehicle", "gt answer": "feet(1.00)<br/>people(0.60)<br/>pedal(0.60)<br/>person(0.60)", "pred answer": "gas", "question_id": 832195, "best approach": "wiki, concept, image", "verif answer": "people", "anno approach": "wiki", "verif wiki answer": "people(0.6862)", "verif concept answer": "people(0.6894)", "verif image answer": "people(0.6672)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083219.jpg"}, {"question": "what is the name of the tennis play", "gt answer": "serve(1.00)<br/>swing(0.60)<br/>boy(0.60)<br/>forehand(0.60)", "pred answer": "tennis", "question_id": 4181785, "best approach": "image", "verif answer": "serve", "anno approach": "image", "verif wiki answer": "hit ball(0.5001)", "verif concept answer": "forehand(0.5004)", "verif image answer": "serve(0.5207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000418178.jpg"}, {"question": "what kind of sandwich is this", "gt answer": "ham and cheese(1.00)<br/>breakfast(0.60)<br/>grilled(0.60)", "pred answer": "roast beef", "question_id": 3122825, "best approach": "wiki", "verif answer": "grilled", "anno approach": "wiki", "verif wiki answer": "ham and cheese(0.7058)", "verif concept answer": "grilled(0.7292)", "verif image answer": "grilled(0.6661)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312282.jpg"}, {"question": "what is a drink with these items blended into it called", "gt answer": "smoothie(1.00)<br/>juice(0.60)<br/>lemonade(0.60)", "pred answer": "coffee", "question_id": 284515, "best approach": "wiki, concept, image", "verif answer": "lemonade", "anno approach": "concept, wiki", "verif wiki answer": "lemonade(0.5550)", "verif concept answer": "lemonade(0.5932)", "verif image answer": "lemonade(0.5131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028451.jpg"}, {"question": "what type of berries are used to top this dessert", "gt answer": "raspberry(1.00)<br/>red(0.60)", "pred answer": "blueberry", "question_id": 5586905, "best approach": "image", "verif answer": "red wine", "anno approach": "image", "verif wiki answer": "red wine(0.7179)", "verif concept answer": "red wine(0.6805)", "verif image answer": "red(0.6638)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558690.jpg"}, {"question": "which item depicted is also a word that means to filter", "gt answer": "screen(1.00)", "pred answer": "window", "question_id": 4794615, "best approach": "", "verif answer": "white", "anno approach": "", "verif wiki answer": "white(0.7022)", "verif concept answer": "white(0.7043)", "verif image answer": "white(0.6232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479461.jpg"}, {"question": "what superstition is known about the black cat in the image", "gt answer": "bad luck(1.00)", "pred answer": "feline", "question_id": 2200535, "best approach": "wiki, concept, image", "verif answer": "bad luck", "anno approach": "concept, wiki", "verif wiki answer": "bad luck(0.5320)", "verif concept answer": "bad luck(0.5466)", "verif image answer": "bad luck(0.5014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220053.jpg"}, {"question": "what kind of piano is in the photo", "gt answer": "grand(1.00)", "pred answer": "roman", "question_id": 282295, "best approach": "", "verif answer": "modern", "anno approach": "", "verif wiki answer": "modern(0.7014)", "verif concept answer": "modern(0.6367)", "verif image answer": "modern(0.6474)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028229.jpg"}, {"question": "what kind of cloud formation is that plane flying through", "gt answer": "storm(1.00)<br/>cirrus(0.60)", "pred answer": "cumulus", "question_id": 5188985, "best approach": "", "verif answer": "cumulus", "anno approach": "", "verif wiki answer": "cumulus(0.6601)", "verif concept answer": "cumulus(0.6430)", "verif image answer": "cumulus(0.5024)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518898.jpg"}, {"question": "who built the first one of these machines", "gt answer": "richard trevithick(1.00)<br/>george washington(0.60)", "pred answer": "steam", "question_id": 2666895, "best approach": "wiki, concept, image", "verif answer": "richard trevithick", "anno approach": "wiki", "verif wiki answer": "richard trevithick(0.7311)", "verif concept answer": "richard trevithick(0.7311)", "verif image answer": "richard trevithick(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266689.jpg"}, {"question": "what is a large group of these animals called", "gt answer": "herd(1.00)<br/>flock(1.00)<br/>ram(0.60)", "pred answer": "dairy", "question_id": 2538295, "best approach": "concept", "verif answer": "pack", "anno approach": "concept", "verif wiki answer": "pack(0.5123)", "verif concept answer": "flock(0.5415)", "verif image answer": "pack(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253829.jpg"}, {"question": "how is this sandwich cooked", "gt answer": "grilled(1.00)<br/>handmade(0.60)<br/>stove(0.60)", "pred answer": "grilled", "question_id": 2455775, "best approach": "wiki, concept", "verif answer": "grilled", "anno approach": "wiki", "verif wiki answer": "grilled(0.7311)", "verif concept answer": "grilled(0.7310)", "verif image answer": "boiled(0.7149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245577.jpg"}, {"question": "what does the round disk tell you", "gt answer": "time(1.00)", "pred answer": "clock", "question_id": 222305, "best approach": "", "verif answer": "daylight", "anno approach": "", "verif wiki answer": "daylight(0.7305)", "verif concept answer": "daylight(0.7069)", "verif image answer": "daylight(0.5033)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000022230.jpg"}, {"question": "what is the state of the business on the left", "gt answer": "open(1.00)<br/>cafe(0.60)", "pred answer": "quiet", "question_id": 3468175, "best approach": "wiki", "verif answer": "tennis", "anno approach": "wiki", "verif wiki answer": "open(0.6386)", "verif concept answer": "tennis(0.6494)", "verif image answer": "tennis(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346817.jpg"}, {"question": "are these mosquito nets for guests or students", "gt answer": "guest(1.00)<br/>student(0.60)", "pred answer": "children", "question_id": 3497915, "best approach": "wiki, concept, image", "verif answer": "student", "anno approach": "wiki", "verif wiki answer": "student(0.6422)", "verif concept answer": "student(0.6241)", "verif image answer": "student(0.6457)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000349791.jpg"}, {"question": "what do you call the pattern of the red shirt the woman is wearing", "gt answer": "plaid(1.00)<br/>flannel(0.60)<br/>checkered(0.60)", "pred answer": "stripe", "question_id": 2442095, "best approach": "wiki, concept", "verif answer": "plaid", "anno approach": "wiki", "verif wiki answer": "plaid(0.6690)", "verif concept answer": "plaid(0.5854)", "verif image answer": "checkered(0.5886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244209.jpg"}, {"question": "which languages use non latin letters like those depicted", "gt answer": "indian(1.00)<br/>chinese(0.60)<br/>india(0.60)", "pred answer": "chinese", "question_id": 3913975, "best approach": "concept, image", "verif answer": "india", "anno approach": "", "verif wiki answer": "hindu(0.7309)", "verif concept answer": "india(0.7304)", "verif image answer": "india(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391397.jpg"}, {"question": "this montage is reminiscent of which card game that requires matching pairs", "gt answer": "memory(1.00)", "pred answer": "beach", "question_id": 3830145, "best approach": "image", "verif answer": "ivory", "anno approach": "image", "verif wiki answer": "ivory(0.5006)", "verif concept answer": "pizza(0.5003)", "verif image answer": "memory(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383014.jpg"}, {"question": "what type of puzzle do you see", "gt answer": "crossword(1.00)", "pred answer": "desktop", "question_id": 3652985, "best approach": "", "verif answer": "checkered", "anno approach": "", "verif wiki answer": "checkered(0.7115)", "verif concept answer": "checkered(0.6444)", "verif image answer": "checkered(0.5598)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365298.jpg"}, {"question": "how many servings of this food does the average american consume yearly", "gt answer": "46(1.00)<br/>300(0.60)<br/>20(0.60)<br/>400(0.60)", "pred answer": "8", "question_id": 3006295, "best approach": "wiki, concept, image", "verif answer": "46", "anno approach": "wiki", "verif wiki answer": "46(0.6963)", "verif concept answer": "46(0.7272)", "verif image answer": "46(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300629.jpg"}, {"question": "", "gt answer": "fire fighter(0.60)<br/>firefight(0.60)<br/>fire hydrant(0.60)<br/>firefighter(0.60)", "pred answer": "children", "question_id": 4660425, "best approach": "", "verif answer": "fireman", "anno approach": "", "verif wiki answer": "fireman(0.7085)", "verif concept answer": "fireman(0.7058)", "verif image answer": "fireman(0.6912)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466042.jpg"}, {"question": "what is the name of this train", "gt answer": "locomotive(1.00)<br/>steam engine(0.60)<br/>steam(0.60)", "pred answer": "steam engine", "question_id": 2127125, "best approach": "wiki, concept, image", "verif answer": "steam engine", "anno approach": "wiki", "verif wiki answer": "steam engine(0.6652)", "verif concept answer": "steam engine(0.6601)", "verif image answer": "steam engine(0.6542)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212712.jpg"}, {"question": "what are a bundle of these fruits called", "gt answer": "bunch(1.00)", "pred answer": "banana", "question_id": 1229395, "best approach": "", "verif answer": "banana", "anno approach": "", "verif wiki answer": "banana(0.6550)", "verif concept answer": "banana(0.6397)", "verif image answer": "banana(0.6768)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122939.jpg"}, {"question": "what could this picture be an advertisement for", "gt answer": "toothpaste(1.00)<br/>shave(0.60)", "pred answer": "selfie", "question_id": 1388465, "best approach": "concept", "verif answer": "brush teeth", "anno approach": "concept", "verif wiki answer": "brush teeth(0.5000)", "verif concept answer": "shave(0.5001)", "verif image answer": "brush teeth(0.7184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138846.jpg"}, {"question": "what is he about to blow out", "gt answer": "candle(1.00)", "pred answer": "candle", "question_id": 4746015, "best approach": "concept, image", "verif answer": "candle", "anno approach": "", "verif wiki answer": "cupcake(0.7311)", "verif concept answer": "candle(0.7311)", "verif image answer": "candle(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000474601.jpg"}, {"question": "what 's the material of the counter", "gt answer": "marble(1.00)<br/>stone(0.60)<br/>granite(0.60)<br/>tile(0.60)", "pred answer": "marble", "question_id": 5373355, "best approach": "image", "verif answer": "marble", "anno approach": "image", "verif wiki answer": "granite(0.7306)", "verif concept answer": "granite(0.7300)", "verif image answer": "marble(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537335.jpg"}, {"question": "what kind of trick is this skater performing", "gt answer": "kickflip(1.00)<br/>jump(0.60)<br/>ollie(0.60)<br/>flip(0.60)", "pred answer": "grind", "question_id": 165565, "best approach": "wiki, concept, image", "verif answer": "jump", "anno approach": "wiki", "verif wiki answer": "jump(0.6505)", "verif concept answer": "jump(0.6427)", "verif image answer": "jump(0.6598)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016556.jpg"}, {"question": "in what branch of the military do these men serve", "gt answer": "navy(1.00)", "pred answer": "navy", "question_id": 1314275, "best approach": "image", "verif answer": "navy", "anno approach": "image", "verif wiki answer": "air force(0.5350)", "verif concept answer": "air force(0.6275)", "verif image answer": "navy(0.6461)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000131427.jpg"}, {"question": "what airline is this plane", "gt answer": "southwest(1.00)<br/>american airline(0.60)", "pred answer": "boeing", "question_id": 5556585, "best approach": "wiki, concept", "verif answer": "southwest", "anno approach": "wiki", "verif wiki answer": "southwest(0.6915)", "verif concept answer": "southwest(0.6963)", "verif image answer": "air canada(0.6422)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555658.jpg"}, {"question": "what breed are these racehorses", "gt answer": "new(0.60)<br/>stallion(1.00)", "pred answer": "clydesdale", "question_id": 2453265, "best approach": "", "verif answer": "draft", "anno approach": "", "verif wiki answer": "arabian(0.6719)", "verif concept answer": "arabian(0.7266)", "verif image answer": "draft(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245326.jpg"}, {"question": "how old must you be to drink this legally", "gt answer": "21(1.00)", "pred answer": "18", "question_id": 4779435, "best approach": "wiki", "verif answer": "21", "anno approach": "wiki", "verif wiki answer": "21(0.7310)", "verif concept answer": "18(0.6425)", "verif image answer": "18(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477943.jpg"}, {"question": "what type of oil was used if any", "gt answer": "olive(1.00)<br/>olive oil(0.60)", "pred answer": "black", "question_id": 1579115, "best approach": "wiki", "verif answer": "olive", "anno approach": "wiki", "verif wiki answer": "olive(0.6534)", "verif concept answer": "vegetable(0.6483)", "verif image answer": "vegetable(0.6419)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157911.jpg"}, {"question": "who makes these scooters", "gt answer": "yamaha(1.00)<br/>bmw(0.60)<br/>honda(0.60)", "pred answer": "harley davidson", "question_id": 3187805, "best approach": "", "verif answer": "kawasaki", "anno approach": "", "verif wiki answer": "kawasaki(0.7306)", "verif concept answer": "kawasaki(0.7297)", "verif image answer": "kawasaki(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318780.jpg"}, {"question": "how are these women able to talk to each other", "gt answer": "skype(1.00)<br/>video(0.60)", "pred answer": "bluetooth", "question_id": 979995, "best approach": "", "verif answer": "scissor", "anno approach": "", "verif wiki answer": "scissor(0.7311)", "verif concept answer": "scissor(0.7311)", "verif image answer": "scissor(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097999.jpg"}, {"question": "what is this fixture used for", "gt answer": "potty(1.00)", "pred answer": "bath", "question_id": 2374135, "best approach": "wiki", "verif answer": "puke", "anno approach": "wiki", "verif wiki answer": "potty(0.6640)", "verif concept answer": "park meter(0.6225)", "verif image answer": "puke(0.7036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237413.jpg"}, {"question": "why is this woman crouching down", "gt answer": "play tennis(1.00)<br/>hit ball(0.60)", "pred answer": "hit", "question_id": 3605715, "best approach": "wiki, concept, image", "verif answer": "play tennis", "anno approach": "concept, wiki", "verif wiki answer": "play tennis(0.7310)", "verif concept answer": "play tennis(0.7310)", "verif image answer": "play tennis(0.6617)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000360571.jpg"}, {"question": "which object is the biggest parenting hazzard", "gt answer": "fireplace(1.00)<br/>tv(1.00)", "pred answer": "counter", "question_id": 189385, "best approach": "wiki, concept", "verif answer": "shelf", "anno approach": "wiki", "verif wiki answer": "fireplace(0.6412)", "verif concept answer": "fireplace(0.6493)", "verif image answer": "shelf(0.7044)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000018938.jpg"}, {"question": "what do people of this age range typically do on their phones", "gt answer": "text(1.00)", "pred answer": "flip", "question_id": 1453605, "best approach": "", "verif answer": "play game", "anno approach": "", "verif wiki answer": "play game(0.7054)", "verif concept answer": "play game(0.7010)", "verif image answer": "play game(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145360.jpg"}, {"question": "what size bed is in the picture", "gt answer": "queen(1.00)<br/>full(1.00)", "pred answer": "queen", "question_id": 2742245, "best approach": "wiki, image", "verif answer": "queen", "anno approach": "image, wiki", "verif wiki answer": "queen(0.6649)", "verif concept answer": "king(0.6452)", "verif image answer": "queen(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274224.jpg"}, {"question": "how much does this animal usually weigh", "gt answer": "300 pounds(1.00)<br/>500 pounds(0.60)<br/>400 lbs(0.60)<br/>1000 lbs(0.60)", "pred answer": "500 lbs", "question_id": 5717745, "best approach": "wiki, concept, image", "verif answer": "1000 lbs", "anno approach": "image", "verif wiki answer": "400 lbs(0.5233)", "verif concept answer": "400 lbs(0.5121)", "verif image answer": "1000 lbs(0.5439)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571774.jpg"}, {"question": "what sporting event is this", "gt answer": "motorcross(1.00)<br/>dirt bike(0.60)<br/>motorbike(0.60)", "pred answer": "race", "question_id": 3653145, "best approach": "wiki, concept, image", "verif answer": "dirt bike", "anno approach": "wiki", "verif wiki answer": "dirt bike(0.7179)", "verif concept answer": "dirt bike(0.6926)", "verif image answer": "dirt bike(0.6706)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365314.jpg"}, {"question": "home much does a train tank weigh", "gt answer": "3 tons(1.00)<br/>10000(0.60)", "pred answer": "ton", "question_id": 4879525, "best approach": "wiki, concept", "verif answer": "3 tons", "anno approach": "", "verif wiki answer": "3 tons(0.5964)", "verif concept answer": "3 tons(0.5851)", "verif image answer": "million(0.5066)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487952.jpg"}, {"question": "what event is this", "gt answer": "ted talk(1.00)<br/>train(0.60)", "pred answer": "youtube", "question_id": 3939545, "best approach": "wiki, concept", "verif answer": "birthday", "anno approach": "", "verif wiki answer": "ted talk(0.6502)", "verif concept answer": "ted talk(0.6484)", "verif image answer": "birthday(0.6560)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393954.jpg"}, {"question": "what decade did this sport first become popular", "gt answer": "70s(1.00)<br/>1950(0.60)<br/>1970's(0.60)", "pred answer": "1960's", "question_id": 719085, "best approach": "", "verif answer": "1980's", "anno approach": "", "verif wiki answer": "1980's(0.6715)", "verif concept answer": "1980's(0.7115)", "verif image answer": "1980's(0.6132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071908.jpg"}, {"question": "where was the sauce made at", "gt answer": "tomato(1.00)<br/>factory(0.60)<br/>kitchen(0.60)<br/>home(0.60)", "pred answer": "oven", "question_id": 2149555, "best approach": "image", "verif answer": "restaurant", "anno approach": "image", "verif wiki answer": "restaurant(0.6590)", "verif concept answer": "restaurant(0.6205)", "verif image answer": "kitchen(0.6145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214955.jpg"}, {"question": "what language is on the sign", "gt answer": "english(1.00)<br/>french(1.00)", "pred answer": "spanish", "question_id": 5725855, "best approach": "image", "verif answer": "english", "anno approach": "image", "verif wiki answer": "german(0.7046)", "verif concept answer": "german(0.7291)", "verif image answer": "english(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572585.jpg"}, {"question": "name the dress material of this boy shown in this picture", "gt answer": "nylon(1.00)<br/>ski suit(0.60)<br/>snowsuit(0.60)", "pred answer": "wool", "question_id": 2746905, "best approach": "image", "verif answer": "nylon", "anno approach": "image", "verif wiki answer": "snowsuit(0.6685)", "verif concept answer": "snowsuit(0.6986)", "verif image answer": "nylon(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274690.jpg"}, {"question": "what type of pastry is in front of the man", "gt answer": "donut(1.00)", "pred answer": "doughnut", "question_id": 586945, "best approach": "wiki", "verif answer": "doughnut", "anno approach": "wiki", "verif wiki answer": "donut(0.6366)", "verif concept answer": "sprinkle(0.6353)", "verif image answer": "doughnut(0.7066)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058694.jpg"}, {"question": "what activity is taking place", "gt answer": "skateboard(1.00)", "pred answer": "skateboard", "question_id": 5631235, "best approach": "", "verif answer": "box truck", "anno approach": "", "verif wiki answer": "box truck(0.6591)", "verif concept answer": "box truck(0.5945)", "verif image answer": "box truck(0.6835)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000563123.jpg"}, {"question": "where can i buy the fruit shown here", "gt answer": "supermarket(1.00)<br/>store(0.60)<br/>grocery store(0.60)", "pred answer": "walmart", "question_id": 3635545, "best approach": "wiki, concept, image", "verif answer": "supermarket", "anno approach": "concept, wiki", "verif wiki answer": "supermarket(0.7222)", "verif concept answer": "supermarket(0.7212)", "verif image answer": "supermarket(0.5050)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363554.jpg"}, {"question": "what are the long objects in the water", "gt answer": "canoes(1.00)<br/>canoe(0.60)<br/>boat(0.60)<br/>row boat(0.60)", "pred answer": "boat", "question_id": 3356305, "best approach": "", "verif answer": "row", "anno approach": "", "verif wiki answer": "row(0.6582)", "verif concept answer": "row(0.6499)", "verif image answer": "row(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335630.jpg"}, {"question": "what is this animals stage of life", "gt answer": "early(1.00)<br/>baby(0.60)", "pred answer": "toddler", "question_id": 161125, "best approach": "wiki, concept, image", "verif answer": "early", "anno approach": "image, wiki", "verif wiki answer": "early(0.6497)", "verif concept answer": "early(0.6476)", "verif image answer": "early(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016112.jpg"}, {"question": "what do you call the implements which these two men are holding", "gt answer": "bat(1.00)<br/>baseball bat(1.00)", "pred answer": "bat", "question_id": 5575685, "best approach": "wiki, concept, image", "verif answer": "baseball bat", "anno approach": "wiki", "verif wiki answer": "baseball bat(0.6974)", "verif concept answer": "baseball bat(0.7262)", "verif image answer": "baseball bat(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557568.jpg"}, {"question": "when you return a product and it must be placed back on the floor typically in spaces like these you might be charged a re what fee", "gt answer": "restock(1.00)<br/>money(0.60)", "pred answer": "office", "question_id": 1797705, "best approach": "wiki, concept", "verif answer": "restock", "anno approach": "wiki", "verif wiki answer": "restock(0.7096)", "verif concept answer": "restock(0.6725)", "verif image answer": "glue(0.6213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000179770.jpg"}, {"question": "how many stomachs does this animal have", "gt answer": "1(1.00)<br/>2(1.00)<br/>4(0.60)", "pred answer": "3", "question_id": 4091315, "best approach": "wiki", "verif answer": "2", "anno approach": "wiki", "verif wiki answer": "2(0.7193)", "verif concept answer": "3(0.6612)", "verif image answer": "3(0.6449)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409131.jpg"}, {"question": "what do you call a racing event for this mode of transportation", "gt answer": "regatta(1.00)<br/>sailboat(0.60)", "pred answer": "sail", "question_id": 4128485, "best approach": "", "verif answer": "sail", "anno approach": "", "verif wiki answer": "sail(0.7176)", "verif concept answer": "sail(0.6952)", "verif image answer": "sail(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412848.jpg"}, {"question": "which item in this picture helps people see after dark", "gt answer": "streetlight(1.00)<br/>light(0.60)<br/>street light(0.60)", "pred answer": "umbrella", "question_id": 3857165, "best approach": "", "verif answer": "lamp", "anno approach": "", "verif wiki answer": "lamp(0.6932)", "verif concept answer": "lamp(0.6978)", "verif image answer": "lamp(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385716.jpg"}, {"question": "why are the leaves not green", "gt answer": "autumn(1.00)", "pred answer": "fall", "question_id": 3237205, "best approach": "wiki, concept, image", "verif answer": "autumn", "anno approach": "wiki", "verif wiki answer": "autumn(0.7311)", "verif concept answer": "autumn(0.7311)", "verif image answer": "autumn(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323720.jpg"}, {"question": "what engine is this train using", "gt answer": "steam(1.00)", "pred answer": "steam", "question_id": 316665, "best approach": "image", "verif answer": "steam", "anno approach": "image", "verif wiki answer": "coal(0.6138)", "verif concept answer": "coal(0.6586)", "verif image answer": "steam(0.7006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000031666.jpg"}, {"question": "what is this part of", "gt answer": "airplane(1.00)<br/>plane(1.00)", "pred answer": "sky", "question_id": 5721525, "best approach": "wiki", "verif answer": "plane", "anno approach": "wiki", "verif wiki answer": "plane(0.7310)", "verif concept answer": "cloud(0.7306)", "verif image answer": "cloud(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572152.jpg"}, {"question": "what type of bird is this", "gt answer": "goose(1.00)<br/>duck(0.60)", "pred answer": "duck", "question_id": 4693735, "best approach": "", "verif answer": "swan", "anno approach": "", "verif wiki answer": "pelican(0.6618)", "verif concept answer": "swan(0.6660)", "verif image answer": "pelican(0.6351)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469373.jpg"}, {"question": "what country produces the most fruit used as a topping in this picture", "gt answer": "united state(1.00)<br/>mexico(0.60)<br/>usa(0.60)<br/>us(0.60)", "pred answer": "us", "question_id": 5125695, "best approach": "wiki, concept", "verif answer": "united state", "anno approach": "wiki", "verif wiki answer": "united state(0.6663)", "verif concept answer": "united state(0.6519)", "verif image answer": "usa(0.6586)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512569.jpg"}, {"question": "", "gt answer": "danish(0.60)<br/>fire(0.60)<br/>creme brule(0.60)", "pred answer": "chocolate", "question_id": 2961695, "best approach": "wiki, concept, image", "verif answer": "fire", "anno approach": "", "verif wiki answer": "fire(0.6481)", "verif concept answer": "fire(0.6517)", "verif image answer": "danish(0.6462)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296169.jpg"}, {"question": "where would this usually happen", "gt answer": "on lake(1.00)<br/>airport(0.60)<br/>alaska(0.60)<br/>lake(0.60)", "pred answer": "harbor", "question_id": 1562045, "best approach": "wiki, concept, image", "verif answer": "lake", "anno approach": "wiki", "verif wiki answer": "lake(0.7305)", "verif concept answer": "lake(0.7301)", "verif image answer": "airport(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000156204.jpg"}, {"question": "what game is played", "gt answer": "frisbee(1.00)", "pred answer": "frisbee", "question_id": 500985, "best approach": "wiki, concept, image", "verif answer": "frisbee", "anno approach": "wiki", "verif wiki answer": "frisbee(0.7311)", "verif concept answer": "frisbee(0.7311)", "verif image answer": "frisbee(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050098.jpg"}, {"question": "what is the name of the attatchment being pointed to", "gt answer": "bidet(1.00)<br/>fountain(0.60)", "pred answer": "hardware store", "question_id": 3234705, "best approach": "", "verif answer": "toilet", "anno approach": "", "verif wiki answer": "toilet(0.7310)", "verif concept answer": "toilet(0.6909)", "verif image answer": "toilet(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323470.jpg"}, {"question": "", "gt answer": "rockies(0.60)<br/>alp(0.60)<br/>alaska(0.60)<br/>himalayas(0.60)", "pred answer": "alp", "question_id": 2777265, "best approach": "wiki, concept, image", "verif answer": "alp", "anno approach": "image, concept", "verif wiki answer": "alp(0.6665)", "verif concept answer": "alp(0.7294)", "verif image answer": "alp(0.7040)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277726.jpg"}, {"question": "what do the peas represent", "gt answer": "mouth(1.00)<br/>tongue(0.60)<br/>eye(0.60)<br/>hair(0.60)", "pred answer": "vitamin", "question_id": 3693975, "best approach": "wiki, concept, image", "verif answer": "hair", "anno approach": "image, wiki", "verif wiki answer": "hair(0.5639)", "verif concept answer": "hair(0.5010)", "verif image answer": "hair(0.6274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369397.jpg"}, {"question": "what could he be in danger of triggering", "gt answer": "avalanche(1.00)", "pred answer": "lift", "question_id": 4589085, "best approach": "", "verif answer": "lift", "anno approach": "", "verif wiki answer": "lift(0.7027)", "verif concept answer": "lift(0.7291)", "verif image answer": "colorado(0.6620)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458908.jpg"}, {"question": "what is the brand of the keyboard shown", "gt answer": "sony(1.00)<br/>motorola(0.60)<br/>ibm(0.60)<br/>hp(0.60)", "pred answer": "dell", "question_id": 1261805, "best approach": "wiki, concept, image", "verif answer": "motorola", "anno approach": "wiki", "verif wiki answer": "motorola(0.7311)", "verif concept answer": "motorola(0.7311)", "verif image answer": "motorola(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126180.jpg"}, {"question": "what model of boat is this", "gt answer": "speed(1.00)<br/>motor boat(0.60)", "pred answer": "canoe", "question_id": 5086785, "best approach": "", "verif answer": "wooden", "anno approach": "", "verif wiki answer": "wooden(0.6400)", "verif concept answer": "wooden(0.6426)", "verif image answer": "wooden(0.6750)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000508678.jpg"}, {"question": "what fruit is this", "gt answer": "grapefruit(1.00)<br/>orange(1.00)", "pred answer": "orange", "question_id": 1166035, "best approach": "wiki, concept, image", "verif answer": "orange", "anno approach": "wiki", "verif wiki answer": "orange(0.7268)", "verif concept answer": "orange(0.7287)", "verif image answer": "orange(0.6974)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116603.jpg"}, {"question": "what time of day is it", "gt answer": "dusk(1.00)<br/>even(0.60)<br/>sunrise(0.60)<br/>sunset(0.60)", "pred answer": "even", "question_id": 1867385, "best approach": "wiki, concept, image", "verif answer": "sunset", "anno approach": "wiki", "verif wiki answer": "sunset(0.7305)", "verif concept answer": "sunset(0.6455)", "verif image answer": "sunset(0.6593)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186738.jpg"}, {"question": "what do you use this for", "gt answer": "coffee(1.00)<br/>breakfast(0.60)<br/>make coffee(0.60)<br/>cook(0.60)", "pred answer": "cook", "question_id": 3660495, "best approach": "wiki, concept, image", "verif answer": "coffee", "anno approach": "concept, wiki", "verif wiki answer": "coffee(0.6813)", "verif concept answer": "coffee(0.7303)", "verif image answer": "coffee(0.6991)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366049.jpg"}, {"question": "what on this plate is an animal", "gt answer": "turkey(1.00)<br/>cow(0.60)<br/>chicken(0.60)", "pred answer": "monkey", "question_id": 250455, "best approach": "", "verif answer": "potato", "anno approach": "", "verif wiki answer": "potato(0.7310)", "verif concept answer": "potato(0.7292)", "verif image answer": "potato(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025045.jpg"}, {"question": "what type of place is this", "gt answer": "city(1.00)", "pred answer": "city", "question_id": 1252665, "best approach": "wiki, concept, image", "verif answer": "city", "anno approach": "wiki", "verif wiki answer": "city(0.7309)", "verif concept answer": "city(0.7268)", "verif image answer": "city(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125266.jpg"}, {"question": "are these items raw or cooked", "gt answer": "raw(1.00)", "pred answer": "healthy", "question_id": 1861315, "best approach": "", "verif answer": "undercooked", "anno approach": "", "verif wiki answer": "undercooked(0.7311)", "verif concept answer": "undercooked(0.7311)", "verif image answer": "undercooked(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186131.jpg"}, {"question": "name the place where these persons are playing", "gt answer": "baseball field(1.00)<br/>stadium(1.00)", "pred answer": "stadium", "question_id": 1933275, "best approach": "image", "verif answer": "stadium", "anno approach": "image", "verif wiki answer": "baseball game(0.6539)", "verif concept answer": "ballpark(0.6874)", "verif image answer": "stadium(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193327.jpg"}, {"question": "what does the pole display", "gt answer": "flag(1.00)", "pred answer": "money", "question_id": 5357135, "best approach": "", "verif answer": "shield", "anno approach": "", "verif wiki answer": "shield(0.6989)", "verif concept answer": "shield(0.6950)", "verif image answer": "shield(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535713.jpg"}, {"question": "the fish in the scene is in which pixar movie", "gt answer": "find nemo(1.00)", "pred answer": "cell phone", "question_id": 2963775, "best approach": "wiki, concept", "verif answer": "find nemo", "anno approach": "", "verif wiki answer": "find nemo(0.7203)", "verif concept answer": "find nemo(0.6928)", "verif image answer": "hot dog(0.7018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296377.jpg"}, {"question": "what genus of flower is placed inside the vase", "gt answer": "daisy(1.00)<br/>orchid(0.60)", "pred answer": "rose", "question_id": 3153745, "best approach": "", "verif answer": "rose", "anno approach": "", "verif wiki answer": "rose(0.7142)", "verif concept answer": "rose(0.6700)", "verif image answer": "rose(0.6866)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315374.jpg"}, {"question": "how is the man getting down the hill", "gt answer": "ski(1.00)", "pred answer": "ski", "question_id": 5396065, "best approach": "concept", "verif answer": "ski", "anno approach": "concept", "verif wiki answer": "ski pole(0.7144)", "verif concept answer": "ski(0.7179)", "verif image answer": "ski pole(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539606.jpg"}, {"question": "", "gt answer": "horse jump(0.60)<br/>ride(0.60)<br/>equestrian(0.60)", "pred answer": "horse race", "question_id": 5128385, "best approach": "", "verif answer": "horse race", "anno approach": "", "verif wiki answer": "horse race(0.7311)", "verif concept answer": "horse race(0.7310)", "verif image answer": "horse race(0.7072)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512838.jpg"}, {"question": "what south american singer is famous for wearing these on her head", "gt answer": "carmen miranda(1.00)", "pred answer": "nike", "question_id": 5045545, "best approach": "", "verif answer": "gene kelly", "anno approach": "", "verif wiki answer": "gene kelly(0.7311)", "verif concept answer": "gene kelly(0.7311)", "verif image answer": "gene kelly(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000504554.jpg"}, {"question": "what activity is this", "gt answer": "sing(1.00)<br/>baseball(0.60)<br/>national anthem(0.60)", "pred answer": "basketball", "question_id": 328455, "best approach": "wiki, concept, image", "verif answer": "national anthem", "anno approach": "", "verif wiki answer": "national anthem(0.7310)", "verif concept answer": "national anthem(0.7311)", "verif image answer": "national anthem(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032845.jpg"}, {"question": "how many tiers is this dish", "gt answer": "3(1.00)", "pred answer": "12", "question_id": 55875, "best approach": "", "verif answer": "4", "anno approach": "", "verif wiki answer": "4(0.6483)", "verif concept answer": "4(0.6719)", "verif image answer": "2(0.6427)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005587.jpg"}, {"question": "how often does this animal participate in this activity daily", "gt answer": "20 hours(1.00)<br/>less(0.60)<br/>very(0.60)", "pred answer": "20 years", "question_id": 1781935, "best approach": "image", "verif answer": "million", "anno approach": "image", "verif wiki answer": "million(0.6497)", "verif concept answer": "million(0.6557)", "verif image answer": "20 hours(0.6114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178193.jpg"}, {"question": "what is the minimum speed this plane must achieve to lift off from the ground", "gt answer": "150 mph(1.00)<br/>150mph(0.60)<br/>100(0.60)", "pred answer": "500 mph", "question_id": 3973535, "best approach": "wiki, concept", "verif answer": "150 mph", "anno approach": "wiki", "verif wiki answer": "150 mph(0.5694)", "verif concept answer": "150 mph(0.5048)", "verif image answer": "60(0.5229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397353.jpg"}, {"question": "what part of the traffic day is this", "gt answer": "rush hour(1.00)", "pred answer": "morn", "question_id": 1084465, "best approach": "image", "verif answer": "rush hour", "anno approach": "image", "verif wiki answer": "bus(0.6582)", "verif concept answer": "bus(0.6513)", "verif image answer": "rush hour(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108446.jpg"}, {"question": "what is an elephant trainer called", "gt answer": "elephant trainer(1.00)<br/>mahout(0.60)", "pred answer": "man", "question_id": 3007825, "best approach": "wiki, concept, image", "verif answer": "mahout", "anno approach": "concept, wiki", "verif wiki answer": "mahout(0.7153)", "verif concept answer": "mahout(0.7079)", "verif image answer": "mahout(0.5677)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300782.jpg"}, {"question": "what type of animals are these", "gt answer": "cow(0.60)<br/>rhino(1.00)", "pred answer": "elephant", "question_id": 5291175, "best approach": "", "verif answer": "horse", "anno approach": "", "verif wiki answer": "horse(0.6598)", "verif concept answer": "horse(0.6570)", "verif image answer": "horse(0.7257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529117.jpg"}, {"question": "what are the lines in the road called here", "gt answer": "crosswalk(1.00)", "pred answer": "crosswalk", "question_id": 2722555, "best approach": "", "verif answer": "sidewalk", "anno approach": "", "verif wiki answer": "line(0.7035)", "verif concept answer": "line(0.7011)", "verif image answer": "sidewalk(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000272255.jpg"}, {"question": "", "gt answer": "direction(0.60)<br/>1 way(0.60)", "pred answer": "street name", "question_id": 116055, "best approach": "wiki, concept, image", "verif answer": "1 way", "anno approach": "concept, wiki", "verif wiki answer": "1 way(0.6495)", "verif concept answer": "1 way(0.6548)", "verif image answer": "direction(0.5032)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011605.jpg"}, {"question": "what institution are these men a part of", "gt answer": "university(1.00)", "pred answer": "school", "question_id": 249725, "best approach": "", "verif answer": "college", "anno approach": "", "verif wiki answer": "college(0.5161)", "verif concept answer": "college(0.7252)", "verif image answer": "college(0.5013)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024972.jpg"}, {"question": "what type of leavening does the bread use", "gt answer": "yeast(1.00)<br/>0(1.00)", "pred answer": "wheat", "question_id": 2912075, "best approach": "", "verif answer": "glazed", "anno approach": "", "verif wiki answer": "glazed(0.7311)", "verif concept answer": "glazed(0.7311)", "verif image answer": "glazed(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291207.jpg"}, {"question": "what period of the day does this image look like", "gt answer": "day(1.00)<br/>even(0.60)<br/>afternoon(0.60)<br/>sunset(0.60)", "pred answer": "wwii", "question_id": 494345, "best approach": "wiki, concept, image", "verif answer": "day", "anno approach": "image, wiki", "verif wiki answer": "day(0.6500)", "verif concept answer": "day(0.6401)", "verif image answer": "day(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049434.jpg"}, {"question": "what kind of phone is this child holding", "gt answer": "cell(1.00)<br/>cellphone(0.60)", "pred answer": "smartphone", "question_id": 3675235, "best approach": "wiki, concept, image", "verif answer": "cell", "anno approach": "wiki", "verif wiki answer": "cell(0.6338)", "verif concept answer": "cell(0.6432)", "verif image answer": "cell(0.6459)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367523.jpg"}, {"question": "what was the type of plastic in the dogs mouth", "gt answer": "bottle(1.00)<br/>regular(0.60)", "pred answer": "on rock", "question_id": 2881575, "best approach": "wiki, concept, image", "verif answer": "bottle", "anno approach": "wiki", "verif wiki answer": "bottle(0.7265)", "verif concept answer": "bottle(0.7238)", "verif image answer": "bottle(0.7185)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288157.jpg"}, {"question": "what ingredients are in this", "gt answer": "ice cream(1.00)<br/>sugar(0.60)<br/>cashew(0.60)", "pred answer": "meat", "question_id": 4311125, "best approach": "", "verif answer": "vitamin c", "anno approach": "", "verif wiki answer": "vitamin c(0.7310)", "verif concept answer": "vitamin c(0.7310)", "verif image answer": "vitamin c(0.7097)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431112.jpg"}, {"question": "what is the purpose of what the small lamb is doing", "gt answer": "feed(1.00)<br/>nursing(0.60)<br/>eat(0.60)", "pred answer": "fight", "question_id": 4477115, "best approach": "image", "verif answer": "feed", "anno approach": "image", "verif wiki answer": "pet(0.6155)", "verif concept answer": "pet(0.6210)", "verif image answer": "feed(0.6221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447711.jpg"}, {"question": "this guy is skate boarding in front of what city building", "gt answer": "court house(1.00)<br/>courthouse(0.60)", "pred answer": "chicago", "question_id": 5357775, "best approach": "", "verif answer": "philadelphia", "anno approach": "", "verif wiki answer": "philadelphia(0.6888)", "verif concept answer": "philadelphia(0.6599)", "verif image answer": "philadelphia(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535777.jpg"}, {"question": "what are these horses doing", "gt answer": "plow(1.00)<br/>mow(0.60)", "pred answer": "stand", "question_id": 558795, "best approach": "", "verif answer": "cart", "anno approach": "", "verif wiki answer": "farm(0.6494)", "verif concept answer": "farm(0.6502)", "verif image answer": "cart(0.7258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000055879.jpg"}, {"question": "what is the name of the baby animals shown here", "gt answer": "cub(1.00)", "pred answer": "ewe", "question_id": 814765, "best approach": "wiki, concept, image", "verif answer": "cub", "anno approach": "wiki", "verif wiki answer": "cub(0.6319)", "verif concept answer": "cub(0.6445)", "verif image answer": "cub(0.6390)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081476.jpg"}, {"question": "what is this airplane doing", "gt answer": "land(1.00)", "pred answer": "land", "question_id": 3166495, "best approach": "wiki, concept, image", "verif answer": "land", "anno approach": "wiki", "verif wiki answer": "land(0.7311)", "verif concept answer": "land(0.7311)", "verif image answer": "land(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316649.jpg"}, {"question": "what low to the ground position is the umpire in", "gt answer": "squat(1.00)<br/>crouch(1.00)", "pred answer": "first", "question_id": 5216635, "best approach": "wiki", "verif answer": "jump", "anno approach": "wiki", "verif wiki answer": "squat(0.6464)", "verif concept answer": "jump(0.6461)", "verif image answer": "jump(0.6539)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521663.jpg"}, {"question": "are they remodeling or is it just a mess", "gt answer": "mess(1.00)", "pred answer": "broken", "question_id": 1738435, "best approach": "", "verif answer": "home", "anno approach": "", "verif wiki answer": "africa(0.6133)", "verif concept answer": "africa(0.6218)", "verif image answer": "home(0.6601)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000173843.jpg"}, {"question": "what juice is advertized on the truck", "gt answer": "coconut(1.00)", "pred answer": "coca cola", "question_id": 1044435, "best approach": "", "verif answer": "apple", "anno approach": "", "verif wiki answer": "apple(0.6756)", "verif concept answer": "apple(0.6696)", "verif image answer": "apple(0.7012)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000104443.jpg"}, {"question": "what is the boy doing", "gt answer": "cut paper(1.00)<br/>cut(0.60)<br/>play(0.60)", "pred answer": "cut", "question_id": 4736785, "best approach": "", "verif answer": "sew", "anno approach": "", "verif wiki answer": "sew(0.6551)", "verif concept answer": "sew(0.6473)", "verif image answer": "sew(0.6447)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473678.jpg"}, {"question": "what are two common cooking methods for this food", "gt answer": "grill(1.00)", "pred answer": "donuts", "question_id": 803865, "best approach": "", "verif answer": "bbq", "anno approach": "", "verif wiki answer": "grilled(0.6760)", "verif concept answer": "bbq(0.6995)", "verif image answer": "bbq(0.7000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080386.jpg"}, {"question": "what century is this", "gt answer": "19th(1.00)<br/>1900(0.60)<br/>20th(0.60)<br/>18th(0.60)", "pred answer": "19th", "question_id": 4264085, "best approach": "wiki, concept, image", "verif answer": "19th", "anno approach": "image, wiki", "verif wiki answer": "19th(0.7284)", "verif concept answer": "19th(0.6617)", "verif image answer": "19th(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426408.jpg"}, {"question": "what do they use to clean off the side walk", "gt answer": "shovel(1.00)", "pred answer": "rain", "question_id": 5230345, "best approach": "wiki, concept", "verif answer": "shovel", "anno approach": "wiki", "verif wiki answer": "shovel(0.6499)", "verif concept answer": "shovel(0.6542)", "verif image answer": "plate(0.6436)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523034.jpg"}, {"question": "what team is that", "gt answer": "red(1.00)", "pred answer": "cardinal", "question_id": 1290045, "best approach": "", "verif answer": "cardinal", "anno approach": "", "verif wiki answer": "cardinal(0.7310)", "verif concept answer": "cardinal(0.7310)", "verif image answer": "cardinal(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129004.jpg"}, {"question": "what company owns this plane", "gt answer": "american(1.00)<br/>american airline(1.00)", "pred answer": "american airline", "question_id": 1610625, "best approach": "wiki, concept", "verif answer": "american airline", "anno approach": "wiki", "verif wiki answer": "american airline(0.7222)", "verif concept answer": "american airline(0.7037)", "verif image answer": "virgin(0.5252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161062.jpg"}, {"question": "what is the average life span of this type of animal", "gt answer": "20(1.00)<br/>40 years(0.60)<br/>20 years(0.60)", "pred answer": "30 years", "question_id": 5293795, "best approach": "wiki, image", "verif answer": "15 years", "anno approach": "wiki", "verif wiki answer": "20(0.6781)", "verif concept answer": "15 years(0.7040)", "verif image answer": "20(0.5591)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529379.jpg"}, {"question": "when did these communication devices become popular", "gt answer": "2000s(1.00)<br/>2000(0.60)<br/>1990's(0.60)", "pred answer": "1970", "question_id": 4478835, "best approach": "wiki, concept", "verif answer": "1990", "anno approach": "wiki", "verif wiki answer": "2000(0.5027)", "verif concept answer": "1990's(0.5085)", "verif image answer": "1990(0.6966)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447883.jpg"}, {"question": "this sport can be found in what international sports event every four years", "gt answer": "olympics(1.00)<br/>ski(0.60)", "pred answer": "olympics", "question_id": 3421905, "best approach": "wiki", "verif answer": "downhill", "anno approach": "wiki", "verif wiki answer": "ski(0.5611)", "verif concept answer": "downhill(0.5360)", "verif image answer": "downhill(0.5864)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342190.jpg"}, {"question": "can you tell me the kind of tree shown in this photo", "gt answer": "oak(1.00)<br/>pear(0.60)", "pred answer": "oak", "question_id": 1517415, "best approach": "wiki, concept, image", "verif answer": "oak", "anno approach": "wiki", "verif wiki answer": "oak(0.7310)", "verif concept answer": "oak(0.6971)", "verif image answer": "oak(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151741.jpg"}, {"question": "what animal is being mimicked in this food art", "gt answer": "dolphin(1.00)", "pred answer": "monkey", "question_id": 1340725, "best approach": "", "verif answer": "ladybug", "anno approach": "", "verif wiki answer": "ladybug(0.7300)", "verif concept answer": "ladybug(0.7291)", "verif image answer": "ladybug(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134072.jpg"}, {"question": "what is the colorful object in the photo called", "gt answer": "kite(1.00)", "pred answer": "kite", "question_id": 31185, "best approach": "", "verif answer": "parachute", "anno approach": "", "verif wiki answer": "parachute(0.6502)", "verif concept answer": "parachute(0.6447)", "verif image answer": "parachute(0.6568)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003118.jpg"}, {"question": "what is the purpose of this picture", "gt answer": "advertising(1.00)<br/>fun(0.60)", "pred answer": "fun", "question_id": 1546675, "best approach": "concept, image", "verif answer": "advertising", "anno approach": "image", "verif wiki answer": "fun(0.5012)", "verif concept answer": "advertising(0.5487)", "verif image answer": "advertising(0.6631)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154667.jpg"}, {"question": "what movie focuses around two of these vehicles", "gt answer": "chip(1.00)", "pred answer": "dirt bike", "question_id": 3885035, "best approach": "", "verif answer": "motorcycle", "anno approach": "", "verif wiki answer": "motorcycle(0.5112)", "verif concept answer": "motorcycle(0.5032)", "verif image answer": "motorcycle(0.5419)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388503.jpg"}, {"question": "what type of sandwich is this", "gt answer": "egg salad(1.00)<br/>egg(1.00)", "pred answer": "roast beef", "question_id": 2845295, "best approach": "wiki, concept, image", "verif answer": "egg salad", "anno approach": "", "verif wiki answer": "egg salad(0.7311)", "verif concept answer": "egg salad(0.7310)", "verif image answer": "egg salad(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284529.jpg"}, {"question": "what do these animals eat", "gt answer": "peanut(1.00)<br/>leaf(0.60)<br/>vegetation(0.60)<br/>grass(0.60)", "pred answer": "plant", "question_id": 5573345, "best approach": "wiki, image", "verif answer": "leaf", "anno approach": "wiki", "verif wiki answer": "leaf(0.6295)", "verif concept answer": "plant(0.6451)", "verif image answer": "leaf(0.6484)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557334.jpg"}, {"question": "where can you buy a bed like this", "gt answer": "furniture store(1.00)<br/>japan(0.60)<br/>ikea(0.60)", "pred answer": "amazon", "question_id": 1759235, "best approach": "wiki, concept, image", "verif answer": "ikea", "anno approach": "wiki", "verif wiki answer": "ikea(0.7308)", "verif concept answer": "ikea(0.7282)", "verif image answer": "ikea(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000175923.jpg"}, {"question": "what are these people doing that shows they are relaxing", "gt answer": "sit(1.00)", "pred answer": "picture", "question_id": 4299605, "best approach": "", "verif answer": "sleep", "anno approach": "", "verif wiki answer": "reflection(0.7010)", "verif concept answer": "reflection(0.6823)", "verif image answer": "sleep(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429960.jpg"}, {"question": "", "gt answer": "direction(0.60)", "pred answer": "float", "question_id": 3756655, "best approach": "", "verif answer": "turn", "anno approach": "", "verif wiki answer": "1 way(0.6417)", "verif concept answer": "turn(0.6489)", "verif image answer": "1 way(0.6175)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375665.jpg"}, {"question": "what is this player doing", "gt answer": "pitch(1.00)<br/>baseball(0.60)", "pred answer": "pitch", "question_id": 504295, "best approach": "wiki, concept, image", "verif answer": "pitch", "anno approach": "image, concept, wiki", "verif wiki answer": "pitch(0.5271)", "verif concept answer": "pitch(0.6177)", "verif image answer": "pitch(0.6393)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050429.jpg"}, {"question": "is this a hotel or a residential area", "gt answer": "hotel(1.00)<br/>residential(0.60)", "pred answer": "private", "question_id": 3824475, "best approach": "", "verif answer": "modern", "anno approach": "", "verif wiki answer": "modern(0.6451)", "verif concept answer": "modern(0.6436)", "verif image answer": "modern(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382447.jpg"}, {"question": "what sport are they playing", "gt answer": "soccer(1.00)<br/>football(0.60)", "pred answer": "football", "question_id": 609045, "best approach": "", "verif answer": "frisbee", "anno approach": "", "verif wiki answer": "frisbee(0.5027)", "verif concept answer": "frisbee(0.5012)", "verif image answer": "frisbee(0.6550)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060904.jpg"}, {"question": "what is the object that is on the red thing called", "gt answer": "hat(1.00)<br/>bonnet(0.60)", "pred answer": "cardinal", "question_id": 749475, "best approach": "wiki, concept, image", "verif answer": "bonnet", "anno approach": "wiki", "verif wiki answer": "bonnet(0.7281)", "verif concept answer": "bonnet(0.5161)", "verif image answer": "bonnet(0.5047)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074947.jpg"}, {"question": "what is the breed of the dog", "gt answer": "maltese(1.00)<br/>pug(0.60)<br/>schnauzer(0.60)", "pred answer": "bulldog", "question_id": 712645, "best approach": "", "verif answer": "pomeranian", "anno approach": "", "verif wiki answer": "pomeranian(0.7153)", "verif concept answer": "pomeranian(0.6845)", "verif image answer": "pomeranian(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071264.jpg"}, {"question": "what 's inside the item the cat is sleeping on", "gt answer": "stuffing(1.00)<br/>bat(0.60)", "pred answer": "cloth", "question_id": 3231645, "best approach": "wiki", "verif answer": "toy", "anno approach": "wiki", "verif wiki answer": "stuffing(0.7283)", "verif concept answer": "toy(0.7225)", "verif image answer": "toy(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323164.jpg"}, {"question": "which team won the most recent championship in the pictured sport", "gt answer": "houston astros(1.00)<br/>dodger(0.60)", "pred answer": "dodger", "question_id": 1867915, "best approach": "concept", "verif answer": "houston astros", "anno approach": "concept", "verif wiki answer": "dodger(0.6604)", "verif concept answer": "houston astros(0.6707)", "verif image answer": "dodger(0.6465)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186791.jpg"}, {"question": "what bird appears in this picture", "gt answer": "eagle(1.00)", "pred answer": "hawk", "question_id": 4731005, "best approach": "", "verif answer": "hawk", "anno approach": "", "verif wiki answer": "hawk(0.6453)", "verif concept answer": "hawk(0.6513)", "verif image answer": "hawk(0.7041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473100.jpg"}, {"question": "where might i find this", "gt answer": "flower shop(1.00)<br/>wed(0.60)<br/>garden(0.60)", "pred answer": "restaurant", "question_id": 1275435, "best approach": "wiki, concept, image", "verif answer": "wed", "anno approach": "wiki", "verif wiki answer": "wed(0.6951)", "verif concept answer": "wed(0.6963)", "verif image answer": "wed(0.7258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127543.jpg"}, {"question": "what shape is the sign in the lower right corner", "gt answer": "hexagon(1.00)<br/>octagon(1.00)", "pred answer": "rectangle", "question_id": 1437585, "best approach": "", "verif answer": "rectangle", "anno approach": "", "verif wiki answer": "rectangle(0.7309)", "verif concept answer": "rectangle(0.7278)", "verif image answer": "rectangle(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143758.jpg"}, {"question": "what safety precaution did both of these people take", "gt answer": "helmet(1.00)<br/>yield(0.60)", "pred answer": "helmet", "question_id": 5055015, "best approach": "wiki, concept, image", "verif answer": "helmet", "anno approach": "image, wiki", "verif wiki answer": "helmet(0.6459)", "verif concept answer": "helmet(0.6398)", "verif image answer": "helmet(0.6811)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505501.jpg"}, {"question": "what is the floating vest constructed from", "gt answer": "foam(1.00)<br/>neoprene(0.60)", "pred answer": "rubber", "question_id": 4609955, "best approach": "wiki, concept", "verif answer": "nylon", "anno approach": "wiki", "verif wiki answer": "neoprene(0.7263)", "verif concept answer": "neoprene(0.6801)", "verif image answer": "nylon(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460995.jpg"}, {"question": "what gum uses this animal for advertising", "gt answer": "fruit stripe(1.00)", "pred answer": "horse", "question_id": 4528135, "best approach": "", "verif answer": "stripe", "anno approach": "", "verif wiki answer": "stripe(0.5004)", "verif concept answer": "stripe(0.5009)", "verif image answer": "stripe(0.5745)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000452813.jpg"}, {"question": "dogs are often attracted to which item in this photo", "gt answer": "fire hydrant(1.00)<br/>hydrant(0.60)", "pred answer": "fire hydrant", "question_id": 4083515, "best approach": "", "verif answer": "fire", "anno approach": "", "verif wiki answer": "fire lane(0.5000)", "verif concept answer": "fire(0.5001)", "verif image answer": "fire(0.5008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408351.jpg"}, {"question": "how is this food prepared", "gt answer": "baked in oven(1.00)<br/>fried(0.60)<br/>oven(0.60)<br/>mix(0.60)", "pred answer": "fried", "question_id": 300235, "best approach": "image", "verif answer": "oven", "anno approach": "image", "verif wiki answer": "boiled(0.7265)", "verif concept answer": "boiled(0.7160)", "verif image answer": "oven(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030023.jpg"}, {"question": "what happens next", "gt answer": "horse jump(1.00)<br/>jump(0.60)<br/>ride(0.60)", "pred answer": "gallop", "question_id": 5295005, "best approach": "wiki, concept", "verif answer": "horse ride", "anno approach": "wiki", "verif wiki answer": "horse jump(0.6837)", "verif concept answer": "horse jump(0.6234)", "verif image answer": "horse ride(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529500.jpg"}, {"question": "what type of ship is sailing in this photo", "gt answer": "ferry(1.00)<br/>tanker(0.60)<br/>barge(0.60)", "pred answer": "barge", "question_id": 549625, "best approach": "image", "verif answer": "barge", "anno approach": "image", "verif wiki answer": "freight(0.6420)", "verif concept answer": "raft(0.6485)", "verif image answer": "barge(0.7149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054962.jpg"}, {"question": "what type of tennis court is this", "gt answer": "clay(1.00)<br/>dirt(0.60)", "pred answer": "dirt", "question_id": 3968125, "best approach": "image", "verif answer": "clay", "anno approach": "image", "verif wiki answer": "dirt(0.7302)", "verif concept answer": "dirt(0.7310)", "verif image answer": "clay(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396812.jpg"}, {"question": "are these good or bad for you", "gt answer": "good(1.00)", "pred answer": "good", "question_id": 3262395, "best approach": "wiki, concept", "verif answer": "good", "anno approach": "wiki", "verif wiki answer": "good(0.7285)", "verif concept answer": "good(0.7306)", "verif image answer": "poor(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000326239.jpg"}, {"question": "the potatoes are refered to what based on their shape", "gt answer": "wedge(1.00)<br/>fry(1.00)", "pred answer": "bacon", "question_id": 681835, "best approach": "wiki, concept", "verif answer": "fry", "anno approach": "wiki", "verif wiki answer": "fry(0.5017)", "verif concept answer": "wedge(0.5002)", "verif image answer": "french fry(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068183.jpg"}, {"question": "what kind of job does the lady do", "gt answer": "cross guard(1.00)<br/>traffic control(0.60)", "pred answer": "police officer", "question_id": 487595, "best approach": "wiki, concept, image", "verif answer": "traffic control", "anno approach": "wiki", "verif wiki answer": "traffic control(0.6487)", "verif concept answer": "traffic control(0.6530)", "verif image answer": "traffic control(0.6442)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048759.jpg"}, {"question": "is the hat shown in this photo cowboy style or sombrero", "gt answer": "sombrero(1.00)", "pred answer": "cowboy", "question_id": 5407465, "best approach": "", "verif answer": "cowboy", "anno approach": "", "verif wiki answer": "cowboy(0.6420)", "verif concept answer": "cowboy(0.6842)", "verif image answer": "stripe(0.5327)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540746.jpg"}, {"question": "what is the building structure shown", "gt answer": "clock tower(1.00)<br/>clock(0.60)", "pred answer": "church", "question_id": 422285, "best approach": "wiki, concept, image", "verif answer": "clock", "anno approach": "wiki", "verif wiki answer": "clock(0.5003)", "verif concept answer": "clock(0.5080)", "verif image answer": "clock(0.5018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042228.jpg"}, {"question": "what sport are the boys doing", "gt answer": "skateboard(1.00)<br/>skate(0.60)", "pred answer": "skateboard", "question_id": 704905, "best approach": "concept", "verif answer": "skateboard", "anno approach": "concept", "verif wiki answer": "skate park(0.6936)", "verif concept answer": "skateboard(0.6983)", "verif image answer": "skate park(0.6760)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070490.jpg"}, {"question": "can you guess the place where these people are standing", "gt answer": "dugout(1.00)<br/>stadium(1.00)<br/>ballpark(0.60)", "pred answer": "baseball stadium", "question_id": 5588045, "best approach": "", "verif answer": "football stadium", "anno approach": "", "verif wiki answer": "baseball field(0.7293)", "verif concept answer": "baseball field(0.7268)", "verif image answer": "football stadium(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558804.jpg"}, {"question": "what tool do you need to take those off", "gt answer": "wrench(1.00)", "pred answer": "meter", "question_id": 121085, "best approach": "", "verif answer": "ring", "anno approach": "", "verif wiki answer": "meter(0.5001)", "verif concept answer": "meter(0.5005)", "verif image answer": "ring(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012108.jpg"}, {"question": "what breed of dog is in this picture", "gt answer": "mutt(1.00)<br/>chihuahua(0.60)", "pred answer": "collie", "question_id": 1179465, "best approach": "wiki, concept", "verif answer": "chihuahua", "anno approach": "wiki", "verif wiki answer": "chihuahua(0.6293)", "verif concept answer": "chihuahua(0.6473)", "verif image answer": "collie(0.6443)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117946.jpg"}, {"question": "what is this positive gesture of praise or appreciation called", "gt answer": "high 5(1.00)<br/>tennis(0.60)", "pred answer": "tennis", "question_id": 4298295, "best approach": "", "verif answer": "wimbledon", "anno approach": "", "verif wiki answer": "wimbledon(0.5956)", "verif concept answer": "wimbledon(0.5601)", "verif image answer": "wimbledon(0.5907)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429829.jpg"}, {"question": "what are the panels on the wall used for", "gt answer": "privacy(1.00)", "pred answer": "wash hand", "question_id": 2173065, "best approach": "", "verif answer": "toilet", "anno approach": "", "verif wiki answer": "toilet(0.6779)", "verif concept answer": "toilet(0.5747)", "verif image answer": "toilet(0.7048)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217306.jpg"}, {"question": "which items shown here are used for drinking wine", "gt answer": "wine glass(1.00)<br/>glass(1.00)", "pred answer": "wine", "question_id": 1669595, "best approach": "wiki, concept, image", "verif answer": "wine glass", "anno approach": "wiki", "verif wiki answer": "glass(0.7247)", "verif concept answer": "glass(0.7291)", "verif image answer": "wine glass(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166959.jpg"}, {"question": "what vegetables are present in this photo", "gt answer": "tomato carrot cauliflower(1.00)", "pred answer": "tomato", "question_id": 3838885, "best approach": "wiki, concept", "verif answer": "tomato carrot cauliflower", "anno approach": "", "verif wiki answer": "tomato carrot cauliflower(0.5725)", "verif concept answer": "tomato carrot cauliflower(0.5537)", "verif image answer": "apple(0.5064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383888.jpg"}, {"question": "what kind of processor do these have", "gt answer": "intel(1.00)<br/>computer(0.60)", "pred answer": "hp", "question_id": 758295, "best approach": "", "verif answer": "hp", "anno approach": "", "verif wiki answer": "hp(0.6956)", "verif concept answer": "hp(0.6252)", "verif image answer": "hp(0.5093)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075829.jpg"}, {"question": "what are the things called that are in their hands", "gt answer": "pole(1.00)<br/>ski pole(0.60)", "pred answer": "pole", "question_id": 2083815, "best approach": "wiki, concept, image", "verif answer": "pole", "anno approach": "wiki", "verif wiki answer": "pole(0.7311)", "verif concept answer": "pole(0.7311)", "verif image answer": "pole(0.7264)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208381.jpg"}, {"question": "can you tell me what the symbol in the photo indicates", "gt answer": "crossroad(1.00)<br/>intersection(0.60)<br/>street name(0.60)<br/>street(0.60)", "pred answer": "street sign", "question_id": 4789825, "best approach": "wiki, concept, image", "verif answer": "crossroad", "anno approach": "image", "verif wiki answer": "crossroad(0.6649)", "verif concept answer": "crossroad(0.6883)", "verif image answer": "crossroad(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478982.jpg"}, {"question": "what does the shop whose sign is in the background mainly sell", "gt answer": "book(1.00)<br/>grocery(0.60)<br/>cloth(0.60)", "pred answer": "newspaper", "question_id": 5129245, "best approach": "image", "verif answer": "book", "anno approach": "image", "verif wiki answer": "furniture(0.5900)", "verif concept answer": "furniture(0.6458)", "verif image answer": "book(0.6768)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512924.jpg"}, {"question": "how much would this meal cost on average", "gt answer": "5 dollars(1.00)<br/>5(0.60)<br/>baked(0.60)", "pred answer": "350", "question_id": 1493435, "best approach": "wiki, concept", "verif answer": "5 dollars", "anno approach": "", "verif wiki answer": "5 dollars(0.6640)", "verif concept answer": "5 dollars(0.6463)", "verif image answer": "1(0.5756)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149343.jpg"}, {"question": "how much longer until these are cooked", "gt answer": "1 minute(1.00)<br/>5 minutes(0.60)", "pred answer": "1 hour", "question_id": 3714895, "best approach": "concept", "verif answer": "3 minutes", "anno approach": "concept", "verif wiki answer": "10 minutes(0.6866)", "verif concept answer": "1 minute(0.6869)", "verif image answer": "3 minutes(0.7158)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371489.jpg"}, {"question": "what type of boats are these", "gt answer": "canoes(1.00)<br/>row boat(0.60)", "pred answer": "canoes", "question_id": 4091635, "best approach": "", "verif answer": "row", "anno approach": "", "verif wiki answer": "row(0.6521)", "verif concept answer": "row(0.6492)", "verif image answer": "fish boat(0.6464)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409163.jpg"}, {"question": "what kind of plant is next to the sheets", "gt answer": "house(1.00)<br/>fern(0.60)<br/>lily(0.60)<br/>indoor(0.60)", "pred answer": "fern", "question_id": 382045, "best approach": "wiki, concept", "verif answer": "house", "anno approach": "wiki", "verif wiki answer": "house(0.7258)", "verif concept answer": "house(0.7018)", "verif image answer": "fern(0.6181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038204.jpg"}, {"question": "can you name the bird sitting on the rock", "gt answer": "eagle(1.00)<br/>hawk(0.60)", "pred answer": "owl", "question_id": 3253845, "best approach": "wiki, concept, image", "verif answer": "hawk", "anno approach": "image, concept, wiki", "verif wiki answer": "hawk(0.5111)", "verif concept answer": "hawk(0.5405)", "verif image answer": "hawk(0.6426)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325384.jpg"}, {"question": "what is the name of the food strapped together with the red bands", "gt answer": "asparagus(1.00)", "pred answer": "vegetable", "question_id": 4849645, "best approach": "wiki, concept, image", "verif answer": "asparagus", "anno approach": "wiki", "verif wiki answer": "asparagus(0.5843)", "verif concept answer": "asparagus(0.6097)", "verif image answer": "asparagus(0.6129)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484964.jpg"}, {"question": "what might this woman 's trousers be made of", "gt answer": "denim(1.00)<br/>cotton(0.60)<br/>wool(0.60)<br/>polyester(0.60)", "pred answer": "denim", "question_id": 4769505, "best approach": "wiki, image", "verif answer": "denim", "anno approach": "wiki", "verif wiki answer": "denim(0.7311)", "verif concept answer": "wool(0.7311)", "verif image answer": "denim(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476950.jpg"}, {"question": "where is this a native meal", "gt answer": "poland(1.00)<br/>peru(0.60)<br/>germany(0.60)<br/>america(0.60)", "pred answer": "restaurant", "question_id": 2002725, "best approach": "wiki", "verif answer": "america", "anno approach": "wiki", "verif wiki answer": "poland(0.6188)", "verif concept answer": "germany(0.5956)", "verif image answer": "america(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200272.jpg"}, {"question": "what breed of dog is this", "gt answer": "pomeranian(1.00)", "pred answer": "retriever", "question_id": 267325, "best approach": "image", "verif answer": "pomeranian", "anno approach": "image", "verif wiki answer": "teddy bear(0.6485)", "verif concept answer": "teddy bear(0.6563)", "verif image answer": "pomeranian(0.7158)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000026732.jpg"}, {"question": "what material is the fireplace made from", "gt answer": "brick(1.00)", "pred answer": "brick", "question_id": 1270845, "best approach": "wiki, concept, image", "verif answer": "brick", "anno approach": "wiki", "verif wiki answer": "brick(0.7251)", "verif concept answer": "brick(0.6766)", "verif image answer": "brick(0.6880)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127084.jpg"}, {"question": "what breed is the dog", "gt answer": "pomeranian(1.00)", "pred answer": "pomeranian", "question_id": 2149435, "best approach": "wiki, concept, image", "verif answer": "pomeranian", "anno approach": "image, wiki", "verif wiki answer": "pomeranian(0.6560)", "verif concept answer": "pomeranian(0.6427)", "verif image answer": "pomeranian(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214943.jpg"}, {"question": "what kind of cargo do these train cars carry", "gt answer": "bag(0.60)<br/>people(0.60)<br/>passenger(1.00)<br/>human(0.60)", "pred answer": "people", "question_id": 748615, "best approach": "wiki, concept, image", "verif answer": "people", "anno approach": "wiki", "verif wiki answer": "people(0.6589)", "verif concept answer": "bag(0.6523)", "verif image answer": "bag(0.6299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074861.jpg"}, {"question": "is the road wet or dry", "gt answer": "wet(1.00)", "pred answer": "wet", "question_id": 3467415, "best approach": "wiki, concept, image", "verif answer": "wet", "anno approach": "wiki", "verif wiki answer": "wet(0.7307)", "verif concept answer": "wet(0.7310)", "verif image answer": "wet(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346741.jpg"}, {"question": "what type of lighting is found in this room", "gt answer": "overhead(1.00)<br/>indoor(0.60)", "pred answer": "overhead", "question_id": 3223945, "best approach": "wiki, concept", "verif answer": "overhead", "anno approach": "wiki", "verif wiki answer": "overhead(0.6412)", "verif concept answer": "overhead(0.6322)", "verif image answer": "indoor(0.6372)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322394.jpg"}, {"question": "what brand of mouse is this", "gt answer": "dell(1.00)<br/>logitech(1.00)", "pred answer": "dell", "question_id": 4282145, "best approach": "", "verif answer": "acer", "anno approach": "", "verif wiki answer": "acer(0.7308)", "verif concept answer": "acer(0.7019)", "verif image answer": "acer(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428214.jpg"}, {"question": "what animal is at nine o'clock", "gt answer": "lion(1.00)<br/>horse(0.60)", "pred answer": "dalmation", "question_id": 2386055, "best approach": "", "verif answer": "cow", "anno approach": "", "verif wiki answer": "cow(0.7311)", "verif concept answer": "cow(0.7311)", "verif image answer": "cow(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238605.jpg"}, {"question": "what is powering that train", "gt answer": "steam(1.00)<br/>coal(0.60)<br/>engine(0.60)", "pred answer": "coal", "question_id": 1538175, "best approach": "wiki, concept, image", "verif answer": "coal", "anno approach": "image, concept, wiki", "verif wiki answer": "coal(0.6855)", "verif concept answer": "coal(0.7284)", "verif image answer": "coal(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153817.jpg"}, {"question": "", "gt answer": "screen(0.60)<br/>glass(0.60)<br/>bay(0.60)", "pred answer": "gothic", "question_id": 2651145, "best approach": "wiki, concept, image", "verif answer": "screen", "anno approach": "", "verif wiki answer": "screen(0.7310)", "verif concept answer": "screen(0.7310)", "verif image answer": "screen(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265114.jpg"}, {"question": "what is the temperature like", "gt answer": "cool(1.00)", "pred answer": "cool", "question_id": 3607515, "best approach": "wiki, concept, image", "verif answer": "cool", "anno approach": "wiki", "verif wiki answer": "cool(0.7180)", "verif concept answer": "cool(0.7307)", "verif image answer": "cool(0.7143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000360751.jpg"}, {"question": "what is the length of the surfboard the man in the black shorts at the back of the line of people is holding", "gt answer": "7 feet(1.00)", "pred answer": "2 feet", "question_id": 5636175, "best approach": "", "verif answer": "8 feet", "anno approach": "", "verif wiki answer": "20 feet(0.5748)", "verif concept answer": "20 feet(0.6116)", "verif image answer": "8 feet(0.7248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000563617.jpg"}, {"question": "what ethnicity is the girl", "gt answer": "caucasian(1.00)<br/>white(1.00)", "pred answer": "caucasian", "question_id": 4176315, "best approach": "wiki, concept, image", "verif answer": "caucasian", "anno approach": "wiki", "verif wiki answer": "caucasian(0.7311)", "verif concept answer": "caucasian(0.7310)", "verif image answer": "caucasian(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417631.jpg"}, {"question": "is this a flat screen or projection tv", "gt answer": "flat screen(1.00)", "pred answer": "flat screen", "question_id": 4922435, "best approach": "wiki, concept, image", "verif answer": "flat screen", "anno approach": "", "verif wiki answer": "flat screen(0.7310)", "verif concept answer": "flat screen(0.7290)", "verif image answer": "flat screen(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492243.jpg"}, {"question": "what material is this landform made of", "gt answer": "sand(1.00)", "pred answer": "sand", "question_id": 3220825, "best approach": "", "verif answer": "plastic", "anno approach": "", "verif wiki answer": "plastic(0.7307)", "verif concept answer": "rock(0.7260)", "verif image answer": "plastic(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322082.jpg"}, {"question": "what type of lighting is shown here", "gt answer": "overhead(1.00)<br/>ceiling(0.60)<br/>pot(0.60)", "pred answer": "track", "question_id": 2789365, "best approach": "concept", "verif answer": "indoor", "anno approach": "concept", "verif wiki answer": "indoor(0.6134)", "verif concept answer": "overhead(0.6221)", "verif image answer": "indoor(0.6313)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278936.jpg"}, {"question": "what is the temperature like", "gt answer": "hot(1.00)<br/>warm(0.60)", "pred answer": "cool", "question_id": 204505, "best approach": "wiki, concept", "verif answer": "warm", "anno approach": "wiki", "verif wiki answer": "warm(0.7305)", "verif concept answer": "warm(0.7290)", "verif image answer": "sunny(0.6192)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020450.jpg"}, {"question": "what brand of tooth brush is this girl using", "gt answer": "oral b(1.00)<br/>crest(0.60)<br/>bic(0.60)<br/>colgate(0.60)", "pred answer": "colgate", "question_id": 3381675, "best approach": "concept", "verif answer": "oral b", "anno approach": "concept", "verif wiki answer": "colgate(0.6462)", "verif concept answer": "oral b(0.7279)", "verif image answer": "colgate(0.6098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338167.jpg"}, {"question": "where can a similar chair be purchased", "gt answer": "furniture store(1.00)<br/>walmart(0.60)", "pred answer": "ikea", "question_id": 3154285, "best approach": "", "verif answer": "japan", "anno approach": "", "verif wiki answer": "japan(0.7038)", "verif concept answer": "store(0.6484)", "verif image answer": "low(0.6372)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315428.jpg"}, {"question": "what season has obviously gone by in this photo", "gt answer": "fall(1.00)<br/>winter(1.00)", "pred answer": "fall", "question_id": 2760095, "best approach": "wiki, concept, image", "verif answer": "fall", "anno approach": "wiki", "verif wiki answer": "fall(0.7311)", "verif concept answer": "fall(0.7311)", "verif image answer": "fall(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276009.jpg"}, {"question": "what method was used to cook this meat", "gt answer": "grill(1.00)<br/>grilled(0.60)", "pred answer": "grill", "question_id": 1084295, "best approach": "wiki, concept, image", "verif answer": "grill", "anno approach": "image, concept, wiki", "verif wiki answer": "grill(0.6584)", "verif concept answer": "grill(0.7213)", "verif image answer": "grill(0.7267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108429.jpg"}, {"question": "what is filled in those bottles", "gt answer": "citrus juice(1.00)<br/>juice(0.60)", "pred answer": "food", "question_id": 546915, "best approach": "wiki, concept, image", "verif answer": "juice", "anno approach": "concept, wiki", "verif wiki answer": "juice(0.6707)", "verif concept answer": "juice(0.7021)", "verif image answer": "juice(0.6002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054691.jpg"}, {"question": "what is the woman selling", "gt answer": "smoothies(1.00)<br/>ride(0.60)<br/>smoothie(0.60)", "pred answer": "newspaper", "question_id": 4085285, "best approach": "wiki, concept", "verif answer": "cloth", "anno approach": "wiki", "verif wiki answer": "smoothie(0.5792)", "verif concept answer": "smoothie(0.5411)", "verif image answer": "cloth(0.6058)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408528.jpg"}, {"question": "what does this machine do", "gt answer": "bake(1.00)<br/>cook(0.60)", "pred answer": "eat", "question_id": 5728595, "best approach": "wiki, concept, image", "verif answer": "bake", "anno approach": "wiki", "verif wiki answer": "bake(0.6403)", "verif concept answer": "bake(0.6571)", "verif image answer": "bake(0.6393)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572859.jpg"}, {"question": "what do people do in this room", "gt answer": "poop(1.00)<br/>bathroom(0.60)<br/>wash(0.60)", "pred answer": "wash hand", "question_id": 2362945, "best approach": "", "verif answer": "wash hand", "anno approach": "", "verif wiki answer": "wash hand(0.7250)", "verif concept answer": "wash hand(0.7259)", "verif image answer": "wash hand(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236294.jpg"}, {"question": "what substance is normally being dispensed by this vehicle", "gt answer": "pesticide(1.00)", "pred answer": "water", "question_id": 392725, "best approach": "", "verif answer": "grain", "anno approach": "", "verif wiki answer": "grain(0.7173)", "verif concept answer": "grain(0.7102)", "verif image answer": "snow(0.6467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039272.jpg"}, {"question": "what genus of flower is placed inside the blue vase", "gt answer": "lily(0.60)<br/>orchid(1.00)<br/>pink(0.60)", "pred answer": "rose", "question_id": 287665, "best approach": "", "verif answer": "morn glory", "anno approach": "", "verif wiki answer": "morn glory(0.7310)", "verif concept answer": "morn glory(0.7307)", "verif image answer": "tulip(0.6390)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028766.jpg"}, {"question": "what basic equipment is required for this sport", "gt answer": "ski(1.00)<br/>skiis(0.60)", "pred answer": "ski", "question_id": 4956515, "best approach": "image", "verif answer": "skiis", "anno approach": "image", "verif wiki answer": "ski pole(0.6480)", "verif concept answer": "ski pole(0.6901)", "verif image answer": "skiis(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495651.jpg"}, {"question": "what object is used for travel", "gt answer": "bike(1.00)<br/>bicycle(1.00)", "pred answer": "motorcycle", "question_id": 2784115, "best approach": "wiki, concept, image", "verif answer": "bicycle", "anno approach": "image, wiki", "verif wiki answer": "bike(0.6401)", "verif concept answer": "bike(0.6376)", "verif image answer": "bicycle(0.6949)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278411.jpg"}, {"question": "what is contained within those shelves", "gt answer": "book(1.00)", "pred answer": "book", "question_id": 3519725, "best approach": "wiki, concept, image", "verif answer": "book", "anno approach": "image, wiki", "verif wiki answer": "book(0.6577)", "verif concept answer": "book(0.6391)", "verif image answer": "book(0.7127)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351972.jpg"}, {"question": "what is filled in that oval object the boy is holding", "gt answer": "balloon(1.00)<br/>helium(0.60)<br/>cheese(0.60)", "pred answer": "cupcake", "question_id": 5083825, "best approach": "concept, image", "verif answer": "balloon", "anno approach": "image", "verif wiki answer": "rubber(0.6682)", "verif concept answer": "balloon(0.6835)", "verif image answer": "balloon(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000508382.jpg"}, {"question": "what other tools can be used to cut and make a hole in wood", "gt answer": "knife(1.00)<br/>scissor(0.60)", "pred answer": "knife", "question_id": 5529745, "best approach": "image", "verif answer": "spatula", "anno approach": "image", "verif wiki answer": "spatula(0.5219)", "verif concept answer": "spatula(0.5006)", "verif image answer": "knife(0.5025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552974.jpg"}, {"question": "what are the green objects in this photo used for", "gt answer": "sit(1.00)", "pred answer": "relax", "question_id": 4677695, "best approach": "image", "verif answer": "forest gump", "anno approach": "image", "verif wiki answer": "forest gump(0.7275)", "verif concept answer": "forest gump(0.7122)", "verif image answer": "sit(0.6840)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467769.jpg"}, {"question": "what city is that landmark in", "gt answer": "st louis(1.00)<br/>washington dc(0.60)", "pred answer": "new york", "question_id": 590415, "best approach": "", "verif answer": "paris", "anno approach": "", "verif wiki answer": "paris(0.7275)", "verif concept answer": "paris(0.7155)", "verif image answer": "paris(0.7238)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059041.jpg"}, {"question": "how much water does this require to grow", "gt answer": "gallon(1.00)", "pred answer": "lot", "question_id": 297555, "best approach": "concept", "verif answer": "5 gallons", "anno approach": "concept", "verif wiki answer": "5 gallons(0.6781)", "verif concept answer": "gallon(0.6565)", "verif image answer": "baked(0.6752)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029755.jpg"}, {"question": "how are these items powered", "gt answer": "battery(1.00)<br/>dc(0.60)", "pred answer": "battery", "question_id": 5184835, "best approach": "wiki, concept, image", "verif answer": "battery", "anno approach": "", "verif wiki answer": "battery(0.7281)", "verif concept answer": "battery(0.7310)", "verif image answer": "battery(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518483.jpg"}, {"question": "the woman is holding what piece of sporting equipment", "gt answer": "tennis racket(1.00)", "pred answer": "tennis racket", "question_id": 506205, "best approach": "wiki, concept, image", "verif answer": "tennis racket", "anno approach": "wiki", "verif wiki answer": "tennis racket(0.7311)", "verif concept answer": "tennis racket(0.7311)", "verif image answer": "tennis racket(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050620.jpg"}, {"question": "what time of day is depicted", "gt answer": "dusk(1.00)<br/>sunrise(0.60)<br/>day(0.60)<br/>morn(0.60)", "pred answer": "dusk", "question_id": 2578135, "best approach": "wiki, concept, image", "verif answer": "dusk", "anno approach": "image, wiki", "verif wiki answer": "dusk(0.6542)", "verif concept answer": "dusk(0.6474)", "verif image answer": "dusk(0.6878)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257813.jpg"}, {"question": "what 's rhe difference between a black bear and a brown bear", "gt answer": "color(1.00)", "pred answer": "black", "question_id": 851635, "best approach": "", "verif answer": "trunk", "anno approach": "", "verif wiki answer": "brand(0.6528)", "verif concept answer": "brand(0.6531)", "verif image answer": "trunk(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085163.jpg"}, {"question": "what is the position of the skis", "gt answer": "horizontal(1.00)<br/>left(0.60)", "pred answer": "snowplow", "question_id": 2182845, "best approach": "concept, image", "verif answer": "horizontal", "anno approach": "concept", "verif wiki answer": "downhill(0.6128)", "verif concept answer": "horizontal(0.6529)", "verif image answer": "horizontal(0.5249)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218284.jpg"}, {"question": "what 's the summertime version of this sport", "gt answer": "water ski(1.00)<br/>skate(0.60)<br/>hike(0.60)", "pred answer": "ski", "question_id": 235395, "best approach": "wiki, concept, image", "verif answer": "water ski", "anno approach": "wiki", "verif wiki answer": "water ski(0.7310)", "verif concept answer": "water ski(0.7311)", "verif image answer": "water ski(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023539.jpg"}, {"question": "which city was the first to install signal lights to facilitate this activity", "gt answer": "chicago(1.00)<br/>london(0.60)<br/>usa(0.60)<br/>new york(0.60)", "pred answer": "new york", "question_id": 2356705, "best approach": "wiki, concept, image", "verif answer": "new york", "anno approach": "concept, wiki", "verif wiki answer": "new york(0.6281)", "verif concept answer": "new york(0.7142)", "verif image answer": "london(0.5378)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000235670.jpg"}, {"question": "what is the name for a group of birds", "gt answer": "flock(1.00)<br/>robin(0.60)", "pred answer": "sparrow", "question_id": 5392835, "best approach": "image", "verif answer": "herd", "anno approach": "image", "verif wiki answer": "herd(0.7311)", "verif concept answer": "herd(0.7311)", "verif image answer": "flock(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539283.jpg"}, {"question": "is this veggies or fruits", "gt answer": "veggies(1.00)", "pred answer": "vegetable", "question_id": 3179985, "best approach": "image", "verif answer": "veggies", "anno approach": "image", "verif wiki answer": "broccoli(0.5005)", "verif concept answer": "broccoli(0.5021)", "verif image answer": "veggies(0.5540)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317998.jpg"}, {"question": "how old do you estimate this man to be", "gt answer": "forty(1.00)<br/>45(0.60)<br/>48(0.60)<br/>30(0.60)", "pred answer": "21", "question_id": 14035, "best approach": "", "verif answer": "50", "anno approach": "", "verif wiki answer": "50(0.6736)", "verif concept answer": "50(0.6502)", "verif image answer": "50(0.6188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001403.jpg"}, {"question": "what kind of bird is this", "gt answer": "puffin(1.00)<br/>pelican(0.60)", "pred answer": "pelican", "question_id": 4297585, "best approach": "wiki, concept, image", "verif answer": "puffin", "anno approach": "", "verif wiki answer": "puffin(0.7311)", "verif concept answer": "puffin(0.7298)", "verif image answer": "puffin(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429758.jpg"}, {"question": "what did this person jump off", "gt answer": "boat(1.00)<br/>dock(1.00)<br/>water ski(0.60)", "pred answer": "surfboard", "question_id": 483815, "best approach": "wiki, concept, image", "verif answer": "water ski", "anno approach": "wiki", "verif wiki answer": "water ski(0.6460)", "verif concept answer": "water ski(0.6480)", "verif image answer": "water ski(0.6482)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048381.jpg"}, {"question": "what species of birds are those", "gt answer": "geese(1.00)<br/>crane(0.60)", "pred answer": "geese", "question_id": 4613015, "best approach": "wiki, concept", "verif answer": "duck", "anno approach": "wiki", "verif wiki answer": "geese(0.6447)", "verif concept answer": "geese(0.6749)", "verif image answer": "duck(0.7057)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461301.jpg"}, {"question": "the net shown in the picture is made up of which material", "gt answer": "nylon(1.00)", "pred answer": "concrete", "question_id": 3886415, "best approach": "", "verif answer": "neoprene", "anno approach": "", "verif wiki answer": "neoprene(0.6495)", "verif concept answer": "neoprene(0.6320)", "verif image answer": "neoprene(0.6760)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388641.jpg"}, {"question": "how difficult is what this snowboarder is doing", "gt answer": "very(1.00)<br/>easy(0.60)", "pred answer": "fast", "question_id": 5393785, "best approach": "", "verif answer": "moderately", "anno approach": "", "verif wiki answer": "moderately(0.6476)", "verif concept answer": "moderately(0.6260)", "verif image answer": "moderately(0.6626)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539378.jpg"}, {"question": "where are they", "gt answer": "colorado(0.60)<br/>mountain(1.00)", "pred answer": "mountain", "question_id": 3748735, "best approach": "", "verif answer": "mount everest", "anno approach": "", "verif wiki answer": "aspen(0.6731)", "verif concept answer": "mount everest(0.7140)", "verif image answer": "mount everest(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374873.jpg"}, {"question": "what is the diameter of the red umbrella", "gt answer": "40 inches(1.00)<br/>3(0.60)", "pred answer": "2 stories", "question_id": 5744565, "best approach": "", "verif answer": "inside", "anno approach": "", "verif wiki answer": "inside(0.6735)", "verif concept answer": "inside(0.7297)", "verif image answer": "inside(0.7018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000574456.jpg"}, {"question": "what kind of bread is this", "gt answer": "foccacia(1.00)<br/>pita(0.60)<br/>french(0.60)", "pred answer": "bagel", "question_id": 375395, "best approach": "wiki, concept, image", "verif answer": "foccacia", "anno approach": "concept, wiki", "verif wiki answer": "foccacia(0.7311)", "verif concept answer": "foccacia(0.7310)", "verif image answer": "foccacia(0.6638)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000037539.jpg"}, {"question": "where can donuts such as this one be purchased", "gt answer": "bakery(1.00)<br/>krispy kreme(0.60)<br/>dunkin donuts(0.60)", "pred answer": "sprinkle", "question_id": 3549365, "best approach": "wiki, concept", "verif answer": "krispy kreme", "anno approach": "wiki", "verif wiki answer": "bakery(0.7192)", "verif concept answer": "bakery(0.7266)", "verif image answer": "krispy kreme(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354936.jpg"}, {"question": "what are the name of those plants", "gt answer": "banana(1.00)<br/>bush(0.60)", "pred answer": "banana", "question_id": 3751865, "best approach": "concept, image", "verif answer": "aloe", "anno approach": "concept", "verif wiki answer": "aloe(0.5901)", "verif concept answer": "banana(0.5753)", "verif image answer": "banana(0.5046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375186.jpg"}, {"question": "what items in this pic could be made of bee wax", "gt answer": "candle(1.00)", "pred answer": "pane", "question_id": 3335555, "best approach": "wiki, concept, image", "verif answer": "candle", "anno approach": "image, wiki", "verif wiki answer": "candle(0.7003)", "verif concept answer": "candle(0.6601)", "verif image answer": "candle(0.7074)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333555.jpg"}, {"question": "what is this cake commonly made of", "gt answer": "butter(1.00)<br/>sponge(0.60)<br/>flour(0.60)", "pred answer": "flour", "question_id": 4852345, "best approach": "concept", "verif answer": "sugar", "anno approach": "concept", "verif wiki answer": "sugar(0.6544)", "verif concept answer": "butter(0.6577)", "verif image answer": "sugar(0.6861)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485234.jpg"}, {"question": "what is the man in the middle selling", "gt answer": "bed(1.00)<br/>furniture(0.60)", "pred answer": "bread", "question_id": 5023795, "best approach": "image", "verif answer": "person", "anno approach": "image", "verif wiki answer": "person(0.6683)", "verif concept answer": "trailer(0.6467)", "verif image answer": "furniture(0.6394)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502379.jpg"}, {"question": "what kind of red car is this", "gt answer": "bmw(1.00)<br/>sedan(0.60)", "pred answer": "honda", "question_id": 542865, "best approach": "image", "verif answer": "kawasaki", "anno approach": "image", "verif wiki answer": "kawasaki(0.6804)", "verif concept answer": "kawasaki(0.6746)", "verif image answer": "sedan(0.6518)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054286.jpg"}, {"question": "is this in a resturaunt or at home", "gt answer": "restaurant(1.00)<br/>home(0.60)", "pred answer": "home", "question_id": 214515, "best approach": "wiki, concept, image", "verif answer": "home", "anno approach": "image, wiki", "verif wiki answer": "home(0.7089)", "verif concept answer": "home(0.6781)", "verif image answer": "home(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000021451.jpg"}, {"question": "what type of transportation is shown", "gt answer": "bicycle(1.00)<br/>bike(0.60)", "pred answer": "bike", "question_id": 3307265, "best approach": "concept", "verif answer": "bike", "anno approach": "concept", "verif wiki answer": "bike(0.6343)", "verif concept answer": "bicycle(0.6374)", "verif image answer": "bike(0.7264)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000330726.jpg"}, {"question": "how fast does this machine travel", "gt answer": "80 mph(1.00)", "pred answer": "80 mph", "question_id": 455435, "best approach": "wiki, concept, image", "verif answer": "80 mph", "anno approach": "concept, wiki", "verif wiki answer": "80 mph(0.6077)", "verif concept answer": "80 mph(0.5845)", "verif image answer": "80 mph(0.5074)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045543.jpg"}, {"question": "what famous disney character flies with the help of the object in this picture", "gt answer": "mary poppins(1.00)", "pred answer": "mary poppins", "question_id": 4307105, "best approach": "wiki, concept, image", "verif answer": "mary poppins", "anno approach": "wiki", "verif wiki answer": "mary poppins(0.7307)", "verif concept answer": "mary poppins(0.7191)", "verif image answer": "mary poppins(0.6891)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430710.jpg"}, {"question": "what kind of eating utensil is on the plate", "gt answer": "spoon(1.00)<br/>fork(0.60)", "pred answer": "fork", "question_id": 1494985, "best approach": "wiki, concept, image", "verif answer": "fork", "anno approach": "image, wiki", "verif wiki answer": "fork(0.7298)", "verif concept answer": "fork(0.6940)", "verif image answer": "fork(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149498.jpg"}, {"question": "these people are wearing straps so they don't destroy what", "gt answer": "television(1.00)<br/>control(0.60)<br/>wall(0.60)", "pred answer": "fan", "question_id": 3719655, "best approach": "wiki, concept, image", "verif answer": "control", "anno approach": "image, concept, wiki", "verif wiki answer": "control(0.5005)", "verif concept answer": "control(0.5356)", "verif image answer": "control(0.5357)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371965.jpg"}, {"question": "what type of environment is in this picture", "gt answer": "desert(1.00)<br/>dessert(0.60)", "pred answer": "desert", "question_id": 290965, "best approach": "wiki, concept, image", "verif answer": "desert", "anno approach": "wiki", "verif wiki answer": "desert(0.7310)", "verif concept answer": "desert(0.7267)", "verif image answer": "desert(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029096.jpg"}, {"question": "what event or climb is this group undertaking", "gt answer": "cross country ski(1.00)", "pred answer": "ski", "question_id": 528195, "best approach": "", "verif answer": "ski", "anno approach": "", "verif wiki answer": "ski(0.6753)", "verif concept answer": "ski(0.7179)", "verif image answer": "ski(0.6734)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052819.jpg"}, {"question": "who can fix a broken urinal", "gt answer": "plumber(1.00)", "pred answer": "man", "question_id": 1615855, "best approach": "", "verif answer": "bathroom", "anno approach": "", "verif wiki answer": "bathroom(0.5001)", "verif concept answer": "bathroom(0.5004)", "verif image answer": "bathroom(0.5006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161585.jpg"}, {"question": "what company owns the truck", "gt answer": "u haul(1.00)", "pred answer": "delta", "question_id": 4898905, "best approach": "", "verif answer": "public", "anno approach": "", "verif wiki answer": "public(0.5819)", "verif concept answer": "public(0.6387)", "verif image answer": "boat(0.5217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489890.jpg"}, {"question": "how are the cucumbers chopped", "gt answer": "knife(1.00)<br/>small(0.60)", "pred answer": "slice", "question_id": 2147335, "best approach": "wiki, concept, image", "verif answer": "small", "anno approach": "wiki", "verif wiki answer": "small(0.5002)", "verif concept answer": "small(0.5000)", "verif image answer": "small(0.5048)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214733.jpg"}, {"question": "what move is this tennis player currently using", "gt answer": "serve(1.00)<br/>forehand(0.60)", "pred answer": "backhand", "question_id": 4397565, "best approach": "wiki, concept, image", "verif answer": "forehand", "anno approach": "wiki", "verif wiki answer": "forehand(0.7309)", "verif concept answer": "forehand(0.6986)", "verif image answer": "forehand(0.6801)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439756.jpg"}, {"question": "is this a road bike or a dirt bike", "gt answer": "dirt bike(1.00)<br/>road(0.60)", "pred answer": "dirt bike", "question_id": 1191245, "best approach": "wiki, concept", "verif answer": "dirt bike", "anno approach": "wiki", "verif wiki answer": "dirt bike(0.7311)", "verif concept answer": "dirt bike(0.7311)", "verif image answer": "race(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119124.jpg"}, {"question": "name the ingredients used for preparing this dish", "gt answer": "dough spinach cheese(1.00)<br/>flour(0.60)", "pred answer": "cheese", "question_id": 2525185, "best approach": "image", "verif answer": "flour", "anno approach": "image", "verif wiki answer": "cheese(0.6692)", "verif concept answer": "cheese(0.6825)", "verif image answer": "flour(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252518.jpg"}, {"question": "what type of wave is this image showing", "gt answer": "small(1.00)", "pred answer": "cumulus", "question_id": 4071025, "best approach": "wiki", "verif answer": "8 inches", "anno approach": "wiki", "verif wiki answer": "small(0.7055)", "verif concept answer": "8 inches(0.7079)", "verif image answer": "8 inches(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407102.jpg"}, {"question": "what are the skate boards missing", "gt answer": "wheel(1.00)", "pred answer": "wheel", "question_id": 5278865, "best approach": "wiki, concept", "verif answer": "wheel", "anno approach": "wiki", "verif wiki answer": "wheel(0.7281)", "verif concept answer": "wheel(0.7139)", "verif image answer": "plastic(0.6843)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527886.jpg"}, {"question": "is this a truck or train stop", "gt answer": "truck(1.00)", "pred answer": "truck", "question_id": 2945455, "best approach": "wiki, concept, image", "verif answer": "truck", "anno approach": "wiki", "verif wiki answer": "truck(0.5001)", "verif concept answer": "truck(0.5001)", "verif image answer": "truck(0.5014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000294545.jpg"}, {"question": "what movie genre is referenced here", "gt answer": "scifi(1.00)", "pred answer": "wine", "question_id": 3404125, "best approach": "wiki, concept, image", "verif answer": "scifi", "anno approach": "", "verif wiki answer": "scifi(0.7196)", "verif concept answer": "scifi(0.6893)", "verif image answer": "scifi(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340412.jpg"}, {"question": "what is this technique called", "gt answer": "roast(1.00)<br/>bake(1.00)", "pred answer": "cook", "question_id": 314375, "best approach": "image", "verif answer": "grilled", "anno approach": "image", "verif wiki answer": "grilled(0.7050)", "verif concept answer": "cook(0.6506)", "verif image answer": "bake(0.5873)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000031437.jpg"}, {"question": "what is the marking on these animals calle", "gt answer": "brand(1.00)<br/>marker(0.60)<br/>number(0.60)", "pred answer": "striped", "question_id": 2190305, "best approach": "wiki, image", "verif answer": "number", "anno approach": "wiki", "verif wiki answer": "brand(0.6621)", "verif concept answer": "number(0.6693)", "verif image answer": "brand(0.6504)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219030.jpg"}, {"question": "what are these weapons used for", "gt answer": "cut(1.00)<br/>stab(0.60)<br/>protection(0.60)", "pred answer": "travel", "question_id": 5438145, "best approach": "concept", "verif answer": "sew", "anno approach": "concept", "verif wiki answer": "sew(0.6873)", "verif concept answer": "stab(0.7088)", "verif image answer": "sew(0.7221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543814.jpg"}, {"question": "how old must the man be the use the vehicle in this image", "gt answer": "18(1.00)<br/>21(0.60)", "pred answer": "17", "question_id": 176975, "best approach": "", "verif answer": "16", "anno approach": "", "verif wiki answer": "16(0.6933)", "verif concept answer": "nineteenth(0.6397)", "verif image answer": "16(0.6339)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000017697.jpg"}, {"question": "does the weather above to be above or below 50 degrees in this picture", "gt answer": "below(1.00)", "pred answer": "below", "question_id": 5792715, "best approach": "image", "verif answer": "below", "anno approach": "image", "verif wiki answer": "high(0.7195)", "verif concept answer": "high(0.7172)", "verif image answer": "below(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000579271.jpg"}, {"question": "what meal is this", "gt answer": "sandwich(1.00)<br/>lunch(0.60)", "pred answer": "lunch", "question_id": 1095685, "best approach": "concept", "verif answer": "lunch", "anno approach": "concept", "verif wiki answer": "hot dog(0.6908)", "verif concept answer": "lunch(0.7264)", "verif image answer": "burger(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000109568.jpg"}, {"question": "what animal is seen in this image", "gt answer": "duck(1.00)<br/>goose(0.60)<br/>swan(0.60)", "pred answer": "bear", "question_id": 4085025, "best approach": "", "verif answer": "canada goose", "anno approach": "", "verif wiki answer": "canada goose(0.6635)", "verif concept answer": "canada goose(0.6811)", "verif image answer": "canada goose(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408502.jpg"}, {"question": "who won the gold medal in women 's slalom skiing at the 2018 winter olympics", "gt answer": "frida hansdotter(1.00)<br/>tiffany(0.60)", "pred answer": "shawn white", "question_id": 1665995, "best approach": "image", "verif answer": "frida hansdotter", "anno approach": "image", "verif wiki answer": "bode miller(0.6495)", "verif concept answer": "bode miller(0.6301)", "verif image answer": "frida hansdotter(0.6996)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166599.jpg"}, {"question": "why does this man have his foot on the ground", "gt answer": "stopped(1.00)<br/>asphalt(0.60)<br/>balance(0.60)", "pred answer": "direct traffic", "question_id": 4498476, "best approach": "", "verif answer": "move", "anno approach": "", "verif wiki answer": "move(0.6560)", "verif concept answer": "move(0.6510)", "verif image answer": "move(0.7069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449847.jpg"}, {"question": "what move in surfing is this man performing", "gt answer": "flip(1.00)<br/>jump(0.60)", "pred answer": "wave", "question_id": 1032675, "best approach": "image", "verif answer": "kick flip", "anno approach": "image", "verif wiki answer": "kick flip(0.6872)", "verif concept answer": "kick flip(0.6451)", "verif image answer": "jump(0.6470)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103267.jpg"}, {"question": "is this a passenger train or freight train", "gt answer": "freight(1.00)", "pred answer": "freight", "question_id": 5019995, "best approach": "wiki", "verif answer": "cargo", "anno approach": "wiki", "verif wiki answer": "freight(0.7311)", "verif concept answer": "cargo(0.7311)", "verif image answer": "commuter(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501999.jpg"}, {"question": "what is the function of the black area in the middle of the item next to the keyboard", "gt answer": "scroll(1.00)", "pred answer": "heat", "question_id": 1274185, "best approach": "image", "verif answer": "scroll", "anno approach": "image", "verif wiki answer": "read(0.6391)", "verif concept answer": "read(0.6350)", "verif image answer": "scroll(0.6502)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127418.jpg"}, {"question": "what is the culinary term for this dish", "gt answer": "slider(1.00)<br/>burger(0.60)", "pred answer": "egg", "question_id": 1901355, "best approach": "", "verif answer": "sandwich", "anno approach": "", "verif wiki answer": "sandwich(0.6491)", "verif concept answer": "sandwich(0.6462)", "verif image answer": "sandwich(0.6265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190135.jpg"}, {"question": "what type of brain power is this large animal known for", "gt answer": "memory(1.00)", "pred answer": "tusk", "question_id": 4472435, "best approach": "", "verif answer": "party", "anno approach": "", "verif wiki answer": "ivory(0.6244)", "verif concept answer": "ivory(0.6333)", "verif image answer": "party(0.6335)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447243.jpg"}, {"question": "the white plumes behind the planes are called what", "gt answer": "contrail(1.00)<br/>smoke(0.60)<br/>jet(0.60)", "pred answer": "cloud", "question_id": 2901925, "best approach": "wiki, concept, image", "verif answer": "contrail", "anno approach": "wiki", "verif wiki answer": "contrail(0.7310)", "verif concept answer": "contrail(0.7309)", "verif image answer": "contrail(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000290192.jpg"}, {"question": "if five hits the ball hard enough that no one catches it and then runs through all the bases then that is called a what", "gt answer": "home run(1.00)<br/>homerun(0.60)", "pred answer": "hit", "question_id": 3120505, "best approach": "wiki, image", "verif answer": "home run", "anno approach": "wiki", "verif wiki answer": "home run(0.6771)", "verif concept answer": "court(0.7057)", "verif image answer": "home run(0.7100)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312050.jpg"}, {"question": "what type of function is this man at", "gt answer": "wine taste(1.00)<br/>party(0.60)", "pred answer": "dine", "question_id": 472135, "best approach": "", "verif answer": "family reunion", "anno approach": "", "verif wiki answer": "family reunion(0.6661)", "verif concept answer": "anniversary(0.6577)", "verif image answer": "family reunion(0.6720)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047213.jpg"}, {"question": "is this in a hotel or hospital room", "gt answer": "hospital(1.00)", "pred answer": "hilton", "question_id": 4251235, "best approach": "wiki, concept, image", "verif answer": "hospital", "anno approach": "wiki", "verif wiki answer": "hospital(0.7311)", "verif concept answer": "hospital(0.7219)", "verif image answer": "hospital(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425123.jpg"}, {"question": "what is the goal of the game these boys are playing", "gt answer": "catch(1.00)<br/>catch frisbee(1.00)", "pred answer": "frisbee", "question_id": 4452445, "best approach": "", "verif answer": "frisbee", "anno approach": "", "verif wiki answer": "frisbee(0.6099)", "verif concept answer": "frisbee(0.5979)", "verif image answer": "goal(0.5608)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445244.jpg"}, {"question": "what company is this plane owned by", "gt answer": "united(1.00)<br/>american(0.60)", "pred answer": "boeing", "question_id": 3896825, "best approach": "", "verif answer": "boeing", "anno approach": "", "verif wiki answer": "boeing(0.6361)", "verif concept answer": "boeing(0.6383)", "verif image answer": "boeing(0.5717)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389682.jpg"}, {"question": "what is the pattern on the umbrella", "gt answer": "striped(1.00)<br/>stripe(1.00)", "pred answer": "stripe", "question_id": 3987705, "best approach": "wiki, concept, image", "verif answer": "stripe", "anno approach": "concept, wiki", "verif wiki answer": "stripe(0.7310)", "verif concept answer": "stripe(0.7310)", "verif image answer": "stripe(0.6897)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398770.jpg"}, {"question": "", "gt answer": "walkway(0.60)<br/>airstair(0.60)", "pred answer": "jet bridge", "question_id": 4295735, "best approach": "", "verif answer": "train", "anno approach": "", "verif wiki answer": "train(0.6487)", "verif concept answer": "train(0.5188)", "verif image answer": "train(0.5006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429573.jpg"}, {"question": "what are the squares behind the animal", "gt answer": "screen(1.00)<br/>fence(0.60)<br/>white(0.60)", "pred answer": "blind", "question_id": 3384685, "best approach": "wiki, concept", "verif answer": "purple", "anno approach": "wiki", "verif wiki answer": "fence(0.7194)", "verif concept answer": "fence(0.6932)", "verif image answer": "purple(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338468.jpg"}, {"question": "what breed of cat is this", "gt answer": "hairless(1.00)<br/>siamese(0.60)", "pred answer": "siamese", "question_id": 3221215, "best approach": "image", "verif answer": "siamese", "anno approach": "image", "verif wiki answer": "sheep dog(0.6288)", "verif concept answer": "sheep dog(0.6510)", "verif image answer": "siamese(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322121.jpg"}, {"question": "how many children play this sport a year", "gt answer": "million(1.00)<br/>thousand(0.60)", "pred answer": "3", "question_id": 1517565, "best approach": "wiki", "verif answer": "6", "anno approach": "wiki", "verif wiki answer": "million(0.6606)", "verif concept answer": "6(0.6652)", "verif image answer": "6(0.6540)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151756.jpg"}, {"question": "what was that club used for", "gt answer": "baseball(1.00)<br/>hit(0.60)<br/>hit baseball(0.60)<br/>bat(0.60)", "pred answer": "hit", "question_id": 3040885, "best approach": "", "verif answer": "baseball bat", "anno approach": "", "verif wiki answer": "baseball bat(0.6427)", "verif concept answer": "baseball bat(0.6348)", "verif image answer": "baseball bat(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304088.jpg"}, {"question": "what are these vehicles used for", "gt answer": "fish(1.00)<br/>sail(0.60)", "pred answer": "travel", "question_id": 1479245, "best approach": "image", "verif answer": "boat", "anno approach": "image", "verif wiki answer": "boat(0.7289)", "verif concept answer": "boat(0.7263)", "verif image answer": "fish(0.6947)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147924.jpg"}, {"question": "where is this located", "gt answer": "beach(1.00)", "pred answer": "beach", "question_id": 4415465, "best approach": "concept", "verif answer": "desert", "anno approach": "concept", "verif wiki answer": "desert(0.7305)", "verif concept answer": "beach(0.7052)", "verif image answer": "desert(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441546.jpg"}, {"question": "what trick is being performed", "gt answer": "backflip(1.00)<br/>flip(0.60)", "pred answer": "ski", "question_id": 3577595, "best approach": "", "verif answer": "trick", "anno approach": "", "verif wiki answer": "trick(0.7311)", "verif concept answer": "trick(0.7311)", "verif image answer": "trick(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357759.jpg"}, {"question": "is the cat awake or sleep", "gt answer": "awake(1.00)", "pred answer": "rest", "question_id": 1093935, "best approach": "", "verif answer": "both", "anno approach": "", "verif wiki answer": "both(0.5221)", "verif concept answer": "both(0.5003)", "verif image answer": "both(0.5005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000109393.jpg"}, {"question": "what kind of building is this", "gt answer": "tower(1.00)<br/>clock tower(0.60)<br/>church(0.60)<br/>courthouse(0.60)", "pred answer": "church", "question_id": 634955, "best approach": "wiki, concept, image", "verif answer": "tower", "anno approach": "image, wiki", "verif wiki answer": "tower(0.6502)", "verif concept answer": "tower(0.6512)", "verif image answer": "tower(0.6894)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063495.jpg"}, {"question": "what lines the separation in this photo", "gt answer": "fence(1.00)", "pred answer": "gate", "question_id": 3814035, "best approach": "image", "verif answer": "stair", "anno approach": "image", "verif wiki answer": "stair(0.5416)", "verif concept answer": "stair(0.5317)", "verif image answer": "fence(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381403.jpg"}, {"question": "what kind of haircut does this girl have", "gt answer": "bob(1.00)", "pred answer": "bun", "question_id": 2294945, "best approach": "image", "verif answer": "bob", "anno approach": "image", "verif wiki answer": "pony tail(0.7307)", "verif concept answer": "pony tail(0.7282)", "verif image answer": "bob(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000229494.jpg"}, {"question": "what type of cooktop does the stove have", "gt answer": "gas(1.00)<br/>glass(0.60)", "pred answer": "marble", "question_id": 4033255, "best approach": "", "verif answer": "electric", "anno approach": "", "verif wiki answer": "electric(0.7311)", "verif concept answer": "electric(0.7311)", "verif image answer": "outboard(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403325.jpg"}, {"question": "what is required to do what the man on the left is doing", "gt answer": "camera(1.00)<br/>plate(0.60)<br/>film(0.60)", "pred answer": "talk", "question_id": 4603625, "best approach": "wiki, concept", "verif answer": "camera", "anno approach": "wiki", "verif wiki answer": "camera(0.6493)", "verif concept answer": "camera(0.6479)", "verif image answer": "pizza(0.6151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460362.jpg"}, {"question": "what type of fuel would this type of vehicle need", "gt answer": "gasoline(1.00)<br/>gas(0.60)", "pred answer": "gasoline", "question_id": 1911735, "best approach": "wiki, concept", "verif answer": "gasoline", "anno approach": "wiki", "verif wiki answer": "gasoline(0.6854)", "verif concept answer": "gasoline(0.6415)", "verif image answer": "diesel(0.6446)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191173.jpg"}, {"question": "what type of day is this", "gt answer": "cloudy(1.00)", "pred answer": "cloudy", "question_id": 5018515, "best approach": "wiki, concept, image", "verif answer": "cloudy", "anno approach": "wiki", "verif wiki answer": "cloudy(0.7310)", "verif concept answer": "cloudy(0.7311)", "verif image answer": "cloudy(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501851.jpg"}, {"question": "what company makes the product that the man is drinking", "gt answer": "coca cola(1.00)<br/>coke(0.60)", "pred answer": "wilson", "question_id": 5276495, "best approach": "", "verif answer": "pepsi", "anno approach": "", "verif wiki answer": "pepsi(0.5016)", "verif concept answer": "pepsi(0.5035)", "verif image answer": "pepsi(0.7130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527649.jpg"}, {"question": "what do you use this yellow thing for", "gt answer": "fly(1.00)", "pred answer": "transportation", "question_id": 1794795, "best approach": "wiki, concept, image", "verif answer": "fly", "anno approach": "wiki", "verif wiki answer": "fly(0.7310)", "verif concept answer": "fly(0.7293)", "verif image answer": "fly(0.7211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000179479.jpg"}, {"question": "what kind of job is this", "gt answer": "athlete(1.00)", "pred answer": "wine taster", "question_id": 2129985, "best approach": "", "verif answer": "referee", "anno approach": "", "verif wiki answer": "opponent(0.7308)", "verif concept answer": "opponent(0.7306)", "verif image answer": "referee(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212998.jpg"}, {"question": "what is the freeway portion over the street called", "gt answer": "overpass(1.00)<br/>bridge(0.60)", "pred answer": "asphalt", "question_id": 4012295, "best approach": "wiki, concept, image", "verif answer": "overpass", "anno approach": "", "verif wiki answer": "overpass(0.7308)", "verif concept answer": "overpass(0.7296)", "verif image answer": "overpass(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401229.jpg"}, {"question": "is this a meal or snack", "gt answer": "snack(1.00)", "pred answer": "snack", "question_id": 5220745, "best approach": "wiki, concept, image", "verif answer": "snack", "anno approach": "wiki", "verif wiki answer": "snack(0.6282)", "verif concept answer": "snack(0.5703)", "verif image answer": "snack(0.5888)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522074.jpg"}, {"question": "is the sun rising or setting", "gt answer": "set(1.00)", "pred answer": "sunset", "question_id": 702615, "best approach": "", "verif answer": "windsor", "anno approach": "", "verif wiki answer": "windsor(0.5847)", "verif concept answer": "windsor(0.6522)", "verif image answer": "simulation(0.6410)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070261.jpg"}, {"question": "what branch of the military are these uniforms from", "gt answer": "army(1.00)<br/>navy(1.00)<br/>air force(0.60)", "pred answer": "marine", "question_id": 3239585, "best approach": "", "verif answer": "marine", "anno approach": "", "verif wiki answer": "marine(0.7311)", "verif concept answer": "marine(0.7311)", "verif image answer": "marine(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323958.jpg"}, {"question": "what kind of boat is being used", "gt answer": "motor boat(1.00)<br/>wooden(0.60)<br/>row boat(0.60)", "pred answer": "canoe", "question_id": 3105735, "best approach": "image", "verif answer": "row", "anno approach": "image", "verif wiki answer": "row(0.6542)", "verif concept answer": "row(0.6279)", "verif image answer": "wooden(0.6325)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310573.jpg"}, {"question": "what is the menu at this restaurant", "gt answer": "taco(1.00)", "pred answer": "spanish", "question_id": 4746145, "best approach": "", "verif answer": "mexican", "anno approach": "", "verif wiki answer": "mexican(0.6515)", "verif concept answer": "mexican(0.6576)", "verif image answer": "mexican(0.5916)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000474614.jpg"}, {"question": "what kind of media is she reading", "gt answer": "magazine(1.00)", "pred answer": "picture", "question_id": 4975585, "best approach": "", "verif answer": "better home", "anno approach": "", "verif wiki answer": "better home(0.7185)", "verif concept answer": "better home(0.7269)", "verif image answer": "better home(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497558.jpg"}, {"question": "how old is the tan building on the left", "gt answer": "100(1.00)<br/>50 years(0.60)<br/>100 years(0.60)", "pred answer": "50 years", "question_id": 2050475, "best approach": "wiki, concept, image", "verif answer": "50 years", "anno approach": "", "verif wiki answer": "50 years(0.6692)", "verif concept answer": "100 years(0.6473)", "verif image answer": "100 years(0.6449)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205047.jpg"}, {"question": "how many seconds does the player have to hold the item before he has to pass", "gt answer": "30(1.00)<br/>3(0.60)<br/>5(0.60)", "pred answer": "16", "question_id": 2423615, "best approach": "wiki, concept", "verif answer": "30", "anno approach": "concept, wiki", "verif wiki answer": "30(0.6582)", "verif concept answer": "30(0.7116)", "verif image answer": "3(0.6487)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000242361.jpg"}, {"question": "what does this symbol mean", "gt answer": "stop(1.00)", "pred answer": "street name", "question_id": 5724875, "best approach": "", "verif answer": "wrong way", "anno approach": "", "verif wiki answer": "wrong way(0.6365)", "verif concept answer": "wrong way(0.6344)", "verif image answer": "brake(0.5306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572487.jpg"}, {"question": "how old do you believe this building is", "gt answer": "100 years(1.00)", "pred answer": "19th", "question_id": 3844125, "best approach": "", "verif answer": "50 years", "anno approach": "", "verif wiki answer": "50 years(0.6602)", "verif concept answer": "1886(0.6443)", "verif image answer": "50 years(0.6338)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384412.jpg"}, {"question": "what type of knot is this", "gt answer": "windsor(1.00)<br/>tie(1.00)", "pred answer": "windsor", "question_id": 4230505, "best approach": "concept, image", "verif answer": "windsor", "anno approach": "image", "verif wiki answer": "bow tie(0.6528)", "verif concept answer": "windsor(0.6465)", "verif image answer": "windsor(0.6916)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000423050.jpg"}, {"question": "what nickname for the furry animal starts with the same letter as the food in the box", "gt answer": "pussy(1.00)", "pred answer": "cat", "question_id": 4378575, "best approach": "", "verif answer": "chicago", "anno approach": "", "verif wiki answer": "taxi(0.5064)", "verif concept answer": "taxi(0.5003)", "verif image answer": "chicago(0.5125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437857.jpg"}, {"question": "what is this group about to do", "gt answer": "ski(1.00)", "pred answer": "ski", "question_id": 2773215, "best approach": "", "verif answer": "ski pole", "anno approach": "", "verif wiki answer": "skate(0.6728)", "verif concept answer": "skate(0.6794)", "verif image answer": "ski pole(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277321.jpg"}, {"question": "what is he walking on", "gt answer": "sidewalk(1.00)<br/>pavement(0.60)", "pred answer": "street", "question_id": 603875, "best approach": "wiki", "verif answer": "pavement", "anno approach": "wiki", "verif wiki answer": "sidewalk(0.6668)", "verif concept answer": "pavement(0.7309)", "verif image answer": "street(0.5254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060387.jpg"}, {"question": "would you say these objects are organized or disorganized", "gt answer": "disorganized(1.00)", "pred answer": "produce", "question_id": 1306105, "best approach": "wiki, concept, image", "verif answer": "disorganized", "anno approach": "wiki", "verif wiki answer": "disorganized(0.5341)", "verif concept answer": "disorganized(0.5206)", "verif image answer": "disorganized(0.5119)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130610.jpg"}, {"question": "is this snow or sand", "gt answer": "snow(1.00)", "pred answer": "fresh", "question_id": 1586765, "best approach": "wiki, concept", "verif answer": "slope", "anno approach": "concept, wiki", "verif wiki answer": "snow(0.5244)", "verif concept answer": "snow(0.5618)", "verif image answer": "slope(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000158676.jpg"}, {"question": "what position is depicted here", "gt answer": "batter(1.00)<br/>hitter(0.60)<br/>base(0.60)", "pred answer": "batter", "question_id": 3785225, "best approach": "", "verif answer": "home", "anno approach": "", "verif wiki answer": "home(0.5202)", "verif concept answer": "home(0.5280)", "verif image answer": "home(0.5459)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378522.jpg"}, {"question": "what dessert is this", "gt answer": "cheesecake(1.00)", "pred answer": "cake", "question_id": 3594795, "best approach": "wiki, concept, image", "verif answer": "cheesecake", "anno approach": "wiki", "verif wiki answer": "cheesecake(0.6998)", "verif concept answer": "cheesecake(0.7214)", "verif image answer": "cheesecake(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359479.jpg"}, {"question": "what walking aid is this man using", "gt answer": "cane(1.00)<br/>crutch(0.60)", "pred answer": "hose", "question_id": 5358985, "best approach": "wiki", "verif answer": "desk", "anno approach": "wiki", "verif wiki answer": "crutch(0.6580)", "verif concept answer": "sidewalk(0.6383)", "verif image answer": "desk(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535898.jpg"}, {"question": "what holiday do many people drink guinness on", "gt answer": "st patrick's day(1.00)", "pred answer": "valentine's day", "question_id": 2765145, "best approach": "wiki", "verif answer": "thanksgiving", "anno approach": "wiki", "verif wiki answer": "st patrick's day(0.7198)", "verif concept answer": "thanksgiving(0.7077)", "verif image answer": "thanksgiving(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276514.jpg"}, {"question": "this dog is being held back by what", "gt answer": "leash(1.00)", "pred answer": "leash", "question_id": 291895, "best approach": "wiki", "verif answer": "leather", "anno approach": "wiki", "verif wiki answer": "leash(0.7292)", "verif concept answer": "leather(0.7163)", "verif image answer": "leather(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029189.jpg"}, {"question": "would this person be more likely to be a type a or b person", "gt answer": "(1.00)<br/>type(1.00)<br/>b(0.60)", "pred answer": "professional", "question_id": 1782755, "best approach": "", "verif answer": "vitamin", "anno approach": "", "verif wiki answer": "vitamin(0.6248)", "verif concept answer": "vitamin(0.6226)", "verif image answer": "vitamin(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178275.jpg"}, {"question": "what companies sell the outdoor gear the people are wearing", "gt answer": "rei(1.00)<br/>columbia(0.60)", "pred answer": "pole", "question_id": 2650235, "best approach": "", "verif answer": "north face", "anno approach": "", "verif wiki answer": "adidas(0.6594)", "verif concept answer": "adidas(0.6644)", "verif image answer": "north face(0.7057)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265023.jpg"}, {"question": "what type of instrument is he holding", "gt answer": "guitar(1.00)", "pred answer": "piano", "question_id": 2221275, "best approach": "wiki, concept, image", "verif answer": "guitar", "anno approach": "wiki", "verif wiki answer": "guitar(0.7310)", "verif concept answer": "guitar(0.7310)", "verif image answer": "guitar(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222127.jpg"}, {"question": "what brand of cell phone is the man in green using", "gt answer": "iphone(1.00)<br/>nokia(0.60)<br/>samsung(0.60)<br/>sony(0.60)", "pred answer": "iphone", "question_id": 3264805, "best approach": "concept, image", "verif answer": "nokia", "anno approach": "", "verif wiki answer": "smartphone(0.7310)", "verif concept answer": "nokia(0.7311)", "verif image answer": "nokia(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000326480.jpg"}, {"question": "what kind of cocktail is this woman drinking", "gt answer": "martini(1.00)", "pred answer": "vodka cranberry", "question_id": 862215, "best approach": "", "verif answer": "vodka cranberry", "anno approach": "", "verif wiki answer": "vodka cranberry(0.7311)", "verif concept answer": "vodka cranberry(0.7311)", "verif image answer": "vodka cranberry(0.7136)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086221.jpg"}, {"question": "what is the guy on the horse doing with the cattle", "gt answer": "herd(1.00)<br/>drive(0.60)", "pred answer": "row", "question_id": 1787545, "best approach": "", "verif answer": "shepherd", "anno approach": "", "verif wiki answer": "shepherd(0.6475)", "verif concept answer": "shepherd(0.6692)", "verif image answer": "shepherd(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178754.jpg"}, {"question": "the fruit in the picture is a good source of what vitamin", "gt answer": "vitamin c(1.00)<br/>b(0.60)<br/>orange(0.60)", "pred answer": "vitamin", "question_id": 5589175, "best approach": "", "verif answer": "c", "anno approach": "", "verif wiki answer": "c(0.6670)", "verif concept answer": "c(0.7175)", "verif image answer": "c(0.6824)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558917.jpg"}, {"question": "where is all the pie", "gt answer": "eaten(1.00)", "pred answer": "table", "question_id": 2622615, "best approach": "", "verif answer": "trash", "anno approach": "", "verif wiki answer": "trash(0.7310)", "verif concept answer": "trash(0.7112)", "verif image answer": "trash(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262261.jpg"}, {"question": "what gender normally uses these products", "gt answer": "female(1.00)<br/>women(1.00)", "pred answer": "female", "question_id": 2088825, "best approach": "wiki, concept, image", "verif answer": "female", "anno approach": "concept, wiki", "verif wiki answer": "female(0.7303)", "verif concept answer": "female(0.6842)", "verif image answer": "female(0.5181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208882.jpg"}, {"question": "who is the leading player of this sport", "gt answer": "babe ruth(1.00)<br/>batter(0.60)", "pred answer": "pitcher", "question_id": 2525675, "best approach": "", "verif answer": "randy johnson", "anno approach": "", "verif wiki answer": "randy johnson(0.7303)", "verif concept answer": "randy johnson(0.7293)", "verif image answer": "randy johnson(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252567.jpg"}, {"question": "are they racing or playing a game", "gt answer": "play game(1.00)<br/>game(1.00)<br/>play(0.60)", "pred answer": "horse race", "question_id": 3127445, "best approach": "wiki, concept, image", "verif answer": "play", "anno approach": "wiki", "verif wiki answer": "play(0.5000)", "verif concept answer": "play(0.5001)", "verif image answer": "play(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312744.jpg"}, {"question": "what kind of plant is the bird looking at", "gt answer": "cactus(1.00)<br/>aloe(0.60)", "pred answer": "leaf", "question_id": 2370985, "best approach": "image", "verif answer": "cactus", "anno approach": "image", "verif wiki answer": "moss(0.6226)", "verif concept answer": "moss(0.6441)", "verif image answer": "cactus(0.6969)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237098.jpg"}, {"question": "where would a drink be stored in this room", "gt answer": "refrigerator(1.00)<br/>fridge(0.60)", "pred answer": "refrigerator", "question_id": 2889485, "best approach": "", "verif answer": "magnet", "anno approach": "", "verif wiki answer": "magnet(0.7296)", "verif concept answer": "magnet(0.6491)", "verif image answer": "magnet(0.6410)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288948.jpg"}, {"question": "the child in black is running towards what base", "gt answer": "first(1.00)<br/>1st(0.60)<br/>home(0.60)", "pred answer": "second", "question_id": 3173065, "best approach": "wiki, concept, image", "verif answer": "first", "anno approach": "wiki", "verif wiki answer": "first(0.6462)", "verif concept answer": "first(0.6473)", "verif image answer": "first(0.6442)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317306.jpg"}, {"question": "what is this part of the house used for", "gt answer": "bath(1.00)<br/>defecation(0.60)", "pred answer": "bath", "question_id": 534255, "best approach": "concept", "verif answer": "bath", "anno approach": "concept", "verif wiki answer": "bathroom(0.6570)", "verif concept answer": "bath(0.7087)", "verif image answer": "bathroom(0.6468)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053425.jpg"}, {"question": "how much did this motorcycle cost", "gt answer": "5000(1.00)", "pred answer": "5 pounds", "question_id": 828005, "best approach": "", "verif answer": "4000", "anno approach": "", "verif wiki answer": "4000(0.6463)", "verif concept answer": "4000(0.6332)", "verif image answer": "4000(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082800.jpg"}, {"question": "in what state can this street be found", "gt answer": "ohio(1.00)<br/>new york(0.60)", "pred answer": "new york", "question_id": 643565, "best approach": "wiki, concept", "verif answer": "columbus", "anno approach": "wiki", "verif wiki answer": "new york(0.6491)", "verif concept answer": "new york(0.6443)", "verif image answer": "columbus(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064356.jpg"}, {"question": "what is on the tv", "gt answer": "video game(1.00)<br/>game(0.60)", "pred answer": "speed skate", "question_id": 2762445, "best approach": "", "verif answer": "play video game", "anno approach": "", "verif wiki answer": "play video game(0.7296)", "verif concept answer": "play video game(0.7306)", "verif image answer": "play game(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276244.jpg"}, {"question": "where are the eating out of the same bowl", "gt answer": "kitchen(1.00)", "pred answer": "refridgerator", "question_id": 5420605, "best approach": "", "verif answer": "restaurant", "anno approach": "", "verif wiki answer": "restaurant(0.7307)", "verif concept answer": "restaurant(0.7295)", "verif image answer": "restaurant(0.6824)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542060.jpg"}, {"question": "what family of fruits is shown", "gt answer": "citrus(1.00)", "pred answer": "orange", "question_id": 5535425, "best approach": "", "verif answer": "orange and lime", "anno approach": "", "verif wiki answer": "orange and lime(0.7311)", "verif concept answer": "orange and lime(0.7311)", "verif image answer": "orange(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553542.jpg"}, {"question": "which military department is in this photo", "gt answer": "air force(1.00)<br/>airforce(0.60)<br/>navy(0.60)", "pred answer": "air force", "question_id": 1434395, "best approach": "wiki, concept", "verif answer": "air force", "anno approach": "wiki", "verif wiki answer": "air force(0.5006)", "verif concept answer": "air force(0.5000)", "verif image answer": "airforce(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143439.jpg"}, {"question": "the bright color that can be seen over the window shade is often associated with which february holiday", "gt answer": "valentine's day(1.00)<br/>valentine's(1.00)", "pred answer": "christmas", "question_id": 3370685, "best approach": "wiki, concept", "verif answer": "valentine", "anno approach": "wiki", "verif wiki answer": "valentine's(0.6523)", "verif concept answer": "valentine's(0.6618)", "verif image answer": "valentine(0.6852)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337068.jpg"}, {"question": "what does this sign signify", "gt answer": "speed limit(1.00)", "pred answer": "brake", "question_id": 1372815, "best approach": "", "verif answer": "direct", "anno approach": "", "verif wiki answer": "direct(0.6369)", "verif concept answer": "direct(0.5697)", "verif image answer": "direct(0.5704)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000137281.jpg"}, {"question": "what device is this person pointing at", "gt answer": "microwave(1.00)<br/>computer(0.60)", "pred answer": "toy", "question_id": 5006945, "best approach": "wiki, concept", "verif answer": "electron", "anno approach": "wiki", "verif wiki answer": "microwave(0.5051)", "verif concept answer": "microwave(0.5057)", "verif image answer": "electron(0.6260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500694.jpg"}, {"question": "name the material used to make this handbag shown in this picture", "gt answer": "canvas(1.00)<br/>paper(0.60)", "pred answer": "leather", "question_id": 591745, "best approach": "", "verif answer": "plastic", "anno approach": "", "verif wiki answer": "ceramic(0.5001)", "verif concept answer": "ceramic(0.5058)", "verif image answer": "plastic(0.6450)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059174.jpg"}, {"question": "is this hygienic or unhygienic", "gt answer": "unhygienic(1.00)", "pred answer": "healthy", "question_id": 3639335, "best approach": "wiki, concept, image", "verif answer": "unhygienic", "anno approach": "", "verif wiki answer": "unhygienic(0.7310)", "verif concept answer": "unhygienic(0.7310)", "verif image answer": "unhygienic(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363933.jpg"}, {"question": "name the place where these elephant is standing in this picture", "gt answer": "zoo(1.00)<br/>pen(0.60)", "pred answer": "zoo", "question_id": 445445, "best approach": "wiki, concept, image", "verif answer": "zoo", "anno approach": "image, concept, wiki", "verif wiki answer": "zoo(0.6677)", "verif concept answer": "zoo(0.7310)", "verif image answer": "zoo(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000044544.jpg"}, {"question": "which type of driving surface is the car driving on", "gt answer": "asphalt(1.00)<br/>road(0.60)", "pred answer": "asphalt", "question_id": 5689845, "best approach": "wiki, concept, image", "verif answer": "asphalt", "anno approach": "concept, wiki", "verif wiki answer": "asphalt(0.7025)", "verif concept answer": "asphalt(0.7232)", "verif image answer": "asphalt(0.6809)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568984.jpg"}, {"question": "what is on the mans face", "gt answer": "glass(1.00)<br/>beard(0.60)<br/>mustache(0.60)", "pred answer": "glass", "question_id": 1858185, "best approach": "wiki, concept", "verif answer": "glass", "anno approach": "wiki", "verif wiki answer": "glass(0.6636)", "verif concept answer": "glass(0.6557)", "verif image answer": "beard(0.5201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185818.jpg"}, {"question": "how do you score in this game", "gt answer": "catch frisbee(1.00)<br/>goal(0.60)", "pred answer": "bat", "question_id": 3786215, "best approach": "", "verif answer": "tan", "anno approach": "", "verif wiki answer": "tan(0.7194)", "verif concept answer": "tan(0.6740)", "verif image answer": "tan(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378621.jpg"}, {"question": "in what type of events would multiple planes fly in formation", "gt answer": "airshow(1.00)<br/>show(0.60)", "pred answer": "military", "question_id": 5812185, "best approach": "wiki, concept", "verif answer": "show", "anno approach": "wiki", "verif wiki answer": "show(0.7100)", "verif concept answer": "show(0.6191)", "verif image answer": "ww2(0.5755)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000581218.jpg"}, {"question": "is the bus for tourists or public transportation", "gt answer": "tourist(1.00)<br/>public(0.60)<br/>both(0.60)", "pred answer": "tour", "question_id": 1112355, "best approach": "image", "verif answer": "public", "anno approach": "image", "verif wiki answer": "public(0.7311)", "verif concept answer": "public(0.5021)", "verif image answer": "tourist(0.6947)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111235.jpg"}, {"question": "what typeof dress material the children is wearing in this picture", "gt answer": "costume(1.00)<br/>cotton(0.60)<br/>sleep(0.60)", "pred answer": "metal", "question_id": 616065, "best approach": "concept", "verif answer": "children", "anno approach": "concept", "verif wiki answer": "children(0.6115)", "verif concept answer": "costume(0.6030)", "verif image answer": "children(0.6812)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061606.jpg"}, {"question": "the smoking woman can develop what illness if she makes her habit lifelong", "gt answer": "cancer(1.00)<br/>lung cancer(0.60)", "pred answer": "tired", "question_id": 2225885, "best approach": "wiki, concept", "verif answer": "lung cancer", "anno approach": "concept, wiki", "verif wiki answer": "lung cancer(0.6432)", "verif concept answer": "lung cancer(0.7094)", "verif image answer": "scurvy(0.6530)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222588.jpg"}, {"question": "what is the name of the sport she is doing", "gt answer": "horseback ride(1.00)<br/>polo(0.60)<br/>equestrian(0.60)", "pred answer": "polo", "question_id": 1842465, "best approach": "wiki, concept, image", "verif answer": "polo", "anno approach": "wiki", "verif wiki answer": "polo(0.7306)", "verif concept answer": "polo(0.7310)", "verif image answer": "polo(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184246.jpg"}, {"question": "what is the name of that toy in the background", "gt answer": "ring(1.00)", "pred answer": "cake", "question_id": 5440465, "best approach": "", "verif answer": "walmart", "anno approach": "", "verif wiki answer": "walmart(0.5140)", "verif concept answer": "sailor(0.5768)", "verif image answer": "walmart(0.6846)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544046.jpg"}, {"question": "would species of bird is this", "gt answer": "woodpecker(1.00)<br/>hummingbird(1.00)", "pred answer": "finch", "question_id": 1148985, "best approach": "", "verif answer": "bird", "anno approach": "", "verif wiki answer": "bird(0.7310)", "verif concept answer": "bird(0.7301)", "verif image answer": "bird(0.7225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114898.jpg"}, {"question": "what restaurant was this dish cooked at", "gt answer": "ihop(1.00)<br/>diner(0.60)", "pred answer": "french", "question_id": 3517705, "best approach": "concept", "verif answer": "diner", "anno approach": "concept", "verif wiki answer": "deli(0.6459)", "verif concept answer": "diner(0.6687)", "verif image answer": "martha(0.6481)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351770.jpg"}, {"question": "what pork dish does big j 's serve", "gt answer": "pulled pork(1.00)<br/>bacon(0.60)", "pred answer": "hotdog", "question_id": 5262915, "best approach": "", "verif answer": "ham", "anno approach": "", "verif wiki answer": "ham(0.6599)", "verif concept answer": "ham(0.6427)", "verif image answer": "ham(0.5916)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526291.jpg"}, {"question": "what is the name of the person that designed these", "gt answer": "george stephenson(1.00)<br/>richard trevithick(0.60)", "pred answer": "engineer", "question_id": 2069755, "best approach": "", "verif answer": "pole", "anno approach": "", "verif wiki answer": "pole(0.7310)", "verif concept answer": "pole(0.7302)", "verif image answer": "pole(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206975.jpg"}, {"question": "what style of skiing is this", "gt answer": "mogul(1.00)<br/>normal(0.60)<br/>alpine(0.60)", "pred answer": "cross country", "question_id": 3901206, "best approach": "wiki, concept, image", "verif answer": "normal", "anno approach": "image, wiki", "verif wiki answer": "alpine(0.6450)", "verif concept answer": "normal(0.6402)", "verif image answer": "normal(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390120.jpg"}, {"question": "what is the name of the mascot shown in the picture", "gt answer": "oriole(1.00)<br/>penguin(0.60)", "pred answer": "stripe", "question_id": 3891455, "best approach": "wiki, image", "verif answer": "oriole", "anno approach": "", "verif wiki answer": "oriole(0.7246)", "verif concept answer": "red sox(0.6307)", "verif image answer": "oriole(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389145.jpg"}, {"question": "did he miss or score a point", "gt answer": "score(1.00)", "pred answer": "hit", "question_id": 2194075, "best approach": "", "verif answer": "serve", "anno approach": "", "verif wiki answer": "serve(0.6151)", "verif concept answer": "serve(0.5508)", "verif image answer": "serve(0.6955)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219407.jpg"}, {"question": "what is the proper name of someone who drives a vehicle like this", "gt answer": "conductor(1.00)<br/>engineer(0.60)", "pred answer": "engineer", "question_id": 3082925, "best approach": "wiki, image", "verif answer": "engineer", "anno approach": "wiki", "verif wiki answer": "conductor(0.7304)", "verif concept answer": "engineer(0.7310)", "verif image answer": "conductor(0.6967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308292.jpg"}, {"question": "what is the man doing", "gt answer": "travel(1.00)", "pred answer": "travel", "question_id": 4912295, "best approach": "wiki, concept", "verif answer": "vacation", "anno approach": "wiki", "verif wiki answer": "travel(0.5891)", "verif concept answer": "travel(0.5255)", "verif image answer": "vacation(0.6384)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491229.jpg"}, {"question": "what is the name of this motorcycle", "gt answer": "dirt bike(1.00)<br/>tour(0.60)<br/>honda(0.60)", "pred answer": "harley davidson", "question_id": 2630315, "best approach": "", "verif answer": "motorbike", "anno approach": "", "verif wiki answer": "motorbike(0.6111)", "verif concept answer": "motorbike(0.6384)", "verif image answer": "motorbike(0.6439)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263031.jpg"}, {"question": "at what age do these open their eyes", "gt answer": "2 weeks(1.00)<br/>1 week(0.60)", "pred answer": "puppy", "question_id": 3159445, "best approach": "wiki, concept, image", "verif answer": "1 week", "anno approach": "wiki", "verif wiki answer": "1 week(0.7311)", "verif concept answer": "1 week(0.6791)", "verif image answer": "1 week(0.7087)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315944.jpg"}, {"question": "what would his room be classified as", "gt answer": "dine(1.00)", "pred answer": "kitchen", "question_id": 561165, "best approach": "", "verif answer": "adult", "anno approach": "", "verif wiki answer": "adult(0.6324)", "verif concept answer": "adult(0.6439)", "verif image answer": "tv(0.6292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000056116.jpg"}, {"question": "what holiday might they be celebrating", "gt answer": "st patrick's day(1.00)", "pred answer": "4th of july", "question_id": 1217825, "best approach": "", "verif answer": "july 4th", "anno approach": "", "verif wiki answer": "valentine(0.6507)", "verif concept answer": "july 4th(0.6963)", "verif image answer": "baby shower(0.6652)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000121782.jpg"}, {"question": "where would you typically find this animal", "gt answer": "forest(1.00)<br/>wood(0.60)", "pred answer": "forest", "question_id": 5461935, "best approach": "wiki, concept", "verif answer": "forest", "anno approach": "concept, wiki", "verif wiki answer": "forest(0.6454)", "verif concept answer": "forest(0.7043)", "verif image answer": "wood(0.6454)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546193.jpg"}, {"question": "what shape is shown in the image", "gt answer": "circle(1.00)<br/>round(0.60)", "pred answer": "circle", "question_id": 1601395, "best approach": "wiki, concept, image", "verif answer": "circle", "anno approach": "wiki", "verif wiki answer": "circle(0.7303)", "verif concept answer": "circle(0.7304)", "verif image answer": "circle(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160139.jpg"}, {"question": "what food is being made in this kitchen", "gt answer": "soup(1.00)<br/>pasta(1.00)", "pred answer": "popcorn", "question_id": 4215425, "best approach": "", "verif answer": "noodle", "anno approach": "", "verif wiki answer": "carrot(0.6414)", "verif concept answer": "carrot(0.6437)", "verif image answer": "noodle(0.6908)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421542.jpg"}, {"question": "what motor powers this bus", "gt answer": "diesel(1.00)<br/>electric(0.60)", "pred answer": "gas", "question_id": 3992365, "best approach": "wiki, concept, image", "verif answer": "electric", "anno approach": "concept, wiki", "verif wiki answer": "electric(0.7015)", "verif concept answer": "electric(0.7034)", "verif image answer": "electric(0.6495)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399236.jpg"}, {"question": "what is the person doing with the disc", "gt answer": "throw(1.00)<br/>throw it(0.60)", "pred answer": "catch", "question_id": 776635, "best approach": "", "verif answer": "pitch", "anno approach": "", "verif wiki answer": "pitch(0.7309)", "verif concept answer": "pitch(0.6818)", "verif image answer": "pitch(0.6734)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077663.jpg"}, {"question": "what branch of the military is this man from", "gt answer": "marine(1.00)<br/>navy(0.60)<br/>high(0.60)", "pred answer": "navy", "question_id": 2100105, "best approach": "wiki", "verif answer": "navy", "anno approach": "wiki", "verif wiki answer": "marine(0.7289)", "verif concept answer": "navy(0.6829)", "verif image answer": "navy(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210010.jpg"}, {"question": "on the plate is a hotdog chips and what fruit", "gt answer": "strawberry(1.00)", "pred answer": "blueberry", "question_id": 452675, "best approach": "wiki, concept, image", "verif answer": "strawberry", "anno approach": "wiki", "verif wiki answer": "strawberry(0.7061)", "verif concept answer": "strawberry(0.7017)", "verif image answer": "strawberry(0.6940)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045267.jpg"}, {"question": "what year was this sport invented", "gt answer": "1965(1.00)<br/>1800(0.60)", "pred answer": "1950", "question_id": 2844065, "best approach": "image", "verif answer": "1950", "anno approach": "image", "verif wiki answer": "1950(0.7310)", "verif concept answer": "1950(0.6865)", "verif image answer": "1965(0.6487)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284406.jpg"}, {"question": "what kind of sun protection should you use while doing this activity", "gt answer": "sunscreen(1.00)", "pred answer": "sunscreen", "question_id": 4277145, "best approach": "", "verif answer": "sun protection", "anno approach": "", "verif wiki answer": "sun protection(0.7310)", "verif concept answer": "sun protection(0.7310)", "verif image answer": "sun protection(0.6668)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427714.jpg"}, {"question": "what is the name for the popular statue in the background", "gt answer": "christ redeemer(1.00)<br/>air(0.60)<br/>cross(0.60)", "pred answer": "big ben", "question_id": 3487825, "best approach": "wiki, concept, image", "verif answer": "cross", "anno approach": "wiki", "verif wiki answer": "cross(0.7310)", "verif concept answer": "cross(0.7310)", "verif image answer": "cross(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348782.jpg"}, {"question": "what time is shown", "gt answer": "1:15(1.00)", "pred answer": "roman", "question_id": 4329645, "best approach": "", "verif answer": "3:52", "anno approach": "", "verif wiki answer": "3:52(0.7262)", "verif concept answer": "3:52(0.7293)", "verif image answer": "3:52(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432964.jpg"}, {"question": "what kind of airplane is this", "gt answer": "biplane(1.00)<br/>prop(0.60)<br/>private(0.60)", "pred answer": "biplane", "question_id": 1161715, "best approach": "image", "verif answer": "seaplane", "anno approach": "image", "verif wiki answer": "seaplane(0.7151)", "verif concept answer": "seaplane(0.7141)", "verif image answer": "biplane(0.6538)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116171.jpg"}, {"question": "what type of clouds appear in the picture", "gt answer": "nimbus(1.00)<br/>storm(0.60)", "pred answer": "cumulus", "question_id": 675715, "best approach": "", "verif answer": "cumulus", "anno approach": "", "verif wiki answer": "cumulus(0.7306)", "verif concept answer": "cumulus(0.7310)", "verif image answer": "cumulus(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067571.jpg"}, {"question": "who is throwing the ball", "gt answer": "catcher(1.00)<br/>pitcher(0.60)", "pred answer": "catcher", "question_id": 2955785, "best approach": "wiki, concept, image", "verif answer": "catcher", "anno approach": "concept, wiki", "verif wiki answer": "catcher(0.7308)", "verif concept answer": "catcher(0.7225)", "verif image answer": "catcher(0.5346)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295578.jpg"}, {"question": "what breed of dog is pictured", "gt answer": "mutt(1.00)<br/>collie(0.60)", "pred answer": "labrador", "question_id": 2354465, "best approach": "concept, image", "verif answer": "chihuahua", "anno approach": "", "verif wiki answer": "chihuahua(0.6957)", "verif concept answer": "collie(0.6464)", "verif image answer": "collie(0.6665)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000235446.jpg"}, {"question": "what book is that", "gt answer": "paperback(1.00)<br/>cook(0.60)", "pred answer": "walk in wood", "question_id": 5266665, "best approach": "wiki, concept, image", "verif answer": "paperback", "anno approach": "image, concept", "verif wiki answer": "paperback(0.5019)", "verif concept answer": "paperback(0.6455)", "verif image answer": "paperback(0.7081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526666.jpg"}, {"question": "how would the water taste that the man is riding on", "gt answer": "salty(1.00)", "pred answer": "wave", "question_id": 2152885, "best approach": "", "verif answer": "danger", "anno approach": "", "verif wiki answer": "danger(0.7274)", "verif concept answer": "danger(0.7052)", "verif image answer": "danger(0.7197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215288.jpg"}, {"question": "to what animal kingdom does this animal belong", "gt answer": "feline(1.00)<br/>lion(0.60)<br/>mammal(0.60)", "pred answer": "tiger", "question_id": 1938215, "best approach": "wiki, concept, image", "verif answer": "mammal", "anno approach": "wiki", "verif wiki answer": "mammal(0.6431)", "verif concept answer": "mammal(0.6539)", "verif image answer": "mammal(0.6708)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193821.jpg"}, {"question": "what disney movie is this object the center of", "gt answer": "beauty and beast(1.00)", "pred answer": "lassie", "question_id": 2505665, "best approach": "", "verif answer": "wizard of oz", "anno approach": "", "verif wiki answer": "wizard of oz(0.7296)", "verif concept answer": "wizard of oz(0.7309)", "verif image answer": "wizard of oz(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250566.jpg"}, {"question": "what languages are the signs are in", "gt answer": "chinese(1.00)", "pred answer": "chinese", "question_id": 1751935, "best approach": "", "verif answer": "korean", "anno approach": "", "verif wiki answer": "japanese(0.6472)", "verif concept answer": "english(0.6273)", "verif image answer": "korean(0.6930)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000175193.jpg"}, {"question": "what type of contest is featured at a show of this nature", "gt answer": "car show(1.00)<br/>car(1.00)<br/>race(0.60)", "pred answer": "horse race", "question_id": 280585, "best approach": "wiki, concept, image", "verif answer": "race", "anno approach": "concept, wiki", "verif wiki answer": "race(0.7302)", "verif concept answer": "race(0.7298)", "verif image answer": "race(0.6640)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028058.jpg"}, {"question": "how do a plane 's wings help them to fly", "gt answer": "lift(1.00)", "pred answer": "engine", "question_id": 3487155, "best approach": "", "verif answer": "flight", "anno approach": "", "verif wiki answer": "flight(0.6383)", "verif concept answer": "flight(0.6419)", "verif image answer": "flight(0.6298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348715.jpg"}, {"question": "when is it legal for the driver to resume driving", "gt answer": "green light(1.00)", "pred answer": "red light", "question_id": 2504175, "best approach": "wiki, concept", "verif answer": "green light", "anno approach": "wiki", "verif wiki answer": "green light(0.5989)", "verif concept answer": "green light(0.5414)", "verif image answer": "illegal(0.5108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250417.jpg"}, {"question": "is this a library or a bookstore", "gt answer": "library(1.00)<br/>bookstore(0.60)", "pred answer": "both", "question_id": 1878035, "best approach": "", "verif answer": "store", "anno approach": "", "verif wiki answer": "store(0.5007)", "verif concept answer": "store(0.5034)", "verif image answer": "online(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187803.jpg"}, {"question": "where was this photo taken", "gt answer": "intersection(1.00)<br/>above(0.60)<br/>outside(0.60)", "pred answer": "street", "question_id": 901945, "best approach": "wiki, concept", "verif answer": "above", "anno approach": "wiki", "verif wiki answer": "above(0.6128)", "verif concept answer": "above(0.6429)", "verif image answer": "street(0.6189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090194.jpg"}, {"question": "what is the name of the type of shirt this woman is wearing", "gt answer": "tank top(1.00)", "pred answer": "tank top", "question_id": 3855045, "best approach": "wiki, concept", "verif answer": "tank top", "anno approach": "wiki", "verif wiki answer": "tank top(0.7300)", "verif concept answer": "tank top(0.7309)", "verif image answer": "t shirt(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385504.jpg"}, {"question": "what type of plant is on this table", "gt answer": "succulent(1.00)<br/>indoor(0.60)", "pred answer": "fern", "question_id": 432565, "best approach": "", "verif answer": "fern", "anno approach": "", "verif wiki answer": "fern(0.6403)", "verif concept answer": "fern(0.6456)", "verif image answer": "fern(0.5886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043256.jpg"}, {"question": "what time period were these devices made in", "gt answer": "1800's(1.00)<br/>industrial(0.60)<br/>1800s(0.60)", "pred answer": "1804", "question_id": 3778785, "best approach": "wiki, concept", "verif answer": "1800's", "anno approach": "", "verif wiki answer": "1800's(0.6507)", "verif concept answer": "1800's(0.6465)", "verif image answer": "industrial(0.6299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377878.jpg"}, {"question": "what famous tournament is held for this sport in england", "gt answer": "wimbledon(1.00)<br/>tennis(0.60)<br/>open(0.60)", "pred answer": "wimbledon", "question_id": 4773285, "best approach": "wiki, concept, image", "verif answer": "wimbledon", "anno approach": "wiki", "verif wiki answer": "wimbledon(0.7305)", "verif concept answer": "wimbledon(0.6921)", "verif image answer": "wimbledon(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477328.jpg"}, {"question": "is this a girl 's room or a boy 's room", "gt answer": "girl(1.00)<br/>boy(1.00)", "pred answer": "girl", "question_id": 2140085, "best approach": "wiki, concept, image", "verif answer": "girl", "anno approach": "wiki", "verif wiki answer": "girl(0.6508)", "verif concept answer": "girl(0.6512)", "verif image answer": "girl(0.6438)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214008.jpg"}, {"question": "what type of home to these animals build", "gt answer": "nest(1.00)<br/>bird house(0.60)", "pred answer": "apartment", "question_id": 1881815, "best approach": "concept, image", "verif answer": "nest", "anno approach": "image", "verif wiki answer": "barn(0.7239)", "verif concept answer": "nest(0.6931)", "verif image answer": "nest(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188181.jpg"}, {"question": "what is the purpose of the light attached to the picture", "gt answer": "illumination(1.00)<br/>display(0.60)", "pred answer": "light", "question_id": 5557975, "best approach": "", "verif answer": "decoration", "anno approach": "", "verif wiki answer": "decoration(0.6430)", "verif concept answer": "decoration(0.6533)", "verif image answer": "decoration(0.7046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555797.jpg"}, {"question": "what are these objects", "gt answer": "motorcycle(1.00)", "pred answer": "motorcycle", "question_id": 1047115, "best approach": "concept, image", "verif answer": "motorcycle", "anno approach": "", "verif wiki answer": "hell angel(0.7311)", "verif concept answer": "motorcycle(0.7311)", "verif image answer": "motorcycle(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000104711.jpg"}, {"question": "is this product manufactured by apple or another brand", "gt answer": "another brand(1.00)<br/>motorola(0.60)", "pred answer": "apple", "question_id": 3730775, "best approach": "", "verif answer": "apple", "anno approach": "", "verif wiki answer": "apple(0.7267)", "verif concept answer": "apple(0.7309)", "verif image answer": "apple(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373077.jpg"}, {"question": "what is the name of the car this dog is sitting in", "gt answer": "fiat(1.00)", "pred answer": "van", "question_id": 4474245, "best approach": "", "verif answer": "volvo", "anno approach": "", "verif wiki answer": "volvo(0.6586)", "verif concept answer": "volvo(0.6526)", "verif image answer": "volvo(0.6720)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447424.jpg"}, {"question": "what year was the style of this kitchen popular", "gt answer": "1970(1.00)<br/>1950s(0.60)<br/>1940(0.60)", "pred answer": "1960", "question_id": 2583705, "best approach": "concept, image", "verif answer": "1940", "anno approach": "", "verif wiki answer": "1850(0.6373)", "verif concept answer": "1940(0.6350)", "verif image answer": "1940(0.6469)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258370.jpg"}, {"question": "the mouth of an animal like this one is called a what", "gt answer": "beak(1.00)", "pred answer": "robin", "question_id": 5481075, "best approach": "", "verif answer": "seed", "anno approach": "", "verif wiki answer": "seed(0.7311)", "verif concept answer": "seed(0.7311)", "verif image answer": "canine(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548107.jpg"}, {"question": "what is the person in the background saying with their hands", "gt answer": "out(1.00)<br/>safe(1.00)", "pred answer": "pitch", "question_id": 3336345, "best approach": "wiki, concept, image", "verif answer": "safe", "anno approach": "image, wiki", "verif wiki answer": "safe(0.5012)", "verif concept answer": "safe(0.5018)", "verif image answer": "safe(0.7033)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333634.jpg"}, {"question": "what is the person in this picture doing", "gt answer": "bike(1.00)<br/>bicycling(1.00)", "pred answer": "traffic", "question_id": 4837815, "best approach": "image", "verif answer": "bicycling", "anno approach": "image", "verif wiki answer": "bicycle(0.6584)", "verif concept answer": "bicycle(0.6447)", "verif image answer": "bicycling(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483781.jpg"}, {"question": "what type of flower is pictured in the vase", "gt answer": "lavendar(1.00)<br/>lavender(0.60)", "pred answer": "rose", "question_id": 2838145, "best approach": "", "verif answer": "rose", "anno approach": "", "verif wiki answer": "rose(0.6830)", "verif concept answer": "rose(0.6696)", "verif image answer": "rose(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283814.jpg"}, {"question": "what are the red items in the bowl", "gt answer": "tomato(1.00)<br/>grape(0.60)", "pred answer": "tomato", "question_id": 2706885, "best approach": "wiki, concept", "verif answer": "tomato", "anno approach": "wiki", "verif wiki answer": "tomato(0.7310)", "verif concept answer": "tomato(0.7311)", "verif image answer": "apple(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270688.jpg"}, {"question": "what is the utensil at the top right of the plate", "gt answer": "fork(1.00)", "pred answer": "fork", "question_id": 4460065, "best approach": "wiki, concept, image", "verif answer": "fork", "anno approach": "wiki", "verif wiki answer": "fork(0.7063)", "verif concept answer": "fork(0.7307)", "verif image answer": "fork(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000446006.jpg"}, {"question": "why are they cutting this cake", "gt answer": "married(1.00)<br/>to eat(0.60)", "pred answer": "cut cake", "question_id": 4853645, "best approach": "wiki, concept, image", "verif answer": "to eat", "anno approach": "concept, wiki", "verif wiki answer": "to eat(0.7310)", "verif concept answer": "to eat(0.7309)", "verif image answer": "to eat(0.6825)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485364.jpg"}, {"question": "the chocolate pie in the girl 's hand is liked by which other category of people", "gt answer": "adult(1.00)<br/>police(0.60)<br/>donut(0.60)", "pred answer": "cherry", "question_id": 1213515, "best approach": "image", "verif answer": "donut", "anno approach": "image", "verif wiki answer": "donut(0.5884)", "verif concept answer": "donut(0.6505)", "verif image answer": "adult(0.6475)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000121351.jpg"}, {"question": "what are the buildings called", "gt answer": "skyscraper(1.00)", "pred answer": "apart", "question_id": 3770445, "best approach": "wiki, concept, image", "verif answer": "skyscraper", "anno approach": "image, concept, wiki", "verif wiki answer": "skyscraper(0.6259)", "verif concept answer": "skyscraper(0.6761)", "verif image answer": "skyscraper(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377044.jpg"}, {"question": "where is an arrangement like this likely to be", "gt answer": "live room(1.00)<br/>table(0.60)", "pred answer": "live room", "question_id": 2701865, "best approach": "concept", "verif answer": "live", "anno approach": "concept", "verif wiki answer": "table(0.6521)", "verif concept answer": "live room(0.6479)", "verif image answer": "live(0.6605)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270186.jpg"}, {"question": "why are some bananas green", "gt answer": "not ripe(1.00)<br/>unripe(0.60)", "pred answer": "not ripe", "question_id": 807455, "best approach": "concept, image", "verif answer": "unripe", "anno approach": "", "verif wiki answer": "unripe(0.7310)", "verif concept answer": "not ripe(0.7308)", "verif image answer": "not ripe(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080745.jpg"}, {"question": "how is this side item prepared", "gt answer": "fried(1.00)<br/>deep fried(0.60)<br/>fryer(0.60)", "pred answer": "fried", "question_id": 460145, "best approach": "image", "verif answer": "handmade", "anno approach": "image", "verif wiki answer": "handmade(0.6485)", "verif concept answer": "handmade(0.6608)", "verif image answer": "fried(0.6038)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046014.jpg"}, {"question": "what motorcycle brand is this", "gt answer": "ducati(1.00)<br/>honda(0.60)", "pred answer": "harley davidson", "question_id": 1693775, "best approach": "image", "verif answer": "hell angel", "anno approach": "image", "verif wiki answer": "harley(0.6472)", "verif concept answer": "hell angel(0.6507)", "verif image answer": "honda(0.6364)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169377.jpg"}, {"question": "what material are the umbrellas made of", "gt answer": "straw(1.00)", "pred answer": "wicker", "question_id": 4594715, "best approach": "", "verif answer": "rattan", "anno approach": "", "verif wiki answer": "peanut(0.6622)", "verif concept answer": "rattan(0.7079)", "verif image answer": "rattan(0.6428)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459471.jpg"}, {"question": "what type of penguin is this", "gt answer": "emperor(1.00)<br/>king(0.60)<br/>puffin(0.60)", "pred answer": "seagull", "question_id": 859455, "best approach": "wiki, concept, image", "verif answer": "emperor", "anno approach": "image, wiki", "verif wiki answer": "emperor(0.6268)", "verif concept answer": "emperor(0.6060)", "verif image answer": "emperor(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085945.jpg"}, {"question": "what kind of dog is this", "gt answer": "dalmation(1.00)<br/>dalmatian(0.60)", "pred answer": "beagle", "question_id": 3018955, "best approach": "wiki, concept, image", "verif answer": "dalmation", "anno approach": "image, wiki", "verif wiki answer": "dalmation(0.6661)", "verif concept answer": "dalmation(0.6265)", "verif image answer": "dalmation(0.6964)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301895.jpg"}, {"question": "what kind of truck is shown", "gt answer": "garbage(1.00)<br/>dump(1.00)<br/>garbage truck(0.60)", "pred answer": "tow", "question_id": 4477955, "best approach": "concept", "verif answer": "trash", "anno approach": "concept", "verif wiki answer": "trash(0.7035)", "verif concept answer": "garbage(0.6915)", "verif image answer": "trash(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447795.jpg"}, {"question": "name the material used to make this sofa shown in this picture", "gt answer": "microfiber(1.00)<br/>cloth(0.60)", "pred answer": "cloth", "question_id": 1163535, "best approach": "", "verif answer": "lace", "anno approach": "", "verif wiki answer": "lace(0.7303)", "verif concept answer": "lace(0.7311)", "verif image answer": "lace(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116353.jpg"}, {"question": "what was the machine beside the bowl used for", "gt answer": "timer(1.00)<br/>toast(1.00)", "pred answer": "cook", "question_id": 18105, "best approach": "wiki, concept, image", "verif answer": "timer", "anno approach": "image", "verif wiki answer": "timer(0.6395)", "verif concept answer": "timer(0.6513)", "verif image answer": "timer(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001810.jpg"}, {"question": "when did this sport become popular", "gt answer": "1846(1.00)<br/>1940(0.60)", "pred answer": "1839", "question_id": 236395, "best approach": "", "verif answer": "1968", "anno approach": "", "verif wiki answer": "1968(0.6866)", "verif concept answer": "1968(0.6591)", "verif image answer": "1968(0.6727)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023639.jpg"}, {"question": "what piece of furniture is the television on top of", "gt answer": "desk(1.00)", "pred answer": "couch", "question_id": 1448815, "best approach": "", "verif answer": "table", "anno approach": "", "verif wiki answer": "table(0.7311)", "verif concept answer": "table(0.7311)", "verif image answer": "table(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144881.jpg"}, {"question": "what math concept is often taught with these objects", "gt answer": "fraction(1.00)", "pred answer": "italians", "question_id": 5212665, "best approach": "", "verif answer": "math", "anno approach": "", "verif wiki answer": "lampshade(0.6801)", "verif concept answer": "math(0.6924)", "verif image answer": "math(0.6588)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521266.jpg"}, {"question": "what teams are these players playing for", "gt answer": "dodger(1.00)<br/>yankees(0.60)", "pred answer": "baseball", "question_id": 395285, "best approach": "", "verif answer": "cardinal", "anno approach": "", "verif wiki answer": "cardinal(0.7294)", "verif concept answer": "cardinal(0.7080)", "verif image answer": "cardinal(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039528.jpg"}, {"question": "what motorcycle brand is that", "gt answer": "bmw(1.00)<br/>kawasaki(1.00)<br/>honda(0.60)", "pred answer": "kawasaki", "question_id": 5221505, "best approach": "wiki, concept, image", "verif answer": "kawasaki", "anno approach": "image, concept, wiki", "verif wiki answer": "kawasaki(0.6680)", "verif concept answer": "kawasaki(0.7292)", "verif image answer": "kawasaki(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522150.jpg"}, {"question": "what is a popular food served in this event", "gt answer": "hotdog(1.00)<br/>hotdogs(0.60)", "pred answer": "ball", "question_id": 3769125, "best approach": "", "verif answer": "pepperoni", "anno approach": "", "verif wiki answer": "pepperoni(0.6071)", "verif concept answer": "pepperoni(0.6007)", "verif image answer": "pepperoni(0.6435)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376912.jpg"}, {"question": "what is the name of the stone on the right", "gt answer": "brick(1.00)<br/>walmart(0.60)", "pred answer": "first base", "question_id": 5240445, "best approach": "wiki, concept, image", "verif answer": "brick", "anno approach": "concept, wiki", "verif wiki answer": "brick(0.7301)", "verif concept answer": "brick(0.7247)", "verif image answer": "brick(0.6539)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000524044.jpg"}, {"question": "what does the bus carry on top off it", "gt answer": "passenger(1.00)<br/>people(1.00)", "pred answer": "people", "question_id": 2334775, "best approach": "wiki, concept, image", "verif answer": "passenger", "anno approach": "image, wiki", "verif wiki answer": "passenger(0.6504)", "verif concept answer": "passenger(0.6355)", "verif image answer": "passenger(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233477.jpg"}, {"question": "why is the animal there", "gt answer": "curious(1.00)<br/>hot(0.60)", "pred answer": "eat", "question_id": 2014065, "best approach": "image", "verif answer": "cold", "anno approach": "image", "verif wiki answer": "cold(0.6922)", "verif concept answer": "cold(0.7248)", "verif image answer": "hot(0.5997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201406.jpg"}, {"question": "what is the breaded portion of this edible called", "gt answer": "crust(1.00)<br/>dough(0.60)", "pred answer": "sub", "question_id": 987395, "best approach": "", "verif answer": "pastry", "anno approach": "", "verif wiki answer": "pastry(0.6858)", "verif concept answer": "pastry(0.6038)", "verif image answer": "pastry(0.6554)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098739.jpg"}, {"question": "what material is the surface of the vanity", "gt answer": "marble(1.00)<br/>granite(1.00)<br/>formica(0.60)", "pred answer": "marble", "question_id": 5321065, "best approach": "wiki, concept, image", "verif answer": "granite", "anno approach": "wiki", "verif wiki answer": "granite(0.7311)", "verif concept answer": "granite(0.7311)", "verif image answer": "granite(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532106.jpg"}, {"question": "what do you use these for", "gt answer": "travel(1.00)<br/>sleep(0.60)", "pred answer": "travel", "question_id": 2224265, "best approach": "wiki", "verif answer": "sleep", "anno approach": "wiki", "verif wiki answer": "travel(0.6742)", "verif concept answer": "talk(0.6557)", "verif image answer": "sleep(0.6993)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222426.jpg"}, {"question": "where is this landmark", "gt answer": "philadelphia(1.00)<br/>boston(0.60)<br/>new york city(0.60)", "pred answer": "museum", "question_id": 4202915, "best approach": "wiki, concept, image", "verif answer": "boston", "anno approach": "image, wiki", "verif wiki answer": "boston(0.7079)", "verif concept answer": "boston(0.6677)", "verif image answer": "boston(0.7185)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420291.jpg"}, {"question": "what is the technical term for this automobile", "gt answer": "cart(1.00)<br/>buggy(0.60)", "pred answer": "wooden", "question_id": 3364145, "best approach": "", "verif answer": "0", "anno approach": "", "verif wiki answer": "0(0.6489)", "verif concept answer": "0(0.6311)", "verif image answer": "0(0.6373)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000336414.jpg"}, {"question": "what do the arrows on the road mean", "gt answer": "turn(1.00)<br/>direction(0.60)", "pred answer": "yield", "question_id": 4171295, "best approach": "", "verif answer": "run", "anno approach": "", "verif wiki answer": "run(0.5427)", "verif concept answer": "run(0.6405)", "verif image answer": "direct(0.5148)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417129.jpg"}, {"question": "who invented the two wheel transportation in this photo", "gt answer": "segway(1.00)<br/>dean kamen(1.00)", "pred answer": "protzmann", "question_id": 716035, "best approach": "wiki, concept, image", "verif answer": "segway", "anno approach": "image, wiki", "verif wiki answer": "segway(0.6712)", "verif concept answer": "segway(0.6618)", "verif image answer": "segway(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071603.jpg"}, {"question": "why are these sheep marked", "gt answer": "shear(1.00)<br/>number(0.60)", "pred answer": "wool", "question_id": 1110025, "best approach": "wiki, concept, image", "verif answer": "number", "anno approach": "image, wiki", "verif wiki answer": "number(0.6533)", "verif concept answer": "number(0.6824)", "verif image answer": "number(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111002.jpg"}, {"question": "what is the person that operates this called", "gt answer": "pilot(1.00)", "pred answer": "pilot", "question_id": 2053235, "best approach": "", "verif answer": "navy", "anno approach": "", "verif wiki answer": "navy(0.5004)", "verif concept answer": "navy(0.5002)", "verif image answer": "navy(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205323.jpg"}, {"question": "how much calorie can be got from eating that food", "gt answer": "500(1.00)<br/>300(0.60)", "pred answer": "400", "question_id": 4634325, "best approach": "concept, image", "verif answer": "300", "anno approach": "concept", "verif wiki answer": "400(0.5647)", "verif concept answer": "300(0.6279)", "verif image answer": "300(0.5617)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463432.jpg"}, {"question": "what sports equipment do you see behind the people", "gt answer": "skateboard(1.00)", "pred answer": "surf board", "question_id": 3191395, "best approach": "wiki, concept, image", "verif answer": "skateboard", "anno approach": "wiki", "verif wiki answer": "skateboard(0.7107)", "verif concept answer": "skateboard(0.6650)", "verif image answer": "skateboard(0.6411)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319139.jpg"}, {"question": "which cooking oil is used to cook the food", "gt answer": "olive oil(1.00)<br/>canola(0.60)<br/>sesame(0.60)<br/>olive(0.60)", "pred answer": "iron", "question_id": 1779395, "best approach": "image", "verif answer": "olive oil", "anno approach": "image", "verif wiki answer": "sesame(0.6443)", "verif concept answer": "olive(0.5897)", "verif image answer": "olive oil(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177939.jpg"}, {"question": "which brand of dog is sitting in the picture shown", "gt answer": "shepherd(1.00)<br/>mutt(0.60)<br/>german shepherd(0.60)", "pred answer": "lab", "question_id": 2676115, "best approach": "", "verif answer": "collie", "anno approach": "", "verif wiki answer": "collie(0.7294)", "verif concept answer": "collie(0.7223)", "verif image answer": "collie(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000267611.jpg"}, {"question": "what is being done", "gt answer": "surgery(1.00)", "pred answer": "work", "question_id": 326755, "best approach": "", "verif answer": "button", "anno approach": "", "verif wiki answer": "button(0.7238)", "verif concept answer": "button(0.6987)", "verif image answer": "button(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032675.jpg"}, {"question": "what kind of laptop is the child using", "gt answer": "macbook(1.00)<br/>apple(0.60)<br/>microsoft(0.60)", "pred answer": "dell", "question_id": 536325, "best approach": "", "verif answer": "dell", "anno approach": "", "verif wiki answer": "dell(0.5872)", "verif concept answer": "dell(0.5378)", "verif image answer": "dell(0.5018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053632.jpg"}, {"question": "this picture is lit up with the help of what part of a camera", "gt answer": "flash(1.00)", "pred answer": "glass", "question_id": 3523995, "best approach": "concept, image", "verif answer": "flash", "anno approach": "", "verif wiki answer": "dim(0.6475)", "verif concept answer": "flash(0.6525)", "verif image answer": "flash(0.6584)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000352399.jpg"}, {"question": "what state is this sport most associated with", "gt answer": "california(1.00)<br/>hawaii(0.60)", "pred answer": "los angeles", "question_id": 1701065, "best approach": "image", "verif answer": "new york", "anno approach": "image", "verif wiki answer": "new york(0.6513)", "verif concept answer": "new york(0.6780)", "verif image answer": "california(0.6251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000170106.jpg"}, {"question": "people with this color hair are often found in which island nation", "gt answer": "ireland(1.00)<br/>play(0.60)", "pred answer": "us", "question_id": 1269675, "best approach": "wiki, concept", "verif answer": "ireland", "anno approach": "wiki", "verif wiki answer": "ireland(0.7115)", "verif concept answer": "ireland(0.7310)", "verif image answer": "scotland(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126967.jpg"}, {"question": "which food item here has the most protein", "gt answer": "egg(1.00)<br/>fish(0.60)<br/>salmon(0.60)", "pred answer": "meat", "question_id": 5388615, "best approach": "wiki, concept, image", "verif answer": "egg", "anno approach": "image, wiki", "verif wiki answer": "egg(0.6571)", "verif concept answer": "egg(0.6640)", "verif image answer": "egg(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538861.jpg"}, {"question": "what popular vacation vessel is this", "gt answer": "cruise ship(1.00)<br/>cruise(0.60)", "pred answer": "marina", "question_id": 3481435, "best approach": "wiki, concept, image", "verif answer": "cruise", "anno approach": "image, wiki", "verif wiki answer": "cruise(0.6956)", "verif concept answer": "cruise(0.7112)", "verif image answer": "cruise(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348143.jpg"}, {"question": "what animals are surrounding the giraffe 's legs", "gt answer": "gazelle(1.00)<br/>deer(0.60)<br/>goat(0.60)", "pred answer": "elephant", "question_id": 435455, "best approach": "wiki, concept", "verif answer": "gazelle", "anno approach": "concept", "verif wiki answer": "gazelle(0.6879)", "verif concept answer": "gazelle(0.7311)", "verif image answer": "goat(0.7214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043545.jpg"}, {"question": "what is the main goal of the game he is playing", "gt answer": "hit ball(1.00)", "pred answer": "hit ball", "question_id": 592625, "best approach": "", "verif answer": "point", "anno approach": "", "verif wiki answer": "point(0.6671)", "verif concept answer": "point(0.7309)", "verif image answer": "point(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059262.jpg"}, {"question": "who determines whether a baseball player is out at base", "gt answer": "umpire(1.00)<br/>referee(0.60)", "pred answer": "baseball player", "question_id": 927535, "best approach": "", "verif answer": "judge", "anno approach": "", "verif wiki answer": "judge(0.7228)", "verif concept answer": "judge(0.7216)", "verif image answer": "judge(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092753.jpg"}, {"question": "what country invented this food", "gt answer": "germany(1.00)<br/>usa(0.60)", "pred answer": "italy", "question_id": 3159725, "best approach": "wiki, concept, image", "verif answer": "germany", "anno approach": "concept, wiki", "verif wiki answer": "germany(0.6556)", "verif concept answer": "germany(0.6851)", "verif image answer": "germany(0.6502)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315972.jpg"}, {"question": "what is the couch made of", "gt answer": "fabric(1.00)<br/>cotton(0.60)<br/>leather(0.60)", "pred answer": "leather", "question_id": 3575845, "best approach": "image", "verif answer": "velvet", "anno approach": "image", "verif wiki answer": "velvet(0.7311)", "verif concept answer": "velvet(0.7310)", "verif image answer": "leather(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357584.jpg"}, {"question": "why won't the pedestrians need to worry about the truck", "gt answer": "on sidewalk(1.00)<br/>sidewalk(0.60)", "pred answer": "fire hydrant", "question_id": 303955, "best approach": "", "verif answer": "fire hydrant", "anno approach": "", "verif wiki answer": "fire hydrant(0.7302)", "verif concept answer": "fire hydrant(0.7309)", "verif image answer": "crosswalk(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030395.jpg"}, {"question": "what time is it", "gt answer": "9:25(1.00)", "pred answer": "3:52", "question_id": 535735, "best approach": "wiki, concept", "verif answer": "1:15", "anno approach": "", "verif wiki answer": "9:25(0.5001)", "verif concept answer": "9:25(0.5001)", "verif image answer": "1:15(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053573.jpg"}, {"question": "where did this surfer get his board", "gt answer": "shop(1.00)<br/>store(0.60)", "pred answer": "california", "question_id": 3023725, "best approach": "", "verif answer": "online", "anno approach": "", "verif wiki answer": "online(0.7294)", "verif concept answer": "online(0.7206)", "verif image answer": "online(0.6608)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302372.jpg"}, {"question": "what common skin condition does the boy to the left have", "gt answer": "acne(1.00)", "pred answer": "grey", "question_id": 3130715, "best approach": "", "verif answer": "cold", "anno approach": "", "verif wiki answer": "cold(0.6226)", "verif concept answer": "cold(0.6469)", "verif image answer": "cold(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313071.jpg"}, {"question": "why would she eat this", "gt answer": "hungry(1.00)<br/>hunger(0.60)", "pred answer": "hungry", "question_id": 3930375, "best approach": "image", "verif answer": "holiday", "anno approach": "image", "verif wiki answer": "holiday(0.7310)", "verif concept answer": "hunger(0.7295)", "verif image answer": "hungry(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393037.jpg"}, {"question": "what other sodas taste like coca cola", "gt answer": "pepsi(1.00)", "pred answer": "beer", "question_id": 4612675, "best approach": "", "verif answer": "coca cola", "anno approach": "", "verif wiki answer": "coca cola(0.5035)", "verif concept answer": "coca cola(0.5106)", "verif image answer": "coke(0.5070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461267.jpg"}, {"question": "which airlines is portrayed in this photo", "gt answer": "air france(1.00)<br/>france(0.60)", "pred answer": "airbus", "question_id": 936575, "best approach": "wiki, concept, image", "verif answer": "air france", "anno approach": "concept, wiki", "verif wiki answer": "air france(0.6960)", "verif concept answer": "air france(0.6353)", "verif image answer": "air france(0.5924)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093657.jpg"}, {"question": "what store is known for the type of coffee table seen in the image", "gt answer": "ikea(1.00)<br/>starbucks(0.60)<br/>walmart(0.60)", "pred answer": "ikea", "question_id": 429725, "best approach": "", "verif answer": "ashley", "anno approach": "", "verif wiki answer": "ashley(0.6192)", "verif concept answer": "ashley(0.5415)", "verif image answer": "ashley(0.6069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042972.jpg"}, {"question": "which material choice would lead one to suspect this decor is in a tropical region", "gt answer": "bamboo(1.00)", "pred answer": "clay", "question_id": 3690865, "best approach": "wiki", "verif answer": "wicker", "anno approach": "wiki", "verif wiki answer": "bamboo(0.6940)", "verif concept answer": "flower(0.6542)", "verif image answer": "wicker(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369086.jpg"}, {"question": "how old is the child", "gt answer": "1(1.00)<br/>young(0.60)", "pred answer": "1", "question_id": 2432115, "best approach": "wiki, concept", "verif answer": "1 year", "anno approach": "wiki", "verif wiki answer": "1(0.6426)", "verif concept answer": "1(0.6530)", "verif image answer": "1 year(0.6538)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243211.jpg"}, {"question": "what does the animal use hay for", "gt answer": "bed(1.00)<br/>to eat(0.60)<br/>eat(0.60)", "pred answer": "food", "question_id": 5597285, "best approach": "wiki, concept, image", "verif answer": "bed", "anno approach": "wiki", "verif wiki answer": "bed(0.5001)", "verif concept answer": "bed(0.5000)", "verif image answer": "bed(0.5017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559728.jpg"}, {"question": "what piece of furniture is housing the white clothing", "gt answer": "wardrobe(1.00)", "pred answer": "bed", "question_id": 4384485, "best approach": "", "verif answer": "scarf", "anno approach": "", "verif wiki answer": "scarf(0.6292)", "verif concept answer": "scarf(0.6194)", "verif image answer": "scarf(0.6685)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000438448.jpg"}, {"question": "what shade of blue was used for his shirt", "gt answer": "baby blue(1.00)<br/>ocean(0.60)", "pred answer": "grey", "question_id": 4008625, "best approach": "image", "verif answer": "algae", "anno approach": "image", "verif wiki answer": "purple(0.6498)", "verif concept answer": "algae(0.6525)", "verif image answer": "baby blue(0.6511)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400862.jpg"}, {"question": "this surfer might be in shark infested waters what movie could this picture be taken from", "gt answer": "jaw(1.00)", "pred answer": "dumbo", "question_id": 5192875, "best approach": "", "verif answer": "homeward bound", "anno approach": "", "verif wiki answer": "lion king(0.5487)", "verif concept answer": "homeward bound(0.6644)", "verif image answer": "homeward bound(0.5310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000519287.jpg"}, {"question": "what is the frame made of", "gt answer": "wood(1.00)", "pred answer": "metal", "question_id": 5419735, "best approach": "", "verif answer": "hardwood", "anno approach": "", "verif wiki answer": "hardwood(0.6814)", "verif concept answer": "hardwood(0.6693)", "verif image answer": "hardwood(0.6457)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541973.jpg"}, {"question": "what type of suit is this woman wearing", "gt answer": "wet suit(1.00)<br/>wetsuit(1.00)<br/>wet(0.60)", "pred answer": "wet suit", "question_id": 4136255, "best approach": "wiki, concept, image", "verif answer": "wet suit", "anno approach": "wiki", "verif wiki answer": "wet suit(0.7311)", "verif concept answer": "wet suit(0.7311)", "verif image answer": "wet suit(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000413625.jpg"}, {"question": "who invented the device on this picture", "gt answer": "samuel fox(1.00)<br/>ben franklin(0.60)", "pred answer": "samuel fox", "question_id": 3470975, "best approach": "wiki, concept, image", "verif answer": "samuel fox", "anno approach": "image, wiki", "verif wiki answer": "samuel fox(0.6453)", "verif concept answer": "samuel fox(0.6451)", "verif image answer": "samuel fox(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347097.jpg"}, {"question": "what kind of dog is in the photo", "gt answer": "saint bernard(1.00)<br/>bulldog(0.60)", "pred answer": "beagle", "question_id": 1832405, "best approach": "", "verif answer": "collie", "anno approach": "", "verif wiki answer": "collie(0.5004)", "verif concept answer": "collie(0.5003)", "verif image answer": "collie(0.5088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183240.jpg"}, {"question": "what brand are these", "gt answer": "boyds(1.00)<br/>toy r us(0.60)", "pred answer": "morris michtom", "question_id": 2072505, "best approach": "wiki", "verif answer": "heinz", "anno approach": "wiki", "verif wiki answer": "boyds(0.6771)", "verif concept answer": "heinz(0.6845)", "verif image answer": "heinz(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207250.jpg"}, {"question": "what does this light color usually indicate", "gt answer": "go(1.00)", "pred answer": "go", "question_id": 2338295, "best approach": "", "verif answer": "slow down", "anno approach": "", "verif wiki answer": "green(0.7301)", "verif concept answer": "green(0.7242)", "verif image answer": "slow down(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233829.jpg"}, {"question": "what activity would take place", "gt answer": "picnic(1.00)<br/>eat(0.60)", "pred answer": "eat", "question_id": 1476595, "best approach": "wiki", "verif answer": "lunch", "anno approach": "wiki", "verif wiki answer": "picnic(0.6542)", "verif concept answer": "lunch(0.6436)", "verif image answer": "lunch(0.6864)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147659.jpg"}, {"question": "how is power transmitted from the power lines shown to the vehicle in the photo", "gt answer": "cable(1.00)<br/>power line(0.60)<br/>overhead(0.60)<br/>electricity(0.60)", "pred answer": "electric", "question_id": 1864105, "best approach": "concept, image", "verif answer": "cable", "anno approach": "", "verif wiki answer": "overhead(0.6466)", "verif concept answer": "cable(0.6657)", "verif image answer": "cable(0.6444)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186410.jpg"}, {"question": "which type of materials are used to make the blue dress weared by the man in the photo", "gt answer": "polyester(1.00)<br/>nylon(0.60)<br/>neoprene(0.60)<br/>cloth(0.60)", "pred answer": "cotton", "question_id": 1476235, "best approach": "image", "verif answer": "nylon", "anno approach": "image", "verif wiki answer": "nylon(0.7310)", "verif concept answer": "nylon(0.7215)", "verif image answer": "polyester(0.6569)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147623.jpg"}, {"question": "how are these people related", "gt answer": "teammate(1.00)<br/>team(0.60)<br/>family(0.60)<br/>same team(0.60)", "pred answer": "pack", "question_id": 2153415, "best approach": "wiki, concept, image", "verif answer": "same team", "anno approach": "", "verif wiki answer": "same team(0.7310)", "verif concept answer": "same team(0.7311)", "verif image answer": "same team(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215341.jpg"}, {"question": "what animal enjoys eating the orange food", "gt answer": "rabbit(1.00)<br/>horse(0.60)", "pred answer": "eye", "question_id": 1785205, "best approach": "wiki, image", "verif answer": "pony", "anno approach": "wiki", "verif wiki answer": "rabbit(0.6398)", "verif concept answer": "pony(0.6645)", "verif image answer": "rabbit(0.6602)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178520.jpg"}, {"question": "what casino game does this clock resemble", "gt answer": "roulette(1.00)", "pred answer": "big ben", "question_id": 3512505, "best approach": "", "verif answer": "thomas", "anno approach": "", "verif wiki answer": "roman numeral(0.5001)", "verif concept answer": "watch(0.5003)", "verif image answer": "thomas(0.5034)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351250.jpg"}, {"question": "what are they watching", "gt answer": "game(1.00)<br/>football(0.60)<br/>television(0.60)", "pred answer": "wii", "question_id": 3930915, "best approach": "wiki, concept, image", "verif answer": "television", "anno approach": "image, concept, wiki", "verif wiki answer": "television(0.6018)", "verif concept answer": "television(0.6359)", "verif image answer": "television(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393091.jpg"}, {"question": "what kind of coffee shop pastry is this", "gt answer": "coffee cake(1.00)<br/>starbucks(0.60)<br/>bread(0.60)", "pred answer": "cheesecake", "question_id": 15225, "best approach": "wiki, concept, image", "verif answer": "coffee cake", "anno approach": "", "verif wiki answer": "coffee cake(0.6431)", "verif concept answer": "coffee cake(0.6427)", "verif image answer": "coffee cake(0.6292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001522.jpg"}, {"question": "what shape is the clock face", "gt answer": "circle(1.00)<br/>round(1.00)", "pred answer": "round", "question_id": 4661535, "best approach": "wiki, concept, image", "verif answer": "circle", "anno approach": "image, concept, wiki", "verif wiki answer": "circle(0.5945)", "verif concept answer": "circle(0.6285)", "verif image answer": "circle(0.6268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466153.jpg"}, {"question": "what common juice is made from the yellow fruit depicted", "gt answer": "lemonade(1.00)<br/>lemon(0.60)", "pred answer": "orange", "question_id": 3566545, "best approach": "wiki", "verif answer": "lemonade", "anno approach": "wiki", "verif wiki answer": "lemonade(0.7216)", "verif concept answer": "orange(0.6339)", "verif image answer": "orange(0.6844)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356654.jpg"}, {"question": "what type of drink is present in the photo", "gt answer": "margarita(1.00)<br/>cocktail(0.60)<br/>beer(0.60)", "pred answer": "juice", "question_id": 1557955, "best approach": "wiki, concept, image", "verif answer": "cocktail", "anno approach": "wiki", "verif wiki answer": "cocktail(0.7297)", "verif concept answer": "cocktail(0.7058)", "verif image answer": "cocktail(0.7275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155795.jpg"}, {"question": "what is the best brand of tool for repairing toilets", "gt answer": "black and decker(1.00)<br/>snake(0.60)", "pred answer": "dryer", "question_id": 4280855, "best approach": "", "verif answer": "frigidaire", "anno approach": "", "verif wiki answer": "slice(0.5000)", "verif concept answer": "slice(0.5002)", "verif image answer": "frigidaire(0.5054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428085.jpg"}, {"question": "when was the peak popularity for this sport", "gt answer": "2000(1.00)<br/>1960's(0.60)", "pred answer": "1873", "question_id": 4267915, "best approach": "wiki, concept", "verif answer": "2000", "anno approach": "wiki", "verif wiki answer": "2000(0.6530)", "verif concept answer": "2000(0.6463)", "verif image answer": "1970(0.6489)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426791.jpg"}, {"question": "what are the three players in this picture doing with the ball", "gt answer": "play soccer(1.00)<br/>kick(0.60)<br/>soccer(0.60)", "pred answer": "hit", "question_id": 1653195, "best approach": "", "verif answer": "block", "anno approach": "", "verif wiki answer": "block(0.6714)", "verif concept answer": "block(0.6360)", "verif image answer": "block(0.6956)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000165319.jpg"}, {"question": "how is food being kept at the proper temperature", "gt answer": "crock pot(1.00)", "pred answer": "oven", "question_id": 2591375, "best approach": "", "verif answer": "steamed", "anno approach": "", "verif wiki answer": "steamed(0.6484)", "verif concept answer": "steamed(0.6982)", "verif image answer": "steamed(0.6528)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259137.jpg"}, {"question": "how does the animal in this image produce its distinctive sound", "gt answer": "pure(1.00)<br/>purr(0.60)<br/>meow(0.60)", "pred answer": "music", "question_id": 3171625, "best approach": "wiki, concept, image", "verif answer": "purr", "anno approach": "", "verif wiki answer": "purr(0.7309)", "verif concept answer": "purr(0.7303)", "verif image answer": "purr(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317162.jpg"}, {"question": "what do you call the area of the window the cat is sitting on", "gt answer": "sill(1.00)", "pred answer": "blind", "question_id": 2887705, "best approach": "", "verif answer": "shelf", "anno approach": "", "verif wiki answer": "shelf(0.6404)", "verif concept answer": "shelf(0.6406)", "verif image answer": "shelf(0.6455)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288770.jpg"}, {"question": "what happened just before this picture was taken", "gt answer": "jump(1.00)<br/>he jumped(0.60)", "pred answer": "fall", "question_id": 1002265, "best approach": "", "verif answer": "jumped", "anno approach": "", "verif wiki answer": "jumped(0.7045)", "verif concept answer": "jumped(0.6783)", "verif image answer": "fall(0.6185)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100226.jpg"}, {"question": "what material is the sign made out of", "gt answer": "metal(1.00)<br/>steel(1.00)", "pred answer": "metal", "question_id": 3307275, "best approach": "wiki, concept, image", "verif answer": "metal", "anno approach": "image, wiki", "verif wiki answer": "metal(0.6566)", "verif concept answer": "metal(0.6056)", "verif image answer": "metal(0.6400)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000330727.jpg"}, {"question": "what skateboard trick is this man performing", "gt answer": "barrel roll(1.00)<br/>pipe(0.60)", "pred answer": "kickflip", "question_id": 4214525, "best approach": "", "verif answer": "grind", "anno approach": "", "verif wiki answer": "grind(0.7079)", "verif concept answer": "grind(0.7030)", "verif image answer": "grind(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421452.jpg"}, {"question": "to what are the boats tied", "gt answer": "anchor(1.00)<br/>pole(0.60)", "pred answer": "dock", "question_id": 2980505, "best approach": "image", "verif answer": "pier", "anno approach": "image", "verif wiki answer": "pier(0.6202)", "verif concept answer": "pier(0.6461)", "verif image answer": "anchor(0.5793)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000298050.jpg"}, {"question": "what kind of art is on the wall", "gt answer": "paint(1.00)<br/>japanese(0.60)<br/>flower(0.60)<br/>decoration(0.60)", "pred answer": "paint", "question_id": 5606365, "best approach": "wiki, concept, image", "verif answer": "paint", "anno approach": "image, wiki", "verif wiki answer": "paint(0.7261)", "verif concept answer": "paint(0.5975)", "verif image answer": "paint(0.6701)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560636.jpg"}, {"question": "what year were these first ever flown", "gt answer": "1903(1.00)<br/>1912(0.60)<br/>1880(0.60)", "pred answer": "1930", "question_id": 4776365, "best approach": "wiki, concept, image", "verif answer": "1903", "anno approach": "concept", "verif wiki answer": "1903(0.7005)", "verif concept answer": "1903(0.7182)", "verif image answer": "1903(0.6689)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477636.jpg"}, {"question": "where does the content of this bottle come from", "gt answer": "spring(1.00)<br/>earth(0.60)<br/>lake(0.60)", "pred answer": "internet", "question_id": 5239955, "best approach": "wiki, concept", "verif answer": "inside", "anno approach": "wiki", "verif wiki answer": "spring(0.6359)", "verif concept answer": "spring(0.6095)", "verif image answer": "inside(0.7257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523995.jpg"}, {"question": "what kind of container might someone carry these things in", "gt answer": "backpack(1.00)<br/>suitcase(0.60)<br/>case(0.60)", "pred answer": "purse", "question_id": 2487095, "best approach": "", "verif answer": "purse", "anno approach": "", "verif wiki answer": "purse(0.7220)", "verif concept answer": "purse(0.7281)", "verif image answer": "purse(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248709.jpg"}, {"question": "what kind of competition is this", "gt answer": "sheep herd(1.00)<br/>rodeo(0.60)<br/>herd(0.60)", "pred answer": "sheep", "question_id": 2395585, "best approach": "", "verif answer": "sheep", "anno approach": "", "verif wiki answer": "horse show(0.6693)", "verif concept answer": "sheep(0.7306)", "verif image answer": "horse show(0.6678)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000239558.jpg"}, {"question": "what is the function of this sewer drain", "gt answer": "drain water(1.00)", "pred answer": "smell", "question_id": 5170705, "best approach": "", "verif answer": "train", "anno approach": "", "verif wiki answer": "fire(0.5296)", "verif concept answer": "fire(0.5761)", "verif image answer": "train(0.6452)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517070.jpg"}, {"question": "what are those flags symbolizing", "gt answer": "sale(1.00)<br/>mcdonalds(0.60)", "pred answer": "military", "question_id": 2243955, "best approach": "image", "verif answer": "sale", "anno approach": "image", "verif wiki answer": "food(0.5001)", "verif concept answer": "food(0.5001)", "verif image answer": "sale(0.6879)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224395.jpg"}, {"question": "what brand of phone is this woman holding", "gt answer": "nokia(1.00)", "pred answer": "samsung", "question_id": 2576705, "best approach": "wiki", "verif answer": "nokia", "anno approach": "wiki", "verif wiki answer": "nokia(0.6811)", "verif concept answer": "samsung(0.6498)", "verif image answer": "samsung(0.6750)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257670.jpg"}, {"question": "what type of elephants are these", "gt answer": "african(1.00)<br/>perform(0.60)<br/>zoo(0.60)<br/>indian(0.60)", "pred answer": "african", "question_id": 3691805, "best approach": "wiki, concept, image", "verif answer": "african", "anno approach": "image, wiki", "verif wiki answer": "african(0.6437)", "verif concept answer": "african(0.6362)", "verif image answer": "african(0.6955)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369180.jpg"}, {"question": "are these cellphones modern or antique", "gt answer": "antique(1.00)", "pred answer": "old", "question_id": 1184135, "best approach": "", "verif answer": "formal", "anno approach": "", "verif wiki answer": "formal(0.7311)", "verif concept answer": "formal(0.7311)", "verif image answer": "formal(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118413.jpg"}, {"question": "a fruit drink concocted by a device like this is often called a what", "gt answer": "smoothie(1.00)<br/>blender(0.60)", "pred answer": "grape", "question_id": 1866465, "best approach": "wiki, concept", "verif answer": "blender", "anno approach": "wiki", "verif wiki answer": "blender(0.7076)", "verif concept answer": "blender(0.6915)", "verif image answer": "smoothies(0.6796)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186646.jpg"}, {"question": "a biblical story tells of a similar event pictured name the protagonist", "gt answer": "noah(1.00)", "pred answer": "jack and jill", "question_id": 2872285, "best approach": "wiki, image", "verif answer": "sunset", "anno approach": "wiki", "verif wiki answer": "noah(0.6489)", "verif concept answer": "sunset(0.7007)", "verif image answer": "noah(0.6607)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287228.jpg"}, {"question": "when did this sport begin", "gt answer": "1800s(1.00)<br/>1945(0.60)", "pred answer": "1839", "question_id": 4763605, "best approach": "wiki, concept", "verif answer": "1945", "anno approach": "concept, wiki", "verif wiki answer": "1945(0.6011)", "verif concept answer": "1945(0.6710)", "verif image answer": "1950(0.6221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476360.jpg"}, {"question": "what nutrients does this meal provide", "gt answer": "calcium(1.00)<br/>vegetable(0.60)", "pred answer": "protein", "question_id": 5649825, "best approach": "image", "verif answer": "calcium", "anno approach": "image", "verif wiki answer": "carbohydrate(0.7295)", "verif concept answer": "carbohydrate(0.7309)", "verif image answer": "calcium(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564982.jpg"}, {"question": "what type of beds are these", "gt answer": "double(1.00)<br/>queen(0.60)<br/>twin(0.60)", "pred answer": "queen", "question_id": 543185, "best approach": "image", "verif answer": "twin", "anno approach": "image", "verif wiki answer": "twin(0.5155)", "verif concept answer": "twin(0.5208)", "verif image answer": "double(0.5007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054318.jpg"}, {"question": "what is the pattern on the socks called", "gt answer": "stripe(1.00)<br/>striped(0.60)", "pred answer": "stripe", "question_id": 4989385, "best approach": "image", "verif answer": "striped", "anno approach": "image", "verif wiki answer": "striped(0.7311)", "verif concept answer": "striped(0.7310)", "verif image answer": "stripe(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000498938.jpg"}, {"question": "", "gt answer": "by magnet(0.60)", "pred answer": "magnet", "question_id": 3821895, "best approach": "", "verif answer": "magnet", "anno approach": "", "verif wiki answer": "magnet(0.7028)", "verif concept answer": "magnet(0.6741)", "verif image answer": "magnet(0.5510)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382189.jpg"}, {"question": "what kind of facility", "gt answer": "harbor(1.00)<br/>boat(0.60)", "pred answer": "marina", "question_id": 561455, "best approach": "wiki, concept, image", "verif answer": "harbor", "anno approach": "concept, wiki", "verif wiki answer": "harbor(0.7308)", "verif concept answer": "harbor(0.7309)", "verif image answer": "harbor(0.6546)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000056145.jpg"}, {"question": "name the place where this horse is running in this picture", "gt answer": "rodeo(1.00)<br/>ring(0.60)", "pred answer": "field", "question_id": 2848885, "best approach": "concept", "verif answer": "rodeo", "anno approach": "concept", "verif wiki answer": "circus(0.6326)", "verif concept answer": "rodeo(0.6501)", "verif image answer": "circus(0.6284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284888.jpg"}, {"question": "what town is featured in this photo", "gt answer": "san francisco(1.00)<br/>chicago(0.60)", "pred answer": "china", "question_id": 4211345, "best approach": "", "verif answer": "city", "anno approach": "", "verif wiki answer": "city(0.6206)", "verif concept answer": "city(0.5823)", "verif image answer": "city(0.6100)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421134.jpg"}, {"question": "the lights seen here look like what sort of orbiting bodies", "gt answer": "star(1.00)<br/>traffic light(0.60)", "pred answer": "caution", "question_id": 5640745, "best approach": "wiki, concept, image", "verif answer": "traffic light", "anno approach": "wiki", "verif wiki answer": "traffic light(0.7310)", "verif concept answer": "traffic light(0.7296)", "verif image answer": "traffic light(0.6977)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564074.jpg"}, {"question": "what type of bird is shown in this iamge", "gt answer": "parrot(1.00)", "pred answer": "parakeet", "question_id": 1735385, "best approach": "", "verif answer": "woodpecker", "anno approach": "", "verif wiki answer": "woodpecker(0.7311)", "verif concept answer": "woodpecker(0.7311)", "verif image answer": "parakeet(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000173538.jpg"}, {"question": "why is this cat laying on a laptop", "gt answer": "warmth(1.00)<br/>rest(0.60)", "pred answer": "it want attention", "question_id": 5729935, "best approach": "wiki, concept, image", "verif answer": "warmth", "anno approach": "image, concept, wiki", "verif wiki answer": "warmth(0.6799)", "verif concept answer": "warmth(0.7179)", "verif image answer": "warmth(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572993.jpg"}, {"question": "what type of birds are being shown in this picture", "gt answer": "seagull(1.00)<br/>eagle(0.60)", "pred answer": "seagull", "question_id": 5370665, "best approach": "wiki, concept, image", "verif answer": "seagull", "anno approach": "wiki", "verif wiki answer": "seagull(0.7297)", "verif concept answer": "seagull(0.7310)", "verif image answer": "seagull(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537066.jpg"}, {"question": "which of the items in this dish might be collected underground", "gt answer": "green bean(1.00)<br/>mushroom(1.00)<br/>carrot(0.60)", "pred answer": "pasta", "question_id": 4878245, "best approach": "concept", "verif answer": "mushroom", "anno approach": "concept", "verif wiki answer": "potato(0.6504)", "verif concept answer": "mushroom(0.6645)", "verif image answer": "potato(0.6436)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487824.jpg"}, {"question": "this vehicle can typically hold how many gallons of fuel", "gt answer": "100(1.00)<br/>250(0.60)<br/>60(0.60)<br/>200(0.60)", "pred answer": "lot", "question_id": 2787315, "best approach": "wiki, concept, image", "verif answer": "100", "anno approach": "concept, wiki", "verif wiki answer": "100(0.6682)", "verif concept answer": "100(0.7179)", "verif image answer": "100(0.6559)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278731.jpg"}, {"question": "why might we suspect that this is a model home that is not in use yet", "gt answer": "no furniture(1.00)", "pred answer": "clean", "question_id": 4093385, "best approach": "", "verif answer": "clean", "anno approach": "", "verif wiki answer": "clean(0.7297)", "verif concept answer": "clean(0.7310)", "verif image answer": "bent(0.7160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409338.jpg"}, {"question": "what is the name of this bike the person is doing tricks on", "gt answer": "bmx(1.00)<br/>tony(0.60)<br/>bicycle(0.60)<br/>schwinn(0.60)", "pred answer": "skateboard", "question_id": 891555, "best approach": "wiki, concept, image", "verif answer": "bicycle", "anno approach": "wiki", "verif wiki answer": "bicycle(0.6517)", "verif concept answer": "bicycle(0.6604)", "verif image answer": "tony(0.6490)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089155.jpg"}, {"question": "does that cat seem content or agitated", "gt answer": "content(1.00)", "pred answer": "healthy", "question_id": 1038775, "best approach": "", "verif answer": "warmth", "anno approach": "", "verif wiki answer": "warmth(0.6896)", "verif concept answer": "warmth(0.7245)", "verif image answer": "warmth(0.6577)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103877.jpg"}, {"question": "what type of sandwich is this", "gt answer": "mcrib(1.00)<br/>hoagie(0.60)", "pred answer": "meat", "question_id": 2064755, "best approach": "wiki", "verif answer": "pork", "anno approach": "wiki", "verif wiki answer": "mcrib(0.6444)", "verif concept answer": "grilled(0.6432)", "verif image answer": "pork(0.7215)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206475.jpg"}, {"question": "how much do these types of dogs weigh when they're born", "gt answer": "1 pound(1.00)", "pred answer": "1", "question_id": 2072895, "best approach": "", "verif answer": "2 tons", "anno approach": "", "verif wiki answer": "money(0.6734)", "verif concept answer": "money(0.6837)", "verif image answer": "2 tons(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207289.jpg"}, {"question": "what is the white grainy substance in this image", "gt answer": "rice(1.00)", "pred answer": "egg", "question_id": 3288535, "best approach": "", "verif answer": "wheat", "anno approach": "", "verif wiki answer": "wheat(0.6927)", "verif concept answer": "wheat(0.7205)", "verif image answer": "wheat(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328853.jpg"}, {"question": "is this for hauling or for passengers", "gt answer": "passenger(1.00)", "pred answer": "freight", "question_id": 2217465, "best approach": "", "verif answer": "people", "anno approach": "", "verif wiki answer": "freight(0.7075)", "verif concept answer": "people(0.7305)", "verif image answer": "freight(0.7032)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221746.jpg"}, {"question": "where are these chairs most commonly found", "gt answer": "poolside(1.00)<br/>pool(0.60)", "pred answer": "outside", "question_id": 776395, "best approach": "", "verif answer": "daisy", "anno approach": "", "verif wiki answer": "daisy(0.6712)", "verif concept answer": "daisy(0.6814)", "verif image answer": "daisy(0.6467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077639.jpg"}, {"question": "can you name the variety of the trees shown in this picture", "gt answer": "aspen(1.00)<br/>pine tree(0.60)<br/>pine(0.60)", "pred answer": "oak", "question_id": 4853035, "best approach": "", "verif answer": "oak", "anno approach": "", "verif wiki answer": "oak(0.7311)", "verif concept answer": "oak(0.7310)", "verif image answer": "oak(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485303.jpg"}, {"question": "what type of body of water would this be considered", "gt answer": "river(1.00)<br/>canal(0.60)", "pred answer": "lake", "question_id": 260335, "best approach": "", "verif answer": "lake", "anno approach": "", "verif wiki answer": "lake(0.7311)", "verif concept answer": "lake(0.7311)", "verif image answer": "lake(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000026033.jpg"}, {"question": "what is this dog made out of", "gt answer": "towel(1.00)<br/>cloth(1.00)", "pred answer": "fur", "question_id": 4152035, "best approach": "wiki, concept, image", "verif answer": "towel", "anno approach": "wiki", "verif wiki answer": "towel(0.7311)", "verif concept answer": "towel(0.7310)", "verif image answer": "cloth(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415203.jpg"}, {"question": "what sport are these people playing a round of", "gt answer": "golf(1.00)<br/>cricket(0.60)<br/>frisbee(0.60)", "pred answer": "frisbee", "question_id": 3956735, "best approach": "wiki, concept, image", "verif answer": "cricket", "anno approach": "concept, wiki", "verif wiki answer": "cricket(0.6270)", "verif concept answer": "cricket(0.7241)", "verif image answer": "frisbee(0.5006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395673.jpg"}, {"question": "why are all these people on the street", "gt answer": "parade(1.00)", "pred answer": "parade", "question_id": 1160045, "best approach": "wiki, concept", "verif answer": "parade", "anno approach": "wiki", "verif wiki answer": "parade(0.6513)", "verif concept answer": "parade(0.6449)", "verif image answer": "light(0.6309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116004.jpg"}, {"question": "what material is the gray rocking chair made of", "gt answer": "wicker(1.00)<br/>wood(0.60)", "pred answer": "wood", "question_id": 524185, "best approach": "", "verif answer": "rattan", "anno approach": "", "verif wiki answer": "rattan(0.7292)", "verif concept answer": "rattan(0.7310)", "verif image answer": "rattan(0.6485)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052418.jpg"}, {"question": "how did the man change his facial hair", "gt answer": "shave(1.00)", "pred answer": "scan", "question_id": 3185255, "best approach": "", "verif answer": "shadow", "anno approach": "", "verif wiki answer": "shadow(0.5062)", "verif concept answer": "shadow(0.5221)", "verif image answer": "shadow(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318525.jpg"}, {"question": "who would prepare this", "gt answer": "chef(1.00)<br/>italians(0.60)<br/>cook(0.60)", "pred answer": "restaurant", "question_id": 1498175, "best approach": "wiki, concept, image", "verif answer": "chef", "anno approach": "image, concept, wiki", "verif wiki answer": "chef(0.5895)", "verif concept answer": "chef(0.6321)", "verif image answer": "chef(0.6327)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149817.jpg"}, {"question": "why do people wear these suits", "gt answer": "stay warm(1.00)<br/>cold(0.60)", "pred answer": "wet suit", "question_id": 4310775, "best approach": "wiki, concept, image", "verif answer": "stay warm", "anno approach": "concept, wiki", "verif wiki answer": "stay warm(0.6589)", "verif concept answer": "stay warm(0.7117)", "verif image answer": "stay warm(0.5026)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431077.jpg"}, {"question": "what style is the light fixture", "gt answer": "tiffany(1.00)<br/>art deco(0.60)", "pred answer": "chandelier", "question_id": 313295, "best approach": "wiki, concept", "verif answer": "art deco", "anno approach": "", "verif wiki answer": "art deco(0.6470)", "verif concept answer": "art deco(0.6451)", "verif image answer": "chandelier(0.6380)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000031329.jpg"}, {"question": "what is round above the words kurz", "gt answer": "clock(1.00)", "pred answer": "big ben", "question_id": 4767065, "best approach": "", "verif answer": "big ben", "anno approach": "", "verif wiki answer": "big ben(0.7308)", "verif concept answer": "big ben(0.7270)", "verif image answer": "decor(0.6802)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476706.jpg"}, {"question": "what is the best position to read in bed", "gt answer": "lay down(1.00)", "pred answer": "student", "question_id": 2016445, "best approach": "concept, image", "verif answer": "relax", "anno approach": "", "verif wiki answer": "relax(0.5307)", "verif concept answer": "lay down(0.5176)", "verif image answer": "lay down(0.5009)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201644.jpg"}, {"question": "how skilled does this skier appear to be", "gt answer": "very(1.00)<br/>amateur(0.60)", "pred answer": "0", "question_id": 3735095, "best approach": "image", "verif answer": "amateur", "anno approach": "image", "verif wiki answer": "moderately(0.6534)", "verif concept answer": "moderately(0.6600)", "verif image answer": "amateur(0.6839)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373509.jpg"}, {"question": "is this cat male or female", "gt answer": "female(1.00)<br/>male(1.00)", "pred answer": "female", "question_id": 4807905, "best approach": "wiki, concept, image", "verif answer": "female", "anno approach": "concept, wiki", "verif wiki answer": "female(0.7279)", "verif concept answer": "female(0.7153)", "verif image answer": "male(0.6418)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480790.jpg"}, {"question": "what gauge of sheet metal was used to make the stainless steel refrigerator", "gt answer": "24 gauge(1.00)<br/>3(0.60)<br/>aluminium(0.60)", "pred answer": "roman", "question_id": 4221615, "best approach": "image", "verif answer": "aluminium", "anno approach": "image", "verif wiki answer": "2(0.5831)", "verif concept answer": "2(0.6117)", "verif image answer": "aluminium(0.7174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422161.jpg"}, {"question": "where can you find these at the grocery store", "gt answer": "freezer(1.00)", "pred answer": "diner", "question_id": 4328775, "best approach": "", "verif answer": "diner", "anno approach": "", "verif wiki answer": "350(0.6503)", "verif concept answer": "diner(0.6767)", "verif image answer": "diner(0.6424)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432877.jpg"}, {"question": "what kind of road are the vehicles on", "gt answer": "city(1.00)<br/>highway(0.60)<br/>concrete(0.60)", "pred answer": "street", "question_id": 2006195, "best approach": "", "verif answer": "asphalt", "anno approach": "", "verif wiki answer": "asphalt(0.6806)", "verif concept answer": "asphalt(0.6570)", "verif image answer": "asphalt(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200619.jpg"}, {"question": "what breed of cat is this", "gt answer": "calico(1.00)<br/>ragdoll(0.60)", "pred answer": "calico", "question_id": 2467365, "best approach": "wiki, concept", "verif answer": "calico", "anno approach": "wiki", "verif wiki answer": "calico(0.7307)", "verif concept answer": "calico(0.7308)", "verif image answer": "striped(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246736.jpg"}, {"question": "which brand of gray car is shown in this picture", "gt answer": "mazda(1.00)<br/>mercedes(0.60)", "pred answer": "bmw", "question_id": 1609105, "best approach": "wiki, image", "verif answer": "kawasaki", "anno approach": "wiki", "verif wiki answer": "mercedes(0.6487)", "verif concept answer": "kawasaki(0.6615)", "verif image answer": "mercedes(0.6469)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160910.jpg"}, {"question": "what is the name of the object used to fasten the luggage to the car", "gt answer": "strap(1.00)<br/>rack(0.60)", "pred answer": "glove", "question_id": 771855, "best approach": "concept", "verif answer": "rack", "anno approach": "concept", "verif wiki answer": "rack(0.6553)", "verif concept answer": "strap(0.6477)", "verif image answer": "string(0.6472)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077185.jpg"}, {"question": "what holiday is this platter used for", "gt answer": "thanksgiving(1.00)<br/>july 4th(0.60)<br/>easter(0.60)", "pred answer": "valentine", "question_id": 1142595, "best approach": "wiki", "verif answer": "thanksgiving", "anno approach": "wiki", "verif wiki answer": "thanksgiving(0.6968)", "verif concept answer": "christmas(0.6769)", "verif image answer": "easter(0.6522)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114259.jpg"}, {"question": "what types of clocks are these called", "gt answer": "grandfather clock(1.00)<br/>analog(0.60)", "pred answer": "clock", "question_id": 4456055, "best approach": "", "verif answer": "grandfather", "anno approach": "", "verif wiki answer": "grandfather(0.7310)", "verif concept answer": "grandfather(0.7309)", "verif image answer": "grandfather(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445605.jpg"}, {"question": "how do you care for this equipment", "gt answer": "wax(1.00)<br/>clean(0.60)<br/>storage(0.60)", "pred answer": "attach to surfer", "question_id": 192515, "best approach": "wiki, concept, image", "verif answer": "clean", "anno approach": "wiki", "verif wiki answer": "clean(0.7311)", "verif concept answer": "clean(0.7311)", "verif image answer": "clean(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019251.jpg"}, {"question": "what is the jet of white called", "gt answer": "smoke(1.00)<br/>trail(0.60)<br/>exhaust(0.60)", "pred answer": "jet", "question_id": 1252275, "best approach": "", "verif answer": "stripe", "anno approach": "", "verif wiki answer": "stripe(0.6458)", "verif concept answer": "stripe(0.6648)", "verif image answer": "stripe(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125227.jpg"}, {"question": "what is this made of", "gt answer": "silver(1.00)<br/>bronze(0.60)<br/>metal(0.60)", "pred answer": "metal", "question_id": 5138815, "best approach": "wiki", "verif answer": "copper", "anno approach": "wiki", "verif wiki answer": "silver(0.6385)", "verif concept answer": "copper(0.6811)", "verif image answer": "metal(0.6456)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513881.jpg"}, {"question": "is this a team or individual sport", "gt answer": "individual(1.00)<br/>snow(0.60)", "pred answer": "polo", "question_id": 5600155, "best approach": "wiki, concept, image", "verif answer": "individual", "anno approach": "concept, wiki", "verif wiki answer": "individual(0.6256)", "verif concept answer": "individual(0.7309)", "verif image answer": "individual(0.5088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560015.jpg"}, {"question": "is this a half bath or a full bath", "gt answer": "full(1.00)", "pred answer": "full", "question_id": 4665915, "best approach": "wiki, concept, image", "verif answer": "full", "anno approach": "wiki", "verif wiki answer": "full(0.7308)", "verif concept answer": "full(0.7311)", "verif image answer": "full(0.7222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466591.jpg"}, {"question": "what type of flowers are those", "gt answer": "daisy(1.00)", "pred answer": "tulip", "question_id": 5514135, "best approach": "", "verif answer": "pansy", "anno approach": "", "verif wiki answer": "pansy(0.6620)", "verif concept answer": "orchid(0.5607)", "verif image answer": "pansy(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000551413.jpg"}, {"question": "what toppings are on this pizza", "gt answer": "pepper(1.00)<br/>potato(0.60)", "pred answer": "olive", "question_id": 3791115, "best approach": "wiki, concept", "verif answer": "potato", "anno approach": "wiki", "verif wiki answer": "potato(0.6483)", "verif concept answer": "potato(0.6582)", "verif image answer": "spinach(0.6248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379111.jpg"}, {"question": "what toy is this", "gt answer": "teddy bear(1.00)<br/>bear(0.60)", "pred answer": "teddy bear", "question_id": 4617015, "best approach": "wiki, concept, image", "verif answer": "teddy bear", "anno approach": "wiki", "verif wiki answer": "teddy bear(0.7308)", "verif concept answer": "teddy bear(0.7263)", "verif image answer": "teddy bear(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461701.jpg"}, {"question": "the dishes shown before you are cooked with which type of oil", "gt answer": "olive(1.00)<br/>vegetable(0.60)<br/>sesame(0.60)", "pred answer": "omega 3", "question_id": 5112085, "best approach": "image", "verif answer": "vegetable", "anno approach": "image", "verif wiki answer": "canola(0.6378)", "verif concept answer": "canola(0.7003)", "verif image answer": "vegetable(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511208.jpg"}, {"question": "", "gt answer": "in oven(0.60)<br/>bake(0.60)<br/>oven(0.60)<br/>baked(0.60)", "pred answer": "oven", "question_id": 5283555, "best approach": "image", "verif answer": "bake it", "anno approach": "image", "verif wiki answer": "bake it(0.6483)", "verif concept answer": "bake it(0.6392)", "verif image answer": "bake(0.6067)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528355.jpg"}, {"question": "can you guess where the meeting is taking place", "gt answer": "white house(1.00)<br/>washington dc(0.60)<br/>usa(0.60)", "pred answer": "award", "question_id": 4865815, "best approach": "", "verif answer": "america", "anno approach": "", "verif wiki answer": "america(0.6911)", "verif concept answer": "america(0.6499)", "verif image answer": "america(0.5966)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000486581.jpg"}, {"question": "what is the couch in the photo made out of", "gt answer": "fabric(1.00)<br/>wool(0.60)", "pred answer": "wood", "question_id": 4575875, "best approach": "", "verif answer": "cloth", "anno approach": "", "verif wiki answer": "cloth(0.7309)", "verif concept answer": "cloth(0.6887)", "verif image answer": "cloth(0.6512)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457587.jpg"}, {"question": "is it safe or unsafe to be that close to train tracks", "gt answer": "unsafe(1.00)", "pred answer": "unsafe", "question_id": 3533445, "best approach": "wiki, concept, image", "verif answer": "unsafe", "anno approach": "", "verif wiki answer": "unsafe(0.7066)", "verif concept answer": "unsafe(0.7308)", "verif image answer": "unsafe(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353344.jpg"}, {"question": "what food is sold here", "gt answer": "pizza(1.00)", "pred answer": "bread", "question_id": 5586565, "best approach": "wiki, image", "verif answer": "pizza", "anno approach": "wiki", "verif wiki answer": "pizza(0.6504)", "verif concept answer": "calzone(0.6781)", "verif image answer": "pizza(0.6813)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558656.jpg"}, {"question": "what kind of meal is shown on the table", "gt answer": "dinner(1.00)<br/>lunch(0.60)", "pred answer": "breakfast", "question_id": 4163155, "best approach": "wiki, concept, image", "verif answer": "lunch", "anno approach": "wiki", "verif wiki answer": "lunch(0.7311)", "verif concept answer": "lunch(0.7311)", "verif image answer": "lunch(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416315.jpg"}, {"question": "what job function would use these", "gt answer": "spy(1.00)<br/>cook(0.60)", "pred answer": "cut", "question_id": 5805385, "best approach": "wiki", "verif answer": "chef", "anno approach": "wiki", "verif wiki answer": "cook(0.7299)", "verif concept answer": "chef(0.7208)", "verif image answer": "chef(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580538.jpg"}, {"question": "when was this piece of electronic equipment invented", "gt answer": "1981(1.00)", "pred answer": "1950s", "question_id": 1597315, "best approach": "", "verif answer": "steve job", "anno approach": "", "verif wiki answer": "steve job(0.7311)", "verif concept answer": "steve job(0.7311)", "verif image answer": "steve job(0.6954)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159731.jpg"}, {"question": "which type of bridge is this", "gt answer": "train bridge(1.00)", "pred answer": "golden gate", "question_id": 547365, "best approach": "", "verif answer": "bridge", "anno approach": "", "verif wiki answer": "bridge(0.7278)", "verif concept answer": "bridge(0.7177)", "verif image answer": "bridge(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054736.jpg"}, {"question": "where did this food originate from", "gt answer": "italy(1.00)", "pred answer": "italy", "question_id": 3575095, "best approach": "wiki, concept, image", "verif answer": "italy", "anno approach": "wiki", "verif wiki answer": "italy(0.6596)", "verif concept answer": "italy(0.6593)", "verif image answer": "italy(0.6615)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357509.jpg"}, {"question": "the vehicle in this photo is also known as a rocket", "gt answer": "crotch(1.00)", "pred answer": "harley davidson", "question_id": 3407635, "best approach": "image", "verif answer": "crotch", "anno approach": "image", "verif wiki answer": "harley(0.6733)", "verif concept answer": "harley(0.6817)", "verif image answer": "crotch(0.7193)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340763.jpg"}, {"question": "is this english or american riding", "gt answer": "american(1.00)<br/>english(1.00)", "pred answer": "clydesdale", "question_id": 2076985, "best approach": "concept", "verif answer": "german", "anno approach": "concept", "verif wiki answer": "french(0.6555)", "verif concept answer": "english(0.6426)", "verif image answer": "german(0.6606)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207698.jpg"}, {"question": "which zoos allow visitors to do this", "gt answer": "pet zoo(1.00)<br/>0(0.60)", "pred answer": "san diego", "question_id": 2461195, "best approach": "", "verif answer": "zoo", "anno approach": "", "verif wiki answer": "zoo(0.6624)", "verif concept answer": "zoo(0.6607)", "verif image answer": "zoo(0.6585)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246119.jpg"}, {"question": "what city is this", "gt answer": "washington dc(1.00)", "pred answer": "london", "question_id": 3717915, "best approach": "", "verif answer": "rome", "anno approach": "", "verif wiki answer": "rome(0.6838)", "verif concept answer": "rome(0.6756)", "verif image answer": "rome(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371791.jpg"}, {"question": "what kind of pizza is that", "gt answer": "supreme(1.00)", "pred answer": "pepperoni", "question_id": 4451405, "best approach": "", "verif answer": "pepperoni", "anno approach": "", "verif wiki answer": "pepperoni(0.6586)", "verif concept answer": "tomato(0.6565)", "verif image answer": "pepperoni(0.6909)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445140.jpg"}, {"question": "what is purpose of the bottles", "gt answer": "decoration(1.00)<br/>drink(0.60)", "pred answer": "water", "question_id": 74765, "best approach": "wiki, concept", "verif answer": "drink", "anno approach": "concept, wiki", "verif wiki answer": "drink(0.6291)", "verif concept answer": "drink(0.6678)", "verif image answer": "display(0.5361)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007476.jpg"}, {"question": "why is there a zebra inside", "gt answer": "taxidermy(1.00)<br/>zoo(0.60)<br/>mounted(0.60)", "pred answer": "bath", "question_id": 1478295, "best approach": "wiki, concept, image", "verif answer": "zoo", "anno approach": "wiki", "verif wiki answer": "zoo(0.6696)", "verif concept answer": "zoo(0.6373)", "verif image answer": "zoo(0.6630)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147829.jpg"}, {"question": "how much calorie can be got in the food they are holding", "gt answer": "300(1.00)<br/>200(0.60)<br/>500(0.60)<br/>lot(0.60)", "pred answer": "200", "question_id": 199675, "best approach": "wiki, concept, image", "verif answer": "500", "anno approach": "image, wiki", "verif wiki answer": "200(0.5193)", "verif concept answer": "200(0.5368)", "verif image answer": "500(0.6078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019967.jpg"}, {"question": "in what state are these mountain ranges", "gt answer": "nevada(1.00)<br/>idaho(0.60)<br/>washington(0.60)", "pred answer": "texas", "question_id": 301755, "best approach": "wiki, concept", "verif answer": "colorado", "anno approach": "wiki", "verif wiki answer": "washington(0.5007)", "verif concept answer": "washington(0.5011)", "verif image answer": "colorado(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030175.jpg"}, {"question": "what kind of book is the boy reading", "gt answer": "fiction(1.00)", "pred answer": "window", "question_id": 465806, "best approach": "image", "verif answer": "listen", "anno approach": "image", "verif wiki answer": "listen(0.5000)", "verif concept answer": "listen(0.5000)", "verif image answer": "fiction(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046580.jpg"}, {"question": "this is meant to do what to the birds", "gt answer": "scare(1.00)", "pred answer": "migrate", "question_id": 1887225, "best approach": "image", "verif answer": "dry", "anno approach": "image", "verif wiki answer": "dry(0.7128)", "verif concept answer": "dry(0.7294)", "verif image answer": "scare(0.6667)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188722.jpg"}, {"question": "is this after or before school hours", "gt answer": "after(1.00)<br/>before(0.60)", "pred answer": "before", "question_id": 4716475, "best approach": "wiki, concept", "verif answer": "before", "anno approach": "", "verif wiki answer": "before(0.7216)", "verif concept answer": "before(0.6904)", "verif image answer": "boy(0.5946)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471647.jpg"}, {"question": "how heavy can this mammal get in pounds", "gt answer": "1600 lbs(1.00)<br/>2000(0.60)<br/>800(0.60)", "pred answer": "ton", "question_id": 3758695, "best approach": "", "verif answer": "baby", "anno approach": "", "verif wiki answer": "baby(0.5044)", "verif concept answer": "baby(0.5308)", "verif image answer": "baby(0.5822)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375869.jpg"}, {"question": "what are these people working on", "gt answer": "surfboard(1.00)<br/>surf board(0.60)", "pred answer": "surfboard", "question_id": 371745, "best approach": "wiki, concept", "verif answer": "surf", "anno approach": "wiki", "verif wiki answer": "surfboard(0.5796)", "verif concept answer": "surfboard(0.5481)", "verif image answer": "surf(0.6443)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000037174.jpg"}, {"question": "is this business casual or professional attire", "gt answer": "professional(1.00)<br/>business(1.00)<br/>casual(0.60)", "pred answer": "casual", "question_id": 5668555, "best approach": "wiki, concept, image", "verif answer": "professional", "anno approach": "wiki", "verif wiki answer": "professional(0.7258)", "verif concept answer": "professional(0.7310)", "verif image answer": "professional(0.7276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566855.jpg"}, {"question": "what team did the player on the left begin his mlb career with", "gt answer": "yankees(1.00)<br/>red sox(0.60)", "pred answer": "dodger", "question_id": 2894255, "best approach": "", "verif answer": "cardinal", "anno approach": "", "verif wiki answer": "cardinal(0.7271)", "verif concept answer": "cardinal(0.7311)", "verif image answer": "cardinal(0.7052)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000289425.jpg"}, {"question": "what is the waist measurement of the girls jeans", "gt answer": "28(1.00)<br/>32(0.60)<br/>20 inches(0.60)", "pred answer": "low", "question_id": 3563445, "best approach": "wiki, concept, image", "verif answer": "20 inches", "anno approach": "concept, wiki", "verif wiki answer": "20 inches(0.7258)", "verif concept answer": "20 inches(0.7207)", "verif image answer": "20 inches(0.6752)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356344.jpg"}, {"question": "what breed of dog is in the truck", "gt answer": "german shepherd(1.00)<br/>german shepard(0.60)", "pred answer": "beagle", "question_id": 1822425, "best approach": "", "verif answer": "shepard", "anno approach": "", "verif wiki answer": "shepard(0.6441)", "verif concept answer": "shepard(0.6388)", "verif image answer": "shepard(0.6390)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182242.jpg"}, {"question": "what sport does the team on the top of the double decker bus play", "gt answer": "hockey(1.00)<br/>soccer(0.60)", "pred answer": "football", "question_id": 2736535, "best approach": "wiki, concept", "verif answer": "hockey", "anno approach": "wiki", "verif wiki answer": "hockey(0.5521)", "verif concept answer": "hockey(0.5246)", "verif image answer": "leather(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273653.jpg"}, {"question": "what type of boat is this", "gt answer": "cruise ship(1.00)<br/>ship(0.60)<br/>freight(0.60)", "pred answer": "sail", "question_id": 60045, "best approach": "", "verif answer": "passenger", "anno approach": "", "verif wiki answer": "passenger(0.7076)", "verif concept answer": "passenger(0.6578)", "verif image answer": "cruise(0.6688)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006004.jpg"}, {"question": "is the writing on the walls and ramps here illegal or legal", "gt answer": "illegal(1.00)", "pred answer": "illegal", "question_id": 1368195, "best approach": "", "verif answer": "legal", "anno approach": "", "verif wiki answer": "legal(0.7310)", "verif concept answer": "legal(0.7309)", "verif image answer": "legal(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136819.jpg"}, {"question": "what kind of boat is pictured", "gt answer": "tug(1.00)<br/>tugboat(1.00)", "pred answer": "fish boat", "question_id": 1608485, "best approach": "wiki, concept, image", "verif answer": "tugboat", "anno approach": "concept, wiki", "verif wiki answer": "tugboat(0.7307)", "verif concept answer": "tugboat(0.7293)", "verif image answer": "tugboat(0.6825)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160848.jpg"}, {"question": "what kind of crotch rocket is in the photo", "gt answer": "suzuki(1.00)<br/>motorcycle(0.60)", "pred answer": "harley", "question_id": 794815, "best approach": "wiki, concept", "verif answer": "motorcycle", "anno approach": "wiki", "verif wiki answer": "motorcycle(0.6861)", "verif concept answer": "motorcycle(0.6737)", "verif image answer": "bike(0.6731)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079481.jpg"}, {"question": "where does that door lead to", "gt answer": "outside(1.00)<br/>hall(0.60)", "pred answer": "door", "question_id": 2339705, "best approach": "concept", "verif answer": "dock", "anno approach": "concept", "verif wiki answer": "dock(0.5038)", "verif concept answer": "hall(0.5002)", "verif image answer": "dock(0.5523)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233970.jpg"}, {"question": "", "gt answer": "45(0.60)<br/>30 degrees(0.60)", "pred answer": "north", "question_id": 3322045, "best approach": "", "verif answer": "wide angle", "anno approach": "", "verif wiki answer": "wide angle(0.6416)", "verif concept answer": "wide angle(0.6157)", "verif image answer": "wide angle(0.5445)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332204.jpg"}, {"question": "why is the grass discolored", "gt answer": "drought(1.00)<br/>dry(0.60)<br/>sun(0.60)", "pred answer": "bent", "question_id": 603165, "best approach": "wiki, concept, image", "verif answer": "dry", "anno approach": "wiki", "verif wiki answer": "dry(0.7253)", "verif concept answer": "dry(0.7197)", "verif image answer": "dry(0.7003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060316.jpg"}, {"question": "why is the smoke black", "gt answer": "coal(1.00)", "pred answer": "dark", "question_id": 3719785, "best approach": "wiki, concept", "verif answer": "coal", "anno approach": "wiki", "verif wiki answer": "coal(0.5306)", "verif concept answer": "coal(0.5262)", "verif image answer": "diesel(0.5080)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371978.jpg"}, {"question": "what breed of dog is that", "gt answer": "husky(1.00)<br/>german shepard(0.60)", "pred answer": "lab", "question_id": 4123635, "best approach": "image", "verif answer": "husky", "anno approach": "image", "verif wiki answer": "german shepherd(0.6572)", "verif concept answer": "german shepherd(0.6715)", "verif image answer": "husky(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412363.jpg"}, {"question": "how fast can this bike go", "gt answer": "100 mph(1.00)<br/>120 mph(0.60)", "pred answer": "80 mph", "question_id": 3255695, "best approach": "wiki", "verif answer": "80 mph", "anno approach": "wiki", "verif wiki answer": "100 mph(0.5011)", "verif concept answer": "80 mph(0.5071)", "verif image answer": "30 mph(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325569.jpg"}, {"question": "what sort of nut has the same name as this color green", "gt answer": "pistachio(1.00)", "pred answer": "walnut", "question_id": 3626185, "best approach": "", "verif answer": "cherry", "anno approach": "", "verif wiki answer": "cherry(0.5569)", "verif concept answer": "cherry(0.5424)", "verif image answer": "cherry(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362618.jpg"}, {"question": "what is the process that allows the bear to stay on the window", "gt answer": "suction(1.00)", "pred answer": "wind", "question_id": 2450895, "best approach": "image", "verif answer": "flush", "anno approach": "image", "verif wiki answer": "flush(0.6589)", "verif concept answer": "tusk(0.6575)", "verif image answer": "suction(0.6448)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245089.jpg"}, {"question": "what would you call the man behind the catcher", "gt answer": "umpire(1.00)", "pred answer": "umpire", "question_id": 3283465, "best approach": "", "verif answer": "bleacher", "anno approach": "", "verif wiki answer": "bleacher(0.7308)", "verif concept answer": "bleacher(0.7182)", "verif image answer": "bleacher(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328346.jpg"}, {"question": "why would they need those", "gt answer": "extra seat(1.00)", "pred answer": "travel", "question_id": 3642515, "best approach": "", "verif answer": "travel", "anno approach": "", "verif wiki answer": "travel(0.6772)", "verif concept answer": "travel(0.6939)", "verif image answer": "travel(0.7222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364251.jpg"}, {"question": "what kind of tennis stroke is this", "gt answer": "forehand(1.00)", "pred answer": "forehand", "question_id": 5281085, "best approach": "", "verif answer": "backhand", "anno approach": "", "verif wiki answer": "backhand(0.7250)", "verif concept answer": "backhand(0.7019)", "verif image answer": "backhand(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528108.jpg"}, {"question": "why would we suspect the person eating this is not diabetic", "gt answer": "sugar(1.00)", "pred answer": "fry", "question_id": 2294075, "best approach": "", "verif answer": "frost", "anno approach": "", "verif wiki answer": "frost(0.5879)", "verif concept answer": "frost(0.6125)", "verif image answer": "frost(0.5671)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000229407.jpg"}, {"question": "what type of motorcycle is that", "gt answer": "chopper(1.00)<br/>harley(0.60)", "pred answer": "honda", "question_id": 3722925, "best approach": "wiki, concept, image", "verif answer": "harley", "anno approach": "image, wiki", "verif wiki answer": "harley(0.5163)", "verif concept answer": "harley(0.5350)", "verif image answer": "harley(0.5824)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372292.jpg"}, {"question": "what time of day is it", "gt answer": "afternoon(1.00)<br/>morn(0.60)", "pred answer": "afternoon", "question_id": 4097405, "best approach": "wiki, concept", "verif answer": "morn", "anno approach": "wiki", "verif wiki answer": "afternoon(0.7203)", "verif concept answer": "afternoon(0.7181)", "verif image answer": "morn(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409740.jpg"}, {"question": "what is this person about to do", "gt answer": "slide(1.00)", "pred answer": "hit ball", "question_id": 4024065, "best approach": "wiki, concept, image", "verif answer": "slide", "anno approach": "", "verif wiki answer": "slide(0.7311)", "verif concept answer": "slide(0.7310)", "verif image answer": "slide(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402406.jpg"}, {"question": "why is this place so crowded", "gt answer": "rush hour(1.00)<br/>bus(0.60)", "pred answer": "parade", "question_id": 490925, "best approach": "image", "verif answer": "rush hour", "anno approach": "image", "verif wiki answer": "double decker(0.7056)", "verif concept answer": "traffic jam(0.6922)", "verif image answer": "rush hour(0.7248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049092.jpg"}, {"question": "are these ducks or geese", "gt answer": "duck(1.00)", "pred answer": "pigeon", "question_id": 33895, "best approach": "", "verif answer": "swan", "anno approach": "", "verif wiki answer": "swan(0.7124)", "verif concept answer": "swan(0.5019)", "verif image answer": "swan(0.5498)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003389.jpg"}, {"question": "what is it likely this man is doing", "gt answer": "photography(0.60)<br/>take photograph(1.00)<br/>take picture(0.60)", "pred answer": "work", "question_id": 4029605, "best approach": "", "verif answer": "light", "anno approach": "", "verif wiki answer": "motorcycle(0.6366)", "verif concept answer": "motorcycle(0.6560)", "verif image answer": "light(0.6751)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402960.jpg"}, {"question": "at what age can someone drink this", "gt answer": "21(1.00)", "pred answer": "21", "question_id": 5777185, "best approach": "wiki", "verif answer": "21", "anno approach": "wiki", "verif wiki answer": "21(0.7307)", "verif concept answer": "15(0.6757)", "verif image answer": "18(0.6762)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000577718.jpg"}, {"question": "what is the newest model of apple laptops", "gt answer": "macbook pro(1.00)<br/>macbook(0.60)", "pred answer": "dell", "question_id": 5781285, "best approach": "", "verif answer": "notebook", "anno approach": "", "verif wiki answer": "laptop(0.6492)", "verif concept answer": "notebook(0.6663)", "verif image answer": "notebook(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578128.jpg"}, {"question": "what is the process called that produces the red area on the chair", "gt answer": "rust(1.00)<br/>oxidation(0.60)", "pred answer": "paint", "question_id": 1052805, "best approach": "wiki, concept, image", "verif answer": "oxidation", "anno approach": "wiki", "verif wiki answer": "oxidation(0.7311)", "verif concept answer": "oxidation(0.7311)", "verif image answer": "oxidation(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105280.jpg"}, {"question": "what is the dental difference between these two animals", "gt answer": "canine(1.00)", "pred answer": "rabies", "question_id": 4563765, "best approach": "wiki, concept, image", "verif answer": "canine", "anno approach": "wiki", "verif wiki answer": "canine(0.6494)", "verif concept answer": "canine(0.6503)", "verif image answer": "canine(0.6349)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456376.jpg"}, {"question": "", "gt answer": "1960's(0.60)<br/>1950's(0.60)<br/>70's(0.60)", "pred answer": "1970's", "question_id": 4889285, "best approach": "wiki, concept, image", "verif answer": "70's", "anno approach": "", "verif wiki answer": "70's(0.6496)", "verif concept answer": "70's(0.6304)", "verif image answer": "70's(0.6454)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488928.jpg"}, {"question": "what is the name for this creatures offspring", "gt answer": "puppy(1.00)", "pred answer": "calf", "question_id": 473875, "best approach": "wiki, concept, image", "verif answer": "puppy", "anno approach": "wiki", "verif wiki answer": "puppy(0.6443)", "verif concept answer": "puppy(0.6546)", "verif image answer": "puppy(0.6623)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047387.jpg"}, {"question": "what is a general function of the item she is holding", "gt answer": "shade(1.00)", "pred answer": "rain", "question_id": 2556235, "best approach": "", "verif answer": "rain", "anno approach": "", "verif wiki answer": "rain(0.7300)", "verif concept answer": "rain(0.7309)", "verif image answer": "rain(0.6797)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255623.jpg"}, {"question": "are there an even number of wheels or an odd number of wheels in this parking lot", "gt answer": "even(1.00)", "pred answer": "15", "question_id": 622165, "best approach": "", "verif answer": "night", "anno approach": "", "verif wiki answer": "night(0.7136)", "verif concept answer": "night(0.7298)", "verif image answer": "filter(0.6828)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000062216.jpg"}, {"question": "what kind of road is this", "gt answer": "highway(1.00)<br/>interstate(1.00)", "pred answer": "asphalt", "question_id": 487425, "best approach": "wiki, concept, image", "verif answer": "interstate", "anno approach": "concept, wiki", "verif wiki answer": "interstate(0.7301)", "verif concept answer": "interstate(0.7310)", "verif image answer": "interstate(0.6563)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048742.jpg"}, {"question": "what brand of soap is the man in the photo holding", "gt answer": "palmolive(1.00)", "pred answer": "kenmore", "question_id": 2238755, "best approach": "wiki, image", "verif answer": "palmolive", "anno approach": "wiki", "verif wiki answer": "palmolive(0.7299)", "verif concept answer": "aloe(0.7285)", "verif image answer": "palmolive(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223875.jpg"}, {"question": "what vegetable are the green leaves", "gt answer": "arugula(1.00)<br/>lettuce(0.60)<br/>spinach(0.60)", "pred answer": "broccoli", "question_id": 2327185, "best approach": "wiki, concept, image", "verif answer": "arugula", "anno approach": "concept, wiki", "verif wiki answer": "arugula(0.7307)", "verif concept answer": "arugula(0.7286)", "verif image answer": "arugula(0.6887)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232718.jpg"}, {"question": "are giraffee carnivorous or herbivorous animals", "gt answer": "herbivorous(1.00)", "pred answer": "herbivorous", "question_id": 5276185, "best approach": "wiki, concept, image", "verif answer": "herbivorous", "anno approach": "", "verif wiki answer": "herbivorous(0.7311)", "verif concept answer": "herbivorous(0.7311)", "verif image answer": "herbivorous(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527618.jpg"}, {"question": "what brand is the carpetting", "gt answer": "dupont(1.00)", "pred answer": "ashley", "question_id": 5717735, "best approach": "wiki, concept", "verif answer": "dupont", "anno approach": "", "verif wiki answer": "dupont(0.6585)", "verif concept answer": "dupont(0.6567)", "verif image answer": "target(0.6517)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571773.jpg"}, {"question": "what century is this", "gt answer": "20th(1.00)<br/>19th(0.60)", "pred answer": "19th", "question_id": 3539335, "best approach": "concept", "verif answer": "19th", "anno approach": "concept", "verif wiki answer": "19th(0.7308)", "verif concept answer": "20th(0.7047)", "verif image answer": "19th(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353933.jpg"}, {"question": "what company made the accordian that the man is playing", "gt answer": "castiglione(1.00)<br/>yamaha(0.60)", "pred answer": "wilson", "question_id": 2063845, "best approach": "", "verif answer": "columbia", "anno approach": "", "verif wiki answer": "columbia(0.6207)", "verif concept answer": "columbia(0.6354)", "verif image answer": "columbia(0.6419)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206384.jpg"}, {"question": "which popular video game do you think she is playing right now", "gt answer": "mario(1.00)", "pred answer": "wii", "question_id": 3435145, "best approach": "", "verif answer": "wii bowl", "anno approach": "", "verif wiki answer": "wii bowl(0.7096)", "verif concept answer": "wii bowl(0.7264)", "verif image answer": "wii bowl(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343514.jpg"}, {"question": "what kind of transportation is this man on", "gt answer": "submarine(1.00)<br/>bus(1.00)", "pred answer": "motorcycle", "question_id": 5073905, "best approach": "wiki, concept", "verif answer": "train", "anno approach": "concept, wiki", "verif wiki answer": "submarine(0.5058)", "verif concept answer": "submarine(0.6226)", "verif image answer": "train(0.6257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507390.jpg"}, {"question": "who is wearing black", "gt answer": "umpire(1.00)", "pred answer": "umpire", "question_id": 4111095, "best approach": "wiki, concept, image", "verif answer": "umpire", "anno approach": "image, wiki", "verif wiki answer": "umpire(0.5159)", "verif concept answer": "umpire(0.5132)", "verif image answer": "umpire(0.5652)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000411109.jpg"}, {"question": "this fruit is high in what common nutrient", "gt answer": "potassium(1.00)", "pred answer": "potassium", "question_id": 2066765, "best approach": "", "verif answer": "vitamin c", "anno approach": "", "verif wiki answer": "vitamin c(0.6513)", "verif concept answer": "vitamin c(0.6572)", "verif image answer": "vitamin c(0.6413)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206676.jpg"}, {"question": "what is the calorie count for a slice of the pizza shown in the image", "gt answer": "400(1.00)<br/>800(0.60)<br/>300(0.60)", "pred answer": "500", "question_id": 870785, "best approach": "wiki", "verif answer": "300", "anno approach": "wiki", "verif wiki answer": "400(0.6537)", "verif concept answer": "300(0.6616)", "verif image answer": "46(0.6392)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087078.jpg"}, {"question": "what type of electrical lighting is in this kitchen", "gt answer": "fluorescent(1.00)<br/>led(0.60)", "pred answer": "electric", "question_id": 2681515, "best approach": "wiki, concept, image", "verif answer": "led", "anno approach": "concept, wiki", "verif wiki answer": "led(0.7094)", "verif concept answer": "led(0.7115)", "verif image answer": "led(0.6457)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268151.jpg"}, {"question": "what cell phone is that", "gt answer": "flip phone(1.00)<br/>flip(0.60)<br/>sony(0.60)", "pred answer": "flip phone", "question_id": 5784845, "best approach": "", "verif answer": "smartphone", "anno approach": "", "verif wiki answer": "smartphone(0.7188)", "verif concept answer": "smartphone(0.7298)", "verif image answer": "smartphone(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578484.jpg"}, {"question": "which place is famous for manufacturing this type of vehicles", "gt answer": "harley davidson(1.00)<br/>italy(0.60)", "pred answer": "honda", "question_id": 2746675, "best approach": "concept", "verif answer": "italy", "anno approach": "concept", "verif wiki answer": "yamaha(0.6602)", "verif concept answer": "italy(0.6681)", "verif image answer": "yamaha(0.6385)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274667.jpg"}, {"question": "its a bird its a blank", "gt answer": "plane(1.00)<br/>airplane(0.60)", "pred answer": "pigeon", "question_id": 4715895, "best approach": "", "verif answer": "cloud", "anno approach": "", "verif wiki answer": "cloud(0.7308)", "verif concept answer": "cloud(0.7305)", "verif image answer": "cloud(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471589.jpg"}, {"question": "who designed this area", "gt answer": "architect(1.00)<br/>engineer(0.60)", "pred answer": "gothic", "question_id": 3444565, "best approach": "wiki, concept, image", "verif answer": "architect", "anno approach": "concept, wiki", "verif wiki answer": "architect(0.7254)", "verif concept answer": "architect(0.7273)", "verif image answer": "architect(0.6594)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344456.jpg"}, {"question": "what is another name for elephant", "gt answer": "pacaderm(1.00)<br/>african(0.60)<br/>dumbo(0.60)", "pred answer": "mammal", "question_id": 1024605, "best approach": "concept", "verif answer": "dumbo", "anno approach": "concept", "verif wiki answer": "tusk(0.6757)", "verif concept answer": "pacaderm(0.7147)", "verif image answer": "dumbo(0.7191)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000102460.jpg"}, {"question": "how well cooked is this pizza", "gt answer": "raw(1.00)<br/>undercooked(0.60)", "pred answer": "very", "question_id": 3650345, "best approach": "", "verif answer": "cooked", "anno approach": "", "verif wiki answer": "very(0.6574)", "verif concept answer": "very(0.6576)", "verif image answer": "cooked(0.7080)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365034.jpg"}, {"question": "what kind of meat is in the picture", "gt answer": "chicken(1.00)", "pred answer": "beef", "question_id": 4565635, "best approach": "", "verif answer": "pork", "anno approach": "", "verif wiki answer": "roast(0.6516)", "verif concept answer": "roast(0.6555)", "verif image answer": "pork(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456563.jpg"}, {"question": "what is on the bush", "gt answer": "light(1.00)", "pred answer": "fan", "question_id": 3840705, "best approach": "image", "verif answer": "illumination", "anno approach": "image", "verif wiki answer": "illumination(0.6130)", "verif concept answer": "illumination(0.6006)", "verif image answer": "light(0.5179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384070.jpg"}, {"question": "what flavor do you think this cake is", "gt answer": "vanilla(1.00)", "pred answer": "vanilla", "question_id": 3129395, "best approach": "wiki, image", "verif answer": "sweet", "anno approach": "wiki", "verif wiki answer": "vanilla(0.6122)", "verif concept answer": "sweet(0.6268)", "verif image answer": "vanilla(0.6001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312939.jpg"}, {"question": "why is this girl unhappy", "gt answer": "rain(1.00)", "pred answer": "rain", "question_id": 3310315, "best approach": "", "verif answer": "cold", "anno approach": "", "verif wiki answer": "cold(0.7311)", "verif concept answer": "cold(0.7311)", "verif image answer": "cold(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331031.jpg"}, {"question": "when was snowboard first introduced as an olympic sport", "gt answer": "1998(1.00)<br/>1980's(0.60)", "pred answer": "1800s", "question_id": 1191575, "best approach": "", "verif answer": "1970", "anno approach": "", "verif wiki answer": "1924(0.6073)", "verif concept answer": "1970(0.6373)", "verif image answer": "1970(0.6353)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119157.jpg"}, {"question": "what is the bun topped with", "gt answer": "onion(1.00)<br/>cheese(0.60)", "pred answer": "fry", "question_id": 5061365, "best approach": "", "verif answer": "fry", "anno approach": "", "verif wiki answer": "ketchup(0.5693)", "verif concept answer": "fry(0.5593)", "verif image answer": "fry(0.6432)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506136.jpg"}, {"question": "", "gt answer": "africa(0.60)<br/>tropic(0.60)<br/>rainforest(0.60)<br/>pet store(0.60)", "pred answer": "rainforest", "question_id": 1374205, "best approach": "wiki, image", "verif answer": "pet store", "anno approach": "", "verif wiki answer": "africa(0.6977)", "verif concept answer": "south america(0.6993)", "verif image answer": "pet store(0.7019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000137420.jpg"}, {"question": "what will the batter try to do", "gt answer": "hit(1.00)<br/>homerun(0.60)<br/>swing(0.60)<br/>hit ball(0.60)", "pred answer": "hit ball", "question_id": 4700535, "best approach": "wiki, concept", "verif answer": "home run", "anno approach": "wiki", "verif wiki answer": "hit ball(0.7310)", "verif concept answer": "hit ball(0.7310)", "verif image answer": "home run(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470053.jpg"}, {"question": "what is the clothing made of that these people are wearing", "gt answer": "neoprene(1.00)<br/>nylon(0.60)", "pred answer": "wet suit", "question_id": 3751105, "best approach": "wiki", "verif answer": "rubber", "anno approach": "wiki", "verif wiki answer": "neoprene(0.6506)", "verif concept answer": "rubber(0.7184)", "verif image answer": "nylon(0.6383)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375110.jpg"}, {"question": "why is this person holding an umbrella", "gt answer": "for shade(1.00)<br/>shade(1.00)<br/>block sun(0.60)", "pred answer": "rain", "question_id": 4914005, "best approach": "", "verif answer": "rain", "anno approach": "", "verif wiki answer": "rain(0.6339)", "verif concept answer": "rain(0.6456)", "verif image answer": "rain(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491400.jpg"}, {"question": "what time of year is this sport traditionally played", "gt answer": "summer(1.00)<br/>spring(1.00)", "pred answer": "summer", "question_id": 2269835, "best approach": "wiki, concept, image", "verif answer": "summer", "anno approach": "concept, wiki", "verif wiki answer": "summer(0.7196)", "verif concept answer": "summer(0.6780)", "verif image answer": "summer(0.6437)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226983.jpg"}, {"question": "what 's the skateboarder doing", "gt answer": "jump(1.00)", "pred answer": "jump", "question_id": 3931105, "best approach": "", "verif answer": "ollie", "anno approach": "", "verif wiki answer": "skateboard(0.6380)", "verif concept answer": "ollie(0.6474)", "verif image answer": "ollie(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393110.jpg"}, {"question": "what operating systems do these items appear to be running on", "gt answer": "window(1.00)", "pred answer": "ibm", "question_id": 1381895, "best approach": "", "verif answer": "internet explorer", "anno approach": "", "verif wiki answer": "internet explorer(0.6528)", "verif concept answer": "internet explorer(0.6570)", "verif image answer": "business(0.6315)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138189.jpg"}, {"question": "what material is this mans suit made of", "gt answer": "cotton(1.00)<br/>wool(1.00)<br/>polyester(0.60)", "pred answer": "cotton", "question_id": 1082935, "best approach": "", "verif answer": "cloth", "anno approach": "", "verif wiki answer": "cloth(0.6616)", "verif concept answer": "cloth(0.7269)", "verif image answer": "fleece(0.6511)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108293.jpg"}, {"question": "what kind of house is on this truck", "gt answer": "mobile home(1.00)<br/>trailer(0.60)", "pred answer": "apartment", "question_id": 794985, "best approach": "wiki, concept, image", "verif answer": "trailer", "anno approach": "concept, wiki", "verif wiki answer": "trailer(0.6732)", "verif concept answer": "trailer(0.7260)", "verif image answer": "trailer(0.7032)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079498.jpg"}, {"question": "what kind of dish is the woman eating", "gt answer": "mexican(1.00)", "pred answer": "cake", "question_id": 5718675, "best approach": "wiki, concept, image", "verif answer": "mexican", "anno approach": "image, wiki", "verif wiki answer": "mexican(0.6274)", "verif concept answer": "mexican(0.6580)", "verif image answer": "mexican(0.6650)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571867.jpg"}, {"question": "who became famous by flying one of these in a lightning storm", "gt answer": "benjamin franklin(1.00)<br/>ben franklin(0.60)", "pred answer": "ben franklin", "question_id": 1590265, "best approach": "", "verif answer": "mozi", "anno approach": "", "verif wiki answer": "mozi(0.7155)", "verif concept answer": "mozi(0.6532)", "verif image answer": "mozi(0.6674)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159026.jpg"}, {"question": "the pointy items on the top of this animal 's head are called what", "gt answer": "horn(1.00)<br/>tusk(0.60)", "pred answer": "hat", "question_id": 1082235, "best approach": "image", "verif answer": "udder", "anno approach": "image", "verif wiki answer": "udder(0.7311)", "verif concept answer": "tusk(0.7307)", "verif image answer": "horn(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108223.jpg"}, {"question": "where do you think this place could be located", "gt answer": "skatepark(1.00)<br/>skate park(1.00)", "pred answer": "park", "question_id": 2567485, "best approach": "wiki, concept", "verif answer": "skate park", "anno approach": "wiki", "verif wiki answer": "skate park(0.6527)", "verif concept answer": "skatepark(0.6486)", "verif image answer": "park(0.6421)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256748.jpg"}, {"question": "", "gt answer": "coffee shop(0.60)<br/>dunkin donuts(0.60)", "pred answer": "bakery", "question_id": 1057335, "best approach": "", "verif answer": "bakery", "anno approach": "", "verif wiki answer": "bakery(0.6841)", "verif concept answer": "bakery(0.6714)", "verif image answer": "bakery(0.7045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105733.jpg"}, {"question": "what does this vehicle use for fuel", "gt answer": "diesel(1.00)<br/>coal(0.60)", "pred answer": "coal", "question_id": 873225, "best approach": "wiki, concept, image", "verif answer": "coal", "anno approach": "image, wiki", "verif wiki answer": "coal(0.7006)", "verif concept answer": "coal(0.6651)", "verif image answer": "coal(0.7200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087322.jpg"}, {"question": "what direction is the wind blowing from in this photo", "gt answer": "west(1.00)<br/>right(0.60)<br/>left(0.60)", "pred answer": "south", "question_id": 5272165, "best approach": "", "verif answer": "western", "anno approach": "", "verif wiki answer": "western(0.7303)", "verif concept answer": "western(0.7310)", "verif image answer": "western(0.7026)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527216.jpg"}, {"question": "what type of luggage is this", "gt answer": "carry on(1.00)<br/>suitcase(0.60)", "pred answer": "backpack", "question_id": 3958305, "best approach": "", "verif answer": "backpack", "anno approach": "", "verif wiki answer": "backpack(0.7309)", "verif concept answer": "backpack(0.7310)", "verif image answer": "backpack(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395830.jpg"}, {"question": "what items did the suit case contain before it was emptied", "gt answer": "cloth(1.00)<br/>food(0.60)<br/>paper(0.60)", "pred answer": "newspaper", "question_id": 670575, "best approach": "wiki, concept, image", "verif answer": "food", "anno approach": "wiki", "verif wiki answer": "food(0.6518)", "verif concept answer": "food(0.6559)", "verif image answer": "food(0.6602)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067057.jpg"}, {"question": "what type of bikes are these people riding", "gt answer": "motorbike(1.00)<br/>bmx(0.60)<br/>motocross(0.60)<br/>motorcycle(0.60)", "pred answer": "dirt bike", "question_id": 3504355, "best approach": "wiki, concept, image", "verif answer": "motorcycle", "anno approach": "wiki", "verif wiki answer": "motorcycle(0.7234)", "verif concept answer": "motorcycle(0.7307)", "verif image answer": "motorcycle(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350435.jpg"}, {"question": "what is the average weight of this animal at birth", "gt answer": "100lbs(1.00)<br/>500(0.60)", "pred answer": "10 years", "question_id": 466095, "best approach": "", "verif answer": "2000", "anno approach": "", "verif wiki answer": "50(0.5070)", "verif concept answer": "50(0.5070)", "verif image answer": "2000(0.6442)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046609.jpg"}, {"question": "what brewery is the beer from", "gt answer": "brew dog(1.00)<br/>scotland(0.60)", "pred answer": "budweiser", "question_id": 4543725, "best approach": "concept, image", "verif answer": "brew dog", "anno approach": "", "verif wiki answer": "paris(0.7306)", "verif concept answer": "brew dog(0.7311)", "verif image answer": "brew dog(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000454372.jpg"}, {"question": "how can i get up on a snowboard", "gt answer": "carefully(1.00)<br/>balance(0.60)", "pred answer": "grind", "question_id": 1961975, "best approach": "concept", "verif answer": "balance", "anno approach": "concept", "verif wiki answer": "balance(0.6563)", "verif concept answer": "carefully(0.6527)", "verif image answer": "balance(0.6757)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196197.jpg"}, {"question": "what is the average lifespan of this animal", "gt answer": "30 years(1.00)<br/>20 years(0.60)", "pred answer": "25", "question_id": 4183525, "best approach": "wiki", "verif answer": "30 years", "anno approach": "wiki", "verif wiki answer": "30 years(0.7266)", "verif concept answer": "25 years(0.6041)", "verif image answer": "25 years(0.7181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000418352.jpg"}, {"question": "which beatles song features a road like this", "gt answer": "abbey(1.00)", "pred answer": "jack and jill", "question_id": 2017285, "best approach": "", "verif answer": "cherry", "anno approach": "", "verif wiki answer": "cherry(0.6741)", "verif concept answer": "cherry(0.6564)", "verif image answer": "cherry(0.6361)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201728.jpg"}, {"question": "which farmer of song fame is often associated with these animals", "gt answer": "old macdonald(1.00)<br/>dell(0.60)", "pred answer": "cow", "question_id": 2426565, "best approach": "concept", "verif answer": "dell", "anno approach": "concept", "verif wiki answer": "herbivore(0.5012)", "verif concept answer": "dell(0.5157)", "verif image answer": "herbivore(0.5044)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000242656.jpg"}, {"question": "what brand is the stove", "gt answer": "kenmore(1.00)<br/>new(0.60)<br/>kitchen aid(0.60)<br/>samsung(0.60)", "pred answer": "ge", "question_id": 3948805, "best approach": "wiki", "verif answer": "lg", "anno approach": "wiki", "verif wiki answer": "new(0.6398)", "verif concept answer": "lg(0.6490)", "verif image answer": "lg(0.6469)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000394880.jpg"}, {"question": "what profession does this person have", "gt answer": "baker(1.00)<br/>cook(1.00)<br/>chef(0.60)", "pred answer": "chef", "question_id": 1511725, "best approach": "wiki, concept, image", "verif answer": "chef", "anno approach": "wiki", "verif wiki answer": "chef(0.7309)", "verif concept answer": "chef(0.7276)", "verif image answer": "chef(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151172.jpg"}, {"question": "what kind of company 's do these trucks work for", "gt answer": "construction(1.00)<br/>carnival(0.60)<br/>transport(0.60)", "pred answer": "bus", "question_id": 3629735, "best approach": "wiki, concept, image", "verif answer": "construction", "anno approach": "concept, wiki", "verif wiki answer": "construction(0.6543)", "verif concept answer": "construction(0.6709)", "verif image answer": "construction(0.5521)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362973.jpg"}, {"question": "what is special about the sports items in the case", "gt answer": "old(1.00)<br/>antique(0.60)<br/>racket(0.60)", "pred answer": "cloth", "question_id": 1332985, "best approach": "wiki, concept, image", "verif answer": "antique", "anno approach": "image", "verif wiki answer": "antique(0.5034)", "verif concept answer": "antique(0.5143)", "verif image answer": "antique(0.5635)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000133298.jpg"}, {"question": "what food is this", "gt answer": "candy apple(1.00)<br/>apple(1.00)", "pred answer": "tomato", "question_id": 2236875, "best approach": "image", "verif answer": "tomato", "anno approach": "image", "verif wiki answer": "tomato(0.6067)", "verif concept answer": "tomato(0.6708)", "verif image answer": "apple(0.6435)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223687.jpg"}, {"question": "which wearable item shown here is associated with ball games", "gt answer": "cap(1.00)<br/>baseball cap(0.60)", "pred answer": "hat", "question_id": 3929745, "best approach": "image", "verif answer": "hat", "anno approach": "image", "verif wiki answer": "hat(0.5983)", "verif concept answer": "hat(0.6384)", "verif image answer": "cap(0.5516)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392974.jpg"}, {"question": "when would i want this", "gt answer": "lunch(1.00)<br/>dinner(1.00)", "pred answer": "dinner", "question_id": 1671805, "best approach": "wiki, concept, image", "verif answer": "lunch", "anno approach": "concept, wiki", "verif wiki answer": "lunch(0.6636)", "verif concept answer": "lunch(0.6865)", "verif image answer": "lunch(0.6384)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167180.jpg"}, {"question": "what type of animals are in this picture", "gt answer": "cow(1.00)", "pred answer": "dog", "question_id": 3974615, "best approach": "", "verif answer": "horse", "anno approach": "", "verif wiki answer": "horse(0.7226)", "verif concept answer": "horse(0.7311)", "verif image answer": "horse(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397461.jpg"}, {"question": "what breed of dogs are these", "gt answer": "dachshund(1.00)<br/>doberman(0.60)", "pred answer": "collie", "question_id": 3776095, "best approach": "wiki", "verif answer": "dachsund", "anno approach": "wiki", "verif wiki answer": "doberman(0.6592)", "verif concept answer": "dachsund(0.6593)", "verif image answer": "dachsund(0.6469)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377609.jpg"}, {"question": "what type of palm tree is picured here t", "gt answer": "coconut(1.00)<br/>pine(0.60)", "pred answer": "palm", "question_id": 1174975, "best approach": "wiki", "verif answer": "oak", "anno approach": "wiki", "verif wiki answer": "pine(0.6602)", "verif concept answer": "oak(0.6554)", "verif image answer": "oak(0.6636)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117497.jpg"}, {"question": "what size are the tires on that truck", "gt answer": "big(1.00)<br/>huge(0.60)", "pred answer": "large", "question_id": 3625555, "best approach": "", "verif answer": "large", "anno approach": "", "verif wiki answer": "large(0.6597)", "verif concept answer": "large(0.6467)", "verif image answer": "large(0.6969)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362555.jpg"}, {"question": "are these indian or african elephants", "gt answer": "indian(1.00)<br/>african(0.60)", "pred answer": "african", "question_id": 615, "best approach": "wiki, concept, image", "verif answer": "african", "anno approach": "wiki", "verif wiki answer": "african(0.7310)", "verif concept answer": "african(0.7310)", "verif image answer": "african(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000061.jpg"}, {"question": "these long necked creatures live in what environment", "gt answer": "africa(1.00)<br/>hot(0.60)<br/>wild(0.60)", "pred answer": "zoo", "question_id": 5267135, "best approach": "", "verif answer": "serengeti", "anno approach": "", "verif wiki answer": "serengeti(0.7309)", "verif concept answer": "serengeti(0.7133)", "verif image answer": "serengeti(0.6467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526713.jpg"}, {"question": "which branch of mathematics teaches learners about angular shapes like the ones seen here", "gt answer": "geometry(1.00)", "pred answer": "spoon", "question_id": 4599595, "best approach": "", "verif answer": "retro", "anno approach": "", "verif wiki answer": "broccoli(0.5526)", "verif concept answer": "broccoli(0.5343)", "verif image answer": "retro(0.7177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459959.jpg"}, {"question": "what is this boat doing", "gt answer": "float(1.00)<br/>cruise(0.60)<br/>boat(0.60)", "pred answer": "fish", "question_id": 841625, "best approach": "", "verif answer": "barge", "anno approach": "", "verif wiki answer": "barge(0.7241)", "verif concept answer": "barge(0.7279)", "verif image answer": "fly(0.6920)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084162.jpg"}, {"question": "what kind of fuel does this vehicle use", "gt answer": "gasoline(1.00)<br/>bus(0.60)<br/>diesel(0.60)", "pred answer": "diesel", "question_id": 2792225, "best approach": "image", "verif answer": "gasoline", "anno approach": "image", "verif wiki answer": "jet fuel(0.6539)", "verif concept answer": "jet fuel(0.6687)", "verif image answer": "gasoline(0.7119)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000279222.jpg"}, {"question": "what were those buildings for originally", "gt answer": "storage(1.00)<br/>farm(0.60)<br/>time(0.60)", "pred answer": "church", "question_id": 76855, "best approach": "image", "verif answer": "farm", "anno approach": "image", "verif wiki answer": "farm(0.6484)", "verif concept answer": "farm(0.6513)", "verif image answer": "storage(0.6479)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007685.jpg"}, {"question": "what type of dog is this", "gt answer": "boxer(1.00)<br/>labrador(0.60)", "pred answer": "boxer", "question_id": 3169075, "best approach": "", "verif answer": "lab", "anno approach": "", "verif wiki answer": "lab(0.6213)", "verif concept answer": "lab(0.5447)", "verif image answer": "lab(0.6595)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316907.jpg"}, {"question": "how many times has this apple been cut", "gt answer": "once(1.00)", "pred answer": "40", "question_id": 5782315, "best approach": "", "verif answer": "eaten", "anno approach": "", "verif wiki answer": "eaten(0.7297)", "verif concept answer": "eaten(0.7296)", "verif image answer": "rarely(0.6830)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578231.jpg"}, {"question": "what is terr short for", "gt answer": "terrace(1.00)", "pred answer": "street", "question_id": 4872455, "best approach": "wiki", "verif answer": "terrace", "anno approach": "wiki", "verif wiki answer": "terrace(0.7213)", "verif concept answer": "cross(0.6452)", "verif image answer": "cross(0.6041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487245.jpg"}, {"question": "what kind of bird is this", "gt answer": "sandpiper(1.00)<br/>blue jay(0.60)<br/>sparrow(0.60)<br/>finch(0.60)", "pred answer": "sparrow", "question_id": 4795535, "best approach": "image", "verif answer": "sandpiper", "anno approach": "image", "verif wiki answer": "sparrow(0.5539)", "verif concept answer": "sparrow(0.5344)", "verif image answer": "sandpiper(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479553.jpg"}, {"question": "what major tennis tournament is played on the surface seen here", "gt answer": "wimbledon(1.00)", "pred answer": "us open", "question_id": 4355545, "best approach": "", "verif answer": "us open", "anno approach": "", "verif wiki answer": "us open(0.6858)", "verif concept answer": "world series(0.6496)", "verif image answer": "world series(0.6616)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435554.jpg"}, {"question": "what is the significance of this man 's tie", "gt answer": "business(1.00)<br/>collar(0.60)", "pred answer": "identification", "question_id": 4280935, "best approach": "image", "verif answer": "collar", "anno approach": "image", "verif wiki answer": "suit(0.6438)", "verif concept answer": "suit(0.6517)", "verif image answer": "collar(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428093.jpg"}, {"question": "what is the purpose of this object", "gt answer": "weigh(1.00)<br/>tell time(0.60)<br/>time tell(0.60)<br/>time(0.60)", "pred answer": "tell time", "question_id": 1133385, "best approach": "wiki, concept, image", "verif answer": "tell time", "anno approach": "concept, wiki", "verif wiki answer": "tell time(0.7218)", "verif concept answer": "tell time(0.7309)", "verif image answer": "tell time(0.6413)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113338.jpg"}, {"question": "what city is this plane taking off from", "gt answer": "paris(1.00)", "pred answer": "london", "question_id": 1843005, "best approach": "", "verif answer": "philadelphia", "anno approach": "", "verif wiki answer": "philadelphia(0.6415)", "verif concept answer": "philadelphia(0.6474)", "verif image answer": "philadelphia(0.7084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184300.jpg"}, {"question": "what quadrupedal creatures are depicted", "gt answer": "giraffe(1.00)", "pred answer": "zebra", "question_id": 1859065, "best approach": "wiki, concept, image", "verif answer": "giraffe", "anno approach": "wiki", "verif wiki answer": "giraffe(0.7310)", "verif concept answer": "giraffe(0.7311)", "verif image answer": "giraffe(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185906.jpg"}, {"question": "people who use this equipment are typically called what", "gt answer": "surfer(1.00)", "pred answer": "surf", "question_id": 2733525, "best approach": "", "verif answer": "duke kahanamoku", "anno approach": "", "verif wiki answer": "duke kahanamoku(0.7308)", "verif concept answer": "duke kahanamoku(0.6641)", "verif image answer": "duke kahanamoku(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273352.jpg"}, {"question": "which celebration is the image relating to", "gt answer": "halloween(1.00)", "pred answer": "easter", "question_id": 1249145, "best approach": "wiki, concept, image", "verif answer": "halloween", "anno approach": "wiki", "verif wiki answer": "halloween(0.6427)", "verif concept answer": "halloween(0.6275)", "verif image answer": "halloween(0.6531)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000124914.jpg"}, {"question": "which muscle group is used in the move shown", "gt answer": "leg(1.00)", "pred answer": "pad", "question_id": 5596475, "best approach": "", "verif answer": "abdominal", "anno approach": "", "verif wiki answer": "abdominal(0.6773)", "verif concept answer": "foot(0.6888)", "verif image answer": "abdominal(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559647.jpg"}, {"question": "when were motorcycles invented", "gt answer": "1885(1.00)<br/>2010(0.60)<br/>1960(0.60)<br/>1930s(0.60)", "pred answer": "1970", "question_id": 1440895, "best approach": "wiki, concept, image", "verif answer": "1930s", "anno approach": "wiki", "verif wiki answer": "1930s(0.7302)", "verif concept answer": "1930s(0.7298)", "verif image answer": "1930s(0.7161)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144089.jpg"}, {"question": "who invented the sport that the women are playing", "gt answer": "walter wingfield(1.00)<br/>man(0.60)", "pred answer": "tennis", "question_id": 4826595, "best approach": "", "verif answer": "federer", "anno approach": "", "verif wiki answer": "federer(0.6954)", "verif concept answer": "federer(0.6403)", "verif image answer": "federer(0.6474)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482659.jpg"}, {"question": "why is the sign standing in the street", "gt answer": "advertising(1.00)<br/>park(0.60)", "pred answer": "food", "question_id": 2802705, "best approach": "wiki, concept", "verif answer": "farm", "anno approach": "wiki", "verif wiki answer": "advertising(0.7297)", "verif concept answer": "advertising(0.7301)", "verif image answer": "farm(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280270.jpg"}, {"question": "what does this truck do", "gt answer": "transport(1.00)<br/>haul(0.60)", "pred answer": "haul", "question_id": 4071355, "best approach": "wiki, concept", "verif answer": "haul", "anno approach": "wiki", "verif wiki answer": "haul(0.6002)", "verif concept answer": "haul(0.5148)", "verif image answer": "taxi(0.5782)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407135.jpg"}, {"question": "what kind of dog is in the photo", "gt answer": "bichon frise(1.00)<br/>poodle(0.60)", "pred answer": "poodle", "question_id": 4610995, "best approach": "", "verif answer": "cat", "anno approach": "", "verif wiki answer": "cat(0.7029)", "verif concept answer": "cat(0.6734)", "verif image answer": "cat(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461099.jpg"}, {"question": "can you guess the place where this sport is played", "gt answer": "baseball field(1.00)<br/>baseball stadium(0.60)<br/>ballpark(0.60)<br/>stadium(0.60)", "pred answer": "baseball field", "question_id": 3864295, "best approach": "wiki, concept, image", "verif answer": "baseball field", "anno approach": "concept, wiki", "verif wiki answer": "baseball field(0.7300)", "verif concept answer": "baseball field(0.7288)", "verif image answer": "baseball field(0.6428)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000386429.jpg"}, {"question": "what are on the lady 's feet", "gt answer": "boot(1.00)", "pred answer": "luggage", "question_id": 1569395, "best approach": "wiki, concept, image", "verif answer": "boot", "anno approach": "image, wiki", "verif wiki answer": "boot(0.5066)", "verif concept answer": "boot(0.5030)", "verif image answer": "boot(0.6447)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000156939.jpg"}, {"question": "what century is this", "gt answer": "20th(1.00)<br/>19th(0.60)", "pred answer": "19th", "question_id": 749755, "best approach": "concept", "verif answer": "19th", "anno approach": "concept", "verif wiki answer": "19th(0.6980)", "verif concept answer": "20th(0.6795)", "verif image answer": "18th(0.6870)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074975.jpg"}, {"question": "what type of shoes is the woman wearing", "gt answer": "boot(1.00)", "pred answer": "sandal", "question_id": 4004305, "best approach": "", "verif answer": "leather", "anno approach": "", "verif wiki answer": "leather(0.6919)", "verif concept answer": "leather(0.7166)", "verif image answer": "goggle(0.6690)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400430.jpg"}, {"question": "what 's the bear for", "gt answer": "decoration(1.00)<br/>kid(0.60)", "pred answer": "compute", "question_id": 5453645, "best approach": "", "verif answer": "display", "anno approach": "", "verif wiki answer": "decor(0.6453)", "verif concept answer": "decor(0.6547)", "verif image answer": "display(0.6955)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545364.jpg"}, {"question": "what gender is the person holding the toddler", "gt answer": "female(1.00)", "pred answer": "female", "question_id": 4256285, "best approach": "wiki, image", "verif answer": "female", "anno approach": "wiki", "verif wiki answer": "female(0.7308)", "verif concept answer": "male(0.7307)", "verif image answer": "female(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425628.jpg"}, {"question": "what part of group does this man belong", "gt answer": "navy(1.00)<br/>catcher(0.60)<br/>military(0.60)", "pred answer": "goalie", "question_id": 2155115, "best approach": "concept", "verif answer": "military", "anno approach": "concept", "verif wiki answer": "marine(0.6108)", "verif concept answer": "navy(0.6975)", "verif image answer": "military(0.7171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215511.jpg"}, {"question": "how far can this ladder go for", "gt answer": "105 feet(1.00)<br/>far(0.60)", "pred answer": "10 feet", "question_id": 5179755, "best approach": "image", "verif answer": "3 feet", "anno approach": "image", "verif wiki answer": "3 feet(0.6537)", "verif concept answer": "5 feet(0.6514)", "verif image answer": "105 feet(0.6005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517975.jpg"}, {"question": "what size is the t shirt worn by the man in the shorts", "gt answer": "medium(1.00)<br/>large(1.00)", "pred answer": "medium", "question_id": 4718635, "best approach": "wiki, concept, image", "verif answer": "medium", "anno approach": "image, wiki", "verif wiki answer": "large(0.6589)", "verif concept answer": "medium(0.6664)", "verif image answer": "medium(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471863.jpg"}, {"question": "what type of phone does he have", "gt answer": "flip(1.00)<br/>motorola(0.60)", "pred answer": "flip phone", "question_id": 989405, "best approach": "", "verif answer": "iphone", "anno approach": "", "verif wiki answer": "iphone(0.7296)", "verif concept answer": "button(0.6460)", "verif image answer": "iphone(0.6713)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098940.jpg"}, {"question": "what brand are the rear view mirrors on the bus", "gt answer": "honda(1.00)<br/>toshiba(0.60)<br/>ford(0.60)", "pred answer": "rayban", "question_id": 2024105, "best approach": "wiki, concept, image", "verif answer": "toshiba", "anno approach": "image, wiki", "verif wiki answer": "ford(0.6466)", "verif concept answer": "ford(0.6419)", "verif image answer": "toshiba(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202410.jpg"}, {"question": "what is the name of this kind of blind", "gt answer": "vertical(1.00)<br/>horizontal(0.60)<br/>metal(0.60)", "pred answer": "blind", "question_id": 2204085, "best approach": "wiki, concept", "verif answer": "vertical", "anno approach": "concept", "verif wiki answer": "vertical(0.5137)", "verif concept answer": "vertical(0.5534)", "verif image answer": "brown(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220408.jpg"}, {"question": "what are the typical activities one might do here", "gt answer": "swim(1.00)<br/>surf(0.60)", "pred answer": "swim", "question_id": 559845, "best approach": "wiki, concept, image", "verif answer": "swim", "anno approach": "wiki", "verif wiki answer": "swim(0.7296)", "verif concept answer": "swim(0.7305)", "verif image answer": "swim(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000055984.jpg"}, {"question": "how fast can this train go", "gt answer": "100 mph(1.00)<br/>30 mph(0.60)", "pred answer": "80 mph", "question_id": 847765, "best approach": "wiki, concept, image", "verif answer": "100 mph", "anno approach": "image, wiki", "verif wiki answer": "100 mph(0.5636)", "verif concept answer": "100 mph(0.5364)", "verif image answer": "100 mph(0.6439)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084776.jpg"}, {"question": "what does this type of train transport", "gt answer": "passenger(1.00)<br/>people(0.60)<br/>freight(0.60)", "pred answer": "people", "question_id": 72325, "best approach": "wiki, concept, image", "verif answer": "people", "anno approach": "wiki", "verif wiki answer": "people(0.7304)", "verif concept answer": "people(0.7134)", "verif image answer": "freight(0.7054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007232.jpg"}, {"question": "the poles in the background are called what", "gt answer": "electric(1.00)", "pred answer": "telephone", "question_id": 1457385, "best approach": "", "verif answer": "power line", "anno approach": "", "verif wiki answer": "power line(0.7310)", "verif concept answer": "power line(0.7310)", "verif image answer": "power line(0.5019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145738.jpg"}, {"question": "what type of bird is this", "gt answer": "hawk(1.00)", "pred answer": "sparrow", "question_id": 1826025, "best approach": "image", "verif answer": "hawk", "anno approach": "image", "verif wiki answer": "finch(0.7305)", "verif concept answer": "falcon(0.7152)", "verif image answer": "hawk(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182602.jpg"}, {"question": "is it raining or just overcast", "gt answer": "overcast(1.00)", "pred answer": "sunny", "question_id": 5536335, "best approach": "", "verif answer": "storm", "anno approach": "", "verif wiki answer": "storm(0.6559)", "verif concept answer": "storm(0.6550)", "verif image answer": "storm(0.5017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553633.jpg"}, {"question": "which of the devices laying on top of the laptop keyboard was manufactured first", "gt answer": "1 on far right(1.00)<br/>right(0.60)", "pred answer": "apple", "question_id": 3201255, "best approach": "", "verif answer": "remote", "anno approach": "", "verif wiki answer": "mouse(0.6549)", "verif concept answer": "remote(0.6587)", "verif image answer": "remote(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320125.jpg"}, {"question": "what common design does this appear to be a part of", "gt answer": "smiley face(1.00)", "pred answer": "floral", "question_id": 794625, "best approach": "wiki, concept, image", "verif answer": "smiley face", "anno approach": "", "verif wiki answer": "smiley face(0.7244)", "verif concept answer": "smiley face(0.7213)", "verif image answer": "smiley face(0.7248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079462.jpg"}, {"question": "which type of transportation vehicles are mostly shown", "gt answer": "boat(1.00)", "pred answer": "boat", "question_id": 1229505, "best approach": "", "verif answer": "yacht", "anno approach": "", "verif wiki answer": "yacht(0.6793)", "verif concept answer": "raft(0.6445)", "verif image answer": "yacht(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122950.jpg"}, {"question": "how many professional teams are there in the us for this sport", "gt answer": "30(1.00)", "pred answer": "5", "question_id": 83295, "best approach": "concept", "verif answer": "30", "anno approach": "concept", "verif wiki answer": "20(0.6669)", "verif concept answer": "30(0.7081)", "verif image answer": "15(0.6816)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008329.jpg"}, {"question": "what type of car is the white vehicle", "gt answer": "mercedes(1.00)<br/>nissan(0.60)<br/>sedan(0.60)", "pred answer": "van", "question_id": 2129415, "best approach": "image", "verif answer": "mercedes benz", "anno approach": "image", "verif wiki answer": "mercedes benz(0.6319)", "verif concept answer": "mercedes benz(0.6304)", "verif image answer": "mercedes(0.5398)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212941.jpg"}, {"question": "what are the smaller animals called", "gt answer": "lamb(1.00)<br/>goat(0.60)<br/>sheep(0.60)<br/>kid(0.60)", "pred answer": "ewe", "question_id": 4398705, "best approach": "concept, image", "verif answer": "kid", "anno approach": "image", "verif wiki answer": "ewe(0.6794)", "verif concept answer": "kid(0.6548)", "verif image answer": "kid(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439870.jpg"}, {"question": "what category of food is being displayed", "gt answer": "fruit(1.00)", "pred answer": "fruit", "question_id": 1548685, "best approach": "wiki, concept, image", "verif answer": "fruit", "anno approach": "image, concept, wiki", "verif wiki answer": "fruit(0.5024)", "verif concept answer": "fruit(0.6216)", "verif image answer": "fruit(0.6517)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154868.jpg"}, {"question": "what is the complimentary color to the necktie", "gt answer": "red(1.00)<br/>white(1.00)<br/>green(0.60)", "pred answer": "red", "question_id": 4662025, "best approach": "wiki, concept, image", "verif answer": "white", "anno approach": "wiki", "verif wiki answer": "red(0.6974)", "verif concept answer": "red(0.7247)", "verif image answer": "white(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466202.jpg"}, {"question": "what is this tool used for", "gt answer": "stay dry(1.00)<br/>keep dry(0.60)", "pred answer": "travel", "question_id": 1226055, "best approach": "image", "verif answer": "protection", "anno approach": "image", "verif wiki answer": "protection(0.5748)", "verif concept answer": "protection(0.5824)", "verif image answer": "stay dry(0.5325)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122605.jpg"}, {"question": "how much does the skateboard in the photo cost", "gt answer": "$50(1.00)<br/>40(0.60)", "pred answer": "200", "question_id": 1962905, "best approach": "", "verif answer": "$18", "anno approach": "", "verif wiki answer": "$18(0.6421)", "verif concept answer": "$18(0.6424)", "verif image answer": "$18(0.6713)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196290.jpg"}, {"question": "what is this type of vessel called specifically", "gt answer": "ship(1.00)", "pred answer": "sail", "question_id": 3881715, "best approach": "", "verif answer": "sail", "anno approach": "", "verif wiki answer": "sail(0.7171)", "verif concept answer": "sail(0.6521)", "verif image answer": "sail(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388171.jpg"}, {"question": "what food are these people endorsing", "gt answer": "hotdogs(1.00)<br/>dessert(0.60)<br/>hot dog(0.60)", "pred answer": "sandwich", "question_id": 3773315, "best approach": "", "verif answer": "sandwich", "anno approach": "", "verif wiki answer": "sandwich(0.6767)", "verif concept answer": "sandwich(0.7226)", "verif image answer": "sandwich(0.6531)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377331.jpg"}, {"question": "what part of the body is the object in the person 's hand worn on", "gt answer": "head(1.00)", "pred answer": "head", "question_id": 4593495, "best approach": "", "verif answer": "wilson", "anno approach": "", "verif wiki answer": "mane(0.6846)", "verif concept answer": "mane(0.6888)", "verif image answer": "wilson(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459349.jpg"}, {"question": "what is the scientific name of the animal present", "gt answer": "feline(1.00)<br/>cat(1.00)", "pred answer": "feline", "question_id": 2128685, "best approach": "wiki, image", "verif answer": "feline", "anno approach": "wiki", "verif wiki answer": "feline(0.6536)", "verif concept answer": "domestic(0.6482)", "verif image answer": "feline(0.6692)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212868.jpg"}, {"question": "what language is this sign written in", "gt answer": "arabic(1.00)", "pred answer": "english", "question_id": 234055, "best approach": "image", "verif answer": "arabic", "anno approach": "image", "verif wiki answer": "english(0.6908)", "verif concept answer": "english(0.7277)", "verif image answer": "arabic(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023405.jpg"}, {"question": "what type of elephant is this", "gt answer": "baby(1.00)<br/>african(0.60)<br/>elephant(0.60)", "pred answer": "african", "question_id": 3531335, "best approach": "wiki, concept, image", "verif answer": "baby", "anno approach": "wiki", "verif wiki answer": "baby(0.7308)", "verif concept answer": "baby(0.7309)", "verif image answer": "baby(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353133.jpg"}, {"question": "what type of birds are swimming", "gt answer": "duck(1.00)<br/>puffin(1.00)", "pred answer": "robin", "question_id": 4965785, "best approach": "wiki", "verif answer": "goose", "anno approach": "wiki", "verif wiki answer": "duck(0.6449)", "verif concept answer": "goose(0.6572)", "verif image answer": "goose(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496578.jpg"}, {"question": "what type of shoes are pictured", "gt answer": "loafer(1.00)<br/>summer(0.60)<br/>dress(0.60)", "pred answer": "sneaker", "question_id": 5310765, "best approach": "wiki, concept", "verif answer": "sneaker", "anno approach": "wiki", "verif wiki answer": "loafer(0.5732)", "verif concept answer": "loafer(0.5710)", "verif image answer": "sneaker(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531076.jpg"}, {"question": "what should the cars be doing at this light", "gt answer": "go(1.00)<br/>slow down(0.60)", "pred answer": "red light", "question_id": 704445, "best approach": "wiki, concept", "verif answer": "stop", "anno approach": "wiki", "verif wiki answer": "slow down(0.7206)", "verif concept answer": "slow down(0.7260)", "verif image answer": "stop(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070444.jpg"}, {"question": "name the laptop model shown in this picture", "gt answer": "dell(1.00)<br/>hp(0.60)", "pred answer": "dell", "question_id": 4808835, "best approach": "image", "verif answer": "acer", "anno approach": "image", "verif wiki answer": "acer(0.6865)", "verif concept answer": "acer(0.6873)", "verif image answer": "dell(0.6479)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480883.jpg"}, {"question": "where did they purchases their uniforms", "gt answer": "store(0.60)<br/>dick sport good(1.00)<br/>mlb(0.60)", "pred answer": "walmart", "question_id": 3859345, "best approach": "", "verif answer": "stadium", "anno approach": "", "verif wiki answer": "stadium(0.6567)", "verif concept answer": "stadium(0.6288)", "verif image answer": "stadium(0.6603)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385934.jpg"}, {"question": "where do people usually use this contraption", "gt answer": "construction site(1.00)<br/>dig(0.60)", "pred answer": "fire", "question_id": 324745, "best approach": "wiki, concept, image", "verif answer": "construction site", "anno approach": "image, wiki", "verif wiki answer": "construction site(0.7085)", "verif concept answer": "construction site(0.6684)", "verif image answer": "construction site(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032474.jpg"}, {"question": "what is this object for", "gt answer": "traffic control(1.00)<br/>traffic(0.60)<br/>control traffic(0.60)", "pred answer": "street name", "question_id": 4575195, "best approach": "wiki, concept", "verif answer": "stop", "anno approach": "wiki", "verif wiki answer": "traffic(0.6805)", "verif concept answer": "traffic(0.6661)", "verif image answer": "stop(0.7009)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457519.jpg"}, {"question": "the man eating likely had parents that both had what color hair", "gt answer": "blonde(1.00)<br/>donut(0.60)", "pred answer": "white", "question_id": 3222125, "best approach": "wiki, concept, image", "verif answer": "blonde", "anno approach": "wiki", "verif wiki answer": "blonde(0.5965)", "verif concept answer": "blonde(0.6142)", "verif image answer": "blonde(0.5853)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322212.jpg"}, {"question": "what manufacturer makes those", "gt answer": "schwinn(1.00)<br/>huffy(0.60)<br/>bird(0.60)", "pred answer": "bike", "question_id": 3380125, "best approach": "wiki, concept, image", "verif answer": "huffy", "anno approach": "image", "verif wiki answer": "huffy(0.5253)", "verif concept answer": "huffy(0.5464)", "verif image answer": "huffy(0.6200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338012.jpg"}, {"question": "what country does the flag represent", "gt answer": "malaysia(1.00)<br/>china(0.60)", "pred answer": "britain", "question_id": 2811775, "best approach": "wiki, concept", "verif answer": "malaysia", "anno approach": "concept, wiki", "verif wiki answer": "malaysia(0.6580)", "verif concept answer": "malaysia(0.6945)", "verif image answer": "japan(0.5960)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281177.jpg"}, {"question": "why does he have glasses on", "gt answer": "to see(1.00)<br/>sunny(0.60)<br/>shade(0.60)", "pred answer": "reflection", "question_id": 3924745, "best approach": "wiki", "verif answer": "sunny", "anno approach": "wiki", "verif wiki answer": "to see(0.5188)", "verif concept answer": "shade(0.5074)", "verif image answer": "sunny(0.6295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392474.jpg"}, {"question": "healthy or unhealthy", "gt answer": "unhealthy(1.00)<br/>healthy(1.00)", "pred answer": "healthy", "question_id": 2331215, "best approach": "wiki, concept, image", "verif answer": "healthy", "anno approach": "wiki", "verif wiki answer": "healthy(0.7311)", "verif concept answer": "healthy(0.7310)", "verif image answer": "healthy(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233121.jpg"}, {"question": "what breed of horse is that", "gt answer": "mustang(1.00)<br/>pinto(0.60)", "pred answer": "mustang", "question_id": 4995365, "best approach": "concept", "verif answer": "palomino", "anno approach": "concept", "verif wiki answer": "horse(0.6491)", "verif concept answer": "mustang(0.6658)", "verif image answer": "palomino(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499536.jpg"}, {"question": "what type of flowers are those on the counter", "gt answer": "lily(1.00)<br/>hydrangea(0.60)<br/>plastic(0.60)<br/>rose(0.60)", "pred answer": "daisy", "question_id": 4756595, "best approach": "wiki", "verif answer": "rose", "anno approach": "wiki", "verif wiki answer": "lily(0.6524)", "verif concept answer": "rose(0.6601)", "verif image answer": "rose(0.6948)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475659.jpg"}, {"question": "what is a staple of the diet of these animals", "gt answer": "fish(1.00)<br/>salmon(0.60)", "pred answer": "vitamin", "question_id": 5209805, "best approach": "", "verif answer": "egg", "anno approach": "", "verif wiki answer": "egg(0.5819)", "verif concept answer": "egg(0.5194)", "verif image answer": "egg(0.7245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520980.jpg"}, {"question": "what brands of this riding instrument are the best", "gt answer": "van(1.00)<br/>skateboard(0.60)<br/>element(0.60)", "pred answer": "skateboard", "question_id": 3803445, "best approach": "wiki, concept, image", "verif answer": "skateboard", "anno approach": "concept, wiki", "verif wiki answer": "skateboard(0.6523)", "verif concept answer": "skateboard(0.6519)", "verif image answer": "skateboard(0.6091)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000380344.jpg"}, {"question": "what does it mean if this were to light up yellow", "gt answer": "slow down(1.00)<br/>yield(0.60)<br/>caution(0.60)", "pred answer": "yield", "question_id": 2844546, "best approach": "image", "verif answer": "caution", "anno approach": "image", "verif wiki answer": "go(0.6358)", "verif concept answer": "caution(0.6996)", "verif image answer": "slow down(0.5224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284454.jpg"}, {"question": "what type of birds are these", "gt answer": "flamingo(1.00)", "pred answer": "pelican", "question_id": 4899425, "best approach": "", "verif answer": "geese", "anno approach": "", "verif wiki answer": "geese(0.6929)", "verif concept answer": "geese(0.7197)", "verif image answer": "geese(0.7157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489942.jpg"}, {"question": "what might you do in a room like this", "gt answer": "eat(1.00)<br/>read(1.00)<br/>relax(0.60)", "pred answer": "watch tv", "question_id": 4627125, "best approach": "concept, image", "verif answer": "eat", "anno approach": "", "verif wiki answer": "relax(0.6469)", "verif concept answer": "read(0.6520)", "verif image answer": "eat(0.6676)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000462712.jpg"}, {"question": "when would a person do this", "gt answer": "night(1.00)<br/>bed(0.60)", "pred answer": "work", "question_id": 1692495, "best approach": "wiki, concept, image", "verif answer": "night", "anno approach": "concept, wiki", "verif wiki answer": "night(0.6791)", "verif concept answer": "night(0.7218)", "verif image answer": "night(0.6507)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169249.jpg"}, {"question": "what gender are the statues", "gt answer": "male(1.00)<br/>men(0.60)", "pred answer": "female", "question_id": 5038835, "best approach": "wiki", "verif answer": "male", "anno approach": "wiki", "verif wiki answer": "male(0.7310)", "verif concept answer": "female(0.7266)", "verif image answer": "female(0.7275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503883.jpg"}, {"question": "what kind of train is this", "gt answer": "commuter(1.00)<br/>transportation(0.60)<br/>passenger(0.60)", "pred answer": "passenger", "question_id": 2188625, "best approach": "concept", "verif answer": "train", "anno approach": "concept", "verif wiki answer": "train(0.6999)", "verif concept answer": "passenger(0.6442)", "verif image answer": "train(0.6799)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218862.jpg"}, {"question": "what does the red and yellow triangular sign mean", "gt answer": "pedestrian cross(1.00)<br/>caution(0.60)<br/>crosswalk(0.60)", "pred answer": "no park", "question_id": 4956415, "best approach": "wiki, concept, image", "verif answer": "pedestrian cross", "anno approach": "wiki", "verif wiki answer": "pedestrian cross(0.7212)", "verif concept answer": "pedestrian cross(0.7109)", "verif image answer": "pedestrian cross(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495641.jpg"}, {"question": "what brand of bat is the batter using", "gt answer": "louisville slugger(1.00)", "pred answer": "wilson", "question_id": 5222335, "best approach": "", "verif answer": "batter", "anno approach": "", "verif wiki answer": "wilson(0.6424)", "verif concept answer": "wilson(0.6371)", "verif image answer": "batter(0.6600)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522233.jpg"}, {"question": "what part of the city would this be located in", "gt answer": "park(1.00)<br/>downtown(1.00)<br/>center(0.60)", "pred answer": "city", "question_id": 3071375, "best approach": "wiki, concept, image", "verif answer": "downtown", "anno approach": "wiki", "verif wiki answer": "downtown(0.7311)", "verif concept answer": "downtown(0.7311)", "verif image answer": "downtown(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307137.jpg"}, {"question": "what green vegetable is that", "gt answer": "pea(1.00)", "pred answer": "pickle", "question_id": 3560685, "best approach": "", "verif answer": "pickle", "anno approach": "", "verif wiki answer": "loafer(0.5097)", "verif concept answer": "loafer(0.7101)", "verif image answer": "pickle(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356068.jpg"}, {"question": "what is usually worn when partaking in this sport", "gt answer": "wetsuit(1.00)<br/>wet suit(0.60)", "pred answer": "wetsuit", "question_id": 244545, "best approach": "concept, image", "verif answer": "wet suit", "anno approach": "", "verif wiki answer": "wet suit(0.6498)", "verif concept answer": "wetsuit(0.6484)", "verif image answer": "wetsuit(0.6483)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024454.jpg"}, {"question": "what brand of computer is on the desk", "gt answer": "dell(1.00)<br/>acer(0.60)", "pred answer": "desktop", "question_id": 4610185, "best approach": "image", "verif answer": "dell", "anno approach": "image", "verif wiki answer": "logitech(0.7093)", "verif concept answer": "logitech(0.7116)", "verif image answer": "dell(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461018.jpg"}, {"question": "can you tell me which type of cloth is used on the floor of this photo", "gt answer": "carpet(1.00)<br/>cotton(0.60)", "pred answer": "wool", "question_id": 2373405, "best approach": "", "verif answer": "plastic", "anno approach": "", "verif wiki answer": "plastic(0.7241)", "verif concept answer": "plastic(0.7204)", "verif image answer": "plastic(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237340.jpg"}, {"question": "what species of bear is this", "gt answer": "black bear(1.00)<br/>brown bear(0.60)<br/>grizzly(0.60)<br/>black(0.60)", "pred answer": "brown", "question_id": 4055275, "best approach": "", "verif answer": "brown", "anno approach": "", "verif wiki answer": "brown(0.7269)", "verif concept answer": "brown(0.7196)", "verif image answer": "brown(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405527.jpg"}, {"question": "is he seeling those fruits or going to eat them", "gt answer": "sell(1.00)<br/>eat(1.00)", "pred answer": "banana", "question_id": 3323115, "best approach": "image", "verif answer": "sell", "anno approach": "image", "verif wiki answer": "drink(0.5001)", "verif concept answer": "drink(0.5002)", "verif image answer": "sell(0.6401)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332311.jpg"}, {"question": "what is the woman attempting to hit", "gt answer": "tennis ball(1.00)<br/>ball(1.00)", "pred answer": "tennis ball", "question_id": 1842185, "best approach": "wiki, concept, image", "verif answer": "tennis ball", "anno approach": "wiki", "verif wiki answer": "tennis ball(0.7311)", "verif concept answer": "tennis ball(0.7310)", "verif image answer": "tennis ball(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184218.jpg"}, {"question": "working together or alone", "gt answer": "together(1.00)<br/>alone(0.60)", "pred answer": "quiet", "question_id": 5740765, "best approach": "wiki, concept, image", "verif answer": "together", "anno approach": "concept, wiki", "verif wiki answer": "together(0.7310)", "verif concept answer": "together(0.7310)", "verif image answer": "together(0.5205)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000574076.jpg"}, {"question": "why is one urinal smaller than the others", "gt answer": "children(1.00)<br/>kid(0.60)", "pred answer": "bleach", "question_id": 444205, "best approach": "wiki, concept", "verif answer": "kid", "anno approach": "wiki", "verif wiki answer": "kid(0.6275)", "verif concept answer": "kid(0.6412)", "verif image answer": "toy(0.6334)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000044420.jpg"}, {"question": "what type of art is covering this truck", "gt answer": "graffiti(1.00)<br/>grafitti(0.60)", "pred answer": "graffiti", "question_id": 4873535, "best approach": "wiki, concept, image", "verif answer": "graffiti", "anno approach": "wiki", "verif wiki answer": "graffiti(0.7233)", "verif concept answer": "graffiti(0.7044)", "verif image answer": "graffiti(0.7225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487353.jpg"}, {"question": "what holiday theme is represented on the donut", "gt answer": "halloween(1.00)", "pred answer": "sprinkle", "question_id": 25705, "best approach": "", "verif answer": "wed", "anno approach": "", "verif wiki answer": "wed(0.7311)", "verif concept answer": "wed(0.7311)", "verif image answer": "wed(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002570.jpg"}, {"question": "which northeast american state has a name that sounds exactly like a part of this animal", "gt answer": "maine(1.00)<br/>massachusetts(0.60)", "pred answer": "texas", "question_id": 2694625, "best approach": "image", "verif answer": "maine", "anno approach": "image", "verif wiki answer": "new york(0.6221)", "verif concept answer": "new york(0.6823)", "verif image answer": "maine(0.7217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269462.jpg"}, {"question": "what was the main food on the larger plate", "gt answer": "pancake(1.00)<br/>danish(0.60)<br/>desert(0.60)", "pred answer": "pizza", "question_id": 3836205, "best approach": "image", "verif answer": "dessert", "anno approach": "image", "verif wiki answer": "dessert(0.6435)", "verif concept answer": "dessert(0.6465)", "verif image answer": "desert(0.6357)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383620.jpg"}, {"question": "what is this move called in tennis", "gt answer": "backhand(1.00)<br/>serve(0.60)", "pred answer": "serve", "question_id": 919485, "best approach": "wiki", "verif answer": "forehand", "anno approach": "wiki", "verif wiki answer": "backhand(0.7309)", "verif concept answer": "forehand(0.7310)", "verif image answer": "underhand(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000091948.jpg"}, {"question": "why style of numbering is seen here", "gt answer": "roman numeral(1.00)<br/>roman(1.00)<br/>numeral(0.60)", "pred answer": "analog", "question_id": 593995, "best approach": "", "verif answer": "hour", "anno approach": "", "verif wiki answer": "hour(0.7304)", "verif concept answer": "hour(0.7096)", "verif image answer": "hour(0.5545)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059399.jpg"}, {"question": "what browser is this laptop using", "gt answer": "chrome(1.00)", "pred answer": "dell", "question_id": 89995, "best approach": "concept", "verif answer": "silver", "anno approach": "concept", "verif wiki answer": "silver(0.7002)", "verif concept answer": "chrome(0.6564)", "verif image answer": "silver(0.6988)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008999.jpg"}, {"question": "what activity does the person in burgundy want to do", "gt answer": "fly kite(1.00)<br/>kite(0.60)", "pred answer": "kite fly", "question_id": 5090495, "best approach": "image", "verif answer": "kite fly", "anno approach": "image", "verif wiki answer": "kite fly(0.7311)", "verif concept answer": "kite fly(0.7311)", "verif image answer": "fly kite(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509049.jpg"}, {"question": "what type of vehicle the officer is in", "gt answer": "segway(1.00)<br/>police(0.60)<br/>scooter(0.60)", "pred answer": "car", "question_id": 2481945, "best approach": "", "verif answer": "car", "anno approach": "", "verif wiki answer": "car(0.7304)", "verif concept answer": "car(0.7248)", "verif image answer": "car(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248194.jpg"}, {"question": "what does the man with the frisbee 's back tattoo represent", "gt answer": "peace(1.00)", "pred answer": "goalie", "question_id": 1660695, "best approach": "wiki, image", "verif answer": "peace", "anno approach": "wiki", "verif wiki answer": "peace(0.6602)", "verif concept answer": "flag(0.6509)", "verif image answer": "peace(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166069.jpg"}, {"question": "do these animals have good memory or poor memory", "gt answer": "good(1.00)<br/>poor(1.00)", "pred answer": "good", "question_id": 4298035, "best approach": "", "verif answer": "high", "anno approach": "", "verif wiki answer": "high(0.5033)", "verif concept answer": "high(0.5090)", "verif image answer": "high(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429803.jpg"}, {"question": "what is the name of this bike gang", "gt answer": "hell angel(1.00)", "pred answer": "motorcycle", "question_id": 1958485, "best approach": "wiki, concept, image", "verif answer": "hell angel", "anno approach": "", "verif wiki answer": "hell angel(0.7311)", "verif concept answer": "hell angel(0.7311)", "verif image answer": "hell angel(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195848.jpg"}, {"question": "what spicy ingredient is in this recipe", "gt answer": "pepper(1.00)", "pred answer": "pepper", "question_id": 3114485, "best approach": "", "verif answer": "tomato", "anno approach": "", "verif wiki answer": "potato(0.5904)", "verif concept answer": "potato(0.6040)", "verif image answer": "tomato(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311448.jpg"}, {"question": "what is the average diameter of the toy shown here", "gt answer": "10 inches(1.00)", "pred answer": "5 feet", "question_id": 5604815, "best approach": "wiki, concept", "verif answer": "10 inches", "anno approach": "concept", "verif wiki answer": "10 inches(0.6214)", "verif concept answer": "10 inches(0.6607)", "verif image answer": "3(0.6321)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560481.jpg"}, {"question": "what style shirt is the man wearing", "gt answer": "t shirt(1.00)<br/>polo(0.60)", "pred answer": "button up", "question_id": 3479815, "best approach": "wiki, concept, image", "verif answer": "t shirt", "anno approach": "wiki", "verif wiki answer": "t shirt(0.7308)", "verif concept answer": "t shirt(0.7310)", "verif image answer": "t shirt(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347981.jpg"}, {"question": "a big shot at using the item depicted here might be called the big what", "gt answer": "kahuna(1.00)<br/>professional(0.60)<br/>cheese(0.60)", "pred answer": "surfboard", "question_id": 672595, "best approach": "", "verif answer": "disorganized", "anno approach": "", "verif wiki answer": "disorganized(0.5031)", "verif concept answer": "disorganized(0.5528)", "verif image answer": "disorganized(0.6556)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067259.jpg"}, {"question": "how many people aboard", "gt answer": "20(1.00)<br/>many(0.60)<br/>fifty(0.60)", "pred answer": "30", "question_id": 5239885, "best approach": "wiki, concept", "verif answer": "10", "anno approach": "wiki", "verif wiki answer": "fifty(0.6426)", "verif concept answer": "many(0.6346)", "verif image answer": "10(0.6449)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523988.jpg"}, {"question": "what is the brand of the faucet", "gt answer": "moen(1.00)<br/>delta(0.60)", "pred answer": "ge", "question_id": 2878545, "best approach": "wiki, concept", "verif answer": "delta", "anno approach": "wiki", "verif wiki answer": "delta(0.7286)", "verif concept answer": "delta(0.7310)", "verif image answer": "boeing(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287854.jpg"}, {"question": "can you tell me the kind of tree shown in this picture", "gt answer": "birch(1.00)<br/>maple(1.00)<br/>oak(0.60)", "pred answer": "oak", "question_id": 3544835, "best approach": "wiki, concept, image", "verif answer": "birch", "anno approach": "wiki", "verif wiki answer": "birch(0.7305)", "verif concept answer": "birch(0.7307)", "verif image answer": "birch(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354483.jpg"}, {"question": "how hot does this appliance become", "gt answer": "350 degrees(1.00)<br/>250(0.60)", "pred answer": "cold", "question_id": 1290065, "best approach": "image", "verif answer": "350 degrees", "anno approach": "image", "verif wiki answer": "350(0.5237)", "verif concept answer": "350(0.5198)", "verif image answer": "350 degrees(0.6686)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129006.jpg"}, {"question": "what kind of flower is this", "gt answer": "lilac(1.00)<br/>daisy(0.60)<br/>brocoli(0.60)", "pred answer": "brocoli", "question_id": 404745, "best approach": "wiki, image", "verif answer": "lilac", "anno approach": "image", "verif wiki answer": "lilac(0.6634)", "verif concept answer": "broccoli(0.6790)", "verif image answer": "lilac(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040474.jpg"}, {"question": "were these shoes popular in the 1980 's or the present", "gt answer": "1980's(1.00)", "pred answer": "tennis", "question_id": 908335, "best approach": "image", "verif answer": "1980's", "anno approach": "image", "verif wiki answer": "1998(0.5000)", "verif concept answer": "1990(0.5000)", "verif image answer": "1980's(0.5015)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090833.jpg"}, {"question": "what fruit is this truck carrying", "gt answer": "banana(1.00)<br/>kitchen(0.60)", "pred answer": "banana", "question_id": 2483245, "best approach": "concept", "verif answer": "kitchen", "anno approach": "concept", "verif wiki answer": "south america(0.6565)", "verif concept answer": "kitchen(0.6604)", "verif image answer": "vegetable(0.6137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248324.jpg"}, {"question": "what are the types of lights shown called", "gt answer": "lamp(1.00)<br/>overhead(0.60)<br/>wall(0.60)", "pred answer": "spot light", "question_id": 3246825, "best approach": "wiki, concept, image", "verif answer": "wall", "anno approach": "wiki", "verif wiki answer": "wall(0.6414)", "verif concept answer": "wall(0.6335)", "verif image answer": "wall(0.6373)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324682.jpg"}, {"question": "where are the potato chips made", "gt answer": "factory(1.00)<br/>idaho(1.00)<br/>mississippi(0.60)", "pred answer": "cafe", "question_id": 1825075, "best approach": "wiki, concept", "verif answer": "idaho", "anno approach": "", "verif wiki answer": "idaho(0.7309)", "verif concept answer": "idaho(0.7168)", "verif image answer": "mississippi(0.6766)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182507.jpg"}, {"question": "what kind of bird is this", "gt answer": "woodpecker(1.00)", "pred answer": "parrot", "question_id": 4298195, "best approach": "wiki, concept", "verif answer": "woodpecker", "anno approach": "wiki", "verif wiki answer": "woodpecker(0.7001)", "verif concept answer": "woodpecker(0.7287)", "verif image answer": "parrot(0.6935)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429819.jpg"}, {"question": "what is the woman in the gray sweatshirt pushing", "gt answer": "stroller(1.00)", "pred answer": "suitcase", "question_id": 5679765, "best approach": "wiki, concept", "verif answer": "stroller", "anno approach": "", "verif wiki answer": "stroller(0.6912)", "verif concept answer": "stroller(0.7175)", "verif image answer": "luggage(0.6046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567976.jpg"}, {"question": "what type of meat is on top of the pizza", "gt answer": "bacon(1.00)<br/>ham(0.60)", "pred answer": "chicken", "question_id": 3120175, "best approach": "wiki", "verif answer": "cheese", "anno approach": "wiki", "verif wiki answer": "ham(0.5129)", "verif concept answer": "cheese(0.5024)", "verif image answer": "cheese(0.5399)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312017.jpg"}, {"question": "what is this dish called", "gt answer": "ramen(1.00)<br/>stir fry(0.60)", "pred answer": "salad", "question_id": 2073315, "best approach": "", "verif answer": "pasta", "anno approach": "", "verif wiki answer": "pasta(0.6547)", "verif concept answer": "pasta(0.6237)", "verif image answer": "pasta(0.6718)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207331.jpg"}, {"question": "what type of food is this", "gt answer": "bread(1.00)<br/>banana bread(0.60)<br/>cake(0.60)<br/>meatloaf(0.60)", "pred answer": "turkey", "question_id": 2550185, "best approach": "wiki, concept, image", "verif answer": "meatloaf", "anno approach": "wiki", "verif wiki answer": "meatloaf(0.7309)", "verif concept answer": "meatloaf(0.7289)", "verif image answer": "meatloaf(0.7189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255018.jpg"}, {"question": "what kind of ramps are these called", "gt answer": "half pipe(1.00)<br/>pipe(0.60)<br/>skateboard(0.60)", "pred answer": "skate park", "question_id": 3593965, "best approach": "wiki, concept, image", "verif answer": "pipe", "anno approach": "image, wiki", "verif wiki answer": "pipe(0.6488)", "verif concept answer": "pipe(0.6436)", "verif image answer": "pipe(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359396.jpg"}, {"question": "what is the pizza topped with", "gt answer": "egg(1.00)", "pred answer": "vegetable", "question_id": 4190525, "best approach": "", "verif answer": "cheese", "anno approach": "", "verif wiki answer": "cheese(0.6259)", "verif concept answer": "cheese(0.5699)", "verif image answer": "cheese(0.6439)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419052.jpg"}, {"question": "what is the name of this meal", "gt answer": "nacho(1.00)<br/>pizza(1.00)<br/>lunch(0.60)", "pred answer": "cheese", "question_id": 3348455, "best approach": "wiki, image", "verif answer": "pizza", "anno approach": "image, wiki", "verif wiki answer": "pizza(0.5492)", "verif concept answer": "lunch(0.5003)", "verif image answer": "pizza(0.6722)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334845.jpg"}, {"question": "what is it called when you consume too much of the fluid contained in these bottles", "gt answer": "intoxication(1.00)<br/>drunk(0.60)", "pred answer": "wine", "question_id": 545415, "best approach": "wiki, concept, image", "verif answer": "drunk", "anno approach": "image", "verif wiki answer": "drunk(0.6847)", "verif concept answer": "drunk(0.6593)", "verif image answer": "drunk(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054541.jpg"}, {"question": "when is this dish normally served", "gt answer": "after meal(1.00)<br/>dessert(0.60)<br/>desert(0.60)", "pred answer": "breakfast", "question_id": 4818895, "best approach": "wiki, concept", "verif answer": "after meal", "anno approach": "", "verif wiki answer": "after meal(0.6926)", "verif concept answer": "after meal(0.7228)", "verif image answer": "cake(0.6569)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481889.jpg"}, {"question": "what type of shoes is the child wearing", "gt answer": "boot(1.00)", "pred answer": "sneaker", "question_id": 3814605, "best approach": "", "verif answer": "leather", "anno approach": "", "verif wiki answer": "leather(0.7169)", "verif concept answer": "leather(0.6517)", "verif image answer": "leather(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381460.jpg"}, {"question": "what is in the mans mouth", "gt answer": "cigarette(1.00)", "pred answer": "toothbrush", "question_id": 3269665, "best approach": "wiki, concept, image", "verif answer": "cigarette", "anno approach": "wiki", "verif wiki answer": "cigarette(0.7309)", "verif concept answer": "cigarette(0.7304)", "verif image answer": "cigarette(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000326966.jpg"}, {"question": "what brand of motorcycle is featured on the right", "gt answer": "suzuki(1.00)<br/>honda(0.60)<br/>kawasaki(0.60)", "pred answer": "harley davidson", "question_id": 3322715, "best approach": "", "verif answer": "triumph", "anno approach": "", "verif wiki answer": "triumph(0.7311)", "verif concept answer": "triumph(0.7270)", "verif image answer": "triumph(0.7161)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332271.jpg"}, {"question": "what might be unsafe in this picture", "gt answer": "wire(1.00)<br/>electrical(0.60)", "pred answer": "computer", "question_id": 995395, "best approach": "image", "verif answer": "power line", "anno approach": "image", "verif wiki answer": "power line(0.6511)", "verif concept answer": "power line(0.5607)", "verif image answer": "wire(0.5804)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099539.jpg"}, {"question": "why does the man have this backpack on", "gt answer": "hike(1.00)<br/>camp(0.60)", "pred answer": "coat", "question_id": 3296615, "best approach": "wiki, concept", "verif answer": "run", "anno approach": "wiki", "verif wiki answer": "hike(0.6640)", "verif concept answer": "hike(0.6757)", "verif image answer": "run(0.6851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329661.jpg"}, {"question": "who is the champion of the world for the sport shown on the image", "gt answer": "kelly slater(1.00)<br/>surfer(0.60)", "pred answer": "kelly slater", "question_id": 2911655, "best approach": "", "verif answer": "duke kahanamoku", "anno approach": "", "verif wiki answer": "duke kahanamoku(0.7311)", "verif concept answer": "duke kahanamoku(0.7310)", "verif image answer": "duke kahanamoku(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291165.jpg"}, {"question": "what is usually found in these green bottles made with", "gt answer": "grape(1.00)<br/>wine(1.00)", "pred answer": "wine", "question_id": 4871185, "best approach": "wiki, concept, image", "verif answer": "wine", "anno approach": "concept, wiki", "verif wiki answer": "wine(0.7234)", "verif concept answer": "wine(0.7235)", "verif image answer": "wine(0.6807)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487118.jpg"}, {"question": "are the motorcycles shown being used professionally or just for fun", "gt answer": "professionally(1.00)<br/>fun(0.60)<br/>professional(0.60)", "pred answer": "competition", "question_id": 4108985, "best approach": "wiki, concept, image", "verif answer": "professionally", "anno approach": "image, wiki", "verif wiki answer": "professionally(0.5016)", "verif concept answer": "professionally(0.5002)", "verif image answer": "professionally(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000410898.jpg"}, {"question": "what is the white remote used for", "gt answer": "game(1.00)<br/>tv(0.60)<br/>video game(0.60)<br/>wii(0.60)", "pred answer": "play game", "question_id": 4223435, "best approach": "image", "verif answer": "wii", "anno approach": "image", "verif wiki answer": "wii(0.6264)", "verif concept answer": "wii(0.6352)", "verif image answer": "game(0.5766)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422343.jpg"}, {"question": "what country does this player hail from", "gt answer": "puerto rico(1.00)<br/>mexico(0.60)<br/>cuba(0.60)<br/>united state(0.60)", "pred answer": "brazil", "question_id": 3434035, "best approach": "concept, image", "verif answer": "cuba", "anno approach": "concept", "verif wiki answer": "spain(0.6609)", "verif concept answer": "cuba(0.6864)", "verif image answer": "united state(0.6196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343403.jpg"}, {"question": "why is this unusual for an animal", "gt answer": "animal don't watch tv(1.00)", "pred answer": "cat", "question_id": 5602425, "best approach": "", "verif answer": "grey", "anno approach": "", "verif wiki answer": "grey(0.5454)", "verif concept answer": "grey(0.6329)", "verif image answer": "car(0.5239)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560242.jpg"}, {"question": "what kind of playground this is", "gt answer": "bat cage(1.00)<br/>pitch(0.60)<br/>yard(0.60)", "pred answer": "skate park", "question_id": 915815, "best approach": "wiki, concept", "verif answer": "baseball", "anno approach": "wiki", "verif wiki answer": "yard(0.5608)", "verif concept answer": "yard(0.5238)", "verif image answer": "baseball(0.6047)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000091581.jpg"}, {"question": "what is the name for this style of cycle", "gt answer": "bicycle(1.00)", "pred answer": "10 speed", "question_id": 4032225, "best approach": "", "verif answer": "mountain bike", "anno approach": "", "verif wiki answer": "mountain bike(0.6544)", "verif concept answer": "mountain bike(0.6489)", "verif image answer": "mountain bike(0.6222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403222.jpg"}, {"question": "is this animal an herbivore carnivore or omnivore", "gt answer": "herbivore(1.00)", "pred answer": "herbivore", "question_id": 384905, "best approach": "wiki, concept, image", "verif answer": "herbivore", "anno approach": "wiki", "verif wiki answer": "herbivore(0.7311)", "verif concept answer": "herbivore(0.7311)", "verif image answer": "herbivore(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038490.jpg"}, {"question": "", "gt answer": "vacation(0.60)<br/>tour bus(0.60)<br/>double decker(0.60)", "pred answer": "tour", "question_id": 1127035, "best approach": "wiki, concept, image", "verif answer": "double decker", "anno approach": "", "verif wiki answer": "double decker(0.6487)", "verif concept answer": "double decker(0.6552)", "verif image answer": "double decker(0.6427)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000112703.jpg"}, {"question": "is this a recreational or work activity", "gt answer": "recreational(1.00)<br/>surf(0.60)", "pred answer": "hobby", "question_id": 3791055, "best approach": "wiki, concept", "verif answer": "recreational", "anno approach": "concept, wiki", "verif wiki answer": "recreational(0.5011)", "verif concept answer": "recreational(0.5272)", "verif image answer": "commercial(0.5006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379105.jpg"}, {"question": "what kind off bag is it", "gt answer": "purse(1.00)", "pred answer": "backpack", "question_id": 3159945, "best approach": "", "verif answer": "desk", "anno approach": "", "verif wiki answer": "desk(0.6599)", "verif concept answer": "desk(0.6544)", "verif image answer": "desk(0.6663)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315994.jpg"}, {"question": "what kind of television is this", "gt answer": "flat screen(1.00)<br/>flatscreen(1.00)", "pred answer": "flat screen", "question_id": 3957585, "best approach": "wiki, concept, image", "verif answer": "flat screen", "anno approach": "image, wiki", "verif wiki answer": "flat screen(0.7238)", "verif concept answer": "flat screen(0.6620)", "verif image answer": "flat screen(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395758.jpg"}, {"question": "why does she need an umbrella", "gt answer": "it rain(1.00)<br/>rain(0.60)<br/>sunny(0.60)", "pred answer": "rain", "question_id": 614005, "best approach": "", "verif answer": "shade", "anno approach": "", "verif wiki answer": "shade(0.6595)", "verif concept answer": "shade(0.7251)", "verif image answer": "snow(0.6679)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061400.jpg"}, {"question": "which sports game are they playing", "gt answer": "disc golf(1.00)<br/>horseshoe(0.60)", "pred answer": "disc golf", "question_id": 3917485, "best approach": "wiki, concept, image", "verif answer": "disc golf", "anno approach": "wiki", "verif wiki answer": "disc golf(0.7297)", "verif concept answer": "disc golf(0.6969)", "verif image answer": "disc golf(0.7131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391748.jpg"}, {"question": "what iconic badass women trio recreated this in a movie", "gt answer": "blue crush(1.00)", "pred answer": "bethany hamilton", "question_id": 1649515, "best approach": "wiki, concept, image", "verif answer": "blue crush", "anno approach": "", "verif wiki answer": "blue crush(0.7307)", "verif concept answer": "blue crush(0.7311)", "verif image answer": "blue crush(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000164951.jpg"}, {"question": "who is the largest manufacturer of this piece of sports equipment", "gt answer": "wham o(1.00)<br/>rawlings(0.60)<br/>frisbee(0.60)<br/>wilson(0.60)", "pred answer": "frisbee", "question_id": 4600975, "best approach": "image", "verif answer": "hasbro", "anno approach": "image", "verif wiki answer": "hasbro(0.6608)", "verif concept answer": "hasbro(0.6802)", "verif image answer": "wilson(0.6348)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460097.jpg"}, {"question": "which city in europe has the most of these", "gt answer": "copenhagen(1.00)<br/>france(0.60)<br/>venice(0.60)<br/>paris(0.60)", "pred answer": "new york", "question_id": 5206795, "best approach": "wiki, concept, image", "verif answer": "paris", "anno approach": "wiki", "verif wiki answer": "paris(0.6965)", "verif concept answer": "paris(0.7151)", "verif image answer": "paris(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520679.jpg"}, {"question": "what ethnicty is the man", "gt answer": "indian(1.00)<br/>asian(0.60)<br/>black(0.60)<br/>spanish(0.60)", "pred answer": "white", "question_id": 5414915, "best approach": "wiki, concept, image", "verif answer": "black", "anno approach": "image, wiki", "verif wiki answer": "asian(0.6114)", "verif concept answer": "asian(0.6308)", "verif image answer": "black(0.6688)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541491.jpg"}, {"question": "what can i put here", "gt answer": "pizza(1.00)<br/>food(0.60)<br/>stove(0.60)", "pred answer": "dish", "question_id": 1858665, "best approach": "wiki", "verif answer": "cake", "anno approach": "wiki", "verif wiki answer": "pizza(0.6791)", "verif concept answer": "food(0.6524)", "verif image answer": "cake(0.6883)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185866.jpg"}, {"question": "what kind of trees are in this picture", "gt answer": "maple(1.00)<br/>oak(1.00)<br/>aspen(0.60)", "pred answer": "elm", "question_id": 1718065, "best approach": "wiki, concept, image", "verif answer": "oak", "anno approach": "wiki", "verif wiki answer": "oak(0.7305)", "verif concept answer": "oak(0.7310)", "verif image answer": "oak(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171806.jpg"}, {"question": "what do these animals eat", "gt answer": "dog food(1.00)<br/>kibble(0.60)<br/>meat(0.60)", "pred answer": "dog food", "question_id": 5328575, "best approach": "wiki, concept, image", "verif answer": "dog food", "anno approach": "image, wiki", "verif wiki answer": "dog food(0.6554)", "verif concept answer": "dog food(0.6460)", "verif image answer": "dog food(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532857.jpg"}, {"question": "these sea faring vehicles are often christened by bottles of what vintage", "gt answer": "champagne(1.00)<br/>wine(0.60)", "pred answer": "boat", "question_id": 2984685, "best approach": "concept, image", "verif answer": "champagne", "anno approach": "concept", "verif wiki answer": "beer(0.6790)", "verif concept answer": "champagne(0.7041)", "verif image answer": "champagne(0.6666)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000298468.jpg"}, {"question": "what body of water is this", "gt answer": "atlantic(1.00)<br/>ocean(1.00)<br/>pacific ocean(0.60)", "pred answer": "lake", "question_id": 3202175, "best approach": "", "verif answer": "pacific", "anno approach": "", "verif wiki answer": "pacific(0.7307)", "verif concept answer": "pacific(0.7310)", "verif image answer": "pacific(0.7010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320217.jpg"}, {"question": "", "gt answer": "braid(0.60)", "pred answer": "bridle", "question_id": 1088025, "best approach": "", "verif answer": "pony tail", "anno approach": "", "verif wiki answer": "pony tail(0.6423)", "verif concept answer": "pony tail(0.6564)", "verif image answer": "pony tail(0.5774)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108802.jpg"}, {"question": "what is the main vitamin is broccoli", "gt answer": "c(1.00)<br/>vitamin c(0.60)<br/>potassium(0.60)", "pred answer": "vitamin", "question_id": 5694365, "best approach": "wiki, concept", "verif answer": "vitamin c", "anno approach": "concept, wiki", "verif wiki answer": "vitamin c(0.6869)", "verif concept answer": "vitamin c(0.7302)", "verif image answer": "d(0.6980)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569436.jpg"}, {"question": "what is the light saying", "gt answer": "go(1.00)", "pred answer": "go", "question_id": 2426635, "best approach": "", "verif answer": "slow down", "anno approach": "", "verif wiki answer": "slow down(0.7286)", "verif concept answer": "slow down(0.7271)", "verif image answer": "slow down(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000242663.jpg"}, {"question": "is this a gift you can send or is it too fragile", "gt answer": "fragile(1.00)", "pred answer": "annual", "question_id": 1859545, "best approach": "", "verif answer": "annual", "anno approach": "", "verif wiki answer": "annual(0.7167)", "verif concept answer": "annual(0.7256)", "verif image answer": "annual(0.6680)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185954.jpg"}, {"question": "what is the metal structure everyone is sitting behind called", "gt answer": "fence(1.00)", "pred answer": "bleacher", "question_id": 483405, "best approach": "", "verif answer": "gate", "anno approach": "", "verif wiki answer": "stair(0.6311)", "verif concept answer": "stair(0.6241)", "verif image answer": "gate(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048340.jpg"}, {"question": "which game is played using these animals", "gt answer": "race(1.00)<br/>polo(0.60)", "pred answer": "horse race", "question_id": 1246095, "best approach": "", "verif answer": "horse race", "anno approach": "", "verif wiki answer": "horse race(0.6960)", "verif concept answer": "ride(0.6683)", "verif image answer": "horse race(0.7149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000124609.jpg"}, {"question": "where could i find this", "gt answer": "jungle(1.00)<br/>south america(0.60)<br/>brazil(0.60)", "pred answer": "forest", "question_id": 339405, "best approach": "image", "verif answer": "south america", "anno approach": "image", "verif wiki answer": "garden(0.7309)", "verif concept answer": "garden(0.7307)", "verif image answer": "south america(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033940.jpg"}, {"question": "which food group is this age group constantly being encouraged to eat from", "gt answer": "vegetable(1.00)", "pred answer": "birthday party", "question_id": 517355, "best approach": "", "verif answer": "veggies", "anno approach": "", "verif wiki answer": "veggies(0.5740)", "verif concept answer": "veggies(0.5859)", "verif image answer": "veggies(0.5736)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000051735.jpg"}, {"question": "what is the large white ceramic oval in the picture used for", "gt answer": "bath(1.00)", "pred answer": "bath", "question_id": 1466115, "best approach": "concept, image", "verif answer": "bath", "anno approach": "", "verif wiki answer": "sit(0.6506)", "verif concept answer": "bath(0.7154)", "verif image answer": "bath(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146611.jpg"}, {"question": "what language is pictured on the right vases", "gt answer": "chinese(1.00)<br/>arabic(1.00)", "pred answer": "english", "question_id": 605265, "best approach": "wiki, concept", "verif answer": "hindu", "anno approach": "wiki", "verif wiki answer": "arabic(0.6563)", "verif concept answer": "arabic(0.6484)", "verif image answer": "hindu(0.7002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060526.jpg"}, {"question": "what is the name of the eye condition this cat has", "gt answer": "heterochromia(1.00)", "pred answer": "not at all", "question_id": 5802345, "best approach": "wiki, image", "verif answer": "heterochromia", "anno approach": "", "verif wiki answer": "heterochromia(0.5041)", "verif concept answer": "lick(0.5023)", "verif image answer": "heterochromia(0.5014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580234.jpg"}, {"question": "what platform is this sport being played on", "gt answer": "street(1.00)<br/>road(0.60)<br/>pavement(0.60)", "pred answer": "coin", "question_id": 4755765, "best approach": "wiki, concept", "verif answer": "pavement", "anno approach": "concept", "verif wiki answer": "pavement(0.5056)", "verif concept answer": "pavement(0.5574)", "verif image answer": "street sign(0.5016)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475576.jpg"}, {"question": "what vegetable are those burger toppings made from", "gt answer": "cucumber(1.00)<br/>pickle(0.60)", "pred answer": "pickle", "question_id": 4754255, "best approach": "wiki, concept", "verif answer": "pickle", "anno approach": "wiki", "verif wiki answer": "pickle(0.7299)", "verif concept answer": "pickle(0.7066)", "verif image answer": "lime(0.6824)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475425.jpg"}, {"question": "who invented this device", "gt answer": "frederick graff sr(1.00)<br/>frederick graff(0.60)<br/>fireman(0.60)", "pred answer": "citikitty", "question_id": 4436935, "best approach": "wiki, concept, image", "verif answer": "frederick graff", "anno approach": "wiki", "verif wiki answer": "frederick graff(0.7311)", "verif concept answer": "frederick graff(0.7310)", "verif image answer": "frederick graff(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443693.jpg"}, {"question": "", "gt answer": "vandalism(0.60)<br/>graffiti(0.60)", "pred answer": "stop", "question_id": 42455, "best approach": "", "verif answer": "caution", "anno approach": "", "verif wiki answer": "caution(0.5056)", "verif concept answer": "caution(0.5233)", "verif image answer": "caution(0.5073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004245.jpg"}, {"question": "what is the name of clothing round the man 's neck", "gt answer": "tie(1.00)<br/>collar(0.60)", "pred answer": "tie", "question_id": 2964555, "best approach": "wiki, concept, image", "verif answer": "tie", "anno approach": "image, concept, wiki", "verif wiki answer": "tie(0.6303)", "verif concept answer": "tie(0.7253)", "verif image answer": "tie(0.6642)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296455.jpg"}, {"question": "where is the monument located", "gt answer": "washington dc(1.00)<br/>dc(0.60)", "pred answer": "in sky", "question_id": 5349655, "best approach": "concept", "verif answer": "white house", "anno approach": "concept", "verif wiki answer": "white house(0.7280)", "verif concept answer": "washington dc(0.6436)", "verif image answer": "washington(0.6416)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534965.jpg"}, {"question": "what is the wooden object with the words written on it", "gt answer": "sign(1.00)<br/>plaque(0.60)<br/>desk(0.60)<br/>crib(0.60)", "pred answer": "picture", "question_id": 5164635, "best approach": "wiki, concept, image", "verif answer": "desk", "anno approach": "concept, wiki", "verif wiki answer": "desk(0.7310)", "verif concept answer": "desk(0.7309)", "verif image answer": "desk(0.6026)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516463.jpg"}, {"question": "what would be a good call for this play in baseball", "gt answer": "strike(1.00)<br/>play(0.60)<br/>safe(0.60)", "pred answer": "baseball", "question_id": 5660885, "best approach": "wiki, concept, image", "verif answer": "safe", "anno approach": "image, wiki", "verif wiki answer": "safe(0.6355)", "verif concept answer": "safe(0.6313)", "verif image answer": "safe(0.6772)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566088.jpg"}, {"question": "is this an example of work or distraction", "gt answer": "distraction(1.00)", "pred answer": "illegal", "question_id": 5487235, "best approach": "", "verif answer": "danger", "anno approach": "", "verif wiki answer": "danger(0.5012)", "verif concept answer": "danger(0.5003)", "verif image answer": "danger(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548723.jpg"}, {"question": "penalty for what", "gt answer": "honk(1.00)<br/>noise(0.60)", "pred answer": "ticket", "question_id": 3226705, "best approach": "image", "verif answer": "sleep", "anno approach": "image", "verif wiki answer": "sleep(0.6058)", "verif concept answer": "sleep(0.5193)", "verif image answer": "noise(0.5503)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322670.jpg"}, {"question": "what is used to eat the food in the bowl", "gt answer": "spoon(1.00)", "pred answer": "chop stick", "question_id": 4475745, "best approach": "wiki", "verif answer": "spoon", "anno approach": "wiki", "verif wiki answer": "spoon(0.7310)", "verif concept answer": "fork(0.7144)", "verif image answer": "fork(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447574.jpg"}, {"question": "the child is in what kind of park", "gt answer": "skate(1.00)<br/>skate park(0.60)", "pred answer": "skate park", "question_id": 1600375, "best approach": "concept, image", "verif answer": "skate", "anno approach": "concept", "verif wiki answer": "skateboard(0.6199)", "verif concept answer": "skate(0.7213)", "verif image answer": "skate(0.6488)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160037.jpg"}, {"question": "what kind of dessert is this", "gt answer": "pud(1.00)<br/>banana(0.60)", "pred answer": "pie", "question_id": 2224445, "best approach": "", "verif answer": "stew", "anno approach": "", "verif wiki answer": "stew(0.7311)", "verif concept answer": "stew(0.7311)", "verif image answer": "stew(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222444.jpg"}, {"question": "what meat is being served", "gt answer": "roast beef(1.00)<br/>beef(0.60)", "pred answer": "beef", "question_id": 749425, "best approach": "image", "verif answer": "corned beef", "anno approach": "image", "verif wiki answer": "corned beef(0.7268)", "verif concept answer": "corned beef(0.6813)", "verif image answer": "beef(0.6538)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074942.jpg"}, {"question": "what is the name of show in which these antique vehicles are participating", "gt answer": "car show(1.00)<br/>rv(0.60)", "pred answer": "friend", "question_id": 5715415, "best approach": "image", "verif answer": "race", "anno approach": "image", "verif wiki answer": "race(0.6566)", "verif concept answer": "race(0.7063)", "verif image answer": "rv(0.6269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571541.jpg"}, {"question": "what species of animal is this", "gt answer": "egret(1.00)<br/>pelican(0.60)<br/>bird(0.60)", "pred answer": "duck", "question_id": 4178235, "best approach": "image", "verif answer": "heron", "anno approach": "image", "verif wiki answer": "heron(0.6320)", "verif concept answer": "pelican(0.5206)", "verif image answer": "egret(0.5130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417823.jpg"}, {"question": "which hairstyle is this women doing", "gt answer": "blowout(1.00)<br/>bang(0.60)<br/>messy(0.60)", "pred answer": "ponytail", "question_id": 2080005, "best approach": "wiki, concept, image", "verif answer": "blowout", "anno approach": "image", "verif wiki answer": "blowout(0.5017)", "verif concept answer": "blowout(0.5003)", "verif image answer": "blowout(0.7007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208000.jpg"}, {"question": "art or vandalism", "gt answer": "vandalism(1.00)", "pred answer": "paint", "question_id": 663515, "best approach": "", "verif answer": "graffiti", "anno approach": "", "verif wiki answer": "graffiti(0.7309)", "verif concept answer": "graffiti(0.7299)", "verif image answer": "graffiti(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000066351.jpg"}, {"question": "which would be the best place to do this activity", "gt answer": "park(1.00)", "pred answer": "park", "question_id": 2831385, "best approach": "", "verif answer": "field", "anno approach": "", "verif wiki answer": "forest(0.6468)", "verif concept answer": "field(0.6482)", "verif image answer": "field(0.6485)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283138.jpg"}, {"question": "what is the building these children are gathered in called", "gt answer": "school(1.00)", "pred answer": "school", "question_id": 5635845, "best approach": "", "verif answer": "restaurant", "anno approach": "", "verif wiki answer": "cafeteria(0.7197)", "verif concept answer": "restaurant(0.7074)", "verif image answer": "restaurant(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000563584.jpg"}, {"question": "what is the full name of this store", "gt answer": "super fish(1.00)", "pred answer": "7 eleven", "question_id": 2730885, "best approach": "", "verif answer": "heinz", "anno approach": "", "verif wiki answer": "heinz(0.6133)", "verif concept answer": "heinz(0.5936)", "verif image answer": "heinz(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273088.jpg"}, {"question": "where could you sit", "gt answer": "chair(1.00)", "pred answer": "bench", "question_id": 3190575, "best approach": "", "verif answer": "sofa", "anno approach": "", "verif wiki answer": "sofa(0.7310)", "verif concept answer": "luggage(0.7309)", "verif image answer": "sofa(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319057.jpg"}, {"question": "what is the name of those flowers", "gt answer": "carnation(1.00)<br/>rose(0.60)", "pred answer": "rose", "question_id": 2897665, "best approach": "image", "verif answer": "daisy", "anno approach": "image", "verif wiki answer": "daisy(0.6465)", "verif concept answer": "daisy(0.6525)", "verif image answer": "rose(0.6404)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000289766.jpg"}, {"question": "what grocery store is this", "gt answer": "whole food(1.00)<br/>walmart(0.60)", "pred answer": "grocery", "question_id": 3228475, "best approach": "wiki, image", "verif answer": "whole food", "anno approach": "wiki", "verif wiki answer": "whole food(0.6489)", "verif concept answer": "store(0.6583)", "verif image answer": "whole food(0.6598)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322847.jpg"}, {"question": "what is this road most likely used for", "gt answer": "bike(1.00)<br/>walk(0.60)<br/>cycling(0.60)", "pred answer": "transportation", "question_id": 2474935, "best approach": "concept", "verif answer": "bicycle", "anno approach": "concept", "verif wiki answer": "bicycle(0.6664)", "verif concept answer": "bike(0.6498)", "verif image answer": "bicycle(0.6460)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247493.jpg"}, {"question": "what kind of soup is this", "gt answer": "vegetable(1.00)", "pred answer": "fish", "question_id": 2445285, "best approach": "", "verif answer": "fruit", "anno approach": "", "verif wiki answer": "fruit(0.5002)", "verif concept answer": "fruit(0.5003)", "verif image answer": "fruit(0.5267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244528.jpg"}, {"question": "what activity are they doing", "gt answer": "video game(1.00)<br/>wii bowl(0.60)", "pred answer": "video game", "question_id": 1134365, "best approach": "concept", "verif answer": "video game", "anno approach": "concept", "verif wiki answer": "wii bowl(0.7177)", "verif concept answer": "video game(0.7303)", "verif image answer": "wii bowl(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113436.jpg"}, {"question": "is this meal healthy or unhealthy", "gt answer": "unhealthy(1.00)", "pred answer": "healthy", "question_id": 4539075, "best approach": "", "verif answer": "healthy", "anno approach": "", "verif wiki answer": "healthy(0.7311)", "verif concept answer": "healthy(0.7311)", "verif image answer": "healthy(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453907.jpg"}, {"question": "why are all these planes in a line", "gt answer": "airshow(1.00)", "pred answer": "parked", "question_id": 720305, "best approach": "", "verif answer": "military", "anno approach": "", "verif wiki answer": "military(0.7311)", "verif concept answer": "military(0.7311)", "verif image answer": "military(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072030.jpg"}, {"question": "how much will this animal weigh when fully grown", "gt answer": "50 lbs(1.00)", "pred answer": "10 pounds", "question_id": 2231145, "best approach": "", "verif answer": "$350", "anno approach": "", "verif wiki answer": "intoxication(0.6766)", "verif concept answer": "intoxication(0.6771)", "verif image answer": "$350(0.6937)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223114.jpg"}, {"question": "to whom is the tennis player depicted in the photo married to", "gt answer": "alexis ohanian(1.00)<br/>bieber(0.60)", "pred answer": "serena williams", "question_id": 1885185, "best approach": "wiki", "verif answer": "bieber", "anno approach": "wiki", "verif wiki answer": "alexis ohanian(0.6561)", "verif concept answer": "bieber(0.7253)", "verif image answer": "bieber(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188518.jpg"}, {"question": "what is a common condition that affects a person after they eat too much of this", "gt answer": "indigestion(1.00)", "pred answer": "potato", "question_id": 345235, "best approach": "wiki, concept, image", "verif answer": "indigestion", "anno approach": "", "verif wiki answer": "indigestion(0.6323)", "verif concept answer": "indigestion(0.6064)", "verif image answer": "indigestion(0.6265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000034523.jpg"}, {"question": "what kind of bears are these", "gt answer": "grizzly(1.00)", "pred answer": "brown", "question_id": 1836115, "best approach": "", "verif answer": "brown", "anno approach": "", "verif wiki answer": "brown(0.7306)", "verif concept answer": "brown(0.7310)", "verif image answer": "brown(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183611.jpg"}, {"question": "what item handle does the an appear to have resting next to him", "gt answer": "luggage(1.00)<br/>crutch(1.00)<br/>suitcase(0.60)", "pred answer": "book", "question_id": 899025, "best approach": "wiki, concept, image", "verif answer": "crutch", "anno approach": "wiki", "verif wiki answer": "crutch(0.7311)", "verif concept answer": "crutch(0.7311)", "verif image answer": "crutch(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089902.jpg"}, {"question": "what type of dog is that surfing", "gt answer": "poodle(1.00)", "pred answer": "labrador", "question_id": 3721365, "best approach": "", "verif answer": "teddy bear", "anno approach": "", "verif wiki answer": "teddy bear(0.6534)", "verif concept answer": "teddy bear(0.6662)", "verif image answer": "teddy bear(0.6618)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372136.jpg"}, {"question": "what denomination is the church", "gt answer": "christian(1.00)<br/>catholic(1.00)", "pred answer": "cabin", "question_id": 3933965, "best approach": "", "verif answer": "church", "anno approach": "", "verif wiki answer": "church(0.5001)", "verif concept answer": "church(0.5004)", "verif image answer": "church(0.6195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393396.jpg"}, {"question": "what object does not belong in this room", "gt answer": "chair(1.00)", "pred answer": "toilet", "question_id": 3158955, "best approach": "wiki, concept", "verif answer": "chair", "anno approach": "wiki", "verif wiki answer": "chair(0.6766)", "verif concept answer": "chair(0.7025)", "verif image answer": "bench(0.5128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315895.jpg"}, {"question": "what is the diameter of the toy in this picture", "gt answer": "12 inches(1.00)<br/>8 inches(0.60)<br/>6(0.60)", "pred answer": "42 inches", "question_id": 4653605, "best approach": "image", "verif answer": "6 inches", "anno approach": "image", "verif wiki answer": "6 inches(0.7186)", "verif concept answer": "6 inches(0.6778)", "verif image answer": "8 inches(0.6823)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465360.jpg"}, {"question": "what city is wmata in", "gt answer": "washington(1.00)<br/>washington dc(0.60)", "pred answer": "philadelphia", "question_id": 2621915, "best approach": "", "verif answer": "rome", "anno approach": "", "verif wiki answer": "rome(0.6452)", "verif concept answer": "rome(0.7247)", "verif image answer": "rome(0.5489)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262191.jpg"}, {"question": "why is one animal smaller", "gt answer": "baby(1.00)<br/>child(0.60)", "pred answer": "calf", "question_id": 4997385, "best approach": "", "verif answer": "early", "anno approach": "", "verif wiki answer": "early(0.6322)", "verif concept answer": "early(0.6312)", "verif image answer": "early(0.5819)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499738.jpg"}, {"question": "what brand is this snowboard", "gt answer": "nitro(1.00)", "pred answer": "burton", "question_id": 2086215, "best approach": "", "verif answer": "dell", "anno approach": "", "verif wiki answer": "dell(0.7278)", "verif concept answer": "burton(0.7293)", "verif image answer": "dell(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208621.jpg"}, {"question": "what holiday do those candles represent", "gt answer": "hanukkah(1.00)<br/>christmas(0.60)", "pred answer": "christmas", "question_id": 2550455, "best approach": "wiki, concept, image", "verif answer": "hanukkah", "anno approach": "wiki", "verif wiki answer": "hanukkah(0.7235)", "verif concept answer": "hanukkah(0.7298)", "verif image answer": "hanukkah(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255045.jpg"}, {"question": "for what events where these trophies given", "gt answer": "golf(1.00)<br/>sport(0.60)", "pred answer": "birthday party", "question_id": 3259035, "best approach": "", "verif answer": "wii", "anno approach": "", "verif wiki answer": "wii(0.5921)", "verif concept answer": "wii(0.6690)", "verif image answer": "long distance(0.5498)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325903.jpg"}, {"question": "what is the woman using to cut the cake", "gt answer": "sword(1.00)", "pred answer": "spoon", "question_id": 4886825, "best approach": "", "verif answer": "dice", "anno approach": "", "verif wiki answer": "clip(0.5010)", "verif concept answer": "clip(0.5003)", "verif image answer": "dice(0.5034)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488682.jpg"}, {"question": "what type of beverage are lemons popular igredient in", "gt answer": "lemonade(1.00)", "pred answer": "beer", "question_id": 4121945, "best approach": "wiki, concept, image", "verif answer": "lemonade", "anno approach": "concept, wiki", "verif wiki answer": "lemonade(0.6937)", "verif concept answer": "lemonade(0.7079)", "verif image answer": "lemonade(0.6381)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412194.jpg"}, {"question": "what type of place is this", "gt answer": "train depot(1.00)<br/>train station(1.00)", "pred answer": "train station", "question_id": 648905, "best approach": "wiki", "verif answer": "spring", "anno approach": "wiki", "verif wiki answer": "train station(0.7253)", "verif concept answer": "spring(0.7302)", "verif image answer": "spring(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064890.jpg"}, {"question": "why does the person wear a helmet for", "gt answer": "protection(1.00)<br/>safety(0.60)<br/>danger(0.60)", "pred answer": "helmet", "question_id": 313585, "best approach": "concept", "verif answer": "danger", "anno approach": "concept", "verif wiki answer": "balance(0.6447)", "verif concept answer": "danger(0.6963)", "verif image answer": "balance(0.6262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000031358.jpg"}, {"question": "what type of serve is being performed", "gt answer": "backhand(1.00)<br/>underhand(0.60)<br/>overhand(0.60)", "pred answer": "serve", "question_id": 2562365, "best approach": "wiki, concept", "verif answer": "serve", "anno approach": "wiki", "verif wiki answer": "overhand(0.6188)", "verif concept answer": "overhand(0.6430)", "verif image answer": "serve(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256236.jpg"}, {"question": "how long does this type of animal live when it 's real", "gt answer": "20 years(1.00)<br/>12 years(0.60)", "pred answer": "10 years", "question_id": 462555, "best approach": "wiki", "verif answer": "12 years", "anno approach": "wiki", "verif wiki answer": "12 years(0.7020)", "verif concept answer": "15 years(0.6126)", "verif image answer": "15 years(0.6799)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046255.jpg"}, {"question": "how is this dish cooked", "gt answer": "toasted(1.00)<br/>fried(0.60)", "pred answer": "fried", "question_id": 4454115, "best approach": "wiki", "verif answer": "toasted", "anno approach": "wiki", "verif wiki answer": "toasted(0.6616)", "verif concept answer": "bread(0.6508)", "verif image answer": "bread(0.6464)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445411.jpg"}, {"question": "what is the yellow stuff on top of this hotdog", "gt answer": "mustard(1.00)<br/>cheese(0.60)", "pred answer": "mustard", "question_id": 4480695, "best approach": "concept", "verif answer": "cheese", "anno approach": "concept", "verif wiki answer": "rice(0.5207)", "verif concept answer": "cheese(0.5365)", "verif image answer": "rice(0.5124)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448069.jpg"}, {"question": "what are these people working on", "gt answer": "laptop(1.00)<br/>work(0.60)<br/>homework(0.60)", "pred answer": "laptop", "question_id": 2595145, "best approach": "wiki, concept, image", "verif answer": "work", "anno approach": "image, wiki", "verif wiki answer": "work(0.5819)", "verif concept answer": "work(0.5961)", "verif image answer": "work(0.6365)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259514.jpg"}, {"question": "what are the toys made from", "gt answer": "plastic(1.00)", "pred answer": "plastic", "question_id": 549765, "best approach": "concept", "verif answer": "nylon", "anno approach": "concept", "verif wiki answer": "nylon(0.6493)", "verif concept answer": "plastic(0.6485)", "verif image answer": "nylon(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054976.jpg"}, {"question": "how long does this animal live", "gt answer": "20 years(1.00)<br/>50 years(0.60)<br/>30 years(0.60)", "pred answer": "10 years", "question_id": 3756375, "best approach": "wiki, concept, image", "verif answer": "50 years", "anno approach": "image, wiki", "verif wiki answer": "30 years(0.6343)", "verif concept answer": "30 years(0.6158)", "verif image answer": "50 years(0.7208)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375637.jpg"}, {"question": "what is used to perform this sport", "gt answer": "bat(1.00)", "pred answer": "bat", "question_id": 1199945, "best approach": "", "verif answer": "batter", "anno approach": "", "verif wiki answer": "batter(0.7311)", "verif concept answer": "batter(0.7311)", "verif image answer": "batter(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119994.jpg"}, {"question": "where can i get these books", "gt answer": "library(1.00)<br/>bookstore(0.60)<br/>amazon(0.60)", "pred answer": "online", "question_id": 5318315, "best approach": "wiki, concept, image", "verif answer": "bookstore", "anno approach": "wiki", "verif wiki answer": "bookstore(0.7311)", "verif concept answer": "bookstore(0.7310)", "verif image answer": "bookstore(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531831.jpg"}, {"question": "what sport is this in the united states", "gt answer": "soccer(1.00)", "pred answer": "football", "question_id": 477295, "best approach": "", "verif answer": "football", "anno approach": "", "verif wiki answer": "football(0.7204)", "verif concept answer": "football(0.6578)", "verif image answer": "football(0.6476)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047729.jpg"}, {"question": "what is the fastest one on earth", "gt answer": "bullet(1.00)<br/>amtrak(0.60)", "pred answer": "europe", "question_id": 2518605, "best approach": "concept", "verif answer": "bullet train", "anno approach": "concept", "verif wiki answer": "driver(0.5022)", "verif concept answer": "bullet(0.5013)", "verif image answer": "bullet train(0.6352)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251860.jpg"}, {"question": "what was used to stain the boys' shirts", "gt answer": "fake blood(1.00)<br/>dye(0.60)<br/>food color(0.60)<br/>ketchup(0.60)", "pred answer": "paint", "question_id": 1070725, "best approach": "wiki, concept", "verif answer": "dye", "anno approach": "wiki", "verif wiki answer": "dye(0.7235)", "verif concept answer": "dye(0.7207)", "verif image answer": "paint(0.6562)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000107072.jpg"}, {"question": "what is the man made of", "gt answer": "cast iron(1.00)<br/>iron(0.60)<br/>bronze(0.60)<br/>metal(0.60)", "pred answer": "brick", "question_id": 463735, "best approach": "wiki, concept, image", "verif answer": "iron", "anno approach": "image, wiki", "verif wiki answer": "iron(0.6482)", "verif concept answer": "iron(0.6692)", "verif image answer": "iron(0.6839)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046373.jpg"}, {"question": "what does this device do", "gt answer": "tell time(1.00)<br/>time tell(0.60)", "pred answer": "tell time", "question_id": 228385, "best approach": "wiki, concept, image", "verif answer": "tell time", "anno approach": "concept, wiki", "verif wiki answer": "tell time(0.7305)", "verif concept answer": "tell time(0.7193)", "verif image answer": "tell time(0.5826)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000022838.jpg"}, {"question": "what is this object used for", "gt answer": "fight fire(1.00)<br/>firefight(1.00)", "pred answer": "fire", "question_id": 3110315, "best approach": "", "verif answer": "fire", "anno approach": "", "verif wiki answer": "fire(0.6565)", "verif concept answer": "fire(0.6604)", "verif image answer": "fire(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311031.jpg"}, {"question": "what makes that toothbrush work", "gt answer": "battery(1.00)<br/>electricity(0.60)<br/>energy(0.60)", "pred answer": "battery", "question_id": 4054005, "best approach": "concept, image", "verif answer": "electricity", "anno approach": "concept", "verif wiki answer": "electricity(0.7262)", "verif concept answer": "battery(0.7219)", "verif image answer": "battery(0.6805)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405400.jpg"}, {"question": "how fast can this machine go", "gt answer": "slow(1.00)<br/>30mph(0.60)<br/>25(0.60)<br/>25 mph(0.60)", "pred answer": "20 mph", "question_id": 2715925, "best approach": "wiki, image", "verif answer": "slow", "anno approach": "wiki", "verif wiki answer": "slow(0.6330)", "verif concept answer": "25(0.6272)", "verif image answer": "slow(0.6498)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000271592.jpg"}, {"question": "what is in the drink on the table", "gt answer": "lemon(1.00)<br/>coke(0.60)<br/>tea(0.60)", "pred answer": "soda", "question_id": 3402675, "best approach": "image", "verif answer": "tea", "anno approach": "image", "verif wiki answer": "tea(0.7245)", "verif concept answer": "tea(0.6619)", "verif image answer": "lemon(0.5049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340267.jpg"}, {"question": "what do you do to that item before putting it in your pocket", "gt answer": "close(1.00)<br/>talk(0.60)", "pred answer": "brush", "question_id": 2530655, "best approach": "", "verif answer": "take picture", "anno approach": "", "verif wiki answer": "take picture(0.6782)", "verif concept answer": "take picture(0.7149)", "verif image answer": "take picture(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253065.jpg"}, {"question": "what category of food is this", "gt answer": "dessert(1.00)<br/>desert(1.00)<br/>cake(0.60)", "pred answer": "cake", "question_id": 4411995, "best approach": "image", "verif answer": "desert", "anno approach": "image", "verif wiki answer": "cake(0.6558)", "verif concept answer": "cupcake(0.6273)", "verif image answer": "desert(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441199.jpg"}, {"question": "what country can you find this bus riding around town", "gt answer": "ireland(1.00)<br/>england(1.00)<br/>germany(0.60)", "pred answer": "england", "question_id": 525235, "best approach": "wiki, concept, image", "verif answer": "england", "anno approach": "wiki", "verif wiki answer": "ireland(0.7060)", "verif concept answer": "ireland(0.7309)", "verif image answer": "england(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052523.jpg"}, {"question": "on average how old does this breed of cat live to be", "gt answer": "12 years(1.00)<br/>15 years(0.60)<br/>15(0.60)", "pred answer": "7", "question_id": 5646555, "best approach": "wiki, concept", "verif answer": "20 years", "anno approach": "wiki", "verif wiki answer": "12 years(0.6549)", "verif concept answer": "12 years(0.6600)", "verif image answer": "20 years(0.6689)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564655.jpg"}, {"question": "how old are the two children in this photo", "gt answer": "10(1.00)", "pred answer": "2", "question_id": 3078845, "best approach": "", "verif answer": "22", "anno approach": "", "verif wiki answer": "0(0.6432)", "verif concept answer": "22(0.6745)", "verif image answer": "22(0.6448)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307884.jpg"}, {"question": "what type of day is this", "gt answer": "sunny(1.00)<br/>clear(0.60)<br/>cloudy(0.60)", "pred answer": "sunny", "question_id": 3661355, "best approach": "wiki, concept, image", "verif answer": "cloudy", "anno approach": "wiki", "verif wiki answer": "cloudy(0.7295)", "verif concept answer": "cloudy(0.7299)", "verif image answer": "cloudy(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366135.jpg"}, {"question": "what is the blue item called", "gt answer": "bus stop(1.00)", "pred answer": "bus", "question_id": 5602545, "best approach": "wiki, concept, image", "verif answer": "bus stop", "anno approach": "image, concept, wiki", "verif wiki answer": "bus stop(0.5163)", "verif concept answer": "bus stop(0.6051)", "verif image answer": "bus stop(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560254.jpg"}, {"question": "what appliance the device shown control", "gt answer": "tv(1.00)<br/>television(0.60)", "pred answer": "cell phone", "question_id": 3581585, "best approach": "wiki, concept, image", "verif answer": "television", "anno approach": "concept, wiki", "verif wiki answer": "television(0.6467)", "verif concept answer": "television(0.6450)", "verif image answer": "television(0.5964)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358158.jpg"}, {"question": "what is the lady doing to the sheep", "gt answer": "sheer(1.00)<br/>shear(1.00)", "pred answer": "shear", "question_id": 4014555, "best approach": "", "verif answer": "clip", "anno approach": "", "verif wiki answer": "clip(0.6039)", "verif concept answer": "clip(0.5508)", "verif image answer": "clip(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401455.jpg"}, {"question": "what safety equipment should the sup user be wearing", "gt answer": "life jacket(1.00)", "pred answer": "helmet", "question_id": 1135985, "best approach": "", "verif answer": "bikini", "anno approach": "", "verif wiki answer": "bikini(0.7267)", "verif concept answer": "bikini(0.7285)", "verif image answer": "bikini(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113598.jpg"}, {"question": "what needed repair in this room", "gt answer": "toilet(1.00)", "pred answer": "toilet", "question_id": 595155, "best approach": "wiki, concept, image", "verif answer": "toilet", "anno approach": "wiki", "verif wiki answer": "toilet(0.7311)", "verif concept answer": "toilet(0.7223)", "verif image answer": "toilet(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059515.jpg"}, {"question": "who is considered the best man at this sport", "gt answer": "roger federer(1.00)", "pred answer": "rafael nadal", "question_id": 4833045, "best approach": "wiki, concept, image", "verif answer": "roger federer", "anno approach": "image, wiki", "verif wiki answer": "roger federer(0.5711)", "verif concept answer": "roger federer(0.5551)", "verif image answer": "roger federer(0.6031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483304.jpg"}, {"question": "what type of oil was used to paint this picture", "gt answer": "linseed(1.00)<br/>grease(0.60)", "pred answer": "fish", "question_id": 393155, "best approach": "wiki, concept, image", "verif answer": "grease", "anno approach": "wiki", "verif wiki answer": "grease(0.6463)", "verif concept answer": "grease(0.6627)", "verif image answer": "grease(0.6313)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039315.jpg"}, {"question": "what kind of bed is this", "gt answer": "bunk(1.00)<br/>bunk bed(0.60)", "pred answer": "bunk", "question_id": 461685, "best approach": "wiki, concept, image", "verif answer": "bunk", "anno approach": "wiki", "verif wiki answer": "bunk(0.7311)", "verif concept answer": "bunk(0.7310)", "verif image answer": "bunk(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046168.jpg"}, {"question": "how many inches is this tv display", "gt answer": "32(1.00)<br/>40(0.60)<br/>50(0.60)", "pred answer": "20", "question_id": 4299185, "best approach": "wiki", "verif answer": "20", "anno approach": "wiki", "verif wiki answer": "50(0.6700)", "verif concept answer": "20(0.7258)", "verif image answer": "20(0.6936)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429918.jpg"}, {"question": "how many points does it take to win in badminton", "gt answer": "21(1.00)<br/>12(0.60)<br/>20(0.60)<br/>5(0.60)", "pred answer": "45", "question_id": 1092085, "best approach": "wiki, concept, image", "verif answer": "21", "anno approach": "image, wiki", "verif wiki answer": "21(0.7027)", "verif concept answer": "21(0.6676)", "verif image answer": "21(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000109208.jpg"}, {"question": "what is this animal hunted for", "gt answer": "tusk(1.00)<br/>ivory(1.00)", "pred answer": "drink water", "question_id": 2935435, "best approach": "wiki, concept, image", "verif answer": "tusk", "anno approach": "image, wiki", "verif wiki answer": "tusk(0.5588)", "verif concept answer": "tusk(0.5824)", "verif image answer": "tusk(0.6394)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293543.jpg"}, {"question": "who is famous for doing this", "gt answer": "tony hawk(1.00)", "pred answer": "shaun white", "question_id": 838725, "best approach": "wiki, concept, image", "verif answer": "tony hawk", "anno approach": "wiki", "verif wiki answer": "tony hawk(0.6503)", "verif concept answer": "tony hawk(0.6406)", "verif image answer": "tony hawk(0.6576)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083872.jpg"}, {"question": "is the bird migrating or native", "gt answer": "native(1.00)<br/>(0.60)", "pred answer": "domestic", "question_id": 1642875, "best approach": "wiki", "verif answer": "wild", "anno approach": "wiki", "verif wiki answer": "(0.7224)", "verif concept answer": "wild(0.7309)", "verif image answer": "wild(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000164287.jpg"}, {"question": "why is one person lying down", "gt answer": "tired(1.00)<br/>sleep(1.00)", "pred answer": "rest", "question_id": 2310195, "best approach": "concept, image", "verif answer": "sick", "anno approach": "", "verif wiki answer": "sick(0.7198)", "verif concept answer": "sleep(0.6702)", "verif image answer": "sleep(0.6804)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231019.jpg"}, {"question": "what is the name of the national organization that oversees this sport", "gt answer": "major league baseball(1.00)<br/>mlb(0.60)", "pred answer": "dodger", "question_id": 1366415, "best approach": "wiki, concept", "verif answer": "major league baseball", "anno approach": "wiki", "verif wiki answer": "major league baseball(0.7226)", "verif concept answer": "major league baseball(0.7304)", "verif image answer": "major league(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136641.jpg"}, {"question": "what type of bread is this", "gt answer": "banana bread(1.00)<br/>wheat(0.60)<br/>banana(0.60)<br/>whole grain(0.60)", "pred answer": "vanilla", "question_id": 5428175, "best approach": "wiki, concept, image", "verif answer": "whole grain", "anno approach": "wiki", "verif wiki answer": "whole grain(0.6645)", "verif concept answer": "whole grain(0.6807)", "verif image answer": "whole grain(0.6941)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542817.jpg"}, {"question": "name the bird", "gt answer": "wren(1.00)<br/>finch(0.60)", "pred answer": "finch", "question_id": 1685745, "best approach": "", "verif answer": "sparrow", "anno approach": "", "verif wiki answer": "sparrow(0.6810)", "verif concept answer": "sparrow(0.6738)", "verif image answer": "robin(0.6002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168574.jpg"}, {"question": "when was this sport invented", "gt answer": "1839(1.00)<br/>1885(0.60)<br/>1800's(0.60)<br/>1880(0.60)", "pred answer": "1880", "question_id": 2209895, "best approach": "concept, image", "verif answer": "1804", "anno approach": "", "verif wiki answer": "1804(0.7311)", "verif concept answer": "1880(0.7311)", "verif image answer": "1880(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220989.jpg"}, {"question": "are these trains in operation right now or are they shut down for the night", "gt answer": "shut down(1.00)<br/>in operation(0.60)", "pred answer": "landed", "question_id": 1367365, "best approach": "wiki, concept, image", "verif answer": "shut down", "anno approach": "concept, wiki", "verif wiki answer": "shut down(0.6339)", "verif concept answer": "shut down(0.5897)", "verif image answer": "shut down(0.5005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136736.jpg"}, {"question": "what type of food is this", "gt answer": "sushi(1.00)<br/>japanese(0.60)<br/>asian(0.60)<br/>meat(0.60)", "pred answer": "sandwich", "question_id": 505565, "best approach": "wiki, concept", "verif answer": "meat", "anno approach": "wiki", "verif wiki answer": "asian(0.6486)", "verif concept answer": "meat(0.6603)", "verif image answer": "thai(0.6576)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050556.jpg"}, {"question": "what does the yellow color of these fruit mean", "gt answer": "ripe(1.00)<br/>good(0.60)", "pred answer": "banana", "question_id": 1979625, "best approach": "wiki, concept, image", "verif answer": "good", "anno approach": "image, wiki", "verif wiki answer": "good(0.6476)", "verif concept answer": "good(0.6518)", "verif image answer": "good(0.7134)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197962.jpg"}, {"question": "who owns the horses", "gt answer": "farmer(1.00)<br/>rancher(0.60)", "pred answer": "man", "question_id": 2476415, "best approach": "wiki, concept, image", "verif answer": "farmer", "anno approach": "wiki", "verif wiki answer": "farmer(0.7306)", "verif concept answer": "farmer(0.7298)", "verif image answer": "farmer(0.7047)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247641.jpg"}, {"question": "is the orange motorcycle used for sport or long distance travel", "gt answer": "long distance(1.00)<br/>sport(1.00)", "pred answer": "transportation", "question_id": 3905655, "best approach": "", "verif answer": "competition", "anno approach": "", "verif wiki answer": "race(0.5013)", "verif concept answer": "race(0.5003)", "verif image answer": "competition(0.5211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390565.jpg"}, {"question": "what are the lines on the potato chips called", "gt answer": "ridge(1.00)<br/>ruffle(0.60)", "pred answer": "track", "question_id": 4175405, "best approach": "wiki, concept", "verif answer": "ruffle", "anno approach": "concept", "verif wiki answer": "ruffle(0.6605)", "verif concept answer": "ruffle(0.7138)", "verif image answer": "foot(0.5057)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417540.jpg"}, {"question": "what is the name of the music player", "gt answer": "record player(1.00)", "pred answer": "guitar", "question_id": 4285355, "best approach": "wiki, concept", "verif answer": "record player", "anno approach": "wiki", "verif wiki answer": "record player(0.5013)", "verif concept answer": "record player(0.5069)", "verif image answer": "dexter(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428535.jpg"}, {"question": "why might one suspect the emblem at the front is meant to reference the us", "gt answer": "eagle(1.00)<br/>railroad(0.60)", "pred answer": "track", "question_id": 3515375, "best approach": "wiki, concept, image", "verif answer": "eagle", "anno approach": "wiki", "verif wiki answer": "eagle(0.5058)", "verif concept answer": "eagle(0.5173)", "verif image answer": "eagle(0.5014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351537.jpg"}, {"question": "what country eats the most of this food", "gt answer": "norway(1.00)<br/>united state(0.60)", "pred answer": "italy", "question_id": 4917275, "best approach": "concept", "verif answer": "united state", "anno approach": "concept", "verif wiki answer": "sweden(0.6589)", "verif concept answer": "norway(0.6621)", "verif image answer": "united state(0.7129)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491727.jpg"}, {"question": "is this person inside or outside", "gt answer": "outside(1.00)", "pred answer": "outside", "question_id": 4055485, "best approach": "", "verif answer": "inside", "anno approach": "", "verif wiki answer": "inside(0.6977)", "verif concept answer": "inside(0.7199)", "verif image answer": "outdoor(0.6431)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405548.jpg"}, {"question": "is this a gerbil or hamster", "gt answer": "hamster(1.00)", "pred answer": "tiger", "question_id": 2435045, "best approach": "", "verif answer": "window", "anno approach": "", "verif wiki answer": "window(0.5000)", "verif concept answer": "window(0.5000)", "verif image answer": "window(0.5014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243504.jpg"}, {"question": "what is the purpose of the truck being so close to the water", "gt answer": "unload boat(1.00)", "pred answer": "transportation", "question_id": 279805, "best approach": "wiki, concept", "verif answer": "unload boat", "anno approach": "", "verif wiki answer": "unload boat(0.7303)", "verif concept answer": "unload boat(0.7261)", "verif image answer": "transportation(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027980.jpg"}, {"question": "what type of lighting is on the ceiling", "gt answer": "track(1.00)", "pred answer": "fluorescent", "question_id": 1286495, "best approach": "concept", "verif answer": "racetrack", "anno approach": "concept", "verif wiki answer": "racetrack(0.6216)", "verif concept answer": "track(0.6217)", "verif image answer": "racetrack(0.6440)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128649.jpg"}, {"question": "where is this art typically displayed", "gt answer": "museum(1.00)<br/>art gallery(0.60)<br/>pottery(0.60)", "pred answer": "museum", "question_id": 3442935, "best approach": "wiki, concept, image", "verif answer": "museum", "anno approach": "image, wiki", "verif wiki answer": "museum(0.6506)", "verif concept answer": "museum(0.6597)", "verif image answer": "museum(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344293.jpg"}, {"question": "what paint style is on the bike on the right", "gt answer": "flame(1.00)", "pred answer": "striped", "question_id": 5126445, "best approach": "", "verif answer": "new balance", "anno approach": "", "verif wiki answer": "new balance(0.6714)", "verif concept answer": "new balance(0.7234)", "verif image answer": "new balance(0.6762)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512644.jpg"}, {"question": "how old is this bird", "gt answer": "1 year(1.00)<br/>5 years(0.60)", "pred answer": "2", "question_id": 743905, "best approach": "concept", "verif answer": "1", "anno approach": "concept", "verif wiki answer": "1(0.6360)", "verif concept answer": "1 year(0.6140)", "verif image answer": "1(0.6467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074390.jpg"}, {"question": "what dish can you make with these ingredients", "gt answer": "salad(1.00)<br/>tofu(0.60)<br/>taco(0.60)", "pred answer": "salad", "question_id": 2706515, "best approach": "concept, image", "verif answer": "taco", "anno approach": "concept", "verif wiki answer": "taco(0.7310)", "verif concept answer": "salad(0.7288)", "verif image answer": "salad(0.6677)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270651.jpg"}, {"question": "what type of eatery is this", "gt answer": "pizzeria(1.00)<br/>italian(0.60)<br/>pizza(0.60)", "pred answer": "italian", "question_id": 3250125, "best approach": "concept, image", "verif answer": "italian", "anno approach": "concept", "verif wiki answer": "italian(0.6138)", "verif concept answer": "pizzeria(0.5801)", "verif image answer": "pizzeria(0.5287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325012.jpg"}, {"question": "what are these guys on there way to do", "gt answer": "camp(1.00)<br/>backpack(0.60)<br/>hike(1.00)", "pred answer": "throw frisbee", "question_id": 741565, "best approach": "", "verif answer": "pet store", "anno approach": "", "verif wiki answer": "pet store(0.6325)", "verif concept answer": "pet store(0.6899)", "verif image answer": "pet store(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074156.jpg"}, {"question": "when was this made", "gt answer": "1903(1.00)<br/>1900(0.60)<br/>1900's(0.60)", "pred answer": "1930s", "question_id": 5251695, "best approach": "wiki, concept, image", "verif answer": "1903", "anno approach": "concept", "verif wiki answer": "1903(0.6700)", "verif concept answer": "1903(0.7083)", "verif image answer": "1903(0.6735)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525169.jpg"}, {"question": "what kind of donut is this", "gt answer": "sprinkle(1.00)<br/>glazed(0.60)", "pred answer": "vanilla", "question_id": 967135, "best approach": "wiki, concept", "verif answer": "glazed", "anno approach": "wiki", "verif wiki answer": "sprinkle(0.6509)", "verif concept answer": "sprinkle(0.6636)", "verif image answer": "glazed(0.7052)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096713.jpg"}, {"question": "what should this woman be careful of", "gt answer": "car(1.00)<br/>traffic(0.60)", "pred answer": "bicycle", "question_id": 4614965, "best approach": "concept", "verif answer": "car", "anno approach": "concept", "verif wiki answer": "stop light(0.6956)", "verif concept answer": "car(0.7305)", "verif image answer": "stop light(0.7245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461496.jpg"}, {"question": "what are the kids looking at", "gt answer": "camera(1.00)<br/>skier(0.60)", "pred answer": "ski", "question_id": 2497305, "best approach": "", "verif answer": "mirror", "anno approach": "", "verif wiki answer": "mirror(0.7304)", "verif concept answer": "film(0.6914)", "verif image answer": "film(0.6450)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249730.jpg"}, {"question": "what famous dancing video game franchise was created for this gaming console system", "gt answer": "just dance(1.00)<br/>dance(0.60)<br/>karaoke(0.60)", "pred answer": "wii", "question_id": 1270765, "best approach": "wiki, concept, image", "verif answer": "just dance", "anno approach": "concept, wiki", "verif wiki answer": "just dance(0.5621)", "verif concept answer": "just dance(0.5301)", "verif image answer": "just dance(0.5007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127076.jpg"}, {"question": "what is being sold", "gt answer": "surf board(1.00)", "pred answer": "surfboard", "question_id": 3770155, "best approach": "wiki, concept, image", "verif answer": "surf board", "anno approach": "wiki", "verif wiki answer": "surf board(0.7171)", "verif concept answer": "surf board(0.6586)", "verif image answer": "surf board(0.6852)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377015.jpg"}, {"question": "who invented the device pictured", "gt answer": "steve job(1.00)<br/>bill gate(0.60)<br/>laptop(0.60)<br/>people(0.60)", "pred answer": "steve job", "question_id": 641865, "best approach": "wiki, concept, image", "verif answer": "steve job", "anno approach": "image, wiki", "verif wiki answer": "steve job(0.6947)", "verif concept answer": "steve job(0.7105)", "verif image answer": "steve job(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064186.jpg"}, {"question": "what is the person cooking", "gt answer": "carrot(1.00)<br/>vegetable(0.60)", "pred answer": "soup", "question_id": 866115, "best approach": "concept", "verif answer": "pepper", "anno approach": "concept", "verif wiki answer": "pepper(0.6915)", "verif concept answer": "carrot(0.6838)", "verif image answer": "pepper(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086611.jpg"}, {"question": "what electrical item is in front of the children on the table", "gt answer": "projector(1.00)", "pred answer": "book", "question_id": 1975035, "best approach": "image", "verif answer": "projector", "anno approach": "image", "verif wiki answer": "fry(0.5001)", "verif concept answer": "fry(0.5000)", "verif image answer": "projector(0.5004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197503.jpg"}, {"question": "what brand of computer", "gt answer": "samsung(1.00)<br/>toshiba(0.60)", "pred answer": "dell", "question_id": 475025, "best approach": "", "verif answer": "nokia", "anno approach": "", "verif wiki answer": "nokia(0.6479)", "verif concept answer": "nokia(0.6943)", "verif image answer": "nokia(0.6611)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047502.jpg"}, {"question": "what are these people about to do", "gt answer": "ski(1.00)", "pred answer": "ski", "question_id": 94085, "best approach": "wiki, concept, image", "verif answer": "ski", "anno approach": "wiki", "verif wiki answer": "ski(0.7311)", "verif concept answer": "ski(0.7311)", "verif image answer": "ski(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009408.jpg"}, {"question": "what movie involves a cat and dog that are best friends venturing home like those in the picture", "gt answer": "homeward bound(1.00)", "pred answer": "garfield", "question_id": 116355, "best approach": "", "verif answer": "dumbo", "anno approach": "", "verif wiki answer": "dumbo(0.7305)", "verif concept answer": "dumbo(0.6264)", "verif image answer": "dumbo(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011635.jpg"}, {"question": "is the food on the sign a fruit or a vegetable", "gt answer": "fruit(1.00)", "pred answer": "vegetable", "question_id": 3741715, "best approach": "", "verif answer": "banana", "anno approach": "", "verif wiki answer": "banana(0.5005)", "verif concept answer": "vegetable(0.5003)", "verif image answer": "banana(0.5007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374171.jpg"}, {"question": "what country is this in", "gt answer": "spain(1.00)<br/>chile(1.00)<br/>england(0.60)", "pred answer": "thailand", "question_id": 2206155, "best approach": "", "verif answer": "thailand", "anno approach": "", "verif wiki answer": "thailand(0.6467)", "verif concept answer": "thailand(0.6486)", "verif image answer": "thailand(0.6460)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220615.jpg"}, {"question": "what animal do these resemble", "gt answer": "bear(1.00)", "pred answer": "dog", "question_id": 2895835, "best approach": "", "verif answer": "teddy bear", "anno approach": "", "verif wiki answer": "teddy bear(0.7266)", "verif concept answer": "teddy bear(0.7240)", "verif image answer": "teddy bear(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000289583.jpg"}, {"question": "which american president is associated with this type of bear", "gt answer": "teddy roosevelt(1.00)<br/>roosevelt(0.60)<br/>theodore roosevelt(0.60)", "pred answer": "roosevelt", "question_id": 3902865, "best approach": "wiki, concept, image", "verif answer": "roosevelt", "anno approach": "wiki", "verif wiki answer": "roosevelt(0.7307)", "verif concept answer": "roosevelt(0.7259)", "verif image answer": "roosevelt(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390286.jpg"}, {"question": "what is about to happen", "gt answer": "horseback ride(0.60)<br/>horse ride(1.00)<br/>horse race(0.60)", "pred answer": "ride", "question_id": 5292265, "best approach": "image", "verif answer": "race", "anno approach": "image", "verif wiki answer": "race(0.5986)", "verif concept answer": "race(0.5316)", "verif image answer": "horse race(0.5007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529226.jpg"}, {"question": "", "gt answer": "levi(0.60)<br/>cowboy(0.60)", "pred answer": "levis", "question_id": 2571635, "best approach": "", "verif answer": "lee", "anno approach": "", "verif wiki answer": "lee(0.5003)", "verif concept answer": "ll bean(0.5001)", "verif image answer": "ll bean(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257163.jpg"}, {"question": "how much is the honking penalty", "gt answer": "350(1.00)<br/>$350(1.00)", "pred answer": "$350", "question_id": 5573875, "best approach": "wiki, concept, image", "verif answer": "$350", "anno approach": "concept, wiki", "verif wiki answer": "$350(0.7310)", "verif concept answer": "$350(0.7308)", "verif image answer": "$350(0.6818)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557387.jpg"}, {"question": "what type of shells are on the table", "gt answer": "pistachio(1.00)", "pred answer": "grape", "question_id": 5034785, "best approach": "image", "verif answer": "cashew", "anno approach": "image", "verif wiki answer": "cashew(0.5007)", "verif concept answer": "cashew(0.5064)", "verif image answer": "pistachio(0.5027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503478.jpg"}, {"question": "what does this guys shirt say", "gt answer": "park(1.00)", "pred answer": "sport", "question_id": 287975, "best approach": "", "verif answer": "advertising", "anno approach": "", "verif wiki answer": "advertising(0.6345)", "verif concept answer": "advertising(0.6373)", "verif image answer": "advertising(0.5058)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028797.jpg"}, {"question": "where is this clock town and christmas tree located", "gt answer": "downtown(1.00)<br/>london(0.60)<br/>philadelphia(0.60)", "pred answer": "england", "question_id": 1885155, "best approach": "wiki, concept", "verif answer": "london", "anno approach": "wiki", "verif wiki answer": "philadelphia(0.6471)", "verif concept answer": "london(0.6481)", "verif image answer": "new york(0.6476)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188515.jpg"}, {"question": "what places are specifically created for this activity", "gt answer": "skate park(1.00)", "pred answer": "skate park", "question_id": 4633555, "best approach": "wiki, concept, image", "verif answer": "skate park", "anno approach": "wiki", "verif wiki answer": "skate park(0.7097)", "verif concept answer": "skate park(0.7054)", "verif image answer": "skate park(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463355.jpg"}, {"question": "what is the name of the ancient greek sport that evolved into the sport featured above", "gt answer": "discus(1.00)<br/>soccer(0.60)<br/>frisbee(0.60)", "pred answer": "frisbee", "question_id": 2978665, "best approach": "wiki, concept, image", "verif answer": "frisbee", "anno approach": "wiki", "verif wiki answer": "frisbee(0.6692)", "verif concept answer": "frisbee(0.6481)", "verif image answer": "frisbee(0.6436)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297866.jpg"}, {"question": "what kind of train is this", "gt answer": "commuter(1.00)", "pred answer": "passenger", "question_id": 578015, "best approach": "", "verif answer": "passenger", "anno approach": "", "verif wiki answer": "passenger(0.6773)", "verif concept answer": "passenger(0.7258)", "verif image answer": "passenger(0.6416)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000057801.jpg"}, {"question": "what popular grilled sandwich is made of these animals", "gt answer": "hamburger(1.00)<br/>roast beef(0.60)<br/>burger(0.60)", "pred answer": "beef", "question_id": 4891145, "best approach": "", "verif answer": "bbq", "anno approach": "", "verif wiki answer": "bbq(0.5117)", "verif concept answer": "bbq(0.5036)", "verif image answer": "bbq(0.6087)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489114.jpg"}, {"question": "what 's the normal size of these animal 's ear", "gt answer": "big(1.00)<br/>3 feet(0.60)<br/>5 feet(0.60)<br/>large(0.60)", "pred answer": "8 inches", "question_id": 2182835, "best approach": "wiki, concept, image", "verif answer": "5 feet", "anno approach": "concept, wiki", "verif wiki answer": "5 feet(0.6445)", "verif concept answer": "3 feet(0.6415)", "verif image answer": "large(0.5934)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218283.jpg"}, {"question": "what will happen next", "gt answer": "serve(1.00)<br/>swing(0.60)<br/>hit ball(0.60)", "pred answer": "serve", "question_id": 5575075, "best approach": "wiki, concept, image", "verif answer": "serve", "anno approach": "wiki", "verif wiki answer": "serve(0.6504)", "verif concept answer": "serve(0.6390)", "verif image answer": "serve(0.6677)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557507.jpg"}, {"question": "what brand is the horseradish", "gt answer": "kraft(1.00)<br/>french(0.60)<br/>heinz(0.60)", "pred answer": "dalmatian", "question_id": 4183945, "best approach": "wiki, concept, image", "verif answer": "kraft", "anno approach": "concept, wiki", "verif wiki answer": "kraft(0.7225)", "verif concept answer": "kraft(0.7292)", "verif image answer": "kraft(0.5125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000418394.jpg"}, {"question": "is this a snack or a lunch", "gt answer": "snack(1.00)", "pred answer": "snack", "question_id": 2526115, "best approach": "wiki", "verif answer": "snack", "anno approach": "wiki", "verif wiki answer": "snack(0.5939)", "verif concept answer": "vegetable(0.5656)", "verif image answer": "vegetable(0.5045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252611.jpg"}, {"question": "what is the state bird for the location pictured", "gt answer": "seagull(1.00)<br/>robin(0.60)<br/>cardinal(0.60)", "pred answer": "new york", "question_id": 3663855, "best approach": "wiki, concept, image", "verif answer": "cardinal", "anno approach": "image, wiki", "verif wiki answer": "cardinal(0.5097)", "verif concept answer": "cardinal(0.5064)", "verif image answer": "cardinal(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366385.jpg"}, {"question": "what is the name of the trick this boy is doing", "gt answer": "kick flip(1.00)<br/>ollie(0.60)<br/>fly(0.60)", "pred answer": "ollie", "question_id": 5423165, "best approach": "wiki", "verif answer": "kickflip", "anno approach": "wiki", "verif wiki answer": "kick flip(0.6455)", "verif concept answer": "kickflip(0.6423)", "verif image answer": "kickflip(0.6907)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542316.jpg"}, {"question": "what type of cuisine is pictured here", "gt answer": "asian(1.00)<br/>japanese(0.60)<br/>coconut(0.60)<br/>indian(0.60)", "pred answer": "japanese", "question_id": 4512835, "best approach": "wiki, concept, image", "verif answer": "coconut", "anno approach": "wiki", "verif wiki answer": "coconut(0.7065)", "verif concept answer": "coconut(0.6751)", "verif image answer": "coconut(0.6614)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451283.jpg"}, {"question": "in what country is the airline shown in the photo based", "gt answer": "canada(1.00)<br/>france(0.60)<br/>chile(0.60)", "pred answer": "australia", "question_id": 1754185, "best approach": "image", "verif answer": "chile", "anno approach": "image", "verif wiki answer": "alaska(0.6475)", "verif concept answer": "alaska(0.6529)", "verif image answer": "chile(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000175418.jpg"}, {"question": "is it warm or cold", "gt answer": "warm(1.00)<br/>hot(0.60)", "pred answer": "hot", "question_id": 1404165, "best approach": "wiki, concept, image", "verif answer": "hot", "anno approach": "concept, wiki", "verif wiki answer": "hot(0.6809)", "verif concept answer": "hot(0.6009)", "verif image answer": "hot(0.5254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140416.jpg"}, {"question": "what is this green vegetable", "gt answer": "lettuce(1.00)<br/>broccoli(0.60)", "pred answer": "broccoli", "question_id": 4955285, "best approach": "wiki, concept, image", "verif answer": "broccoli", "anno approach": "wiki", "verif wiki answer": "broccoli(0.7311)", "verif concept answer": "broccoli(0.7311)", "verif image answer": "broccoli(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495528.jpg"}, {"question": "where must the ball go for a score", "gt answer": "goal(1.00)<br/>net(0.60)", "pred answer": "first base", "question_id": 3675195, "best approach": "wiki, concept, image", "verif answer": "net", "anno approach": "wiki", "verif wiki answer": "net(0.6254)", "verif concept answer": "net(0.6272)", "verif image answer": "net(0.6456)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367519.jpg"}, {"question": "what is this behavior called", "gt answer": "perch(1.00)<br/>relax(0.60)<br/>fish(0.60)<br/>rest(0.60)", "pred answer": "eat", "question_id": 1414605, "best approach": "wiki, concept, image", "verif answer": "rest", "anno approach": "wiki", "verif wiki answer": "fish(0.6482)", "verif concept answer": "rest(0.6381)", "verif image answer": "rest(0.6491)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000141460.jpg"}, {"question": "what is keeping people in", "gt answer": "rail(1.00)<br/>rain(0.60)<br/>wall(0.60)<br/>fence(0.60)", "pred answer": "fence", "question_id": 2131035, "best approach": "wiki, concept, image", "verif answer": "fence", "anno approach": "wiki", "verif wiki answer": "fence(0.7311)", "verif concept answer": "fence(0.7311)", "verif image answer": "fence(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000213103.jpg"}, {"question": "what is the horse pulling", "gt answer": "carriage(1.00)", "pred answer": "carriage", "question_id": 995365, "best approach": "wiki, concept, image", "verif answer": "carriage", "anno approach": "wiki", "verif wiki answer": "carriage(0.7294)", "verif concept answer": "carriage(0.7309)", "verif image answer": "carriage(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099536.jpg"}, {"question": "what kind of vegetable is the side dish made from", "gt answer": "potato(1.00)", "pred answer": "potato", "question_id": 3411395, "best approach": "", "verif answer": "carrot", "anno approach": "", "verif wiki answer": "carrot(0.6470)", "verif concept answer": "carrot(0.6456)", "verif image answer": "carrot(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341139.jpg"}, {"question": "where would one usually find this animal", "gt answer": "wood(1.00)<br/>forest(0.60)<br/>mountain(0.60)<br/>zoo(0.60)", "pred answer": "north pole", "question_id": 5076055, "best approach": "wiki, concept, image", "verif answer": "forest", "anno approach": "wiki", "verif wiki answer": "zoo(0.6367)", "verif concept answer": "forest(0.6378)", "verif image answer": "forest(0.6645)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507605.jpg"}, {"question": "why doesn't he have on safety gear", "gt answer": "he is reckless(1.00)<br/>0(0.60)", "pred answer": "skateboard", "question_id": 132785, "best approach": "wiki, concept, image", "verif answer": "he is reckless", "anno approach": "", "verif wiki answer": "he is reckless(0.7311)", "verif concept answer": "he is reckless(0.7311)", "verif image answer": "he is reckless(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013278.jpg"}, {"question": "which asian american female won the gold medal in this sport", "gt answer": "chloe kim(1.00)<br/>park(0.60)", "pred answer": "chloe kim", "question_id": 5299105, "best approach": "wiki, concept, image", "verif answer": "chloe kim", "anno approach": "image, concept, wiki", "verif wiki answer": "chloe kim(0.6698)", "verif concept answer": "chloe kim(0.7181)", "verif image answer": "chloe kim(0.7132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529910.jpg"}, {"question": "what are the plate on the ground of this game", "gt answer": "base(1.00)", "pred answer": "home plate", "question_id": 632635, "best approach": "", "verif answer": "home plate", "anno approach": "", "verif wiki answer": "home plate(0.7090)", "verif concept answer": "home plate(0.7295)", "verif image answer": "home plate(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063263.jpg"}, {"question": "in which room is this photo taken at", "gt answer": "bathroom(1.00)", "pred answer": "live room", "question_id": 4780075, "best approach": "", "verif answer": "toilet", "anno approach": "", "verif wiki answer": "toilet(0.7276)", "verif concept answer": "toilet(0.7083)", "verif image answer": "toilet(0.6981)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478007.jpg"}, {"question": "what kind of transportation was used here", "gt answer": "horse and buggy(1.00)<br/>horse(0.60)<br/>carriage(0.60)", "pred answer": "horse", "question_id": 144775, "best approach": "wiki, concept, image", "verif answer": "carriage", "anno approach": "concept, wiki", "verif wiki answer": "carriage(0.7307)", "verif concept answer": "carriage(0.7192)", "verif image answer": "horse(0.6225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000014477.jpg"}, {"question": "what type of vegetable is in the bowl", "gt answer": "zucchini(1.00)<br/>pepper(0.60)", "pred answer": "potato", "question_id": 2934895, "best approach": "", "verif answer": "carrot", "anno approach": "", "verif wiki answer": "carrot(0.5818)", "verif concept answer": "carrot(0.5344)", "verif image answer": "carrot(0.6168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293489.jpg"}, {"question": "what usually contains these objects", "gt answer": "drawer(1.00)<br/>purse(0.60)", "pred answer": "desk", "question_id": 3711575, "best approach": "wiki, concept", "verif answer": "purse", "anno approach": "wiki", "verif wiki answer": "purse(0.7126)", "verif concept answer": "purse(0.7281)", "verif image answer": "desk(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371157.jpg"}, {"question": "specify direction of traffic that need to stop", "gt answer": "right(1.00)", "pred answer": "north", "question_id": 1463895, "best approach": "", "verif answer": "right handed", "anno approach": "", "verif wiki answer": "right handed(0.7310)", "verif concept answer": "right handed(0.7263)", "verif image answer": "right handed(0.6925)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146389.jpg"}, {"question": "when was this communication device invented", "gt answer": "1973(1.00)<br/>cell phone(0.60)", "pred answer": "1970", "question_id": 1434825, "best approach": "wiki, concept, image", "verif answer": "1973", "anno approach": "image, concept, wiki", "verif wiki answer": "1973(0.6642)", "verif concept answer": "1973(0.7276)", "verif image answer": "1973(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143482.jpg"}, {"question": "what is the name of a famous manufacturer of these items", "gt answer": "ty(1.00)", "pred answer": "theodore roosevelt", "question_id": 3518295, "best approach": "", "verif answer": "toy r us", "anno approach": "", "verif wiki answer": "toy r us(0.7311)", "verif concept answer": "toy r us(0.7311)", "verif image answer": "toy r us(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351829.jpg"}, {"question": "what types of fats are in a dessert like this", "gt answer": "saturated(1.00)<br/>milk(0.60)<br/>solid(0.60)", "pred answer": "protein", "question_id": 5173215, "best approach": "", "verif answer": "calcium", "anno approach": "", "verif wiki answer": "calcium(0.6916)", "verif concept answer": "calcium(0.6993)", "verif image answer": "calcium(0.6984)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517321.jpg"}, {"question": "what is the reflective body called", "gt answer": "water(1.00)<br/>lake(1.00)", "pred answer": "sand", "question_id": 4831185, "best approach": "wiki, concept, image", "verif answer": "lake", "anno approach": "concept, wiki", "verif wiki answer": "lake(0.7311)", "verif concept answer": "lake(0.7310)", "verif image answer": "lake(0.6611)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483118.jpg"}, {"question": "what time of year is it", "gt answer": "fall(1.00)<br/>autumn(1.00)", "pred answer": "fall", "question_id": 5429465, "best approach": "wiki, concept, image", "verif answer": "fall", "anno approach": "wiki", "verif wiki answer": "fall(0.7311)", "verif concept answer": "fall(0.7311)", "verif image answer": "fall(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542946.jpg"}, {"question": "what does this object do", "gt answer": "cook(1.00)<br/>bake(0.60)", "pred answer": "eat", "question_id": 4550815, "best approach": "wiki, concept, image", "verif answer": "bake", "anno approach": "image, concept, wiki", "verif wiki answer": "bake(0.5575)", "verif concept answer": "bake(0.5982)", "verif image answer": "bake(0.6281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455081.jpg"}, {"question": "which of the seven deadly sins has the same name as an item seen here", "gt answer": "vanity(1.00)<br/>cleanliness(0.60)<br/>bathroom(0.60)", "pred answer": "mirror", "question_id": 2808085, "best approach": "concept", "verif answer": "vanity", "anno approach": "concept", "verif wiki answer": "bathroom(0.6147)", "verif concept answer": "vanity(0.6405)", "verif image answer": "cleanliness(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280808.jpg"}, {"question": "how many times should you do this in a day", "gt answer": "twice(1.00)<br/>3(0.60)", "pred answer": "3", "question_id": 2757935, "best approach": "wiki, image", "verif answer": "3", "anno approach": "wiki", "verif wiki answer": "3(0.6718)", "verif concept answer": "2(0.6635)", "verif image answer": "3(0.6463)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000275793.jpg"}, {"question": "", "gt answer": "regular(0.60)<br/>crouch(0.60)", "pred answer": "longboard", "question_id": 1485175, "best approach": "wiki, concept, image", "verif answer": "regular", "anno approach": "image, concept", "verif wiki answer": "regular(0.6772)", "verif concept answer": "regular(0.7251)", "verif image answer": "regular(0.7246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148517.jpg"}, {"question": "what are these spoons used for", "gt answer": "measure(1.00)", "pred answer": "brush teeth", "question_id": 4652045, "best approach": "wiki, concept", "verif answer": "paint", "anno approach": "wiki", "verif wiki answer": "measure(0.7061)", "verif concept answer": "measure(0.6749)", "verif image answer": "paint(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465204.jpg"}, {"question": "what kind of bag that 's holding these apples called", "gt answer": "mesh(1.00)", "pred answer": "backpack", "question_id": 3297655, "best approach": "", "verif answer": "yarn", "anno approach": "", "verif wiki answer": "wax(0.6456)", "verif concept answer": "wax(0.6498)", "verif image answer": "yarn(0.7031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329765.jpg"}, {"question": "what kind of sandwich is this", "gt answer": "chicken(1.00)<br/>reuben(0.60)<br/>roast(0.60)", "pred answer": "hotdogs", "question_id": 704795, "best approach": "", "verif answer": "grilled", "anno approach": "", "verif wiki answer": "grilled(0.6924)", "verif concept answer": "grilled(0.7309)", "verif image answer": "grilled(0.7126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070479.jpg"}, {"question": "what is the item draped over the stop sign", "gt answer": "measure tape(1.00)", "pred answer": "wire", "question_id": 5640435, "best approach": "", "verif answer": "fold", "anno approach": "", "verif wiki answer": "shade(0.6508)", "verif concept answer": "shade(0.6458)", "verif image answer": "fold(0.6803)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564043.jpg"}, {"question": "what is it called when you use this mode of transportation overnight", "gt answer": "red eye(1.00)", "pred answer": "fly", "question_id": 4892975, "best approach": "image", "verif answer": "take off", "anno approach": "image", "verif wiki answer": "take off(0.6291)", "verif concept answer": "take off(0.6451)", "verif image answer": "red eye(0.6151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489297.jpg"}, {"question": "what is the place that this is played called", "gt answer": "tennis court(1.00)<br/>court(0.60)<br/>tennis(0.60)", "pred answer": "tennis court", "question_id": 1057085, "best approach": "wiki, image", "verif answer": "tennis court", "anno approach": "image, wiki", "verif wiki answer": "tennis court(0.5310)", "verif concept answer": "open(0.5345)", "verif image answer": "tennis court(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105708.jpg"}, {"question": "what kind of fish is used to make this meal", "gt answer": "salmon(1.00)<br/>tuna(1.00)", "pred answer": "salad", "question_id": 5427155, "best approach": "wiki, concept", "verif answer": "chicken", "anno approach": "wiki", "verif wiki answer": "salmon(0.5030)", "verif concept answer": "salmon(0.5058)", "verif image answer": "chicken(0.5988)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542715.jpg"}, {"question": "what is the type of the apple shown in the picture", "gt answer": "granny smith(1.00)<br/>green(0.60)", "pred answer": "granny smith", "question_id": 2732885, "best approach": "concept, image", "verif answer": "granny smith", "anno approach": "", "verif wiki answer": "green(0.7039)", "verif concept answer": "granny smith(0.7079)", "verif image answer": "granny smith(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273288.jpg"}, {"question": "is this train arriving or departing the station", "gt answer": "arrive(1.00)", "pred answer": "leave", "question_id": 5704065, "best approach": "wiki, concept, image", "verif answer": "arrive", "anno approach": "wiki", "verif wiki answer": "arrive(0.7281)", "verif concept answer": "arrive(0.7301)", "verif image answer": "arrive(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570406.jpg"}, {"question": "what event is this", "gt answer": "baby shower(1.00)<br/>st patrick's day(0.60)<br/>baby(0.60)", "pred answer": "birthday", "question_id": 1045645, "best approach": "wiki, concept, image", "verif answer": "baby shower", "anno approach": "wiki", "verif wiki answer": "baby shower(0.6981)", "verif concept answer": "baby shower(0.7276)", "verif image answer": "baby shower(0.7054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000104564.jpg"}, {"question": "what do you call what 's on the backdrop", "gt answer": "star(1.00)", "pred answer": "star", "question_id": 4899275, "best approach": "wiki, concept, image", "verif answer": "star", "anno approach": "wiki", "verif wiki answer": "star(0.7311)", "verif concept answer": "star(0.7311)", "verif image answer": "star(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489927.jpg"}, {"question": "where did this sport originate", "gt answer": "usa(1.00)<br/>california(0.60)<br/>us(0.60)", "pred answer": "europe", "question_id": 2447115, "best approach": "image", "verif answer": "united state", "anno approach": "image", "verif wiki answer": "united state(0.6092)", "verif concept answer": "united state(0.6479)", "verif image answer": "california(0.6411)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244711.jpg"}, {"question": "seattle is known for what object seen in this photograph", "gt answer": "kite(1.00)<br/>fog(0.60)", "pred answer": "string", "question_id": 4585965, "best approach": "", "verif answer": "cloud", "anno approach": "", "verif wiki answer": "cloud(0.6434)", "verif concept answer": "cloud(0.6426)", "verif image answer": "cloud(0.6502)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458596.jpg"}, {"question": "what might i dress like this for", "gt answer": "halloween(1.00)<br/>wed(0.60)<br/>church(0.60)<br/>party(0.60)", "pred answer": "work", "question_id": 931065, "best approach": "wiki, concept, image", "verif answer": "halloween", "anno approach": "wiki", "verif wiki answer": "halloween(0.7310)", "verif concept answer": "halloween(0.7311)", "verif image answer": "halloween(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093106.jpg"}, {"question": "what kind of activity would a vehicle like this undertake", "gt answer": "dump(1.00)<br/>construction(1.00)<br/>haul(0.60)", "pred answer": "construction", "question_id": 3796545, "best approach": "wiki, concept", "verif answer": "haul", "anno approach": "wiki", "verif wiki answer": "haul(0.6145)", "verif concept answer": "haul(0.5390)", "verif image answer": "transport(0.5471)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379654.jpg"}, {"question": "is this an urban or rural setting", "gt answer": "urban(1.00)<br/>rural(0.60)", "pred answer": "rural", "question_id": 3244095, "best approach": "wiki, concept, image", "verif answer": "rural", "anno approach": "wiki", "verif wiki answer": "rural(0.7299)", "verif concept answer": "rural(0.7300)", "verif image answer": "rural(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324409.jpg"}, {"question": "who was the first president of the nation on the flag in this photo", "gt answer": "george washington(1.00)<br/>washington(0.60)", "pred answer": "obama", "question_id": 4903285, "best approach": "", "verif answer": "air force 1", "anno approach": "", "verif wiki answer": "air force 1(0.7044)", "verif concept answer": "air force 1(0.7134)", "verif image answer": "richard trevithick(0.6927)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490328.jpg"}, {"question": "what brand of clothing does the person in the ski gears wearing", "gt answer": "columbia(1.00)<br/>north face(0.60)", "pred answer": "north face", "question_id": 5488345, "best approach": "", "verif answer": "adidas", "anno approach": "", "verif wiki answer": "adidas(0.6624)", "verif concept answer": "adidas(0.6573)", "verif image answer": "rei(0.6372)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548834.jpg"}, {"question": "what are the two types of washroom fixtures shown here", "gt answer": "toilet(1.00)", "pred answer": "bathroom", "question_id": 3377485, "best approach": "", "verif answer": "toilet seat", "anno approach": "", "verif wiki answer": "toilet seat(0.7308)", "verif concept answer": "toilet seat(0.7310)", "verif image answer": "toilet seat(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337748.jpg"}, {"question": "what will this plane do", "gt answer": "take off(1.00)", "pred answer": "fly", "question_id": 68195, "best approach": "concept", "verif answer": "land", "anno approach": "concept", "verif wiki answer": "land(0.7309)", "verif concept answer": "take off(0.7305)", "verif image answer": "fly(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006819.jpg"}, {"question": "what iconic brand of motorcycle is in the picture", "gt answer": "harley davidson(1.00)", "pred answer": "triumph", "question_id": 5568865, "best approach": "", "verif answer": "triumph", "anno approach": "", "verif wiki answer": "triumph(0.7310)", "verif concept answer": "triumph(0.7310)", "verif image answer": "triumph(0.7121)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556886.jpg"}, {"question": "which holiday does this room seem to celebrate", "gt answer": "christmas(1.00)<br/>valentine's day(0.60)", "pred answer": "christmas", "question_id": 4863095, "best approach": "wiki, concept, image", "verif answer": "christmas", "anno approach": "concept, wiki", "verif wiki answer": "christmas(0.7310)", "verif concept answer": "christmas(0.7256)", "verif image answer": "christmas(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000486309.jpg"}, {"question": "what team is this", "gt answer": "pirate(1.00)<br/>oriole(0.60)<br/>baseball(0.60)<br/>cub(0.60)", "pred answer": "met", "question_id": 5392705, "best approach": "wiki, concept, image", "verif answer": "cub", "anno approach": "wiki", "verif wiki answer": "cub(0.7261)", "verif concept answer": "cub(0.7021)", "verif image answer": "cub(0.6729)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539270.jpg"}, {"question": "what kind of bird is on tv", "gt answer": "hummingbird(1.00)<br/>bluejay(0.60)<br/>robin(0.60)", "pred answer": "pelican", "question_id": 5361755, "best approach": "wiki, image", "verif answer": "hummingbird", "anno approach": "wiki", "verif wiki answer": "hummingbird(0.7310)", "verif concept answer": "cyanocitta cristata(0.7304)", "verif image answer": "hummingbird(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536175.jpg"}, {"question": "what is this room used for", "gt answer": "urine(1.00)<br/>urinate(0.60)<br/>pee(0.60)<br/>bathroom(0.60)", "pred answer": "bath", "question_id": 5817665, "best approach": "", "verif answer": "toilet", "anno approach": "", "verif wiki answer": "toilet(0.7309)", "verif concept answer": "toilet(0.7269)", "verif image answer": "toilet(0.7074)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000581766.jpg"}, {"question": "where is this picture taken", "gt answer": "lake(1.00)<br/>harbor(0.60)<br/>bay(0.60)", "pred answer": "pond", "question_id": 239355, "best approach": "concept, image", "verif answer": "harbor", "anno approach": "image", "verif wiki answer": "alaska(0.6660)", "verif concept answer": "harbor(0.6611)", "verif image answer": "harbor(0.7174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023935.jpg"}, {"question": "what year was this game first played", "gt answer": "1839(1.00)", "pred answer": "1950", "question_id": 3253875, "best approach": "", "verif answer": "1880", "anno approach": "", "verif wiki answer": "1880(0.7310)", "verif concept answer": "1880(0.7310)", "verif image answer": "1880(0.6592)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325387.jpg"}, {"question": "if this woman 's bikini top were not present she would be said to be going what", "gt answer": "topless(1.00)", "pred answer": "swim", "question_id": 3961435, "best approach": "", "verif answer": "google", "anno approach": "", "verif wiki answer": "boy(0.5008)", "verif concept answer": "boy(0.5001)", "verif image answer": "google(0.6844)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396143.jpg"}, {"question": "what type of boat is this", "gt answer": "fish(1.00)", "pred answer": "fish", "question_id": 5546685, "best approach": "concept, image", "verif answer": "fish", "anno approach": "", "verif wiki answer": "fish boat(0.6516)", "verif concept answer": "fish(0.6478)", "verif image answer": "fish(0.6562)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554668.jpg"}, {"question": "what is the average life expectancy for the gender of human pictured here", "gt answer": "80(1.00)<br/>70(0.60)", "pred answer": "10 years", "question_id": 4440785, "best approach": "image", "verif answer": "70", "anno approach": "image", "verif wiki answer": "20(0.6492)", "verif concept answer": "20(0.6439)", "verif image answer": "70(0.6596)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000444078.jpg"}, {"question": "what kind of surfboard is the person riding", "gt answer": "longboard(1.00)<br/>professional(0.60)", "pred answer": "longboard", "question_id": 3095515, "best approach": "", "verif answer": "shortboard", "anno approach": "", "verif wiki answer": "shortboard(0.7064)", "verif concept answer": "shortboard(0.7280)", "verif image answer": "shortboard(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000309551.jpg"}, {"question": "what number is on the jersey of this dodgers player", "gt answer": "47(1.00)", "pred answer": "19", "question_id": 1357945, "best approach": "", "verif answer": "19", "anno approach": "", "verif wiki answer": "19(0.7305)", "verif concept answer": "19(0.7084)", "verif image answer": "15(0.6390)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000135794.jpg"}, {"question": "what religion is in this church", "gt answer": "catholic(1.00)", "pred answer": "hindu", "question_id": 4808185, "best approach": "", "verif answer": "christianity", "anno approach": "", "verif wiki answer": "christianity(0.7307)", "verif concept answer": "christianity(0.7311)", "verif image answer": "christianity(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480818.jpg"}, {"question": "is this a primary color or a pastel that is depicted on the board", "gt answer": "pastel(1.00)<br/>blue(0.60)", "pred answer": "green", "question_id": 2721435, "best approach": "image", "verif answer": "primary", "anno approach": "image", "verif wiki answer": "primary(0.6149)", "verif concept answer": "primary(0.6155)", "verif image answer": "pastel(0.5317)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000272143.jpg"}, {"question": "where did this style of portable tv come from", "gt answer": "sony(1.00)<br/>usa(0.60)", "pred answer": "ikea", "question_id": 4643305, "best approach": "concept, image", "verif answer": "motorola", "anno approach": "", "verif wiki answer": "motorola(0.6894)", "verif concept answer": "sony(0.6276)", "verif image answer": "sony(0.6275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464330.jpg"}, {"question": "what is on her head", "gt answer": "veil(1.00)", "pred answer": "hat", "question_id": 5727895, "best approach": "", "verif answer": "scarf", "anno approach": "", "verif wiki answer": "scarf(0.5706)", "verif concept answer": "hijab(0.5115)", "verif image answer": "hijab(0.5088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572789.jpg"}, {"question": "how many jets are on this type of plane", "gt answer": "4(1.00)<br/>1(1.00)", "pred answer": "2", "question_id": 3965725, "best approach": "concept", "verif answer": "4", "anno approach": "concept", "verif wiki answer": "0(0.6403)", "verif concept answer": "4(0.6583)", "verif image answer": "0(0.6455)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396572.jpg"}, {"question": "what year is this car", "gt answer": "1960(1.00)<br/>1965(0.60)<br/>1940(0.60)", "pred answer": "1950", "question_id": 3078355, "best approach": "wiki, concept", "verif answer": "1946", "anno approach": "wiki", "verif wiki answer": "1940(0.6860)", "verif concept answer": "1940(0.6971)", "verif image answer": "1946(0.7018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307835.jpg"}, {"question": "what medium was this photo taken in", "gt answer": "film(1.00)<br/>camera(0.60)", "pred answer": "black and white", "question_id": 2388165, "best approach": "image", "verif answer": "film", "anno approach": "image", "verif wiki answer": "black and white(0.7061)", "verif concept answer": "black and white(0.5049)", "verif image answer": "film(0.7264)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238816.jpg"}, {"question": "what kind of birds are these", "gt answer": "hum(0.60)<br/>cardinal(1.00)<br/>robin(1.00)", "pred answer": "sparrow", "question_id": 3853425, "best approach": "concept", "verif answer": "finch", "anno approach": "concept", "verif wiki answer": "finch(0.5002)", "verif concept answer": "robin(0.5454)", "verif image answer": "finch(0.6046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385342.jpg"}, {"question": "which country exports the most of the fruit shown in this picture", "gt answer": "guatemala(1.00)<br/>india(0.60)<br/>mexico(0.60)<br/>ecuador(0.60)", "pred answer": "brazil", "question_id": 2027425, "best approach": "image", "verif answer": "india", "anno approach": "image", "verif wiki answer": "india(0.6575)", "verif concept answer": "china(0.6087)", "verif image answer": "guatemala(0.6436)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202742.jpg"}, {"question": "which predators feed on these animals", "gt answer": "lion(1.00)", "pred answer": "lion", "question_id": 3408985, "best approach": "", "verif answer": "feline", "anno approach": "", "verif wiki answer": "feline(0.7311)", "verif concept answer": "feline(0.7311)", "verif image answer": "feline(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340898.jpg"}, {"question": "would the luggage in this photo be considered new or vintage", "gt answer": "vintage(1.00)", "pred answer": "old", "question_id": 5447195, "best approach": "", "verif answer": "old", "anno approach": "", "verif wiki answer": "old(0.7309)", "verif concept answer": "old(0.7304)", "verif image answer": "old(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544719.jpg"}, {"question": "what country is this hair color most common", "gt answer": "ireland(1.00)<br/>scotland(1.00)", "pred answer": "india", "question_id": 600355, "best approach": "wiki, concept, image", "verif answer": "ireland", "anno approach": "wiki", "verif wiki answer": "scotland(0.6454)", "verif concept answer": "ireland(0.6464)", "verif image answer": "ireland(0.6493)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060035.jpg"}, {"question": "what sport are the dogs pictured known for", "gt answer": "hunt(1.00)<br/>race(0.60)", "pred answer": "fetch", "question_id": 2179785, "best approach": "wiki, concept", "verif answer": "race", "anno approach": "wiki", "verif wiki answer": "race(0.6610)", "verif concept answer": "race(0.6408)", "verif image answer": "retrieve(0.5938)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217978.jpg"}, {"question": "what editing tools was used to create this", "gt answer": "photoshop(1.00)<br/>color(0.60)<br/>paint(0.60)", "pred answer": "electricity", "question_id": 4243005, "best approach": "wiki, concept, image", "verif answer": "color", "anno approach": "wiki", "verif wiki answer": "color(0.6970)", "verif concept answer": "color(0.7223)", "verif image answer": "color(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424300.jpg"}]
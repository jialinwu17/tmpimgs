[{"question": "would this dish be served at mcdonald 's or someplace fancier", "gt answer": "someplace fancier(1.00)<br/>restaurant(0.60)", "pred answer": "bakery", "question_id": 2695505, "best approach": "wiki, concept, image", "verif answer": "restaurant", "anno approach": "wiki", "verif wiki answer": "restaurant(0.6957)", "verif concept answer": "restaurant(0.6841)", "verif image answer": "restaurant(0.7094)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269550.jpg"}, {"question": "who took this photo", "gt answer": "dave hayward(1.00)<br/>woman(0.60)<br/>photographer(0.60)", "pred answer": "jockey", "question_id": 4825635, "best approach": "concept, image", "verif answer": "photographer", "anno approach": "", "verif wiki answer": "farmer(0.6609)", "verif concept answer": "photographer(0.6980)", "verif image answer": "photographer(0.6761)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482563.jpg"}, {"question": "which computer accessory is the person touching", "gt answer": "keyboard(1.00)", "pred answer": "computer", "question_id": 3423815, "best approach": "concept", "verif answer": "piano", "anno approach": "concept", "verif wiki answer": "piano(0.7279)", "verif concept answer": "keyboard(0.7303)", "verif image answer": "piano(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342381.jpg"}, {"question": "why is she holding that", "gt answer": "rain(1.00)<br/>umbrella(0.60)<br/>protection(0.60)", "pred answer": "rain", "question_id": 5263625, "best approach": "", "verif answer": "stay dry", "anno approach": "", "verif wiki answer": "stay dry(0.6723)", "verif concept answer": "stay dry(0.6962)", "verif image answer": "stay dry(0.6599)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526362.jpg"}, {"question": "what is the name of this sport in england", "gt answer": "football(1.00)", "pred answer": "soccer", "question_id": 1938245, "best approach": "", "verif answer": "soccer", "anno approach": "", "verif wiki answer": "soccer(0.7093)", "verif concept answer": "soccer(0.7172)", "verif image answer": "sport(0.7038)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193824.jpg"}, {"question": "what type of boards to these people have", "gt answer": "surf(1.00)<br/>surfboard(0.60)<br/>surf board(0.60)", "pred answer": "surf board", "question_id": 389225, "best approach": "wiki, concept", "verif answer": "boogie board", "anno approach": "wiki", "verif wiki answer": "surf board(0.6377)", "verif concept answer": "surf board(0.6183)", "verif image answer": "boogie board(0.6394)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038922.jpg"}, {"question": "how many teeth do these animals have in their mouths", "gt answer": "32(1.00)<br/>20(0.60)<br/>100(0.60)", "pred answer": "4", "question_id": 5719535, "best approach": "wiki, image", "verif answer": "100", "anno approach": "wiki", "verif wiki answer": "20(0.6879)", "verif concept answer": "40(0.6939)", "verif image answer": "100(0.6944)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571953.jpg"}, {"question": "how many times do you wind up a fireman 's hose before it is completely wound up", "gt answer": "50(1.00)<br/>15(0.60)<br/>20(0.60)<br/>100(0.60)", "pred answer": "300", "question_id": 296715, "best approach": "wiki", "verif answer": "50", "anno approach": "wiki", "verif wiki answer": "50(0.7151)", "verif concept answer": "100(0.6793)", "verif image answer": "100(0.6513)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029671.jpg"}, {"question": "what meat do we get from the animal on the front of the food truck", "gt answer": "pork(1.00)<br/>0(0.60)<br/>beef(0.60)", "pred answer": "cow", "question_id": 1363695, "best approach": "wiki, concept, image", "verif answer": "pork", "anno approach": "image, wiki", "verif wiki answer": "pork(0.6489)", "verif concept answer": "pork(0.6638)", "verif image answer": "pork(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136369.jpg"}, {"question": "when the orange items on the trees fall some people like to save them by pressing them into what", "gt answer": "book(1.00)", "pred answer": "scissor", "question_id": 3433195, "best approach": "wiki, concept", "verif answer": "book", "anno approach": "wiki", "verif wiki answer": "book(0.6392)", "verif concept answer": "book(0.6047)", "verif image answer": "shield(0.5924)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343319.jpg"}, {"question": "the fruit eaten by the boy is good for which part of the body", "gt answer": "muscle(1.00)", "pred answer": "muscle", "question_id": 4563025, "best approach": "wiki, concept, image", "verif answer": "muscle", "anno approach": "image, wiki", "verif wiki answer": "muscle(0.6514)", "verif concept answer": "muscle(0.6652)", "verif image answer": "muscle(0.6914)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456302.jpg"}, {"question": "what kind of beer is this", "gt answer": "budweiser(1.00)<br/>dark(0.60)", "pred answer": "budweiser", "question_id": 5473155, "best approach": "wiki, concept, image", "verif answer": "budweiser", "anno approach": "wiki", "verif wiki answer": "budweiser(0.6882)", "verif concept answer": "budweiser(0.6832)", "verif image answer": "budweiser(0.6970)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000547315.jpg"}, {"question": "the red chair that the cat is on is commonly referred to as a what kind of chair", "gt answer": "fold(1.00)<br/>calico(0.60)", "pred answer": "chair", "question_id": 1829955, "best approach": "", "verif answer": "collar", "anno approach": "", "verif wiki answer": "collar(0.7222)", "verif concept answer": "collar(0.7271)", "verif image answer": "collar(0.7190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182995.jpg"}, {"question": "what is the scientific name of those animals", "gt answer": "ovis aries(1.00)<br/>sheep(0.60)<br/>canine(0.60)", "pred answer": "sheep", "question_id": 800305, "best approach": "concept, image", "verif answer": "ovis aries", "anno approach": "", "verif wiki answer": "sheep(0.6134)", "verif concept answer": "ovis aries(0.6351)", "verif image answer": "ovis aries(0.6247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080030.jpg"}, {"question": "what materials were used to make the fake mouse and keyboard", "gt answer": "clay(1.00)<br/>rubber(0.60)", "pred answer": "plastic", "question_id": 3627515, "best approach": "image", "verif answer": "clay", "anno approach": "image", "verif wiki answer": "rubber(0.6165)", "verif concept answer": "rubber(0.6038)", "verif image answer": "clay(0.7138)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362751.jpg"}, {"question": "is it hot or cold in this image", "gt answer": "cold(1.00)", "pred answer": "hot", "question_id": 4576565, "best approach": "concept", "verif answer": "cold", "anno approach": "concept", "verif wiki answer": "hot(0.7145)", "verif concept answer": "cold(0.7221)", "verif image answer": "hot(0.7143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457656.jpg"}, {"question": "what is the breed of this dog", "gt answer": "retriever(1.00)<br/>black lab(0.60)", "pred answer": "labrador", "question_id": 2581765, "best approach": "", "verif answer": "labrador", "anno approach": "", "verif wiki answer": "german shepherd(0.6239)", "verif concept answer": "german shepherd(0.6188)", "verif image answer": "labrador(0.6339)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258176.jpg"}, {"question": "who 's driving the bus", "gt answer": "bus driver(1.00)<br/>man(0.60)", "pred answer": "bus driver", "question_id": 1749095, "best approach": "wiki, concept, image", "verif answer": "bus driver", "anno approach": "wiki", "verif wiki answer": "bus driver(0.7280)", "verif concept answer": "bus driver(0.7286)", "verif image answer": "bus driver(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174909.jpg"}, {"question": "approximately how tall is the building behind the animal shown here", "gt answer": "20 feet(1.00)<br/>30 feet(1.00)", "pred answer": "11 feet", "question_id": 3912165, "best approach": "wiki, concept, image", "verif answer": "20 feet", "anno approach": "", "verif wiki answer": "30 feet(0.6623)", "verif concept answer": "30 feet(0.6599)", "verif image answer": "20 feet(0.6697)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391216.jpg"}, {"question": "what kind of chair is the woman relaxing in", "gt answer": "recliner(1.00)", "pred answer": "sofa", "question_id": 539295, "best approach": "", "verif answer": "couch", "anno approach": "", "verif wiki answer": "couch(0.5822)", "verif concept answer": "couch(0.6320)", "verif image answer": "couch(0.7066)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053929.jpg"}, {"question": "what type of tennis game is this called", "gt answer": "double(1.00)<br/>tennis(0.60)", "pred answer": "swing", "question_id": 5699965, "best approach": "", "verif answer": "men", "anno approach": "", "verif wiki answer": "men(0.6463)", "verif concept answer": "men(0.6733)", "verif image answer": "men(0.6661)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569996.jpg"}, {"question": "what substance is used to clean these windows", "gt answer": "windex(1.00)<br/>water(1.00)", "pred answer": "cloth", "question_id": 658555, "best approach": "wiki, concept", "verif answer": "soap", "anno approach": "wiki", "verif wiki answer": "water(0.5229)", "verif concept answer": "windex(0.5470)", "verif image answer": "soap(0.6597)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065855.jpg"}, {"question": "who invented this device in the second world war", "gt answer": "alan turing(1.00)", "pred answer": "bill gate", "question_id": 4560715, "best approach": "image", "verif answer": "irma s rombauer", "anno approach": "image", "verif wiki answer": "irma s rombauer(0.7254)", "verif concept answer": "irma s rombauer(0.7257)", "verif image answer": "alan turing(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456071.jpg"}, {"question": "what is the purpose of the striped object", "gt answer": "pillow(1.00)<br/>rest(1.00)", "pred answer": "sleep", "question_id": 1580775, "best approach": "image", "verif answer": "pillow", "anno approach": "image", "verif wiki answer": "bed(0.5585)", "verif concept answer": "bed(0.5616)", "verif image answer": "pillow(0.6767)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000158077.jpg"}, {"question": "what kind of gas could be used to fill the balloons", "gt answer": "helium(1.00)", "pred answer": "diesel", "question_id": 2588825, "best approach": "concept, image", "verif answer": "toxoplasmosis", "anno approach": "", "verif wiki answer": "toxoplasmosis(0.5723)", "verif concept answer": "helium(0.5479)", "verif image answer": "helium(0.5559)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258882.jpg"}, {"question": "in this picture what is keeping the kite in the air", "gt answer": "wind(1.00)<br/>string(0.60)", "pred answer": "wind", "question_id": 2655135, "best approach": "wiki, concept, image", "verif answer": "wind", "anno approach": "wiki", "verif wiki answer": "wind(0.6523)", "verif concept answer": "wind(0.6349)", "verif image answer": "wind(0.6544)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265513.jpg"}, {"question": "what is this room used for", "gt answer": "confer(1.00)<br/>meet(1.00)", "pred answer": "work", "question_id": 4005345, "best approach": "image", "verif answer": "work", "anno approach": "image", "verif wiki answer": "work(0.6825)", "verif concept answer": "1950(0.6608)", "verif image answer": "confer(0.6640)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400534.jpg"}, {"question": "what cultures have this as a common meal", "gt answer": "western(1.00)<br/>american(0.60)<br/>french(0.60)", "pred answer": "american", "question_id": 5490985, "best approach": "wiki", "verif answer": "asian", "anno approach": "wiki", "verif wiki answer": "american(0.6823)", "verif concept answer": "asian(0.7011)", "verif image answer": "asian(0.6877)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000549098.jpg"}, {"question": "what does this animal use it 's long appendage for", "gt answer": "drink water(0.60)<br/>grab(1.00)", "pred answer": "tusk", "question_id": 3220955, "best approach": "wiki, concept, image", "verif answer": "drink water", "anno approach": "wiki", "verif wiki answer": "drink water(0.6693)", "verif concept answer": "drink water(0.6529)", "verif image answer": "drink water(0.6302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322095.jpg"}, {"question": "what stunt is this", "gt answer": "jump(1.00)<br/>skateboard(0.60)", "pred answer": "skateboard", "question_id": 3666655, "best approach": "image", "verif answer": "olly", "anno approach": "image", "verif wiki answer": "skate(0.6881)", "verif concept answer": "olly(0.6960)", "verif image answer": "skateboard(0.6829)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366665.jpg"}, {"question": "is this a salad bar or a buffet", "gt answer": "buffet(1.00)", "pred answer": "table", "question_id": 413055, "best approach": "", "verif answer": "bakery", "anno approach": "", "verif wiki answer": "bakery(0.7052)", "verif concept answer": "bakery(0.6806)", "verif image answer": "bakery(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041305.jpg"}, {"question": "name the material used to make these board carried by the people in this picture", "gt answer": "polyurethane(1.00)<br/>plastic(0.60)<br/>wood(0.60)<br/>fiberglass(0.60)", "pred answer": "wood", "question_id": 1625205, "best approach": "wiki, concept, image", "verif answer": "fiberglass", "anno approach": "image, wiki", "verif wiki answer": "fiberglass(0.6671)", "verif concept answer": "fiberglass(0.6695)", "verif image answer": "fiberglass(0.7015)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162520.jpg"}, {"question": "what kind of camera is the man using", "gt answer": "webcam(1.00)", "pred answer": "camera", "question_id": 1942355, "best approach": "image", "verif answer": "webcam", "anno approach": "image", "verif wiki answer": "canon(0.5448)", "verif concept answer": "canon(0.5393)", "verif image answer": "webcam(0.6646)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194235.jpg"}, {"question": "what trick on the skateboard is the man doing", "gt answer": "grind(1.00)<br/>jump(0.60)", "pred answer": "jump", "question_id": 4418585, "best approach": "concept", "verif answer": "jump", "anno approach": "concept", "verif wiki answer": "jump(0.6407)", "verif concept answer": "grind(0.6343)", "verif image answer": "jump(0.7275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441858.jpg"}, {"question": "how is this dish prepared", "gt answer": "oven(1.00)<br/>in oven(0.60)<br/>baked(0.60)", "pred answer": "baked", "question_id": 2149975, "best approach": "image", "verif answer": "in oven", "anno approach": "image", "verif wiki answer": "baked in oven(0.6724)", "verif concept answer": "bake(0.6968)", "verif image answer": "in oven(0.6994)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214997.jpg"}, {"question": "which food item seen here is famous for having good fats", "gt answer": "avocado(1.00)", "pred answer": "hot dog", "question_id": 3474055, "best approach": "wiki, concept, image", "verif answer": "avocado", "anno approach": "concept, wiki", "verif wiki answer": "avocado(0.6719)", "verif concept answer": "avocado(0.6654)", "verif image answer": "avocado(0.6082)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347405.jpg"}, {"question": "what health benefit does the vegetable in this photo promote", "gt answer": "fiber(1.00)<br/>vitamin c(0.60)<br/>vitamin(0.60)", "pred answer": "eye", "question_id": 1841165, "best approach": "wiki, concept", "verif answer": "vitamin", "anno approach": "wiki", "verif wiki answer": "vitamin(0.6182)", "verif concept answer": "vitamin(0.6279)", "verif image answer": "carbohydrate(0.6136)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184116.jpg"}, {"question": "what is a single hanging light fixture called", "gt answer": "chandelier(1.00)<br/>lamp(0.60)", "pred answer": "lava", "question_id": 1519545, "best approach": "", "verif answer": "tiffany", "anno approach": "", "verif wiki answer": "flash(0.5002)", "verif concept answer": "flash(0.5015)", "verif image answer": "tiffany(0.5027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151954.jpg"}, {"question": "where was this picture taken", "gt answer": "train station(1.00)<br/>station(0.60)<br/>india(0.60)", "pred answer": "airport", "question_id": 4265565, "best approach": "wiki, image", "verif answer": "train station", "anno approach": "wiki", "verif wiki answer": "train station(0.7161)", "verif concept answer": "station(0.7106)", "verif image answer": "train station(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426556.jpg"}, {"question": "i wonder where he bought such a colorful umbrella", "gt answer": "amazon(1.00)<br/>store(0.60)<br/>walmart(0.60)", "pred answer": "amazon", "question_id": 3543355, "best approach": "wiki, concept, image", "verif answer": "amazon", "anno approach": "wiki", "verif wiki answer": "amazon(0.7086)", "verif concept answer": "amazon(0.7117)", "verif image answer": "amazon(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354335.jpg"}, {"question": "what sauce is commonly served with this food", "gt answer": "tartar(1.00)", "pred answer": "fish", "question_id": 2157465, "best approach": "wiki", "verif answer": "butter", "anno approach": "wiki", "verif wiki answer": "tartar(0.5801)", "verif concept answer": "butter(0.5962)", "verif image answer": "salad(0.5199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215746.jpg"}, {"question": "name the place where the game is played by the person", "gt answer": "baseball field(1.00)<br/>ballpark(0.60)<br/>stadium(0.60)", "pred answer": "baseball field", "question_id": 5223505, "best approach": "wiki, concept", "verif answer": "baseball field", "anno approach": "wiki", "verif wiki answer": "baseball field(0.7079)", "verif concept answer": "baseball field(0.6805)", "verif image answer": "ballpark(0.6800)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522350.jpg"}, {"question": "how long does this animal live", "gt answer": "50 years(1.00)<br/>60 years(0.60)<br/>100 years(0.60)", "pred answer": "africa", "question_id": 5044545, "best approach": "wiki, concept, image", "verif answer": "100 years", "anno approach": "", "verif wiki answer": "100 years(0.6825)", "verif concept answer": "100 years(0.6676)", "verif image answer": "100 years(0.6536)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000504454.jpg"}, {"question": "what was the purpose of this railroad car", "gt answer": "caboose(1.00)<br/>transport people(0.60)<br/>transport(0.60)", "pred answer": "transportation", "question_id": 3734255, "best approach": "wiki, concept, image", "verif answer": "caboose", "anno approach": "", "verif wiki answer": "caboose(0.6881)", "verif concept answer": "caboose(0.6662)", "verif image answer": "caboose(0.6801)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373425.jpg"}, {"question": "what type of drum is that in the picture", "gt answer": "snare(1.00)<br/>bongo(0.60)<br/>electronic(0.60)", "pred answer": "bunk", "question_id": 2929125, "best approach": "wiki, concept, image", "verif answer": "bongo", "anno approach": "", "verif wiki answer": "bongo(0.7255)", "verif concept answer": "bongo(0.7224)", "verif image answer": "bongo(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292912.jpg"}, {"question": "do you think these are elephants or mammoths", "gt answer": "elephant(1.00)", "pred answer": "both", "question_id": 3310595, "best approach": "", "verif answer": "herbivore", "anno approach": "", "verif wiki answer": "herbivore(0.6897)", "verif concept answer": "herbivore(0.7109)", "verif image answer": "herbivore(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331059.jpg"}, {"question": "what are the strings made from in the rackets", "gt answer": "nylon(1.00)<br/>plastic(0.60)<br/>wire(0.60)", "pred answer": "nylon", "question_id": 2464175, "best approach": "", "verif answer": "foam", "anno approach": "", "verif wiki answer": "foam(0.6370)", "verif concept answer": "foam(0.6358)", "verif image answer": "foam(0.7051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246417.jpg"}, {"question": "what does this sign mean", "gt answer": "park(1.00)<br/>vehicle(0.60)<br/>car(0.60)", "pred answer": "street sign", "question_id": 4269835, "best approach": "wiki, concept, image", "verif answer": "car", "anno approach": "wiki", "verif wiki answer": "car(0.7020)", "verif concept answer": "car(0.6939)", "verif image answer": "car(0.6627)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426983.jpg"}, {"question": "what is this person making", "gt answer": "pottery(1.00)<br/>vase(1.00)<br/>pot(0.60)", "pred answer": "cloth", "question_id": 2445975, "best approach": "wiki, concept, image", "verif answer": "vase", "anno approach": "image, concept, wiki", "verif wiki answer": "vase(0.6067)", "verif concept answer": "vase(0.6993)", "verif image answer": "pottery(0.6381)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244597.jpg"}, {"question": "the objects pictured would most likely store what type of plant", "gt answer": "flower(1.00)<br/>rose(0.60)", "pred answer": "flower", "question_id": 91275, "best approach": "wiki, concept, image", "verif answer": "flower", "anno approach": "wiki", "verif wiki answer": "flower(0.7203)", "verif concept answer": "flower(0.7286)", "verif image answer": "flower(0.7014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009127.jpg"}, {"question": "originating in japan what is this leisure activity called", "gt answer": "karaoke(1.00)", "pred answer": "marriage", "question_id": 3298885, "best approach": "", "verif answer": "football", "anno approach": "", "verif wiki answer": "football(0.7265)", "verif concept answer": "football(0.7297)", "verif image answer": "football(0.7168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329888.jpg"}, {"question": "what is the first name of the famous golfer with the name pictures as his last name", "gt answer": "arnold(1.00)", "pred answer": "john deere", "question_id": 4312405, "best approach": "", "verif answer": "soul surfer", "anno approach": "", "verif wiki answer": "soul surfer(0.7309)", "verif concept answer": "soul surfer(0.7299)", "verif image answer": "soul surfer(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431240.jpg"}, {"question": "what sound that also is a word for masticating is used by infants to signify this vehicle", "gt answer": "chew(1.00)", "pred answer": "track", "question_id": 610485, "best approach": "", "verif answer": "track", "anno approach": "", "verif wiki answer": "track(0.6548)", "verif concept answer": "track(0.6565)", "verif image answer": "indian(0.6261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061048.jpg"}, {"question": "why 's his dog wearing clouths", "gt answer": "warmth(1.00)<br/>christmas(0.60)<br/>party(0.60)", "pred answer": "relax", "question_id": 364395, "best approach": "concept", "verif answer": "party", "anno approach": "concept", "verif wiki answer": "party(0.5001)", "verif concept answer": "warmth(0.5001)", "verif image answer": "party(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036439.jpg"}, {"question": "where are double decker buses used", "gt answer": "city(1.00)<br/>london(0.60)<br/>tour(0.60)<br/>england(0.60)", "pred answer": "work", "question_id": 3616725, "best approach": "wiki, concept, image", "verif answer": "city", "anno approach": "wiki", "verif wiki answer": "city(0.6707)", "verif concept answer": "city(0.6907)", "verif image answer": "city(0.6808)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361672.jpg"}, {"question": "what type of suit is the lady wearing", "gt answer": "bikini(1.00)<br/>swim(0.60)", "pred answer": "wet suit", "question_id": 4173505, "best approach": "", "verif answer": "boogie board", "anno approach": "", "verif wiki answer": "boogie board(0.7152)", "verif concept answer": "boogie board(0.7244)", "verif image answer": "wetsuit(0.6755)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417350.jpg"}, {"question": "what might be in the drawers of this picture", "gt answer": "utensil(1.00)<br/>food(0.60)", "pred answer": "dish", "question_id": 727155, "best approach": "wiki, concept, image", "verif answer": "utensil", "anno approach": "wiki", "verif wiki answer": "utensil(0.7304)", "verif concept answer": "utensil(0.7309)", "verif image answer": "utensil(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072715.jpg"}, {"question": "what type of laptop is being used", "gt answer": "acer(1.00)<br/>dell(0.60)<br/>hp(0.60)", "pred answer": "dell", "question_id": 3374905, "best approach": "", "verif answer": "logitech", "anno approach": "", "verif wiki answer": "logitech(0.6780)", "verif concept answer": "ibm(0.6749)", "verif image answer": "logitech(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337490.jpg"}, {"question": "the color of the bus is the same color scheme for what fast food restaurant", "gt answer": "mcdonalds(1.00)<br/>mcdonald's(0.60)", "pred answer": "green", "question_id": 4680975, "best approach": "", "verif answer": "wooden", "anno approach": "", "verif wiki answer": "wooden(0.5926)", "verif concept answer": "wooden(0.6352)", "verif image answer": "wooden(0.5802)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000468097.jpg"}, {"question": "is the creature in this photo nocturnal or diurnal", "gt answer": "diurnal(1.00)<br/>nocturnal(1.00)<br/>both(0.60)", "pred answer": "healthy", "question_id": 2941085, "best approach": "wiki, image", "verif answer": "diurnal", "anno approach": "", "verif wiki answer": "diurnal(0.7301)", "verif concept answer": "normal(0.7306)", "verif image answer": "diurnal(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000294108.jpg"}, {"question": "what breed of cow is this", "gt answer": "holstein(1.00)<br/>jersey(0.60)", "pred answer": "angus", "question_id": 927815, "best approach": "image", "verif answer": "angus", "anno approach": "image", "verif wiki answer": "angus(0.6925)", "verif concept answer": "angus(0.6859)", "verif image answer": "jersey(0.6782)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092781.jpg"}, {"question": "what are those stairs outside the window", "gt answer": "fire escape(1.00)", "pred answer": "backsplash", "question_id": 881925, "best approach": "image", "verif answer": "5 million", "anno approach": "image", "verif wiki answer": "5 million(0.7161)", "verif concept answer": "5 million(0.6326)", "verif image answer": "fire escape(0.7033)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088192.jpg"}, {"question": "can you name the piece of furniture on the left side of the photo", "gt answer": "bookcase(1.00)<br/>bookshelf(0.60)", "pred answer": "shelf", "question_id": 26085, "best approach": "", "verif answer": "clock", "anno approach": "", "verif wiki answer": "clock(0.6974)", "verif concept answer": "clock(0.7189)", "verif image answer": "clock(0.6999)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002608.jpg"}, {"question": "what type of train is in the image", "gt answer": "cargo(1.00)<br/>freight(1.00)<br/>locomotive(0.60)", "pred answer": "freight", "question_id": 1989535, "best approach": "image", "verif answer": "freight", "anno approach": "image", "verif wiki answer": "tanker(0.6977)", "verif concept answer": "tanker(0.6679)", "verif image answer": "freight(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198953.jpg"}, {"question": "is this a real scene or a painting", "gt answer": "real(1.00)<br/>paint(0.60)", "pred answer": "real", "question_id": 5415365, "best approach": "wiki, image", "verif answer": "fake", "anno approach": "wiki", "verif wiki answer": "real(0.6674)", "verif concept answer": "fake(0.6849)", "verif image answer": "real(0.6205)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541536.jpg"}, {"question": "what fabric is that bedspread made from", "gt answer": "silk(1.00)", "pred answer": "quilt", "question_id": 2094095, "best approach": "wiki", "verif answer": "fluffy", "anno approach": "wiki", "verif wiki answer": "silk(0.6626)", "verif concept answer": "fluffy(0.5518)", "verif image answer": "fluffy(0.7282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209409.jpg"}, {"question": "what type of squash is used in this dish", "gt answer": "zucchini(1.00)<br/>yellow(0.60)<br/>white(0.60)", "pred answer": "green", "question_id": 4467095, "best approach": "wiki, concept, image", "verif answer": "zucchini", "anno approach": "", "verif wiki answer": "zucchini(0.6602)", "verif concept answer": "zucchini(0.6605)", "verif image answer": "zucchini(0.6526)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000446709.jpg"}, {"question": "in what country would you find this bus", "gt answer": "united kingdom(1.00)<br/>england(1.00)<br/>london(0.60)", "pred answer": "england", "question_id": 5734855, "best approach": "wiki, image", "verif answer": "england", "anno approach": "wiki", "verif wiki answer": "england(0.6911)", "verif concept answer": "spain(0.6964)", "verif image answer": "england(0.7008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000573485.jpg"}, {"question": "what kind of garnish is on top of this dish", "gt answer": "basil(1.00)<br/>spinach(0.60)", "pred answer": "spinach", "question_id": 5447055, "best approach": "wiki, concept", "verif answer": "basil", "anno approach": "wiki", "verif wiki answer": "basil(0.6732)", "verif concept answer": "basil(0.6736)", "verif image answer": "spinach(0.6412)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544705.jpg"}, {"question": "how much weight can each chair on this ski lift support", "gt answer": "500 lbs(1.00)<br/>500 pounds(0.60)", "pred answer": "lot", "question_id": 4059645, "best approach": "wiki, concept", "verif answer": "500 pounds", "anno approach": "wiki", "verif wiki answer": "500 lbs(0.5812)", "verif concept answer": "500 lbs(0.5684)", "verif image answer": "500 pounds(0.6842)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405964.jpg"}, {"question": "what do people typically call this type of bread", "gt answer": "pita(1.00)<br/>tortilla(1.00)", "pred answer": "sub", "question_id": 2637105, "best approach": "", "verif answer": "glazed", "anno approach": "", "verif wiki answer": "glazed(0.5503)", "verif concept answer": "glazed(0.5198)", "verif image answer": "glazed(0.5912)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263710.jpg"}, {"question": "what makes the green vegetable on the plate green", "gt answer": "chlorophyll(1.00)<br/>broccoli(0.60)", "pred answer": "chlorophyll", "question_id": 423845, "best approach": "wiki, concept, image", "verif answer": "chlorophyll", "anno approach": "wiki", "verif wiki answer": "chlorophyll(0.6946)", "verif concept answer": "chlorophyll(0.6918)", "verif image answer": "chlorophyll(0.7103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042384.jpg"}, {"question": "what are these machines used for", "gt answer": "compute(1.00)<br/>work(0.60)<br/>type(0.60)", "pred answer": "compute", "question_id": 732265, "best approach": "wiki, concept, image", "verif answer": "compute", "anno approach": "wiki", "verif wiki answer": "compute(0.7073)", "verif concept answer": "compute(0.6983)", "verif image answer": "compute(0.6723)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073226.jpg"}, {"question": "what kind of worker would clean up the paper towels", "gt answer": "janitor(1.00)", "pred answer": "pet", "question_id": 454685, "best approach": "concept", "verif answer": "bleach", "anno approach": "concept", "verif wiki answer": "bleach(0.7198)", "verif concept answer": "janitor(0.7250)", "verif image answer": "bleach(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045468.jpg"}, {"question": "what kind of weather is this", "gt answer": "snowy(1.00)<br/>rainy(1.00)<br/>winter(0.60)", "pred answer": "cold", "question_id": 3100535, "best approach": "", "verif answer": "cold", "anno approach": "", "verif wiki answer": "cold(0.6781)", "verif concept answer": "cold(0.6877)", "verif image answer": "fall(0.6819)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310053.jpg"}, {"question": "name the brand of the bicycle shown in this picture", "gt answer": "schwinn(1.00)", "pred answer": "honda", "question_id": 2569815, "best approach": "image", "verif answer": "bmx", "anno approach": "image", "verif wiki answer": "bmx(0.6791)", "verif concept answer": "bmx(0.6725)", "verif image answer": "schwinn(0.6564)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256981.jpg"}, {"question": "what position is the man in green playing", "gt answer": "referee(1.00)", "pred answer": "goalie", "question_id": 542955, "best approach": "", "verif answer": "umpire", "anno approach": "", "verif wiki answer": "umpire(0.6947)", "verif concept answer": "judge(0.6815)", "verif image answer": "umpire(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054295.jpg"}, {"question": "what is one thing this animal is rumored never to do", "gt answer": "forget(1.00)<br/>fly(0.60)", "pred answer": "walk", "question_id": 1200065, "best approach": "concept, image", "verif answer": "fly", "anno approach": "", "verif wiki answer": "jump(0.7265)", "verif concept answer": "fly(0.7277)", "verif image answer": "fly(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000120006.jpg"}, {"question": "what kind of wires", "gt answer": "power line(1.00)<br/>electric(1.00)<br/>overhead(0.60)", "pred answer": "electric", "question_id": 4499025, "best approach": "wiki, concept, image", "verif answer": "electric", "anno approach": "image, wiki", "verif wiki answer": "electric(0.6543)", "verif concept answer": "electric(0.6408)", "verif image answer": "electric(0.6858)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449902.jpg"}, {"question": "what is the average life expectancy of the animal seen here", "gt answer": "60 years(1.00)<br/>25 years(0.60)<br/>50 years(0.60)", "pred answer": "25 years", "question_id": 1572215, "best approach": "image", "verif answer": "100 years", "anno approach": "image", "verif wiki answer": "100 years(0.6537)", "verif concept answer": "100 years(0.6522)", "verif image answer": "60 years(0.5861)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157221.jpg"}, {"question": "where is the animal from", "gt answer": "north pole(1.00)<br/>alaska(0.60)<br/>artic(0.60)", "pred answer": "north pole", "question_id": 5419115, "best approach": "wiki, concept, image", "verif answer": "north pole", "anno approach": "wiki", "verif wiki answer": "north pole(0.7166)", "verif concept answer": "north pole(0.7129)", "verif image answer": "north pole(0.7112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541911.jpg"}, {"question": "what sport is being simulated", "gt answer": "box(1.00)<br/>bowl(0.60)<br/>dance(0.60)", "pred answer": "wii", "question_id": 4212415, "best approach": "", "verif answer": "wii", "anno approach": "", "verif wiki answer": "wii(0.6778)", "verif concept answer": "wii(0.6760)", "verif image answer": "wii(0.6201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421241.jpg"}, {"question": "what type of shirt is the man on the right wearing", "gt answer": "button up(1.00)<br/>button down(0.60)", "pred answer": "t shirt", "question_id": 605935, "best approach": "", "verif answer": "flannel", "anno approach": "", "verif wiki answer": "flannel(0.6888)", "verif concept answer": "flannel(0.6827)", "verif image answer": "flannel(0.6971)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060593.jpg"}, {"question": "what is in the field in the background", "gt answer": "cow(1.00)<br/>pasture(0.60)<br/>horse(0.60)", "pred answer": "fence", "question_id": 4619145, "best approach": "wiki, concept, image", "verif answer": "cow", "anno approach": "image, wiki", "verif wiki answer": "cow(0.6599)", "verif concept answer": "cow(0.6189)", "verif image answer": "cow(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461914.jpg"}, {"question": "what is contained within the large grey box under the tree", "gt answer": "trash(1.00)<br/>electricity(0.60)", "pred answer": "coin", "question_id": 5548155, "best approach": "", "verif answer": "pool", "anno approach": "", "verif wiki answer": "pool(0.7007)", "verif concept answer": "pool(0.7103)", "verif image answer": "pool(0.7282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554815.jpg"}, {"question": "what airline is advertised on the van", "gt answer": "southwest(1.00)<br/>american(0.60)", "pred answer": "american", "question_id": 4192975, "best approach": "wiki, concept, image", "verif answer": "southwest", "anno approach": "wiki", "verif wiki answer": "southwest(0.7139)", "verif concept answer": "southwest(0.7034)", "verif image answer": "southwest(0.7258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419297.jpg"}, {"question": "where would the camera need to be to get this shot", "gt answer": "above(1.00)<br/>in air(0.60)<br/>overhead(0.60)", "pred answer": "mountain", "question_id": 1663765, "best approach": "wiki, concept, image", "verif answer": "in air", "anno approach": "concept, wiki", "verif wiki answer": "in air(0.6737)", "verif concept answer": "in air(0.6840)", "verif image answer": "in air(0.6404)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166376.jpg"}, {"question": "you should never drive while using what electronic", "gt answer": "phone(1.00)<br/>cellphone(0.60)", "pred answer": "right", "question_id": 2383455, "best approach": "", "verif answer": "smartphone", "anno approach": "", "verif wiki answer": "cell phone(0.6860)", "verif concept answer": "cell phone(0.7090)", "verif image answer": "smartphone(0.7175)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238345.jpg"}, {"question": "in what kind of structure are the people sitting in", "gt answer": "tent(1.00)", "pred answer": "tent", "question_id": 4281265, "best approach": "wiki, concept, image", "verif answer": "tent", "anno approach": "wiki", "verif wiki answer": "tent(0.6614)", "verif concept answer": "tent(0.6613)", "verif image answer": "tent(0.6442)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428126.jpg"}, {"question": "what type of brightly colored bird is this", "gt answer": "peacock(1.00)", "pred answer": "stork", "question_id": 918585, "best approach": "wiki, concept, image", "verif answer": "peacock", "anno approach": "wiki", "verif wiki answer": "peacock(0.7195)", "verif concept answer": "peacock(0.7227)", "verif image answer": "peacock(0.7202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000091858.jpg"}, {"question": "are these saltwater or freshwater fish", "gt answer": "saltwater(1.00)", "pred answer": "fresh", "question_id": 2315425, "best approach": "", "verif answer": "ocean", "anno approach": "", "verif wiki answer": "ocean(0.7280)", "verif concept answer": "lake(0.7142)", "verif image answer": "ocean(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231542.jpg"}, {"question": "what chemical sorrounds these people", "gt answer": "air(1.00)<br/>oxygen(1.00)<br/>bag(0.60)", "pred answer": "gas", "question_id": 2478265, "best approach": "", "verif answer": "helium", "anno approach": "", "verif wiki answer": "helium(0.5964)", "verif concept answer": "helium(0.6523)", "verif image answer": "helium(0.5622)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247826.jpg"}, {"question": "what type of scissors are these", "gt answer": "safety(0.60)<br/>craft(1.00)", "pred answer": "scissor", "question_id": 4451035, "best approach": "wiki, concept, image", "verif answer": "safety", "anno approach": "image, concept, wiki", "verif wiki answer": "safety(0.5368)", "verif concept answer": "safety(0.6440)", "verif image answer": "safety(0.5903)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445103.jpg"}, {"question": "what is the machine in the front of the train cars called", "gt answer": "locomotive(1.00)<br/>engine(0.60)<br/>tractor(0.60)", "pred answer": "steam", "question_id": 1639335, "best approach": "wiki, concept, image", "verif answer": "tractor", "anno approach": "concept", "verif wiki answer": "tractor(0.6464)", "verif concept answer": "tractor(0.6778)", "verif image answer": "tractor(0.6278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163933.jpg"}, {"question": "what type of coffee is that", "gt answer": "espresso(1.00)<br/>hot(0.60)<br/>latte(0.60)", "pred answer": "latte", "question_id": 1432585, "best approach": "wiki, concept", "verif answer": "espresso", "anno approach": "wiki", "verif wiki answer": "espresso(0.7185)", "verif concept answer": "espresso(0.7268)", "verif image answer": "latte(0.6679)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143258.jpg"}, {"question": "what type of picture might she be taking", "gt answer": "selfie(1.00)", "pred answer": "phone", "question_id": 4842775, "best approach": "image", "verif answer": "selfie", "anno approach": "image", "verif wiki answer": "candid(0.6296)", "verif concept answer": "candid(0.6063)", "verif image answer": "selfie(0.6572)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484277.jpg"}, {"question": "what kind of chips are these", "gt answer": "potato(1.00)<br/>ruffle(0.60)", "pred answer": "fish", "question_id": 2636235, "best approach": "", "verif answer": "cracker", "anno approach": "", "verif wiki answer": "cracker(0.7229)", "verif concept answer": "cracker(0.7233)", "verif image answer": "cracker(0.6910)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263623.jpg"}, {"question": "what is attached to the truck", "gt answer": "trailer(1.00)", "pred answer": "ladder", "question_id": 784685, "best approach": "", "verif answer": "shelter", "anno approach": "", "verif wiki answer": "shelter(0.6998)", "verif concept answer": "shelter(0.7152)", "verif image answer": "shelter(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078468.jpg"}, {"question": "chemically what kind of water is in the picture", "gt answer": "salt(1.00)<br/>h2o(0.60)<br/>ocean(0.60)", "pred answer": "ocean", "question_id": 835275, "best approach": "wiki, concept, image", "verif answer": "salt", "anno approach": "wiki", "verif wiki answer": "salt(0.7221)", "verif concept answer": "salt(0.7125)", "verif image answer": "salt(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083527.jpg"}, {"question": "what is the focus of the people in the room", "gt answer": "television(1.00)<br/>tv(1.00)<br/>watch tv(0.60)", "pred answer": "party", "question_id": 680535, "best approach": "", "verif answer": "bed", "anno approach": "", "verif wiki answer": "bed(0.5954)", "verif concept answer": "bed(0.5966)", "verif image answer": "bed(0.5912)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068053.jpg"}, {"question": "", "gt answer": "sponsor(0.60)<br/>advertising(0.60)<br/>advertiser(0.60)", "pred answer": "bat", "question_id": 3436915, "best approach": "", "verif answer": "hit ball", "anno approach": "", "verif wiki answer": "hit ball(0.7143)", "verif concept answer": "hit ball(0.7038)", "verif image answer": "hit ball(0.7076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343691.jpg"}, {"question": "what type of cow is that", "gt answer": "angus(1.00)<br/>jersey(0.60)<br/>dairy(0.60)<br/>holstein(0.60)", "pred answer": "holstein", "question_id": 5560575, "best approach": "wiki, concept", "verif answer": "jersey", "anno approach": "wiki", "verif wiki answer": "angus(0.7034)", "verif concept answer": "angus(0.7052)", "verif image answer": "jersey(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556057.jpg"}, {"question": "are these pumpkins or manderines", "gt answer": "manderines(1.00)<br/>pumpkin(0.60)<br/>mandarin(0.60)", "pred answer": "orange", "question_id": 2235995, "best approach": "wiki, concept, image", "verif answer": "manderines", "anno approach": "", "verif wiki answer": "manderines(0.7308)", "verif concept answer": "manderines(0.7309)", "verif image answer": "manderines(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223599.jpg"}, {"question": "what is the name of this snowboard stunt", "gt answer": "360(1.00)<br/>olly(0.60)<br/>half pipe(0.60)", "pred answer": "jump", "question_id": 5250855, "best approach": "wiki, concept, image", "verif answer": "olly", "anno approach": "wiki", "verif wiki answer": "olly(0.6746)", "verif concept answer": "half pipe(0.6330)", "verif image answer": "half pipe(0.6580)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525085.jpg"}, {"question": "what did the boy on the mound do", "gt answer": "pitch(1.00)<br/>throw(0.60)", "pred answer": "hit ball", "question_id": 1559955, "best approach": "", "verif answer": "catch", "anno approach": "", "verif wiki answer": "catch(0.7234)", "verif concept answer": "catch(0.7192)", "verif image answer": "baseball(0.7088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155995.jpg"}, {"question": "what possible events is the aircraft in the picture engaged in", "gt answer": "taxi(1.00)<br/>land(0.60)<br/>takeoff(0.60)", "pred answer": "fly", "question_id": 5297805, "best approach": "wiki, concept, image", "verif answer": "land", "anno approach": "wiki", "verif wiki answer": "land(0.7272)", "verif concept answer": "land(0.7261)", "verif image answer": "land(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529780.jpg"}, {"question": "what baseball teams are playing", "gt answer": "little league(1.00)<br/>kid(0.60)", "pred answer": "yankees", "question_id": 5159285, "best approach": "wiki, concept", "verif answer": "kid", "anno approach": "wiki", "verif wiki answer": "little league(0.7169)", "verif concept answer": "little league(0.7128)", "verif image answer": "kid(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515928.jpg"}, {"question": "what brand jeans is the woman wearing", "gt answer": "lee(1.00)<br/>denim(0.60)<br/>levi(0.60)", "pred answer": "levis", "question_id": 261325, "best approach": "", "verif answer": "levis", "anno approach": "", "verif wiki answer": "levis(0.7213)", "verif concept answer": "levis(0.7109)", "verif image answer": "levis(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000026132.jpg"}, {"question": "what sport is this", "gt answer": "disc golf(1.00)", "pred answer": "disc golf", "question_id": 63805, "best approach": "wiki, concept", "verif answer": "disc golf", "anno approach": "wiki", "verif wiki answer": "disc golf(0.7209)", "verif concept answer": "disc golf(0.6835)", "verif image answer": "tennis(0.6880)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006380.jpg"}, {"question": "why are there so many scissors", "gt answer": "artwork(1.00)<br/>art(0.60)", "pred answer": "stab", "question_id": 3911025, "best approach": "", "verif answer": "stopped", "anno approach": "", "verif wiki answer": "stopped(0.6766)", "verif concept answer": "stopped(0.6694)", "verif image answer": "stopped(0.6622)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391102.jpg"}, {"question": "what are displayed on the tv screens", "gt answer": "screensaver(1.00)<br/>screen saver(0.60)", "pred answer": "type", "question_id": 5576785, "best approach": "wiki, concept", "verif answer": "dell", "anno approach": "", "verif wiki answer": "screensaver(0.6912)", "verif concept answer": "screensaver(0.6665)", "verif image answer": "dell(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557678.jpg"}, {"question": "what brand snowboard is this", "gt answer": "burton(1.00)<br/>oakley(0.60)", "pred answer": "burton", "question_id": 2463185, "best approach": "wiki, concept, image", "verif answer": "burton", "anno approach": "image, wiki", "verif wiki answer": "burton(0.6465)", "verif concept answer": "burton(0.6482)", "verif image answer": "burton(0.6800)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246318.jpg"}, {"question": "what are they using for shade here", "gt answer": "umbrella(1.00)", "pred answer": "umbrella", "question_id": 1747945, "best approach": "wiki, concept, image", "verif answer": "umbrella", "anno approach": "image, wiki", "verif wiki answer": "umbrella(0.7177)", "verif concept answer": "umbrella(0.6867)", "verif image answer": "umbrella(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174794.jpg"}, {"question": "what type of features does the background animal have", "gt answer": "long neck(1.00)<br/>spot(1.00)", "pred answer": "neck", "question_id": 3588745, "best approach": "", "verif answer": "cracked", "anno approach": "", "verif wiki answer": "cracked(0.6911)", "verif concept answer": "cracked(0.7111)", "verif image answer": "neck(0.6924)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358874.jpg"}, {"question": "what kind of plant is sitting closest to the street", "gt answer": "banana(1.00)<br/>aloe(0.60)", "pred answer": "pine tree", "question_id": 2308645, "best approach": "", "verif answer": "south america", "anno approach": "", "verif wiki answer": "south america(0.5616)", "verif concept answer": "south america(0.5618)", "verif image answer": "south america(0.5220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000230864.jpg"}, {"question": "how was this picture made", "gt answer": "puzzle(1.00)", "pred answer": "watch", "question_id": 897535, "best approach": "wiki, concept", "verif answer": "puzzle", "anno approach": "wiki", "verif wiki answer": "puzzle(0.6493)", "verif concept answer": "puzzle(0.5128)", "verif image answer": "photoshop(0.5469)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089753.jpg"}, {"question": "what type of oven is this", "gt answer": "convection(1.00)<br/>industrial(0.60)<br/>microwave(0.60)<br/>kitchen(0.60)", "pred answer": "convection", "question_id": 2030355, "best approach": "wiki, concept, image", "verif answer": "kitchen", "anno approach": "wiki", "verif wiki answer": "industrial(0.7077)", "verif concept answer": "kitchen(0.7109)", "verif image answer": "kitchen(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203035.jpg"}, {"question": "which movie featured a man in this position telling his life story to strangers", "gt answer": "forrest gump(1.00)<br/>forest gump(0.60)", "pred answer": "cloth", "question_id": 5105, "best approach": "wiki, concept", "verif answer": "forrest gump", "anno approach": "wiki", "verif wiki answer": "forrest gump(0.6690)", "verif concept answer": "forrest gump(0.6310)", "verif image answer": "0(0.6318)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000510.jpg"}, {"question": "who is credited with inventing this item", "gt answer": "steve job(1.00)<br/>thomas edison(0.60)<br/>martin cooper(0.60)", "pred answer": "rayban", "question_id": 54305, "best approach": "wiki, concept, image", "verif answer": "martin cooper", "anno approach": "", "verif wiki answer": "martin cooper(0.6333)", "verif concept answer": "martin cooper(0.6505)", "verif image answer": "martin cooper(0.6396)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005430.jpg"}, {"question": "what kind of bird is this", "gt answer": "finch(1.00)<br/>pigeon(0.60)<br/>sparrow(0.60)<br/>robin(0.60)", "pred answer": "finch", "question_id": 2330395, "best approach": "wiki", "verif answer": "sparrow", "anno approach": "wiki", "verif wiki answer": "finch(0.5664)", "verif concept answer": "sparrow(0.6261)", "verif image answer": "sparrow(0.6021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233039.jpg"}, {"question": "what company makes this man 's sneakers", "gt answer": "converse(1.00)", "pred answer": "adidas", "question_id": 2969465, "best approach": "", "verif answer": "nike", "anno approach": "", "verif wiki answer": "nike(0.5900)", "verif concept answer": "nike(0.5621)", "verif image answer": "nike(0.6249)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296946.jpg"}, {"question": "what type of pot is the bread being cooked on", "gt answer": "skillet(1.00)<br/>iron(0.60)<br/>metal(0.60)", "pred answer": "pan", "question_id": 515255, "best approach": "", "verif answer": "silver", "anno approach": "", "verif wiki answer": "silver(0.6695)", "verif concept answer": "silver(0.6974)", "verif image answer": "silver(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000051525.jpg"}, {"question": "how is the side item cooked", "gt answer": "toasted(1.00)<br/>fast(0.60)", "pred answer": "grilled", "question_id": 5770875, "best approach": "wiki, concept, image", "verif answer": "toasted", "anno approach": "concept, wiki", "verif wiki answer": "toasted(0.6586)", "verif concept answer": "toasted(0.6328)", "verif image answer": "toasted(0.5892)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000577087.jpg"}, {"question": "what kind of coat is the skier wearing", "gt answer": "ski jacket(1.00)<br/>ski(0.60)", "pred answer": "nylon", "question_id": 691695, "best approach": "wiki, concept", "verif answer": "downhill", "anno approach": "wiki", "verif wiki answer": "ski jacket(0.6497)", "verif concept answer": "ski jacket(0.6516)", "verif image answer": "downhill(0.6733)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069169.jpg"}, {"question": "what color is the gazebo", "gt answer": "white(1.00)<br/>green(0.60)", "pred answer": "white", "question_id": 5094855, "best approach": "concept, image", "verif answer": "white", "anno approach": "", "verif wiki answer": "red(0.6420)", "verif concept answer": "white(0.6501)", "verif image answer": "white(0.6441)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509485.jpg"}, {"question": "what is the tall item for", "gt answer": "lighthouse(1.00)<br/>tell time(0.60)", "pred answer": "clock", "question_id": 2329105, "best approach": "wiki, concept, image", "verif answer": "lighthouse", "anno approach": "image, wiki", "verif wiki answer": "lighthouse(0.6960)", "verif concept answer": "lighthouse(0.6127)", "verif image answer": "lighthouse(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232910.jpg"}, {"question": "what does he hope the umpire says after he does this", "gt answer": "strike(1.00)", "pred answer": "first base", "question_id": 200905, "best approach": "wiki, concept, image", "verif answer": "strike", "anno approach": "concept, wiki", "verif wiki answer": "strike(0.5382)", "verif concept answer": "strike(0.5611)", "verif image answer": "strike(0.5092)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020090.jpg"}, {"question": "is this a city or country picture", "gt answer": "city(1.00)", "pred answer": "urban", "question_id": 99995, "best approach": "", "verif answer": "india", "anno approach": "", "verif wiki answer": "urban(0.6822)", "verif concept answer": "india(0.6976)", "verif image answer": "india(0.6623)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009999.jpg"}, {"question": "how is the side item cooked", "gt answer": "boiled(1.00)<br/>grilled(0.60)", "pred answer": "grilled", "question_id": 1599245, "best approach": "concept", "verif answer": "raw", "anno approach": "concept", "verif wiki answer": "raw(0.6425)", "verif concept answer": "grilled(0.6234)", "verif image answer": "raw(0.6296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159924.jpg"}, {"question": "how does this machine move", "gt answer": "electricity(1.00)<br/>engine(0.60)<br/>track(0.60)", "pred answer": "engine", "question_id": 3697625, "best approach": "wiki, concept", "verif answer": "engine", "anno approach": "wiki", "verif wiki answer": "engine(0.7234)", "verif concept answer": "engine(0.6543)", "verif image answer": "cable(0.6711)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369762.jpg"}, {"question": "is there a traffic accident causing all this traffic or is it just rush hour", "gt answer": "rush hour(1.00)", "pred answer": "normal", "question_id": 4247055, "best approach": "wiki, concept, image", "verif answer": "rush hour", "anno approach": "image, wiki", "verif wiki answer": "rush hour(0.6023)", "verif concept answer": "rush hour(0.5489)", "verif image answer": "rush hour(0.6483)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424705.jpg"}, {"question": "how long must this dish cook", "gt answer": "1 hour(1.00)<br/>15 minutes(0.60)", "pred answer": "1 hour", "question_id": 5017235, "best approach": "image", "verif answer": "6 hours", "anno approach": "image", "verif wiki answer": "6 hours(0.6728)", "verif concept answer": "6 hours(0.6498)", "verif image answer": "15 minutes(0.5565)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501723.jpg"}, {"question": "what kind of people ride in this", "gt answer": "commuter(1.00)<br/>train(0.60)", "pred answer": "passenger", "question_id": 3930865, "best approach": "image", "verif answer": "commuter", "anno approach": "image", "verif wiki answer": "first(0.5001)", "verif concept answer": "first(0.5003)", "verif image answer": "commuter(0.5078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393086.jpg"}, {"question": "what profession does this for a living", "gt answer": "computer repair(1.00)", "pred answer": "chef", "question_id": 2828285, "best approach": "concept", "verif answer": "chef", "anno approach": "concept", "verif wiki answer": "type(0.5136)", "verif concept answer": "computer repair(0.5073)", "verif image answer": "chef(0.6150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282828.jpg"}, {"question": "what is the name of the small purple flowers in this arrangement", "gt answer": "violet(1.00)<br/>lavender(0.60)<br/>rose(0.60)", "pred answer": "tulip", "question_id": 5579875, "best approach": "wiki", "verif answer": "violet", "anno approach": "wiki", "verif wiki answer": "violet(0.7286)", "verif concept answer": "tulip(0.7247)", "verif image answer": "tulip(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557987.jpg"}, {"question": "what is the largest one of this type of waterway", "gt answer": "panama canal(1.00)<br/>sea(0.60)<br/>river(0.60)", "pred answer": "canal", "question_id": 2953105, "best approach": "", "verif answer": "canal", "anno approach": "", "verif wiki answer": "canal(0.6938)", "verif concept answer": "pacific ocean(0.7003)", "verif image answer": "canal(0.7063)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295310.jpg"}, {"question": "what type of car is in this photo", "gt answer": "sedan(1.00)<br/>nissan(0.60)<br/>bmw(0.60)", "pred answer": "jeep", "question_id": 2234815, "best approach": "image", "verif answer": "mercedes", "anno approach": "image", "verif wiki answer": "mercedes(0.7216)", "verif concept answer": "bmw(0.7125)", "verif image answer": "sedan(0.7157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223481.jpg"}, {"question": "what is the materal these horses are baked with called", "gt answer": "fondant(1.00)<br/>dough(1.00)<br/>clay(0.60)", "pred answer": "frost", "question_id": 4309255, "best approach": "wiki, concept, image", "verif answer": "fondant", "anno approach": "wiki", "verif wiki answer": "fondant(0.7030)", "verif concept answer": "fondant(0.7098)", "verif image answer": "fondant(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430925.jpg"}, {"question": "is the cooking range gas or electric", "gt answer": "electric(1.00)<br/>gas(0.60)", "pred answer": "electric", "question_id": 2030345, "best approach": "image", "verif answer": "electric", "anno approach": "image", "verif wiki answer": "diesel(0.7190)", "verif concept answer": "gas(0.6149)", "verif image answer": "electric(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203034.jpg"}, {"question": "is this a clean or a messy workstation", "gt answer": "messy(1.00)<br/>clean(1.00)", "pred answer": "clean", "question_id": 5614795, "best approach": "", "verif answer": "wash", "anno approach": "", "verif wiki answer": "wash(0.7154)", "verif concept answer": "wash(0.7042)", "verif image answer": "wash(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561479.jpg"}, {"question": "how much can this animal weigh", "gt answer": "2 tons(1.00)<br/>ton(0.60)", "pred answer": "lot", "question_id": 1297815, "best approach": "wiki, concept", "verif answer": "1000 lbs", "anno approach": "wiki", "verif wiki answer": "ton(0.6798)", "verif concept answer": "ton(0.6760)", "verif image answer": "1000 lbs(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129781.jpg"}, {"question": "what year was this competition held", "gt answer": "2012(1.00)<br/>2004(0.60)", "pred answer": "1965", "question_id": 4107555, "best approach": "", "verif answer": "1965", "anno approach": "", "verif wiki answer": "1965(0.6836)", "verif concept answer": "1965(0.6673)", "verif image answer": "2008(0.6475)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000410755.jpg"}, {"question": "what event is this person attending", "gt answer": "game convention(1.00)", "pred answer": "birthday", "question_id": 1570065, "best approach": "", "verif answer": "baseball game", "anno approach": "", "verif wiki answer": "wed(0.6275)", "verif concept answer": "fair(0.5853)", "verif image answer": "baseball game(0.6833)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157006.jpg"}, {"question": "what is the proper equipment for this vehicle", "gt answer": "helmet(1.00)<br/>mirror(0.60)", "pred answer": "sidecar", "question_id": 3208385, "best approach": "", "verif answer": "hat", "anno approach": "", "verif wiki answer": "hat(0.6692)", "verif concept answer": "hat(0.6762)", "verif image answer": "hat(0.7037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320838.jpg"}, {"question": "why are the lens orange on the goggles", "gt answer": "glare(1.00)", "pred answer": "sunglasses", "question_id": 4056055, "best approach": "", "verif answer": "snow", "anno approach": "", "verif wiki answer": "snow(0.6096)", "verif concept answer": "snow(0.6140)", "verif image answer": "reflection(0.5156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405605.jpg"}, {"question": "what type of truck is this", "gt answer": "fedex(1.00)<br/>delivery(0.60)<br/>mail(0.60)", "pred answer": "garbage", "question_id": 3392505, "best approach": "wiki, concept, image", "verif answer": "delivery", "anno approach": "wiki", "verif wiki answer": "delivery(0.7270)", "verif concept answer": "delivery(0.7229)", "verif image answer": "delivery(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000339250.jpg"}, {"question": "what style of bicycle is this", "gt answer": "10 speed(1.00)<br/>road(0.60)<br/>mountain(0.60)", "pred answer": "motorcycle", "question_id": 2981825, "best approach": "wiki, concept, image", "verif answer": "mountain", "anno approach": "wiki", "verif wiki answer": "mountain(0.6572)", "verif concept answer": "mountain(0.6418)", "verif image answer": "road(0.6493)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000298182.jpg"}, {"question": "what is this room used for", "gt answer": "bath(1.00)", "pred answer": "bath", "question_id": 1381535, "best approach": "image", "verif answer": "water", "anno approach": "image", "verif wiki answer": "water(0.6153)", "verif concept answer": "water(0.7086)", "verif image answer": "bath(0.6631)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138153.jpg"}, {"question": "how can this woman keep herself safe while crossing the road", "gt answer": "look both way(1.00)", "pred answer": "helmet", "question_id": 2603735, "best approach": "", "verif answer": "helmet", "anno approach": "", "verif wiki answer": "helmet(0.6337)", "verif concept answer": "helmet(0.6175)", "verif image answer": "helmet(0.6352)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260373.jpg"}, {"question": "what was used to decorate the top of this cake", "gt answer": "ice(1.00)<br/>candle(0.60)<br/>frost(0.60)", "pred answer": "frost", "question_id": 3290185, "best approach": "", "verif answer": "fondant", "anno approach": "", "verif wiki answer": "sprinkle(0.7297)", "verif concept answer": "sprinkle(0.7256)", "verif image answer": "fondant(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329018.jpg"}, {"question": "which category of cows are shown in the photo", "gt answer": "dairy(1.00)<br/>bull(0.60)", "pred answer": "jersey", "question_id": 1926425, "best approach": "", "verif answer": "jersey", "anno approach": "", "verif wiki answer": "jersey(0.6594)", "verif concept answer": "jersey(0.6915)", "verif image answer": "jersey(0.6919)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000192642.jpg"}, {"question": "in the office building behind the clock are they more likely to make cell phones or soccer balls", "gt answer": "cell phone(1.00)", "pred answer": "paper", "question_id": 4513535, "best approach": "", "verif answer": "smartphone", "anno approach": "", "verif wiki answer": "smartphone(0.7058)", "verif concept answer": "smartphone(0.7242)", "verif image answer": "smartphone(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451353.jpg"}, {"question": "", "gt answer": "light(0.60)<br/>decoration(0.60)<br/>decor(0.60)", "pred answer": "shade", "question_id": 2217396, "best approach": "wiki, concept, image", "verif answer": "decoration", "anno approach": "", "verif wiki answer": "decoration(0.6321)", "verif concept answer": "decoration(0.6401)", "verif image answer": "decoration(0.6365)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221739.jpg"}, {"question": "what material is the pillow made from", "gt answer": "feather(1.00)<br/>cotton(0.60)<br/>foam(0.60)", "pred answer": "fabric", "question_id": 2222605, "best approach": "", "verif answer": "polyester", "anno approach": "", "verif wiki answer": "polyester(0.6711)", "verif concept answer": "polyester(0.6945)", "verif image answer": "polyester(0.6860)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222260.jpg"}, {"question": "how can we tell no one has used this vehicle in a long time", "gt answer": "rust(1.00)", "pred answer": "truck", "question_id": 3611455, "best approach": "wiki, image", "verif answer": "brand", "anno approach": "wiki", "verif wiki answer": "rust(0.6059)", "verif concept answer": "brand(0.6155)", "verif image answer": "rust(0.6076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361145.jpg"}, {"question": "what company created the shoes the person is wearing", "gt answer": "converse(1.00)<br/>van(1.00)", "pred answer": "adidas", "question_id": 3132135, "best approach": "image", "verif answer": "nike", "anno approach": "image", "verif wiki answer": "nike(0.7221)", "verif concept answer": "nike(0.6415)", "verif image answer": "van(0.5539)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313213.jpg"}, {"question": "where is this surfer", "gt answer": "under wave(1.00)<br/>ocean(0.60)<br/>california(0.60)<br/>hawaii(0.60)", "pred answer": "beach", "question_id": 1940455, "best approach": "wiki, concept, image", "verif answer": "hawaii", "anno approach": "wiki", "verif wiki answer": "hawaii(0.6849)", "verif concept answer": "ocean(0.6873)", "verif image answer": "hawaii(0.7126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194045.jpg"}, {"question": "what kind of day is it", "gt answer": "clear(1.00)<br/>sunny(1.00)<br/>afternoon(0.60)", "pred answer": "cloudy", "question_id": 148445, "best approach": "", "verif answer": "cloudy", "anno approach": "", "verif wiki answer": "cloudy(0.7183)", "verif concept answer": "cloudy(0.7266)", "verif image answer": "cloudy(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000014844.jpg"}, {"question": "what is the player with the blue helmet doing", "gt answer": "slide(1.00)", "pred answer": "pitch", "question_id": 2262985, "best approach": "", "verif answer": "steal", "anno approach": "", "verif wiki answer": "steal(0.7071)", "verif concept answer": "steal(0.6938)", "verif image answer": "steal(0.6728)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226298.jpg"}, {"question": "what type of charger would this phone require", "gt answer": "usb(1.00)<br/>samsung(0.60)", "pred answer": "cell", "question_id": 186835, "best approach": "", "verif answer": "electric", "anno approach": "", "verif wiki answer": "electric(0.7215)", "verif concept answer": "electric(0.7174)", "verif image answer": "electric(0.7116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000018683.jpg"}, {"question": "what is the weather like in this picture", "gt answer": "rain(1.00)<br/>rainy(0.60)", "pred answer": "rainy", "question_id": 425165, "best approach": "wiki, concept", "verif answer": "rainy", "anno approach": "wiki", "verif wiki answer": "rain(0.6897)", "verif concept answer": "rain(0.6722)", "verif image answer": "rainy(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042516.jpg"}, {"question": "what happened to doris", "gt answer": "died(1.00)", "pred answer": "crash", "question_id": 5596575, "best approach": "image", "verif answer": "eaten", "anno approach": "image", "verif wiki answer": "eaten(0.6706)", "verif concept answer": "eaten(0.6598)", "verif image answer": "died(0.6109)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559657.jpg"}, {"question": "why are these people covering themselves", "gt answer": "snow(1.00)<br/>rain(0.60)", "pred answer": "parade", "question_id": 1434905, "best approach": "", "verif answer": "cold weather", "anno approach": "", "verif wiki answer": "cold weather(0.6967)", "verif concept answer": "cold weather(0.7017)", "verif image answer": "cold weather(0.6914)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143490.jpg"}, {"question": "what 's model is this airplane", "gt answer": "747(1.00)<br/>boeing(0.60)", "pred answer": "boeing", "question_id": 1225735, "best approach": "wiki, concept, image", "verif answer": "boeing", "anno approach": "wiki", "verif wiki answer": "boeing(0.7131)", "verif concept answer": "boeing(0.6928)", "verif image answer": "boeing(0.7114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122573.jpg"}, {"question": "is this a river creek stream or lake", "gt answer": "river(1.00)<br/>stream(0.60)", "pred answer": "lake", "question_id": 796065, "best approach": "", "verif answer": "lake", "anno approach": "", "verif wiki answer": "lake(0.6759)", "verif concept answer": "lake(0.6957)", "verif image answer": "lake(0.6726)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079606.jpg"}, {"question": "what breed is this bird", "gt answer": "seagull(1.00)", "pred answer": "sparrow", "question_id": 3080735, "best approach": "", "verif answer": "geese", "anno approach": "", "verif wiki answer": "geese(0.6740)", "verif concept answer": "geese(0.6960)", "verif image answer": "geese(0.6659)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308073.jpg"}, {"question": "what breed of cats are these", "gt answer": "siamese(1.00)<br/>domestic shorthair(0.60)", "pred answer": "tabby", "question_id": 944445, "best approach": "image", "verif answer": "calico", "anno approach": "image", "verif wiki answer": "calico(0.6423)", "verif concept answer": "calico(0.6347)", "verif image answer": "siamese(0.6405)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094444.jpg"}, {"question": "what is the substance these men are walking on", "gt answer": "sand(1.00)", "pred answer": "sand", "question_id": 686485, "best approach": "wiki, concept, image", "verif answer": "sand", "anno approach": "concept, wiki", "verif wiki answer": "sand(0.6937)", "verif concept answer": "sand(0.6948)", "verif image answer": "sand(0.6612)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068648.jpg"}, {"question": "who is this tennis player", "gt answer": "rafael nadal(1.00)<br/>man(0.60)<br/>federer(0.60)", "pred answer": "roger federer", "question_id": 2331115, "best approach": "wiki, concept", "verif answer": "rafael nadal", "anno approach": "wiki", "verif wiki answer": "rafael nadal(0.7193)", "verif concept answer": "rafael nadal(0.7186)", "verif image answer": "roger federer(0.6982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233111.jpg"}, {"question": "what happens when a car reaches this sign", "gt answer": "turn(1.00)<br/>it turn(1.00)<br/>drive(0.60)", "pred answer": "stop", "question_id": 4354355, "best approach": "wiki, concept, image", "verif answer": "it turn", "anno approach": "wiki", "verif wiki answer": "it turn(0.6922)", "verif concept answer": "it turn(0.6697)", "verif image answer": "it turn(0.6913)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435435.jpg"}, {"question": "was this bed made by the owner or by a factory", "gt answer": "factory(1.00)<br/>owner(1.00)", "pred answer": "factory", "question_id": 4365085, "best approach": "concept, image", "verif answer": "owner", "anno approach": "", "verif wiki answer": "master(0.5769)", "verif concept answer": "owner(0.6406)", "verif image answer": "owner(0.6454)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436508.jpg"}, {"question": "is this a full bath or a half bath", "gt answer": "full(1.00)", "pred answer": "full", "question_id": 1181405, "best approach": "wiki, concept, image", "verif answer": "full", "anno approach": "wiki", "verif wiki answer": "full(0.7304)", "verif concept answer": "full(0.7300)", "verif image answer": "full(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118140.jpg"}, {"question": "what type of cat is that", "gt answer": "calico(1.00)<br/>domestic(0.60)<br/>house cat(0.60)", "pred answer": "tabby", "question_id": 2302275, "best approach": "wiki, concept, image", "verif answer": "calico", "anno approach": "wiki", "verif wiki answer": "calico(0.7066)", "verif concept answer": "calico(0.7090)", "verif image answer": "calico(0.7017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000230227.jpg"}, {"question": "how is the umbrella in the photo unusual", "gt answer": "clear(1.00)<br/>black and white(0.60)", "pred answer": "small", "question_id": 819035, "best approach": "wiki", "verif answer": "wide angle", "anno approach": "wiki", "verif wiki answer": "clear(0.7076)", "verif concept answer": "wide angle(0.7193)", "verif image answer": "wide angle(0.6841)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081903.jpg"}, {"question": "why is the water in this photo not blue", "gt answer": "algae(1.00)", "pred answer": "algae", "question_id": 4341935, "best approach": "wiki, concept, image", "verif answer": "algae", "anno approach": "wiki", "verif wiki answer": "algae(0.7167)", "verif concept answer": "algae(0.7172)", "verif image answer": "algae(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434193.jpg"}, {"question": "what is the art form made by this", "gt answer": "collage(1.00)", "pred answer": "paint", "question_id": 4475885, "best approach": "wiki, concept, image", "verif answer": "collage", "anno approach": "image", "verif wiki answer": "collage(0.6820)", "verif concept answer": "collage(0.6609)", "verif image answer": "collage(0.7080)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447588.jpg"}, {"question": "what items would you typically find in these bags", "gt answer": "cloth(1.00)", "pred answer": "travel", "question_id": 2816175, "best approach": "", "verif answer": "book", "anno approach": "", "verif wiki answer": "book(0.6173)", "verif concept answer": "book(0.5498)", "verif image answer": "book(0.6819)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281617.jpg"}, {"question": "what kind off vitamins do you get from this vegetable", "gt answer": "b(1.00)<br/>c(0.60)", "pred answer": "vitamin c", "question_id": 723705, "best approach": "wiki", "verif answer": "vitamin c", "anno approach": "wiki", "verif wiki answer": "c(0.7098)", "verif concept answer": "vitamin c(0.7063)", "verif image answer": "vitamin c(0.7211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072370.jpg"}, {"question": "what habitat is this animal most commonly found in", "gt answer": "savannah(1.00)<br/>zoo(0.60)<br/>tropical(0.60)", "pred answer": "africa", "question_id": 36685, "best approach": "wiki", "verif answer": "zoo", "anno approach": "wiki", "verif wiki answer": "savannah(0.6183)", "verif concept answer": "grassland(0.5397)", "verif image answer": "zoo(0.7084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003668.jpg"}, {"question": "are these flowers annuals or perannuals", "gt answer": "annual(1.00)", "pred answer": "annual", "question_id": 4548985, "best approach": "wiki, concept, image", "verif answer": "annual", "anno approach": "", "verif wiki answer": "annual(0.7294)", "verif concept answer": "annual(0.7300)", "verif image answer": "annual(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000454898.jpg"}, {"question": "what are the meters used for", "gt answer": "park(1.00)", "pred answer": "park meter", "question_id": 2148705, "best approach": "wiki", "verif answer": "park", "anno approach": "wiki", "verif wiki answer": "park(0.6795)", "verif concept answer": "park meter(0.5355)", "verif image answer": "park meter(0.6505)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214870.jpg"}, {"question": "what newspaper is this woman looking at", "gt answer": "new york time(1.00)<br/>new york(0.60)", "pred answer": "magazine", "question_id": 2603815, "best approach": "", "verif answer": "amazon", "anno approach": "", "verif wiki answer": "amazon(0.6092)", "verif concept answer": "amazon(0.7105)", "verif image answer": "amazon(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260381.jpg"}, {"question": "what breed of horse is shown", "gt answer": "clydesdale(1.00)", "pred answer": "clydesdale", "question_id": 1349585, "best approach": "wiki, concept, image", "verif answer": "clydesdale", "anno approach": "wiki", "verif wiki answer": "clydesdale(0.7088)", "verif concept answer": "clydesdale(0.7055)", "verif image answer": "clydesdale(0.6885)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134958.jpg"}, {"question": "what is the man reading", "gt answer": "newspaper(1.00)<br/>magazine(0.60)", "pred answer": "paper", "question_id": 1385215, "best approach": "image", "verif answer": "newspaper", "anno approach": "image", "verif wiki answer": "magazine(0.6456)", "verif concept answer": "magazine(0.6812)", "verif image answer": "newspaper(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138521.jpg"}, {"question": "how many teeth do these animals have in their mouth", "gt answer": "32(1.00)<br/>30(0.60)", "pred answer": "2000", "question_id": 1038655, "best approach": "wiki", "verif answer": "50", "anno approach": "wiki", "verif wiki answer": "30(0.6673)", "verif concept answer": "20(0.6660)", "verif image answer": "50(0.7243)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103865.jpg"}, {"question": "", "gt answer": "floral(0.60)<br/>stripe(0.60)<br/>striped(0.60)", "pred answer": "stripe", "question_id": 2629675, "best approach": "wiki, concept, image", "verif answer": "stripe", "anno approach": "", "verif wiki answer": "stripe(0.7136)", "verif concept answer": "stripe(0.7185)", "verif image answer": "stripe(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262967.jpg"}, {"question": "where would you find snapshots like these posted", "gt answer": "facebook(1.00)<br/>hotel(0.60)", "pred answer": "bedroom", "question_id": 5298865, "best approach": "wiki, concept", "verif answer": "facebook", "anno approach": "concept, wiki", "verif wiki answer": "facebook(0.5719)", "verif concept answer": "facebook(0.6626)", "verif image answer": "instagram(0.5136)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529886.jpg"}, {"question": "where are these animals", "gt answer": "farm(1.00)", "pred answer": "farm", "question_id": 5024855, "best approach": "", "verif answer": "horse", "anno approach": "", "verif wiki answer": "horse(0.6750)", "verif concept answer": "horse(0.6870)", "verif image answer": "horse(0.6875)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502485.jpg"}, {"question": "the what chemical makes the vegetable orange", "gt answer": "beta carotene(1.00)<br/>c(0.60)<br/>chlorophyll(0.60)", "pred answer": "carrot", "question_id": 4394455, "best approach": "wiki, concept, image", "verif answer": "beta carotene", "anno approach": "concept, wiki", "verif wiki answer": "beta carotene(0.6777)", "verif concept answer": "beta carotene(0.6687)", "verif image answer": "beta carotene(0.6345)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439445.jpg"}, {"question": "what types of ducks are these", "gt answer": "mallard(1.00)", "pred answer": "geese", "question_id": 4488655, "best approach": "", "verif answer": "geese", "anno approach": "", "verif wiki answer": "puffin(0.6848)", "verif concept answer": "geese(0.7093)", "verif image answer": "puffin(0.6866)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448865.jpg"}, {"question": "these types of bikes are known as what", "gt answer": "tricycle(1.00)<br/>bicycle(0.60)", "pred answer": "bicycle", "question_id": 2266325, "best approach": "concept", "verif answer": "schwinn", "anno approach": "concept", "verif wiki answer": "schwinn(0.6603)", "verif concept answer": "tricycle(0.6531)", "verif image answer": "schwinn(0.6565)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226632.jpg"}, {"question": "what shape is quesadilla", "gt answer": "triangle(1.00)", "pred answer": "rectangle", "question_id": 991395, "best approach": "", "verif answer": "in half", "anno approach": "", "verif wiki answer": "in half(0.7140)", "verif concept answer": "in half(0.7157)", "verif image answer": "in half(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099139.jpg"}, {"question": "what is the name of this person onscreen", "gt answer": "dexter(1.00)", "pred answer": "camera", "question_id": 3470555, "best approach": "", "verif answer": "record player", "anno approach": "", "verif wiki answer": "fowler(0.6103)", "verif concept answer": "record player(0.6396)", "verif image answer": "record player(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347055.jpg"}, {"question": "what could someone drink in the left object besides coffee", "gt answer": "tea(1.00)", "pred answer": "coffee", "question_id": 2306505, "best approach": "", "verif answer": "coffee", "anno approach": "", "verif wiki answer": "coffee(0.7017)", "verif concept answer": "beer(0.6988)", "verif image answer": "latte(0.6822)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000230650.jpg"}, {"question": "what type of clouds are those", "gt answer": "cirrus(1.00)<br/>stratus(0.60)<br/>cumulus(0.60)<br/>white(0.60)", "pred answer": "cumulus", "question_id": 88165, "best approach": "wiki, concept, image", "verif answer": "cumulus", "anno approach": "image, wiki", "verif wiki answer": "cumulus(0.6467)", "verif concept answer": "cumulus(0.6440)", "verif image answer": "cumulus(0.6848)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008816.jpg"}, {"question": "is this veggies or fruit", "gt answer": "veggies(1.00)", "pred answer": "fruit", "question_id": 797925, "best approach": "", "verif answer": "fruit", "anno approach": "", "verif wiki answer": "fruit(0.6456)", "verif concept answer": "fruit(0.5559)", "verif image answer": "green(0.5510)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079792.jpg"}, {"question": "what part is missing on this bus", "gt answer": "front(1.00)<br/>grill(0.60)", "pred answer": "back", "question_id": 1106585, "best approach": "", "verif answer": "left", "anno approach": "", "verif wiki answer": "left(0.6930)", "verif concept answer": "left(0.6849)", "verif image answer": "left(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000110658.jpg"}, {"question": "which item of sci fi fame is purported to look like this object", "gt answer": "ufo(1.00)", "pred answer": "sunscreen", "question_id": 482575, "best approach": "", "verif answer": "frisbee", "anno approach": "", "verif wiki answer": "catch(0.7140)", "verif concept answer": "catch(0.7112)", "verif image answer": "frisbee(0.7183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048257.jpg"}, {"question": "what year did this man win the election", "gt answer": "2008(1.00)<br/>2004(1.00)", "pred answer": "1950", "question_id": 296395, "best approach": "wiki, concept", "verif answer": "2008", "anno approach": "wiki", "verif wiki answer": "2008(0.7142)", "verif concept answer": "2008(0.6544)", "verif image answer": "2010(0.6489)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029639.jpg"}, {"question": "what type of board are they people on", "gt answer": "surf(1.00)<br/>surf board(1.00)", "pred answer": "surfboard", "question_id": 1682945, "best approach": "image", "verif answer": "surfboard", "anno approach": "image", "verif wiki answer": "surfboard(0.7116)", "verif concept answer": "surfboard(0.7196)", "verif image answer": "surf(0.6624)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168294.jpg"}, {"question": "what made those stains", "gt answer": "grease(1.00)", "pred answer": "paint", "question_id": 2878725, "best approach": "concept", "verif answer": "linseed", "anno approach": "concept", "verif wiki answer": "linseed(0.6574)", "verif concept answer": "grease(0.6839)", "verif image answer": "linseed(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287872.jpg"}, {"question": "where is this", "gt answer": "high school(1.00)<br/>arizona(0.60)<br/>grand canyon(0.60)", "pred answer": "london", "question_id": 4887645, "best approach": "wiki, concept, image", "verif answer": "grand canyon", "anno approach": "", "verif wiki answer": "grand canyon(0.7123)", "verif concept answer": "grand canyon(0.7069)", "verif image answer": "arizona(0.7026)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488764.jpg"}, {"question": "why would one suspect that this is not chicago", "gt answer": "sign(1.00)", "pred answer": "light", "question_id": 3365805, "best approach": "", "verif answer": "street sign", "anno approach": "", "verif wiki answer": "google(0.5186)", "verif concept answer": "google(0.5234)", "verif image answer": "street sign(0.6360)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000336580.jpg"}, {"question": "about what time of the day is this", "gt answer": "noon(1.00)<br/>afternoon(1.00)", "pred answer": "afternoon", "question_id": 241075, "best approach": "wiki, concept", "verif answer": "afternoon", "anno approach": "wiki", "verif wiki answer": "noon(0.6628)", "verif concept answer": "afternoon(0.6725)", "verif image answer": "lunch(0.6152)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024107.jpg"}, {"question": "what is the best way type of cleaner for this floor", "gt answer": "bleach(1.00)", "pred answer": "bleach", "question_id": 1916665, "best approach": "concept, image", "verif answer": "sponge", "anno approach": "", "verif wiki answer": "sponge(0.7144)", "verif concept answer": "bleach(0.6980)", "verif image answer": "bleach(0.6816)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191666.jpg"}, {"question": "what kind of event is happening", "gt answer": "speech(1.00)<br/>award(0.60)", "pred answer": "press conference", "question_id": 1936545, "best approach": "image", "verif answer": "press conference", "anno approach": "image", "verif wiki answer": "press conference(0.7098)", "verif concept answer": "press conference(0.7183)", "verif image answer": "award(0.6158)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193654.jpg"}, {"question": "who is taking the picture of this bathroom", "gt answer": "owner(1.00)", "pred answer": "conductor", "question_id": 1871575, "best approach": "wiki, concept, image", "verif answer": "owner", "anno approach": "image, wiki", "verif wiki answer": "owner(0.5236)", "verif concept answer": "owner(0.5248)", "verif image answer": "owner(0.6002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187157.jpg"}, {"question": "what is being used to heat this area", "gt answer": "heater(1.00)<br/>gas(0.60)", "pred answer": "gas", "question_id": 4837145, "best approach": "wiki, concept, image", "verif answer": "gas", "anno approach": "concept, wiki", "verif wiki answer": "gas(0.5927)", "verif concept answer": "gas(0.7039)", "verif image answer": "gas(0.6097)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483714.jpg"}, {"question": "name the type of flooring shown in this picture", "gt answer": "carpet(1.00)<br/>tile(0.60)", "pred answer": "tile", "question_id": 3221805, "best approach": "wiki", "verif answer": "tile", "anno approach": "wiki", "verif wiki answer": "carpet(0.7026)", "verif concept answer": "tile(0.6852)", "verif image answer": "tile(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322180.jpg"}, {"question": "what is holding this man 's pants up", "gt answer": "belt(1.00)<br/>suspend(1.00)", "pred answer": "cap", "question_id": 2082565, "best approach": "wiki, concept, image", "verif answer": "suspend", "anno approach": "wiki", "verif wiki answer": "suspend(0.5817)", "verif concept answer": "belt(0.5085)", "verif image answer": "suspend(0.5088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208256.jpg"}, {"question": "what team is the player on who is sliding into base", "gt answer": "yankees(1.00)<br/>home(0.60)", "pred answer": "yankees", "question_id": 1913405, "best approach": "", "verif answer": "red sox", "anno approach": "", "verif wiki answer": "red sox(0.7157)", "verif concept answer": "red sox(0.7040)", "verif image answer": "red sox(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191340.jpg"}, {"question": "what type of animal do the two large kites look like", "gt answer": "stingray(1.00)<br/>dragon(0.60)<br/>bird(0.60)", "pred answer": "octopus", "question_id": 17855, "best approach": "", "verif answer": "octopus", "anno approach": "", "verif wiki answer": "octopus(0.7142)", "verif concept answer": "octopus(0.7245)", "verif image answer": "octopus(0.7007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001785.jpg"}, {"question": "what are these bears doing", "gt answer": "swim(1.00)<br/>fish(1.00)<br/>hunt(0.60)", "pred answer": "fish", "question_id": 5710745, "best approach": "wiki, image", "verif answer": "swim", "anno approach": "wiki", "verif wiki answer": "swim(0.6794)", "verif concept answer": "hunt(0.6108)", "verif image answer": "swim(0.6255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571074.jpg"}, {"question": "what is the oxymoronic divinity based name of the famous american group who rides the above vehicle", "gt answer": "hell angel(1.00)", "pred answer": "honda", "question_id": 2104505, "best approach": "", "verif answer": "kentucky derby", "anno approach": "", "verif wiki answer": "kentucky derby(0.6906)", "verif concept answer": "kentucky derby(0.6884)", "verif image answer": "kentucky derby(0.6949)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210450.jpg"}, {"question": "what chewing gum is named is based on the animal shown", "gt answer": "fruit stripe(1.00)<br/>stripe(0.60)", "pred answer": "fruit stripe", "question_id": 3384275, "best approach": "wiki, concept, image", "verif answer": "fruit stripe", "anno approach": "concept, wiki", "verif wiki answer": "fruit stripe(0.7310)", "verif concept answer": "fruit stripe(0.7310)", "verif image answer": "fruit stripe(0.6402)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338427.jpg"}, {"question": "what material is the screen depicted made out of", "gt answer": "plastic(1.00)<br/>glass(0.60)", "pred answer": "glass", "question_id": 22445, "best approach": "image", "verif answer": "glass", "anno approach": "image", "verif wiki answer": "foam(0.6931)", "verif concept answer": "foam(0.6872)", "verif image answer": "glass(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002244.jpg"}, {"question": "what is the processor used in this laptop", "gt answer": "intel(1.00)", "pred answer": "dell", "question_id": 3412055, "best approach": "", "verif answer": "computer", "anno approach": "", "verif wiki answer": "computer(0.6761)", "verif concept answer": "computer(0.7075)", "verif image answer": "computer(0.6871)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341205.jpg"}, {"question": "what is this vehicle used for", "gt answer": "fly(1.00)<br/>fight(0.60)<br/>cargo(0.60)", "pred answer": "transportation", "question_id": 2508805, "best approach": "image", "verif answer": "fly", "anno approach": "image", "verif wiki answer": "wing(0.5338)", "verif concept answer": "cargo(0.5428)", "verif image answer": "fly(0.5827)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250880.jpg"}, {"question": "how would you describe these animals eating style", "gt answer": "graze(1.00)<br/>slow(0.60)", "pred answer": "grilled", "question_id": 1492535, "best approach": "wiki, concept, image", "verif answer": "graze", "anno approach": "wiki", "verif wiki answer": "graze(0.6635)", "verif concept answer": "graze(0.6704)", "verif image answer": "graze(0.6891)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149253.jpg"}, {"question": "what country is this building located in", "gt answer": "belgium(1.00)<br/>england(0.60)", "pred answer": "london", "question_id": 2486015, "best approach": "wiki, concept", "verif answer": "england", "anno approach": "", "verif wiki answer": "belgium(0.6969)", "verif concept answer": "belgium(0.7064)", "verif image answer": "england(0.7077)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248601.jpg"}, {"question": "what culture considers these to be good luck", "gt answer": "hindu(1.00)<br/>chinese(0.60)<br/>india(0.60)<br/>indian(0.60)", "pred answer": "africa", "question_id": 2615965, "best approach": "wiki, concept, image", "verif answer": "chinese", "anno approach": "concept, wiki", "verif wiki answer": "chinese(0.6367)", "verif concept answer": "chinese(0.6631)", "verif image answer": "chinese(0.5899)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261596.jpg"}, {"question": "who do these beautiful bottles do", "gt answer": "hold flower(1.00)<br/>hold thing(0.60)", "pred answer": "david evans strickler", "question_id": 3486165, "best approach": "", "verif answer": "decoration", "anno approach": "", "verif wiki answer": "decoration(0.7299)", "verif concept answer": "decoration(0.7273)", "verif image answer": "decoration(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348616.jpg"}, {"question": "is this a formal or casual situation", "gt answer": "formal(1.00)<br/>casual(1.00)", "pred answer": "casual", "question_id": 631665, "best approach": "wiki, concept, image", "verif answer": "casual", "anno approach": "concept", "verif wiki answer": "casual(0.7228)", "verif concept answer": "casual(0.7263)", "verif image answer": "casual(0.6912)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063166.jpg"}, {"question": "what general material is the statue made of", "gt answer": "bronze(1.00)<br/>metal(0.60)<br/>stone(0.60)<br/>copper(0.60)", "pred answer": "stone", "question_id": 652205, "best approach": "image", "verif answer": "metal", "anno approach": "image", "verif wiki answer": "wood(0.6282)", "verif concept answer": "wood(0.6753)", "verif image answer": "metal(0.7226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065220.jpg"}, {"question": "what do they make the cup shown out of", "gt answer": "styrofoam(1.00)<br/>paper(0.60)", "pred answer": "glass", "question_id": 470225, "best approach": "", "verif answer": "foam", "anno approach": "", "verif wiki answer": "plastic(0.6369)", "verif concept answer": "plastic(0.6260)", "verif image answer": "foam(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047022.jpg"}, {"question": "what breed of dogs are these", "gt answer": "doberman(1.00)<br/>mutt(0.60)<br/>terrier(0.60)<br/>chihuahua(0.60)", "pred answer": "dog", "question_id": 3995945, "best approach": "wiki, concept, image", "verif answer": "doberman", "anno approach": "wiki", "verif wiki answer": "doberman(0.6734)", "verif concept answer": "doberman(0.7002)", "verif image answer": "doberman(0.7020)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399594.jpg"}, {"question": "what time of day does it appear to be in this photo", "gt answer": "even(1.00)<br/>dusk(1.00)<br/>dawn(0.60)", "pred answer": "morn", "question_id": 635405, "best approach": "", "verif answer": "sunset", "anno approach": "", "verif wiki answer": "sunset(0.6536)", "verif concept answer": "sunset(0.6663)", "verif image answer": "sunset(0.7071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063540.jpg"}, {"question": "are they eating inside or outside", "gt answer": "outside(1.00)", "pred answer": "outside", "question_id": 2510495, "best approach": "wiki, concept", "verif answer": "cafe", "anno approach": "concept, wiki", "verif wiki answer": "outside(0.6782)", "verif concept answer": "outside(0.7193)", "verif image answer": "cafe(0.7256)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251049.jpg"}, {"question": "what is the lady inserting coins into", "gt answer": "park meter(1.00)<br/>meter(0.60)", "pred answer": "money", "question_id": 4666155, "best approach": "image", "verif answer": "car", "anno approach": "image", "verif wiki answer": "car(0.7136)", "verif concept answer": "car(0.6880)", "verif image answer": "park meter(0.6138)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466615.jpg"}, {"question": "what is the top speed of this train", "gt answer": "300 mph(1.00)<br/>150(0.60)<br/>120 mph(0.60)<br/>100(0.60)", "pred answer": "30 mph", "question_id": 5034075, "best approach": "wiki, image", "verif answer": "100", "anno approach": "wiki", "verif wiki answer": "150(0.6793)", "verif concept answer": "200(0.6223)", "verif image answer": "100(0.7048)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503407.jpg"}, {"question": "what kind of jet is that", "gt answer": "fighter(1.00)", "pred answer": "fighter jet", "question_id": 5465945, "best approach": "", "verif answer": "geese", "anno approach": "", "verif wiki answer": "geese(0.6895)", "verif concept answer": "geese(0.7068)", "verif image answer": "geese(0.7165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546594.jpg"}, {"question": "note the most dominant color in the photo what continent is known for being this color", "gt answer": "antarctica(1.00)<br/>red(0.60)<br/>grey(0.60)", "pred answer": "north america", "question_id": 423085, "best approach": "image", "verif answer": "antarctica", "anno approach": "image", "verif wiki answer": "north america(0.6834)", "verif concept answer": "north america(0.7182)", "verif image answer": "antarctica(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042308.jpg"}, {"question": "what room is this", "gt answer": "live room(1.00)<br/>livingroom(0.60)<br/>bedroom(0.60)", "pred answer": "bedroom", "question_id": 2159075, "best approach": "image", "verif answer": "bedroom", "anno approach": "image", "verif wiki answer": "bedroom(0.7298)", "verif concept answer": "bedroom(0.6714)", "verif image answer": "live room(0.7218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215907.jpg"}, {"question": "on what is this person traveling on", "gt answer": "ski(1.00)<br/>snow(0.60)<br/>sky(0.60)", "pred answer": "ski", "question_id": 4406755, "best approach": "concept", "verif answer": "ski", "anno approach": "concept", "verif wiki answer": "skiis(0.6707)", "verif concept answer": "ski(0.7054)", "verif image answer": "snow(0.6088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440675.jpg"}, {"question": "where style skateboard is this skateboard", "gt answer": "longboard(1.00)<br/>long board(1.00)<br/>kid(0.60)", "pred answer": "street", "question_id": 394955, "best approach": "wiki, concept, image", "verif answer": "longboard", "anno approach": "concept, wiki", "verif wiki answer": "longboard(0.6879)", "verif concept answer": "longboard(0.7049)", "verif image answer": "longboard(0.6678)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039495.jpg"}, {"question": "the fruit in the picture grows most abundantly on what continent", "gt answer": "south america(1.00)", "pred answer": "africa", "question_id": 2833295, "best approach": "", "verif answer": "brazil", "anno approach": "", "verif wiki answer": "brazil(0.7060)", "verif concept answer": "brazil(0.7147)", "verif image answer": "brazil(0.7018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283329.jpg"}, {"question": "what decade is depicted in the image", "gt answer": "1950's(1.00)<br/>tour bus(0.60)<br/>1950s(0.60)", "pred answer": "1950", "question_id": 2362675, "best approach": "", "verif answer": "modern", "anno approach": "", "verif wiki answer": "modern(0.6642)", "verif concept answer": "modern(0.6332)", "verif image answer": "modern(0.6409)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236267.jpg"}, {"question": "what racing series do these motorcycles particiapte in", "gt answer": "hertz(1.00)<br/>motocross(0.60)<br/>motorcycle(0.60)", "pred answer": "race", "question_id": 4310125, "best approach": "wiki, concept, image", "verif answer": "hertz", "anno approach": "concept, wiki", "verif wiki answer": "hertz(0.6731)", "verif concept answer": "hertz(0.6629)", "verif image answer": "hertz(0.5811)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431012.jpg"}, {"question": "what show is named after this animal", "gt answer": "my little pony(1.00)<br/>horse race(0.60)<br/>mule(0.60)", "pred answer": "race", "question_id": 5129185, "best approach": "", "verif answer": "horse", "anno approach": "", "verif wiki answer": "horse(0.5295)", "verif concept answer": "clydesdale(0.5563)", "verif image answer": "horse(0.5825)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512918.jpg"}, {"question": "what crime are those people committing", "gt answer": "jaywalk(1.00)<br/>speed(0.60)<br/>0(0.60)", "pred answer": "san francisco", "question_id": 2624775, "best approach": "wiki", "verif answer": "toxoplasmosis", "anno approach": "wiki", "verif wiki answer": "speed(0.5092)", "verif concept answer": "washington(0.5017)", "verif image answer": "toxoplasmosis(0.5214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262477.jpg"}, {"question": "what items can be replaced on this dish to make it more healthy", "gt answer": "bacon(1.00)<br/>potato(0.60)<br/>meat(0.60)", "pred answer": "egg", "question_id": 1114555, "best approach": "wiki, concept, image", "verif answer": "potato", "anno approach": "wiki", "verif wiki answer": "meat(0.7222)", "verif concept answer": "potato(0.7174)", "verif image answer": "potato(0.7243)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111455.jpg"}, {"question": "what type of drinks do hikers need while in colder climates", "gt answer": "warm(1.00)<br/>hot(1.00)", "pred answer": "coke", "question_id": 728095, "best approach": "", "verif answer": "windy", "anno approach": "", "verif wiki answer": "windy(0.6307)", "verif concept answer": "windy(0.5671)", "verif image answer": "windy(0.5736)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072809.jpg"}, {"question": "what animals might be out of shot in this picture", "gt answer": "shark(1.00)<br/>fish(1.00)<br/>dog(0.60)", "pred answer": "shark", "question_id": 549385, "best approach": "wiki, concept", "verif answer": "dog", "anno approach": "wiki", "verif wiki answer": "shark(0.7061)", "verif concept answer": "shark(0.7132)", "verif image answer": "dog(0.7161)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054938.jpg"}, {"question": "what is this man using to communicate", "gt answer": "cell phone(1.00)<br/>phone(1.00)<br/>cellphone(0.60)", "pred answer": "cell phone", "question_id": 2152545, "best approach": "wiki, concept, image", "verif answer": "cell phone", "anno approach": "wiki", "verif wiki answer": "cell phone(0.7016)", "verif concept answer": "cell phone(0.7286)", "verif image answer": "cell phone(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215254.jpg"}, {"question": "what is the object in front of the chair used for", "gt answer": "foot rest(1.00)<br/>leg(0.60)<br/>rest(0.60)", "pred answer": "computer", "question_id": 2411485, "best approach": "wiki, concept, image", "verif answer": "foot rest", "anno approach": "wiki", "verif wiki answer": "foot rest(0.7267)", "verif concept answer": "foot rest(0.7199)", "verif image answer": "foot rest(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241148.jpg"}, {"question": "what device is that", "gt answer": "pager(1.00)<br/>calculator(0.60)<br/>remote(0.60)", "pred answer": "cell phone", "question_id": 2089675, "best approach": "wiki, image", "verif answer": "take picture", "anno approach": "", "verif wiki answer": "pager(0.6422)", "verif concept answer": "take picture(0.6433)", "verif image answer": "pager(0.6244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208967.jpg"}, {"question": "what kind of bird is pictured", "gt answer": "dove(1.00)<br/>pigeon(0.60)<br/>sparrow(0.60)", "pred answer": "hawk", "question_id": 3337385, "best approach": "wiki, concept", "verif answer": "dove", "anno approach": "wiki", "verif wiki answer": "dove(0.6944)", "verif concept answer": "dove(0.6859)", "verif image answer": "pigeon(0.6897)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333738.jpg"}, {"question": "", "gt answer": "seed(0.60)<br/>fertalization(0.60)<br/>oxygen(0.60)", "pred answer": "leaf", "question_id": 4701965, "best approach": "wiki, concept, image", "verif answer": "oxygen", "anno approach": "", "verif wiki answer": "oxygen(0.5809)", "verif concept answer": "oxygen(0.5567)", "verif image answer": "oxygen(0.5540)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470196.jpg"}, {"question": "what hotel is this", "gt answer": "hilton(1.00)<br/>travel(0.60)", "pred answer": "hilton", "question_id": 3765055, "best approach": "image", "verif answer": "hospital", "anno approach": "image", "verif wiki answer": "hospital(0.7311)", "verif concept answer": "hospital(0.7310)", "verif image answer": "hilton(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376505.jpg"}, {"question": "why would we suspect that this is not a bachelor apartment", "gt answer": "clean(1.00)", "pred answer": "clean", "question_id": 2525255, "best approach": "", "verif answer": "empty", "anno approach": "", "verif wiki answer": "empty(0.7234)", "verif concept answer": "empty(0.7254)", "verif image answer": "empty(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252525.jpg"}, {"question": "what event is this", "gt answer": "baseball(1.00)<br/>baseball game(1.00)", "pred answer": "baseball game", "question_id": 1043285, "best approach": "wiki", "verif answer": "baseball game", "anno approach": "wiki", "verif wiki answer": "baseball game(0.6918)", "verif concept answer": "sport(0.5730)", "verif image answer": "sport(0.6297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000104328.jpg"}, {"question": "what kind of boat is in this photo", "gt answer": "sail(1.00)<br/>surf(0.60)<br/>surfboard(0.60)", "pred answer": "sailboat", "question_id": 1289725, "best approach": "wiki, concept", "verif answer": "surfboard", "anno approach": "wiki", "verif wiki answer": "surfboard(0.7070)", "verif concept answer": "surfboard(0.7101)", "verif image answer": "sailboat(0.6724)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128972.jpg"}, {"question": "which item is associated with a place famous for a presumed laid back frame of mind", "gt answer": "weed(1.00)<br/>luggage(0.60)<br/>suitcase(0.60)", "pred answer": "cloth", "question_id": 5198675, "best approach": "", "verif answer": "crutch", "anno approach": "", "verif wiki answer": "crutch(0.7031)", "verif concept answer": "crutch(0.7057)", "verif image answer": "crutch(0.7054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000519867.jpg"}, {"question": "what is the purpose of the long thin object that the man in the black shirt is holding", "gt answer": "hit(1.00)<br/>hit baseball(0.60)<br/>hit ball(0.60)", "pred answer": "hit ball", "question_id": 964145, "best approach": "wiki, concept, image", "verif answer": "hit", "anno approach": "concept, wiki", "verif wiki answer": "hit(0.6003)", "verif concept answer": "hit(0.6243)", "verif image answer": "hit(0.5111)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096414.jpg"}, {"question": "what event is this snowboarder partaking in", "gt answer": "olympics(1.00)<br/>snowboard(0.60)<br/>slalom(0.60)", "pred answer": "ski", "question_id": 3084965, "best approach": "wiki, concept", "verif answer": "snowboard", "anno approach": "wiki", "verif wiki answer": "snowboard(0.7166)", "verif concept answer": "snowboard(0.7227)", "verif image answer": "ski(0.6265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308496.jpg"}, {"question": "what event is this", "gt answer": "birthday(1.00)", "pred answer": "birthday", "question_id": 1319095, "best approach": "", "verif answer": "birthday cake", "anno approach": "", "verif wiki answer": "birthday cake(0.7263)", "verif concept answer": "birthday cake(0.7292)", "verif image answer": "birthday cake(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000131909.jpg"}, {"question": "are they above or below this mountain 's treeline", "gt answer": "below(1.00)<br/>above(1.00)", "pred answer": "mountain", "question_id": 3261615, "best approach": "", "verif answer": "overhead", "anno approach": "", "verif wiki answer": "in air(0.6542)", "verif concept answer": "in air(0.7183)", "verif image answer": "overhead(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000326161.jpg"}, {"question": "did the player miss or hit the ball", "gt answer": "hit(1.00)", "pred answer": "hit ball", "question_id": 1493885, "best approach": "image", "verif answer": "strike", "anno approach": "image", "verif wiki answer": "strike(0.7235)", "verif concept answer": "strike(0.7297)", "verif image answer": "hit(0.7227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149388.jpg"}, {"question": "was this photo taken indoors or outdoors", "gt answer": "outdoor(1.00)", "pred answer": "outdoor", "question_id": 1547555, "best approach": "", "verif answer": "outside", "anno approach": "", "verif wiki answer": "outside(0.5419)", "verif concept answer": "outside(0.6308)", "verif image answer": "outside(0.5099)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154755.jpg"}, {"question": "who was a famous person was supposedly was struck by lighting doing this", "gt answer": "benjamin franklin(1.00)<br/>ben franklin(0.60)", "pred answer": "benjamin franklin", "question_id": 1149405, "best approach": "wiki, concept, image", "verif answer": "benjamin franklin", "anno approach": "wiki", "verif wiki answer": "benjamin franklin(0.7268)", "verif concept answer": "benjamin franklin(0.7090)", "verif image answer": "benjamin franklin(0.6993)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114940.jpg"}, {"question": "what does it look like this toy dog is doing", "gt answer": "use laptop(1.00)<br/>view(0.60)", "pred answer": "play video game", "question_id": 1636835, "best approach": "", "verif answer": "wash it", "anno approach": "", "verif wiki answer": "wash it(0.7008)", "verif concept answer": "wash it(0.6828)", "verif image answer": "wash it(0.6873)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163683.jpg"}, {"question": "is the pastry hot or cold", "gt answer": "hot(1.00)<br/>cold(1.00)", "pred answer": "hot", "question_id": 1018745, "best approach": "wiki, concept, image", "verif answer": "hot", "anno approach": "wiki", "verif wiki answer": "hot(0.7042)", "verif concept answer": "hot(0.7255)", "verif image answer": "hot(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000101874.jpg"}, {"question": "what item will change soon in this picture", "gt answer": "picture(1.00)<br/>screen(0.60)<br/>cat(0.60)<br/>tv(0.60)", "pred answer": "camera", "question_id": 2401555, "best approach": "wiki, concept, image", "verif answer": "picture", "anno approach": "wiki", "verif wiki answer": "picture(0.7060)", "verif concept answer": "picture(0.7050)", "verif image answer": "picture(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240155.jpg"}, {"question": "what type of industry do those trucks work in", "gt answer": "log(1.00)<br/>lumber(0.60)", "pred answer": "construction", "question_id": 3002075, "best approach": "wiki", "verif answer": "pine", "anno approach": "wiki", "verif wiki answer": "lumber(0.6982)", "verif concept answer": "pine(0.6944)", "verif image answer": "pine(0.7107)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300207.jpg"}, {"question": "what league is this", "gt answer": "little league(1.00)<br/>baseball(0.60)<br/>little(0.60)", "pred answer": "baseball", "question_id": 4355755, "best approach": "wiki", "verif answer": "high school", "anno approach": "wiki", "verif wiki answer": "little league(0.6543)", "verif concept answer": "little(0.6573)", "verif image answer": "high school(0.6943)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435575.jpg"}, {"question": "what type of hat is the teddy bear wearing", "gt answer": "bonnet(1.00)", "pred answer": "knit", "question_id": 1297715, "best approach": "", "verif answer": "bowtie", "anno approach": "", "verif wiki answer": "bowtie(0.6980)", "verif concept answer": "bowtie(0.7109)", "verif image answer": "bowtie(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129771.jpg"}, {"question": "what company runs the bus", "gt answer": "greenwave(1.00)", "pred answer": "ford", "question_id": 5731915, "best approach": "", "verif answer": "schwinn", "anno approach": "", "verif wiki answer": "schwinn(0.7071)", "verif concept answer": "schwinn(0.7064)", "verif image answer": "schwinn(0.6918)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000573191.jpg"}, {"question": "what century is this", "gt answer": "19th(1.00)<br/>18th(0.60)<br/>20th(0.60)", "pred answer": "19th", "question_id": 204645, "best approach": "wiki, concept", "verif answer": "20th", "anno approach": "wiki", "verif wiki answer": "19th(0.7133)", "verif concept answer": "19th(0.6964)", "verif image answer": "20th(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020464.jpg"}, {"question": "how do you clean this type of fabric", "gt answer": "soap and water(1.00)<br/>brush(0.60)", "pred answer": "bleach", "question_id": 1235825, "best approach": "wiki, concept, image", "verif answer": "soap and water", "anno approach": "wiki", "verif wiki answer": "soap and water(0.7017)", "verif concept answer": "soap and water(0.7266)", "verif image answer": "soap and water(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123582.jpg"}, {"question": "what kind of architecture is this", "gt answer": "victorian(1.00)<br/>roman(0.60)<br/>stone(0.60)", "pred answer": "gothic", "question_id": 2106865, "best approach": "", "verif answer": "gothic", "anno approach": "", "verif wiki answer": "gothic(0.6751)", "verif concept answer": "gothic(0.6730)", "verif image answer": "gothic(0.6804)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210686.jpg"}, {"question": "what type of gun does this police man carry", "gt answer": "9mm(1.00)", "pred answer": "motorcycle", "question_id": 4053165, "best approach": "wiki, concept, image", "verif answer": "9mm", "anno approach": "image, wiki", "verif wiki answer": "9mm(0.6151)", "verif concept answer": "9mm(0.5865)", "verif image answer": "9mm(0.6439)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405316.jpg"}, {"question": "what musical instrument is on the left", "gt answer": "guitar(1.00)", "pred answer": "piano", "question_id": 5432765, "best approach": "wiki, concept, image", "verif answer": "guitar", "anno approach": "concept, wiki", "verif wiki answer": "guitar(0.7251)", "verif concept answer": "guitar(0.7086)", "verif image answer": "guitar(0.6609)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543276.jpg"}, {"question": "what type of bird is in this photo", "gt answer": "crow(1.00)<br/>sparrow(0.60)<br/>hummingbird(0.60)", "pred answer": "crow", "question_id": 1815665, "best approach": "wiki, concept, image", "verif answer": "crow", "anno approach": "concept, wiki", "verif wiki answer": "crow(0.7241)", "verif concept answer": "crow(0.7168)", "verif image answer": "crow(0.6741)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181566.jpg"}, {"question": "how much do these objects weigh", "gt answer": "20 pounds(1.00)<br/>50(0.60)<br/>100 lbs(0.60)", "pred answer": "lot", "question_id": 2499685, "best approach": "wiki", "verif answer": "100 lbs", "anno approach": "wiki", "verif wiki answer": "20 pounds(0.5744)", "verif concept answer": "100 lbs(0.5723)", "verif image answer": "100 lbs(0.7001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249968.jpg"}, {"question": "which breed of apple is this", "gt answer": "gala(1.00)<br/>fuji(0.60)", "pred answer": "granny smith", "question_id": 4811655, "best approach": "", "verif answer": "granny smith", "anno approach": "", "verif wiki answer": "granny smith(0.7300)", "verif concept answer": "granny smith(0.7291)", "verif image answer": "granny smith(0.7046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481165.jpg"}, {"question": "what kind of skiing is this", "gt answer": "downhill(1.00)<br/>slalom(0.60)<br/>race(0.60)", "pred answer": "downhill", "question_id": 3764905, "best approach": "", "verif answer": "cross country", "anno approach": "", "verif wiki answer": "cross country(0.7182)", "verif concept answer": "cross country(0.7207)", "verif image answer": "cross country(0.6810)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376490.jpg"}, {"question": "what is usually displayed on the large white object in the foreground of the picture", "gt answer": "name(1.00)<br/>project(0.60)<br/>flag(0.60)", "pred answer": "build", "question_id": 3862675, "best approach": "", "verif answer": "identification", "anno approach": "", "verif wiki answer": "identification(0.6943)", "verif concept answer": "identification(0.6834)", "verif image answer": "identification(0.7009)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000386267.jpg"}, {"question": "what animal is pictured", "gt answer": "red panda(1.00)<br/>fox(0.60)<br/>bear(0.60)", "pred answer": "tiger", "question_id": 3080985, "best approach": "wiki, concept, image", "verif answer": "bear", "anno approach": "concept, wiki", "verif wiki answer": "bear(0.6447)", "verif concept answer": "bear(0.6328)", "verif image answer": "bear(0.5851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308098.jpg"}, {"question": "who holds the record for this activity of this sport", "gt answer": "barry bond(1.00)", "pred answer": "babe ruth", "question_id": 2524705, "best approach": "", "verif answer": "babe ruth", "anno approach": "", "verif wiki answer": "babe ruth(0.6929)", "verif concept answer": "fast(0.6636)", "verif image answer": "babe ruth(0.6720)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252470.jpg"}, {"question": "is this at the office or in the home", "gt answer": "home(1.00)<br/>office(0.60)", "pred answer": "home", "question_id": 5120885, "best approach": "wiki, concept, image", "verif answer": "home", "anno approach": "wiki", "verif wiki answer": "home(0.7201)", "verif concept answer": "home(0.7223)", "verif image answer": "home(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512088.jpg"}, {"question": "what is special about this player' 's arm", "gt answer": "broken(1.00)", "pred answer": "short", "question_id": 880875, "best approach": "", "verif answer": "art", "anno approach": "", "verif wiki answer": "trash(0.6218)", "verif concept answer": "trash(0.6800)", "verif image answer": "art(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088087.jpg"}, {"question": "what is the complimentary color to the dog 's outfit", "gt answer": "blue(1.00)<br/>black(0.60)<br/>red(0.60)<br/>green(0.60)", "pred answer": "red", "question_id": 282765, "best approach": "wiki, concept, image", "verif answer": "black", "anno approach": "wiki", "verif wiki answer": "black(0.7134)", "verif concept answer": "black(0.6538)", "verif image answer": "red(0.6503)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028276.jpg"}, {"question": "how much does this animal weigh when it is born", "gt answer": "100 lbs(1.00)", "pred answer": "500", "question_id": 1905515, "best approach": "concept, image", "verif answer": "100 lbs", "anno approach": "image", "verif wiki answer": "ton(0.6959)", "verif concept answer": "100 lbs(0.6850)", "verif image answer": "100 lbs(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190551.jpg"}, {"question": "what type of flower is shown in this photo", "gt answer": "rose(1.00)", "pred answer": "rose", "question_id": 1141945, "best approach": "", "verif answer": "tulip", "anno approach": "", "verif wiki answer": "tulip(0.6695)", "verif concept answer": "tulip(0.6009)", "verif image answer": "daisy(0.6575)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114194.jpg"}, {"question": "what is the type of building in this picture", "gt answer": "cabin(1.00)<br/>garage(0.60)<br/>shed(0.60)", "pred answer": "mountain", "question_id": 590935, "best approach": "", "verif answer": "grand canyon", "anno approach": "", "verif wiki answer": "grand canyon(0.6587)", "verif concept answer": "grand canyon(0.6397)", "verif image answer": "grand canyon(0.6183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059093.jpg"}, {"question": "what are you suppose to never do with the image in this picture", "gt answer": "run(1.00)<br/>run with scissor(0.60)", "pred answer": "cut", "question_id": 4355435, "best approach": "wiki", "verif answer": "fun", "anno approach": "wiki", "verif wiki answer": "run with scissor(0.6894)", "verif concept answer": "play dead(0.7259)", "verif image answer": "fun(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435543.jpg"}, {"question": "what breed of dog is this", "gt answer": "lab(1.00)<br/>greyhound(0.60)", "pred answer": "lab", "question_id": 3359555, "best approach": "concept", "verif answer": "labrador", "anno approach": "concept", "verif wiki answer": "labrador(0.6841)", "verif concept answer": "lab(0.6731)", "verif image answer": "brown(0.6792)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335955.jpg"}, {"question": "how much longer will these flowers live", "gt answer": "2 days(1.00)<br/>5 days(0.60)<br/>week(0.60)", "pred answer": "week", "question_id": 4456895, "best approach": "image", "verif answer": "1 month", "anno approach": "image", "verif wiki answer": "2 weeks(0.6443)", "verif concept answer": "1 month(0.6580)", "verif image answer": "5 days(0.6196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445689.jpg"}, {"question": "which kind of rope is used around the neck of dog shown in this photo", "gt answer": "leash(1.00)<br/>nylon(0.60)<br/>leather(0.60)", "pred answer": "tie", "question_id": 584375, "best approach": "", "verif answer": "plastic", "anno approach": "", "verif wiki answer": "plastic(0.6816)", "verif concept answer": "plastic(0.6868)", "verif image answer": "plastic(0.7123)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058437.jpg"}, {"question": "what is the age of the girl sitting on the ground in the teal green dress", "gt answer": "17(1.00)<br/>16(0.60)<br/>18(0.60)<br/>12(0.60)", "pred answer": "21", "question_id": 4049906, "best approach": "wiki", "verif answer": "19", "anno approach": "wiki", "verif wiki answer": "12(0.6310)", "verif concept answer": "19(0.6426)", "verif image answer": "19(0.6919)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404990.jpg"}, {"question": "what photo technique is being used", "gt answer": "sephia(1.00)<br/>filter(0.60)", "pred answer": "black and white", "question_id": 5520925, "best approach": "", "verif answer": "black and white", "anno approach": "", "verif wiki answer": "vandalism(0.6781)", "verif concept answer": "vandalism(0.6636)", "verif image answer": "black and white(0.7221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552092.jpg"}, {"question": "what is this girl 's favorite disney movie", "gt answer": "cinderella(1.00)", "pred answer": "mickey mouse", "question_id": 3249525, "best approach": "", "verif answer": "mickey mouse", "anno approach": "", "verif wiki answer": "mickey mouse(0.7302)", "verif concept answer": "mickey mouse(0.7298)", "verif image answer": "mickey mouse(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324952.jpg"}, {"question": "what are these people about to do", "gt answer": "buy food(1.00)<br/>eat(1.00)", "pred answer": "eat", "question_id": 733025, "best approach": "wiki, concept", "verif answer": "buy food", "anno approach": "", "verif wiki answer": "buy food(0.6999)", "verif concept answer": "buy food(0.6781)", "verif image answer": "cut cake(0.6602)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073302.jpg"}, {"question": "which color on the dog is associated with lent and easter", "gt answer": "purple(1.00)<br/>pink(0.60)<br/>white(0.60)", "pred answer": "blue", "question_id": 3519145, "best approach": "concept, image", "verif answer": "red", "anno approach": "concept", "verif wiki answer": "red(0.7236)", "verif concept answer": "purple(0.6573)", "verif image answer": "purple(0.5997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351914.jpg"}, {"question": "what movie character is represented", "gt answer": "gandalf(1.00)", "pred answer": "mary poppins", "question_id": 1744065, "best approach": "", "verif answer": "hummingbird", "anno approach": "", "verif wiki answer": "hummingbird(0.6922)", "verif concept answer": "hummingbird(0.7116)", "verif image answer": "hummingbird(0.5147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174406.jpg"}, {"question": "what does the toilet lid say", "gt answer": "dirty(1.00)", "pred answer": "hello", "question_id": 4793575, "best approach": "wiki, image", "verif answer": "dirty", "anno approach": "wiki", "verif wiki answer": "dirty(0.5002)", "verif concept answer": "down(0.5000)", "verif image answer": "dirty(0.5019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479357.jpg"}, {"question": "what are these model buildings made out of", "gt answer": "plastic(0.60)<br/>wood(0.60)<br/>brick(1.00)<br/>stone(0.60)", "pred answer": "brick", "question_id": 5557155, "best approach": "wiki, concept, image", "verif answer": "brick", "anno approach": "image, wiki", "verif wiki answer": "brick(0.6651)", "verif concept answer": "brick(0.6359)", "verif image answer": "brick(0.6873)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555715.jpg"}, {"question": "what does this walking sign mean", "gt answer": "safe to cross(1.00)<br/>stop(0.60)", "pred answer": "direct", "question_id": 162095, "best approach": "wiki, concept, image", "verif answer": "stop", "anno approach": "image, concept, wiki", "verif wiki answer": "stop(0.5561)", "verif concept answer": "stop(0.6722)", "verif image answer": "stop(0.7011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016209.jpg"}, {"question": "what are the ingredients for the dish", "gt answer": "vegetable(1.00)<br/>lettuce(0.60)<br/>veggies(0.60)", "pred answer": "vegetable", "question_id": 601725, "best approach": "wiki, image", "verif answer": "veggies", "anno approach": "image, wiki", "verif wiki answer": "veggies(0.5894)", "verif concept answer": "kale(0.6253)", "verif image answer": "veggies(0.6429)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060172.jpg"}, {"question": "where could you borrow the object on the bed from", "gt answer": "library(1.00)<br/>play(0.60)", "pred answer": "amazon", "question_id": 5298275, "best approach": "wiki", "verif answer": "library", "anno approach": "wiki", "verif wiki answer": "library(0.7108)", "verif concept answer": "bookstore(0.6901)", "verif image answer": "bookstore(0.7031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529827.jpg"}, {"question": "what type of console is the game for", "gt answer": "xbox(1.00)", "pred answer": "wii", "question_id": 540525, "best approach": "wiki, concept", "verif answer": "xbox", "anno approach": "wiki", "verif wiki answer": "xbox(0.7282)", "verif concept answer": "xbox(0.7290)", "verif image answer": "wii(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054052.jpg"}, {"question": "when was the object the person is wearing on their feet first produced in the united states", "gt answer": "1700(1.00)<br/>1950s(0.60)<br/>2002(0.60)<br/>1892(0.60)", "pred answer": "1948", "question_id": 450865, "best approach": "wiki, concept", "verif answer": "1892", "anno approach": "", "verif wiki answer": "1700(0.7242)", "verif concept answer": "1700(0.7184)", "verif image answer": "1892(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045086.jpg"}, {"question": "what are these vehicles driving on", "gt answer": "road(1.00)<br/>asphalt(0.60)", "pred answer": "track", "question_id": 3986155, "best approach": "wiki, concept, image", "verif answer": "asphalt", "anno approach": "wiki", "verif wiki answer": "asphalt(0.6614)", "verif concept answer": "asphalt(0.6600)", "verif image answer": "asphalt(0.6502)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398615.jpg"}, {"question": "what is the dog doing", "gt answer": "herd(1.00)<br/>pee(0.60)", "pred answer": "herd", "question_id": 4809505, "best approach": "wiki, concept, image", "verif answer": "herd", "anno approach": "image, wiki", "verif wiki answer": "herd(0.6767)", "verif concept answer": "herd(0.6444)", "verif image answer": "herd(0.6998)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480950.jpg"}, {"question": "if these players stay outside and don't drink enough they could fall prey to what dangerous condition", "gt answer": "dehydration(1.00)", "pred answer": "danger", "question_id": 455245, "best approach": "", "verif answer": "lion king", "anno approach": "", "verif wiki answer": "lion king(0.6895)", "verif concept answer": "lion king(0.6998)", "verif image answer": "lion king(0.7159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045524.jpg"}, {"question": "what type of bear is that", "gt answer": "grizzly(1.00)<br/>brown bear(0.60)<br/>brown(0.60)", "pred answer": "brown", "question_id": 3701935, "best approach": "wiki, concept, image", "verif answer": "brown", "anno approach": "wiki", "verif wiki answer": "brown(0.7192)", "verif concept answer": "brown(0.7233)", "verif image answer": "brown(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370193.jpg"}, {"question": "what type of bird is this", "gt answer": "owl(1.00)", "pred answer": "vulture", "question_id": 1690355, "best approach": "", "verif answer": "eagle", "anno approach": "", "verif wiki answer": "eagle(0.6050)", "verif concept answer": "eagle(0.6277)", "verif image answer": "eagle(0.6216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169035.jpg"}, {"question": "what is the large structure in the background of this photo made of", "gt answer": "brick(1.00)<br/>build(0.60)", "pred answer": "brick", "question_id": 15625, "best approach": "concept", "verif answer": "brick and mortar", "anno approach": "concept", "verif wiki answer": "apartment(0.6646)", "verif concept answer": "brick(0.6304)", "verif image answer": "brick and mortar(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001562.jpg"}, {"question": "who normally rides this type of transportation", "gt answer": "kid(1.00)<br/>passenger(0.60)<br/>student(0.60)", "pred answer": "human", "question_id": 3159975, "best approach": "", "verif answer": "children", "anno approach": "", "verif wiki answer": "children(0.7077)", "verif concept answer": "children(0.7046)", "verif image answer": "children(0.6967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315997.jpg"}, {"question": "what part of the body does this activity work the most of", "gt answer": "leg(1.00)<br/>arm(1.00)", "pred answer": "arm", "question_id": 607205, "best approach": "wiki", "verif answer": "tan", "anno approach": "wiki", "verif wiki answer": "leg(0.6826)", "verif concept answer": "tan(0.6523)", "verif image answer": "tan(0.7164)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060720.jpg"}, {"question": "what is the name of the trick the motor cyclist is doing", "gt answer": "wheelie(1.00)<br/>barn(0.60)", "pred answer": "ride", "question_id": 4204755, "best approach": "image", "verif answer": "wheelie", "anno approach": "image", "verif wiki answer": "grind(0.6364)", "verif concept answer": "grind(0.6000)", "verif image answer": "wheelie(0.6750)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420475.jpg"}, {"question": "what kind of bull is this", "gt answer": "longhorn(1.00)<br/>brown(0.60)", "pred answer": "brown", "question_id": 1802535, "best approach": "wiki, concept", "verif answer": "longhorn", "anno approach": "wiki", "verif wiki answer": "longhorn(0.7006)", "verif concept answer": "longhorn(0.7007)", "verif image answer": "grizzly(0.6982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180253.jpg"}, {"question": "what companies sell the device in this photo", "gt answer": "motorola(1.00)", "pred answer": "nokia", "question_id": 4903565, "best approach": "", "verif answer": "flip phone", "anno approach": "", "verif wiki answer": "samsung(0.5994)", "verif concept answer": "samsung(0.6703)", "verif image answer": "flip phone(0.7056)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490356.jpg"}, {"question": "what is being sold on that truck", "gt answer": "soda(1.00)<br/>coke(0.60)<br/>coca cola(0.60)<br/>hotdog(0.60)", "pred answer": "ice cream", "question_id": 1846695, "best approach": "concept", "verif answer": "coca cola", "anno approach": "concept", "verif wiki answer": "coca cola(0.6687)", "verif concept answer": "soda(0.6594)", "verif image answer": "coca cola(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184669.jpg"}, {"question": "what breed of dog is this", "gt answer": "boxer(1.00)", "pred answer": "labrador", "question_id": 2374255, "best approach": "", "verif answer": "mutt", "anno approach": "", "verif wiki answer": "mutt(0.6713)", "verif concept answer": "mutt(0.6502)", "verif image answer": "mutt(0.6575)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237425.jpg"}, {"question": "what is being pulled by the truck", "gt answer": "camper(1.00)<br/>trailer(1.00)<br/>rv(0.60)", "pred answer": "food", "question_id": 5281985, "best approach": "image", "verif answer": "camper", "anno approach": "image", "verif wiki answer": "carriage(0.5859)", "verif concept answer": "carriage(0.6706)", "verif image answer": "camper(0.6866)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528198.jpg"}, {"question": "where is this happening", "gt answer": "circus(1.00)<br/>rodeo(0.60)", "pred answer": "stable", "question_id": 3635765, "best approach": "wiki, concept", "verif answer": "horse show", "anno approach": "wiki", "verif wiki answer": "rodeo(0.6045)", "verif concept answer": "rodeo(0.5553)", "verif image answer": "horse show(0.6734)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363576.jpg"}, {"question": "what type of device is the man using", "gt answer": "phone(1.00)<br/>smartphone(0.60)<br/>cell phone(0.60)", "pred answer": "cell phone", "question_id": 3840585, "best approach": "wiki, concept, image", "verif answer": "phone", "anno approach": "wiki", "verif wiki answer": "phone(0.6775)", "verif concept answer": "phone(0.5974)", "verif image answer": "phone(0.6118)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384058.jpg"}, {"question": "what name is given to the figure at the plate", "gt answer": "batter(1.00)<br/>umpire(0.60)<br/>catcher(0.60)", "pred answer": "babe ruth", "question_id": 3331525, "best approach": "concept", "verif answer": "pitcher", "anno approach": "concept", "verif wiki answer": "hitter(0.6945)", "verif concept answer": "catcher(0.6104)", "verif image answer": "pitcher(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333152.jpg"}, {"question": "what toping is on the frankfurter on the left of the two shown", "gt answer": "sauerkraut(1.00)", "pred answer": "cheese", "question_id": 2730535, "best approach": "", "verif answer": "cheese", "anno approach": "", "verif wiki answer": "cheese(0.6692)", "verif concept answer": "cheese(0.6774)", "verif image answer": "cheese(0.6759)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273053.jpg"}, {"question": "is it day or night here", "gt answer": "day(1.00)<br/>night(1.00)", "pred answer": "day", "question_id": 3701215, "best approach": "concept, image", "verif answer": "day", "anno approach": "", "verif wiki answer": "daytime(0.6720)", "verif concept answer": "day(0.7061)", "verif image answer": "day(0.7204)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370121.jpg"}, {"question": "what kind of electronic is on the table", "gt answer": "laptop(1.00)", "pred answer": "laptop", "question_id": 4607035, "best approach": "wiki, image", "verif answer": "laptop", "anno approach": "wiki", "verif wiki answer": "laptop(0.7259)", "verif concept answer": "computer(0.7141)", "verif image answer": "laptop(0.6623)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460703.jpg"}, {"question": "what is it called when the sun is here", "gt answer": "sunset(1.00)<br/>shade(0.60)", "pred answer": "shadow", "question_id": 2870035, "best approach": "image", "verif answer": "sunset", "anno approach": "image", "verif wiki answer": "shade(0.6838)", "verif concept answer": "sunrise(0.6621)", "verif image answer": "sunset(0.7098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287003.jpg"}, {"question": "what popular food are these animals slaughtered to create", "gt answer": "hamburger(1.00)<br/>steak(0.60)<br/>meat(0.60)<br/>beef(0.60)", "pred answer": "milk", "question_id": 1845045, "best approach": "wiki, concept, image", "verif answer": "beef", "anno approach": "concept, wiki", "verif wiki answer": "beef(0.6922)", "verif concept answer": "beef(0.6818)", "verif image answer": "steak(0.6070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184504.jpg"}, {"question": "why the person is on the bed", "gt answer": "sick(1.00)<br/>nighttime(0.60)<br/>sleepy(0.60)<br/>rest(0.60)", "pred answer": "sleep", "question_id": 3981245, "best approach": "", "verif answer": "tired", "anno approach": "", "verif wiki answer": "tired(0.7048)", "verif concept answer": "tired(0.7075)", "verif image answer": "tired(0.6781)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398124.jpg"}, {"question": "how long do the teeth on this animal get", "gt answer": "8 inches(1.00)<br/>10 feet(0.60)", "pred answer": "8 inches", "question_id": 4957535, "best approach": "wiki, concept, image", "verif answer": "8 inches", "anno approach": "wiki", "verif wiki answer": "8 inches(0.6785)", "verif concept answer": "8 inches(0.6536)", "verif image answer": "8 inches(0.6788)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495753.jpg"}, {"question": "this baseball team originates from what city", "gt answer": "baltimore(1.00)", "pred answer": "baltimore", "question_id": 3465215, "best approach": "", "verif answer": "oakland", "anno approach": "", "verif wiki answer": "chicago(0.6793)", "verif concept answer": "chicago(0.6683)", "verif image answer": "oakland(0.7164)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346521.jpg"}, {"question": "the fork is stuck into what kind of vegetable", "gt answer": "cucumber(1.00)", "pred answer": "spinach", "question_id": 5183925, "best approach": "", "verif answer": "ketchup", "anno approach": "", "verif wiki answer": "ketchup(0.6936)", "verif concept answer": "ketchup(0.6679)", "verif image answer": "omega 3(0.6924)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518392.jpg"}, {"question": "what item seen here is often depicted as winding up on the head of the intoxicated", "gt answer": "lampshade(1.00)<br/>pizza(0.60)<br/>snake(0.60)", "pred answer": "santa", "question_id": 1299125, "best approach": "", "verif answer": "picnic", "anno approach": "", "verif wiki answer": "picnic(0.7226)", "verif concept answer": "picnic(0.7015)", "verif image answer": "picnic(0.6477)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129912.jpg"}, {"question": "what is the top speed of the white motorcycle", "gt answer": "120 mph(1.00)", "pred answer": "20 mph", "question_id": 5625105, "best approach": "", "verif answer": "500 mph", "anno approach": "", "verif wiki answer": "500 mph(0.6707)", "verif concept answer": "500 mph(0.5920)", "verif image answer": "500 mph(0.6545)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000562510.jpg"}, {"question": "what kind of dog", "gt answer": "dalmation(1.00)<br/>dalmatian(0.60)", "pred answer": "dalmation", "question_id": 5174875, "best approach": "image", "verif answer": "dalmation", "anno approach": "image", "verif wiki answer": "dalmatian(0.7271)", "verif concept answer": "dalmatian(0.7238)", "verif image answer": "dalmation(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517487.jpg"}, {"question": "the way the fruit is laid on this pie is called what", "gt answer": "slice(1.00)<br/>swirl(0.60)<br/>dress(0.60)", "pred answer": "muscle", "question_id": 488485, "best approach": "wiki, concept", "verif answer": "fry", "anno approach": "concept, wiki", "verif wiki answer": "slice(0.5823)", "verif concept answer": "slice(0.6847)", "verif image answer": "fry(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048848.jpg"}, {"question": "why can't one park here", "gt answer": "fire lane(1.00)<br/>illegal(0.60)<br/>hydrant(0.60)", "pred answer": "park", "question_id": 4512195, "best approach": "wiki, concept, image", "verif answer": "fire lane", "anno approach": "wiki", "verif wiki answer": "fire lane(0.6483)", "verif concept answer": "fire lane(0.6526)", "verif image answer": "fire lane(0.6451)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451219.jpg"}, {"question": "what would these people be doing with this bus", "gt answer": "tour(1.00)<br/>travel(1.00)<br/>transport(0.60)", "pred answer": "stand", "question_id": 5703855, "best approach": "wiki, concept, image", "verif answer": "transport", "anno approach": "image, wiki", "verif wiki answer": "transport(0.6471)", "verif concept answer": "transport(0.6599)", "verif image answer": "transport(0.7111)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570385.jpg"}, {"question": "what type of nutrition value does the dish the lady is making have", "gt answer": "carbohydrate(1.00)<br/>fiber(0.60)", "pred answer": "calories", "question_id": 830005, "best approach": "", "verif answer": "protein", "anno approach": "", "verif wiki answer": "protein(0.6947)", "verif concept answer": "protein(0.6795)", "verif image answer": "protein(0.6942)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083000.jpg"}, {"question": "what food is this", "gt answer": "bbq(0.60)<br/>burger(1.00)<br/>hamburger(0.60)", "pred answer": "pizza", "question_id": 2198805, "best approach": "", "verif answer": "roast beef", "anno approach": "", "verif wiki answer": "roast beef(0.6823)", "verif concept answer": "roast beef(0.7106)", "verif image answer": "roast beef(0.5622)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219880.jpg"}, {"question": "is this a public or private air strip", "gt answer": "private(1.00)<br/>public(0.60)", "pred answer": "public", "question_id": 5656415, "best approach": "image", "verif answer": "private", "anno approach": "image", "verif wiki answer": "passenger(0.7216)", "verif concept answer": "passenger(0.7219)", "verif image answer": "private(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000565641.jpg"}, {"question": "what country is associated with the religion shown on the sign", "gt answer": "israel(1.00)<br/>saudi arabia(0.60)<br/>england(0.60)", "pred answer": "india", "question_id": 4873995, "best approach": "wiki, concept", "verif answer": "israel", "anno approach": "wiki", "verif wiki answer": "israel(0.6962)", "verif concept answer": "israel(0.6668)", "verif image answer": "france(0.6420)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487399.jpg"}, {"question": "what branch of the miltary are these men in", "gt answer": "army(1.00)<br/>marine(1.00)<br/>navy(0.60)", "pred answer": "navy", "question_id": 3297565, "best approach": "concept, image", "verif answer": "air force", "anno approach": "concept", "verif wiki answer": "air force(0.6760)", "verif concept answer": "navy(0.6613)", "verif image answer": "navy(0.5548)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329756.jpg"}, {"question": "what kind have bathroom is this", "gt answer": "men(1.00)", "pred answer": "baby", "question_id": 4710855, "best approach": "", "verif answer": "bathroom", "anno approach": "", "verif wiki answer": "bathroom(0.6944)", "verif concept answer": "bathroom(0.6687)", "verif image answer": "biker(0.6862)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471085.jpg"}, {"question": "what is the name of this activity", "gt answer": "water ski(1.00)", "pred answer": "fall", "question_id": 4932935, "best approach": "image", "verif answer": "water ski", "anno approach": "image", "verif wiki answer": "wakeboarding(0.5003)", "verif concept answer": "wakeboarding(0.5007)", "verif image answer": "water ski(0.5030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000493293.jpg"}, {"question": "what food do these animals eat", "gt answer": "dog food(1.00)<br/>kibble(0.60)<br/>meat(0.60)", "pred answer": "meat", "question_id": 908275, "best approach": "wiki, image", "verif answer": "dog food", "anno approach": "wiki", "verif wiki answer": "dog food(0.6860)", "verif concept answer": "meat(0.6824)", "verif image answer": "dog food(0.6719)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090827.jpg"}, {"question": "name the dish the man is eating", "gt answer": "chip(1.00)<br/>popcorn(1.00)", "pred answer": "meat", "question_id": 5491845, "best approach": "", "verif answer": "taco", "anno approach": "", "verif wiki answer": "taco(0.6663)", "verif concept answer": "taco(0.6863)", "verif image answer": "taco(0.7108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000549184.jpg"}, {"question": "what material are the vases made of", "gt answer": "glass(1.00)<br/>sand(0.60)", "pred answer": "glass", "question_id": 3038045, "best approach": "", "verif answer": "wine glass", "anno approach": "", "verif wiki answer": "wine glass(0.6988)", "verif concept answer": "wine glass(0.6580)", "verif image answer": "wine glass(0.7145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303804.jpg"}, {"question": "what part of the boats are not showing and use the wind", "gt answer": "sail(1.00)", "pred answer": "wind", "question_id": 906765, "best approach": "", "verif answer": "sailboat", "anno approach": "", "verif wiki answer": "wind(0.6788)", "verif concept answer": "wind(0.6707)", "verif image answer": "sailboat(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090676.jpg"}, {"question": "what time of day is it in this picture", "gt answer": "night(1.00)<br/>even(0.60)", "pred answer": "night", "question_id": 159525, "best approach": "wiki, concept, image", "verif answer": "night", "anno approach": "image, wiki", "verif wiki answer": "night(0.6659)", "verif concept answer": "night(0.6802)", "verif image answer": "night(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015952.jpg"}, {"question": "what is the name of the chair in which the man is seated", "gt answer": "recliner(1.00)<br/>couch(0.60)<br/>lounge(0.60)", "pred answer": "sofa", "question_id": 4178345, "best approach": "wiki, concept, image", "verif answer": "couch", "anno approach": "wiki", "verif wiki answer": "couch(0.5863)", "verif concept answer": "couch(0.6120)", "verif image answer": "couch(0.5980)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417834.jpg"}, {"question": "where is this food likely displayed", "gt answer": "supermarket(1.00)<br/>produce(1.00)<br/>grocery store(0.60)", "pred answer": "produce", "question_id": 792245, "best approach": "wiki, concept", "verif answer": "produce", "anno approach": "concept, wiki", "verif wiki answer": "produce(0.6436)", "verif concept answer": "produce(0.6933)", "verif image answer": "grocery store(0.6762)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079224.jpg"}, {"question": "how tall are the orange markers in the roadway", "gt answer": "3 feet(1.00)<br/>yard(0.60)", "pred answer": "3 feet", "question_id": 2788235, "best approach": "", "verif answer": "30 feet", "anno approach": "", "verif wiki answer": "2 feet(0.6369)", "verif concept answer": "2 feet(0.6321)", "verif image answer": "30 feet(0.7184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278823.jpg"}, {"question": "which movie starring gene kelley contained a famous muscial number with this item in", "gt answer": "sing in rain(1.00)", "pred answer": "disney", "question_id": 306435, "best approach": "wiki", "verif answer": "wizard of oz", "anno approach": "wiki", "verif wiki answer": "sing in rain(0.7309)", "verif concept answer": "wizard of oz(0.7306)", "verif image answer": "wizard of oz(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030643.jpg"}, {"question": "what type of photo is this man taking", "gt answer": "selfie(1.00)", "pred answer": "black and white", "question_id": 1869065, "best approach": "image", "verif answer": "selfie", "anno approach": "image", "verif wiki answer": "take picture(0.6813)", "verif concept answer": "take picture(0.6486)", "verif image answer": "selfie(0.7033)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186906.jpg"}, {"question": "how deep is this water", "gt answer": "15 feet(1.00)", "pred answer": "70 years", "question_id": 4366265, "best approach": "", "verif answer": "2 feet", "anno approach": "", "verif wiki answer": "2 stories(0.6964)", "verif concept answer": "2 stories(0.6985)", "verif image answer": "2 feet(0.7165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436626.jpg"}, {"question": "is it the mother 's or daughter 's birthday", "gt answer": "daughter(1.00)", "pred answer": "mother", "question_id": 2635165, "best approach": "wiki, concept", "verif answer": "daughter", "anno approach": "wiki", "verif wiki answer": "daughter(0.7276)", "verif concept answer": "daughter(0.7052)", "verif image answer": "valentine(0.7059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263516.jpg"}, {"question": "is the cat indoors or outdoors", "gt answer": "indoor(1.00)", "pred answer": "indoor", "question_id": 4736345, "best approach": "wiki, concept, image", "verif answer": "indoor", "anno approach": "wiki", "verif wiki answer": "indoor(0.7261)", "verif concept answer": "indoor(0.7303)", "verif image answer": "indoor(0.7147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473634.jpg"}, {"question": "what are these men looking at", "gt answer": "television(1.00)<br/>tv(1.00)", "pred answer": "tv", "question_id": 5660545, "best approach": "wiki", "verif answer": "camera", "anno approach": "wiki", "verif wiki answer": "tv(0.6738)", "verif concept answer": "camera(0.6619)", "verif image answer": "camera(0.7095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566054.jpg"}, {"question": "where in the world are there big mountains", "gt answer": "switzerland(1.00)", "pred answer": "north america", "question_id": 2838845, "best approach": "image", "verif answer": "scotland", "anno approach": "image", "verif wiki answer": "scotland(0.6643)", "verif concept answer": "norway(0.5659)", "verif image answer": "switzerland(0.6341)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283884.jpg"}, {"question": "what is the stuff in the middle of the platter", "gt answer": "nut(1.00)<br/>mint(0.60)", "pred answer": "cereal", "question_id": 735835, "best approach": "", "verif answer": "seed", "anno approach": "", "verif wiki answer": "seed(0.5915)", "verif concept answer": "seed(0.5873)", "verif image answer": "seed(0.5903)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073583.jpg"}, {"question": "what breed is this dog", "gt answer": "rottweiler(1.00)<br/>beagle(0.60)<br/>retriever(0.60)", "pred answer": "mix", "question_id": 1148695, "best approach": "wiki, concept, image", "verif answer": "beagle", "anno approach": "wiki", "verif wiki answer": "beagle(0.6914)", "verif concept answer": "beagle(0.6990)", "verif image answer": "beagle(0.7011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114869.jpg"}, {"question": "why is this person attired in thes type of clothes", "gt answer": "cold weather(1.00)", "pred answer": "snow", "question_id": 5396175, "best approach": "", "verif answer": "stay warm", "anno approach": "", "verif wiki answer": "stay warm(0.7017)", "verif concept answer": "stay warm(0.6898)", "verif image answer": "stay warm(0.6850)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539617.jpg"}, {"question": "what part of the house would you store the products shown in the picture", "gt answer": "kitchen(1.00)", "pred answer": "produce", "question_id": 3009505, "best approach": "wiki, concept, image", "verif answer": "kitchen", "anno approach": "image, wiki", "verif wiki answer": "kitchen(0.6715)", "verif concept answer": "kitchen(0.6413)", "verif image answer": "kitchen(0.6933)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300950.jpg"}, {"question": "what kind of liquid soap is used in the sink in the image", "gt answer": "dawn(1.00)<br/>foam(0.60)", "pred answer": "bleach", "question_id": 5141835, "best approach": "wiki, concept, image", "verif answer": "foam", "anno approach": "image, concept, wiki", "verif wiki answer": "foam(0.6532)", "verif concept answer": "foam(0.7303)", "verif image answer": "foam(0.7256)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514183.jpg"}, {"question": "how is this type of food made", "gt answer": "fried(1.00)<br/>bread(0.60)<br/>toasted(0.60)", "pred answer": "baked", "question_id": 3930805, "best approach": "image", "verif answer": "fry", "anno approach": "image", "verif wiki answer": "fry(0.6957)", "verif concept answer": "fry(0.6669)", "verif image answer": "toasted(0.6043)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393080.jpg"}, {"question": "what kind of food is this", "gt answer": "pizza(1.00)", "pred answer": "pizza", "question_id": 3304515, "best approach": "", "verif answer": "bread", "anno approach": "", "verif wiki answer": "bread(0.6953)", "verif concept answer": "bread(0.6832)", "verif image answer": "bread(0.6607)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000330451.jpg"}, {"question": "which form of entertainment is the person utilizing", "gt answer": "video game(1.00)<br/>video(0.60)<br/>wii(0.60)", "pred answer": "video game", "question_id": 352485, "best approach": "wiki", "verif answer": "bowl", "anno approach": "wiki", "verif wiki answer": "video game(0.5720)", "verif concept answer": "bowl(0.6860)", "verif image answer": "bowl(0.5598)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000035248.jpg"}, {"question": "is this the living room or dining room", "gt answer": "dine room(1.00)<br/>both(1.00)<br/>dine(0.60)", "pred answer": "live room", "question_id": 588345, "best approach": "", "verif answer": "hangout", "anno approach": "", "verif wiki answer": "hangout(0.7299)", "verif concept answer": "hangout(0.7252)", "verif image answer": "hangout(0.7097)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058834.jpg"}, {"question": "what was the name of the chicken in moana", "gt answer": "heihei(1.00)", "pred answer": "pigeon", "question_id": 5587655, "best approach": "wiki, concept, image", "verif answer": "heihei", "anno approach": "", "verif wiki answer": "heihei(0.7276)", "verif concept answer": "heihei(0.7137)", "verif image answer": "heihei(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558765.jpg"}, {"question": "what kind of monks are these", "gt answer": "buddhist(1.00)<br/>hindu(0.60)<br/>chinese(0.60)", "pred answer": "indian", "question_id": 410945, "best approach": "wiki, concept, image", "verif answer": "buddhist", "anno approach": "wiki", "verif wiki answer": "buddhist(0.7283)", "verif concept answer": "buddhist(0.7034)", "verif image answer": "buddhist(0.6988)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041094.jpg"}, {"question": "this animal is grazing in the area known as what", "gt answer": "grassland(1.00)<br/>serengeti(0.60)<br/>savannah(0.60)", "pred answer": "grass", "question_id": 4874895, "best approach": "", "verif answer": "pasture", "anno approach": "", "verif wiki answer": "pasture(0.6641)", "verif concept answer": "pasture(0.6828)", "verif image answer": "pasture(0.6593)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487489.jpg"}, {"question": "in what country did this sport originate", "gt answer": "united state(1.00)<br/>america(1.00)", "pred answer": "london", "question_id": 1994875, "best approach": "", "verif answer": "south africa", "anno approach": "", "verif wiki answer": "south africa(0.6763)", "verif concept answer": "south africa(0.6463)", "verif image answer": "south africa(0.6543)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199487.jpg"}, {"question": "is the stop sign image a hexagon or octagon", "gt answer": "octagon(1.00)", "pred answer": "rectangle", "question_id": 2349565, "best approach": "wiki, concept, image", "verif answer": "octagon", "anno approach": "image, concept, wiki", "verif wiki answer": "octagon(0.6456)", "verif concept answer": "octagon(0.6887)", "verif image answer": "octagon(0.6858)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000234956.jpg"}, {"question": "where was this picture taken", "gt answer": "school(1.00)<br/>restaurant(0.60)<br/>cafeteria(0.60)<br/>home(0.60)", "pred answer": "skate park", "question_id": 3157135, "best approach": "wiki, concept, image", "verif answer": "home", "anno approach": "wiki", "verif wiki answer": "home(0.6553)", "verif concept answer": "home(0.6087)", "verif image answer": "home(0.6118)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315713.jpg"}, {"question": "why might one assume this is a private school", "gt answer": "uniform(1.00)", "pred answer": "college", "question_id": 5801205, "best approach": "", "verif answer": "safe", "anno approach": "", "verif wiki answer": "safe(0.6498)", "verif concept answer": "team(0.6472)", "verif image answer": "safe(0.6319)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580120.jpg"}, {"question": "what time is it in this photo", "gt answer": "5:37(1.00)", "pred answer": "6:50", "question_id": 77535, "best approach": "concept", "verif answer": "3:40", "anno approach": "concept", "verif wiki answer": "3:40(0.6309)", "verif concept answer": "5:37(0.6593)", "verif image answer": "3:40(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007753.jpg"}, {"question": "what is the new name for this famous road", "gt answer": "route 66(1.00)", "pred answer": "bridge", "question_id": 1897355, "best approach": "wiki, concept, image", "verif answer": "route 66", "anno approach": "concept, wiki", "verif wiki answer": "route 66(0.7155)", "verif concept answer": "route 66(0.7147)", "verif image answer": "route 66(0.6540)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000189735.jpg"}, {"question": "how long does this breed of animal live", "gt answer": "20 years(1.00)<br/>15 years(0.60)<br/>12 years(0.60)<br/>10 years(0.60)", "pred answer": "2 months", "question_id": 4318795, "best approach": "wiki, concept, image", "verif answer": "12 years", "anno approach": "wiki", "verif wiki answer": "12 years(0.6158)", "verif concept answer": "12 years(0.5968)", "verif image answer": "10 years(0.5958)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431879.jpg"}, {"question": "what hunts these animals", "gt answer": "poacher(1.00)<br/>lion(0.60)<br/>human(0.60)", "pred answer": "leaf", "question_id": 5506995, "best approach": "wiki, concept, image", "verif answer": "lion", "anno approach": "wiki", "verif wiki answer": "lion(0.7302)", "verif concept answer": "lion(0.7298)", "verif image answer": "lion(0.7248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550699.jpg"}, {"question": "how does this mouse work if its not wirely connected", "gt answer": "wireless(1.00)<br/>bluetooth(0.60)<br/>usb(0.60)", "pred answer": "battery", "question_id": 2259865, "best approach": "wiki, concept", "verif answer": "anchor", "anno approach": "wiki", "verif wiki answer": "usb(0.7139)", "verif concept answer": "usb(0.7149)", "verif image answer": "anchor(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225986.jpg"}, {"question": "what 's the best octane of gasoline to put in the tank", "gt answer": "premium(1.00)", "pred answer": "gas", "question_id": 3835255, "best approach": "", "verif answer": "diesel", "anno approach": "", "verif wiki answer": "coal(0.6439)", "verif concept answer": "coal(0.6424)", "verif image answer": "diesel(0.6683)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383525.jpg"}, {"question": "what type of animals are these that have very long necks", "gt answer": "giraffe(1.00)", "pred answer": "giraffe", "question_id": 3159615, "best approach": "wiki, concept, image", "verif answer": "giraffe", "anno approach": "wiki", "verif wiki answer": "giraffe(0.7015)", "verif concept answer": "giraffe(0.6824)", "verif image answer": "giraffe(0.6795)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315961.jpg"}, {"question": "why do people use this kind of transportation", "gt answer": "fun(1.00)<br/>for fun(0.60)<br/>race(0.60)", "pred answer": "ride", "question_id": 792585, "best approach": "wiki, concept, image", "verif answer": "fun", "anno approach": "wiki", "verif wiki answer": "fun(0.7093)", "verif concept answer": "fun(0.6886)", "verif image answer": "fun(0.6839)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079258.jpg"}, {"question": "what device is the baby on", "gt answer": "sled(1.00)<br/>surfboard(0.60)", "pred answer": "ski lift", "question_id": 259965, "best approach": "image", "verif answer": "ski", "anno approach": "image", "verif wiki answer": "ski(0.7284)", "verif concept answer": "ski(0.6668)", "verif image answer": "surfboard(0.6941)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025996.jpg"}, {"question": "what type of seasoning", "gt answer": "parsley(1.00)<br/>pepper(0.60)", "pred answer": "spinach", "question_id": 3511465, "best approach": "", "verif answer": "grease", "anno approach": "", "verif wiki answer": "grease(0.7158)", "verif concept answer": "grease(0.7142)", "verif image answer": "grease(0.6646)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351146.jpg"}, {"question": "in which room is this public area", "gt answer": "restroom(1.00)<br/>bathroom(1.00)", "pred answer": "bathroom", "question_id": 4750335, "best approach": "wiki, concept", "verif answer": "bathroom", "anno approach": "wiki", "verif wiki answer": "bathroom(0.6819)", "verif concept answer": "bathroom(0.6616)", "verif image answer": "hotel(0.6561)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475033.jpg"}, {"question": "from which healthy oil the shown dish is prepared", "gt answer": "olive oil(1.00)<br/>canola(0.60)<br/>peanut(0.60)<br/>sunflower(0.60)", "pred answer": "olive", "question_id": 2742715, "best approach": "wiki, concept", "verif answer": "sesame", "anno approach": "wiki", "verif wiki answer": "canola(0.6581)", "verif concept answer": "canola(0.6371)", "verif image answer": "sesame(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274271.jpg"}, {"question": "what is the most popular topping for the food on the left", "gt answer": "ketchup(1.00)", "pred answer": "hot dog", "question_id": 4459605, "best approach": "wiki, concept", "verif answer": "ketchup", "anno approach": "wiki", "verif wiki answer": "ketchup(0.6755)", "verif concept answer": "ketchup(0.7033)", "verif image answer": "onion(0.6731)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445960.jpg"}, {"question": "what kind of event is this", "gt answer": "kite fly(1.00)", "pred answer": "kite", "question_id": 483395, "best approach": "", "verif answer": "frisbee", "anno approach": "", "verif wiki answer": "frisbee(0.7292)", "verif concept answer": "frisbee(0.7200)", "verif image answer": "frisbee(0.6173)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048339.jpg"}, {"question": "which team has one the most championships of the sport being played here", "gt answer": "new york yankees(1.00)<br/>yankees(0.60)<br/>dodger(0.60)", "pred answer": "dodger", "question_id": 2450625, "best approach": "", "verif answer": "met", "anno approach": "", "verif wiki answer": "met(0.6512)", "verif concept answer": "met(0.6381)", "verif image answer": "met(0.6384)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245062.jpg"}, {"question": "what can you use to change this screen", "gt answer": "remote(1.00)<br/>remote control(0.60)", "pred answer": "remote", "question_id": 700335, "best approach": "wiki, concept, image", "verif answer": "remote", "anno approach": "image, wiki", "verif wiki answer": "remote(0.7217)", "verif concept answer": "remote(0.6749)", "verif image answer": "remote(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070033.jpg"}, {"question": "what kind of wood is on the floor", "gt answer": "oak(1.00)<br/>laminate(0.60)<br/>maple(0.60)", "pred answer": "oak", "question_id": 2719605, "best approach": "wiki, concept, image", "verif answer": "laminate", "anno approach": "wiki", "verif wiki answer": "laminate(0.7111)", "verif concept answer": "laminate(0.7134)", "verif image answer": "laminate(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000271960.jpg"}, {"question": "what kind of material is this truck transporting", "gt answer": "oil(1.00)<br/>gasoline(0.60)", "pred answer": "grain", "question_id": 2268965, "best approach": "concept", "verif answer": "gas", "anno approach": "concept", "verif wiki answer": "grain(0.6588)", "verif concept answer": "gasoline(0.6402)", "verif image answer": "gas(0.6760)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226896.jpg"}, {"question": "what is a trick these children could do", "gt answer": "ollie(0.60)<br/>jump(1.00)", "pred answer": "jump", "question_id": 706425, "best approach": "", "verif answer": "grind", "anno approach": "", "verif wiki answer": "grind(0.7167)", "verif concept answer": "grind(0.7154)", "verif image answer": "grind(0.7055)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070642.jpg"}, {"question": "name the material used to make this board in this picture", "gt answer": "cardboard(1.00)<br/>wood(1.00)", "pred answer": "wood", "question_id": 5183555, "best approach": "", "verif answer": "lumber", "anno approach": "", "verif wiki answer": "lumber(0.7079)", "verif concept answer": "lumber(0.6902)", "verif image answer": "lumber(0.6877)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518355.jpg"}, {"question": "what is this person 's necklace made of", "gt answer": "gold(1.00)<br/>nylon(0.60)", "pred answer": "metal", "question_id": 803055, "best approach": "image", "verif answer": "gold", "anno approach": "image", "verif wiki answer": "nylon(0.6652)", "verif concept answer": "plastic(0.6226)", "verif image answer": "gold(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080305.jpg"}, {"question": "how many of these animals remain in the wild", "gt answer": "many(1.00)<br/>1000(0.60)<br/>thousand(0.60)<br/>endangered(0.60)", "pred answer": "thousand", "question_id": 4585745, "best approach": "wiki, concept, image", "verif answer": "endangered", "anno approach": "wiki", "verif wiki answer": "endangered(0.7226)", "verif concept answer": "endangered(0.7109)", "verif image answer": "endangered(0.6823)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458574.jpg"}, {"question": "what causes high and low tides", "gt answer": "moon(1.00)<br/>rain(0.60)", "pred answer": "boat", "question_id": 3550925, "best approach": "wiki, concept", "verif answer": "moon", "anno approach": "wiki", "verif wiki answer": "moon(0.6724)", "verif concept answer": "moon(0.6859)", "verif image answer": "fog(0.6417)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355092.jpg"}, {"question": "what utensils are being used", "gt answer": "chopstick(1.00)<br/>chop stick(0.60)", "pred answer": "chopstick", "question_id": 5654355, "best approach": "wiki", "verif answer": "spoon", "anno approach": "wiki", "verif wiki answer": "chopstick(0.6385)", "verif concept answer": "japanese(0.5077)", "verif image answer": "spoon(0.7056)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000565435.jpg"}, {"question": "a young boy that is designated to run after this ball during this match would be called a what", "gt answer": "ball boy(1.00)", "pred answer": "tennis", "question_id": 1576565, "best approach": "", "verif answer": "tennis", "anno approach": "", "verif wiki answer": "tennis(0.6043)", "verif concept answer": "tennis(0.5185)", "verif image answer": "john mcenroe(0.5943)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157656.jpg"}, {"question": "this fire hydrant is painted to resemble what", "gt answer": "face(1.00)<br/>fireman(0.60)", "pred answer": "hat", "question_id": 251155, "best approach": "wiki, concept, image", "verif answer": "face", "anno approach": "wiki", "verif wiki answer": "face(0.5302)", "verif concept answer": "face(0.5109)", "verif image answer": "face(0.5013)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025115.jpg"}, {"question": "what geometric shape is the top", "gt answer": "triangle(1.00)", "pred answer": "square", "question_id": 1343205, "best approach": "", "verif answer": "in half", "anno approach": "", "verif wiki answer": "in half(0.6829)", "verif concept answer": "diamond(0.6912)", "verif image answer": "in half(0.7141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134320.jpg"}, {"question": "how thick is the orage surfboard", "gt answer": "2 inches(1.00)<br/>4(0.60)", "pred answer": "1 inch", "question_id": 3735695, "best approach": "concept", "verif answer": "2.5 cm", "anno approach": "concept", "verif wiki answer": "2.5 cm(0.5985)", "verif concept answer": "2 inches(0.5980)", "verif image answer": "2.5 cm(0.6374)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373569.jpg"}, {"question": "if the lights on the back of this object turn red what does it indicate", "gt answer": "brake(1.00)<br/>stop(0.60)", "pred answer": "stop", "question_id": 1694995, "best approach": "", "verif answer": "stopped", "anno approach": "", "verif wiki answer": "stopped(0.6809)", "verif concept answer": "stopped(0.6769)", "verif image answer": "stopped(0.6781)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169499.jpg"}, {"question": "clothes for this sport are typically called tennis what", "gt answer": "shoe(1.00)<br/>gear(1.00)<br/>short(0.60)", "pred answer": "tennis", "question_id": 3293945, "best approach": "wiki, concept, image", "verif answer": "short", "anno approach": "image, wiki", "verif wiki answer": "short(0.6006)", "verif concept answer": "short(0.5607)", "verif image answer": "short(0.7144)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329394.jpg"}, {"question": "what product does the remote next to the cat operate", "gt answer": "television(1.00)<br/>tv(1.00)", "pred answer": "toshiba", "question_id": 4290405, "best approach": "image", "verif answer": "fireplace", "anno approach": "image", "verif wiki answer": "fireplace(0.6867)", "verif concept answer": "fireplace(0.6890)", "verif image answer": "tv(0.6427)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429040.jpg"}, {"question": "what kind of hairstyle does the woman in the black shirt have", "gt answer": "bun(1.00)<br/>bob(0.60)<br/>pony tail(0.60)", "pred answer": "pony tail", "question_id": 1788475, "best approach": "wiki, concept, image", "verif answer": "pony tail", "anno approach": "wiki", "verif wiki answer": "pony tail(0.7287)", "verif concept answer": "pony tail(0.7288)", "verif image answer": "pony tail(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178847.jpg"}, {"question": "where could i purchase that umbrella", "gt answer": "walmart(1.00)<br/>target(0.60)", "pred answer": "walmart", "question_id": 4526195, "best approach": "concept, image", "verif answer": "walmart", "anno approach": "", "verif wiki answer": "department store(0.7134)", "verif concept answer": "walmart(0.6970)", "verif image answer": "walmart(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000452619.jpg"}, {"question": "who makes that baseball bat", "gt answer": "wilson(1.00)<br/>louisville slugger(0.60)", "pred answer": "louisville slugger", "question_id": 5526305, "best approach": "wiki, concept, image", "verif answer": "louisville slugger", "anno approach": "wiki", "verif wiki answer": "louisville slugger(0.7147)", "verif concept answer": "louisville slugger(0.7176)", "verif image answer": "louisville slugger(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552630.jpg"}, {"question": "are the people in this picture enthusiastic or bored", "gt answer": "enthusiastic(1.00)", "pred answer": "unhealthy", "question_id": 5339575, "best approach": "", "verif answer": "happy", "anno approach": "", "verif wiki answer": "happy(0.5233)", "verif concept answer": "happy(0.5086)", "verif image answer": "happy(0.5130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000533957.jpg"}, {"question": "where are these buses parked", "gt answer": "bus stop(1.00)<br/>station(0.60)", "pred answer": "city", "question_id": 3930645, "best approach": "", "verif answer": "train station", "anno approach": "", "verif wiki answer": "train station(0.7037)", "verif concept answer": "train station(0.6923)", "verif image answer": "train station(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393064.jpg"}, {"question": "what will the baseball player do with the bat", "gt answer": "hit ball(1.00)<br/>swing(0.60)<br/>hit(0.60)", "pred answer": "hit ball", "question_id": 3836055, "best approach": "wiki, concept, image", "verif answer": "hit", "anno approach": "wiki", "verif wiki answer": "hit(0.7052)", "verif concept answer": "hit(0.7030)", "verif image answer": "hit(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383605.jpg"}, {"question": "what city is this", "gt answer": "new york(1.00)<br/>new york city(0.60)", "pred answer": "new york city", "question_id": 1028995, "best approach": "wiki, concept, image", "verif answer": "new york city", "anno approach": "wiki", "verif wiki answer": "new york city(0.6879)", "verif concept answer": "new york city(0.6793)", "verif image answer": "new york city(0.6985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000102899.jpg"}, {"question": "what tooth is named after this type of animal", "gt answer": "canine(1.00)", "pred answer": "canine", "question_id": 2619775, "best approach": "wiki, concept, image", "verif answer": "canine", "anno approach": "wiki", "verif wiki answer": "canine(0.7282)", "verif concept answer": "canine(0.7289)", "verif image answer": "canine(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261977.jpg"}, {"question": "what is the primary function of the trucks in this photo", "gt answer": "haul(1.00)<br/>transportation(0.60)", "pred answer": "tow", "question_id": 2535155, "best approach": "wiki, concept, image", "verif answer": "haul", "anno approach": "wiki", "verif wiki answer": "haul(0.6506)", "verif concept answer": "haul(0.6284)", "verif image answer": "haul(0.6441)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253515.jpg"}, {"question": "what is the dog doing in an enclosure with barnyard animals", "gt answer": "herd(1.00)<br/>shepherd(0.60)", "pred answer": "herd", "question_id": 959895, "best approach": "wiki, concept, image", "verif answer": "herd", "anno approach": "wiki", "verif wiki answer": "herd(0.7254)", "verif concept answer": "herd(0.7170)", "verif image answer": "herd(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000095989.jpg"}, {"question": "what is the dish named", "gt answer": "soup(1.00)<br/>cashew chicken(1.00)", "pred answer": "pasta", "question_id": 4154995, "best approach": "image", "verif answer": "soup", "anno approach": "image", "verif wiki answer": "pasta(0.7102)", "verif concept answer": "pasta(0.7070)", "verif image answer": "soup(0.7136)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415499.jpg"}, {"question": "what language is on the sign", "gt answer": "italian(1.00)<br/>spanish(0.60)", "pred answer": "german", "question_id": 3460615, "best approach": "image", "verif answer": "arabic", "anno approach": "image", "verif wiki answer": "french(0.6943)", "verif concept answer": "arabic(0.7210)", "verif image answer": "spanish(0.7092)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346061.jpg"}, {"question": "what is the purpose of the fixtures on the wall", "gt answer": "hold thing(1.00)<br/>bookshelf(0.60)", "pred answer": "tell time", "question_id": 1746235, "best approach": "image", "verif answer": "clock", "anno approach": "image", "verif wiki answer": "clock(0.6734)", "verif concept answer": "clock(0.5845)", "verif image answer": "hold thing(0.6168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174623.jpg"}, {"question": "what makes these animals endangered", "gt answer": "tusk(1.00)", "pred answer": "tusk", "question_id": 394065, "best approach": "wiki, concept, image", "verif answer": "tusk", "anno approach": "concept, wiki", "verif wiki answer": "tusk(0.6784)", "verif concept answer": "tusk(0.6803)", "verif image answer": "tusk(0.6469)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039406.jpg"}, {"question": "what brand is this bike", "gt answer": "harley davidson(1.00)<br/>harley(0.60)<br/>yamaha(0.60)", "pred answer": "harley", "question_id": 3512525, "best approach": "", "verif answer": "triumph", "anno approach": "", "verif wiki answer": "triumph(0.7193)", "verif concept answer": "triumph(0.7039)", "verif image answer": "triumph(0.7001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351252.jpg"}, {"question": "is this food gulten free or vegan", "gt answer": "vegan(1.00)", "pred answer": "vegan", "question_id": 1878725, "best approach": "concept, image", "verif answer": "vegetarian", "anno approach": "", "verif wiki answer": "vegetarian(0.6838)", "verif concept answer": "vegan(0.5690)", "verif image answer": "vegan(0.5591)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187872.jpg"}, {"question": "if the man behind the hitter catches the ball before the hitter gets to first base then the hitter is what", "gt answer": "out(1.00)<br/>safe(0.60)", "pred answer": "babe ruth", "question_id": 466305, "best approach": "wiki, image", "verif answer": "out", "anno approach": "wiki", "verif wiki answer": "out(0.6436)", "verif concept answer": "umpire(0.5766)", "verif image answer": "out(0.6319)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046630.jpg"}, {"question": "what is this man landing on", "gt answer": "home plate(1.00)<br/>base(1.00)", "pred answer": "bat", "question_id": 4524575, "best approach": "", "verif answer": "bat", "anno approach": "", "verif wiki answer": "bat(0.6749)", "verif concept answer": "bat(0.6537)", "verif image answer": "bat(0.6318)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000452457.jpg"}, {"question": "what is this person about to do with the ball", "gt answer": "throw it(1.00)<br/>pitch(0.60)", "pred answer": "swing", "question_id": 4245335, "best approach": "image", "verif answer": "pitch", "anno approach": "image", "verif wiki answer": "land(0.6903)", "verif concept answer": "land(0.6840)", "verif image answer": "pitch(0.6956)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424533.jpg"}, {"question": "the baby of this animal is called what", "gt answer": "calf(1.00)<br/>foal(0.60)<br/>giraffe(0.60)", "pred answer": "calf", "question_id": 4145555, "best approach": "wiki, concept, image", "verif answer": "calf", "anno approach": "concept, wiki", "verif wiki answer": "calf(0.7083)", "verif concept answer": "calf(0.7164)", "verif image answer": "calf(0.6602)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000414555.jpg"}, {"question": "what hairstyle does the woman have", "gt answer": "ponytail(1.00)<br/>bun(0.60)", "pred answer": "ponytail", "question_id": 4133345, "best approach": "wiki, image", "verif answer": "pony tail", "anno approach": "wiki", "verif wiki answer": "ponytail(0.6725)", "verif concept answer": "pony tail(0.6885)", "verif image answer": "ponytail(0.6268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000413334.jpg"}, {"question": "what type of clouds are in the sky", "gt answer": "cirrus(1.00)<br/>cumulus(1.00)", "pred answer": "stratus", "question_id": 65395, "best approach": "", "verif answer": "stratus", "anno approach": "", "verif wiki answer": "stratus(0.7192)", "verif concept answer": "stratus(0.7064)", "verif image answer": "stratus(0.7004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006539.jpg"}, {"question": "what model of camera is being used", "gt answer": "kodak(1.00)<br/>digital(1.00)", "pred answer": "canon", "question_id": 5802575, "best approach": "", "verif answer": "cannon", "anno approach": "", "verif wiki answer": "canon(0.6556)", "verif concept answer": "canon(0.6609)", "verif image answer": "cannon(0.6943)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580257.jpg"}, {"question": "who might own one of these", "gt answer": "child(1.00)<br/>kid(0.60)<br/>children(0.60)", "pred answer": "child", "question_id": 4716975, "best approach": "wiki, concept, image", "verif answer": "child", "anno approach": "wiki", "verif wiki answer": "child(0.7239)", "verif concept answer": "child(0.7227)", "verif image answer": "child(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471697.jpg"}, {"question": "how do we know this is not a professional game", "gt answer": "cloth(0.60)<br/>outfit(1.00)", "pred answer": "referee", "question_id": 2481505, "best approach": "", "verif answer": "door", "anno approach": "", "verif wiki answer": "nothing(0.6620)", "verif concept answer": "nothing(0.6543)", "verif image answer": "door(0.7165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248150.jpg"}, {"question": "what is the man wearing on his hand", "gt answer": "glove(1.00)", "pred answer": "glove", "question_id": 1887875, "best approach": "wiki, concept, image", "verif answer": "glove", "anno approach": "image, wiki", "verif wiki answer": "glove(0.6707)", "verif concept answer": "glove(0.6562)", "verif image answer": "glove(0.6896)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188787.jpg"}, {"question": "what position is the person taking off his helmet", "gt answer": "batter(1.00)<br/>home(1.00)", "pred answer": "catcher", "question_id": 5002245, "best approach": "", "verif answer": "hitter", "anno approach": "", "verif wiki answer": "hitter(0.6681)", "verif concept answer": "hitter(0.6734)", "verif image answer": "hitter(0.6778)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500224.jpg"}, {"question": "is this an exercise class or surboard training", "gt answer": "train(1.00)<br/>surfboard train(1.00)<br/>both(0.60)", "pred answer": "cut", "question_id": 4959295, "best approach": "image", "verif answer": "both", "anno approach": "image", "verif wiki answer": "both(0.6306)", "verif concept answer": "both(0.5573)", "verif image answer": "train(0.5163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495929.jpg"}, {"question": "what breed of horse are the ones pictured", "gt answer": "clydesdale(1.00)<br/>mule(0.60)", "pred answer": "clydesdale", "question_id": 2265245, "best approach": "wiki, concept, image", "verif answer": "clydesdale", "anno approach": "wiki", "verif wiki answer": "clydesdale(0.6644)", "verif concept answer": "clydesdale(0.6766)", "verif image answer": "clydesdale(0.6965)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226524.jpg"}, {"question": "what type of activity is usually associated with this area", "gt answer": "travel(1.00)<br/>fly(0.60)<br/>construction(0.60)", "pred answer": "travel", "question_id": 3373425, "best approach": "wiki, concept, image", "verif answer": "construction", "anno approach": "wiki", "verif wiki answer": "construction(0.6834)", "verif concept answer": "construction(0.6704)", "verif image answer": "construction(0.6822)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337342.jpg"}, {"question": "what is missing from this wall", "gt answer": "tile(1.00)<br/>wall(0.60)<br/>window(0.60)", "pred answer": "toilet", "question_id": 2581085, "best approach": "wiki, concept", "verif answer": "tile", "anno approach": "wiki", "verif wiki answer": "tile(0.7052)", "verif concept answer": "tile(0.6443)", "verif image answer": "glass(0.7011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258108.jpg"}, {"question": "what food is in the foreground", "gt answer": "orange(1.00)", "pred answer": "orange", "question_id": 2987115, "best approach": "", "verif answer": "grapefruit", "anno approach": "", "verif wiki answer": "grapefruit(0.6141)", "verif concept answer": "grapefruit(0.7063)", "verif image answer": "grapefruit(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000298711.jpg"}, {"question": "what 's the white cord around the guy on the left", "gt answer": "earbud(1.00)<br/>headphone(0.60)", "pred answer": "wall", "question_id": 4484395, "best approach": "", "verif answer": "wii", "anno approach": "", "verif wiki answer": "wii(0.6602)", "verif concept answer": "wii(0.6676)", "verif image answer": "wii(0.7171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448439.jpg"}, {"question": "name the flight name shown in this picture", "gt answer": "j 4138(1.00)", "pred answer": "airbus", "question_id": 723915, "best approach": "image", "verif answer": "klm", "anno approach": "image", "verif wiki answer": "klm(0.6926)", "verif concept answer": "klm(0.6928)", "verif image answer": "j 4138(0.6876)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072391.jpg"}, {"question": "what is the bag used for", "gt answer": "travel(1.00)<br/>luggage(0.60)", "pred answer": "travel", "question_id": 370245, "best approach": "", "verif answer": "fly", "anno approach": "", "verif wiki answer": "fly(0.7181)", "verif concept answer": "fly(0.6777)", "verif image answer": "fly(0.7202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000037024.jpg"}, {"question": "what kind of boat is this", "gt answer": "canoe(1.00)<br/>paddle(0.60)<br/>kayak(0.60)", "pred answer": "canoe", "question_id": 1131525, "best approach": "wiki, concept, image", "verif answer": "canoe", "anno approach": "image, wiki", "verif wiki answer": "canoe(0.6297)", "verif concept answer": "canoe(0.6428)", "verif image answer": "canoe(0.6618)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113152.jpg"}, {"question": "where might you find these signs", "gt answer": "street(1.00)<br/>airport(0.60)<br/>tourist(0.60)", "pred answer": "street", "question_id": 892035, "best approach": "wiki, concept, image", "verif answer": "airport", "anno approach": "wiki", "verif wiki answer": "airport(0.6691)", "verif concept answer": "airport(0.6795)", "verif image answer": "airport(0.6985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089203.jpg"}, {"question": "what form is the man using to throw the frisbee", "gt answer": "underhand(1.00)<br/>discus(0.60)<br/>kneel(0.60)<br/>first(0.60)", "pred answer": "arm", "question_id": 1987215, "best approach": "wiki, concept, image", "verif answer": "underhand", "anno approach": "image, wiki", "verif wiki answer": "underhand(0.6514)", "verif concept answer": "underhand(0.6179)", "verif image answer": "underhand(0.6915)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198721.jpg"}, {"question": "can you guess the celebration where the people are enjoying", "gt answer": "fourth of july(1.00)<br/>new year(0.60)<br/>4th of july(0.60)", "pred answer": "party", "question_id": 3783315, "best approach": "", "verif answer": "independence day", "anno approach": "", "verif wiki answer": "independence day(0.7280)", "verif concept answer": "independence day(0.7302)", "verif image answer": "independence day(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378331.jpg"}, {"question": "what state in the united states gets the largest amount of what is landing on this umbrella", "gt answer": "washington(1.00)<br/>hawaii(0.60)", "pred answer": "boston", "question_id": 4760345, "best approach": "", "verif answer": "pennsylvania", "anno approach": "", "verif wiki answer": "pennsylvania(0.7116)", "verif concept answer": "pennsylvania(0.7010)", "verif image answer": "pennsylvania(0.6757)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476034.jpg"}, {"question": "how do i turn this on", "gt answer": "power button(1.00)<br/>remote control(0.60)<br/>remote(0.60)", "pred answer": "remote", "question_id": 4919835, "best approach": "image", "verif answer": "remote", "anno approach": "image", "verif wiki answer": "remote(0.7299)", "verif concept answer": "remote(0.6011)", "verif image answer": "power button(0.7267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491983.jpg"}, {"question": "what mineral causes earth to turn white in warmer climates", "gt answer": "salt(1.00)<br/>stone(0.60)", "pred answer": "calcium", "question_id": 703565, "best approach": "wiki, concept, image", "verif answer": "salt", "anno approach": "wiki", "verif wiki answer": "salt(0.7245)", "verif concept answer": "salt(0.7177)", "verif image answer": "salt(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070356.jpg"}, {"question": "why do giraffes have long neck and tall body", "gt answer": "to eat(1.00)<br/>evolution(0.60)", "pred answer": "giraffe", "question_id": 5682375, "best approach": "wiki, image", "verif answer": "evolution", "anno approach": "wiki", "verif wiki answer": "evolution(0.7039)", "verif concept answer": "camouflage(0.6875)", "verif image answer": "evolution(0.7258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568237.jpg"}, {"question": "the red kite shown in the photo is of which country", "gt answer": "us(1.00)<br/>china(1.00)<br/>usa(0.60)", "pred answer": "canada", "question_id": 1874355, "best approach": "wiki", "verif answer": "france", "anno approach": "wiki", "verif wiki answer": "us(0.6019)", "verif concept answer": "france(0.6021)", "verif image answer": "france(0.6468)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187435.jpg"}, {"question": "what instrument is the boy using", "gt answer": "trombone(1.00)", "pred answer": "piano", "question_id": 2527025, "best approach": "wiki, concept", "verif answer": "trombone", "anno approach": "wiki", "verif wiki answer": "trombone(0.7292)", "verif concept answer": "trombone(0.7275)", "verif image answer": "donut(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252702.jpg"}, {"question": "what do you call the shelter these animals stay in usually", "gt answer": "stable(1.00)<br/>barn(1.00)", "pred answer": "stable", "question_id": 1318335, "best approach": "wiki, concept", "verif answer": "barn", "anno approach": "wiki", "verif wiki answer": "barn(0.7266)", "verif concept answer": "barn(0.6868)", "verif image answer": "sheep(0.6295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000131833.jpg"}, {"question": "what food is this", "gt answer": "donut(1.00)<br/>donuts(0.60)<br/>espresso(0.60)", "pred answer": "bread", "question_id": 3797365, "best approach": "", "verif answer": "sprinkle", "anno approach": "", "verif wiki answer": "sprinkle(0.7236)", "verif concept answer": "sprinkle(0.7041)", "verif image answer": "sprinkle(0.7054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379736.jpg"}, {"question": "what type of lighting was usued", "gt answer": "natural(1.00)<br/>outdoor(0.60)", "pred answer": "overhead", "question_id": 3910655, "best approach": "wiki, concept, image", "verif answer": "outdoor", "anno approach": "wiki", "verif wiki answer": "outdoor(0.5264)", "verif concept answer": "outdoor(0.5271)", "verif image answer": "outdoor(0.5296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391065.jpg"}, {"question": "what is the function of the man in black", "gt answer": "referee(1.00)<br/>catcher(0.60)<br/>judge(0.60)", "pred answer": "umpire", "question_id": 1696535, "best approach": "", "verif answer": "catch", "anno approach": "", "verif wiki answer": "umpire(0.7240)", "verif concept answer": "umpire(0.7265)", "verif image answer": "catch(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169653.jpg"}, {"question": "who owns the booth", "gt answer": "adobe(1.00)", "pred answer": "samsung", "question_id": 4246695, "best approach": "", "verif answer": "krispy kreme", "anno approach": "", "verif wiki answer": "ll bean(0.6415)", "verif concept answer": "ll bean(0.6516)", "verif image answer": "krispy kreme(0.7004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424669.jpg"}, {"question": "what type of bus is this", "gt answer": "tour(1.00)<br/>tour bus(0.60)<br/>tourist(0.60)<br/>greyhound(0.60)", "pred answer": "tour bus", "question_id": 197255, "best approach": "", "verif answer": "city bus", "anno approach": "", "verif wiki answer": "city bus(0.6672)", "verif concept answer": "city bus(0.6772)", "verif image answer": "city bus(0.7141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019725.jpg"}, {"question": "these players use tennis rackets to hit what", "gt answer": "tennis ball(1.00)<br/>ball(1.00)", "pred answer": "serve", "question_id": 968285, "best approach": "wiki, concept", "verif answer": "serve", "anno approach": "wiki", "verif wiki answer": "ball(0.6529)", "verif concept answer": "ball(0.5549)", "verif image answer": "serve(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096828.jpg"}, {"question": "what day s might i most commonly go to this building", "gt answer": "sunday(1.00)", "pred answer": "vacation", "question_id": 2933425, "best approach": "", "verif answer": "downtown", "anno approach": "", "verif wiki answer": "christmas(0.6898)", "verif concept answer": "christmas(0.7001)", "verif image answer": "downtown(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293342.jpg"}, {"question": "what is the style of paint that the police force seen in the photo use to demarcate their vehicles", "gt answer": "neon(1.00)<br/>checkered(0.60)<br/>spray paint(0.60)", "pred answer": "art", "question_id": 5137295, "best approach": "image", "verif answer": "neon", "anno approach": "image", "verif wiki answer": "neon gas(0.5229)", "verif concept answer": "neon gas(0.5173)", "verif image answer": "neon(0.5476)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513729.jpg"}, {"question": "what is on the court floor", "gt answer": "water(1.00)<br/>asphalt(0.60)<br/>chalk(0.60)", "pred answer": "tennis", "question_id": 4948605, "best approach": "wiki, concept", "verif answer": "rock", "anno approach": "wiki", "verif wiki answer": "chalk(0.7053)", "verif concept answer": "chalk(0.6887)", "verif image answer": "rock(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494860.jpg"}, {"question": "why does a person need to do this", "gt answer": "clean teeth(1.00)", "pred answer": "brush teeth", "question_id": 1967485, "best approach": "image", "verif answer": "clean teeth", "anno approach": "image", "verif wiki answer": "teeth(0.6549)", "verif concept answer": "teeth(0.6503)", "verif image answer": "clean teeth(0.6996)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196748.jpg"}, {"question": "what material is the sofa", "gt answer": "cloth(1.00)", "pred answer": "fabric", "question_id": 897925, "best approach": "", "verif answer": "paper", "anno approach": "", "verif wiki answer": "paper(0.6229)", "verif concept answer": "paper(0.6946)", "verif image answer": "paper(0.6207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089792.jpg"}, {"question": "what is the mat on the floor made of", "gt answer": "bamboo(1.00)<br/>grass(0.60)", "pred answer": "wood", "question_id": 5483185, "best approach": "concept", "verif answer": "plant", "anno approach": "concept", "verif wiki answer": "plant(0.6297)", "verif concept answer": "grass(0.6984)", "verif image answer": "plant(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548318.jpg"}, {"question": "what is in this picture to sit on", "gt answer": "chair(1.00)", "pred answer": "sofa", "question_id": 654475, "best approach": "", "verif answer": "sofa", "anno approach": "", "verif wiki answer": "sofa(0.7206)", "verif concept answer": "sofa(0.7189)", "verif image answer": "sofa(0.6625)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065447.jpg"}, {"question": "what is the brown brick building being used for", "gt answer": "church(1.00)<br/>school(0.60)", "pred answer": "time", "question_id": 1003125, "best approach": "wiki, concept", "verif answer": "church", "anno approach": "wiki", "verif wiki answer": "church(0.7283)", "verif concept answer": "church(0.7150)", "verif image answer": "school(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100312.jpg"}, {"question": "what does the object do", "gt answer": "blend(1.00)", "pred answer": "clean", "question_id": 5512845, "best approach": "", "verif answer": "smell", "anno approach": "", "verif wiki answer": "smell(0.6815)", "verif concept answer": "smell(0.6809)", "verif image answer": "smell(0.6808)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000551284.jpg"}, {"question": "what is the man wearing", "gt answer": "bowtie(1.00)<br/>bow tie(1.00)", "pred answer": "tie", "question_id": 328725, "best approach": "", "verif answer": "bow", "anno approach": "", "verif wiki answer": "bow(0.5278)", "verif concept answer": "bow(0.6330)", "verif image answer": "tie(0.5602)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032872.jpg"}, {"question": "what is the characteristic of this animal that most often helps people identify it", "gt answer": "stripe(1.00)", "pred answer": "zebra", "question_id": 2503675, "best approach": "", "verif answer": "striped", "anno approach": "", "verif wiki answer": "striped(0.7267)", "verif concept answer": "striped(0.6944)", "verif image answer": "design(0.7190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250367.jpg"}, {"question": "if there is a high chair what type of person would use it", "gt answer": "baby(1.00)", "pred answer": "student", "question_id": 949845, "best approach": "", "verif answer": "early", "anno approach": "", "verif wiki answer": "early(0.6557)", "verif concept answer": "early(0.6372)", "verif image answer": "early(0.5914)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094984.jpg"}, {"question": "what is the elephant avoiding stepping on", "gt answer": "human(1.00)<br/>person(1.00)<br/>man(0.60)", "pred answer": "blanket", "question_id": 5474985, "best approach": "concept, image", "verif answer": "skier", "anno approach": "concept", "verif wiki answer": "skier(0.6701)", "verif concept answer": "man(0.6613)", "verif image answer": "man(0.6225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000547498.jpg"}, {"question": "what utensils are in the picture", "gt answer": "spoon(1.00)", "pred answer": "fork", "question_id": 4890285, "best approach": "wiki, concept, image", "verif answer": "spoon", "anno approach": "image, concept, wiki", "verif wiki answer": "spoon(0.5225)", "verif concept answer": "spoon(0.5833)", "verif image answer": "spoon(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489028.jpg"}, {"question": "why are these people in the water", "gt answer": "bath elephant(1.00)<br/>herd(0.60)<br/>play(0.60)<br/>fish(0.60)", "pred answer": "thirsty", "question_id": 3443855, "best approach": "wiki, concept, image", "verif answer": "herd", "anno approach": "image, wiki", "verif wiki answer": "play(0.5599)", "verif concept answer": "play(0.5589)", "verif image answer": "herd(0.6748)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344385.jpg"}, {"question": "what should he have on his head", "gt answer": "helmet(1.00)<br/>hat(0.60)", "pred answer": "hat", "question_id": 175855, "best approach": "wiki, concept, image", "verif answer": "helmet", "anno approach": "wiki", "verif wiki answer": "helmet(0.6550)", "verif concept answer": "helmet(0.6601)", "verif image answer": "helmet(0.6786)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000017585.jpg"}, {"question": "this portion of an animal is known as its what", "gt answer": "hindquarter(1.00)<br/>butt(0.60)", "pred answer": "zebra", "question_id": 2252305, "best approach": "wiki, concept", "verif answer": "butt", "anno approach": "wiki", "verif wiki answer": "butt(0.6165)", "verif concept answer": "butt(0.5869)", "verif image answer": "neck(0.5618)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225230.jpg"}, {"question": "what does this bathroom say about its owner", "gt answer": "clean(1.00)<br/>male(0.60)<br/>man(0.60)", "pred answer": "clean", "question_id": 3490595, "best approach": "wiki, concept, image", "verif answer": "male", "anno approach": "concept, wiki", "verif wiki answer": "male(0.5802)", "verif concept answer": "male(0.5736)", "verif image answer": "male(0.5302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000349059.jpg"}, {"question": "what famous one was bombed by the japanese in december 1941", "gt answer": "pearl harbor(1.00)<br/>harbor(0.60)", "pred answer": "ben franklin", "question_id": 5783175, "best approach": "wiki, concept, image", "verif answer": "pearl harbor", "anno approach": "wiki", "verif wiki answer": "pearl harbor(0.7310)", "verif concept answer": "pearl harbor(0.7308)", "verif image answer": "pearl harbor(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578317.jpg"}, {"question": "what are the shapes around this cake", "gt answer": "star(1.00)", "pred answer": "heart", "question_id": 3871025, "best approach": "wiki, concept", "verif answer": "star", "anno approach": "wiki", "verif wiki answer": "star(0.6897)", "verif concept answer": "star(0.7127)", "verif image answer": "rectangle(0.6893)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387102.jpg"}, {"question": "what is the yellow item located inside of the glass", "gt answer": "candle(1.00)<br/>bird(0.60)", "pred answer": "soap", "question_id": 2641835, "best approach": "", "verif answer": "ice", "anno approach": "", "verif wiki answer": "ice(0.7087)", "verif concept answer": "ice(0.7212)", "verif image answer": "car(0.6886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000264183.jpg"}, {"question": "based off the toppings where is this from", "gt answer": "germany(1.00)<br/>chicago(1.00)", "pred answer": "italy", "question_id": 1549125, "best approach": "", "verif answer": "usa", "anno approach": "", "verif wiki answer": "italy(0.6484)", "verif concept answer": "usa(0.6524)", "verif image answer": "usa(0.6727)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154912.jpg"}, {"question": "this famous sport was desegregated who was the first african american to play with white people", "gt answer": "jackie robinson(1.00)<br/>baseball(0.60)", "pred answer": "little league", "question_id": 710435, "best approach": "wiki, concept, image", "verif answer": "jackie robinson", "anno approach": "", "verif wiki answer": "jackie robinson(0.7273)", "verif concept answer": "jackie robinson(0.7249)", "verif image answer": "jackie robinson(0.7103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071043.jpg"}, {"question": "what day of the week are you least likely to have to use this machine", "gt answer": "sunday(1.00)<br/>winter(0.60)", "pred answer": "winter", "question_id": 2756425, "best approach": "image", "verif answer": "sunday", "anno approach": "image", "verif wiki answer": "snowy(0.5654)", "verif concept answer": "snowy(0.5681)", "verif image answer": "sunday(0.6134)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000275642.jpg"}, {"question": "in what country is this dish most famous", "gt answer": "vietnam(1.00)<br/>japan(0.60)<br/>chinese(0.60)<br/>china(0.60)", "pred answer": "italy", "question_id": 997455, "best approach": "image", "verif answer": "chinese", "anno approach": "image", "verif wiki answer": "chinese(0.6417)", "verif concept answer": "chinese(0.6605)", "verif image answer": "vietnam(0.6385)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099745.jpg"}, {"question": "what is this dish a good source of", "gt answer": "vitamin(1.00)<br/>calcium(0.60)", "pred answer": "fiber", "question_id": 1917405, "best approach": "concept, image", "verif answer": "vitamin", "anno approach": "", "verif wiki answer": "calcium(0.5593)", "verif concept answer": "vitamin(0.6016)", "verif image answer": "vitamin(0.6206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191740.jpg"}, {"question": "are these people tourists or natives", "gt answer": "tourist(1.00)<br/>native(0.60)", "pred answer": "tourist", "question_id": 5579485, "best approach": "", "verif answer": "public", "anno approach": "", "verif wiki answer": "public(0.6535)", "verif concept answer": "public(0.6202)", "verif image answer": "public(0.5967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557948.jpg"}, {"question": "is this a horse or pony", "gt answer": "pony(1.00)<br/>horse(1.00)", "pred answer": "stallion", "question_id": 786565, "best approach": "wiki, concept, image", "verif answer": "horse", "anno approach": "wiki", "verif wiki answer": "horse(0.7024)", "verif concept answer": "horse(0.7300)", "verif image answer": "horse(0.7193)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078656.jpg"}, {"question": "what breed is this", "gt answer": "labrador(1.00)<br/>black labrador(0.60)<br/>retriever(0.60)<br/>lab(0.60)", "pred answer": "labrador", "question_id": 2758855, "best approach": "wiki, concept", "verif answer": "labrador", "anno approach": "wiki", "verif wiki answer": "labrador(0.7256)", "verif concept answer": "labrador(0.7089)", "verif image answer": "black lab(0.6787)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000275885.jpg"}, {"question": "what profession are these people", "gt answer": "chef(1.00)<br/>cook(0.60)", "pred answer": "chef", "question_id": 2577825, "best approach": "concept", "verif answer": "culinary", "anno approach": "concept", "verif wiki answer": "culinary(0.6916)", "verif concept answer": "chef(0.6774)", "verif image answer": "toque(0.6245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257782.jpg"}, {"question": "what sort of wires are above the vehicle", "gt answer": "electrical(1.00)<br/>power(0.60)<br/>phone(0.60)<br/>telephone(0.60)", "pred answer": "electric", "question_id": 784105, "best approach": "concept, image", "verif answer": "electrical", "anno approach": "concept", "verif wiki answer": "telephone(0.6731)", "verif concept answer": "electrical(0.7212)", "verif image answer": "electrical(0.6522)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078410.jpg"}, {"question": "what is this person doing", "gt answer": "play baseball(1.00)<br/>bat(0.60)", "pred answer": "hit ball", "question_id": 1407875, "best approach": "wiki, concept", "verif answer": "play baseball", "anno approach": "", "verif wiki answer": "play baseball(0.7108)", "verif concept answer": "play baseball(0.7279)", "verif image answer": "baseball bat(0.7091)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140787.jpg"}, {"question": "what is this sign for", "gt answer": "stop(1.00)<br/>traffic(0.60)", "pred answer": "park", "question_id": 834075, "best approach": "concept, image", "verif answer": "traffic", "anno approach": "concept", "verif wiki answer": "traffic(0.7107)", "verif concept answer": "stop(0.7019)", "verif image answer": "stop(0.6658)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083407.jpg"}, {"question": "what direction would you drive in this situation", "gt answer": "left(1.00)", "pred answer": "north", "question_id": 3975995, "best approach": "image", "verif answer": "left", "anno approach": "image", "verif wiki answer": "horizontal(0.5189)", "verif concept answer": "horizontal(0.5369)", "verif image answer": "left(0.5611)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397599.jpg"}, {"question": "what nationality is the man holding the plate", "gt answer": "asian(1.00)<br/>white(0.60)<br/>italian(0.60)<br/>french(0.60)", "pred answer": "french", "question_id": 2737825, "best approach": "wiki, concept, image", "verif answer": "asian", "anno approach": "concept, wiki", "verif wiki answer": "asian(0.7187)", "verif concept answer": "asian(0.6943)", "verif image answer": "asian(0.6567)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273782.jpg"}, {"question": "what is the name of a famous contest in kentucky these animals participate in", "gt answer": "kentucky derby(1.00)", "pred answer": "race", "question_id": 4159095, "best approach": "", "verif answer": "hell angel", "anno approach": "", "verif wiki answer": "hell angel(0.5219)", "verif concept answer": "saddle(0.5112)", "verif image answer": "thoroughbred(0.5172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415909.jpg"}, {"question": "what years was this bus in public service", "gt answer": "1950(1.00)<br/>1965(0.60)<br/>1930(0.60)<br/>1945(0.60)", "pred answer": "1940", "question_id": 1921145, "best approach": "wiki, concept, image", "verif answer": "1945", "anno approach": "wiki", "verif wiki answer": "1945(0.6671)", "verif concept answer": "1965(0.6595)", "verif image answer": "1965(0.6650)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000192114.jpg"}, {"question": "what pattern is shown in this picture", "gt answer": "striped(1.00)<br/>stripe(0.60)", "pred answer": "stripe", "question_id": 3665775, "best approach": "wiki, concept, image", "verif answer": "stripe", "anno approach": "wiki", "verif wiki answer": "stripe(0.7285)", "verif concept answer": "stripe(0.7294)", "verif image answer": "stripe(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366577.jpg"}, {"question": "what kind of bird is in this picture", "gt answer": "falcon(1.00)<br/>hawk(0.60)<br/>robin(0.60)", "pred answer": "finch", "question_id": 3345855, "best approach": "wiki", "verif answer": "finch", "anno approach": "wiki", "verif wiki answer": "falcon(0.7204)", "verif concept answer": "finch(0.7219)", "verif image answer": "finch(0.7099)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334585.jpg"}, {"question": "what ocean sea is this", "gt answer": "caribbean(1.00)<br/>atlantic(0.60)<br/>pacific(0.60)<br/>atlantic ocean(0.60)", "pred answer": "atlantic", "question_id": 496115, "best approach": "wiki, concept", "verif answer": "atlantic ocean", "anno approach": "wiki", "verif wiki answer": "atlantic ocean(0.7150)", "verif concept answer": "atlantic ocean(0.6951)", "verif image answer": "pacific ocean(0.6933)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049611.jpg"}, {"question": "what profession would most likely use these intruments", "gt answer": "doctor(1.00)", "pred answer": "military", "question_id": 3835815, "best approach": "wiki, concept, image", "verif answer": "doctor", "anno approach": "wiki", "verif wiki answer": "doctor(0.7111)", "verif concept answer": "doctor(0.6000)", "verif image answer": "doctor(0.5848)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383581.jpg"}, {"question": "", "gt answer": "1960's(0.60)<br/>1970(0.60)<br/>1970's(0.60)", "pred answer": "20th", "question_id": 4098345, "best approach": "", "verif answer": "60s", "anno approach": "", "verif wiki answer": "60s(0.5521)", "verif concept answer": "60s(0.5902)", "verif image answer": "60s(0.6326)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409834.jpg"}, {"question": "what sort of scottish garment is often associated with a pattern similar to that upon this pink and yellow couch", "gt answer": "kilt(1.00)<br/>plaid(1.00)", "pred answer": "native american", "question_id": 4685305, "best approach": "wiki, concept, image", "verif answer": "plaid", "anno approach": "wiki", "verif wiki answer": "plaid(0.7298)", "verif concept answer": "plaid(0.7177)", "verif image answer": "plaid(0.7246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000468530.jpg"}, {"question": "what type of food is this", "gt answer": "sushi(1.00)<br/>soup(0.60)<br/>vegetable(0.60)", "pred answer": "pasta", "question_id": 5056255, "best approach": "wiki, image", "verif answer": "carrot", "anno approach": "wiki", "verif wiki answer": "sushi(0.6744)", "verif concept answer": "carrot(0.6869)", "verif image answer": "sushi(0.6646)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505625.jpg"}, {"question": "how can we be sure which men are not playing this game", "gt answer": "sit(1.00)", "pred answer": "video game", "question_id": 5385185, "best approach": "", "verif answer": "balance", "anno approach": "", "verif wiki answer": "balance(0.6897)", "verif concept answer": "forest gump(0.6994)", "verif image answer": "balance(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538518.jpg"}, {"question": "what do the objects the women are holding protect them from", "gt answer": "rain(1.00)", "pred answer": "sunlight", "question_id": 1708095, "best approach": "image", "verif answer": "shade", "anno approach": "image", "verif wiki answer": "protection(0.7001)", "verif concept answer": "shade(0.7157)", "verif image answer": "rain(0.6516)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000170809.jpg"}, {"question": "what is the shape of that sign", "gt answer": "octagon(1.00)<br/>hexagon(0.60)", "pred answer": "octagon", "question_id": 235425, "best approach": "wiki, concept, image", "verif answer": "octagon", "anno approach": "wiki", "verif wiki answer": "octagon(0.6998)", "verif concept answer": "octagon(0.7012)", "verif image answer": "octagon(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023542.jpg"}, {"question": "what does the street sign mean to drivers", "gt answer": "do not enter(1.00)<br/>yield(0.60)", "pred answer": "crosswalk", "question_id": 3836395, "best approach": "", "verif answer": "stall", "anno approach": "", "verif wiki answer": "slow down(0.6140)", "verif concept answer": "stall(0.6313)", "verif image answer": "stall(0.6042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383639.jpg"}, {"question": "what meat was used", "gt answer": "salami(1.00)<br/>ham(0.60)<br/>fish(0.60)<br/>pork(0.60)", "pred answer": "pork", "question_id": 5100275, "best approach": "wiki, concept", "verif answer": "salami", "anno approach": "", "verif wiki answer": "salami(0.6943)", "verif concept answer": "salami(0.7112)", "verif image answer": "fish(0.6952)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510027.jpg"}, {"question": "what is the offspring of this animal and a horse called", "gt answer": "zorse(1.00)<br/>kid(0.60)<br/>foal(0.60)", "pred answer": "puppy", "question_id": 2448475, "best approach": "", "verif answer": "woman", "anno approach": "", "verif wiki answer": "woman(0.6670)", "verif concept answer": "woman(0.6400)", "verif image answer": "woman(0.6369)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244847.jpg"}, {"question": "what type of bike is this", "gt answer": "dirt bike(1.00)<br/>motor(0.60)<br/>motorbike(0.60)", "pred answer": "dirt bike", "question_id": 236315, "best approach": "wiki", "verif answer": "dirt bike", "anno approach": "wiki", "verif wiki answer": "dirt bike(0.7073)", "verif concept answer": "motorbike(0.6847)", "verif image answer": "motorbike(0.6917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023631.jpg"}, {"question": "what language is this sign in", "gt answer": "arabic(1.00)<br/>japanese(0.60)", "pred answer": "arabic", "question_id": 5596195, "best approach": "wiki, concept, image", "verif answer": "arabic", "anno approach": "wiki", "verif wiki answer": "arabic(0.7140)", "verif concept answer": "arabic(0.7261)", "verif image answer": "arabic(0.7198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559619.jpg"}, {"question": "what could you make out of these ingredients", "gt answer": "salad(1.00)<br/>soup(0.60)<br/>stirfry(0.60)", "pred answer": "salad", "question_id": 3519895, "best approach": "wiki, concept, image", "verif answer": "salad", "anno approach": "wiki", "verif wiki answer": "salad(0.6925)", "verif concept answer": "salad(0.6671)", "verif image answer": "salad(0.6904)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351989.jpg"}, {"question": "what form of animal is this", "gt answer": "polar bear(1.00)<br/>bear(1.00)", "pred answer": "sheep", "question_id": 4721815, "best approach": "", "verif answer": "sheep", "anno approach": "", "verif wiki answer": "polar(0.6505)", "verif concept answer": "sheep(0.6215)", "verif image answer": "sheep(0.7111)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000472181.jpg"}, {"question": "what type of emergencies do these group of people respond to", "gt answer": "fire(1.00)", "pred answer": "traffic", "question_id": 1731985, "best approach": "", "verif answer": "firefight", "anno approach": "", "verif wiki answer": "firefight(0.7028)", "verif concept answer": "firefight(0.7085)", "verif image answer": "firefight(0.7169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000173198.jpg"}, {"question": "when would he wear these types of clothes", "gt answer": "interview(1.00)<br/>business(0.60)<br/>work(0.60)<br/>meet(0.60)", "pred answer": "1940", "question_id": 348165, "best approach": "wiki", "verif answer": "interview", "anno approach": "wiki", "verif wiki answer": "interview(0.6088)", "verif concept answer": "meet(0.5761)", "verif image answer": "business(0.6035)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000034816.jpg"}, {"question": "what does one call this sort of enclosed work space", "gt answer": "cubicle(1.00)<br/>cubical(1.00)<br/>office(0.60)", "pred answer": "office", "question_id": 153745, "best approach": "wiki, concept", "verif answer": "cubicle", "anno approach": "wiki", "verif wiki answer": "cubicle(0.7034)", "verif concept answer": "cubicle(0.6937)", "verif image answer": "politic(0.6455)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015374.jpg"}, {"question": "what is the white item on the left for", "gt answer": "keep food cold(1.00)<br/>fridge(0.60)<br/>storage(0.60)", "pred answer": "sew", "question_id": 966905, "best approach": "", "verif answer": "refridgerator", "anno approach": "", "verif wiki answer": "refridgerator(0.6685)", "verif concept answer": "refridgerator(0.7120)", "verif image answer": "refridgerator(0.6806)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096690.jpg"}, {"question": "what is the texture of that white stuffed animal", "gt answer": "fluffy(1.00)<br/>silk(0.60)<br/>soft(0.60)", "pred answer": "wool", "question_id": 2212895, "best approach": "", "verif answer": "checkered", "anno approach": "", "verif wiki answer": "checkered(0.6694)", "verif concept answer": "checkered(0.6545)", "verif image answer": "checkered(0.6013)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221289.jpg"}, {"question": "is this person an experienced tennis player or just a beginner", "gt answer": "beginner(1.00)", "pred answer": "double", "question_id": 1743915, "best approach": "", "verif answer": "expert", "anno approach": "", "verif wiki answer": "expert(0.7232)", "verif concept answer": "expert(0.6743)", "verif image answer": "public(0.5668)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174391.jpg"}, {"question": "what kind of flowers are in the vase", "gt answer": "bouquet(1.00)<br/>rose(0.60)", "pred answer": "tulip", "question_id": 305, "best approach": "wiki, concept, image", "verif answer": "rose", "anno approach": "wiki", "verif wiki answer": "rose(0.7181)", "verif concept answer": "rose(0.7143)", "verif image answer": "rose(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000030.jpg"}, {"question": "what kind of facility is this", "gt answer": "bathroom(1.00)", "pred answer": "bathroom", "question_id": 1987865, "best approach": "wiki, concept", "verif answer": "bathroom", "anno approach": "wiki", "verif wiki answer": "bathroom(0.7262)", "verif concept answer": "bathroom(0.7001)", "verif image answer": "brown(0.6742)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198786.jpg"}, {"question": "is the second floor of the building residential or commercial property", "gt answer": "residential(1.00)", "pred answer": "commercial", "question_id": 3696895, "best approach": "", "verif answer": "hotel bathroom", "anno approach": "", "verif wiki answer": "urban(0.6738)", "verif concept answer": "urban(0.6362)", "verif image answer": "hotel bathroom(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369689.jpg"}, {"question": "what fun event are they doing on this windy day", "gt answer": "fly kite(1.00)<br/>kite fly(1.00)<br/>kite(0.60)", "pred answer": "kite", "question_id": 3172345, "best approach": "image", "verif answer": "kite", "anno approach": "image", "verif wiki answer": "kite(0.6918)", "verif concept answer": "kite(0.6692)", "verif image answer": "kite fly(0.6582)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317234.jpg"}, {"question": "what topping is on this donut", "gt answer": "coconut(1.00)", "pred answer": "sprinkle", "question_id": 680855, "best approach": "", "verif answer": "pineapple", "anno approach": "", "verif wiki answer": "pine(0.6614)", "verif concept answer": "pineapple(0.7168)", "verif image answer": "pineapple(0.7243)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068085.jpg"}, {"question": "how many times a day does the average person enter one of these types of rooms", "gt answer": "5(1.00)<br/>7(0.60)<br/>3(0.60)<br/>8(0.60)", "pred answer": "50", "question_id": 848335, "best approach": "wiki, concept, image", "verif answer": "3", "anno approach": "wiki", "verif wiki answer": "3(0.6764)", "verif concept answer": "3(0.6445)", "verif image answer": "7(0.6176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084833.jpg"}, {"question": "what is on the wall", "gt answer": "mural(1.00)<br/>paint(0.60)<br/>graffiti(0.60)", "pred answer": "graffiti", "question_id": 2523595, "best approach": "wiki, concept, image", "verif answer": "graffiti", "anno approach": "wiki", "verif wiki answer": "paint(0.7293)", "verif concept answer": "graffiti(0.7136)", "verif image answer": "graffiti(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252359.jpg"}, {"question": "what company operates this airplane", "gt answer": "korean air(1.00)<br/>united(0.60)", "pred answer": "boeing", "question_id": 2834265, "best approach": "", "verif answer": "american", "anno approach": "", "verif wiki answer": "lufthansa(0.6281)", "verif concept answer": "lufthansa(0.6010)", "verif image answer": "american(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283426.jpg"}, {"question": "what animal is on the left", "gt answer": "dog(1.00)<br/>wolf(1.00)<br/>bear(0.60)", "pred answer": "dog", "question_id": 5414395, "best approach": "wiki, concept, image", "verif answer": "dog", "anno approach": "wiki", "verif wiki answer": "dog(0.7212)", "verif concept answer": "dog(0.7102)", "verif image answer": "dog(0.7099)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541439.jpg"}, {"question": "people sit here and put on their makeup what is this type of desk called", "gt answer": "vanity(1.00)", "pred answer": "paint", "question_id": 4652135, "best approach": "", "verif answer": "bathroom", "anno approach": "", "verif wiki answer": "bathroom(0.7296)", "verif concept answer": "cleanliness(0.7182)", "verif image answer": "cleanliness(0.5684)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465213.jpg"}, {"question": "a game played with a stick is called what", "gt answer": "hockey(1.00)", "pred answer": "frisbee", "question_id": 5162495, "best approach": "wiki", "verif answer": "hockey", "anno approach": "wiki", "verif wiki answer": "hockey(0.7179)", "verif concept answer": "soccer(0.6427)", "verif image answer": "basketball(0.6941)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516249.jpg"}, {"question": "is this a commuter train or a freight train", "gt answer": "freight(1.00)<br/>commuter(1.00)", "pred answer": "freight", "question_id": 5352505, "best approach": "", "verif answer": "bullet", "anno approach": "", "verif wiki answer": "bullet(0.7154)", "verif concept answer": "bullet(0.6660)", "verif image answer": "bullet(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535250.jpg"}, {"question": "what might they be buying", "gt answer": "produce(1.00)<br/>vegetable(1.00)<br/>cabbage(0.60)", "pred answer": "food", "question_id": 1896455, "best approach": "", "verif answer": "street", "anno approach": "", "verif wiki answer": "street(0.6730)", "verif concept answer": "street(0.6251)", "verif image answer": "fruit(0.5526)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000189645.jpg"}, {"question": "what architectural type of window is depicted", "gt answer": "oculus(1.00)<br/>rose(0.60)<br/>gothic(0.60)<br/>window(0.60)", "pred answer": "gothic", "question_id": 2061925, "best approach": "wiki, concept, image", "verif answer": "rose", "anno approach": "wiki", "verif wiki answer": "gothic(0.6694)", "verif concept answer": "gothic(0.6862)", "verif image answer": "rose(0.6884)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206192.jpg"}, {"question": "sturges is a gathering of people riding what type of vehicle seen in this image", "gt answer": "motorcycle(1.00)<br/>scooter(0.60)", "pred answer": "motorcycle", "question_id": 5268775, "best approach": "wiki, concept, image", "verif answer": "scooter", "anno approach": "wiki", "verif wiki answer": "scooter(0.7079)", "verif concept answer": "scooter(0.7223)", "verif image answer": "scooter(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526877.jpg"}, {"question": "is this elephant real or man made", "gt answer": "manmade(1.00)<br/>man made(1.00)", "pred answer": "real", "question_id": 3234895, "best approach": "wiki, concept, image", "verif answer": "man made", "anno approach": "", "verif wiki answer": "man made(0.7268)", "verif concept answer": "man made(0.7269)", "verif image answer": "man made(0.7082)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323489.jpg"}, {"question": "what is the cat sitting in", "gt answer": "bed(1.00)", "pred answer": "sofa", "question_id": 1675775, "best approach": "wiki, concept", "verif answer": "bed", "anno approach": "wiki", "verif wiki answer": "bed(0.6890)", "verif concept answer": "bed(0.6641)", "verif image answer": "pillow(0.6534)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167577.jpg"}, {"question": "what breed of dog is in the photo", "gt answer": "beagle(1.00)", "pred answer": "labrador", "question_id": 4283105, "best approach": "wiki, concept, image", "verif answer": "beagle", "anno approach": "image, wiki", "verif wiki answer": "beagle(0.6538)", "verif concept answer": "beagle(0.6457)", "verif image answer": "beagle(0.6817)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428310.jpg"}, {"question": "what traffic sign is the street man holding", "gt answer": "stop sign(1.00)<br/>stop(1.00)", "pred answer": "traffic", "question_id": 4117055, "best approach": "wiki, concept, image", "verif answer": "stop", "anno approach": "image, wiki", "verif wiki answer": "stop(0.5114)", "verif concept answer": "stop(0.5303)", "verif image answer": "stop(0.6468)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000411705.jpg"}, {"question": "what is the thing on the wall used for", "gt answer": "reflection(1.00)<br/>mirror(0.60)<br/>light(0.60)", "pred answer": "sleep", "question_id": 5057135, "best approach": "image", "verif answer": "reflection", "anno approach": "image", "verif wiki answer": "light(0.5708)", "verif concept answer": "light(0.6298)", "verif image answer": "reflection(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505713.jpg"}, {"question": "who painted the painting hanging on the back wall of this restaurant", "gt answer": "van gogh(1.00)", "pred answer": "banksy", "question_id": 2836825, "best approach": "", "verif answer": "monet", "anno approach": "", "verif wiki answer": "monet(0.6934)", "verif concept answer": "monet(0.7142)", "verif image answer": "wine taster(0.6582)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283682.jpg"}, {"question": "are roses annuals or perennials", "gt answer": "annual(1.00)", "pred answer": "heterosexual", "question_id": 1151565, "best approach": "", "verif answer": "fragile", "anno approach": "", "verif wiki answer": "fragile(0.6436)", "verif concept answer": "fragile(0.6961)", "verif image answer": "fragile(0.6981)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115156.jpg"}, {"question": "where is the mast famous outside market for this type of goods", "gt answer": "mexico(1.00)<br/>europe(0.60)<br/>flea market(0.60)", "pred answer": "street", "question_id": 1784115, "best approach": "image", "verif answer": "flea market", "anno approach": "image", "verif wiki answer": "flea market(0.6599)", "verif concept answer": "flea market(0.6727)", "verif image answer": "mexico(0.6603)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178411.jpg"}, {"question": "how do you think this dog is feeling", "gt answer": "tired(1.00)<br/>sleepy(0.60)<br/>cold(0.60)", "pred answer": "sleepy", "question_id": 1340855, "best approach": "wiki, concept, image", "verif answer": "sleepy", "anno approach": "wiki", "verif wiki answer": "sleepy(0.7252)", "verif concept answer": "sleepy(0.7152)", "verif image answer": "sleepy(0.6832)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134085.jpg"}, {"question": "why would we suspect that this individual has the ability to filter our distractions", "gt answer": "headphone(1.00)", "pred answer": "text", "question_id": 1810095, "best approach": "", "verif answer": "television", "anno approach": "", "verif wiki answer": "television(0.6103)", "verif concept answer": "television(0.5712)", "verif image answer": "earbud(0.5942)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181009.jpg"}, {"question": "what style of furniture is this table and example of", "gt answer": "antique(1.00)<br/>formal(0.60)", "pred answer": "gothic", "question_id": 4946225, "best approach": "", "verif answer": "roman", "anno approach": "", "verif wiki answer": "roman(0.6602)", "verif concept answer": "roman(0.6578)", "verif image answer": "roman(0.6766)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494622.jpg"}, {"question": "what is driver 's jacket made out of", "gt answer": "leather(1.00)", "pred answer": "denim", "question_id": 1712725, "best approach": "", "verif answer": "ivory", "anno approach": "", "verif wiki answer": "rubber(0.6994)", "verif concept answer": "ivory(0.7090)", "verif image answer": "ivory(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171272.jpg"}, {"question": "what company introduced the toy being played with here", "gt answer": "frisbee(1.00)<br/>hasbro(0.60)", "pred answer": "frisbee", "question_id": 866205, "best approach": "image", "verif answer": "catch", "anno approach": "image", "verif wiki answer": "catch(0.6979)", "verif concept answer": "catch(0.7061)", "verif image answer": "hasbro(0.7042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086620.jpg"}, {"question": "what is the person 's shape on the wall called", "gt answer": "shadow(1.00)", "pred answer": "cross", "question_id": 3429495, "best approach": "", "verif answer": "reflection", "anno approach": "", "verif wiki answer": "reflection(0.5398)", "verif concept answer": "reflection(0.5568)", "verif image answer": "reflection(0.6492)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342949.jpg"}, {"question": "how capable is the cat at using the device", "gt answer": "not(1.00)<br/>not at all(0.60)", "pred answer": "very", "question_id": 1096295, "best approach": "", "verif answer": "very healthy", "anno approach": "", "verif wiki answer": "very healthy(0.6625)", "verif concept answer": "very healthy(0.6579)", "verif image answer": "very healthy(0.5525)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000109629.jpg"}, {"question": "is this toast or french toast", "gt answer": "french toast(1.00)<br/>toast(0.60)<br/>french(0.60)", "pred answer": "fork", "question_id": 4332215, "best approach": "", "verif answer": "ramen", "anno approach": "", "verif wiki answer": "ramen(0.5124)", "verif concept answer": "ramen(0.5013)", "verif image answer": "ramen(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433221.jpg"}, {"question": "where can this boat go", "gt answer": "to sea(1.00)", "pred answer": "spain", "question_id": 895825, "best approach": "wiki, concept, image", "verif answer": "to sea", "anno approach": "", "verif wiki answer": "to sea(0.6992)", "verif concept answer": "to sea(0.6944)", "verif image answer": "to sea(0.6706)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089582.jpg"}, {"question": "why is this banana brown", "gt answer": "over ripe(1.00)<br/>ripe(0.60)<br/>bad(0.60)", "pred answer": "not ripe", "question_id": 2930125, "best approach": "", "verif answer": "drink", "anno approach": "", "verif wiki answer": "drink(0.6154)", "verif concept answer": "drink(0.6040)", "verif image answer": "drink(0.6540)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293012.jpg"}, {"question": "what type of scenery is this", "gt answer": "patio(1.00)<br/>cafe(0.60)<br/>indoor(0.60)", "pred answer": "city", "question_id": 2794775, "best approach": "wiki, concept, image", "verif answer": "patio", "anno approach": "concept, wiki", "verif wiki answer": "patio(0.7041)", "verif concept answer": "patio(0.7046)", "verif image answer": "patio(0.6669)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000279477.jpg"}, {"question": "what is the name of the area in which the athlete is standing", "gt answer": "court(1.00)<br/>tennis court(1.00)", "pred answer": "net", "question_id": 3775435, "best approach": "", "verif answer": "park", "anno approach": "", "verif wiki answer": "everywhere(0.6084)", "verif concept answer": "everywhere(0.5188)", "verif image answer": "park(0.6361)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377543.jpg"}, {"question": "what is the cost of pineapples", "gt answer": "1.5(1.00)<br/>50(0.60)", "pred answer": "5000", "question_id": 2364845, "best approach": "wiki, concept, image", "verif answer": "1.5", "anno approach": "image, wiki", "verif wiki answer": "1.5(0.6664)", "verif concept answer": "1.5(0.5893)", "verif image answer": "1.5(0.6592)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236484.jpg"}, {"question": "what is the sink layout in this picture commonly called", "gt answer": "vanity(1.00)<br/>double(0.60)<br/>jack and jill(0.60)<br/>bathroom(0.60)", "pred answer": "modern", "question_id": 1995985, "best approach": "wiki, concept, image", "verif answer": "double", "anno approach": "concept, wiki", "verif wiki answer": "double(0.6313)", "verif concept answer": "double(0.6215)", "verif image answer": "double(0.5793)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199598.jpg"}, {"question": "what diet plan would this meal fall under", "gt answer": "healthy(1.00)", "pred answer": "vegetarian", "question_id": 439175, "best approach": "", "verif answer": "vegetarian", "anno approach": "", "verif wiki answer": "vegetarian(0.6728)", "verif concept answer": "vegetarian(0.6789)", "verif image answer": "vegetarian(0.6867)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043917.jpg"}, {"question": "what culture considers these to be good luck", "gt answer": "indian(1.00)<br/>hindi(0.60)", "pred answer": "indian", "question_id": 4566525, "best approach": "", "verif answer": "arabic", "anno approach": "", "verif wiki answer": "arabic(0.6907)", "verif concept answer": "arabic(0.7143)", "verif image answer": "arabic(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456652.jpg"}, {"question": "is the baby laughing or crying", "gt answer": "cry(1.00)", "pred answer": "tired", "question_id": 2636855, "best approach": "wiki, concept, image", "verif answer": "cry", "anno approach": "", "verif wiki answer": "cry(0.7255)", "verif concept answer": "cry(0.7199)", "verif image answer": "cry(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263685.jpg"}, {"question": "what type of natural disaster can happen in a place like this", "gt answer": "avalanche(1.00)", "pred answer": "crash", "question_id": 5378755, "best approach": "concept, image", "verif answer": "avalanche", "anno approach": "", "verif wiki answer": "mountain(0.5979)", "verif concept answer": "avalanche(0.5952)", "verif image answer": "avalanche(0.6039)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537875.jpg"}, {"question": "what is the purpose railings and stairs in the picture", "gt answer": "fire escape(1.00)", "pred answer": "transport", "question_id": 2594395, "best approach": "wiki, concept, image", "verif answer": "fire escape", "anno approach": "image, concept, wiki", "verif wiki answer": "fire escape(0.6826)", "verif concept answer": "fire escape(0.7175)", "verif image answer": "fire escape(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259439.jpg"}, {"question": "what company made this train", "gt answer": "amtrack(1.00)<br/>virgin(0.60)", "pred answer": "toyota", "question_id": 367765, "best approach": "", "verif answer": "green", "anno approach": "", "verif wiki answer": "green(0.7010)", "verif concept answer": "green(0.7065)", "verif image answer": "green(0.7084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036776.jpg"}, {"question": "what is in the dark colored bottle", "gt answer": "wine(1.00)", "pred answer": "wine", "question_id": 2266585, "best approach": "", "verif answer": "beer", "anno approach": "", "verif wiki answer": "milk(0.6491)", "verif concept answer": "milk(0.5813)", "verif image answer": "beer(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226658.jpg"}, {"question": "is this plane landing or taking off", "gt answer": "take off(1.00)<br/>land(1.00)", "pred answer": "take off", "question_id": 2547105, "best approach": "wiki, concept, image", "verif answer": "take off", "anno approach": "wiki", "verif wiki answer": "land(0.7292)", "verif concept answer": "take off(0.7196)", "verif image answer": "take off(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000254710.jpg"}, {"question": "what type of object is inserted in this system to play games", "gt answer": "cd(1.00)<br/>disc(1.00)", "pred answer": "microwave", "question_id": 2600975, "best approach": "image", "verif answer": "cd", "anno approach": "image", "verif wiki answer": "camera(0.6597)", "verif concept answer": "camera(0.6655)", "verif image answer": "cd(0.6981)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260097.jpg"}, {"question": "what are the line of people holding", "gt answer": "flag(1.00)", "pred answer": "kite", "question_id": 2551865, "best approach": "image", "verif answer": "shield", "anno approach": "image", "verif wiki answer": "shield(0.7283)", "verif concept answer": "kite(0.7269)", "verif image answer": "flag(0.6020)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255186.jpg"}, {"question": "", "gt answer": "light(0.60)<br/>decoration(0.60)<br/>decor(0.60)", "pred answer": "water", "question_id": 3937055, "best approach": "image", "verif answer": "paint", "anno approach": "image", "verif wiki answer": "paint(0.5597)", "verif concept answer": "paint(0.5241)", "verif image answer": "light(0.5023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393705.jpg"}, {"question": "are these different animals in this picture or all they all the same animal", "gt answer": "different(1.00)<br/>same(1.00)", "pred answer": "younger", "question_id": 4614455, "best approach": "wiki, concept, image", "verif answer": "same", "anno approach": "concept, wiki", "verif wiki answer": "same(0.6821)", "verif concept answer": "same(0.7076)", "verif image answer": "same(0.6640)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461445.jpg"}, {"question": "the orange fruit is associated with preventing which disease that was once the scourge of sailors", "gt answer": "scurvy(1.00)<br/>grapefruit(0.60)", "pred answer": "banana", "question_id": 5452575, "best approach": "wiki, concept, image", "verif answer": "scurvy", "anno approach": "wiki", "verif wiki answer": "scurvy(0.7305)", "verif concept answer": "scurvy(0.7308)", "verif image answer": "scurvy(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545257.jpg"}, {"question": "where would you see this", "gt answer": "air show(1.00)<br/>sky(0.60)<br/>airshow(0.60)", "pred answer": "airport", "question_id": 4099795, "best approach": "wiki, concept, image", "verif answer": "air show", "anno approach": "wiki", "verif wiki answer": "air show(0.7233)", "verif concept answer": "air show(0.7188)", "verif image answer": "air show(0.7028)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409979.jpg"}, {"question": "what are these animals rumored to never do", "gt answer": "forget(1.00)<br/>sleep(0.60)<br/>jump(0.60)<br/>fly(0.60)", "pred answer": "run", "question_id": 3337055, "best approach": "wiki, concept", "verif answer": "forget", "anno approach": "wiki", "verif wiki answer": "forget(0.7284)", "verif concept answer": "forget(0.7276)", "verif image answer": "fly(0.7055)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333705.jpg"}, {"question": "how many teeth do these animals have", "gt answer": "42(1.00)<br/>36(0.60)<br/>28(0.60)", "pred answer": "300", "question_id": 5526575, "best approach": "wiki, concept", "verif answer": "22", "anno approach": "", "verif wiki answer": "36(0.6824)", "verif concept answer": "28(0.6764)", "verif image answer": "22(0.7256)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552657.jpg"}, {"question": "where are these men playing ball", "gt answer": "baseball field(1.00)<br/>field(0.60)<br/>chicago(0.60)<br/>stadium(0.60)", "pred answer": "baseball", "question_id": 1784435, "best approach": "wiki, image", "verif answer": "stadium", "anno approach": "wiki", "verif wiki answer": "stadium(0.6534)", "verif concept answer": "germany(0.6451)", "verif image answer": "stadium(0.6302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178443.jpg"}, {"question": "what are these planes doing", "gt answer": "land(1.00)<br/>take off(0.60)<br/>parked(0.60)<br/>taxi(0.60)", "pred answer": "fly", "question_id": 1169945, "best approach": "wiki, concept, image", "verif answer": "land", "anno approach": "image, wiki", "verif wiki answer": "land(0.6219)", "verif concept answer": "land(0.6464)", "verif image answer": "land(0.6905)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116994.jpg"}, {"question": "what is on the buns", "gt answer": "hot dog(1.00)<br/>sausage(0.60)", "pred answer": "hot dog", "question_id": 1369625, "best approach": "image", "verif answer": "hot dog", "anno approach": "image", "verif wiki answer": "sausage(0.6014)", "verif concept answer": "sausage(0.6033)", "verif image answer": "hot dog(0.6100)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136962.jpg"}, {"question": "is this animal rested or tired", "gt answer": "tired(1.00)<br/>giraffe(0.60)", "pred answer": "tired", "question_id": 4099095, "best approach": "", "verif answer": "sleepy", "anno approach": "", "verif wiki answer": "sleepy(0.7165)", "verif concept answer": "sleepy(0.7227)", "verif image answer": "sleepy(0.7262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409909.jpg"}, {"question": "what kind of finish was applied to the floors of this house", "gt answer": "gloss(1.00)<br/>wax(0.60)", "pred answer": "laminate", "question_id": 283495, "best approach": "", "verif answer": "marble", "anno approach": "", "verif wiki answer": "marble(0.7300)", "verif concept answer": "marble(0.7309)", "verif image answer": "marble(0.7098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028349.jpg"}, {"question": "this red item is often used when traveling on what sort of vehicle", "gt answer": "airplane(1.00)<br/>plane(0.60)<br/>luggage(0.60)", "pred answer": "van", "question_id": 3210705, "best approach": "", "verif answer": "chair", "anno approach": "", "verif wiki answer": "chair(0.7082)", "verif concept answer": "chair(0.6861)", "verif image answer": "chair(0.6133)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321070.jpg"}, {"question": "can you tell the type of wall shown in the photo", "gt answer": "wooden(1.00)<br/>cabin(0.60)<br/>wood(0.60)", "pred answer": "marble", "question_id": 206525, "best approach": "image", "verif answer": "wood", "anno approach": "image", "verif wiki answer": "wall(0.5139)", "verif concept answer": "wall(0.5104)", "verif image answer": "wood(0.5385)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020652.jpg"}, {"question": "for which meal would this entree be best suited", "gt answer": "dinner(1.00)<br/>lunch(1.00)<br/>breakfast(0.60)", "pred answer": "breakfast", "question_id": 3198685, "best approach": "wiki, concept", "verif answer": "breakfast", "anno approach": "wiki", "verif wiki answer": "breakfast(0.6912)", "verif concept answer": "breakfast(0.6949)", "verif image answer": "noon(0.6917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319868.jpg"}, {"question": "who invented the heater in this image", "gt answer": "franz san galli(1.00)<br/>benjamin franklin(0.60)<br/>plumber(0.60)", "pred answer": "sprague", "question_id": 3174585, "best approach": "wiki, concept", "verif answer": "franz san galli", "anno approach": "wiki", "verif wiki answer": "franz san galli(0.7209)", "verif concept answer": "franz san galli(0.7257)", "verif image answer": "ben franklin(0.6800)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317458.jpg"}, {"question": "what would a person use if they wanted to ride this animal", "gt answer": "saddle(1.00)", "pred answer": "saddle", "question_id": 1757395, "best approach": "wiki, concept, image", "verif answer": "saddle", "anno approach": "wiki", "verif wiki answer": "saddle(0.7228)", "verif concept answer": "saddle(0.7273)", "verif image answer": "saddle(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000175739.jpg"}, {"question": "in what country was this sport invented", "gt answer": "france(1.00)<br/>england(1.00)<br/>china(0.60)", "pred answer": "america", "question_id": 646355, "best approach": "image", "verif answer": "china", "anno approach": "image", "verif wiki answer": "germany(0.5491)", "verif concept answer": "china(0.5971)", "verif image answer": "england(0.5911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064635.jpg"}, {"question": "how can you harvest the material made from this animal 's fur", "gt answer": "shear(1.00)<br/>sheer(0.60)", "pred answer": "wheat", "question_id": 3575105, "best approach": "wiki, concept, image", "verif answer": "shear", "anno approach": "wiki", "verif wiki answer": "shear(0.6791)", "verif concept answer": "shear(0.6206)", "verif image answer": "shear(0.6169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357510.jpg"}, {"question": "what toy store has this as a mascot", "gt answer": "toy r us(1.00)", "pred answer": "toy r us", "question_id": 2068995, "best approach": "wiki, concept, image", "verif answer": "toy r us", "anno approach": "concept, wiki", "verif wiki answer": "toy r us(0.6899)", "verif concept answer": "toy r us(0.6947)", "verif image answer": "toy r us(0.5956)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206899.jpg"}, {"question": "based on the photo how busy is it in the street tonight", "gt answer": "not busy(1.00)<br/>quiet(0.60)<br/>not at all(0.60)", "pred answer": "very", "question_id": 2622605, "best approach": "wiki, concept, image", "verif answer": "quiet", "anno approach": "wiki", "verif wiki answer": "quiet(0.7059)", "verif concept answer": "not at all(0.6811)", "verif image answer": "quiet(0.6710)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262260.jpg"}, {"question": "which children 's character does this resemble", "gt answer": "thomas train(1.00)<br/>thomas tank engine(0.60)", "pred answer": "thomas", "question_id": 198635, "best approach": "", "verif answer": "train", "anno approach": "", "verif wiki answer": "train(0.5122)", "verif concept answer": "train(0.5039)", "verif image answer": "train(0.5292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019863.jpg"}, {"question": "where should you not drive your car according to the sign", "gt answer": "driveway(1.00)", "pred answer": "street", "question_id": 1858485, "best approach": "", "verif answer": "rv", "anno approach": "", "verif wiki answer": "rv(0.6795)", "verif concept answer": "rv(0.6572)", "verif image answer": "rv(0.6207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185848.jpg"}, {"question": "do the fridges appear to be in a home or a place of business", "gt answer": "business(1.00)", "pred answer": "public", "question_id": 5669925, "best approach": "", "verif answer": "suit", "anno approach": "", "verif wiki answer": "professional(0.5970)", "verif concept answer": "suit(0.6322)", "verif image answer": "professional(0.5377)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566992.jpg"}, {"question": "what is the silver round thing hanging in the top right corner called", "gt answer": "clock(1.00)", "pred answer": "clock", "question_id": 926465, "best approach": "", "verif answer": "big ben", "anno approach": "", "verif wiki answer": "big ben(0.7291)", "verif concept answer": "big ben(0.7262)", "verif image answer": "big ben(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092646.jpg"}, {"question": "what paste is applied before doing this activity", "gt answer": "toothpaste(1.00)", "pred answer": "soap", "question_id": 2595955, "best approach": "concept, image", "verif answer": "soap", "anno approach": "", "verif wiki answer": "soap(0.7116)", "verif concept answer": "toothpaste(0.7089)", "verif image answer": "toothpaste(0.7039)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259595.jpg"}, {"question": "what is that for", "gt answer": "call(1.00)<br/>talk(0.60)<br/>take picture(0.60)", "pred answer": "haircut", "question_id": 1224535, "best approach": "image", "verif answer": "take picture", "anno approach": "image", "verif wiki answer": "take picture(0.6625)", "verif concept answer": "take picture(0.5955)", "verif image answer": "call(0.6567)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122453.jpg"}, {"question": "what is this horse pulling", "gt answer": "carriage(1.00)<br/>car(0.60)<br/>cart(0.60)", "pred answer": "carriage", "question_id": 3489045, "best approach": "image", "verif answer": "carriage", "anno approach": "image", "verif wiki answer": "people(0.7236)", "verif concept answer": "people(0.7120)", "verif image answer": "carriage(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348904.jpg"}, {"question": "what can you use to cross this body of water", "gt answer": "boat(1.00)<br/>raft(0.60)", "pred answer": "rail", "question_id": 5141935, "best approach": "", "verif answer": "bird", "anno approach": "", "verif wiki answer": "bird(0.5108)", "verif concept answer": "bird(0.5149)", "verif image answer": "bird(0.7202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514193.jpg"}, {"question": "how old is this child", "gt answer": "6 months(1.00)<br/>2 months(0.60)<br/>8 months(0.60)", "pred answer": "1", "question_id": 1915255, "best approach": "image", "verif answer": "6 months", "anno approach": "image", "verif wiki answer": "8 months(0.6655)", "verif concept answer": "8 months(0.6608)", "verif image answer": "6 months(0.6971)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191525.jpg"}, {"question": "what airline is this", "gt answer": "southwest(1.00)", "pred answer": "southwest", "question_id": 2025835, "best approach": "wiki", "verif answer": "southwest", "anno approach": "wiki", "verif wiki answer": "southwest(0.6899)", "verif concept answer": "american airline(0.6829)", "verif image answer": "boeing(0.5966)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202583.jpg"}, {"question": "which canine sound is the same as a tree part depicted here", "gt answer": "bark(1.00)", "pred answer": "trunk", "question_id": 2318355, "best approach": "wiki, image", "verif answer": "bark", "anno approach": "wiki", "verif wiki answer": "bark(0.7092)", "verif concept answer": "fir(0.7015)", "verif image answer": "bark(0.5860)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231835.jpg"}, {"question": "what kind of trees are these", "gt answer": "palm(1.00)", "pred answer": "palm", "question_id": 2960385, "best approach": "image", "verif answer": "palm", "anno approach": "image", "verif wiki answer": "palm tree(0.6723)", "verif concept answer": "palm tree(0.6738)", "verif image answer": "palm(0.7264)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296038.jpg"}, {"question": "what breed of dog is this", "gt answer": "lab(1.00)<br/>pit bull(0.60)<br/>hound(0.60)", "pred answer": "lab", "question_id": 2846445, "best approach": "", "verif answer": "spaniel", "anno approach": "", "verif wiki answer": "spaniel(0.7138)", "verif concept answer": "spaniel(0.7143)", "verif image answer": "spaniel(0.6677)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284644.jpg"}, {"question": "how many people will this food serve", "gt answer": "8(1.00)<br/>4(0.60)<br/>3(0.60)<br/>2(0.60)", "pred answer": "400", "question_id": 4881505, "best approach": "", "verif answer": "1", "anno approach": "", "verif wiki answer": "1(0.6780)", "verif concept answer": "1(0.6583)", "verif image answer": "1(0.6353)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488150.jpg"}, {"question": "how long does this animal usually live", "gt answer": "30 years(1.00)<br/>30(0.60)<br/>10 years(0.60)", "pred answer": "1800s", "question_id": 4206085, "best approach": "wiki, image", "verif answer": "30", "anno approach": "image, wiki", "verif wiki answer": "30(0.5901)", "verif concept answer": "25(0.5813)", "verif image answer": "30(0.6420)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420608.jpg"}, {"question": "what is hanging from this pole", "gt answer": "street sign(1.00)<br/>sign(1.00)", "pred answer": "traffic", "question_id": 1271045, "best approach": "wiki", "verif answer": "street name", "anno approach": "wiki", "verif wiki answer": "street sign(0.5306)", "verif concept answer": "street(0.5058)", "verif image answer": "street name(0.6389)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127104.jpg"}, {"question": "which type of building will have a clock like this", "gt answer": "church(1.00)<br/>old(0.60)", "pred answer": "apartment", "question_id": 5790025, "best approach": "wiki, concept, image", "verif answer": "church", "anno approach": "wiki", "verif wiki answer": "church(0.7101)", "verif concept answer": "church(0.6980)", "verif image answer": "church(0.7275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000579002.jpg"}, {"question": "who invented this mountain sport", "gt answer": "tom sim(1.00)", "pred answer": "tony hawk", "question_id": 383505, "best approach": "concept, image", "verif answer": "tom sim", "anno approach": "", "verif wiki answer": "bode miller(0.7246)", "verif concept answer": "tom sim(0.6975)", "verif image answer": "tom sim(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038350.jpg"}, {"question": "where is this couple walking around at", "gt answer": "carnival(1.00)<br/>amusement park(0.60)<br/>india(0.60)", "pred answer": "circus", "question_id": 2496195, "best approach": "wiki, concept, image", "verif answer": "amusement park", "anno approach": "concept, wiki", "verif wiki answer": "amusement park(0.7015)", "verif concept answer": "amusement park(0.6794)", "verif image answer": "amusement park(0.6022)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249619.jpg"}, {"question": "what brand of motocycle is this", "gt answer": "bmw(1.00)", "pred answer": "harley", "question_id": 2871735, "best approach": "", "verif answer": "kawasaki", "anno approach": "", "verif wiki answer": "kawasaki(0.7015)", "verif concept answer": "kawasaki(0.7016)", "verif image answer": "kawasaki(0.6790)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287173.jpg"}, {"question": "what type of sandwich is this", "gt answer": "grilled cheese(1.00)<br/>toasted(0.60)", "pred answer": "turkey", "question_id": 2955715, "best approach": "wiki", "verif answer": "toasted", "anno approach": "wiki", "verif wiki answer": "grilled cheese(0.6355)", "verif concept answer": "toasted(0.6269)", "verif image answer": "toasted(0.7097)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295571.jpg"}, {"question": "what is this plant doing in water", "gt answer": "grow(1.00)", "pred answer": "water", "question_id": 3586205, "best approach": "concept, image", "verif answer": "grow", "anno approach": "image", "verif wiki answer": "go(0.6838)", "verif concept answer": "grow(0.6852)", "verif image answer": "grow(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358620.jpg"}, {"question": "what room is this", "gt answer": "computer lab(1.00)<br/>office(1.00)", "pred answer": "office", "question_id": 5777625, "best approach": "wiki, concept", "verif answer": "office", "anno approach": "wiki", "verif wiki answer": "office(0.7028)", "verif concept answer": "office(0.6884)", "verif image answer": "meet(0.6911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000577762.jpg"}, {"question": "who would be most likely to sit here", "gt answer": "person(1.00)<br/>people(0.60)", "pred answer": "old", "question_id": 2430005, "best approach": "image", "verif answer": "man", "anno approach": "image", "verif wiki answer": "man(0.7303)", "verif concept answer": "man(0.7230)", "verif image answer": "person(0.6921)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243000.jpg"}, {"question": "what are the doors in the background called", "gt answer": "french(1.00)<br/>french door(0.60)", "pred answer": "cabinet", "question_id": 2905845, "best approach": "", "verif answer": "arch", "anno approach": "", "verif wiki answer": "arch(0.6790)", "verif concept answer": "arch(0.6401)", "verif image answer": "arch(0.5448)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000290584.jpg"}, {"question": "where does this vehicle travel", "gt answer": "air(1.00)", "pred answer": "jet fuel", "question_id": 74895, "best approach": "", "verif answer": "sky", "anno approach": "", "verif wiki answer": "sky(0.6254)", "verif concept answer": "sky(0.6471)", "verif image answer": "sky(0.6073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007489.jpg"}, {"question": "in what year would you commonly see this plane flying", "gt answer": "1940(1.00)<br/>1940s(0.60)<br/>1989(0.60)<br/>1930(0.60)", "pred answer": "1950", "question_id": 4827985, "best approach": "wiki, concept", "verif answer": "1989", "anno approach": "wiki", "verif wiki answer": "1989(0.6941)", "verif concept answer": "1989(0.6645)", "verif image answer": "1950(0.6581)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482798.jpg"}, {"question": "what team hat is he wearing", "gt answer": "yankees(1.00)<br/>met(0.60)", "pred answer": "blue jay", "question_id": 558725, "best approach": "", "verif answer": "dodger", "anno approach": "", "verif wiki answer": "dodger(0.7244)", "verif concept answer": "dodger(0.7164)", "verif image answer": "dodger(0.6966)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000055872.jpg"}, {"question": "what could be inside the sandwich", "gt answer": "ham(1.00)<br/>meat(1.00)", "pred answer": "sandwich", "question_id": 3773005, "best approach": "wiki, concept", "verif answer": "ham", "anno approach": "wiki", "verif wiki answer": "ham(0.6084)", "verif concept answer": "ham(0.6207)", "verif image answer": "beef(0.5311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377300.jpg"}, {"question": "what brand of peanuts is this", "gt answer": "fisher(1.00)<br/>walmart(0.60)", "pred answer": "whiskey", "question_id": 5240565, "best approach": "wiki, image", "verif answer": "fisher", "anno approach": "", "verif wiki answer": "fisher(0.5000)", "verif concept answer": "target(0.5000)", "verif image answer": "fisher(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000524056.jpg"}, {"question": "what is the name for a device you put money in to park your car", "gt answer": "meter(1.00)", "pred answer": "coin", "question_id": 1520565, "best approach": "", "verif answer": "park meter", "anno approach": "", "verif wiki answer": "wrench(0.6085)", "verif concept answer": "wrench(0.6682)", "verif image answer": "park meter(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000152056.jpg"}, {"question": "who owns this airplane", "gt answer": "skyteam(1.00)<br/>american airline(0.60)", "pred answer": "boeing", "question_id": 1262825, "best approach": "wiki, concept, image", "verif answer": "american airline", "anno approach": "wiki", "verif wiki answer": "american airline(0.5275)", "verif concept answer": "american airline(0.5158)", "verif image answer": "american airline(0.5115)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126282.jpg"}, {"question": "what is the round object used for", "gt answer": "tell time(1.00)<br/>time(0.60)", "pred answer": "time", "question_id": 3100475, "best approach": "", "verif answer": "clock", "anno approach": "", "verif wiki answer": "clock(0.7283)", "verif concept answer": "clock(0.6834)", "verif image answer": "clock(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310047.jpg"}, {"question": "what it company does he work for", "gt answer": "microsoft(1.00)<br/>best buy(0.60)<br/>geek squad(0.60)<br/>ibm(0.60)", "pred answer": "ibm", "question_id": 3006205, "best approach": "wiki, concept, image", "verif answer": "microsoft", "anno approach": "image, wiki", "verif wiki answer": "microsoft(0.6918)", "verif concept answer": "microsoft(0.6819)", "verif image answer": "microsoft(0.7178)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300620.jpg"}, {"question": "what is the metal structure holding up", "gt answer": "power line(1.00)", "pred answer": "bridge", "question_id": 5340265, "best approach": "", "verif answer": "wire", "anno approach": "", "verif wiki answer": "cable(0.6750)", "verif concept answer": "wire(0.7096)", "verif image answer": "wire(0.6142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534026.jpg"}, {"question": "where is this animal found", "gt answer": "alaska(1.00)<br/>arctic(0.60)<br/>north pole(0.60)", "pred answer": "arctic", "question_id": 594625, "best approach": "wiki, image", "verif answer": "arctic", "anno approach": "wiki", "verif wiki answer": "arctic(0.7076)", "verif concept answer": "artic(0.6718)", "verif image answer": "arctic(0.6904)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059462.jpg"}, {"question": "what event was captured by is this photograph", "gt answer": "protest(1.00)", "pred answer": "birthday", "question_id": 3521805, "best approach": "wiki", "verif answer": "selfie", "anno approach": "wiki", "verif wiki answer": "protest(0.6191)", "verif concept answer": "selfie(0.5800)", "verif image answer": "selfie(0.6358)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000352180.jpg"}, {"question": "are the waves good or bad", "gt answer": "bad(1.00)<br/>good(0.60)", "pred answer": "good", "question_id": 4684285, "best approach": "", "verif answer": "over ripe", "anno approach": "", "verif wiki answer": "over ripe(0.5714)", "verif concept answer": "over ripe(0.7261)", "verif image answer": "over ripe(0.5534)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000468428.jpg"}, {"question": "is this a popular or unpopular sport", "gt answer": "popular(1.00)<br/>tennis(0.60)", "pred answer": "tournament", "question_id": 1148805, "best approach": "", "verif answer": "tournament", "anno approach": "", "verif wiki answer": "tournament(0.7299)", "verif concept answer": "tournament(0.7176)", "verif image answer": "tournament(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114880.jpg"}, {"question": "what other animals have the same diet as this one", "gt answer": "herbivore(1.00)<br/>elephant(0.60)<br/>monkey(0.60)<br/>zebra(0.60)", "pred answer": "0", "question_id": 2395815, "best approach": "wiki, concept, image", "verif answer": "elephant", "anno approach": "concept, wiki", "verif wiki answer": "elephant(0.6727)", "verif concept answer": "elephant(0.6748)", "verif image answer": "zebra(0.6362)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000239581.jpg"}, {"question": "what breed of horses are these", "gt answer": "arabian(1.00)<br/>snow(0.60)<br/>stallion(0.60)<br/>mustang(0.60)", "pred answer": "clydesdale", "question_id": 778745, "best approach": "wiki, concept, image", "verif answer": "snow", "anno approach": "image, wiki", "verif wiki answer": "mustang(0.6365)", "verif concept answer": "mustang(0.6493)", "verif image answer": "snow(0.6906)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077874.jpg"}, {"question": "what kind of plant is this", "gt answer": "flower(1.00)<br/>lily(0.60)", "pred answer": "tulip", "question_id": 1195505, "best approach": "image", "verif answer": "lily", "anno approach": "image", "verif wiki answer": "rose(0.5760)", "verif concept answer": "rose(0.5686)", "verif image answer": "lily(0.6262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119550.jpg"}, {"question": "why kind of ship is depicted", "gt answer": "pirate(1.00)<br/>sailboat(0.60)<br/>0(0.60)", "pred answer": "bomber", "question_id": 3783055, "best approach": "wiki, concept, image", "verif answer": "pirate", "anno approach": "", "verif wiki answer": "pirate(0.7286)", "verif concept answer": "pirate(0.7265)", "verif image answer": "pirate(0.7262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378305.jpg"}, {"question": "what is covering the window", "gt answer": "blind(1.00)<br/>curtain(1.00)", "pred answer": "shade", "question_id": 501345, "best approach": "", "verif answer": "shade", "anno approach": "", "verif wiki answer": "shade(0.6994)", "verif concept answer": "shade(0.7145)", "verif image answer": "shade(0.6471)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050134.jpg"}, {"question": "what color tongue do these animals have", "gt answer": "black(1.00)<br/>pink(0.60)<br/>blue(0.60)<br/>red(0.60)", "pred answer": "black", "question_id": 1445, "best approach": "wiki, concept, image", "verif answer": "black", "anno approach": "image, wiki", "verif wiki answer": "black(0.6780)", "verif concept answer": "black(0.6738)", "verif image answer": "black(0.7077)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000144.jpg"}, {"question": "what harbor is this", "gt answer": "boat(1.00)", "pred answer": "canal", "question_id": 4843865, "best approach": "", "verif answer": "yacht", "anno approach": "", "verif wiki answer": "yacht(0.6808)", "verif concept answer": "yacht(0.6965)", "verif image answer": "ship(0.6385)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484386.jpg"}, {"question": "what railroad are they traveling", "gt answer": "subway(1.00)<br/>bristol(1.00)<br/>train(0.60)", "pred answer": "coal", "question_id": 2981545, "best approach": "", "verif answer": "mechanical", "anno approach": "", "verif wiki answer": "mechanical(0.6566)", "verif concept answer": "mechanical(0.6491)", "verif image answer": "mechanical(0.6750)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000298154.jpg"}, {"question": "what is the name of a famous children 's book with a main character of the same species as the animal in the picture", "gt answer": "dumbo(1.00)", "pred answer": "dumbo", "question_id": 4574345, "best approach": "wiki, concept, image", "verif answer": "dumbo", "anno approach": "wiki", "verif wiki answer": "dumbo(0.7305)", "verif concept answer": "dumbo(0.7296)", "verif image answer": "dumbo(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457434.jpg"}, {"question": "what topping is on the food", "gt answer": "rhubarb(1.00)<br/>fruit(0.60)<br/>strawberry(0.60)<br/>pepper(0.60)", "pred answer": "strawberry", "question_id": 5162055, "best approach": "image", "verif answer": "rhubarb", "anno approach": "image", "verif wiki answer": "strawberry(0.6255)", "verif concept answer": "strawberry(0.6222)", "verif image answer": "rhubarb(0.6506)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516205.jpg"}, {"question": "what type of body of water is this", "gt answer": "river(1.00)<br/>lake(1.00)", "pred answer": "lake", "question_id": 1095, "best approach": "concept, image", "verif answer": "lake", "anno approach": "image", "verif wiki answer": "canal(0.7166)", "verif concept answer": "lake(0.6762)", "verif image answer": "lake(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000109.jpg"}, {"question": "what team is pitching", "gt answer": "red sox(1.00)<br/>oriole(0.60)<br/>yankees(0.60)", "pred answer": "red sox", "question_id": 4410625, "best approach": "concept, image", "verif answer": "red sox", "anno approach": "image", "verif wiki answer": "yankees(0.6425)", "verif concept answer": "red sox(0.6007)", "verif image answer": "red sox(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441062.jpg"}, {"question": "what kind of birds are this", "gt answer": "sparrow(1.00)<br/>pigeon(0.60)<br/>brown(0.60)", "pred answer": "geese", "question_id": 55645, "best approach": "wiki, concept, image", "verif answer": "pigeon", "anno approach": "concept, wiki", "verif wiki answer": "pigeon(0.6900)", "verif concept answer": "pigeon(0.7173)", "verif image answer": "brown(0.6495)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005564.jpg"}, {"question": "what is the name of the mascot pictured", "gt answer": "phillie phanatic(1.00)", "pred answer": "ted", "question_id": 3651315, "best approach": "wiki, concept, image", "verif answer": "phillie phanatic", "anno approach": "wiki", "verif wiki answer": "phillie phanatic(0.6933)", "verif concept answer": "phillie phanatic(0.6238)", "verif image answer": "phillie phanatic(0.6279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365131.jpg"}, {"question": "is this singles or doubles tennis", "gt answer": "single(1.00)", "pred answer": "double", "question_id": 3006845, "best approach": "", "verif answer": "woman", "anno approach": "", "verif wiki answer": "woman(0.7110)", "verif concept answer": "woman(0.6295)", "verif image answer": "woman(0.6246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300684.jpg"}, {"question": "what brand are those shoes", "gt answer": "puma(1.00)<br/>nike(0.60)<br/>van(0.60)", "pred answer": "adidas", "question_id": 4515155, "best approach": "image", "verif answer": "levis", "anno approach": "image", "verif wiki answer": "levis(0.7307)", "verif concept answer": "levis(0.7310)", "verif image answer": "puma(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451515.jpg"}, {"question": "these umbrellas are associated with what sort of eating venue", "gt answer": "cafe(1.00)<br/>hotdog(0.60)<br/>outside(0.60)", "pred answer": "table", "question_id": 5204865, "best approach": "", "verif answer": "food truck", "anno approach": "", "verif wiki answer": "food truck(0.7168)", "verif concept answer": "food truck(0.7212)", "verif image answer": "food truck(0.6955)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520486.jpg"}, {"question": "what do you use these items for", "gt answer": "brush teeth(1.00)", "pred answer": "teeth", "question_id": 5041845, "best approach": "", "verif answer": "brush", "anno approach": "", "verif wiki answer": "brush(0.5936)", "verif concept answer": "brush(0.6393)", "verif image answer": "brush(0.6251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000504184.jpg"}, {"question": "what year was the sport in this picture invented", "gt answer": "1950(1.00)<br/>skateboard(0.60)", "pred answer": "1950", "question_id": 1840035, "best approach": "", "verif answer": "70s", "anno approach": "", "verif wiki answer": "70s(0.7275)", "verif concept answer": "70s(0.6949)", "verif image answer": "1800(0.5599)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184003.jpg"}, {"question": "what shapes are on the toy duck", "gt answer": "square(1.00)", "pred answer": "heart", "question_id": 805665, "best approach": "wiki, concept", "verif answer": "triangle", "anno approach": "wiki", "verif wiki answer": "square(0.7005)", "verif concept answer": "square(0.7195)", "verif image answer": "triangle(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080566.jpg"}, {"question": "what kind of transportation is this man using", "gt answer": "skateboard(1.00)", "pred answer": "skateboard", "question_id": 397545, "best approach": "wiki, concept, image", "verif answer": "skateboard", "anno approach": "wiki", "verif wiki answer": "skateboard(0.6558)", "verif concept answer": "skateboard(0.6822)", "verif image answer": "skateboard(0.6608)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039754.jpg"}, {"question": "what are these men about to do", "gt answer": "pray(1.00)<br/>eat(1.00)", "pred answer": "eat", "question_id": 3201375, "best approach": "", "verif answer": "buy food", "anno approach": "", "verif wiki answer": "buy food(0.7251)", "verif concept answer": "buy food(0.7226)", "verif image answer": "buy food(0.7191)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320137.jpg"}, {"question": "how do we know this fruit belongs to someone", "gt answer": "in bowl(1.00)", "pred answer": "tree", "question_id": 9025, "best approach": "image", "verif answer": "apple", "anno approach": "image", "verif wiki answer": "apple(0.5719)", "verif concept answer": "apple(0.5174)", "verif image answer": "in bowl(0.5340)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000902.jpg"}, {"question": "who sells the red pillow cases seen behind these two men", "gt answer": "target(1.00)<br/>internet(0.60)", "pred answer": "steve job", "question_id": 2798835, "best approach": "", "verif answer": "7 eleven", "anno approach": "", "verif wiki answer": "7 eleven(0.7155)", "verif concept answer": "7 eleven(0.6814)", "verif image answer": "7 eleven(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000279883.jpg"}, {"question": "name the material type of sign board shown in this picture", "gt answer": "aluminum(1.00)<br/>metal(0.60)<br/>wood(0.60)", "pred answer": "wood", "question_id": 4861635, "best approach": "wiki, concept, image", "verif answer": "wood", "anno approach": "wiki", "verif wiki answer": "wood(0.5775)", "verif concept answer": "wood(0.6036)", "verif image answer": "wood(0.5987)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000486163.jpg"}, {"question": "name the varieties of banana shown in this picture", "gt answer": "plantain(1.00)<br/>banana(0.60)<br/>green(0.60)", "pred answer": "plantain", "question_id": 526285, "best approach": "concept", "verif answer": "musa", "anno approach": "concept", "verif wiki answer": "musa(0.7207)", "verif concept answer": "plantain(0.7197)", "verif image answer": "musa(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052628.jpg"}, {"question": "is this train yard attraction suited more for children or adults", "gt answer": "children(1.00)<br/>adult(1.00)", "pred answer": "student", "question_id": 3112205, "best approach": "wiki, concept, image", "verif answer": "adult", "anno approach": "image, wiki", "verif wiki answer": "adult(0.6586)", "verif concept answer": "adult(0.6374)", "verif image answer": "adult(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311220.jpg"}, {"question": "what are the three colors on a stop light", "gt answer": "red yellow green(1.00)<br/>red green yellow(0.60)", "pred answer": "green", "question_id": 3515215, "best approach": "", "verif answer": "green", "anno approach": "", "verif wiki answer": "green(0.6569)", "verif concept answer": "green(0.6803)", "verif image answer": "green(0.5571)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351521.jpg"}, {"question": "what are they cooking", "gt answer": "lemon(1.00)", "pred answer": "pancake", "question_id": 2599515, "best approach": "", "verif answer": "tea", "anno approach": "", "verif wiki answer": "tea(0.7071)", "verif concept answer": "tea(0.7000)", "verif image answer": "lemonade(0.6991)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259951.jpg"}, {"question": "what explanation could you have for the planes", "gt answer": "air show(1.00)<br/>airshow(0.60)", "pred answer": "air", "question_id": 4339685, "best approach": "wiki, concept", "verif answer": "aerodynamic", "anno approach": "wiki", "verif wiki answer": "air show(0.6394)", "verif concept answer": "air show(0.6393)", "verif image answer": "aerodynamic(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433968.jpg"}, {"question": "what common drink is made from the yellow fruit in this picture", "gt answer": "lemonade(1.00)<br/>orange(0.60)", "pred answer": "lemonade", "question_id": 1735955, "best approach": "wiki, concept, image", "verif answer": "lemonade", "anno approach": "wiki", "verif wiki answer": "lemonade(0.6564)", "verif concept answer": "lemonade(0.6650)", "verif image answer": "lemonade(0.6719)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000173595.jpg"}, {"question": "was the technology this person is using invented in the past decade or earlier", "gt answer": "earlier(1.00)", "pred answer": "manual", "question_id": 3578375, "best approach": "", "verif answer": "older", "anno approach": "", "verif wiki answer": "older(0.5382)", "verif concept answer": "older(0.5044)", "verif image answer": "classic(0.5111)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357837.jpg"}, {"question": "what are the brown objects over the windows", "gt answer": "blind(1.00)<br/>shade(1.00)", "pred answer": "blind", "question_id": 818105, "best approach": "wiki", "verif answer": "rain", "anno approach": "wiki", "verif wiki answer": "shade(0.5971)", "verif concept answer": "rain(0.6615)", "verif image answer": "sun protection(0.6318)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081810.jpg"}, {"question": "where is this", "gt answer": "ocean(1.00)<br/>beach(1.00)", "pred answer": "beach", "question_id": 505115, "best approach": "wiki, concept, image", "verif answer": "beach", "anno approach": "concept, wiki", "verif wiki answer": "beach(0.6991)", "verif concept answer": "beach(0.6688)", "verif image answer": "beach(0.6225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050511.jpg"}, {"question": "what teams do these players play for", "gt answer": "dodger(1.00)<br/>baseball(0.60)", "pred answer": "yankees", "question_id": 1635535, "best approach": "wiki, concept", "verif answer": "baseball", "anno approach": "wiki", "verif wiki answer": "dodger(0.6786)", "verif concept answer": "dodger(0.6908)", "verif image answer": "baseball(0.6924)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163553.jpg"}, {"question": "what type of diet does this animal have", "gt answer": "vegetarian(1.00)<br/>herbivorous(0.60)", "pred answer": "african and grass", "question_id": 3720225, "best approach": "", "verif answer": "herbivore", "anno approach": "", "verif wiki answer": "herbivore(0.6942)", "verif concept answer": "herbivore(0.6890)", "verif image answer": "herbivore(0.6129)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372022.jpg"}, {"question": "what species of bear is this", "gt answer": "black bear(1.00)<br/>black(0.60)", "pred answer": "brown bear", "question_id": 4943985, "best approach": "image", "verif answer": "black bear", "anno approach": "image", "verif wiki answer": "grizzly(0.6940)", "verif concept answer": "grizzly(0.6838)", "verif image answer": "black bear(0.7142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494398.jpg"}, {"question": "how many people can this bus hold", "gt answer": "25(1.00)<br/>40(0.60)<br/>60(0.60)", "pred answer": "60", "question_id": 1527255, "best approach": "wiki, concept, image", "verif answer": "60", "anno approach": "wiki", "verif wiki answer": "60(0.6712)", "verif concept answer": "60(0.6533)", "verif image answer": "60(0.6678)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000152725.jpg"}, {"question": "what disney movie set in this landscape features a musical number with these animals", "gt answer": "lion king(1.00)", "pred answer": "dumbo", "question_id": 697055, "best approach": "", "verif answer": "dumbo", "anno approach": "", "verif wiki answer": "dumbo(0.7311)", "verif concept answer": "dumbo(0.7310)", "verif image answer": "dumbo(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069705.jpg"}, {"question": "what type of sport is this", "gt answer": "surf(1.00)", "pred answer": "surf", "question_id": 3087445, "best approach": "concept", "verif answer": "surf", "anno approach": "concept", "verif wiki answer": "ride wave(0.7287)", "verif concept answer": "surf(0.7303)", "verif image answer": "ride wave(0.7205)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308744.jpg"}, {"question": "what would be strapped to this animal to transport humans", "gt answer": "saddle(1.00)<br/>carriage(0.60)", "pred answer": "saddle", "question_id": 5334245, "best approach": "concept, image", "verif answer": "saddle", "anno approach": "image", "verif wiki answer": "cart(0.6606)", "verif concept answer": "saddle(0.6623)", "verif image answer": "saddle(0.7017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000533424.jpg"}, {"question": "what sorts of bulls is this advertisement referring to", "gt answer": "sport team(1.00)<br/>chicago(0.60)", "pred answer": "cow", "question_id": 2978725, "best approach": "", "verif answer": "italian", "anno approach": "", "verif wiki answer": "italian(0.6589)", "verif concept answer": "italian(0.7112)", "verif image answer": "germany(0.7007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297872.jpg"}, {"question": "is she right or left handed", "gt answer": "left(1.00)<br/>right(1.00)", "pred answer": "right", "question_id": 4703215, "best approach": "wiki, concept, image", "verif answer": "left", "anno approach": "wiki", "verif wiki answer": "left(0.7260)", "verif concept answer": "left(0.7286)", "verif image answer": "left(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470321.jpg"}, {"question": "what animal kingdom does the animal belong to", "gt answer": "mammal(1.00)<br/>bear(1.00)", "pred answer": "brown", "question_id": 1238915, "best approach": "", "verif answer": "hibernation", "anno approach": "", "verif wiki answer": "hibernation(0.6962)", "verif concept answer": "hibernation(0.6840)", "verif image answer": "hibernation(0.7093)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123891.jpg"}, {"question": "the fabric on that couch was very popular in the eighties what was it called", "gt answer": "floral(1.00)<br/>polyester(0.60)", "pred answer": "wool", "question_id": 3182455, "best approach": "", "verif answer": "retro", "anno approach": "", "verif wiki answer": "retro(0.7004)", "verif concept answer": "retro(0.7180)", "verif image answer": "flower(0.6338)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318245.jpg"}, {"question": "what brand is the truck", "gt answer": "gmc(1.00)", "pred answer": "chevrolet", "question_id": 3846805, "best approach": "", "verif answer": "chevrolet", "anno approach": "", "verif wiki answer": "vw(0.6795)", "verif concept answer": "vw(0.6674)", "verif image answer": "chevrolet(0.7016)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384680.jpg"}, {"question": "what breed of bird is pictured", "gt answer": "cardinal(1.00)", "pred answer": "peacock", "question_id": 3741465, "best approach": "wiki, concept", "verif answer": "cardinal", "anno approach": "concept, wiki", "verif wiki answer": "cardinal(0.6370)", "verif concept answer": "cardinal(0.7264)", "verif image answer": "red sox(0.6276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374146.jpg"}, {"question": "what is the time displayed", "gt answer": "3:00(1.00)<br/>noon(0.60)", "pred answer": "roman numeral", "question_id": 1113185, "best approach": "wiki, concept, image", "verif answer": "3:00", "anno approach": "wiki", "verif wiki answer": "3:00(0.6767)", "verif concept answer": "3:00(0.6383)", "verif image answer": "3:00(0.6099)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111318.jpg"}, {"question": "where would you find this animal on a farm", "gt answer": "stable(1.00)<br/>barn(0.60)", "pred answer": "stable", "question_id": 2309055, "best approach": "wiki, concept, image", "verif answer": "stable", "anno approach": "wiki", "verif wiki answer": "stable(0.6913)", "verif concept answer": "stable(0.7185)", "verif image answer": "stable(0.7202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000230905.jpg"}, {"question": "why does this animal have spots", "gt answer": "camouflage(1.00)", "pred answer": "neck", "question_id": 1482515, "best approach": "", "verif answer": "evolution", "anno approach": "", "verif wiki answer": "evolution(0.7259)", "verif concept answer": "evolution(0.7296)", "verif image answer": "evolution(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148251.jpg"}, {"question": "what animal likes to eat these fruits in cartoons", "gt answer": "monkey(1.00)<br/>bee(0.60)", "pred answer": "monkey", "question_id": 2349495, "best approach": "wiki, concept, image", "verif answer": "monkey", "anno approach": "concept, wiki", "verif wiki answer": "monkey(0.7309)", "verif concept answer": "monkey(0.7299)", "verif image answer": "monkey(0.5570)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000234949.jpg"}, {"question": "what type of dog is this", "gt answer": "pug(1.00)", "pred answer": "pug", "question_id": 1871565, "best approach": "wiki, concept, image", "verif answer": "pug", "anno approach": "image, wiki", "verif wiki answer": "pug(0.6920)", "verif concept answer": "pug(0.6994)", "verif image answer": "pug(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187156.jpg"}, {"question": "what breed of horse is this", "gt answer": "stallion(1.00)<br/>pinto(0.60)<br/>mustang(0.60)", "pred answer": "clydesdale", "question_id": 2026725, "best approach": "", "verif answer": "calico", "anno approach": "", "verif wiki answer": "calico(0.7236)", "verif concept answer": "calico(0.7218)", "verif image answer": "calico(0.6913)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202672.jpg"}, {"question": "what is the man feeding the bird", "gt answer": "seed(1.00)<br/>peanut(0.60)<br/>bread(0.60)", "pred answer": "fish", "question_id": 778055, "best approach": "wiki, concept, image", "verif answer": "bread", "anno approach": "wiki", "verif wiki answer": "bread(0.6281)", "verif concept answer": "bread(0.5991)", "verif image answer": "peanut(0.5913)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077805.jpg"}, {"question": "what is the battery life on this nokia phone", "gt answer": "10 hours(1.00)<br/>2 days(0.60)<br/>1 month(0.60)", "pred answer": "8 hours", "question_id": 2972795, "best approach": "", "verif answer": "5 days", "anno approach": "", "verif wiki answer": "5 days(0.6835)", "verif concept answer": "5 days(0.6597)", "verif image answer": "5 days(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297279.jpg"}, {"question": "what branch of military flies these planes", "gt answer": "airforce(1.00)<br/>air force(1.00)<br/>navy(0.60)", "pred answer": "air force", "question_id": 1185145, "best approach": "wiki, image", "verif answer": "airforce", "anno approach": "wiki", "verif wiki answer": "airforce(0.6611)", "verif concept answer": "navy(0.6456)", "verif image answer": "airforce(0.6604)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118514.jpg"}, {"question": "when was this animal breed made", "gt answer": "1930(1.00)<br/>1500(0.60)", "pred answer": "1948", "question_id": 4709705, "best approach": "", "verif answer": "1945", "anno approach": "", "verif wiki answer": "1945(0.7146)", "verif concept answer": "1940s(0.6752)", "verif image answer": "1945(0.6742)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470970.jpg"}, {"question": "is this a street or a walkway", "gt answer": "walkway(1.00)<br/>street(0.60)", "pred answer": "city", "question_id": 2032525, "best approach": "image", "verif answer": "jet bridge", "anno approach": "image", "verif wiki answer": "jet bridge(0.7246)", "verif concept answer": "jet bridge(0.7174)", "verif image answer": "street(0.6862)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203252.jpg"}, {"question": "what show is this", "gt answer": "auction(1.00)<br/>fair(0.60)", "pred answer": "rodeo", "question_id": 4527826, "best approach": "", "verif answer": "park and rec", "anno approach": "", "verif wiki answer": "park and rec(0.7077)", "verif concept answer": "park and rec(0.6736)", "verif image answer": "park and rec(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000452782.jpg"}, {"question": "what would be the minimum temperature that people would need in order to do this activity", "gt answer": "0 celcius(1.00)", "pred answer": "350", "question_id": 3211815, "best approach": "", "verif answer": "500", "anno approach": "", "verif wiki answer": "500(0.7115)", "verif concept answer": "500(0.6777)", "verif image answer": "500(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321181.jpg"}, {"question": "what kind of outfit does the man have on", "gt answer": "suit(1.00)", "pred answer": "suit", "question_id": 2553295, "best approach": "", "verif answer": "tuxedo", "anno approach": "", "verif wiki answer": "tuxedo(0.7122)", "verif concept answer": "tuxedo(0.6733)", "verif image answer": "tuxedo(0.6059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255329.jpg"}, {"question": "the three chairs are made from what material", "gt answer": "bamboo(1.00)<br/>wood(0.60)<br/>wicker(0.60)", "pred answer": "wood", "question_id": 3631905, "best approach": "wiki, concept, image", "verif answer": "wood", "anno approach": "wiki", "verif wiki answer": "wood(0.6686)", "verif concept answer": "wood(0.6725)", "verif image answer": "wood(0.6448)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363190.jpg"}, {"question": "what is the man holding", "gt answer": "bat(1.00)<br/>baseball bat(0.60)", "pred answer": "bat", "question_id": 4290395, "best approach": "wiki, concept, image", "verif answer": "baseball bat", "anno approach": "wiki", "verif wiki answer": "baseball bat(0.7272)", "verif concept answer": "baseball bat(0.7288)", "verif image answer": "baseball bat(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429039.jpg"}, {"question": "what is the white building made of", "gt answer": "plaster(1.00)<br/>wood(0.60)<br/>cement(0.60)<br/>brick(0.60)", "pred answer": "brick", "question_id": 811355, "best approach": "concept", "verif answer": "brick", "anno approach": "concept", "verif wiki answer": "brick(0.6867)", "verif concept answer": "plaster(0.6864)", "verif image answer": "brick(0.6817)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081135.jpg"}, {"question": "what is the name of the famous horse racing track", "gt answer": "kentucky derby(1.00)", "pred answer": "equestrian", "question_id": 1879765, "best approach": "", "verif answer": "horse race", "anno approach": "", "verif wiki answer": "horse race(0.6802)", "verif concept answer": "horse race(0.6777)", "verif image answer": "horse race(0.7137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187976.jpg"}, {"question": "what is a person called who operates this vehicle", "gt answer": "pilot(1.00)", "pred answer": "pilot", "question_id": 1455515, "best approach": "wiki, concept, image", "verif answer": "pilot", "anno approach": "wiki", "verif wiki answer": "pilot(0.7246)", "verif concept answer": "pilot(0.6960)", "verif image answer": "pilot(0.6815)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145551.jpg"}, {"question": "what object is creating the source of light in this picture", "gt answer": "lamp(1.00)<br/>window(0.60)", "pred answer": "lamp", "question_id": 4155715, "best approach": "concept", "verif answer": "window", "anno approach": "concept", "verif wiki answer": "window(0.7253)", "verif concept answer": "lamp(0.6200)", "verif image answer": "window(0.7084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415571.jpg"}, {"question": "what material is the object made of that the toast is laying on", "gt answer": "paper(1.00)<br/>ceramic(1.00)<br/>china(0.60)", "pred answer": "wood", "question_id": 4897355, "best approach": "wiki, concept, image", "verif answer": "ceramic", "anno approach": "wiki", "verif wiki answer": "ceramic(0.7264)", "verif concept answer": "ceramic(0.6908)", "verif image answer": "ceramic(0.6637)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489735.jpg"}, {"question": "what team does he play for", "gt answer": "0(1.00)<br/>usa(0.60)<br/>united state(0.60)", "pred answer": "met", "question_id": 2038915, "best approach": "", "verif answer": "america", "anno approach": "", "verif wiki answer": "america(0.6696)", "verif concept answer": "america(0.6751)", "verif image answer": "met(0.6290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203891.jpg"}, {"question": "what landmark is in the background", "gt answer": "big ben(1.00)<br/>clock tower(0.60)", "pred answer": "clock tower", "question_id": 2167425, "best approach": "wiki", "verif answer": "roman numeral", "anno approach": "wiki", "verif wiki answer": "clock tower(0.7307)", "verif concept answer": "roman numeral(0.7308)", "verif image answer": "roman numeral(0.6881)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216742.jpg"}, {"question": "what is the purpose for this", "gt answer": "transport(1.00)<br/>transport good(0.60)<br/>farm(0.60)", "pred answer": "ride", "question_id": 4200855, "best approach": "", "verif answer": "lumber", "anno approach": "", "verif wiki answer": "lumber(0.6873)", "verif concept answer": "lumber(0.6873)", "verif image answer": "lumber(0.6869)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420085.jpg"}, {"question": "why isn't this likely to be a married couple", "gt answer": "young(1.00)<br/>children(0.60)", "pred answer": "swim", "question_id": 3150125, "best approach": "", "verif answer": "y", "anno approach": "", "verif wiki answer": "y(0.6854)", "verif concept answer": "y(0.6784)", "verif image answer": "y(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315012.jpg"}, {"question": "by what mode of transportation are the figures going to descend the mountain", "gt answer": "snowboard(1.00)<br/>lift(0.60)", "pred answer": "ski", "question_id": 4694315, "best approach": "concept, image", "verif answer": "skiis", "anno approach": "", "verif wiki answer": "skiis(0.7164)", "verif concept answer": "snowboard(0.6886)", "verif image answer": "snowboard(0.6797)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469431.jpg"}, {"question": "what is the name of the player in the yellow jersey", "gt answer": "goalie(1.00)", "pred answer": "goalie", "question_id": 479815, "best approach": "image", "verif answer": "goalie", "anno approach": "image", "verif wiki answer": "paul pogba(0.6725)", "verif concept answer": "paul pogba(0.6745)", "verif image answer": "goalie(0.7202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047981.jpg"}, {"question": "what is the addictive ingredient in this cigarette", "gt answer": "nicotine(1.00)", "pred answer": "paper", "question_id": 5407905, "best approach": "wiki, concept, image", "verif answer": "nicotine", "anno approach": "image, wiki", "verif wiki answer": "nicotine(0.7090)", "verif concept answer": "nicotine(0.6865)", "verif image answer": "nicotine(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540790.jpg"}, {"question": "what team is this", "gt answer": "cub(1.00)<br/>yankees(0.60)", "pred answer": "minnesota twin", "question_id": 1387415, "best approach": "", "verif answer": "dodger", "anno approach": "", "verif wiki answer": "dodger(0.6926)", "verif concept answer": "dodger(0.6853)", "verif image answer": "dodger(0.7114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138741.jpg"}, {"question": "how would you cook this meat", "gt answer": "in oven(1.00)<br/>roast(0.60)", "pred answer": "grill", "question_id": 4707225, "best approach": "wiki, concept", "verif answer": "in oven", "anno approach": "wiki", "verif wiki answer": "in oven(0.6753)", "verif concept answer": "in oven(0.6660)", "verif image answer": "grill(0.6595)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470722.jpg"}, {"question": "what appliance can be find in the room pictured", "gt answer": "sink(1.00)<br/>shower(0.60)<br/>toilet(0.60)", "pred answer": "wash machine", "question_id": 331825, "best approach": "image", "verif answer": "shower", "anno approach": "image", "verif wiki answer": "bathroom(0.7307)", "verif concept answer": "bathroom(0.7278)", "verif image answer": "shower(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033182.jpg"}, {"question": "what is the type of this called when it 's hired privately to take a group from place to place", "gt answer": "charter(1.00)", "pred answer": "friend", "question_id": 4841585, "best approach": "", "verif answer": "come", "anno approach": "", "verif wiki answer": "come(0.7102)", "verif concept answer": "come(0.7104)", "verif image answer": "come(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484158.jpg"}, {"question": "what is on the cup the man is holding", "gt answer": "strawberry(1.00)<br/>flower(0.60)", "pred answer": "coffee", "question_id": 3857055, "best approach": "concept", "verif answer": "peach", "anno approach": "concept", "verif wiki answer": "flower(0.6352)", "verif concept answer": "strawberry(0.5450)", "verif image answer": "peach(0.6804)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385705.jpg"}, {"question": "how do you tie a tie like this", "gt answer": "bow(1.00)", "pred answer": "clip", "question_id": 4993695, "best approach": "wiki, concept", "verif answer": "bow", "anno approach": "concept, wiki", "verif wiki answer": "bow(0.5488)", "verif concept answer": "bow(0.6199)", "verif image answer": "clip(0.5729)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499369.jpg"}, {"question": "which appliance works the best for smoothies", "gt answer": "blender(1.00)", "pred answer": "blender", "question_id": 2810355, "best approach": "wiki, concept, image", "verif answer": "blender", "anno approach": "wiki", "verif wiki answer": "blender(0.7030)", "verif concept answer": "blender(0.7023)", "verif image answer": "blender(0.6911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281035.jpg"}, {"question": "what room would he do this in", "gt answer": "bathroom(1.00)", "pred answer": "bathroom", "question_id": 4808205, "best approach": "wiki, image", "verif answer": "bathroom", "anno approach": "image, wiki", "verif wiki answer": "bathroom(0.6839)", "verif concept answer": "restroom(0.7280)", "verif image answer": "bathroom(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480820.jpg"}, {"question": "can you guess the place name shown in this picture where these people are standing", "gt answer": "intersection(1.00)<br/>new york city(0.60)<br/>crosswalk(0.60)<br/>new york(0.60)", "pred answer": "london", "question_id": 4340695, "best approach": "image", "verif answer": "city", "anno approach": "image", "verif wiki answer": "city(0.6577)", "verif concept answer": "city(0.6531)", "verif image answer": "new york city(0.6515)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434069.jpg"}, {"question": "what type of garment should the people in this picture be wearing", "gt answer": "swim trunk(1.00)<br/>wetsuit(0.60)", "pred answer": "wet suit", "question_id": 3072595, "best approach": "", "verif answer": "wet suit", "anno approach": "", "verif wiki answer": "wet suit(0.7108)", "verif concept answer": "wet suit(0.7187)", "verif image answer": "wet suit(0.7020)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307259.jpg"}, {"question": "what are the cat 's doing", "gt answer": "play(1.00)", "pred answer": "play", "question_id": 4305635, "best approach": "wiki", "verif answer": "fight", "anno approach": "wiki", "verif wiki answer": "play(0.6856)", "verif concept answer": "fight(0.6888)", "verif image answer": "fight(0.7051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430563.jpg"}, {"question": "what connects to the black item", "gt answer": "hose(1.00)<br/>pole(0.60)<br/>pipe(0.60)", "pred answer": "hose", "question_id": 2249595, "best approach": "wiki, concept, image", "verif answer": "hose", "anno approach": "wiki", "verif wiki answer": "hose(0.7143)", "verif concept answer": "hose(0.7102)", "verif image answer": "hose(0.6981)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224959.jpg"}, {"question": "what food does this animal eat", "gt answer": "seed(1.00)<br/>mice(0.60)", "pred answer": "seed", "question_id": 1381375, "best approach": "", "verif answer": "fish", "anno approach": "", "verif wiki answer": "fish(0.6719)", "verif concept answer": "fish(0.6721)", "verif image answer": "fish(0.6667)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138137.jpg"}, {"question": "what species of tree is seen in the foreground of this picture", "gt answer": "maple(1.00)<br/>pine(0.60)<br/>oak(0.60)", "pred answer": "oak", "question_id": 2025455, "best approach": "wiki, concept, image", "verif answer": "maple", "anno approach": "wiki", "verif wiki answer": "maple(0.7147)", "verif concept answer": "maple(0.7149)", "verif image answer": "maple(0.7178)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202545.jpg"}, {"question": "what sort of noodles are these", "gt answer": "lo mein(1.00)<br/>egg(0.60)", "pred answer": "pasta", "question_id": 329635, "best approach": "", "verif answer": "asian", "anno approach": "", "verif wiki answer": "asian(0.6375)", "verif concept answer": "asian(0.6662)", "verif image answer": "asian(0.6560)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032963.jpg"}, {"question": "what is the building in the background for", "gt answer": "church(1.00)<br/>house(0.60)", "pred answer": "church", "question_id": 4693305, "best approach": "wiki, concept, image", "verif answer": "church", "anno approach": "wiki", "verif wiki answer": "church(0.7252)", "verif concept answer": "church(0.6972)", "verif image answer": "church(0.6985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469330.jpg"}, {"question": "what part of the body is this used on", "gt answer": "teeth(1.00)", "pred answer": "arm", "question_id": 1210015, "best approach": "", "verif answer": "brush teeth", "anno approach": "", "verif wiki answer": "brain(0.6698)", "verif concept answer": "brain(0.6616)", "verif image answer": "brush teeth(0.6950)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000121001.jpg"}, {"question": "what looks wrong with the boys attire", "gt answer": "big shoe(1.00)<br/>too small(0.60)<br/>formal(0.60)", "pred answer": "short", "question_id": 4556515, "best approach": "wiki, concept, image", "verif answer": "formal", "anno approach": "concept, wiki", "verif wiki answer": "formal(0.5848)", "verif concept answer": "formal(0.6240)", "verif image answer": "formal(0.5688)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455651.jpg"}, {"question": "what kind of food is this", "gt answer": "lamb(1.00)<br/>pork(0.60)<br/>meat(0.60)", "pred answer": "chicken", "question_id": 5787655, "best approach": "wiki, concept", "verif answer": "pork", "anno approach": "wiki", "verif wiki answer": "pork(0.6676)", "verif concept answer": "pork(0.6725)", "verif image answer": "steak(0.6279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578765.jpg"}, {"question": "why does this man have a number on his shirt", "gt answer": "uniform(1.00)<br/>jersey(0.60)<br/>baseball player(0.60)", "pred answer": "identification", "question_id": 2932335, "best approach": "wiki, concept, image", "verif answer": "jersey", "anno approach": "concept, wiki", "verif wiki answer": "jersey(0.6202)", "verif concept answer": "jersey(0.6597)", "verif image answer": "baseball player(0.6452)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293233.jpg"}, {"question": "what kind of animal is being shown", "gt answer": "monkey(1.00)", "pred answer": "monkey", "question_id": 1839905, "best approach": "concept", "verif answer": "bird", "anno approach": "concept", "verif wiki answer": "bird(0.6737)", "verif concept answer": "monkey(0.5807)", "verif image answer": "dove(0.5711)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183990.jpg"}, {"question": "what does the graffiti on the sign say", "gt answer": "listen(1.00)", "pred answer": "no u turn", "question_id": 2009465, "best approach": "", "verif answer": "grandview dr", "anno approach": "", "verif wiki answer": "grandview dr(0.6789)", "verif concept answer": "grandview dr(0.6661)", "verif image answer": "grandview dr(0.7256)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200946.jpg"}, {"question": "what is this case used for", "gt answer": "travel(1.00)<br/>cloth(0.60)", "pred answer": "travel", "question_id": 1722295, "best approach": "wiki, concept", "verif answer": "cloth", "anno approach": "wiki", "verif wiki answer": "travel(0.6840)", "verif concept answer": "travel(0.6784)", "verif image answer": "cloth(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000172229.jpg"}, {"question": "what famous american photographer is best known for taking photos in this color scheme", "gt answer": "ansel adams(1.00)<br/>black and white(0.60)", "pred answer": "train conductor", "question_id": 3696035, "best approach": "", "verif answer": "sepia", "anno approach": "", "verif wiki answer": "sepia(0.7152)", "verif concept answer": "sepia(0.7166)", "verif image answer": "sepia(0.7184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369603.jpg"}, {"question": "how many people are on board if it 's full", "gt answer": "600(1.00)<br/>150(0.60)<br/>50(0.60)<br/>200(0.60)", "pred answer": "300", "question_id": 365335, "best approach": "wiki, concept", "verif answer": "50", "anno approach": "wiki", "verif wiki answer": "50(0.6618)", "verif concept answer": "50(0.6220)", "verif image answer": "100(0.6547)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036533.jpg"}, {"question": "what type of metal is this aircraft plated with", "gt answer": "aluminum(1.00)<br/>steel(0.60)<br/>metal(0.60)", "pred answer": "aluminum", "question_id": 2472095, "best approach": "wiki, concept, image", "verif answer": "aluminum", "anno approach": "wiki", "verif wiki answer": "aluminum(0.6895)", "verif concept answer": "aluminum(0.6713)", "verif image answer": "aluminum(0.6640)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247209.jpg"}, {"question": "what type of monitor is that", "gt answer": "computer(1.00)<br/>lcd(0.60)", "pred answer": "ibm", "question_id": 2311645, "best approach": "wiki", "verif answer": "lcd", "anno approach": "wiki", "verif wiki answer": "computer(0.6676)", "verif concept answer": "lcd(0.7221)", "verif image answer": "lcd(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231164.jpg"}, {"question": "the fastest specimen of this animal set the world record at the belmont stakes what was his name", "gt answer": "secretariat(1.00)", "pred answer": "mustang", "question_id": 418955, "best approach": "", "verif answer": "bareback", "anno approach": "", "verif wiki answer": "bareback(0.6390)", "verif concept answer": "bareback(0.6463)", "verif image answer": "bareback(0.6269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041895.jpg"}, {"question": "which digit shown here also sounds like a pastel color", "gt answer": "pinkie(1.00)", "pred answer": "c", "question_id": 4050135, "best approach": "", "verif answer": "c", "anno approach": "", "verif wiki answer": "c(0.6901)", "verif concept answer": "c(0.6851)", "verif image answer": "c(0.6544)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405013.jpg"}, {"question": "which is usually taller a human or the object in the center of the photo", "gt answer": "object(1.00)<br/>pole(0.60)", "pred answer": "man", "question_id": 3120546, "best approach": "concept", "verif answer": "anchor", "anno approach": "concept", "verif wiki answer": "anchor(0.7122)", "verif concept answer": "object(0.6852)", "verif image answer": "anchor(0.7045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312054.jpg"}, {"question": "what are the ingredients for this type of sausage", "gt answer": "beef(1.00)<br/>pork(0.60)<br/>meat(1.00)", "pred answer": "vegetable", "question_id": 436975, "best approach": "wiki, concept, image", "verif answer": "beef", "anno approach": "image, wiki", "verif wiki answer": "beef(0.5764)", "verif concept answer": "beef(0.5866)", "verif image answer": "beef(0.6441)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043697.jpg"}, {"question": "what time of day is it", "gt answer": "afternoon(1.00)<br/>noon(1.00)", "pred answer": "afternoon", "question_id": 2928335, "best approach": "", "verif answer": "morn", "anno approach": "", "verif wiki answer": "morn(0.6946)", "verif concept answer": "morn(0.6994)", "verif image answer": "morn(0.6614)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292833.jpg"}, {"question": "what is the object at the very top of this building called", "gt answer": "spire(1.00)<br/>bell(0.60)<br/>point(0.60)", "pred answer": "clock", "question_id": 3646985, "best approach": "", "verif answer": "court", "anno approach": "", "verif wiki answer": "court(0.6205)", "verif concept answer": "court(0.6497)", "verif image answer": "court(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364698.jpg"}, {"question": "what is the name of this type of bus", "gt answer": "double decker(1.00)", "pred answer": "double decker", "question_id": 4889325, "best approach": "wiki, concept, image", "verif answer": "double decker", "anno approach": "wiki", "verif wiki answer": "double decker(0.7080)", "verif concept answer": "double decker(0.7146)", "verif image answer": "double decker(0.7081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488932.jpg"}, {"question": "which genders bathroom are the toilets most likely to be found in", "gt answer": "men(1.00)<br/>women(0.60)", "pred answer": "male", "question_id": 5342915, "best approach": "", "verif answer": "female", "anno approach": "", "verif wiki answer": "female(0.7253)", "verif concept answer": "male(0.7202)", "verif image answer": "female(0.5528)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534291.jpg"}, {"question": "what type of animal is this", "gt answer": "sheep(1.00)", "pred answer": "sheep", "question_id": 2711855, "best approach": "wiki, concept, image", "verif answer": "sheep", "anno approach": "wiki", "verif wiki answer": "sheep(0.7234)", "verif concept answer": "sheep(0.7245)", "verif image answer": "sheep(0.7140)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000271185.jpg"}, {"question": "the dish before you is good for which parts of the body", "gt answer": "stomach(1.00)<br/>heart(0.60)<br/>muscle(0.60)<br/>immune system(0.60)", "pred answer": "stomach", "question_id": 3526515, "best approach": "wiki, concept, image", "verif answer": "stomach", "anno approach": "image, wiki", "verif wiki answer": "stomach(0.6372)", "verif concept answer": "stomach(0.6303)", "verif image answer": "stomach(0.7237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000352651.jpg"}, {"question": "", "gt answer": "clear(0.60)<br/>cumulus(0.60)<br/>storm(0.60)", "pred answer": "stratus", "question_id": 920065, "best approach": "concept, image", "verif answer": "cumulus", "anno approach": "", "verif wiki answer": "cirrus(0.6187)", "verif concept answer": "cumulus(0.6216)", "verif image answer": "cumulus(0.6452)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092006.jpg"}, {"question": "how old are these people", "gt answer": "70(1.00)<br/>60s(0.60)", "pred answer": "forty", "question_id": 1446205, "best approach": "wiki, concept, image", "verif answer": "60s", "anno approach": "wiki", "verif wiki answer": "60s(0.6279)", "verif concept answer": "60s(0.6465)", "verif image answer": "60s(0.6541)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144620.jpg"}, {"question": "is that a church or a court", "gt answer": "court(1.00)<br/>church(1.00)", "pred answer": "church", "question_id": 2437455, "best approach": "image", "verif answer": "clock", "anno approach": "image", "verif wiki answer": "clock(0.5427)", "verif concept answer": "clock(0.5021)", "verif image answer": "court(0.5190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243745.jpg"}, {"question": "what kind of food is this", "gt answer": "scallop(1.00)<br/>sandwich(0.60)<br/>sea(0.60)<br/>american(0.60)", "pred answer": "sandwich", "question_id": 87345, "best approach": "wiki, concept, image", "verif answer": "sandwich", "anno approach": "concept, wiki", "verif wiki answer": "sandwich(0.6448)", "verif concept answer": "sandwich(0.6742)", "verif image answer": "sandwich(0.6225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008734.jpg"}, {"question": "is this skateboarder doing dangerous stunts or is he safe", "gt answer": "safe(1.00)<br/>danger(1.00)", "pred answer": "safe", "question_id": 1891825, "best approach": "", "verif answer": "meet", "anno approach": "", "verif wiki answer": "meet(0.6037)", "verif concept answer": "meet(0.6164)", "verif image answer": "meet(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000189182.jpg"}, {"question": "what type of room is this", "gt answer": "bedroom(1.00)<br/>large(0.60)", "pred answer": "bedroom", "question_id": 5182185, "best approach": "", "verif answer": "live room", "anno approach": "", "verif wiki answer": "live room(0.5270)", "verif concept answer": "live room(0.5019)", "verif image answer": "live room(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518218.jpg"}, {"question": "in what era was this photo likely taken", "gt answer": "60s(1.00)", "pred answer": "1940", "question_id": 4197675, "best approach": "wiki, concept", "verif answer": "1930s", "anno approach": "wiki", "verif wiki answer": "60s(0.6575)", "verif concept answer": "60s(0.6502)", "verif image answer": "1930s(0.6637)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419767.jpg"}, {"question": "what is the picture of in this photograph", "gt answer": "art(1.00)<br/>supply(0.60)", "pred answer": "sew", "question_id": 1837885, "best approach": "", "verif answer": "ikea", "anno approach": "", "verif wiki answer": "ikea(0.5648)", "verif concept answer": "ikea(0.5190)", "verif image answer": "ikea(0.5275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183788.jpg"}, {"question": "what kind of event can be celebrated with these cakes", "gt answer": "easter(1.00)", "pred answer": "birthday", "question_id": 1509485, "best approach": "", "verif answer": "christmas", "anno approach": "", "verif wiki answer": "christmas(0.5882)", "verif concept answer": "christmas(0.6321)", "verif image answer": "thanksgiving(0.6140)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000150948.jpg"}, {"question": "why is there red sauce in noodles", "gt answer": "tomato(1.00)", "pred answer": "tomato", "question_id": 4019445, "best approach": "wiki, concept", "verif answer": "tomato", "anno approach": "wiki", "verif wiki answer": "tomato(0.6004)", "verif concept answer": "tomato(0.6183)", "verif image answer": "marinara(0.5662)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401944.jpg"}, {"question": "what year did the olympics of the season featured in this picture begin", "gt answer": "1924(1.00)<br/>2010(0.60)<br/>1984(0.60)", "pred answer": "winter", "question_id": 5188195, "best approach": "wiki, concept", "verif answer": "2010", "anno approach": "wiki", "verif wiki answer": "1984(0.6427)", "verif concept answer": "2010(0.6660)", "verif image answer": "1930s(0.6625)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518819.jpg"}, {"question": "what do you call these desserts", "gt answer": "pastry(1.00)<br/>doughnut(0.60)", "pred answer": "cupcake", "question_id": 774445, "best approach": "", "verif answer": "donuts", "anno approach": "", "verif wiki answer": "donuts(0.7167)", "verif concept answer": "donuts(0.7219)", "verif image answer": "sweet(0.5084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077444.jpg"}, {"question": "where does the flying object take off from", "gt answer": "airport(1.00)", "pred answer": "runway", "question_id": 1747125, "best approach": "concept", "verif answer": "airport", "anno approach": "concept", "verif wiki answer": "runway(0.7014)", "verif concept answer": "airport(0.7094)", "verif image answer": "on lake(0.6587)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174712.jpg"}, {"question": "what kind of bird is this", "gt answer": "parakeet(1.00)<br/>parrot(0.60)", "pred answer": "parakeet", "question_id": 2971595, "best approach": "wiki, concept", "verif answer": "parrot", "anno approach": "wiki", "verif wiki answer": "parakeet(0.7289)", "verif concept answer": "parakeet(0.7301)", "verif image answer": "parrot(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297159.jpg"}, {"question": "what is the pattern on these", "gt answer": "fruit(1.00)<br/>floral(0.60)", "pred answer": "leopard", "question_id": 2502255, "best approach": "wiki", "verif answer": "fruit", "anno approach": "wiki", "verif wiki answer": "fruit(0.7064)", "verif concept answer": "striped(0.6952)", "verif image answer": "striped(0.6555)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250225.jpg"}, {"question": "what kind of truck is it", "gt answer": "pickup(1.00)", "pred answer": "truck", "question_id": 2953985, "best approach": "wiki", "verif answer": "pickup", "anno approach": "wiki", "verif wiki answer": "pickup(0.6759)", "verif concept answer": "truck(0.6372)", "verif image answer": "jeep(0.6595)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295398.jpg"}, {"question": "what was that cutlery made of", "gt answer": "stainless steel(1.00)<br/>steel(0.60)<br/>silver(0.60)<br/>chicken(0.60)", "pred answer": "steel", "question_id": 3890615, "best approach": "wiki, concept, image", "verif answer": "stainless steel", "anno approach": "concept, wiki", "verif wiki answer": "stainless steel(0.7183)", "verif concept answer": "stainless steel(0.7138)", "verif image answer": "stainless steel(0.6629)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389061.jpg"}, {"question": "what 's protecting this floor", "gt answer": "carpet(1.00)<br/>rug(1.00)", "pred answer": "vacuum", "question_id": 2367255, "best approach": "wiki, concept", "verif answer": "rug", "anno approach": "concept, wiki", "verif wiki answer": "rug(0.6279)", "verif concept answer": "rug(0.6620)", "verif image answer": "leather(0.5720)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236725.jpg"}, {"question": "what are they studying", "gt answer": "math(1.00)<br/>school(0.60)", "pred answer": "book", "question_id": 1198845, "best approach": "concept, image", "verif answer": "school", "anno approach": "", "verif wiki answer": "sew(0.6001)", "verif concept answer": "school(0.7015)", "verif image answer": "school(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119884.jpg"}, {"question": "in what city could this bus be", "gt answer": "london(1.00)<br/>england(0.60)<br/>berlin(0.60)", "pred answer": "tour", "question_id": 5010285, "best approach": "wiki, image", "verif answer": "berlin", "anno approach": "image, wiki", "verif wiki answer": "london(0.6256)", "verif concept answer": "berlin(0.6928)", "verif image answer": "london(0.6817)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501028.jpg"}, {"question": "how high does this plane fly", "gt answer": "30000 feet(1.00)<br/>very(0.60)", "pred answer": "20 feet", "question_id": 5501045, "best approach": "", "verif answer": "very healthy", "anno approach": "", "verif wiki answer": "very healthy(0.6625)", "verif concept answer": "very healthy(0.6574)", "verif image answer": "very healthy(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550104.jpg"}, {"question": "what is this lady about to hit", "gt answer": "tennis ball(1.00)<br/>ball(0.60)<br/>tennis(0.60)", "pred answer": "tennis ball", "question_id": 5037175, "best approach": "wiki, concept, image", "verif answer": "tennis ball", "anno approach": "wiki", "verif wiki answer": "tennis ball(0.7302)", "verif concept answer": "tennis ball(0.7270)", "verif image answer": "tennis ball(0.7219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503717.jpg"}, {"question": "is this vehicle used primarily for transporting humans or cargo", "gt answer": "cargo(1.00)", "pred answer": "people", "question_id": 857995, "best approach": "concept", "verif answer": "freight", "anno approach": "concept", "verif wiki answer": "freight(0.5979)", "verif concept answer": "cargo(0.5656)", "verif image answer": "transportation(0.5528)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085799.jpg"}, {"question": "these animals are said to gorge in the fall as preparation for what", "gt answer": "hibernation(1.00)<br/>bear(1.00)<br/>winter(0.60)", "pred answer": "hibernate", "question_id": 3711835, "best approach": "wiki", "verif answer": "winter", "anno approach": "wiki", "verif wiki answer": "bear(0.5025)", "verif concept answer": "winter(0.5039)", "verif image answer": "winter(0.5071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371183.jpg"}, {"question": "what move is the man on the skateboard performing", "gt answer": "slide(1.00)<br/>trick(0.60)<br/>jump(0.60)", "pred answer": "grind", "question_id": 111595, "best approach": "concept, image", "verif answer": "slide", "anno approach": "image", "verif wiki answer": "kickflip(0.6771)", "verif concept answer": "slide(0.6257)", "verif image answer": "slide(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011159.jpg"}, {"question": "name the variety of aeroplane which is shown in this picture", "gt answer": "boeing 747(1.00)<br/>commercial(0.60)", "pred answer": "boeing", "question_id": 1013105, "best approach": "", "verif answer": "passenger", "anno approach": "", "verif wiki answer": "boeing(0.6634)", "verif concept answer": "boeing(0.6317)", "verif image answer": "passenger(0.6793)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000101310.jpg"}, {"question": "what activity is the boy doing", "gt answer": "play video game(0.60)<br/>video game(1.00)<br/>game(0.60)<br/>wii(0.60)", "pred answer": "video game", "question_id": 4414605, "best approach": "wiki, concept, image", "verif answer": "video game", "anno approach": "wiki", "verif wiki answer": "video game(0.7249)", "verif concept answer": "video game(0.7291)", "verif image answer": "video game(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441460.jpg"}, {"question": "", "gt answer": "army(0.60)<br/>military(0.60)<br/>levis(0.60)", "pred answer": "suit", "question_id": 1287295, "best approach": "wiki, concept, image", "verif answer": "levis", "anno approach": "image", "verif wiki answer": "levis(0.6389)", "verif concept answer": "levis(0.6197)", "verif image answer": "levis(0.6530)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128729.jpg"}, {"question": "in what architectural style is the building seen here", "gt answer": "gothic(1.00)<br/>modern(1.00)", "pred answer": "roman", "question_id": 1744125, "best approach": "wiki, concept, image", "verif answer": "modern", "anno approach": "wiki", "verif wiki answer": "modern(0.6653)", "verif concept answer": "modern(0.6885)", "verif image answer": "modern(0.6845)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174412.jpg"}, {"question": "what type of sport is this girl playing", "gt answer": "box(1.00)<br/>wii(0.60)", "pred answer": "wii", "question_id": 4582305, "best approach": "wiki, concept", "verif answer": "wii", "anno approach": "wiki", "verif wiki answer": "wii(0.6862)", "verif concept answer": "wii(0.6950)", "verif image answer": "video(0.6615)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458230.jpg"}, {"question": "what country is this", "gt answer": "united state(1.00)<br/>usa(0.60)<br/>america(0.60)", "pred answer": "london", "question_id": 98095, "best approach": "wiki, concept, image", "verif answer": "usa", "anno approach": "concept, wiki", "verif wiki answer": "usa(0.7028)", "verif concept answer": "usa(0.6871)", "verif image answer": "america(0.6290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009809.jpg"}, {"question": "what food is this", "gt answer": "stir fry(1.00)", "pred answer": "sandwich", "question_id": 5270565, "best approach": "wiki, concept, image", "verif answer": "stir fry", "anno approach": "wiki", "verif wiki answer": "stir fry(0.7002)", "verif concept answer": "stir fry(0.6986)", "verif image answer": "stir fry(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527056.jpg"}, {"question": "what are the birds drinking from", "gt answer": "pool(1.00)", "pred answer": "umbrella", "question_id": 2282275, "best approach": "", "verif answer": "trash", "anno approach": "", "verif wiki answer": "trash(0.7167)", "verif concept answer": "trash(0.7137)", "verif image answer": "trash(0.7196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000228227.jpg"}, {"question": "what toppings are on this hotdog", "gt answer": "mustard(1.00)", "pred answer": "ketchup and relish", "question_id": 4688295, "best approach": "wiki, image", "verif answer": "mustard", "anno approach": "wiki", "verif wiki answer": "mustard(0.6811)", "verif concept answer": "cheese(0.6730)", "verif image answer": "mustard(0.7141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000468829.jpg"}, {"question": "what year is this truck", "gt answer": "1969(1.00)<br/>1965(0.60)<br/>1950(0.60)", "pred answer": "1940", "question_id": 5161675, "best approach": "wiki", "verif answer": "1980", "anno approach": "wiki", "verif wiki answer": "1965(0.6504)", "verif concept answer": "1980(0.6715)", "verif image answer": "1980(0.6632)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516167.jpg"}, {"question": "what is the woman sitting on", "gt answer": "bean bag(1.00)", "pred answer": "table", "question_id": 3052245, "best approach": "wiki, concept, image", "verif answer": "bean bag", "anno approach": "", "verif wiki answer": "bean bag(0.7181)", "verif concept answer": "bean bag(0.7272)", "verif image answer": "bean bag(0.7173)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305224.jpg"}, {"question": "can you name the motel hotel", "gt answer": "hilton(1.00)", "pred answer": "hilton", "question_id": 3062495, "best approach": "wiki, concept", "verif answer": "ikea", "anno approach": "wiki", "verif wiki answer": "hilton(0.6467)", "verif concept answer": "hilton(0.6756)", "verif image answer": "ikea(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306249.jpg"}, {"question": "how many oz 's of liquid will this cup hold", "gt answer": "8(1.00)", "pred answer": "400", "question_id": 4295595, "best approach": "", "verif answer": "2", "anno approach": "", "verif wiki answer": "2(0.6759)", "verif concept answer": "75(0.6547)", "verif image answer": "75(0.6172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429559.jpg"}, {"question": "what would he find in what he is reading", "gt answer": "news(1.00)", "pred answer": "magazine", "question_id": 5582865, "best approach": "wiki, concept, image", "verif answer": "news", "anno approach": "image, concept, wiki", "verif wiki answer": "news(0.5491)", "verif concept answer": "news(0.6278)", "verif image answer": "news(0.6148)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558286.jpg"}, {"question": "where would the sun be located relative to the photographer", "gt answer": "behind(1.00)<br/>front(0.60)", "pred answer": "north", "question_id": 3355655, "best approach": "image", "verif answer": "behind", "anno approach": "image", "verif wiki answer": "north(0.6835)", "verif concept answer": "back(0.6983)", "verif image answer": "behind(0.7041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335565.jpg"}, {"question": "what year is that laptop from", "gt answer": "2010(1.00)", "pred answer": "2000", "question_id": 4727375, "best approach": "", "verif answer": "2002", "anno approach": "", "verif wiki answer": "2002(0.6694)", "verif concept answer": "2002(0.6853)", "verif image answer": "2002(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000472737.jpg"}, {"question": "what time of day is this meal eaten", "gt answer": "even(1.00)<br/>dinner(0.60)", "pred answer": "dinner", "question_id": 5634445, "best approach": "concept", "verif answer": "dinner", "anno approach": "concept", "verif wiki answer": "lunch(0.7013)", "verif concept answer": "dinner(0.7092)", "verif image answer": "lunch(0.6573)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000563444.jpg"}, {"question": "how do you make that", "gt answer": "cross stitch(1.00)<br/>sew(0.60)<br/>embroidery(0.60)", "pred answer": "sew", "question_id": 1276445, "best approach": "wiki, concept, image", "verif answer": "sew", "anno approach": "wiki", "verif wiki answer": "sew(0.6633)", "verif concept answer": "sew(0.6384)", "verif image answer": "sew(0.6392)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127644.jpg"}, {"question": "what is the sports position of the man in the orange shirt", "gt answer": "goalie(1.00)", "pred answer": "goalie", "question_id": 3482915, "best approach": "wiki, concept, image", "verif answer": "goalie", "anno approach": "concept, wiki", "verif wiki answer": "goalie(0.7220)", "verif concept answer": "goalie(0.6238)", "verif image answer": "goalie(0.5345)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348291.jpg"}, {"question": "what first responder would use this device", "gt answer": "fireman(1.00)<br/>firefighter(1.00)<br/>fire fighter(0.60)", "pred answer": "fire", "question_id": 4454465, "best approach": "", "verif answer": "firefight", "anno approach": "", "verif wiki answer": "firefight(0.6755)", "verif concept answer": "firefight(0.6893)", "verif image answer": "firefight(0.6634)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445446.jpg"}, {"question": "what is the proper reaction to seeing a stop sign", "gt answer": "stop(1.00)<br/>brake(0.60)", "pred answer": "stop", "question_id": 3444225, "best approach": "", "verif answer": "wrong way", "anno approach": "", "verif wiki answer": "wrong way(0.7226)", "verif concept answer": "wrong way(0.7178)", "verif image answer": "wrong way(0.7151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344422.jpg"}, {"question": "who kept the kitchen so clean", "gt answer": "wife(1.00)<br/>owner(0.60)<br/>grandma(0.60)<br/>maid(0.60)", "pred answer": "chef", "question_id": 4361855, "best approach": "wiki, image", "verif answer": "maid", "anno approach": "wiki", "verif wiki answer": "maid(0.7280)", "verif concept answer": "ge(0.6499)", "verif image answer": "maid(0.7133)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436185.jpg"}, {"question": "what holiday is being celebrated", "gt answer": "july 4th(1.00)<br/>vacation(0.60)<br/>fourth of july(0.60)", "pred answer": "christmas", "question_id": 1349865, "best approach": "wiki", "verif answer": "july 4th", "anno approach": "wiki", "verif wiki answer": "july 4th(0.6816)", "verif concept answer": "4th of july(0.6521)", "verif image answer": "4th of july(0.6535)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134986.jpg"}, {"question": "what model of train is the red train sitting on the tracks", "gt answer": "bullet(1.00)<br/>bullet train(1.00)", "pred answer": "passenger", "question_id": 3956145, "best approach": "wiki, image", "verif answer": "bullet train", "anno approach": "wiki", "verif wiki answer": "bullet train(0.7006)", "verif concept answer": "amtrak(0.6823)", "verif image answer": "bullet train(0.7145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395614.jpg"}, {"question": "what type of nut is pictured", "gt answer": "walnut(1.00)", "pred answer": "pistachio", "question_id": 2610645, "best approach": "", "verif answer": "pistachio", "anno approach": "", "verif wiki answer": "pistachio(0.6556)", "verif concept answer": "pistachio(0.6876)", "verif image answer": "pistachio(0.5735)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261064.jpg"}, {"question": "what type of food is this", "gt answer": "hotdog(1.00)<br/>fast food(0.60)<br/>hot dog(0.60)", "pred answer": "hot dog", "question_id": 5232115, "best approach": "wiki, concept, image", "verif answer": "hot dog", "anno approach": "concept, wiki", "verif wiki answer": "hot dog(0.6845)", "verif concept answer": "hot dog(0.6966)", "verif image answer": "hot dog(0.6195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523211.jpg"}, {"question": "what is the name of the first african american to play this sport", "gt answer": "jackie robinson(1.00)<br/>babe ruth(0.60)", "pred answer": "babe ruth", "question_id": 256755, "best approach": "", "verif answer": "moses walker", "anno approach": "", "verif wiki answer": "moses walker(0.7308)", "verif concept answer": "moses walker(0.7235)", "verif image answer": "moses walker(0.6628)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025675.jpg"}, {"question": "what is a building of this height called", "gt answer": "skyscraper(1.00)", "pred answer": "church", "question_id": 2527495, "best approach": "", "verif answer": "clock tower", "anno approach": "", "verif wiki answer": "clock tower(0.7310)", "verif concept answer": "clock tower(0.7300)", "verif image answer": "clock tower(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252749.jpg"}, {"question": "what is on the tv", "gt answer": "earth(1.00)<br/>dog(0.60)", "pred answer": "dog", "question_id": 328165, "best approach": "concept", "verif answer": "dog", "anno approach": "concept", "verif wiki answer": "dog(0.7211)", "verif concept answer": "earth(0.7208)", "verif image answer": "teddy bear(0.7058)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032816.jpg"}, {"question": "what is this act of playing with a dog called", "gt answer": "fetch(1.00)", "pred answer": "catch", "question_id": 1515815, "best approach": "", "verif answer": "rain", "anno approach": "", "verif wiki answer": "rain(0.6745)", "verif concept answer": "rain(0.6653)", "verif image answer": "rain(0.6378)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151581.jpg"}, {"question": "what material is used to color this court", "gt answer": "paint(1.00)<br/>asphalt(0.60)<br/>green(0.60)", "pred answer": "cement", "question_id": 4166055, "best approach": "", "verif answer": "spray paint", "anno approach": "", "verif wiki answer": "spray paint(0.7291)", "verif concept answer": "spray paint(0.7276)", "verif image answer": "spray paint(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416605.jpg"}, {"question": "how many animals like this currently exist", "gt answer": "20000(1.00)", "pred answer": "2", "question_id": 3579295, "best approach": "", "verif answer": "million", "anno approach": "", "verif wiki answer": "million(0.7046)", "verif concept answer": "million(0.7080)", "verif image answer": "million(0.6985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357929.jpg"}, {"question": "how many stripes does this animal typically have", "gt answer": "lot(1.00)<br/>300(0.60)<br/>200(0.60)<br/>80(0.60)", "pred answer": "7", "question_id": 1023335, "best approach": "wiki, concept", "verif answer": "lot", "anno approach": "wiki", "verif wiki answer": "lot(0.6958)", "verif concept answer": "lot(0.6496)", "verif image answer": "500(0.6463)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000102333.jpg"}, {"question": "what 's the name of this river", "gt answer": "mississippi(1.00)<br/>dirty(0.60)<br/>fox(0.60)<br/>thames(0.60)", "pred answer": "canal", "question_id": 977475, "best approach": "", "verif answer": "canal", "anno approach": "", "verif wiki answer": "canal(0.6621)", "verif concept answer": "canal(0.6526)", "verif image answer": "canal(0.7162)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097747.jpg"}, {"question": "what breed of horse is that", "gt answer": "palomino(1.00)<br/>mustang(1.00)<br/>pony(0.60)", "pred answer": "mustang", "question_id": 3053635, "best approach": "wiki, concept, image", "verif answer": "palomino", "anno approach": "wiki", "verif wiki answer": "palomino(0.7167)", "verif concept answer": "palomino(0.7044)", "verif image answer": "palomino(0.7028)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305363.jpg"}, {"question": "what popular brand of these items features a laughing man of enormous stature", "gt answer": "green giant(1.00)<br/>broccoli(0.60)", "pred answer": "broccoli", "question_id": 1593325, "best approach": "", "verif answer": "heinz", "anno approach": "", "verif wiki answer": "heinz(0.6070)", "verif concept answer": "heinz(0.5788)", "verif image answer": "heinz(0.5763)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159332.jpg"}, {"question": "which sport are these people enjoying", "gt answer": "windsurf(1.00)<br/>wind surf(0.60)<br/>sail(0.60)", "pred answer": "surf", "question_id": 506955, "best approach": "", "verif answer": "surf", "anno approach": "", "verif wiki answer": "surf(0.6741)", "verif concept answer": "surf(0.6925)", "verif image answer": "surf(0.5906)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050695.jpg"}, {"question": "what animal is pictured", "gt answer": "cat(1.00)", "pred answer": "dog", "question_id": 77815, "best approach": "", "verif answer": "dog", "anno approach": "", "verif wiki answer": "dog(0.7165)", "verif concept answer": "dog(0.7180)", "verif image answer": "dog(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007781.jpg"}, {"question": "what type of clock is this", "gt answer": "coocoo(1.00)", "pred answer": "analog", "question_id": 4485335, "best approach": "", "verif answer": "grandfather clock", "anno approach": "", "verif wiki answer": "grandfather clock(0.7263)", "verif concept answer": "grandfather clock(0.6960)", "verif image answer": "grandfather clock(0.7121)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448533.jpg"}, {"question": "who is the famous person that used one of these to win seven races only to have his titles stripped for using performance enhancing drugs", "gt answer": "lance armstrong(1.00)", "pred answer": "bode miller", "question_id": 4697285, "best approach": "", "verif answer": "shut down", "anno approach": "", "verif wiki answer": "shut down(0.6510)", "verif concept answer": "shut down(0.6676)", "verif image answer": "shut down(0.6909)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469728.jpg"}, {"question": "which material is used to make this hand bag shown here", "gt answer": "yarn(1.00)<br/>cotton(0.60)<br/>mesh(0.60)", "pred answer": "polyester", "question_id": 2404635, "best approach": "wiki, concept", "verif answer": "cotton", "anno approach": "wiki", "verif wiki answer": "yarn(0.6591)", "verif concept answer": "yarn(0.5949)", "verif image answer": "cotton(0.6711)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240463.jpg"}, {"question": "why would these people be at the table", "gt answer": "family dinner(1.00)<br/>food(0.60)<br/>supper(0.60)<br/>eat(0.60)", "pred answer": "dinner", "question_id": 1763925, "best approach": "wiki, concept, image", "verif answer": "supper", "anno approach": "image, concept, wiki", "verif wiki answer": "supper(0.6190)", "verif concept answer": "supper(0.6906)", "verif image answer": "eat(0.6562)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176392.jpg"}, {"question": "what team is this", "gt answer": "cub(1.00)<br/>met(0.60)<br/>red sox(0.60)", "pred answer": "baseball", "question_id": 541635, "best approach": "concept", "verif answer": "dodger", "anno approach": "concept", "verif wiki answer": "dodger(0.6675)", "verif concept answer": "red sox(0.6668)", "verif image answer": "dodger(0.6451)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054163.jpg"}, {"question": "who is famous for their temper in this sport", "gt answer": "john mcenroe(1.00)", "pred answer": "roger federer", "question_id": 2720075, "best approach": "", "verif answer": "little league", "anno approach": "", "verif wiki answer": "sharapova(0.6971)", "verif concept answer": "little league(0.6996)", "verif image answer": "little league(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000272007.jpg"}, {"question": "what brand of toothbrush is this", "gt answer": "oral b(1.00)<br/>colgate(1.00)", "pred answer": "oral b", "question_id": 5607505, "best approach": "wiki, concept", "verif answer": "colgate", "anno approach": "wiki", "verif wiki answer": "colgate(0.6705)", "verif concept answer": "colgate(0.6814)", "verif image answer": "teeth(0.6714)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560750.jpg"}, {"question": "what sort of device was likely used to make the shaped edibles", "gt answer": "cookie cutter(1.00)", "pred answer": "grill", "question_id": 3104505, "best approach": "image", "verif answer": "pot", "anno approach": "image", "verif wiki answer": "pot(0.7230)", "verif concept answer": "pot(0.6878)", "verif image answer": "cookie cutter(0.6132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310450.jpg"}, {"question": "what type of bird is that", "gt answer": "owl(1.00)<br/>falcon(0.60)<br/>pigeon(0.60)", "pred answer": "finch", "question_id": 1422395, "best approach": "wiki", "verif answer": "owl", "anno approach": "wiki", "verif wiki answer": "owl(0.7096)", "verif concept answer": "hawk(0.6992)", "verif image answer": "hawk(0.6971)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142239.jpg"}, {"question": "how many people does this vehicle hold", "gt answer": "300(1.00)<br/>lot(0.60)<br/>thousand(0.60)<br/>100(0.60)", "pred answer": "many", "question_id": 5392145, "best approach": "wiki, concept, image", "verif answer": "lot", "anno approach": "wiki", "verif wiki answer": "lot(0.6735)", "verif concept answer": "lot(0.6666)", "verif image answer": "lot(0.6600)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539214.jpg"}, {"question": "how many different species of animals call this body of water home", "gt answer": "thousand(1.00)<br/>100(0.60)", "pred answer": "3", "question_id": 3185645, "best approach": "", "verif answer": "1000", "anno approach": "", "verif wiki answer": "1000(0.7063)", "verif concept answer": "1000(0.6943)", "verif image answer": "1000(0.6676)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318564.jpg"}, {"question": "what fabrics are made these ties", "gt answer": "silk(1.00)", "pred answer": "polyester", "question_id": 413115, "best approach": "", "verif answer": "tie", "anno approach": "", "verif wiki answer": "tie(0.7256)", "verif concept answer": "tie(0.7302)", "verif image answer": "tie(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041311.jpg"}, {"question": "what is this device used for", "gt answer": "teeth(1.00)<br/>brush teeth(0.60)<br/>clean teeth(0.60)", "pred answer": "toothbrush", "question_id": 2170545, "best approach": "wiki", "verif answer": "toothbrush", "anno approach": "wiki", "verif wiki answer": "teeth(0.5506)", "verif concept answer": "toothbrush(0.7096)", "verif image answer": "toothbrush(0.7074)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217054.jpg"}, {"question": "is this an example of humans hanging out togehter or are they working", "gt answer": "hang out(1.00)", "pred answer": "play video game", "question_id": 3532705, "best approach": "", "verif answer": "run", "anno approach": "", "verif wiki answer": "run(0.7213)", "verif concept answer": "run(0.7172)", "verif image answer": "run(0.6934)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353270.jpg"}, {"question": "what kind of berries are shown", "gt answer": "rasberries(1.00)<br/>raspberry(1.00)", "pred answer": "rose", "question_id": 4589845, "best approach": "wiki, concept, image", "verif answer": "raspberry", "anno approach": "", "verif wiki answer": "raspberry(0.7234)", "verif concept answer": "raspberry(0.7224)", "verif image answer": "raspberry(0.6985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458984.jpg"}, {"question": "what type of mattress is this", "gt answer": "single(1.00)<br/>futon(0.60)<br/>air(0.60)<br/>baby(0.60)", "pred answer": "queen", "question_id": 442155, "best approach": "wiki, concept, image", "verif answer": "baby", "anno approach": "image, wiki", "verif wiki answer": "baby(0.5287)", "verif concept answer": "baby(0.5034)", "verif image answer": "baby(0.6731)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000044215.jpg"}, {"question": "what breed of cat is in this picture", "gt answer": "siamese(1.00)<br/>persian(0.60)", "pred answer": "calico", "question_id": 3332915, "best approach": "", "verif answer": "sleep", "anno approach": "", "verif wiki answer": "ragdoll(0.6392)", "verif concept answer": "ragdoll(0.6707)", "verif image answer": "sleep(0.7164)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333291.jpg"}, {"question": "how much taller is the man in the hat than the animal in front of him", "gt answer": "2 feet(1.00)<br/>1 foot(0.60)<br/>3 feet(0.60)", "pred answer": "3 feet", "question_id": 3414575, "best approach": "wiki", "verif answer": "2 feet", "anno approach": "wiki", "verif wiki answer": "2 feet(0.7161)", "verif concept answer": "1 foot(0.6910)", "verif image answer": "1 foot(0.6926)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341457.jpg"}, {"question": "what sound does this animal make", "gt answer": "woof(1.00)<br/>bark(0.60)", "pred answer": "moo", "question_id": 5226605, "best approach": "wiki, concept, image", "verif answer": "woof", "anno approach": "concept, wiki", "verif wiki answer": "woof(0.6309)", "verif concept answer": "woof(0.7235)", "verif image answer": "woof(0.5951)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522660.jpg"}, {"question": "what 's the name of the tallest building in this photo", "gt answer": "big ben(1.00)", "pred answer": "clock tower", "question_id": 1363125, "best approach": "", "verif answer": "roman numeral", "anno approach": "", "verif wiki answer": "roman numeral(0.7300)", "verif concept answer": "roman numeral(0.7299)", "verif image answer": "roman numeral(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136312.jpg"}, {"question": "what activities are most commonly done here", "gt answer": "wash(1.00)<br/>shower(0.60)<br/>wash hand(0.60)", "pred answer": "pee", "question_id": 3576415, "best approach": "", "verif answer": "pee", "anno approach": "", "verif wiki answer": "pee(0.6330)", "verif concept answer": "pee(0.6593)", "verif image answer": "pee(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357641.jpg"}, {"question": "where is this again", "gt answer": "forest(1.00)<br/>wood(0.60)", "pred answer": "farm", "question_id": 1040815, "best approach": "wiki, concept, image", "verif answer": "wood", "anno approach": "image, wiki", "verif wiki answer": "wood(0.6146)", "verif concept answer": "wood(0.6110)", "verif image answer": "wood(0.6985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000104081.jpg"}, {"question": "what is a competition for these animals called", "gt answer": "horse race(1.00)<br/>kentucky derby(0.60)<br/>race(0.60)", "pred answer": "race", "question_id": 3196155, "best approach": "image", "verif answer": "polo", "anno approach": "image", "verif wiki answer": "polo(0.7050)", "verif concept answer": "race(0.7019)", "verif image answer": "horse race(0.6600)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319615.jpg"}, {"question": "what river is this woman on", "gt answer": "nile(1.00)<br/>amazon(1.00)", "pred answer": "nile", "question_id": 4834965, "best approach": "wiki, concept", "verif answer": "amazon", "anno approach": "wiki", "verif wiki answer": "amazon(0.7086)", "verif concept answer": "amazon(0.7192)", "verif image answer": "ganges(0.7033)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483496.jpg"}, {"question": "what cocktail is this lady drinking", "gt answer": "vodka cranberry(1.00)<br/>alcoholic(0.60)", "pred answer": "coke", "question_id": 2090125, "best approach": "", "verif answer": "ollie", "anno approach": "", "verif wiki answer": "ollie(0.6668)", "verif concept answer": "ollie(0.6633)", "verif image answer": "lemonade(0.6235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209012.jpg"}, {"question": "this woman wears glasses for what purpose", "gt answer": "see(1.00)<br/>read(0.60)", "pred answer": "shade", "question_id": 2255395, "best approach": "image", "verif answer": "see", "anno approach": "image", "verif wiki answer": "tell time(0.6974)", "verif concept answer": "read(0.6991)", "verif image answer": "see(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225539.jpg"}, {"question": "what is the life span of this animal", "gt answer": "2 16 years(1.00)<br/>15 years(0.60)<br/>year(0.60)<br/>9 years(0.60)", "pred answer": "10 years", "question_id": 4390855, "best approach": "wiki, concept", "verif answer": "9 years", "anno approach": "wiki", "verif wiki answer": "9 years(0.6610)", "verif concept answer": "9 years(0.6574)", "verif image answer": "10 years(0.6578)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439085.jpg"}, {"question": "what is the large silver item on the top left", "gt answer": "phone(1.00)<br/>keyboard(0.60)", "pred answer": "motorcycle", "question_id": 2838095, "best approach": "concept", "verif answer": "keyboard", "anno approach": "concept", "verif wiki answer": "keyboard(0.6835)", "verif concept answer": "phone(0.6678)", "verif image answer": "keyboard(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283809.jpg"}, {"question": "is this a hangout or a form of a gang", "gt answer": "hangout(1.00)<br/>both(0.60)", "pred answer": "tie", "question_id": 2698295, "best approach": "", "verif answer": "public", "anno approach": "", "verif wiki answer": "public(0.5794)", "verif concept answer": "public(0.5169)", "verif image answer": "public(0.6906)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269829.jpg"}, {"question": "what is the weather like", "gt answer": "overcast(1.00)<br/>sunny(1.00)<br/>cloudy(0.60)", "pred answer": "hot", "question_id": 666915, "best approach": "concept, image", "verif answer": "cloudy", "anno approach": "concept", "verif wiki answer": "cloudy(0.7079)", "verif concept answer": "sunny(0.6743)", "verif image answer": "sunny(0.6169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000066691.jpg"}, {"question": "why is the microwave on the street", "gt answer": "broken(1.00)<br/>trash(1.00)", "pred answer": "broken", "question_id": 686205, "best approach": "wiki, concept, image", "verif answer": "broken", "anno approach": "image, concept, wiki", "verif wiki answer": "broken(0.5953)", "verif concept answer": "broken(0.6325)", "verif image answer": "broken(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068620.jpg"}, {"question": "what is the name for the body of a plane", "gt answer": "fuselage(1.00)<br/>jet(0.60)", "pred answer": "boeing", "question_id": 2503035, "best approach": "wiki, concept", "verif answer": "fuselage", "anno approach": "wiki", "verif wiki answer": "fuselage(0.6766)", "verif concept answer": "fuselage(0.5161)", "verif image answer": "contrail(0.6155)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250303.jpg"}, {"question": "why is that street light crooked", "gt answer": "broken(1.00)<br/>accident(0.60)", "pred answer": "light", "question_id": 2680425, "best approach": "", "verif answer": "trash", "anno approach": "", "verif wiki answer": "trash(0.5420)", "verif concept answer": "flipped(0.5907)", "verif image answer": "trash(0.6922)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268042.jpg"}, {"question": "what is the maximum weight the red suitcase can carry", "gt answer": "50 kg(1.00)<br/>2(0.60)", "pred answer": "500", "question_id": 250605, "best approach": "wiki, concept, image", "verif answer": "50 kg", "anno approach": "image", "verif wiki answer": "50 kg(0.6797)", "verif concept answer": "50 kg(0.6609)", "verif image answer": "50 kg(0.6960)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025060.jpg"}, {"question": "", "gt answer": "doberman(0.60)<br/>mix(0.60)<br/>labrador(0.60)<br/>mixed(0.60)", "pred answer": "lab", "question_id": 1814135, "best approach": "wiki, concept, image", "verif answer": "doberman", "anno approach": "concept", "verif wiki answer": "doberman(0.6675)", "verif concept answer": "doberman(0.7047)", "verif image answer": "doberman(0.6689)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181413.jpg"}, {"question": "what do the white lines indicate", "gt answer": "crosswalk(1.00)<br/>pedestrian cross(0.60)<br/>pedestrian(0.60)", "pred answer": "stop", "question_id": 4128555, "best approach": "concept, image", "verif answer": "pedestrian cross", "anno approach": "image", "verif wiki answer": "line(0.5586)", "verif concept answer": "pedestrian cross(0.5890)", "verif image answer": "pedestrian cross(0.6316)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412855.jpg"}, {"question": "what do people do here", "gt answer": "sleep(1.00)", "pred answer": "clean", "question_id": 3644845, "best approach": "wiki, concept, image", "verif answer": "sleep", "anno approach": "wiki", "verif wiki answer": "sleep(0.7230)", "verif concept answer": "sleep(0.6967)", "verif image answer": "sleep(0.6877)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364484.jpg"}, {"question": "what kind of food appears the most on the monitors at the top of the photo", "gt answer": "sandwich(1.00)<br/>hamburger(1.00)", "pred answer": "chicken", "question_id": 3343645, "best approach": "", "verif answer": "burger", "anno approach": "", "verif wiki answer": "steak(0.6653)", "verif concept answer": "steak(0.6616)", "verif image answer": "burger(0.6907)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334364.jpg"}, {"question": "was this photo taken inside or outside", "gt answer": "inside(1.00)<br/>outside(1.00)", "pred answer": "outside", "question_id": 3185285, "best approach": "wiki, concept, image", "verif answer": "outside", "anno approach": "concept, wiki", "verif wiki answer": "outside(0.6718)", "verif concept answer": "outside(0.7203)", "verif image answer": "outside(0.6933)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318528.jpg"}, {"question": "what is the boat doing on the sand", "gt answer": "beached(1.00)<br/>rest(0.60)<br/>parked(0.60)", "pred answer": "float", "question_id": 5788465, "best approach": "wiki, concept", "verif answer": "beached", "anno approach": "", "verif wiki answer": "beached(0.7170)", "verif concept answer": "beached(0.7119)", "verif image answer": "stopped(0.6573)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578846.jpg"}, {"question": "is this a rich or poor area of town", "gt answer": "poor(1.00)", "pred answer": "poor", "question_id": 4553705, "best approach": "wiki, concept, image", "verif answer": "poor", "anno approach": "wiki", "verif wiki answer": "poor(0.7302)", "verif concept answer": "poor(0.7307)", "verif image answer": "poor(0.7054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455370.jpg"}, {"question": "what are these animals standing inside of", "gt answer": "trailer(1.00)<br/>carriage(0.60)<br/>shelter(0.60)", "pred answer": "mountain", "question_id": 1541195, "best approach": "image", "verif answer": "carriage", "anno approach": "image", "verif wiki answer": "cart(0.6427)", "verif concept answer": "cart(0.6160)", "verif image answer": "carriage(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154119.jpg"}, {"question": "where can i find this road", "gt answer": "peru(1.00)<br/>mountain(1.00)<br/>china(0.60)", "pred answer": "wood", "question_id": 369145, "best approach": "wiki", "verif answer": "city", "anno approach": "wiki", "verif wiki answer": "mountain(0.5826)", "verif concept answer": "city(0.6762)", "verif image answer": "city(0.5970)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036914.jpg"}, {"question": "what activity is taking place here", "gt answer": "selfie(1.00)<br/>rest(1.00)", "pred answer": "sleep", "question_id": 2180995, "best approach": "", "verif answer": "pillow", "anno approach": "", "verif wiki answer": "pillow(0.6332)", "verif concept answer": "pillow(0.6865)", "verif image answer": "pillow(0.6745)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218099.jpg"}, {"question": "why is the horse pulling something", "gt answer": "farm(1.00)<br/>plow(1.00)", "pred answer": "food", "question_id": 3841575, "best approach": "", "verif answer": "ride", "anno approach": "", "verif wiki answer": "ride(0.6150)", "verif concept answer": "ride(0.6368)", "verif image answer": "ride(0.6571)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384157.jpg"}, {"question": "in which state is there a mountain named for these animals", "gt answer": "new york(1.00)<br/>bear(0.60)<br/>california(0.60)<br/>alaska(0.60)", "pred answer": "texas", "question_id": 1156815, "best approach": "wiki, image", "verif answer": "alaska", "anno approach": "wiki", "verif wiki answer": "alaska(0.6876)", "verif concept answer": "pennsylvania(0.6807)", "verif image answer": "alaska(0.6791)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115681.jpg"}, {"question": "what is the average cost for this service", "gt answer": "2 dollars(1.00)", "pred answer": "50", "question_id": 3109265, "best approach": "wiki, concept, image", "verif answer": "2 dollars", "anno approach": "wiki", "verif wiki answer": "2 dollars(0.6661)", "verif concept answer": "2 dollars(0.6658)", "verif image answer": "2 dollars(0.6504)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310926.jpg"}, {"question": "what type of plane is this", "gt answer": "glider(1.00)<br/>airplane(0.60)<br/>private(0.60)", "pred answer": "boeing", "question_id": 677265, "best approach": "wiki, concept, image", "verif answer": "glider", "anno approach": "wiki", "verif wiki answer": "glider(0.6858)", "verif concept answer": "glider(0.6824)", "verif image answer": "glider(0.6534)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067726.jpg"}, {"question": "what kind of vegetable", "gt answer": "carrot(1.00)", "pred answer": "carrot", "question_id": 2325435, "best approach": "wiki, concept, image", "verif answer": "carrot", "anno approach": "image, concept, wiki", "verif wiki answer": "carrot(0.5577)", "verif concept answer": "carrot(0.6230)", "verif image answer": "carrot(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232543.jpg"}, {"question": "what do these pedestrian have to stay dry in the rain", "gt answer": "umbrella(1.00)", "pred answer": "blanket", "question_id": 2873885, "best approach": "", "verif answer": "roof", "anno approach": "", "verif wiki answer": "roof(0.5750)", "verif concept answer": "rain(0.5932)", "verif image answer": "roof(0.6827)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287388.jpg"}, {"question": "what vitamins do you get from this fruit", "gt answer": "vitamin c(1.00)<br/>c(0.60)", "pred answer": "c", "question_id": 271905, "best approach": "concept, image", "verif answer": "vitamin c", "anno approach": "image", "verif wiki answer": "c(0.6895)", "verif concept answer": "vitamin c(0.6902)", "verif image answer": "vitamin c(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027190.jpg"}, {"question": "what types of computers", "gt answer": "laptop(1.00)", "pred answer": "laptop", "question_id": 892385, "best approach": "wiki, concept", "verif answer": "macbook", "anno approach": "wiki", "verif wiki answer": "laptop(0.7296)", "verif concept answer": "laptop(0.7279)", "verif image answer": "macbook(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089238.jpg"}, {"question": "what style of window has an arch on top", "gt answer": "arch(1.00)<br/>french(0.60)", "pred answer": "gothic", "question_id": 4361455, "best approach": "", "verif answer": "french door", "anno approach": "", "verif wiki answer": "french door(0.6877)", "verif concept answer": "french door(0.7055)", "verif image answer": "french door(0.7117)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436145.jpg"}, {"question": "what model of motorcycle is this", "gt answer": "honda(1.00)<br/>mercedes benz(0.60)<br/>motorbike(0.60)", "pred answer": "honda", "question_id": 4778605, "best approach": "wiki, concept", "verif answer": "honda", "anno approach": "wiki", "verif wiki answer": "honda(0.6563)", "verif concept answer": "honda(0.6829)", "verif image answer": "mercedes benz(0.6779)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477860.jpg"}, {"question": "is this a polar bear or black bear", "gt answer": "polar(1.00)<br/>black bear(1.00)<br/>black(0.60)", "pred answer": "polar", "question_id": 5733745, "best approach": "wiki, concept, image", "verif answer": "black bear", "anno approach": "wiki", "verif wiki answer": "black bear(0.7309)", "verif concept answer": "black bear(0.7310)", "verif image answer": "black bear(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000573374.jpg"}, {"question": "what kind of donuts are these", "gt answer": "glazed(1.00)<br/>yeast(0.60)", "pred answer": "donuts", "question_id": 3067985, "best approach": "concept", "verif answer": "sprinkle", "anno approach": "concept", "verif wiki answer": "sprinkle(0.6568)", "verif concept answer": "yeast(0.6762)", "verif image answer": "sprinkle(0.6812)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306798.jpg"}, {"question": "", "gt answer": "32 degree(0.60)", "pred answer": "rainy", "question_id": 3066815, "best approach": "", "verif answer": "rain", "anno approach": "", "verif wiki answer": "rain(0.6219)", "verif concept answer": "rain(0.6677)", "verif image answer": "rain(0.6445)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306681.jpg"}, {"question": "what company designed the e reader shown in the picture", "gt answer": "amazon(1.00)", "pred answer": "apple", "question_id": 1053885, "best approach": "", "verif answer": "walmart", "anno approach": "", "verif wiki answer": "store(0.6050)", "verif concept answer": "walmart(0.6400)", "verif image answer": "store(0.5419)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105388.jpg"}, {"question": "is this a luxury or economy suite", "gt answer": "luxury(1.00)", "pred answer": "illegal", "question_id": 5385475, "best approach": "", "verif answer": "content", "anno approach": "", "verif wiki answer": "hotel(0.6403)", "verif concept answer": "content(0.6919)", "verif image answer": "hotel(0.5006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538547.jpg"}, {"question": "if this player proceeds to hit a ball close to the ground for a short distance that is called a what", "gt answer": "bunt(1.00)<br/>foul(0.60)", "pred answer": "homerun", "question_id": 2471465, "best approach": "wiki", "verif answer": "foul", "anno approach": "wiki", "verif wiki answer": "foul(0.5186)", "verif concept answer": "ball(0.5035)", "verif image answer": "ball(0.5056)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247146.jpg"}, {"question": "what does 30 indicate on the sign", "gt answer": "speed limit(1.00)", "pred answer": "stop", "question_id": 5007125, "best approach": "wiki", "verif answer": "pasta", "anno approach": "wiki", "verif wiki answer": "speed limit(0.5162)", "verif concept answer": "turn(0.5229)", "verif image answer": "pasta(0.5566)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500712.jpg"}, {"question": "what kind of soap would be used on these", "gt answer": "dish soap(1.00)<br/>dawn(0.60)<br/>dish(0.60)", "pred answer": "american", "question_id": 4462665, "best approach": "image", "verif answer": "soap", "anno approach": "image", "verif wiki answer": "soap(0.6661)", "verif concept answer": "soap(0.6395)", "verif image answer": "dish soap(0.6631)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000446266.jpg"}, {"question": "what is the green vegetable on this plate called", "gt answer": "pickle(1.00)", "pred answer": "broccoli", "question_id": 3148225, "best approach": "wiki, concept, image", "verif answer": "pickle", "anno approach": "image, wiki", "verif wiki answer": "pickle(0.5608)", "verif concept answer": "pickle(0.5163)", "verif image answer": "pickle(0.5524)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314822.jpg"}, {"question": "what kind of a horse is this", "gt answer": "shetland(1.00)<br/>ride(0.60)<br/>arabian(0.60)", "pred answer": "mustang", "question_id": 1003375, "best approach": "", "verif answer": "mustang", "anno approach": "", "verif wiki answer": "mustang(0.7157)", "verif concept answer": "mustang(0.7168)", "verif image answer": "mustang(0.6850)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100337.jpg"}, {"question": "in what type or restaurant can you find this dish", "gt answer": "diner(1.00)<br/>deli(0.60)", "pred answer": "restaurant", "question_id": 683855, "best approach": "", "verif answer": "ihop", "anno approach": "", "verif wiki answer": "restaurant(0.6776)", "verif concept answer": "ihop(0.7022)", "verif image answer": "restaurant(0.6985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068385.jpg"}, {"question": "how are these shrimp prepared", "gt answer": "boiled(1.00)", "pred answer": "grilled", "question_id": 139495, "best approach": "wiki", "verif answer": "boiled", "anno approach": "wiki", "verif wiki answer": "boiled(0.6696)", "verif concept answer": "hard boiled(0.6440)", "verif image answer": "hard boiled(0.6298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013949.jpg"}, {"question": "what color is the elephant", "gt answer": "gray(1.00)<br/>grey(1.00)", "pred answer": "baby", "question_id": 272935, "best approach": "wiki, concept, image", "verif answer": "grey", "anno approach": "wiki", "verif wiki answer": "grey(0.6735)", "verif concept answer": "grey(0.6575)", "verif image answer": "grey(0.6327)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027293.jpg"}, {"question": "what festival is this", "gt answer": "annual(0.60)<br/>elephant(1.00)<br/>chinese new year(0.60)", "pred answer": "race", "question_id": 4220635, "best approach": "image", "verif answer": "annual", "anno approach": "image", "verif wiki answer": "herbivore(0.5695)", "verif concept answer": "herbivore(0.5820)", "verif image answer": "annual(0.6195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422063.jpg"}, {"question": "what brand of tooth brush is the man using", "gt answer": "oral b(1.00)<br/>crest(0.60)<br/>electric(0.60)<br/>colgate(0.60)", "pred answer": "colgate", "question_id": 5569545, "best approach": "wiki, concept, image", "verif answer": "crest", "anno approach": "wiki", "verif wiki answer": "crest(0.7256)", "verif concept answer": "crest(0.7094)", "verif image answer": "colgate(0.7027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556954.jpg"}, {"question": "what character is this umbrella designed after", "gt answer": "sock monkey(1.00)<br/>monkey(0.60)<br/>bear(0.60)", "pred answer": "halloween", "question_id": 575155, "best approach": "wiki, concept, image", "verif answer": "sock monkey", "anno approach": "", "verif wiki answer": "sock monkey(0.7309)", "verif concept answer": "sock monkey(0.7310)", "verif image answer": "sock monkey(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000057515.jpg"}, {"question": "what is this plane going to do next", "gt answer": "land(1.00)<br/>fly(1.00)", "pred answer": "take off", "question_id": 2126435, "best approach": "wiki, concept, image", "verif answer": "land", "anno approach": "concept, wiki", "verif wiki answer": "land(0.7145)", "verif concept answer": "land(0.7168)", "verif image answer": "fly(0.5782)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212643.jpg"}, {"question": "why wouldn't this animal be seen in a zoo", "gt answer": "pet(1.00)<br/>domesticated(0.60)<br/>domestic(0.60)", "pred answer": "tired", "question_id": 5412295, "best approach": "wiki, concept, image", "verif answer": "pet", "anno approach": "concept, wiki", "verif wiki answer": "pet(0.7264)", "verif concept answer": "pet(0.6717)", "verif image answer": "pet(0.6379)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541229.jpg"}, {"question": "what is the purpose of the object that the man is sitting on", "gt answer": "transportation(1.00)<br/>ride(0.60)<br/>transport(0.60)", "pred answer": "ride", "question_id": 4715295, "best approach": "wiki, concept, image", "verif answer": "transport", "anno approach": "image, wiki", "verif wiki answer": "transport(0.5091)", "verif concept answer": "transport(0.5251)", "verif image answer": "transport(0.5821)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471529.jpg"}, {"question": "what game is the boy playing", "gt answer": "wii bowl(1.00)<br/>wii(0.60)<br/>bowl(0.60)", "pred answer": "wii", "question_id": 1292055, "best approach": "wiki, concept", "verif answer": "video game", "anno approach": "wiki", "verif wiki answer": "wii(0.6667)", "verif concept answer": "wii(0.6753)", "verif image answer": "video game(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129205.jpg"}, {"question": "which type of glass is used for making this flower vase shown in this picture", "gt answer": "green(1.00)<br/>crystal(0.60)", "pred answer": "tempered", "question_id": 927295, "best approach": "", "verif answer": "fender", "anno approach": "", "verif wiki answer": "fender(0.6533)", "verif concept answer": "rose(0.5889)", "verif image answer": "fender(0.5231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092729.jpg"}, {"question": "what type of desert is on the tray in front", "gt answer": "cupcake(1.00)<br/>dessert(0.60)", "pred answer": "cake", "question_id": 2139995, "best approach": "", "verif answer": "cake", "anno approach": "", "verif wiki answer": "cake(0.6536)", "verif concept answer": "cake(0.6649)", "verif image answer": "cake(0.6769)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000213999.jpg"}, {"question": "what kind of dog is in the photo", "gt answer": "golden retriever(1.00)<br/>german shepard(0.60)", "pred answer": "poodle", "question_id": 103695, "best approach": "concept, image", "verif answer": "golden retriever", "anno approach": "image", "verif wiki answer": "retriever(0.6388)", "verif concept answer": "golden retriever(0.6189)", "verif image answer": "golden retriever(0.6827)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000010369.jpg"}, {"question": "what meat is in between the bread", "gt answer": "hot dog(1.00)<br/>sausage(0.60)<br/>hotdog(0.60)<br/>beef(0.60)", "pred answer": "pork", "question_id": 3512425, "best approach": "concept", "verif answer": "hotdogs", "anno approach": "concept", "verif wiki answer": "hotdogs(0.7181)", "verif concept answer": "hot dog(0.7271)", "verif image answer": "hotdogs(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351242.jpg"}, {"question": "what does it seem like these riders are doing", "gt answer": "hunt(1.00)<br/>horseback ride(0.60)", "pred answer": "play", "question_id": 5267136, "best approach": "concept", "verif answer": "race", "anno approach": "concept", "verif wiki answer": "work(0.6977)", "verif concept answer": "hunt(0.6658)", "verif image answer": "race(0.7108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526713.jpg"}, {"question": "is this a home or a store front model", "gt answer": "home(1.00)<br/>store(0.60)", "pred answer": "public", "question_id": 1422765, "best approach": "wiki, concept", "verif answer": "home", "anno approach": "wiki", "verif wiki answer": "home(0.7036)", "verif concept answer": "home(0.5632)", "verif image answer": "office(0.6923)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142276.jpg"}, {"question": "what type of dog is this", "gt answer": "border collie(1.00)<br/>sheep dog(0.60)", "pred answer": "mutt", "question_id": 2769515, "best approach": "wiki, concept, image", "verif answer": "border collie", "anno approach": "wiki", "verif wiki answer": "border collie(0.6872)", "verif concept answer": "border collie(0.6977)", "verif image answer": "border collie(0.6787)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276951.jpg"}, {"question": "how old is this baby", "gt answer": "3 months(1.00)<br/>6 months(0.60)", "pred answer": "1 year", "question_id": 2534305, "best approach": "", "verif answer": "2 weeks", "anno approach": "", "verif wiki answer": "2 weeks(0.6752)", "verif concept answer": "2 weeks(0.6671)", "verif image answer": "2 weeks(0.6631)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253430.jpg"}, {"question": "what type of animal is swimming", "gt answer": "duck(1.00)<br/>goose(0.60)<br/>bird(0.60)", "pred answer": "duck", "question_id": 3278055, "best approach": "wiki", "verif answer": "bird", "anno approach": "wiki", "verif wiki answer": "bird(0.7191)", "verif concept answer": "swan(0.7064)", "verif image answer": "swan(0.6747)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327805.jpg"}, {"question": "what is this train 's cargo", "gt answer": "car(1.00)<br/>good(0.60)<br/>vehicle(0.60)", "pred answer": "passenger", "question_id": 3670115, "best approach": "", "verif answer": "truck", "anno approach": "", "verif wiki answer": "truck(0.6782)", "verif concept answer": "truck(0.6877)", "verif image answer": "truck(0.6829)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367011.jpg"}, {"question": "what happened just before this picture was taken", "gt answer": "pitch(1.00)<br/>swing(0.60)", "pred answer": "hit ball", "question_id": 924285, "best approach": "", "verif answer": "hit ball", "anno approach": "", "verif wiki answer": "hit ball(0.7236)", "verif concept answer": "hit ball(0.6972)", "verif image answer": "hit ball(0.6221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092428.jpg"}, {"question": "what are these people waiting for", "gt answer": "bus(1.00)<br/>crosswalk(0.60)", "pred answer": "bus", "question_id": 4966735, "best approach": "wiki, concept, image", "verif answer": "bus", "anno approach": "image, wiki", "verif wiki answer": "bus(0.7260)", "verif concept answer": "bus(0.6554)", "verif image answer": "bus(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496673.jpg"}, {"question": "where is this", "gt answer": "small town(1.00)<br/>california(0.60)<br/>street(0.60)<br/>usa(0.60)", "pred answer": "street", "question_id": 4007025, "best approach": "wiki, concept, image", "verif answer": "small town", "anno approach": "image, concept", "verif wiki answer": "small town(0.6715)", "verif concept answer": "small town(0.7217)", "verif image answer": "small town(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400702.jpg"}, {"question": "how busy is the street near the hydrant", "gt answer": "not busy(1.00)<br/>not very(0.60)<br/>empty(0.60)", "pred answer": "very", "question_id": 1150035, "best approach": "wiki, concept", "verif answer": "empty", "anno approach": "wiki", "verif wiki answer": "empty(0.7190)", "verif concept answer": "empty(0.7166)", "verif image answer": "not at all(0.6364)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115003.jpg"}, {"question": "what brand is the mouse", "gt answer": "compaq(1.00)<br/>dell(0.60)", "pred answer": "logitech", "question_id": 4560095, "best approach": "concept", "verif answer": "logitech", "anno approach": "concept", "verif wiki answer": "logitech(0.7303)", "verif concept answer": "compaq(0.7266)", "verif image answer": "logitech(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456009.jpg"}, {"question": "", "gt answer": "chocolate chip cookie and ice cream(0.60)", "pred answer": "potato", "question_id": 4666275, "best approach": "wiki, concept, image", "verif answer": "chocolate chip cookie and ice cream", "anno approach": "wiki", "verif wiki answer": "chocolate chip cookie and ice cream(0.7041)", "verif concept answer": "chocolate chip cookie and ice cream(0.6969)", "verif image answer": "chocolate chip cookie and ice cream(0.6645)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466627.jpg"}, {"question": "what kind of park is this", "gt answer": "skate(1.00)<br/>skateboard(0.60)<br/>skate park(0.60)", "pred answer": "skate park", "question_id": 4094445, "best approach": "wiki, concept", "verif answer": "skatepark", "anno approach": "wiki", "verif wiki answer": "skate(0.7024)", "verif concept answer": "skate(0.6948)", "verif image answer": "skatepark(0.7081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409444.jpg"}, {"question": "what superstition is the cat known for", "gt answer": "bad luck(1.00)", "pred answer": "dog", "question_id": 5725845, "best approach": "wiki, concept, image", "verif answer": "bad luck", "anno approach": "wiki", "verif wiki answer": "bad luck(0.7290)", "verif concept answer": "bad luck(0.7289)", "verif image answer": "bad luck(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572584.jpg"}, {"question": "the grains shown in the picture is good for which part of the body", "gt answer": "brain(1.00)<br/>protein(0.60)<br/>stomach(0.60)", "pred answer": "brain", "question_id": 5117365, "best approach": "wiki, concept", "verif answer": "muscle", "anno approach": "wiki", "verif wiki answer": "brain(0.6653)", "verif concept answer": "brain(0.6803)", "verif image answer": "muscle(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511736.jpg"}, {"question": "is the lead cycle meeting safety requirements or is he unsafe", "gt answer": "safe(1.00)<br/>meet(0.60)", "pred answer": "broken", "question_id": 5057385, "best approach": "concept", "verif answer": "out", "anno approach": "concept", "verif wiki answer": "out(0.6683)", "verif concept answer": "meet(0.7010)", "verif image answer": "out(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505738.jpg"}, {"question": "what emblem is displayed on these airplanes", "gt answer": "maple leaf(1.00)<br/>canada(0.60)<br/>leaf(0.60)", "pred answer": "maple leaf", "question_id": 638205, "best approach": "wiki, concept", "verif answer": "maple leaf", "anno approach": "", "verif wiki answer": "maple leaf(0.7253)", "verif concept answer": "maple leaf(0.7153)", "verif image answer": "leaf(0.6939)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063820.jpg"}, {"question": "what are the risks with being outdoors in cold weather during the winter", "gt answer": "frostbite(1.00)<br/>freeze(0.60)<br/>cold(0.60)", "pred answer": "fall", "question_id": 5368555, "best approach": "wiki, concept", "verif answer": "ski", "anno approach": "wiki", "verif wiki answer": "freeze(0.6731)", "verif concept answer": "freeze(0.6559)", "verif image answer": "ski(0.6800)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536855.jpg"}, {"question": "which city is this street corner at", "gt answer": "berlin(1.00)<br/>amsterdam(0.60)", "pred answer": "berlin", "question_id": 2240425, "best approach": "", "verif answer": "new york", "anno approach": "", "verif wiki answer": "new york(0.6758)", "verif concept answer": "new york(0.6727)", "verif image answer": "new york(0.6780)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224042.jpg"}, {"question": "", "gt answer": "small(0.60)<br/>19 inch(0.60)", "pred answer": "medium", "question_id": 1602595, "best approach": "", "verif answer": "crow", "anno approach": "", "verif wiki answer": "crow(0.6622)", "verif concept answer": "crow(0.7001)", "verif image answer": "crow(0.6917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160259.jpg"}, {"question": "what motorcycle brand is this", "gt answer": "honda(1.00)<br/>kawasaki(1.00)<br/>suzuki(0.60)", "pred answer": "honda", "question_id": 3710215, "best approach": "wiki, concept, image", "verif answer": "kawasaki", "anno approach": "wiki", "verif wiki answer": "kawasaki(0.7213)", "verif concept answer": "kawasaki(0.7220)", "verif image answer": "kawasaki(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371021.jpg"}, {"question": "why to the eyes glow in the camera", "gt answer": "reflection(1.00)", "pred answer": "reflection", "question_id": 5554935, "best approach": "concept", "verif answer": "shade", "anno approach": "concept", "verif wiki answer": "shade(0.6949)", "verif concept answer": "reflection(0.7041)", "verif image answer": "shade(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555493.jpg"}, {"question": "", "gt answer": "1900's(0.60)<br/>1914(0.60)<br/>1930(0.60)", "pred answer": "1970", "question_id": 2084185, "best approach": "wiki, concept, image", "verif answer": "1914", "anno approach": "", "verif wiki answer": "1914(0.6745)", "verif concept answer": "1914(0.6968)", "verif image answer": "1914(0.6728)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208418.jpg"}, {"question": "what brand of shoe is the boy wearing", "gt answer": "nike(1.00)", "pred answer": "adidas", "question_id": 3767505, "best approach": "image", "verif answer": "shoemaker", "anno approach": "image", "verif wiki answer": "shoemaker(0.6892)", "verif concept answer": "shoemaker(0.6847)", "verif image answer": "nike(0.6793)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376750.jpg"}, {"question": "what type of finish are the appliances in this photo", "gt answer": "stainless steel(1.00)<br/>silver(0.60)", "pred answer": "stainless steel", "question_id": 3509605, "best approach": "wiki, concept, image", "verif answer": "stainless steel", "anno approach": "wiki", "verif wiki answer": "stainless steel(0.7304)", "verif concept answer": "stainless steel(0.7307)", "verif image answer": "stainless steel(0.7083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350960.jpg"}, {"question": "what is main purpose of items in the picture", "gt answer": "provide water(1.00)<br/>water(0.60)", "pred answer": "safety", "question_id": 792985, "best approach": "wiki", "verif answer": "provide water", "anno approach": "wiki", "verif wiki answer": "provide water(0.6374)", "verif concept answer": "art(0.6068)", "verif image answer": "water(0.6241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079298.jpg"}, {"question": "what activity is this person doing", "gt answer": "game(1.00)<br/>play(0.60)", "pred answer": "video game", "question_id": 352165, "best approach": "image", "verif answer": "game", "anno approach": "image", "verif wiki answer": "football(0.7190)", "verif concept answer": "video game(0.6884)", "verif image answer": "game(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000035216.jpg"}, {"question": "would you have travel far or nearto get here", "gt answer": "far(1.00)", "pred answer": "slope", "question_id": 3228695, "best approach": "", "verif answer": "105 feet", "anno approach": "", "verif wiki answer": "105 feet(0.5075)", "verif concept answer": "105 feet(0.5728)", "verif image answer": "105 feet(0.5013)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322869.jpg"}, {"question": "where are the centerpieces found", "gt answer": "on table(1.00)<br/>table(1.00)<br/>garden(0.60)", "pred answer": "table", "question_id": 3105015, "best approach": "concept, image", "verif answer": "garden", "anno approach": "concept", "verif wiki answer": "garden(0.6973)", "verif concept answer": "on table(0.6737)", "verif image answer": "on table(0.6187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310501.jpg"}, {"question": "what major us retailer was this animal used as the mascot for", "gt answer": "toy r us(1.00)<br/>zoo(0.60)", "pred answer": "toy r us", "question_id": 1799535, "best approach": "concept", "verif answer": "sit", "anno approach": "concept", "verif wiki answer": "giraffe(0.7010)", "verif concept answer": "toy r us(0.6921)", "verif image answer": "sit(0.7181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000179953.jpg"}, {"question": "what handedness would you guess the girl in the image has right or left", "gt answer": "right(1.00)<br/>left(0.60)", "pred answer": "left", "question_id": 4359635, "best approach": "wiki, concept, image", "verif answer": "left", "anno approach": "wiki", "verif wiki answer": "left(0.7264)", "verif concept answer": "left(0.7168)", "verif image answer": "left(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435963.jpg"}, {"question": "what is the sun setting behind", "gt answer": "wall(1.00)<br/>bridge(0.60)<br/>tree(0.60)", "pred answer": "tree", "question_id": 4954575, "best approach": "wiki, concept, image", "verif answer": "tree", "anno approach": "wiki", "verif wiki answer": "tree(0.6937)", "verif concept answer": "tree(0.6975)", "verif image answer": "tree(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495457.jpg"}, {"question": "what is the gender of the person in the image", "gt answer": "male(1.00)<br/>female(0.60)", "pred answer": "female", "question_id": 424635, "best approach": "concept", "verif answer": "british", "anno approach": "concept", "verif wiki answer": "british(0.7271)", "verif concept answer": "female(0.7152)", "verif image answer": "men(0.7097)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042463.jpg"}, {"question": "what tooth is named after this animal", "gt answer": "canine(1.00)", "pred answer": "canine", "question_id": 3556035, "best approach": "wiki, concept, image", "verif answer": "canine", "anno approach": "wiki", "verif wiki answer": "canine(0.7310)", "verif concept answer": "canine(0.7301)", "verif image answer": "canine(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355603.jpg"}, {"question": "what is the cat looking through", "gt answer": "window(1.00)", "pred answer": "window", "question_id": 512815, "best approach": "", "verif answer": "mac", "anno approach": "", "verif wiki answer": "door(0.7103)", "verif concept answer": "car(0.7099)", "verif image answer": "mac(0.7124)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000051281.jpg"}, {"question": "what sport is this person participating in", "gt answer": "water ski(1.00)<br/>jet ski(0.60)<br/>yacht(0.60)<br/>water(0.60)", "pred answer": "polo", "question_id": 2592495, "best approach": "concept, image", "verif answer": "boat", "anno approach": "", "verif wiki answer": "boat(0.6555)", "verif concept answer": "water ski(0.6040)", "verif image answer": "water ski(0.6328)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259249.jpg"}, {"question": "what type of camera was this taken from", "gt answer": "security camera(1.00)<br/>canon(0.60)", "pred answer": "fisheye", "question_id": 1439655, "best approach": "", "verif answer": "girl", "anno approach": "", "verif wiki answer": "digital(0.5001)", "verif concept answer": "girl(0.5000)", "verif image answer": "girl(0.5088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143965.jpg"}, {"question": "how long did it take to climb this mountain", "gt answer": "6 hours(1.00)<br/>1 hour(0.60)", "pred answer": "10 minutes", "question_id": 3820325, "best approach": "", "verif answer": "2 hours", "anno approach": "", "verif wiki answer": "8 hours(0.6556)", "verif concept answer": "8 hours(0.6656)", "verif image answer": "2 hours(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382032.jpg"}, {"question": "what is the mouse attached to", "gt answer": "cord(1.00)<br/>computer(0.60)<br/>keyboard(0.60)<br/>wire(0.60)", "pred answer": "wire", "question_id": 854835, "best approach": "wiki, concept, image", "verif answer": "wire", "anno approach": "wiki", "verif wiki answer": "wire(0.7223)", "verif concept answer": "wire(0.6668)", "verif image answer": "wire(0.6630)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085483.jpg"}, {"question": "where in the supermarket would you find this food", "gt answer": "deli(1.00)", "pred answer": "grocery", "question_id": 3278765, "best approach": "", "verif answer": "taco", "anno approach": "", "verif wiki answer": "taco(0.6915)", "verif concept answer": "taco(0.6925)", "verif image answer": "taco(0.6818)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327876.jpg"}, {"question": "what food is this", "gt answer": "carrot cake(1.00)<br/>cake(1.00)", "pred answer": "cake", "question_id": 3909915, "best approach": "wiki, concept, image", "verif answer": "carrot cake", "anno approach": "concept, wiki", "verif wiki answer": "carrot cake(0.6970)", "verif concept answer": "carrot cake(0.6906)", "verif image answer": "cake(0.6458)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390991.jpg"}, {"question": "these types of bears typically belong on what continent", "gt answer": "antarctica(1.00)<br/>north america(0.60)", "pred answer": "arctic", "question_id": 1131505, "best approach": "concept", "verif answer": "north america", "anno approach": "concept", "verif wiki answer": "north pole(0.6914)", "verif concept answer": "north america(0.7169)", "verif image answer": "north pole(0.7115)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113150.jpg"}, {"question": "the ads are for which company", "gt answer": "gucci(1.00)", "pred answer": "tony hawk", "question_id": 1484805, "best approach": "wiki, concept, image", "verif answer": "gucci", "anno approach": "wiki", "verif wiki answer": "gucci(0.7219)", "verif concept answer": "gucci(0.7139)", "verif image answer": "gucci(0.6968)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148480.jpg"}, {"question": "what is the name of this flower", "gt answer": "morn glory(1.00)<br/>lily(0.60)<br/>orchid(0.60)", "pred answer": "rose", "question_id": 1563265, "best approach": "wiki, concept, image", "verif answer": "lily", "anno approach": "image, wiki", "verif wiki answer": "lily(0.5017)", "verif concept answer": "lily(0.5159)", "verif image answer": "lily(0.5592)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000156326.jpg"}, {"question": "what material is the bathtub made out of", "gt answer": "ceramic(1.00)<br/>steel(0.60)<br/>metal(0.60)", "pred answer": "wood", "question_id": 4948175, "best approach": "concept, image", "verif answer": "metal", "anno approach": "", "verif wiki answer": "metal(0.6996)", "verif concept answer": "ceramic(0.6716)", "verif image answer": "ceramic(0.6716)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494817.jpg"}, {"question": "what kind of dog is that", "gt answer": "corgi(1.00)<br/>pomeranian(0.60)", "pred answer": "teddy bear", "question_id": 950505, "best approach": "image", "verif answer": "corgi", "anno approach": "image", "verif wiki answer": "beagle(0.6750)", "verif concept answer": "beagle(0.6821)", "verif image answer": "corgi(0.6948)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000095050.jpg"}, {"question": "how many points do you play to in a tennis match", "gt answer": "48(1.00)<br/>45(0.60)<br/>wind(0.60)<br/>100(0.60)", "pred answer": "21", "question_id": 4326835, "best approach": "concept, image", "verif answer": "forty", "anno approach": "", "verif wiki answer": "forty(0.6972)", "verif concept answer": "100(0.6706)", "verif image answer": "45(0.6788)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432683.jpg"}, {"question": "why is the player touching the other player", "gt answer": "tag(1.00)<br/>out(0.60)<br/>accident(0.60)", "pred answer": "run", "question_id": 3811165, "best approach": "", "verif answer": "safe", "anno approach": "", "verif wiki answer": "safe(0.6870)", "verif concept answer": "safe(0.6944)", "verif image answer": "safe(0.7222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381116.jpg"}, {"question": "what type of sandwich is this", "gt answer": "ruben(1.00)<br/>reuben(0.60)<br/>roast beef(0.60)", "pred answer": "roast beef", "question_id": 134685, "best approach": "image", "verif answer": "roast beef", "anno approach": "image", "verif wiki answer": "roast beef(0.6928)", "verif concept answer": "roast beef(0.6681)", "verif image answer": "ruben(0.6907)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013468.jpg"}, {"question": "what kinds of phones are they using", "gt answer": "smartphone(1.00)<br/>blackberry(0.60)", "pred answer": "iphone", "question_id": 600415, "best approach": "", "verif answer": "iphone", "anno approach": "", "verif wiki answer": "iphone(0.6988)", "verif concept answer": "iphone(0.7030)", "verif image answer": "iphone(0.7110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060041.jpg"}, {"question": "where is this scene usually seen", "gt answer": "las vegas(1.00)<br/>light(0.60)<br/>city(0.60)", "pred answer": "city", "question_id": 2839135, "best approach": "wiki", "verif answer": "las vegas", "anno approach": "wiki", "verif wiki answer": "las vegas(0.7210)", "verif concept answer": "spain(0.7099)", "verif image answer": "spain(0.7029)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283913.jpg"}, {"question": "what are these boys doing", "gt answer": "play video game(1.00)<br/>video game(0.60)", "pred answer": "video game", "question_id": 547385, "best approach": "wiki", "verif answer": "play video game", "anno approach": "wiki", "verif wiki answer": "play video game(0.7105)", "verif concept answer": "play wii(0.7099)", "verif image answer": "video game(0.6964)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054738.jpg"}, {"question": "what is this train riding on", "gt answer": "rail(1.00)<br/>track(1.00)", "pred answer": "track", "question_id": 4413875, "best approach": "wiki, concept, image", "verif answer": "track", "anno approach": "concept, wiki", "verif wiki answer": "track(0.6989)", "verif concept answer": "track(0.6989)", "verif image answer": "rail(0.6652)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441387.jpg"}, {"question": "what breed of horse is this", "gt answer": "thoroughbred(1.00)<br/>stallion(0.60)", "pred answer": "clydesdale", "question_id": 1267095, "best approach": "", "verif answer": "clydesdale", "anno approach": "", "verif wiki answer": "clydesdale(0.6842)", "verif concept answer": "clydesdale(0.6983)", "verif image answer": "clydesdale(0.6917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126709.jpg"}, {"question": "what type of food is this", "gt answer": "stir fry(1.00)<br/>ramen(0.60)<br/>italian(0.60)", "pred answer": "vegetarian", "question_id": 2837155, "best approach": "wiki, image", "verif answer": "ramen", "anno approach": "wiki", "verif wiki answer": "ramen(0.6261)", "verif concept answer": "thai(0.6485)", "verif image answer": "ramen(0.6551)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283715.jpg"}, {"question": "who manufactures these vehicles", "gt answer": "ford(1.00)<br/>chevy(0.60)<br/>dodge(0.60)", "pred answer": "honda", "question_id": 2177695, "best approach": "wiki, concept", "verif answer": "ford", "anno approach": "wiki", "verif wiki answer": "ford(0.6908)", "verif concept answer": "ford(0.6612)", "verif image answer": "bus(0.6619)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217769.jpg"}, {"question": "can you tell me the place where this building is seen", "gt answer": "mexico(1.00)<br/>london(0.60)<br/>street(0.60)<br/>city(0.60)", "pred answer": "texas", "question_id": 1251685, "best approach": "", "verif answer": "india", "anno approach": "", "verif wiki answer": "india(0.7014)", "verif concept answer": "india(0.7051)", "verif image answer": "india(0.7059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125168.jpg"}, {"question": "what is the man doing", "gt answer": "tai chi(1.00)<br/>catch(0.60)<br/>fly kite(0.60)<br/>throw frisbee(0.60)", "pred answer": "kite fly", "question_id": 3721995, "best approach": "wiki, concept, image", "verif answer": "throw frisbee", "anno approach": "", "verif wiki answer": "throw frisbee(0.7308)", "verif concept answer": "throw frisbee(0.7186)", "verif image answer": "fly kite(0.7029)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372199.jpg"}, {"question": "is this a snack or meal", "gt answer": "snack(1.00)", "pred answer": "meal", "question_id": 2851305, "best approach": "", "verif answer": "meal", "anno approach": "", "verif wiki answer": "meal(0.6526)", "verif concept answer": "meal(0.5905)", "verif image answer": "meal(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285130.jpg"}, {"question": "what is the vegetable being cut on", "gt answer": "board(1.00)<br/>cucumber(0.60)", "pred answer": "dough", "question_id": 1913385, "best approach": "", "verif answer": "water", "anno approach": "", "verif wiki answer": "water(0.5968)", "verif concept answer": "water(0.6456)", "verif image answer": "water(0.5813)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191338.jpg"}, {"question": "how old is this child", "gt answer": "5(1.00)<br/>6(1.00)<br/>2(0.60)", "pred answer": "3", "question_id": 5232205, "best approach": "wiki", "verif answer": "3", "anno approach": "wiki", "verif wiki answer": "2(0.6785)", "verif concept answer": "3(0.6570)", "verif image answer": "3(0.6957)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523220.jpg"}, {"question": "who lives at this relgious facility", "gt answer": "priest(1.00)", "pred answer": "school", "question_id": 2573505, "best approach": "wiki, concept, image", "verif answer": "priest", "anno approach": "wiki", "verif wiki answer": "priest(0.7285)", "verif concept answer": "priest(0.7257)", "verif image answer": "priest(0.7203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257350.jpg"}, {"question": "in what city are these people getting their picture taken", "gt answer": "boston(1.00)<br/>new york city(0.60)<br/>seattle(0.60)", "pred answer": "new york city", "question_id": 3451045, "best approach": "", "verif answer": "new york", "anno approach": "", "verif wiki answer": "new york(0.6926)", "verif concept answer": "new york(0.6910)", "verif image answer": "new york(0.7075)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345104.jpg"}, {"question": "what vehicle is this", "gt answer": "car(1.00)<br/>audi(0.60)", "pred answer": "bicycle", "question_id": 3629445, "best approach": "wiki, concept, image", "verif answer": "car", "anno approach": "wiki", "verif wiki answer": "car(0.6260)", "verif concept answer": "car(0.6179)", "verif image answer": "car(0.5956)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362944.jpg"}, {"question": "what kind of dog is this", "gt answer": "poodle(1.00)<br/>faux(0.60)", "pred answer": "chow", "question_id": 2860095, "best approach": "wiki, concept, image", "verif answer": "faux", "anno approach": "image, wiki", "verif wiki answer": "faux(0.6294)", "verif concept answer": "faux(0.6229)", "verif image answer": "faux(0.6946)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000286009.jpg"}, {"question": "what are they standing in", "gt answer": "truck(1.00)<br/>vehicle(0.60)", "pred answer": "fire", "question_id": 2680365, "best approach": "", "verif answer": "van", "anno approach": "", "verif wiki answer": "van(0.5816)", "verif concept answer": "van(0.6540)", "verif image answer": "4 wheeler(0.6056)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268036.jpg"}, {"question": "what types of fruit are these", "gt answer": "orange and lime(1.00)<br/>citrus(0.60)<br/>orange(0.60)", "pred answer": "orange", "question_id": 4570505, "best approach": "wiki, concept", "verif answer": "orange and lime", "anno approach": "", "verif wiki answer": "orange and lime(0.7271)", "verif concept answer": "orange and lime(0.7292)", "verif image answer": "orange(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457050.jpg"}, {"question": "how are the napkins folded", "gt answer": "in half(1.00)<br/>triangle(1.00)", "pred answer": "knife", "question_id": 2685485, "best approach": "wiki, concept", "verif answer": "in half", "anno approach": "", "verif wiki answer": "in half(0.5010)", "verif concept answer": "in half(0.5001)", "verif image answer": "table(0.5006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268548.jpg"}, {"question": "what is the girl in the middle wearing on her head", "gt answer": "headband(1.00)<br/>hat(0.60)", "pred answer": "hat", "question_id": 3543275, "best approach": "wiki, concept, image", "verif answer": "hat", "anno approach": "wiki", "verif wiki answer": "hat(0.7292)", "verif concept answer": "hat(0.7022)", "verif image answer": "hat(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354327.jpg"}, {"question": "the baked good shown on the image was invented in which country", "gt answer": "america(1.00)<br/>germany(0.60)<br/>great britain(0.60)", "pred answer": "america", "question_id": 3241655, "best approach": "wiki, concept, image", "verif answer": "great britain", "anno approach": "wiki", "verif wiki answer": "great britain(0.6969)", "verif concept answer": "great britain(0.6771)", "verif image answer": "great britain(0.6888)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324165.jpg"}, {"question": "what does this land on", "gt answer": "runway(1.00)", "pred answer": "runway", "question_id": 367835, "best approach": "", "verif answer": "tarmac", "anno approach": "", "verif wiki answer": "tarmac(0.6861)", "verif concept answer": "tarmac(0.6785)", "verif image answer": "tarmac(0.6702)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036783.jpg"}, {"question": "what nationality eats this type of food", "gt answer": "mexican(1.00)<br/>mexico(0.60)<br/>asian(0.60)", "pred answer": "american", "question_id": 2126105, "best approach": "concept, image", "verif answer": "asian", "anno approach": "concept", "verif wiki answer": "china(0.6615)", "verif concept answer": "asian(0.6743)", "verif image answer": "asian(0.6276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212610.jpg"}, {"question": "what type of show is this", "gt answer": "news(1.00)", "pred answer": "birthday", "question_id": 2212235, "best approach": "", "verif answer": "sport", "anno approach": "", "verif wiki answer": "crt(0.6004)", "verif concept answer": "crt(0.6411)", "verif image answer": "sport(0.6501)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221223.jpg"}, {"question": "what could these children be watching", "gt answer": "cartoon(1.00)<br/>television(0.60)", "pred answer": "map", "question_id": 3721985, "best approach": "", "verif answer": "movie", "anno approach": "", "verif wiki answer": "movie(0.7310)", "verif concept answer": "movie(0.6397)", "verif image answer": "movie(0.6950)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372198.jpg"}, {"question": "why have these people gathered", "gt answer": "protest(1.00)", "pred answer": "parade", "question_id": 2855635, "best approach": "wiki, concept, image", "verif answer": "protest", "anno approach": "concept, wiki", "verif wiki answer": "protest(0.7137)", "verif concept answer": "protest(0.7121)", "verif image answer": "protest(0.6434)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285563.jpg"}, {"question": "what language is that written in yellow", "gt answer": "chinese(1.00)<br/>japanese(0.60)", "pred answer": "spanish", "question_id": 4254805, "best approach": "", "verif answer": "asia", "anno approach": "", "verif wiki answer": "asia(0.6005)", "verif concept answer": "asia(0.5854)", "verif image answer": "asia(0.6594)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425480.jpg"}, {"question": "what is the man wearing on his head", "gt answer": "beanie(1.00)<br/>cap(0.60)", "pred answer": "hat", "question_id": 1382175, "best approach": "", "verif answer": "fedora", "anno approach": "", "verif wiki answer": "turban(0.7309)", "verif concept answer": "turban(0.7309)", "verif image answer": "fedora(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138217.jpg"}, {"question": "what kind of jewelry does she have on", "gt answer": "earring(1.00)", "pred answer": "leather", "question_id": 5201555, "best approach": "concept, image", "verif answer": "suspend", "anno approach": "image", "verif wiki answer": "suspend(0.7208)", "verif concept answer": "earring(0.6552)", "verif image answer": "earring(0.7008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520155.jpg"}, {"question": "which essential food group is missing", "gt answer": "grain(1.00)<br/>dairy(1.00)<br/>meat(0.60)", "pred answer": "egg", "question_id": 5179855, "best approach": "wiki, concept, image", "verif answer": "dairy", "anno approach": "wiki", "verif wiki answer": "dairy(0.6945)", "verif concept answer": "dairy(0.7084)", "verif image answer": "dairy(0.7202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517985.jpg"}, {"question": "what is someone called who can't see this color", "gt answer": "colorblind(1.00)", "pred answer": "man", "question_id": 3410655, "best approach": "image", "verif answer": "colorblind", "anno approach": "image", "verif wiki answer": "reflection(0.6887)", "verif concept answer": "reflection(0.7186)", "verif image answer": "colorblind(0.7226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341065.jpg"}, {"question": "what is the man 's belt a reference to", "gt answer": "rasta(1.00)<br/>gay(0.60)", "pred answer": "skateboard", "question_id": 2842465, "best approach": "wiki, concept, image", "verif answer": "rasta", "anno approach": "wiki", "verif wiki answer": "rasta(0.6532)", "verif concept answer": "rasta(0.6163)", "verif image answer": "rasta(0.6342)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284246.jpg"}, {"question": "what decade was this style of kitchen popular", "gt answer": "1970's(1.00)<br/>1960's(0.60)<br/>1960(0.60)", "pred answer": "70s", "question_id": 5700665, "best approach": "wiki, concept, image", "verif answer": "1960", "anno approach": "image", "verif wiki answer": "1960's(0.5908)", "verif concept answer": "1960's(0.6050)", "verif image answer": "1960(0.6409)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570066.jpg"}, {"question": "what religion holds these animals as sacred", "gt answer": "hindu(1.00)<br/>muslim(0.60)", "pred answer": "hindu", "question_id": 2974885, "best approach": "", "verif answer": "islam", "anno approach": "", "verif wiki answer": "islam(0.7255)", "verif concept answer": "islam(0.7183)", "verif image answer": "islam(0.6891)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297488.jpg"}, {"question": "is this a wild or domestic animal", "gt answer": "domestic(1.00)", "pred answer": "domestic", "question_id": 970295, "best approach": "concept, image", "verif answer": "domestic", "anno approach": "", "verif wiki answer": "calico(0.7283)", "verif concept answer": "domestic(0.7284)", "verif image answer": "domestic(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097029.jpg"}, {"question": "if you're healthy than you are in the what color shown here", "gt answer": "pink(1.00)<br/>green(1.00)", "pred answer": "green", "question_id": 3969245, "best approach": "", "verif answer": "fender", "anno approach": "", "verif wiki answer": "leaf(0.6882)", "verif concept answer": "red(0.6507)", "verif image answer": "fender(0.6982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396924.jpg"}, {"question": "what type of train is pictured here", "gt answer": "passenger train(1.00)<br/>cargo(0.60)<br/>amtrack(0.60)<br/>green(0.60)", "pred answer": "freight", "question_id": 5374125, "best approach": "image", "verif answer": "amtrack", "anno approach": "image", "verif wiki answer": "freight(0.6380)", "verif concept answer": "freight(0.6161)", "verif image answer": "amtrack(0.6383)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537412.jpg"}, {"question": "which part of the body should this equipment be worn on", "gt answer": "feet(1.00)", "pred answer": "arm", "question_id": 3610305, "best approach": "", "verif answer": "people", "anno approach": "", "verif wiki answer": "people(0.5594)", "verif concept answer": "leg(0.5294)", "verif image answer": "leg(0.5134)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361030.jpg"}, {"question": "what is it called to cut carrots like this", "gt answer": "julienne(1.00)<br/>slice(1.00)", "pred answer": "grilled", "question_id": 2299755, "best approach": "concept, image", "verif answer": "slice", "anno approach": "image", "verif wiki answer": "cut(0.5101)", "verif concept answer": "slice(0.6250)", "verif image answer": "slice(0.7257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000229975.jpg"}, {"question": "what effect does this beverage have", "gt answer": "drunk(1.00)<br/>calm(0.60)<br/>intoxication(0.60)", "pred answer": "wine", "question_id": 4724325, "best approach": "concept, image", "verif answer": "light", "anno approach": "concept", "verif wiki answer": "light(0.7264)", "verif concept answer": "calm(0.6406)", "verif image answer": "intoxication(0.5529)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000472432.jpg"}, {"question": "what type of chicken is this", "gt answer": "rooster(1.00)", "pred answer": "vulture", "question_id": 4130885, "best approach": "", "verif answer": "grilled", "anno approach": "", "verif wiki answer": "grilled(0.7234)", "verif concept answer": "grilled(0.7291)", "verif image answer": "grilled(0.6592)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000413088.jpg"}, {"question": "what device is normally used to lead these animals", "gt answer": "rein(1.00)<br/>rain(0.60)", "pred answer": "horse", "question_id": 1517315, "best approach": "", "verif answer": "saddle", "anno approach": "", "verif wiki answer": "saddle(0.6742)", "verif concept answer": "saddle(0.6679)", "verif image answer": "saddle(0.6695)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151731.jpg"}, {"question": "what language do the people in this country speak", "gt answer": "chinese(1.00)<br/>english(0.60)<br/>korean(0.60)", "pred answer": "french", "question_id": 4535335, "best approach": "wiki, concept, image", "verif answer": "english", "anno approach": "wiki", "verif wiki answer": "english(0.7160)", "verif concept answer": "english(0.6665)", "verif image answer": "english(0.6360)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453533.jpg"}, {"question": "what effect would be experienced from too much of the beverage", "gt answer": "drunk(1.00)<br/>intoxication(0.60)", "pred answer": "black and white", "question_id": 4492385, "best approach": "image", "verif answer": "calm", "anno approach": "image", "verif wiki answer": "calm(0.6508)", "verif concept answer": "calm(0.6339)", "verif image answer": "intoxication(0.5979)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449238.jpg"}, {"question": "what movie has the same color scheme as the picture", "gt answer": "schindler's list(1.00)<br/>black and white(0.60)<br/>color(0.60)", "pred answer": "coca cola", "question_id": 3216015, "best approach": "", "verif answer": "long exposure", "anno approach": "", "verif wiki answer": "long exposure(0.5295)", "verif concept answer": "long exposure(0.6875)", "verif image answer": "long exposure(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321601.jpg"}, {"question": "what is the lifespan of this animal", "gt answer": "15 years(1.00)<br/>20(0.60)", "pred answer": "10 years", "question_id": 5673465, "best approach": "concept", "verif answer": "10 years", "anno approach": "concept", "verif wiki answer": "10 years(0.6852)", "verif concept answer": "20(0.6680)", "verif image answer": "10 years(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567346.jpg"}, {"question": "who is advertising in this park", "gt answer": "coca cola(1.00)", "pred answer": "tony hawk", "question_id": 261645, "best approach": "", "verif answer": "coco cola", "anno approach": "", "verif wiki answer": "coco cola(0.5650)", "verif concept answer": "coco cola(0.6298)", "verif image answer": "coco cola(0.5302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000026164.jpg"}, {"question": "is this bed larger smaller or the same size as a twin bed", "gt answer": "larger(1.00)", "pred answer": "twin", "question_id": 787605, "best approach": "", "verif answer": "right fork", "anno approach": "", "verif wiki answer": "right fork(0.7282)", "verif concept answer": "right fork(0.7289)", "verif image answer": "right fork(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078760.jpg"}, {"question": "what geometric shape is the patch on the elephant", "gt answer": "diamond(1.00)", "pred answer": "rectangle", "question_id": 2855705, "best approach": "wiki, concept, image", "verif answer": "diamond", "anno approach": "wiki", "verif wiki answer": "diamond(0.6917)", "verif concept answer": "diamond(0.6757)", "verif image answer": "diamond(0.6624)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285570.jpg"}, {"question": "how many wheels does this vehicle have normally", "gt answer": "18(1.00)", "pred answer": "4", "question_id": 4358395, "best approach": "", "verif answer": "21", "anno approach": "", "verif wiki answer": "21(0.6560)", "verif concept answer": "10(0.6706)", "verif image answer": "21(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435839.jpg"}, {"question": "what brand of jackets are they wearing and what brand of skis are they using", "gt answer": "north face(1.00)<br/>rei(0.60)<br/>columbia(0.60)", "pred answer": "columbia", "question_id": 2408205, "best approach": "image", "verif answer": "north face", "anno approach": "image", "verif wiki answer": "burton(0.6703)", "verif concept answer": "burton(0.6501)", "verif image answer": "north face(0.6775)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240820.jpg"}, {"question": "how long of a runway is required for a small plane to take off", "gt answer": "6000 feet(1.00)", "pred answer": "20 feet", "question_id": 4798995, "best approach": "image", "verif answer": "6000 feet", "anno approach": "image", "verif wiki answer": "1 mile(0.6682)", "verif concept answer": "1 mile(0.6480)", "verif image answer": "6000 feet(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479899.jpg"}, {"question": "what kind of motorcycle is this mirror on", "gt answer": "scooter(1.00)<br/>black(0.60)<br/>harley davidson(0.60)", "pred answer": "honda", "question_id": 3545455, "best approach": "wiki, concept, image", "verif answer": "scooter", "anno approach": "wiki", "verif wiki answer": "scooter(0.7060)", "verif concept answer": "scooter(0.7011)", "verif image answer": "scooter(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354545.jpg"}, {"question": "where is this", "gt answer": "mountain(1.00)<br/>alaska(0.60)", "pred answer": "mountain", "question_id": 5528135, "best approach": "image", "verif answer": "north america", "anno approach": "image", "verif wiki answer": "alp(0.6988)", "verif concept answer": "north america(0.7141)", "verif image answer": "mountain(0.6950)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552813.jpg"}, {"question": "where was the green thing pictured invented", "gt answer": "philadelphia(1.00)<br/>vest(0.60)<br/>1980(0.60)<br/>america(0.60)", "pred answer": "america", "question_id": 5552375, "best approach": "wiki, concept", "verif answer": "london", "anno approach": "", "verif wiki answer": "1980(0.6203)", "verif concept answer": "1980(0.6368)", "verif image answer": "london(0.7022)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555237.jpg"}, {"question": "what is the name of the song belonging to the lyrics", "gt answer": "bohemian rhapsody(1.00)", "pred answer": "black and white", "question_id": 4412635, "best approach": "", "verif answer": "onion", "anno approach": "", "verif wiki answer": "onion(0.6023)", "verif concept answer": "onion(0.6187)", "verif image answer": "onion(0.7273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441263.jpg"}, {"question": "where would you find an umbrella like the one shown", "gt answer": "patio(1.00)<br/>beach(0.60)", "pred answer": "house", "question_id": 2564745, "best approach": "wiki, concept, image", "verif answer": "patio", "anno approach": "wiki", "verif wiki answer": "patio(0.7041)", "verif concept answer": "patio(0.7043)", "verif image answer": "patio(0.6870)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256474.jpg"}, {"question": "where are these people relaxing at", "gt answer": "park(1.00)", "pred answer": "park", "question_id": 4074005, "best approach": "wiki, concept", "verif answer": "park", "anno approach": "wiki", "verif wiki answer": "park(0.5613)", "verif concept answer": "park(0.5444)", "verif image answer": "puddle(0.5420)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407400.jpg"}, {"question": "what season is it", "gt answer": "winter(1.00)", "pred answer": "winter", "question_id": 5092675, "best approach": "wiki, concept, image", "verif answer": "winter", "anno approach": "wiki", "verif wiki answer": "winter(0.7197)", "verif concept answer": "winter(0.7295)", "verif image answer": "winter(0.7267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509267.jpg"}, {"question": "what shape is the playing field in this sport", "gt answer": "diamond(1.00)<br/>square(0.60)", "pred answer": "diamond", "question_id": 1916515, "best approach": "", "verif answer": "rectangle", "anno approach": "", "verif wiki answer": "rectangle(0.6860)", "verif concept answer": "rectangle(0.6735)", "verif image answer": "rectangle(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191651.jpg"}, {"question": "what kind of suface is that court", "gt answer": "dirt(1.00)<br/>clay(1.00)<br/>concrete(0.60)", "pred answer": "asphalt", "question_id": 784665, "best approach": "wiki, concept, image", "verif answer": "dirt", "anno approach": "image, wiki", "verif wiki answer": "dirt(0.6806)", "verif concept answer": "dirt(0.6837)", "verif image answer": "dirt(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078466.jpg"}, {"question": "what tv show is the character on the tv from", "gt answer": "friend(1.00)", "pred answer": "cartoon", "question_id": 399485, "best approach": "concept", "verif answer": "couple", "anno approach": "concept", "verif wiki answer": "couple(0.5876)", "verif concept answer": "friend(0.5776)", "verif image answer": "central park(0.5433)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039948.jpg"}, {"question": "the viewers are seated in an area known as the what", "gt answer": "stand(1.00)<br/>bleacher(0.60)", "pred answer": "stadium", "question_id": 3406225, "best approach": "", "verif answer": "bench", "anno approach": "", "verif wiki answer": "bench(0.7242)", "verif concept answer": "bench(0.7261)", "verif image answer": "catcher(0.7092)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340622.jpg"}, {"question": "why are the bananas sitting under the sun", "gt answer": "ripen(1.00)", "pred answer": "fall", "question_id": 5343235, "best approach": "", "verif answer": "plantain", "anno approach": "", "verif wiki answer": "plantain(0.6918)", "verif concept answer": "plantain(0.7018)", "verif image answer": "plantain(0.7180)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534323.jpg"}, {"question": "what company is responsible for building this plane", "gt answer": "delta(1.00)<br/>boeing(1.00)", "pred answer": "boeing", "question_id": 3684795, "best approach": "wiki, concept, image", "verif answer": "boeing", "anno approach": "concept, wiki", "verif wiki answer": "boeing(0.7203)", "verif concept answer": "boeing(0.7255)", "verif image answer": "boeing(0.6754)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000368479.jpg"}, {"question": "what type of cow is that", "gt answer": "angus(1.00)<br/>brown(0.60)<br/>holstein(0.60)<br/>mix(0.60)", "pred answer": "brown", "question_id": 1820325, "best approach": "", "verif answer": "ox", "anno approach": "", "verif wiki answer": "ox(0.7096)", "verif concept answer": "ox(0.7036)", "verif image answer": "ox(0.6681)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182032.jpg"}, {"question": "what is the breed of each dog", "gt answer": "golden retriever(1.00)", "pred answer": "labrador", "question_id": 2793775, "best approach": "image", "verif answer": "golden retriever", "anno approach": "image", "verif wiki answer": "labrador(0.6575)", "verif concept answer": "labrador(0.6661)", "verif image answer": "golden retriever(0.6996)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000279377.jpg"}, {"question": "when was the first stadium of this type built", "gt answer": "1909(1.00)<br/>1970(0.60)", "pred answer": "1948", "question_id": 32205, "best approach": "wiki, concept, image", "verif answer": "1909", "anno approach": "image", "verif wiki answer": "1909(0.6891)", "verif concept answer": "1909(0.7084)", "verif image answer": "1909(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003220.jpg"}, {"question": "what is this brand famous for", "gt answer": "iphones(1.00)<br/>fun(0.60)<br/>apple(0.60)", "pred answer": "computer", "question_id": 3769885, "best approach": "", "verif answer": "cell phone", "anno approach": "", "verif wiki answer": "motorola(0.7151)", "verif concept answer": "motorola(0.7216)", "verif image answer": "cell phone(0.7249)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376988.jpg"}, {"question": "what kind of apples are shown", "gt answer": "fuji(1.00)<br/>granny smith(0.60)", "pred answer": "granny smith", "question_id": 920315, "best approach": "wiki, concept", "verif answer": "granny smith", "anno approach": "wiki", "verif wiki answer": "granny smith(0.7283)", "verif concept answer": "granny smith(0.7291)", "verif image answer": "mcintosh(0.7044)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092031.jpg"}, {"question": "what model of computer is this", "gt answer": "laptop(1.00)<br/>desktop(0.60)", "pred answer": "dell", "question_id": 851715, "best approach": "image", "verif answer": "macbook", "anno approach": "image", "verif wiki answer": "macbook(0.7256)", "verif concept answer": "macbook(0.7260)", "verif image answer": "laptop(0.6986)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085171.jpg"}, {"question": "what is the specific action which gives this truck its name", "gt answer": "dump(1.00)<br/>pickup(0.60)", "pred answer": "dig", "question_id": 5460745, "best approach": "wiki, concept", "verif answer": "pickup", "anno approach": "wiki", "verif wiki answer": "pickup(0.5281)", "verif concept answer": "pickup(0.5353)", "verif image answer": "construction(0.5226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546074.jpg"}, {"question": "does this person likely have good or bad natural eyesight", "gt answer": "bad(1.00)", "pred answer": "good", "question_id": 2007825, "best approach": "concept", "verif answer": "bad", "anno approach": "concept", "verif wiki answer": "over ripe(0.5749)", "verif concept answer": "bad(0.6426)", "verif image answer": "over ripe(0.5845)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200782.jpg"}, {"question": "what is the name of the vehicle the jet is taking off from", "gt answer": "aircraft carrier(1.00)<br/>pad(0.60)", "pred answer": "runway", "question_id": 4493695, "best approach": "", "verif answer": "helmet", "anno approach": "", "verif wiki answer": "helmet(0.6924)", "verif concept answer": "helmet(0.7245)", "verif image answer": "helmet(0.6852)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449369.jpg"}, {"question": "what type of bird is this", "gt answer": "canada goose(1.00)<br/>goose(1.00)<br/>duck(0.60)", "pred answer": "duck", "question_id": 4763475, "best approach": "wiki, concept, image", "verif answer": "duck", "anno approach": "wiki", "verif wiki answer": "duck(0.6966)", "verif concept answer": "duck(0.7132)", "verif image answer": "duck(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476347.jpg"}, {"question": "is the road surface wet or dry", "gt answer": "wet(1.00)", "pred answer": "wet", "question_id": 3660005, "best approach": "wiki, concept, image", "verif answer": "wet", "anno approach": "wiki", "verif wiki answer": "wet(0.7310)", "verif concept answer": "wet(0.7310)", "verif image answer": "wet(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366000.jpg"}, {"question": "what are sausages stuffed into", "gt answer": "case(1.00)", "pred answer": "grill", "question_id": 1485165, "best approach": "wiki, concept", "verif answer": "sauce", "anno approach": "wiki", "verif wiki answer": "case(0.6900)", "verif concept answer": "case(0.6666)", "verif image answer": "sauce(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148516.jpg"}, {"question": "what is the girl in the picture doing", "gt answer": "take selfie(1.00)<br/>film(0.60)", "pred answer": "take selfie", "question_id": 3477945, "best approach": "wiki, concept, image", "verif answer": "take selfie", "anno approach": "", "verif wiki answer": "take selfie(0.7167)", "verif concept answer": "take selfie(0.7030)", "verif image answer": "take selfie(0.7049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347794.jpg"}, {"question": "what bird species is shown in this image", "gt answer": "robin(1.00)<br/>finch(0.60)", "pred answer": "finch", "question_id": 4608795, "best approach": "concept, image", "verif answer": "finch", "anno approach": "", "verif wiki answer": "bluejay(0.6497)", "verif concept answer": "finch(0.6724)", "verif image answer": "finch(0.6662)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460879.jpg"}, {"question": "what type of wood is that", "gt answer": "lumber(0.60)<br/>bamboo(0.60)<br/>log(1.00)<br/>pine(0.60)", "pred answer": "oak", "question_id": 48345, "best approach": "wiki, concept, image", "verif answer": "lumber", "anno approach": "wiki", "verif wiki answer": "lumber(0.6980)", "verif concept answer": "lumber(0.6993)", "verif image answer": "lumber(0.7005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004834.jpg"}, {"question": "what is the purpose of the green fabric around the horses ankles", "gt answer": "to be seen(1.00)<br/>visibility(1.00)", "pred answer": "helmet", "question_id": 2686445, "best approach": "concept", "verif answer": "identification", "anno approach": "concept", "verif wiki answer": "identification(0.7092)", "verif concept answer": "to be seen(0.7215)", "verif image answer": "identification(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268644.jpg"}, {"question": "what is kept in the tube that the baby is holding", "gt answer": "toothpaste(1.00)<br/>juice(0.60)<br/>straw(0.60)", "pred answer": "helium", "question_id": 415975, "best approach": "", "verif answer": "hay", "anno approach": "", "verif wiki answer": "hay(0.5948)", "verif concept answer": "hay(0.6558)", "verif image answer": "hay(0.6220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041597.jpg"}, {"question": "what food group do these foods belong to", "gt answer": "fruit(1.00)", "pred answer": "fruit", "question_id": 3342085, "best approach": "wiki, concept", "verif answer": "fruit", "anno approach": "concept, wiki", "verif wiki answer": "fruit(0.6779)", "verif concept answer": "fruit(0.7173)", "verif image answer": "citrus(0.6467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334208.jpg"}, {"question": "what is the purpose of the item in the box", "gt answer": "protection(0.60)<br/>compute(1.00)", "pred answer": "compute", "question_id": 795915, "best approach": "wiki, concept, image", "verif answer": "compute", "anno approach": "wiki", "verif wiki answer": "compute(0.7223)", "verif concept answer": "compute(0.7167)", "verif image answer": "compute(0.7093)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079591.jpg"}, {"question": "what is the name of the animated version of this animal found in disney 's the jungle book", "gt answer": "baloo(1.00)", "pred answer": "bear", "question_id": 1375835, "best approach": "image", "verif answer": "bear", "anno approach": "image", "verif wiki answer": "bear(0.7039)", "verif concept answer": "bear(0.6969)", "verif image answer": "baloo(0.6677)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000137583.jpg"}, {"question": "do these mountains more resemble a kanye west promotional art for his music or mackned promotional art for his music", "gt answer": "kanye west(1.00)", "pred answer": "classic", "question_id": 3739605, "best approach": "", "verif answer": "train", "anno approach": "", "verif wiki answer": "train(0.5333)", "verif concept answer": "train(0.5582)", "verif image answer": "2000(0.5482)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373960.jpg"}, {"question": "what is the name of the pattern on the plates", "gt answer": "zigzag(1.00)", "pred answer": "square", "question_id": 1150185, "best approach": "", "verif answer": "contemporary", "anno approach": "", "verif wiki answer": "contemporary(0.7226)", "verif concept answer": "contemporary(0.7196)", "verif image answer": "contemporary(0.6656)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115018.jpg"}, {"question": "what type of flying animal is at the flowers", "gt answer": "hummingbird(1.00)<br/>bee(0.60)<br/>bird(0.60)", "pred answer": "bird", "question_id": 147285, "best approach": "wiki, image", "verif answer": "bird", "anno approach": "wiki", "verif wiki answer": "bird(0.7251)", "verif concept answer": "sparrow(0.6086)", "verif image answer": "bee(0.7106)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000014728.jpg"}, {"question": "what type of food is this", "gt answer": "donut(1.00)<br/>doughnut(0.60)", "pred answer": "hotdogs", "question_id": 5091145, "best approach": "image", "verif answer": "donut", "anno approach": "image", "verif wiki answer": "donuts(0.6634)", "verif concept answer": "sprinkle(0.6435)", "verif image answer": "donut(0.6719)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509114.jpg"}, {"question": "what type of animal can survive that high on a mountain", "gt answer": "goat(1.00)<br/>sheep(0.60)", "pred answer": "cow", "question_id": 5551026, "best approach": "wiki, concept, image", "verif answer": "goat", "anno approach": "wiki", "verif wiki answer": "goat(0.6946)", "verif concept answer": "goat(0.6987)", "verif image answer": "goat(0.6860)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555102.jpg"}, {"question": "what helps this vehicle to remain suspended in the air", "gt answer": "propel(1.00)<br/>propeller(0.60)<br/>air(0.60)", "pred answer": "wing", "question_id": 99875, "best approach": "wiki, concept, image", "verif answer": "propeller", "anno approach": "image, wiki", "verif wiki answer": "propeller(0.6607)", "verif concept answer": "propeller(0.6474)", "verif image answer": "propeller(0.6976)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009987.jpg"}, {"question": "what kind of weather do these cyclists appear dressed for", "gt answer": "cool(1.00)<br/>rain(0.60)<br/>autumn(0.60)<br/>fall(0.60)", "pred answer": "winter", "question_id": 729875, "best approach": "wiki, concept, image", "verif answer": "cool", "anno approach": "concept, wiki", "verif wiki answer": "cool(0.7098)", "verif concept answer": "cool(0.7187)", "verif image answer": "cool(0.6490)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072987.jpg"}, {"question": "what treat can be baked in an oven", "gt answer": "cookies(1.00)<br/>cake(0.60)<br/>bread(0.60)", "pred answer": "doughnut", "question_id": 948845, "best approach": "wiki, concept, image", "verif answer": "bread", "anno approach": "image, wiki", "verif wiki answer": "bread(0.6489)", "verif concept answer": "bread(0.6406)", "verif image answer": "bread(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094884.jpg"}, {"question": "what is the other way you can get down a snow slope", "gt answer": "roll(1.00)<br/>snowboard(0.60)<br/>ski lift(0.60)", "pred answer": "ski", "question_id": 1300245, "best approach": "wiki, concept", "verif answer": "crest", "anno approach": "wiki", "verif wiki answer": "roll(0.6968)", "verif concept answer": "roll(0.6813)", "verif image answer": "crest(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130024.jpg"}, {"question": "how often might a dad get a cake like the one in the photo", "gt answer": "once year(1.00)<br/>once(0.60)<br/>yearly(0.60)", "pred answer": "10 minutes", "question_id": 4097675, "best approach": "wiki, concept", "verif answer": "once year", "anno approach": "", "verif wiki answer": "once year(0.6270)", "verif concept answer": "once year(0.5974)", "verif image answer": "once(0.5555)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409767.jpg"}, {"question": "what is in the bags", "gt answer": "cloth(1.00)<br/>luggage(0.60)", "pred answer": "cloth", "question_id": 5260295, "best approach": "wiki, concept, image", "verif answer": "cloth", "anno approach": "concept, wiki", "verif wiki answer": "cloth(0.6724)", "verif concept answer": "cloth(0.7051)", "verif image answer": "cloth(0.6616)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526029.jpg"}, {"question": "are these bananas for sale or already sold", "gt answer": "for sale(1.00)<br/>sale(0.60)", "pred answer": "sale", "question_id": 2499835, "best approach": "", "verif answer": "shop", "anno approach": "", "verif wiki answer": "shop(0.6325)", "verif concept answer": "shop(0.5841)", "verif image answer": "shop(0.5010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249983.jpg"}, {"question": "what does someone want to happen", "gt answer": "stop harper(1.00)", "pred answer": "stop", "question_id": 3734925, "best approach": "wiki, concept", "verif answer": "vandalism", "anno approach": "", "verif wiki answer": "stop harper(0.7202)", "verif concept answer": "stop harper(0.7099)", "verif image answer": "vandalism(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373492.jpg"}, {"question": "what kind of weather is this", "gt answer": "stormy(1.00)<br/>overcast(0.60)<br/>cloudy(0.60)", "pred answer": "cloudy", "question_id": 3701265, "best approach": "image", "verif answer": "stormy", "anno approach": "image", "verif wiki answer": "cloudy(0.7185)", "verif concept answer": "cloudy(0.7227)", "verif image answer": "stormy(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370126.jpg"}, {"question": "what is the boy on the left peeling", "gt answer": "potato(1.00)", "pred answer": "apple", "question_id": 5694925, "best approach": "", "verif answer": "salad", "anno approach": "", "verif wiki answer": "salad(0.7078)", "verif concept answer": "carrot(0.6982)", "verif image answer": "salad(0.7038)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569492.jpg"}, {"question": "what brand is this vehicle", "gt answer": "mercedes(1.00)<br/>daf(1.00)<br/>lexus(0.60)", "pred answer": "ford", "question_id": 5327685, "best approach": "", "verif answer": "mercedes benz", "anno approach": "", "verif wiki answer": "mercedes benz(0.6797)", "verif concept answer": "mercedes benz(0.6516)", "verif image answer": "mercedes benz(0.6903)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532768.jpg"}, {"question": "how much water do they drink", "gt answer": "lot(1.00)<br/>10 gallons(0.60)<br/>5 gallons(0.60)", "pred answer": "lot", "question_id": 2246745, "best approach": "wiki, concept", "verif answer": "lot", "anno approach": "wiki", "verif wiki answer": "lot(0.7207)", "verif concept answer": "lot(0.6497)", "verif image answer": "gallon(0.5296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224674.jpg"}, {"question": "what is on the elephant 's leg", "gt answer": "blood(1.00)<br/>boot(0.60)", "pred answer": "ivory", "question_id": 5275975, "best approach": "wiki, concept, image", "verif answer": "boot", "anno approach": "wiki", "verif wiki answer": "boot(0.7031)", "verif concept answer": "boot(0.6837)", "verif image answer": "boot(0.7108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527597.jpg"}, {"question": "what type of energy does the white device utilize", "gt answer": "solar(1.00)", "pred answer": "electricity", "question_id": 4400155, "best approach": "", "verif answer": "carbon", "anno approach": "", "verif wiki answer": "carbon(0.6798)", "verif concept answer": "carbon(0.6522)", "verif image answer": "carbon(0.6760)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440015.jpg"}, {"question": "", "gt answer": "sausage(0.60)<br/>hotdog(0.60)<br/>hot dog(0.60)<br/>hotdogs(0.60)<br/>beef(0.60)", "pred answer": "meatloaf", "question_id": 1852255, "best approach": "wiki, concept, image", "verif answer": "hotdogs", "anno approach": "", "verif wiki answer": "hotdogs(0.7209)", "verif concept answer": "hotdogs(0.7142)", "verif image answer": "hotdogs(0.6901)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185225.jpg"}, {"question": "how long will the ride be", "gt answer": "2 hours(1.00)<br/>mile(0.60)", "pred answer": "6 months", "question_id": 4488395, "best approach": "wiki", "verif answer": "2 hours", "anno approach": "wiki", "verif wiki answer": "2 hours(0.6591)", "verif concept answer": "15 minutes(0.6186)", "verif image answer": "mile(0.6529)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448839.jpg"}, {"question": "what 's the primary photographic style used here", "gt answer": "shadow(1.00)<br/>candid(0.60)", "pred answer": "black and white", "question_id": 5160435, "best approach": "", "verif answer": "reflection", "anno approach": "", "verif wiki answer": "sunset(0.6812)", "verif concept answer": "reflection(0.6643)", "verif image answer": "reflection(0.6969)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516043.jpg"}, {"question": "what are the people sitting on", "gt answer": "bench(1.00)<br/>sidewalk(0.60)<br/>chair(0.60)", "pred answer": "stair", "question_id": 1587945, "best approach": "wiki", "verif answer": "table", "anno approach": "wiki", "verif wiki answer": "bench(0.5153)", "verif concept answer": "table(0.5339)", "verif image answer": "table(0.5656)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000158794.jpg"}, {"question": "what type of flowers is the cat sniffing", "gt answer": "rose(1.00)<br/>lily(0.60)", "pred answer": "rose", "question_id": 2943145, "best approach": "wiki, concept, image", "verif answer": "rose", "anno approach": "wiki", "verif wiki answer": "rose(0.6912)", "verif concept answer": "rose(0.6993)", "verif image answer": "rose(0.6853)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000294314.jpg"}, {"question": "what type of energy is moving the board", "gt answer": "kinetic(1.00)<br/>water(0.60)", "pred answer": "electricity", "question_id": 851545, "best approach": "wiki, concept", "verif answer": "microwave", "anno approach": "wiki", "verif wiki answer": "kinetic(0.6694)", "verif concept answer": "kinetic(0.6557)", "verif image answer": "microwave(0.6785)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085154.jpg"}, {"question": "what types of vegetables do you see", "gt answer": "broccoli(1.00)<br/>tomato(0.60)", "pred answer": "pepper", "question_id": 3227495, "best approach": "concept", "verif answer": "tomato", "anno approach": "concept", "verif wiki answer": "green giant(0.5797)", "verif concept answer": "tomato(0.5926)", "verif image answer": "brocoli(0.5222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322749.jpg"}, {"question": "when this animal moves very quickly what is it doing", "gt answer": "gallop(1.00)", "pred answer": "ride", "question_id": 960275, "best approach": "wiki, concept, image", "verif answer": "gallop", "anno approach": "image, wiki", "verif wiki answer": "gallop(0.7196)", "verif concept answer": "gallop(0.6899)", "verif image answer": "gallop(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096027.jpg"}, {"question": "what are they doing", "gt answer": "cut cake(1.00)<br/>eat(0.60)", "pred answer": "birthday", "question_id": 1543455, "best approach": "wiki, concept", "verif answer": "eat", "anno approach": "wiki", "verif wiki answer": "cut cake(0.6960)", "verif concept answer": "cut cake(0.7002)", "verif image answer": "eat(0.7256)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154345.jpg"}, {"question": "what is the name of the garment worn by the men in this photo", "gt answer": "robe(1.00)<br/>coat(0.60)", "pred answer": "suit", "question_id": 5039615, "best approach": "wiki", "verif answer": "formal", "anno approach": "wiki", "verif wiki answer": "coat(0.7185)", "verif concept answer": "formal(0.7259)", "verif image answer": "formal(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503961.jpg"}, {"question": "what activity is this person doing", "gt answer": "paddleboarding(1.00)<br/>surf(1.00)<br/>sail(0.60)", "pred answer": "surf", "question_id": 3448805, "best approach": "", "verif answer": "surfboard", "anno approach": "", "verif wiki answer": "surfboard(0.6411)", "verif concept answer": "surfboard(0.6286)", "verif image answer": "surfboard(0.6049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344880.jpg"}, {"question": "how might a vehicle like this be powered other than electrically", "gt answer": "steam(1.00)<br/>diesel(0.60)<br/>fuel(0.60)", "pred answer": "electricity", "question_id": 2574145, "best approach": "wiki, concept, image", "verif answer": "diesel", "anno approach": "wiki", "verif wiki answer": "diesel(0.7010)", "verif concept answer": "diesel(0.6936)", "verif image answer": "diesel(0.7023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257414.jpg"}, {"question": "who is the parent company of the sponsor", "gt answer": "ge(1.00)<br/>general electric(0.60)", "pred answer": "mercedes", "question_id": 1681875, "best approach": "image", "verif answer": "ge", "anno approach": "image", "verif wiki answer": "general electric(0.6526)", "verif concept answer": "general electric(0.6697)", "verif image answer": "ge(0.7257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168187.jpg"}, {"question": "what team won the title for this sport last year", "gt answer": "astros(1.00)<br/>met(0.60)<br/>houston astros(0.60)", "pred answer": "yankees", "question_id": 1346225, "best approach": "", "verif answer": "dodger", "anno approach": "", "verif wiki answer": "dodger(0.6963)", "verif concept answer": "dodger(0.6985)", "verif image answer": "dodger(0.6767)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134622.jpg"}, {"question": "what kind of donut is the woman eating", "gt answer": "glazed(1.00)<br/>ring(0.60)", "pred answer": "glazed", "question_id": 5043485, "best approach": "", "verif answer": "sprinkle", "anno approach": "", "verif wiki answer": "sprinkle(0.6278)", "verif concept answer": "sprinkle(0.6187)", "verif image answer": "sprinkle(0.6712)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000504348.jpg"}, {"question": "what type of material are these animals laying on", "gt answer": "rock(1.00)<br/>canvas(0.60)<br/>concrete(0.60)", "pred answer": "rock", "question_id": 2316015, "best approach": "wiki, concept, image", "verif answer": "rock", "anno approach": "wiki", "verif wiki answer": "rock(0.6999)", "verif concept answer": "rock(0.6935)", "verif image answer": "rock(0.6870)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231601.jpg"}, {"question": "which item depicted is usually made with baking powder", "gt answer": "roll(0.60)<br/>bun(1.00)<br/>biscuit(0.60)<br/>bread(0.60)", "pred answer": "cake", "question_id": 5264335, "best approach": "concept, image", "verif answer": "bread", "anno approach": "image", "verif wiki answer": "sourdough(0.6526)", "verif concept answer": "biscuit(0.5617)", "verif image answer": "bread(0.6648)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526433.jpg"}, {"question": "is this a legal or illegal parking space", "gt answer": "illegal(1.00)", "pred answer": "illegal", "question_id": 856855, "best approach": "", "verif answer": "legal", "anno approach": "", "verif wiki answer": "legal(0.7068)", "verif concept answer": "legal(0.7255)", "verif image answer": "legal(0.6736)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085685.jpg"}, {"question": "where was this sport invented", "gt answer": "norway(1.00)<br/>sweden(0.60)<br/>switzerland(0.60)<br/>1930s(0.60)", "pred answer": "sweden", "question_id": 5131235, "best approach": "wiki, concept, image", "verif answer": "norway", "anno approach": "wiki", "verif wiki answer": "norway(0.7156)", "verif concept answer": "norway(0.7054)", "verif image answer": "norway(0.7093)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513123.jpg"}, {"question": "whic type of metal is used for making this cycle shown in this picture", "gt answer": "aluminum(1.00)<br/>metal(0.60)", "pred answer": "gas", "question_id": 5465685, "best approach": "wiki, concept, image", "verif answer": "aluminum", "anno approach": "concept, wiki", "verif wiki answer": "aluminum(0.7025)", "verif concept answer": "aluminum(0.7008)", "verif image answer": "aluminum(0.6330)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546568.jpg"}, {"question": "how long has this brand of soda been around", "gt answer": "1886(1.00)<br/>1892(0.60)<br/>100 years(0.60)", "pred answer": "2 weeks", "question_id": 1572375, "best approach": "wiki, concept, image", "verif answer": "1892", "anno approach": "wiki", "verif wiki answer": "1892(0.7049)", "verif concept answer": "1892(0.6753)", "verif image answer": "1892(0.6513)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157237.jpg"}, {"question": "what utensils are not pictured", "gt answer": "fork and knife(1.00)<br/>fork(1.00)", "pred answer": "fork", "question_id": 2898525, "best approach": "", "verif answer": "right fork", "anno approach": "", "verif wiki answer": "right fork(0.7146)", "verif concept answer": "larger(0.7084)", "verif image answer": "right fork(0.7227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000289852.jpg"}, {"question": "what is the name of the item worn around the neck and tied at the waist", "gt answer": "apron(1.00)", "pred answer": "cap", "question_id": 4491975, "best approach": "", "verif answer": "grill", "anno approach": "", "verif wiki answer": "grill(0.7289)", "verif concept answer": "grill(0.7280)", "verif image answer": "grill(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449197.jpg"}, {"question": "can you name the type of ceramic used to make this toilet", "gt answer": "porcelain(1.00)<br/>china(0.60)", "pred answer": "porcelain", "question_id": 3854065, "best approach": "image", "verif answer": "porcelain", "anno approach": "image", "verif wiki answer": "copper(0.6670)", "verif concept answer": "copper(0.6526)", "verif image answer": "porcelain(0.6883)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385406.jpg"}, {"question": "what kind of bike is this", "gt answer": "schwinn(1.00)<br/>motorcycle(0.60)<br/>pedal(0.60)", "pred answer": "motorcycle", "question_id": 2157825, "best approach": "wiki, concept, image", "verif answer": "motorcycle", "anno approach": "wiki", "verif wiki answer": "motorcycle(0.6893)", "verif concept answer": "motorcycle(0.6891)", "verif image answer": "motorcycle(0.6817)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215782.jpg"}, {"question": "which item depicted here is also a kind of shoe", "gt answer": "platform(1.00)<br/>train(0.60)<br/>track(0.60)", "pred answer": "luggage", "question_id": 242575, "best approach": "wiki, concept, image", "verif answer": "train", "anno approach": "image, wiki", "verif wiki answer": "train(0.6156)", "verif concept answer": "train(0.6127)", "verif image answer": "train(0.6733)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024257.jpg"}, {"question": "what shade is this picture in", "gt answer": "black and white(1.00)<br/>sepia(1.00)<br/>gray(0.60)", "pred answer": "sepia", "question_id": 1112905, "best approach": "wiki, concept, image", "verif answer": "gray", "anno approach": "concept, wiki", "verif wiki answer": "gray(0.6589)", "verif concept answer": "gray(0.6866)", "verif image answer": "gray(0.6012)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111290.jpg"}, {"question": "guess what type of ice doll they are going to do", "gt answer": "snow man(1.00)<br/>snowboard(0.60)", "pred answer": "snowboard", "question_id": 123135, "best approach": "concept", "verif answer": "ski lift", "anno approach": "concept", "verif wiki answer": "ski lift(0.7304)", "verif concept answer": "snow man(0.7277)", "verif image answer": "ski lift(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012313.jpg"}, {"question": "at what time of day is the food depicted eaten", "gt answer": "noon(1.00)<br/>afternoon(0.60)<br/>dinner(0.60)<br/>lunch(0.60)", "pred answer": "morn", "question_id": 3039355, "best approach": "", "verif answer": "morn", "anno approach": "", "verif wiki answer": "morn(0.7266)", "verif concept answer": "morn(0.7263)", "verif image answer": "morn(0.7048)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303935.jpg"}, {"question": "what kind of birds are these", "gt answer": "pigeon(1.00)", "pred answer": "hawk", "question_id": 1810345, "best approach": "", "verif answer": "sparrow", "anno approach": "", "verif wiki answer": "sparrow(0.7066)", "verif concept answer": "bird(0.6883)", "verif image answer": "bird(0.6450)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181034.jpg"}, {"question": "how many master card logos are there", "gt answer": "2(1.00)", "pred answer": "12", "question_id": 1970695, "best approach": "", "verif answer": "0", "anno approach": "", "verif wiki answer": "0(0.7220)", "verif concept answer": "0(0.7024)", "verif image answer": "0(0.6974)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197069.jpg"}, {"question": "would this be a traditionally made or custom made", "gt answer": "custom(1.00)", "pred answer": "contemporary", "question_id": 3123385, "best approach": "", "verif answer": "real", "anno approach": "", "verif wiki answer": "restoration(0.6314)", "verif concept answer": "restoration(0.6690)", "verif image answer": "real(0.6777)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312338.jpg"}, {"question": "what is a group of bananas called", "gt answer": "bunch(1.00)", "pred answer": "banana", "question_id": 761305, "best approach": "", "verif answer": "scurvy", "anno approach": "", "verif wiki answer": "orange(0.6100)", "verif concept answer": "orange(0.6105)", "verif image answer": "scurvy(0.6206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076130.jpg"}, {"question": "who had the highest batting rate in history", "gt answer": "ty cobb(1.00)<br/>pete rose(0.60)", "pred answer": "babe ruth", "question_id": 2464125, "best approach": "", "verif answer": "babe ruth", "anno approach": "", "verif wiki answer": "babe ruth(0.7218)", "verif concept answer": "babe ruth(0.7094)", "verif image answer": "babe ruth(0.6983)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246412.jpg"}, {"question": "who makes this phone", "gt answer": "motorola(1.00)<br/>samsung(0.60)", "pred answer": "nokia", "question_id": 228545, "best approach": "wiki, image", "verif answer": "motorola", "anno approach": "wiki", "verif wiki answer": "motorola(0.6972)", "verif concept answer": "nokia(0.6695)", "verif image answer": "motorola(0.7011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000022854.jpg"}, {"question": "what vitamins do you get from these vegetables", "gt answer": "beta carotene(1.00)<br/>(0.60)", "pred answer": "c", "question_id": 564425, "best approach": "", "verif answer": "c", "anno approach": "", "verif wiki answer": "vitamin k(0.6886)", "verif concept answer": "vitamin k(0.7061)", "verif image answer": "c(0.7218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000056442.jpg"}, {"question": "what year was the sport played by this team invented", "gt answer": "1839(1.00)", "pred answer": "1950", "question_id": 741835, "best approach": "wiki, concept, image", "verif answer": "1839", "anno approach": "concept, wiki", "verif wiki answer": "1839(0.7258)", "verif concept answer": "1839(0.7175)", "verif image answer": "1839(0.6680)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074183.jpg"}, {"question": "the shown dish is good for which parts of the body", "gt answer": "muscle(1.00)<br/>stomach(0.60)", "pred answer": "heart", "question_id": 3441385, "best approach": "concept, image", "verif answer": "muscle", "anno approach": "image", "verif wiki answer": "heart(0.6774)", "verif concept answer": "muscle(0.6672)", "verif image answer": "muscle(0.7194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344138.jpg"}, {"question": "what is the process called that denudes these animals of their covering", "gt answer": "shear(1.00)", "pred answer": "fall", "question_id": 5467235, "best approach": "", "verif answer": "sheer", "anno approach": "", "verif wiki answer": "sheer(0.7043)", "verif concept answer": "sheer(0.6931)", "verif image answer": "sheer(0.7013)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546723.jpg"}, {"question": "is this picture taken during high or low tide", "gt answer": "low(1.00)<br/>high(0.60)", "pred answer": "high", "question_id": 4018425, "best approach": "image", "verif answer": "high", "anno approach": "image", "verif wiki answer": "high(0.7117)", "verif concept answer": "high(0.6841)", "verif image answer": "low(0.6963)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401842.jpg"}, {"question": "what is written on the green sign", "gt answer": "hilltop hotel(1.00)<br/>letter(0.60)<br/>walk(0.60)", "pred answer": "juice", "question_id": 2032695, "best approach": "", "verif answer": "newspaper", "anno approach": "", "verif wiki answer": "newspaper(0.6908)", "verif concept answer": "newspaper(0.6482)", "verif image answer": "western ave(0.6658)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203269.jpg"}, {"question": "what kind of pants are the people on the sides of the image wearing", "gt answer": "jean(1.00)<br/>denim(0.60)", "pred answer": "jean", "question_id": 1587865, "best approach": "image", "verif answer": "denim", "anno approach": "image", "verif wiki answer": "sweat(0.6900)", "verif concept answer": "sweat(0.6918)", "verif image answer": "denim(0.7036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000158786.jpg"}, {"question": "what body of water is this person located", "gt answer": "pond(1.00)<br/>lake(1.00)", "pred answer": "lake", "question_id": 4563435, "best approach": "wiki, concept, image", "verif answer": "lake", "anno approach": "wiki", "verif wiki answer": "lake(0.6969)", "verif concept answer": "lake(0.7037)", "verif image answer": "lake(0.6989)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456343.jpg"}, {"question": "is this downhill or cross country skiing or is it telemark skiing", "gt answer": "cross country(1.00)<br/>downhill(0.60)", "pred answer": "cross country", "question_id": 162555, "best approach": "concept", "verif answer": "slope", "anno approach": "concept", "verif wiki answer": "slope(0.7166)", "verif concept answer": "cross country(0.6404)", "verif image answer": "slope(0.6792)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016255.jpg"}, {"question": "what is the general mood in this room", "gt answer": "happy(1.00)", "pred answer": "play video game", "question_id": 2572975, "best approach": "image", "verif answer": "happiness", "anno approach": "image", "verif wiki answer": "happiness(0.6964)", "verif concept answer": "happiness(0.7038)", "verif image answer": "happy(0.6359)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257297.jpg"}, {"question": "what movie features this vehicle and it can not stop", "gt answer": "speed(1.00)<br/>car(0.60)", "pred answer": "dumbo", "question_id": 864525, "best approach": "", "verif answer": "jaywalk", "anno approach": "", "verif wiki answer": "jaywalk(0.7310)", "verif concept answer": "jaywalk(0.7308)", "verif image answer": "jaywalk(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086452.jpg"}, {"question": "where in africa is this photo taken", "gt answer": "savannah(1.00)<br/>outside(0.60)", "pred answer": "africa", "question_id": 1095865, "best approach": "concept, image", "verif answer": "outside", "anno approach": "image", "verif wiki answer": "zoo(0.6488)", "verif concept answer": "outside(0.5950)", "verif image answer": "outside(0.6853)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000109586.jpg"}, {"question": "what is this person performing", "gt answer": "trick(1.00)<br/>flip(0.60)", "pred answer": "ski", "question_id": 2547745, "best approach": "image", "verif answer": "trick", "anno approach": "image", "verif wiki answer": "flip(0.5156)", "verif concept answer": "flip(0.5255)", "verif image answer": "trick(0.6070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000254774.jpg"}, {"question": "what are these books about", "gt answer": "embroidery(1.00)", "pred answer": "move", "question_id": 4514825, "best approach": "", "verif answer": "student", "anno approach": "", "verif wiki answer": "student(0.6221)", "verif concept answer": "student(0.6678)", "verif image answer": "read(0.6629)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451482.jpg"}, {"question": "what is the name of the city this photograph was taken in", "gt answer": "new york(1.00)<br/>boston(0.60)<br/>philadelphia(0.60)", "pred answer": "city", "question_id": 2108495, "best approach": "wiki, concept, image", "verif answer": "philadelphia", "anno approach": "wiki", "verif wiki answer": "philadelphia(0.6849)", "verif concept answer": "philadelphia(0.6978)", "verif image answer": "philadelphia(0.6824)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210849.jpg"}, {"question": "what is the model of this car", "gt answer": "model t(1.00)", "pred answer": "ford", "question_id": 1990115, "best approach": "wiki, concept, image", "verif answer": "model t", "anno approach": "concept, wiki", "verif wiki answer": "model t(0.7137)", "verif concept answer": "model t(0.6968)", "verif image answer": "model t(0.6573)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199011.jpg"}, {"question": "how is this side item cooked", "gt answer": "fried(1.00)<br/>fresh(0.60)", "pred answer": "baked", "question_id": 182765, "best approach": "image", "verif answer": "fresh", "anno approach": "image", "verif wiki answer": "handmade(0.6450)", "verif concept answer": "fry(0.6460)", "verif image answer": "fresh(0.6462)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000018276.jpg"}, {"question": "what is the fire hydrate doing", "gt answer": "leak(1.00)<br/>run(0.60)", "pred answer": "lift it", "question_id": 5412035, "best approach": "wiki, concept", "verif answer": "run", "anno approach": "wiki", "verif wiki answer": "run(0.6872)", "verif concept answer": "run(0.6928)", "verif image answer": "smell(0.6809)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541203.jpg"}, {"question": "how many base are in this sport", "gt answer": "4(1.00)<br/>3(0.60)", "pred answer": "5", "question_id": 397775, "best approach": "image", "verif answer": "6", "anno approach": "image", "verif wiki answer": "6(0.6798)", "verif concept answer": "6(0.6707)", "verif image answer": "4(0.6425)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039777.jpg"}, {"question": "of what is the sidewalk made", "gt answer": "concrete(1.00)", "pred answer": "concrete", "question_id": 385325, "best approach": "", "verif answer": "asphalt", "anno approach": "", "verif wiki answer": "asphalt(0.6797)", "verif concept answer": "wood(0.6910)", "verif image answer": "asphalt(0.7154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038532.jpg"}, {"question": "what type of fruit is this", "gt answer": "lemon(1.00)<br/>orange(1.00)", "pred answer": "orange", "question_id": 4215785, "best approach": "wiki, concept, image", "verif answer": "orange", "anno approach": "image, concept, wiki", "verif wiki answer": "orange(0.6427)", "verif concept answer": "orange(0.7120)", "verif image answer": "orange(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421578.jpg"}, {"question": "how do you remove this animal 's hair", "gt answer": "shear(1.00)<br/>sheer(1.00)", "pred answer": "shear", "question_id": 5255915, "best approach": "wiki, concept, image", "verif answer": "shear", "anno approach": "wiki", "verif wiki answer": "shear(0.6858)", "verif concept answer": "shear(0.6591)", "verif image answer": "sheer(0.6483)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525591.jpg"}, {"question": "what league are the players on this team members of", "gt answer": "major league(1.00)<br/>major(1.00)", "pred answer": "baseball", "question_id": 3957685, "best approach": "wiki", "verif answer": "major league", "anno approach": "wiki", "verif wiki answer": "major league(0.7041)", "verif concept answer": "baseball(0.6661)", "verif image answer": "baseball(0.6722)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395768.jpg"}, {"question": "what kind of couch is this", "gt answer": "loveseat(1.00)<br/>brown(1.00)<br/>long(0.60)", "pred answer": "sectional", "question_id": 1871675, "best approach": "", "verif answer": "miniature", "anno approach": "", "verif wiki answer": "miniature(0.6894)", "verif concept answer": "miniature(0.6944)", "verif image answer": "miniature(0.6978)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187167.jpg"}, {"question": "what breed of dogs are these", "gt answer": "mixed(1.00)<br/>dog(0.60)", "pred answer": "mutt", "question_id": 790215, "best approach": "", "verif answer": "doberman", "anno approach": "", "verif wiki answer": "doberman(0.6508)", "verif concept answer": "doberman(0.6903)", "verif image answer": "doberman(0.6597)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079021.jpg"}, {"question": "where do you get these stuffed animals", "gt answer": "store(1.00)<br/>shop(0.60)<br/>online(0.60)<br/>toy store(0.60)", "pred answer": "store", "question_id": 1573415, "best approach": "wiki, concept, image", "verif answer": "toy store", "anno approach": "concept, wiki", "verif wiki answer": "toy store(0.7213)", "verif concept answer": "online(0.7116)", "verif image answer": "online(0.6228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157341.jpg"}, {"question": "who is controlling these", "gt answer": "pilot(1.00)", "pred answer": "wright brother", "question_id": 4008455, "best approach": "wiki, concept, image", "verif answer": "pilot", "anno approach": "wiki", "verif wiki answer": "pilot(0.7247)", "verif concept answer": "pilot(0.7224)", "verif image answer": "pilot(0.7119)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400845.jpg"}, {"question": "what relationship do these men have", "gt answer": "father and son(0.60)<br/>friend(1.00)", "pred answer": "family", "question_id": 5597605, "best approach": "wiki, image", "verif answer": "friend", "anno approach": "image, wiki", "verif wiki answer": "friend(0.6385)", "verif concept answer": "co worker(0.6867)", "verif image answer": "friend(0.7047)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559760.jpg"}, {"question": "what is this kind of table named after", "gt answer": "picnic(1.00)<br/>picnic table(0.60)", "pred answer": "dinner", "question_id": 3336945, "best approach": "wiki, concept", "verif answer": "picnic table", "anno approach": "wiki", "verif wiki answer": "picnic table(0.6618)", "verif concept answer": "picnic table(0.6545)", "verif image answer": "lunch(0.6074)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333694.jpg"}, {"question": "are these travelers going home or going on an adventure", "gt answer": "adventure(1.00)<br/>home(0.60)", "pred answer": "vacation", "question_id": 3018555, "best approach": "", "verif answer": "dorm", "anno approach": "", "verif wiki answer": "dorm(0.5144)", "verif concept answer": "college(0.5125)", "verif image answer": "nike(0.5083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301855.jpg"}, {"question": "what is underneath this bag", "gt answer": "park meter(1.00)<br/>meter(0.60)", "pred answer": "passenger", "question_id": 811025, "best approach": "", "verif answer": "coin", "anno approach": "", "verif wiki answer": "coin(0.6409)", "verif concept answer": "coin(0.6736)", "verif image answer": "coin(0.5652)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081102.jpg"}, {"question": "which superhero is the cake supposed to be", "gt answer": "wonder woman(1.00)", "pred answer": "cookie monster", "question_id": 4379445, "best approach": "", "verif answer": "captain", "anno approach": "", "verif wiki answer": "batman(0.7184)", "verif concept answer": "batman(0.6962)", "verif image answer": "captain(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437944.jpg"}, {"question": "is this a portrait shot or was the photo taken while this subject was doing something", "gt answer": "candid(1.00)<br/>active(0.60)<br/>eat(0.60)", "pred answer": "take picture", "question_id": 4306915, "best approach": "wiki, concept, image", "verif answer": "active", "anno approach": "wiki", "verif wiki answer": "active(0.7152)", "verif concept answer": "active(0.7180)", "verif image answer": "active(0.7199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430691.jpg"}, {"question": "what is this animal being transported inside of", "gt answer": "trailer(1.00)", "pred answer": "trailer", "question_id": 3820445, "best approach": "wiki", "verif answer": "trailer", "anno approach": "wiki", "verif wiki answer": "trailer(0.7270)", "verif concept answer": "rv(0.5725)", "verif image answer": "carriage(0.5914)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382044.jpg"}, {"question": "what are these on his face used for", "gt answer": "see(1.00)<br/>vision(0.60)", "pred answer": "beard", "question_id": 923405, "best approach": "", "verif answer": "read", "anno approach": "", "verif wiki answer": "read(0.5763)", "verif concept answer": "read(0.6859)", "verif image answer": "communication(0.6666)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092340.jpg"}, {"question": "how does one go about making one of these", "gt answer": "oven(1.00)<br/>dough(0.60)", "pred answer": "10 minutes", "question_id": 4213465, "best approach": "wiki", "verif answer": "bread", "anno approach": "wiki", "verif wiki answer": "oven(0.5389)", "verif concept answer": "bread(0.5851)", "verif image answer": "bread(0.5534)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421346.jpg"}, {"question": "what item in the picture is purported to have a great memory", "gt answer": "elephant(1.00)<br/>trunk(0.60)<br/>brain(0.60)", "pred answer": "ivory", "question_id": 2629795, "best approach": "wiki", "verif answer": "tusk", "anno approach": "wiki", "verif wiki answer": "elephant(0.6810)", "verif concept answer": "tusk(0.6775)", "verif image answer": "tusk(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262979.jpg"}, {"question": "what is attached to this item to keep it from flying away", "gt answer": "string(1.00)<br/>thread(0.60)", "pred answer": "wind", "question_id": 4791255, "best approach": "", "verif answer": "kite", "anno approach": "", "verif wiki answer": "kite(0.7075)", "verif concept answer": "wind(0.6916)", "verif image answer": "wind(0.7067)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479125.jpg"}, {"question": "which african american was famous for this sport", "gt answer": "jackie robinson(1.00)", "pred answer": "babe ruth", "question_id": 4818075, "best approach": "", "verif answer": "moses walker", "anno approach": "", "verif wiki answer": "moses walker(0.7240)", "verif concept answer": "moses walker(0.7216)", "verif image answer": "baseball(0.7190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481807.jpg"}, {"question": "what material is the surfboard made of", "gt answer": "fiberglass(1.00)<br/>plastic(0.60)", "pred answer": "fiberglass", "question_id": 4770665, "best approach": "", "verif answer": "polyurethane", "anno approach": "", "verif wiki answer": "polyurethane(0.7286)", "verif concept answer": "polyurethane(0.7293)", "verif image answer": "polyurethane(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477066.jpg"}, {"question": "what are these vessels usually called", "gt answer": "yacht(0.60)<br/>boat(1.00)<br/>sea(0.60)<br/>fish boat(0.60)", "pred answer": "boat", "question_id": 74555, "best approach": "wiki, concept, image", "verif answer": "yacht", "anno approach": "wiki", "verif wiki answer": "yacht(0.6455)", "verif concept answer": "yacht(0.5639)", "verif image answer": "yacht(0.5882)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007455.jpg"}, {"question": "what is the name of the company on the plane", "gt answer": "delta(1.00)", "pred answer": "delta", "question_id": 5253805, "best approach": "wiki", "verif answer": "delta", "anno approach": "wiki", "verif wiki answer": "delta(0.7235)", "verif concept answer": "boeing(0.6209)", "verif image answer": "american airline(0.7152)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525380.jpg"}, {"question": "is this a lake or ocean", "gt answer": "lake(1.00)", "pred answer": "lake", "question_id": 642445, "best approach": "wiki, concept, image", "verif answer": "lake", "anno approach": "wiki", "verif wiki answer": "lake(0.7119)", "verif concept answer": "lake(0.7261)", "verif image answer": "lake(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064244.jpg"}, {"question": "which manchester united player wears the same number as the person jumping", "gt answer": "paul pogba(1.00)<br/>goalie(0.60)", "pred answer": "frisbee", "question_id": 2487455, "best approach": "image", "verif answer": "frisbee", "anno approach": "image", "verif wiki answer": "frisbee(0.7237)", "verif concept answer": "goalie(0.7235)", "verif image answer": "paul pogba(0.7214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248745.jpg"}, {"question": "what dish is being prepared", "gt answer": "pie(1.00)<br/>banana(0.60)", "pred answer": "banana", "question_id": 1475915, "best approach": "", "verif answer": "apple pie", "anno approach": "", "verif wiki answer": "dessert(0.7022)", "verif concept answer": "dessert(0.6905)", "verif image answer": "apple pie(0.7103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147591.jpg"}, {"question": "which old fashioned song speaks of one of these built for two", "gt answer": "bicycle built for 2(1.00)<br/>classic(0.60)<br/>country(0.60)", "pred answer": "bike", "question_id": 1719665, "best approach": "", "verif answer": "contemporary", "anno approach": "", "verif wiki answer": "deep dish(0.6253)", "verif concept answer": "deep dish(0.5368)", "verif image answer": "contemporary(0.6338)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171966.jpg"}, {"question": "why is there two key boards", "gt answer": "1 for letters 1 for numbers(1.00)", "pred answer": "stop light", "question_id": 3900735, "best approach": "wiki, concept, image", "verif answer": "1 for letters 1 for numbers", "anno approach": "", "verif wiki answer": "1 for letters 1 for numbers(0.7279)", "verif concept answer": "1 for letters 1 for numbers(0.7086)", "verif image answer": "1 for letters 1 for numbers(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390073.jpg"}, {"question": "what is the meaning of the symbols seen on the back of this truck", "gt answer": "caution(1.00)<br/>slow(0.60)<br/>brake(0.60)", "pred answer": "direct", "question_id": 4005935, "best approach": "concept, image", "verif answer": "caution", "anno approach": "", "verif wiki answer": "slow down(0.6704)", "verif concept answer": "caution(0.6733)", "verif image answer": "caution(0.6997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400593.jpg"}, {"question": "what is the purpose of the wooden sticks in the photo", "gt answer": "hold sandwich together(1.00)", "pred answer": "eat", "question_id": 4347535, "best approach": "", "verif answer": "eat", "anno approach": "", "verif wiki answer": "eat(0.6778)", "verif concept answer": "eat(0.6784)", "verif image answer": "eat(0.6740)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434753.jpg"}, {"question": "why would we suspect these two are posing rather than going about their normal routines", "gt answer": "camera(1.00)<br/>mirror(0.60)", "pred answer": "text", "question_id": 1680835, "best approach": "wiki, concept, image", "verif answer": "camera", "anno approach": "image, wiki", "verif wiki answer": "camera(0.6574)", "verif concept answer": "camera(0.6234)", "verif image answer": "camera(0.6635)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168083.jpg"}, {"question": "who is credited for inventing these electronic devices", "gt answer": "steve job(1.00)", "pred answer": "ibm", "question_id": 1263895, "best approach": "", "verif answer": "bill gate", "anno approach": "", "verif wiki answer": "martin cooper(0.7025)", "verif concept answer": "martin cooper(0.6998)", "verif image answer": "bill gate(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126389.jpg"}, {"question": "what stage of life is this boy in", "gt answer": "toddler(1.00)<br/>early(0.60)", "pred answer": "puppy", "question_id": 2371375, "best approach": "wiki, concept", "verif answer": "early", "anno approach": "wiki", "verif wiki answer": "early(0.6861)", "verif concept answer": "early(0.6551)", "verif image answer": "baby(0.6156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237137.jpg"}, {"question": "what were those ceiling fan blades made to resemble", "gt answer": "propeller(1.00)<br/>chopper(0.60)", "pred answer": "track", "question_id": 4904005, "best approach": "image", "verif answer": "chopper", "anno approach": "image", "verif wiki answer": "chopper(0.7094)", "verif concept answer": "chopper(0.5577)", "verif image answer": "propeller(0.5995)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490400.jpg"}, {"question": "what breed of dog is this", "gt answer": "beagle(1.00)<br/>shepherd(0.60)", "pred answer": "collie", "question_id": 606785, "best approach": "", "verif answer": "corgi", "anno approach": "", "verif wiki answer": "corgi(0.6387)", "verif concept answer": "corgi(0.6235)", "verif image answer": "corgi(0.6487)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060678.jpg"}, {"question": "", "gt answer": "stopped(0.60)<br/>stop(0.60)<br/>flash(0.60)", "pred answer": "1800s", "question_id": 4253815, "best approach": "", "verif answer": "christmas", "anno approach": "", "verif wiki answer": "christmas(0.6297)", "verif concept answer": "christmas(0.6658)", "verif image answer": "christmas(0.6827)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425381.jpg"}, {"question": "what type of planes are those", "gt answer": "biplane(1.00)<br/>military(0.60)<br/>prop(0.60)", "pred answer": "fighter jet", "question_id": 4657015, "best approach": "wiki, concept, image", "verif answer": "military", "anno approach": "concept, wiki", "verif wiki answer": "military(0.6696)", "verif concept answer": "military(0.7081)", "verif image answer": "military(0.6803)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465701.jpg"}, {"question": "which animal loves this type of fruit", "gt answer": "monkey(1.00)", "pred answer": "monkey", "question_id": 3727885, "best approach": "wiki, concept, image", "verif answer": "monkey", "anno approach": "concept, wiki", "verif wiki answer": "monkey(0.7271)", "verif concept answer": "monkey(0.7105)", "verif image answer": "monkey(0.6627)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372788.jpg"}, {"question": "what emotions is this man displaying", "gt answer": "hunger(1.00)<br/>sad(0.60)", "pred answer": "happiness", "question_id": 5103855, "best approach": "image", "verif answer": "happiness", "anno approach": "image", "verif wiki answer": "happiness(0.6866)", "verif concept answer": "sad(0.5956)", "verif image answer": "hunger(0.6152)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510385.jpg"}, {"question": "what can i use these for", "gt answer": "computer(1.00)<br/>work(0.60)<br/>print(0.60)", "pred answer": "compute", "question_id": 5009845, "best approach": "image", "verif answer": "work", "anno approach": "image", "verif wiki answer": "lcd(0.6662)", "verif concept answer": "lcd(0.6603)", "verif image answer": "work(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500984.jpg"}, {"question": "from what outdoor area of a house would you gather these", "gt answer": "garden(1.00)", "pred answer": "park", "question_id": 4505845, "best approach": "", "verif answer": "united state", "anno approach": "", "verif wiki answer": "ground(0.6714)", "verif concept answer": "united state(0.7018)", "verif image answer": "ground(0.6408)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450584.jpg"}, {"question": "what animal produces the white topping on the pizza", "gt answer": "cow(1.00)", "pred answer": "cheese", "question_id": 1233895, "best approach": "wiki, concept", "verif answer": "cow", "anno approach": "concept, wiki", "verif wiki answer": "cow(0.6373)", "verif concept answer": "cow(0.7295)", "verif image answer": "cheese(0.7111)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123389.jpg"}, {"question": "how is power supplied to this form of transportation", "gt answer": "gasoline(1.00)<br/>propel(0.60)<br/>fuel(0.60)<br/>engine(0.60)", "pred answer": "engine", "question_id": 502945, "best approach": "wiki", "verif answer": "gas", "anno approach": "wiki", "verif wiki answer": "engine(0.6840)", "verif concept answer": "gas(0.6295)", "verif image answer": "gas(0.6942)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050294.jpg"}, {"question": "what are these sometimes filled with", "gt answer": "jelly(1.00)", "pred answer": "ice", "question_id": 5428095, "best approach": "wiki, concept", "verif answer": "jelly", "anno approach": "wiki", "verif wiki answer": "jelly(0.6636)", "verif concept answer": "jelly(0.6368)", "verif image answer": "air(0.6506)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542809.jpg"}, {"question": "what animal normally attack persons doing these activities", "gt answer": "shark(1.00)", "pred answer": "shark", "question_id": 2068935, "best approach": "wiki, concept, image", "verif answer": "shark", "anno approach": "wiki", "verif wiki answer": "shark(0.7284)", "verif concept answer": "shark(0.7300)", "verif image answer": "shark(0.7271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206893.jpg"}]
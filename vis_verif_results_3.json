[{"question": "who sponsors this vehicle", "gt answer": "citilink(1.00)", "pred answer": "ford", "question_id": 5616415, "best approach": "", "verif answer": "overnite", "anno approach": "", "verif wiki answer": "amtrak(0.7082)", "verif concept answer": "amtrak(0.7102)", "verif image answer": "overnite(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561641.jpg"}, {"question": "which is the cleaning agent used for cleaning of this cooking range", "gt answer": "degreaser(1.00)", "pred answer": "bleach", "question_id": 2858005, "best approach": "", "verif answer": "glass", "anno approach": "", "verif wiki answer": "glass(0.5067)", "verif concept answer": "glass(0.5014)", "verif image answer": "glass(0.5007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285800.jpg"}, {"question": "what is the name of a famous chain that sells this product", "gt answer": "dunkin donuts(1.00)<br/>nintendo(0.60)", "pred answer": "walmart", "question_id": 5213865, "best approach": "wiki, concept", "verif answer": "nintendo", "anno approach": "wiki", "verif wiki answer": "nintendo(0.7302)", "verif concept answer": "nintendo(0.7230)", "verif image answer": "krispy kreme(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521386.jpg"}, {"question": "what is the metal the train rides on", "gt answer": "track(1.00)<br/>steel(0.60)<br/>rail(0.60)", "pred answer": "track", "question_id": 5506245, "best approach": "wiki", "verif answer": "rail", "anno approach": "wiki", "verif wiki answer": "track(0.7208)", "verif concept answer": "rail(0.7184)", "verif image answer": "rail(0.7257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550624.jpg"}, {"question": "what kind of doughnut is in this picture", "gt answer": "powdered(1.00)<br/>jelly filled(1.00)", "pred answer": "doughnut", "question_id": 4437525, "best approach": "wiki, concept, image", "verif answer": "powdered", "anno approach": "wiki", "verif wiki answer": "powdered(0.6408)", "verif concept answer": "powdered(0.6214)", "verif image answer": "powdered(0.6385)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443752.jpg"}, {"question": "what kind of building is this", "gt answer": "apartment(1.00)", "pred answer": "church", "question_id": 2525445, "best approach": "wiki, concept, image", "verif answer": "apartment", "anno approach": "image, wiki", "verif wiki answer": "apartment(0.7117)", "verif concept answer": "apartment(0.6680)", "verif image answer": "apartment(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252544.jpg"}, {"question": "what kind of jacket is the man wearing", "gt answer": "peacoat(1.00)<br/>wool(1.00)<br/>fleece(0.60)", "pred answer": "suit", "question_id": 2518685, "best approach": "wiki, concept, image", "verif answer": "peacoat", "anno approach": "image, concept", "verif wiki answer": "peacoat(0.5932)", "verif concept answer": "wool(0.6495)", "verif image answer": "peacoat(0.7049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251868.jpg"}, {"question": "which muscle was engaged when the man on the right stood that way", "gt answer": "calf(1.00)", "pred answer": "leg", "question_id": 5228275, "best approach": "image", "verif answer": "calf", "anno approach": "image", "verif wiki answer": "bovine(0.5645)", "verif concept answer": "african(0.5909)", "verif image answer": "calf(0.6810)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522827.jpg"}, {"question": "what is the make of this vehicle", "gt answer": "volkswagon(1.00)<br/>vw(0.60)<br/>volkswagen(0.60)<br/>steel(0.60)", "pred answer": "jeep", "question_id": 366395, "best approach": "wiki, concept, image", "verif answer": "steel", "anno approach": "image, wiki", "verif wiki answer": "steel(0.5443)", "verif concept answer": "steel(0.5155)", "verif image answer": "steel(0.6072)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036639.jpg"}, {"question": "what would be a good side for this food", "gt answer": "salad(1.00)", "pred answer": "dough", "question_id": 1255855, "best approach": "", "verif answer": "butter", "anno approach": "", "verif wiki answer": "butter(0.7169)", "verif concept answer": "butter(0.7018)", "verif image answer": "butter(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125585.jpg"}, {"question": "is his fur soft or wire like", "gt answer": "soft(1.00)<br/>wire(0.60)", "pred answer": "shear", "question_id": 3444605, "best approach": "wiki, concept", "verif answer": "soft", "anno approach": "wiki", "verif wiki answer": "soft(0.5144)", "verif concept answer": "soft(0.5215)", "verif image answer": "silk(0.5126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344460.jpg"}, {"question": "what type of donut can been seen in this image", "gt answer": "cruller(1.00)<br/>sugar(0.60)", "pred answer": "glazed", "question_id": 4097065, "best approach": "", "verif answer": "flour", "anno approach": "", "verif wiki answer": "flour(0.5024)", "verif concept answer": "cream(0.5001)", "verif image answer": "flour(0.5274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409706.jpg"}, {"question": "what pattern is on the small bowl", "gt answer": "flower(1.00)<br/>floral(1.00)", "pred answer": "leopard", "question_id": 1305635, "best approach": "wiki, concept, image", "verif answer": "floral", "anno approach": "image, wiki", "verif wiki answer": "flower(0.6875)", "verif concept answer": "flower(0.6553)", "verif image answer": "floral(0.7112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130563.jpg"}, {"question": "which sport is the little girl practising for", "gt answer": "baseball(1.00)<br/>softball(0.60)", "pred answer": "soccer", "question_id": 4203985, "best approach": "", "verif answer": "outfield", "anno approach": "", "verif wiki answer": "wiffleball(0.6439)", "verif concept answer": "outfield(0.7025)", "verif image answer": "wiffleball(0.6665)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420398.jpg"}, {"question": "which president are these famous soft toys named after", "gt answer": "teddy roosevelt(1.00)<br/>roosevelt(0.60)<br/>theodore roosevelt(0.60)", "pred answer": "theodore roosevelt", "question_id": 5714485, "best approach": "wiki, concept, image", "verif answer": "theodore roosevelt", "anno approach": "wiki", "verif wiki answer": "theodore roosevelt(0.7254)", "verif concept answer": "theodore roosevelt(0.7291)", "verif image answer": "theodore roosevelt(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571448.jpg"}, {"question": "what kind of sidedish served with a a sandwich is crunchy", "gt answer": "chip(1.00)<br/>pasta(0.60)", "pred answer": "egg", "question_id": 3104595, "best approach": "wiki, concept, image", "verif answer": "chip", "anno approach": "image, wiki", "verif wiki answer": "chip(0.5652)", "verif concept answer": "chip(0.5270)", "verif image answer": "chip(0.5882)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310459.jpg"}, {"question": "what spice is shown on the table", "gt answer": "pepper(1.00)", "pred answer": "salt", "question_id": 3700595, "best approach": "wiki, concept, image", "verif answer": "pepper", "anno approach": "concept, wiki", "verif wiki answer": "pepper(0.6498)", "verif concept answer": "pepper(0.6910)", "verif image answer": "pepper(0.6213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370059.jpg"}, {"question": "why would we assume this man just hit the ball", "gt answer": "run(1.00)", "pred answer": "foul", "question_id": 2742325, "best approach": "wiki", "verif answer": "gallop", "anno approach": "wiki", "verif wiki answer": "run(0.6791)", "verif concept answer": "gallop(0.6788)", "verif image answer": "gallop(0.7027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274232.jpg"}, {"question": "what kind of plane is this", "gt answer": "prop(1.00)<br/>seaplane(0.60)<br/>small(0.60)", "pred answer": "biplane", "question_id": 3662045, "best approach": "wiki", "verif answer": "biplane", "anno approach": "wiki", "verif wiki answer": "prop(0.6644)", "verif concept answer": "biplane(0.6756)", "verif image answer": "biplane(0.7072)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366204.jpg"}, {"question": "what does the sign on the top imply", "gt answer": "no truck(1.00)", "pred answer": "street", "question_id": 159155, "best approach": "", "verif answer": "driveway", "anno approach": "", "verif wiki answer": "driveway(0.6737)", "verif concept answer": "driveway(0.6413)", "verif image answer": "driveway(0.6781)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015915.jpg"}, {"question": "what is the wire behind her head", "gt answer": "ski lift(1.00)<br/>cable(0.60)<br/>skilift(0.60)<br/>electric(0.60)", "pred answer": "helmet", "question_id": 1990395, "best approach": "wiki, concept, image", "verif answer": "ski lift", "anno approach": "concept, wiki", "verif wiki answer": "ski lift(0.6167)", "verif concept answer": "ski lift(0.6998)", "verif image answer": "ski lift(0.6331)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199039.jpg"}, {"question": "what is the name of the championship match for this sport", "gt answer": "us open(1.00)<br/>wimbledon(0.60)<br/>tennis(0.60)", "pred answer": "wimbledon", "question_id": 1309925, "best approach": "wiki, concept, image", "verif answer": "wimbledon", "anno approach": "image, wiki", "verif wiki answer": "wimbledon(0.6916)", "verif concept answer": "wimbledon(0.7134)", "verif image answer": "wimbledon(0.7275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130992.jpg"}, {"question": "is this animal in a zoo or its natural habitat", "gt answer": "natural habitat(1.00)", "pred answer": "urban", "question_id": 3644025, "best approach": "", "verif answer": "zoo", "anno approach": "", "verif wiki answer": "queen(0.5148)", "verif concept answer": "queen(0.5382)", "verif image answer": "zoo(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364402.jpg"}, {"question": "what grade is he in", "gt answer": "2nd(1.00)<br/>kindergarten(0.60)", "pred answer": "first", "question_id": 3579045, "best approach": "wiki, concept, image", "verif answer": "kindergarten", "anno approach": "image", "verif wiki answer": "kindergarten(0.5643)", "verif concept answer": "kindergarten(0.5882)", "verif image answer": "kindergarten(0.6338)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357904.jpg"}, {"question": "what are you supposed to insert into this object", "gt answer": "coin(1.00)<br/>quarter(0.60)<br/>change(0.60)", "pred answer": "coin", "question_id": 1017505, "best approach": "wiki, concept, image", "verif answer": "coin", "anno approach": "image", "verif wiki answer": "coin(0.6139)", "verif concept answer": "coin(0.6073)", "verif image answer": "coin(0.6530)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000101750.jpg"}, {"question": "what popular fast food restaurant is in this photo", "gt answer": "mcdonalds(1.00)<br/>mcdonald's(1.00)<br/>wooden(0.60)", "pred answer": "taco", "question_id": 2849015, "best approach": "wiki, concept", "verif answer": "mcdonalds", "anno approach": "wiki", "verif wiki answer": "mcdonald's(0.5427)", "verif concept answer": "mcdonalds(0.5477)", "verif image answer": "food(0.5379)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284901.jpg"}, {"question": "", "gt answer": "$50(0.60)<br/>50(0.60)<br/>200(0.60)<br/>$18(0.60)", "pred answer": "2010", "question_id": 102305, "best approach": "wiki, concept, image", "verif answer": "50", "anno approach": "concept, wiki", "verif wiki answer": "50(0.6481)", "verif concept answer": "50(0.6611)", "verif image answer": "$50(0.5260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000010230.jpg"}, {"question": "why is the person in the white shirt wearing a large leather glove on his left hand", "gt answer": "play baseball(1.00)<br/>catch(0.60)<br/>catcher(0.60)", "pred answer": "catch", "question_id": 5443255, "best approach": "wiki, concept, image", "verif answer": "catch", "anno approach": "wiki", "verif wiki answer": "catch(0.5722)", "verif concept answer": "catch(0.5550)", "verif image answer": "catcher(0.5504)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544325.jpg"}, {"question": "what do you call a specialist who repairs these devices", "gt answer": "mechanic(1.00)", "pred answer": "conductor", "question_id": 3215925, "best approach": "image", "verif answer": "mechanic", "anno approach": "image", "verif wiki answer": "chef(0.5018)", "verif concept answer": "chef(0.5004)", "verif image answer": "mechanic(0.7081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321592.jpg"}, {"question": "what 's the main ingredient in this dish", "gt answer": "pasta(1.00)<br/>noodle(0.60)", "pred answer": "vegetable", "question_id": 3977355, "best approach": "image", "verif answer": "noodle", "anno approach": "image", "verif wiki answer": "soup(0.5370)", "verif concept answer": "soup(0.5449)", "verif image answer": "noodle(0.6066)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397735.jpg"}, {"question": "what breed of dog is this", "gt answer": "rottweiler(1.00)<br/>beagle(0.60)<br/>dog(0.60)", "pred answer": "lab", "question_id": 4692815, "best approach": "concept, image", "verif answer": "doberman", "anno approach": "concept", "verif wiki answer": "doberman(0.7299)", "verif concept answer": "beagle(0.7140)", "verif image answer": "beagle(0.6664)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469281.jpg"}, {"question": "what kind of event is this animal participating in", "gt answer": "circus(1.00)<br/>elephant(0.60)", "pred answer": "circus", "question_id": 4097315, "best approach": "wiki, concept, image", "verif answer": "elephant", "anno approach": "image, concept, wiki", "verif wiki answer": "elephant(0.6383)", "verif concept answer": "elephant(0.6740)", "verif image answer": "elephant(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409731.jpg"}, {"question": "are these sheep wild or domesticated", "gt answer": "domesticated(1.00)<br/>wild(1.00)", "pred answer": "wild", "question_id": 3623285, "best approach": "wiki, concept, image", "verif answer": "wild", "anno approach": "wiki", "verif wiki answer": "wild(0.7308)", "verif concept answer": "wild(0.7310)", "verif image answer": "wild(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362328.jpg"}, {"question": "who is the woman on the wall", "gt answer": "model(1.00)<br/>advertising(0.60)", "pred answer": "tony hawk", "question_id": 4554275, "best approach": "", "verif answer": "fun", "anno approach": "", "verif wiki answer": "fun(0.7254)", "verif concept answer": "fun(0.7281)", "verif image answer": "fun(0.7243)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455427.jpg"}, {"question": "what animals have been domesticated", "gt answer": "cat(1.00)<br/>feline(0.60)", "pred answer": "cat", "question_id": 5555165, "best approach": "wiki, concept, image", "verif answer": "cat", "anno approach": "image, concept, wiki", "verif wiki answer": "cat(0.5736)", "verif concept answer": "cat(0.6390)", "verif image answer": "cat(0.6808)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555516.jpg"}, {"question": "name the type of aircraft shown in this picture", "gt answer": "fighter jet(1.00)", "pred answer": "fighter", "question_id": 436065, "best approach": "wiki, concept", "verif answer": "fighter jet", "anno approach": "wiki", "verif wiki answer": "fighter jet(0.6601)", "verif concept answer": "fighter jet(0.6914)", "verif image answer": "military(0.6584)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043606.jpg"}, {"question": "what brand of backpack is this", "gt answer": "jansport(1.00)<br/>north face(0.60)", "pred answer": "ll bean", "question_id": 4925455, "best approach": "", "verif answer": "polar", "anno approach": "", "verif wiki answer": "polar(0.6616)", "verif concept answer": "polar(0.6457)", "verif image answer": "polar(0.6541)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492545.jpg"}, {"question": "what style map is on the wall", "gt answer": "world(1.00)", "pred answer": "caricature", "question_id": 5616305, "best approach": "", "verif answer": "roman", "anno approach": "", "verif wiki answer": "roman(0.6390)", "verif concept answer": "roman(0.6413)", "verif image answer": "roman(0.6513)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561630.jpg"}, {"question": "what sets this apart from a city traffic jam", "gt answer": "cow(1.00)<br/>sheep(0.60)<br/>animal(0.60)", "pred answer": "cloth", "question_id": 4848405, "best approach": "", "verif answer": "goat", "anno approach": "", "verif wiki answer": "goat(0.5533)", "verif concept answer": "goat(0.6864)", "verif image answer": "goat(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484840.jpg"}, {"question": "cellphones can do what", "gt answer": "make call(1.00)<br/>call(0.60)", "pred answer": "run", "question_id": 4192495, "best approach": "concept", "verif answer": "nokia", "anno approach": "concept", "verif wiki answer": "call(0.5224)", "verif concept answer": "make call(0.5454)", "verif image answer": "nokia(0.6332)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419249.jpg"}, {"question": "color is usually associated with this disease", "gt answer": "breast cancer(1.00)<br/>cancer(0.60)<br/>red(0.60)", "pred answer": "grey", "question_id": 2272505, "best approach": "", "verif answer": "pink", "anno approach": "", "verif wiki answer": "pink(0.6046)", "verif concept answer": "pink(0.6241)", "verif image answer": "pink(0.6473)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000227250.jpg"}, {"question": "when would i eat this", "gt answer": "breakfast(1.00)<br/>dinner(0.60)<br/>lunch(0.60)", "pred answer": "dinner", "question_id": 4871825, "best approach": "concept", "verif answer": "cafeteria", "anno approach": "concept", "verif wiki answer": "cafeteria(0.6504)", "verif concept answer": "lunch(0.7019)", "verif image answer": "cafeteria(0.7071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487182.jpg"}, {"question": "what military branch does this jet belong to", "gt answer": "airforce(1.00)<br/>air force(0.60)<br/>navy(0.60)", "pred answer": "air force", "question_id": 1735965, "best approach": "wiki, concept, image", "verif answer": "air force", "anno approach": "wiki", "verif wiki answer": "air force(0.7109)", "verif concept answer": "air force(0.6972)", "verif image answer": "air force(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000173596.jpg"}, {"question": "who is the owner of this building", "gt answer": "pope(1.00)", "pred answer": "priest", "question_id": 606005, "best approach": "", "verif answer": "egypt", "anno approach": "", "verif wiki answer": "egypt(0.7149)", "verif concept answer": "egypt(0.7000)", "verif image answer": "egypt(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060600.jpg"}, {"question": "what 's the tower called", "gt answer": "clock(1.00)<br/>big ben(0.60)", "pred answer": "clock", "question_id": 5588495, "best approach": "wiki, image", "verif answer": "big ben", "anno approach": "image, wiki", "verif wiki answer": "big ben(0.5563)", "verif concept answer": "analog(0.6598)", "verif image answer": "big ben(0.6948)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558849.jpg"}, {"question": "what species of animal is in the picture", "gt answer": "bird(1.00)", "pred answer": "bird", "question_id": 925225, "best approach": "wiki, concept, image", "verif answer": "bird", "anno approach": "image, wiki", "verif wiki answer": "bird(0.6785)", "verif concept answer": "bird(0.7084)", "verif image answer": "bird(0.7276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092522.jpg"}, {"question": "what brand is this", "gt answer": "whirlpool(1.00)<br/>kenmore(0.60)<br/>maytag(0.60)", "pred answer": "kenmore", "question_id": 1182995, "best approach": "wiki, concept, image", "verif answer": "kenmore", "anno approach": "wiki", "verif wiki answer": "kenmore(0.6850)", "verif concept answer": "kenmore(0.7027)", "verif image answer": "kenmore(0.7086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118299.jpg"}, {"question": "what kind of company is advertised on the bus", "gt answer": "yahoo(1.00)<br/>internet(0.60)", "pred answer": "greenwave", "question_id": 3030225, "best approach": "wiki, concept, image", "verif answer": "yahoo", "anno approach": "image, concept, wiki", "verif wiki answer": "yahoo(0.5739)", "verif concept answer": "yahoo(0.6520)", "verif image answer": "yahoo(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303022.jpg"}, {"question": "where is this sport typically played", "gt answer": "tennis court(1.00)<br/>everywhere(0.60)<br/>park(0.60)<br/>europe(0.60)", "pred answer": "tennis court", "question_id": 4552275, "best approach": "concept, image", "verif answer": "tennis court", "anno approach": "", "verif wiki answer": "court(0.6817)", "verif concept answer": "tennis court(0.7098)", "verif image answer": "tennis court(0.7037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455227.jpg"}, {"question": "what shape is the traffic sign", "gt answer": "octagon(1.00)", "pred answer": "octagon", "question_id": 546075, "best approach": "", "verif answer": "circle", "anno approach": "", "verif wiki answer": "diamond(0.5477)", "verif concept answer": "circle(0.5825)", "verif image answer": "circle(0.6393)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054607.jpg"}, {"question": "how can this item be made neat", "gt answer": "make bed(1.00)", "pred answer": "1", "question_id": 848535, "best approach": "", "verif answer": "shear", "anno approach": "", "verif wiki answer": "shear(0.7045)", "verif concept answer": "shear(0.6508)", "verif image answer": "shear(0.6590)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084853.jpg"}, {"question": "which ocean is the beat for this activity", "gt answer": "pacific(1.00)<br/>atlantic(0.60)", "pred answer": "pacific", "question_id": 534965, "best approach": "", "verif answer": "atlantic ocean", "anno approach": "", "verif wiki answer": "pacific ocean(0.7257)", "verif concept answer": "pacific ocean(0.7291)", "verif image answer": "atlantic ocean(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053496.jpg"}, {"question": "what type of seat is this", "gt answer": "toilet(1.00)<br/>plastic(0.60)", "pred answer": "toilet", "question_id": 1237625, "best approach": "image", "verif answer": "toilet", "anno approach": "image", "verif wiki answer": "toilet seat(0.6235)", "verif concept answer": "toilet seat(0.5808)", "verif image answer": "toilet(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123762.jpg"}, {"question": "what kind of product was once stored here", "gt answer": "grain(1.00)<br/>corn(0.60)<br/>oil(0.60)", "pred answer": "beer", "question_id": 3057625, "best approach": "wiki, image", "verif answer": "corn", "anno approach": "wiki", "verif wiki answer": "corn(0.6812)", "verif concept answer": "dairy(0.6529)", "verif image answer": "corn(0.5616)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305762.jpg"}, {"question": "what type of bus is that", "gt answer": "double decker(1.00)<br/>double(0.60)", "pred answer": "tour bus", "question_id": 1784185, "best approach": "wiki, concept, image", "verif answer": "double decker", "anno approach": "wiki", "verif wiki answer": "double decker(0.7159)", "verif concept answer": "double decker(0.7208)", "verif image answer": "double decker(0.7110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178418.jpg"}, {"question": "what could have caused this to happen", "gt answer": "storm(1.00)<br/>flood(1.00)", "pred answer": "crash", "question_id": 4052095, "best approach": "", "verif answer": "fire", "anno approach": "", "verif wiki answer": "fire(0.6356)", "verif concept answer": "fire(0.7007)", "verif image answer": "fire(0.7249)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405209.jpg"}, {"question": "what kind of device are they using", "gt answer": "tablet(1.00)", "pred answer": "laptop", "question_id": 1142265, "best approach": "wiki, concept", "verif answer": "tablet", "anno approach": "wiki", "verif wiki answer": "tablet(0.6124)", "verif concept answer": "tablet(0.6160)", "verif image answer": "laptop(0.5317)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114226.jpg"}, {"question": "what is the complimentary color of the shirt of the man on the right", "gt answer": "blue(1.00)<br/>purple(0.60)<br/>red(0.60)<br/>green(0.60)", "pred answer": "yellow", "question_id": 1105305, "best approach": "wiki, concept", "verif answer": "white", "anno approach": "wiki", "verif wiki answer": "red(0.6240)", "verif concept answer": "red(0.5898)", "verif image answer": "white(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000110530.jpg"}, {"question": "at what time of day would she be doing this", "gt answer": "noon(1.00)<br/>morn(1.00)<br/>afternoon(0.60)", "pred answer": "afternoon", "question_id": 4679055, "best approach": "concept, image", "verif answer": "morn", "anno approach": "", "verif wiki answer": "afternoon(0.7010)", "verif concept answer": "morn(0.7120)", "verif image answer": "morn(0.7109)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467905.jpg"}, {"question": "what style of architecture is photographaed", "gt answer": "classic(1.00)<br/>victorian(0.60)<br/>gothic(0.60)<br/>spanish(0.60)", "pred answer": "roman", "question_id": 4033355, "best approach": "", "verif answer": "roman", "anno approach": "", "verif wiki answer": "roman(0.7098)", "verif concept answer": "roman(0.7138)", "verif image answer": "roman(0.6967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403335.jpg"}, {"question": "what size are these tools normally", "gt answer": "6 inches(1.00)<br/>small(0.60)<br/>8 inches(0.60)", "pred answer": "large", "question_id": 1702075, "best approach": "wiki", "verif answer": "12 inches", "anno approach": "wiki", "verif wiki answer": "8 inches(0.6970)", "verif concept answer": "12 inches(0.6893)", "verif image answer": "12 inches(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000170207.jpg"}, {"question": "what are these used for", "gt answer": "electron(1.00)<br/>travel(0.60)<br/>computer(0.60)", "pred answer": "compute", "question_id": 1519005, "best approach": "image", "verif answer": "travel", "anno approach": "image", "verif wiki answer": "compute(0.6953)", "verif concept answer": "compute(0.7129)", "verif image answer": "travel(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151900.jpg"}, {"question": "what power moves the boats with the long mast", "gt answer": "wind(1.00)", "pred answer": "anchor", "question_id": 4217755, "best approach": "", "verif answer": "string", "anno approach": "", "verif wiki answer": "string(0.6685)", "verif concept answer": "string(0.7003)", "verif image answer": "string(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421775.jpg"}, {"question": "what kind of birds are these", "gt answer": "geese(1.00)<br/>seagull(0.60)<br/>pelican(0.60)", "pred answer": "crow", "question_id": 5143565, "best approach": "image", "verif answer": "duck", "anno approach": "image", "verif wiki answer": "duck(0.6893)", "verif concept answer": "duck(0.7053)", "verif image answer": "geese(0.6938)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514356.jpg"}, {"question": "what is this person hanging from", "gt answer": "parachute(1.00)<br/>rope(0.60)<br/>ladder(0.60)", "pred answer": "surfboard", "question_id": 593135, "best approach": "", "verif answer": "string", "anno approach": "", "verif wiki answer": "string(0.6758)", "verif concept answer": "string(0.6794)", "verif image answer": "string(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059313.jpg"}, {"question": "can you guess the brand of bus shown in this photo", "gt answer": "greyhound(1.00)<br/>city bus(0.60)<br/>coach(0.60)", "pred answer": "ford", "question_id": 4798645, "best approach": "", "verif answer": "tour", "anno approach": "", "verif wiki answer": "tour(0.6246)", "verif concept answer": "tour(0.5939)", "verif image answer": "tour(0.6830)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479864.jpg"}, {"question": "how long do you thing you should cook this", "gt answer": "10 minutes(1.00)", "pred answer": "1 hour", "question_id": 2958035, "best approach": "image", "verif answer": "10 minutes", "anno approach": "image", "verif wiki answer": "1 hour(0.5369)", "verif concept answer": "1 hour(0.5645)", "verif image answer": "10 minutes(0.7059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295803.jpg"}, {"question": "what is double parked in this picture", "gt answer": "motorcycle(1.00)<br/>bike(0.60)", "pred answer": "trailer", "question_id": 1605245, "best approach": "image", "verif answer": "scooter", "anno approach": "image", "verif wiki answer": "scooter(0.7267)", "verif concept answer": "scooter(0.6873)", "verif image answer": "motorcycle(0.5995)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160524.jpg"}, {"question": "what are these animals used for", "gt answer": "food(1.00)<br/>milk(0.60)<br/>meat(0.60)", "pred answer": "meat", "question_id": 758835, "best approach": "wiki, concept", "verif answer": "cloth", "anno approach": "wiki", "verif wiki answer": "meat(0.5056)", "verif concept answer": "meat(0.5125)", "verif image answer": "cloth(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075883.jpg"}, {"question": "what are newborns called", "gt answer": "foal(1.00)<br/>colt(0.60)<br/>baby(0.60)", "pred answer": "zebra", "question_id": 938665, "best approach": "wiki, concept, image", "verif answer": "foal", "anno approach": "wiki", "verif wiki answer": "foal(0.6464)", "verif concept answer": "foal(0.6633)", "verif image answer": "foal(0.6606)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093866.jpg"}, {"question": "what is the black high seat and platform used for", "gt answer": "shoe shine(1.00)", "pred answer": "politic", "question_id": 3876855, "best approach": "image", "verif answer": "shoe shine", "anno approach": "image", "verif wiki answer": "light(0.5726)", "verif concept answer": "watch(0.5851)", "verif image answer": "shoe shine(0.6539)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387685.jpg"}, {"question": "what breed of sheep is this", "gt answer": "merino(1.00)<br/>sheep(0.60)", "pred answer": "merino", "question_id": 1235355, "best approach": "wiki, concept, image", "verif answer": "merino", "anno approach": "concept, wiki", "verif wiki answer": "merino(0.7206)", "verif concept answer": "merino(0.7228)", "verif image answer": "merino(0.6803)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123535.jpg"}, {"question": "what is this pitchers last name", "gt answer": "sonnanstine(1.00)", "pred answer": "randy johnson", "question_id": 1903825, "best approach": "", "verif answer": "baseball", "anno approach": "", "verif wiki answer": "baseball(0.5881)", "verif concept answer": "baseball(0.6160)", "verif image answer": "baseball(0.5118)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190382.jpg"}, {"question": "what kind of weather is it", "gt answer": "cloudy(1.00)<br/>sunny(0.60)", "pred answer": "cloudy", "question_id": 4506665, "best approach": "wiki, concept", "verif answer": "windy", "anno approach": "wiki", "verif wiki answer": "cloudy(0.7280)", "verif concept answer": "cloudy(0.7242)", "verif image answer": "windy(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450666.jpg"}, {"question": "what kind of cheese is that", "gt answer": "cheddar(1.00)", "pred answer": "chicago", "question_id": 4168845, "best approach": "", "verif answer": "tortilla", "anno approach": "", "verif wiki answer": "saudi arabia(0.5294)", "verif concept answer": "saudi arabia(0.5362)", "verif image answer": "tortilla(0.5733)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416884.jpg"}, {"question": "where is this", "gt answer": "ski resort(1.00)<br/>russia(0.60)", "pred answer": "alp", "question_id": 86305, "best approach": "wiki, concept, image", "verif answer": "ski resort", "anno approach": "wiki", "verif wiki answer": "ski resort(0.7310)", "verif concept answer": "ski resort(0.7310)", "verif image answer": "ski resort(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008630.jpg"}, {"question": "how long can this vessel travel", "gt answer": "100 miles(1.00)<br/>3 hours(0.60)", "pred answer": "hour", "question_id": 97455, "best approach": "", "verif answer": "hour", "anno approach": "", "verif wiki answer": "hour(0.6674)", "verif concept answer": "hour(0.6588)", "verif image answer": "hour(0.6172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009745.jpg"}, {"question": "what fuels the car", "gt answer": "vegetable oil(1.00)", "pred answer": "electricity", "question_id": 3036515, "best approach": "", "verif answer": "battery", "anno approach": "", "verif wiki answer": "battery(0.6721)", "verif concept answer": "battery(0.6727)", "verif image answer": "battery(0.6904)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303651.jpg"}, {"question": "what name is given to the ribbons on the kite 's back", "gt answer": "tail(1.00)", "pred answer": "string", "question_id": 361575, "best approach": "", "verif answer": "leather", "anno approach": "", "verif wiki answer": "leather(0.5404)", "verif concept answer": "leather(0.5498)", "verif image answer": "leather(0.5832)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036157.jpg"}, {"question": "what activity does the animal depicted here like to do", "gt answer": "eat wood(1.00)<br/>brush teeth(0.60)", "pred answer": "rodeo", "question_id": 3198185, "best approach": "", "verif answer": "cut", "anno approach": "", "verif wiki answer": "cut(0.5712)", "verif concept answer": "cut(0.5018)", "verif image answer": "cut(0.7008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319818.jpg"}, {"question": "what is the train on", "gt answer": "track(1.00)", "pred answer": "track", "question_id": 17125, "best approach": "wiki, concept, image", "verif answer": "track", "anno approach": "wiki", "verif wiki answer": "track(0.7274)", "verif concept answer": "track(0.7220)", "verif image answer": "track(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001712.jpg"}, {"question": "what are the long hairs on this cat 's face called", "gt answer": "whisker(1.00)", "pred answer": "long", "question_id": 3380915, "best approach": "wiki, concept, image", "verif answer": "whisker", "anno approach": "wiki", "verif wiki answer": "whisker(0.7285)", "verif concept answer": "whisker(0.7270)", "verif image answer": "whisker(0.7187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338091.jpg"}, {"question": "what species of bird is this", "gt answer": "crow(1.00)", "pred answer": "finch", "question_id": 1965405, "best approach": "", "verif answer": "pelican", "anno approach": "", "verif wiki answer": "pelican(0.6290)", "verif concept answer": "pelican(0.6427)", "verif image answer": "pelican(0.6907)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196540.jpg"}, {"question": "what is the name of the type of bread shown at the front", "gt answer": "roll(1.00)<br/>bun(0.60)", "pred answer": "doughnut", "question_id": 1248355, "best approach": "", "verif answer": "sourdough", "anno approach": "", "verif wiki answer": "sourdough(0.6744)", "verif concept answer": "sourdough(0.6321)", "verif image answer": "sourdough(0.6595)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000124835.jpg"}, {"question": "what is the slang term for how the beverage is served", "gt answer": "on rock(1.00)", "pred answer": "drink", "question_id": 1701015, "best approach": "", "verif answer": "mint", "anno approach": "", "verif wiki answer": "mint(0.7201)", "verif concept answer": "mint(0.7236)", "verif image answer": "mint(0.6503)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000170101.jpg"}, {"question": "what would you usually do with this item", "gt answer": "eat it(1.00)<br/>eat(1.00)", "pred answer": "read", "question_id": 2962865, "best approach": "", "verif answer": "picnic", "anno approach": "", "verif wiki answer": "picnic(0.6754)", "verif concept answer": "picnic(0.6063)", "verif image answer": "picnic(0.5148)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296286.jpg"}, {"question": "what type of horse is this", "gt answer": "palomino(1.00)", "pred answer": "arabian", "question_id": 1718345, "best approach": "", "verif answer": "pinto", "anno approach": "", "verif wiki answer": "pinto(0.6551)", "verif concept answer": "pinto(0.6539)", "verif image answer": "mustang(0.6525)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171834.jpg"}, {"question": "what part of flight is this plane in", "gt answer": "take off(1.00)", "pred answer": "take off", "question_id": 5406955, "best approach": "image", "verif answer": "take off", "anno approach": "image", "verif wiki answer": "takeoff(0.6185)", "verif concept answer": "takeoff(0.6346)", "verif image answer": "take off(0.6824)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540695.jpg"}, {"question": "what is this man about to do", "gt answer": "throw frisbee(1.00)<br/>throw(0.60)", "pred answer": "catch", "question_id": 2692635, "best approach": "", "verif answer": "catch", "anno approach": "", "verif wiki answer": "catch(0.7281)", "verif concept answer": "catch(0.7309)", "verif image answer": "catch(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269263.jpg"}, {"question": "what is the profession of the man in this photo", "gt answer": "soldier(1.00)<br/>military(0.60)", "pred answer": "shepherd", "question_id": 2514755, "best approach": "wiki, concept, image", "verif answer": "military", "anno approach": "image, wiki", "verif wiki answer": "military(0.5108)", "verif concept answer": "military(0.5088)", "verif image answer": "military(0.5878)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251475.jpg"}, {"question": "name the type of duck shown in this picture", "gt answer": "mallard(1.00)", "pred answer": "canada goose", "question_id": 1480105, "best approach": "wiki, concept, image", "verif answer": "mallard", "anno approach": "", "verif wiki answer": "mallard(0.7260)", "verif concept answer": "mallard(0.7191)", "verif image answer": "mallard(0.7122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148010.jpg"}, {"question": "is this meal healthy or unhealthy", "gt answer": "healthy(1.00)", "pred answer": "healthy", "question_id": 4151195, "best approach": "wiki, concept, image", "verif answer": "healthy", "anno approach": "image, wiki", "verif wiki answer": "healthy(0.6987)", "verif concept answer": "healthy(0.6942)", "verif image answer": "healthy(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415119.jpg"}, {"question": "what kind of fence surrounds the yard", "gt answer": "chain link(1.00)<br/>metal(0.60)", "pred answer": "concrete", "question_id": 1540625, "best approach": "wiki, concept, image", "verif answer": "chain link", "anno approach": "", "verif wiki answer": "chain link(0.7194)", "verif concept answer": "chain link(0.6981)", "verif image answer": "chain link(0.6959)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154062.jpg"}, {"question": "the standing hair on this animal 's neck is called its what", "gt answer": "mane(1.00)", "pred answer": "mane", "question_id": 3042235, "best approach": "", "verif answer": "pony tail", "anno approach": "", "verif wiki answer": "pony tail(0.7310)", "verif concept answer": "pony tail(0.7309)", "verif image answer": "stripe(0.7116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304223.jpg"}, {"question": "what would one use to get to the second level", "gt answer": "stair(1.00)<br/>step(0.60)<br/>ladder(0.60)", "pred answer": "bus", "question_id": 1498785, "best approach": "wiki, concept, image", "verif answer": "step", "anno approach": "image, concept", "verif wiki answer": "step(0.6274)", "verif concept answer": "ladder(0.6592)", "verif image answer": "step(0.6841)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149878.jpg"}, {"question": "is the broccoli on the plate steamed or baked", "gt answer": "steamed(1.00)", "pred answer": "grilled", "question_id": 2760045, "best approach": "", "verif answer": "boiled", "anno approach": "", "verif wiki answer": "boiled(0.6980)", "verif concept answer": "boiled(0.6156)", "verif image answer": "boiled(0.5706)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276004.jpg"}, {"question": "name the material used to make this toy shown in this picture", "gt answer": "plush(1.00)<br/>cotton(0.60)<br/>stuffing(0.60)<br/>fur(0.60)", "pred answer": "cotton", "question_id": 4755755, "best approach": "concept, image", "verif answer": "felt", "anno approach": "", "verif wiki answer": "felt(0.6600)", "verif concept answer": "fur(0.6465)", "verif image answer": "cotton(0.6451)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475575.jpg"}, {"question": "what makes this water look green", "gt answer": "algae(1.00)<br/>sky(0.60)", "pred answer": "algae", "question_id": 1673905, "best approach": "wiki, concept", "verif answer": "reflection of sky", "anno approach": "wiki", "verif wiki answer": "algae(0.7265)", "verif concept answer": "algae(0.7272)", "verif image answer": "reflection of sky(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167390.jpg"}, {"question": "what is the covering of this cake made from", "gt answer": "ice(1.00)<br/>frost(1.00)", "pred answer": "cotton", "question_id": 5795395, "best approach": "", "verif answer": "fondant", "anno approach": "", "verif wiki answer": "fondant(0.6602)", "verif concept answer": "fondant(0.6710)", "verif image answer": "fondant(0.6962)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000579539.jpg"}, {"question": "when was the pictured snowboarding company founded", "gt answer": "1977(1.00)<br/>1990(0.60)", "pred answer": "2000", "question_id": 3505185, "best approach": "", "verif answer": "1970", "anno approach": "", "verif wiki answer": "1980(0.6253)", "verif concept answer": "1980(0.6537)", "verif image answer": "1970(0.7084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350518.jpg"}, {"question": "what brand of computer is this", "gt answer": "ibm(1.00)<br/>dell(0.60)<br/>apple(0.60)<br/>hp(0.60)", "pred answer": "ibm", "question_id": 1849035, "best approach": "wiki, concept, image", "verif answer": "ibm", "anno approach": "wiki", "verif wiki answer": "ibm(0.7165)", "verif concept answer": "ibm(0.6719)", "verif image answer": "ibm(0.6400)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184903.jpg"}, {"question": "what model of laptop is this", "gt answer": "pc(1.00)<br/>dell(0.60)<br/>ibm(0.60)<br/>old(0.60)", "pred answer": "dell", "question_id": 2926885, "best approach": "wiki, concept", "verif answer": "pc", "anno approach": "wiki", "verif wiki answer": "pc(0.6899)", "verif concept answer": "pc(0.6640)", "verif image answer": "ibm(0.6285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292688.jpg"}, {"question": "where is this", "gt answer": "minneapolis(1.00)<br/>minnesota(0.60)", "pred answer": "street", "question_id": 3039625, "best approach": "wiki, concept, image", "verif answer": "minneapolis", "anno approach": "image", "verif wiki answer": "minneapolis(0.6842)", "verif concept answer": "minneapolis(0.7178)", "verif image answer": "minneapolis(0.7197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303962.jpg"}, {"question": "when a player of this game goes through all the bases without getting tagged that is called a what", "gt answer": "home run(1.00)<br/>homerun(0.60)", "pred answer": "home run", "question_id": 2237185, "best approach": "image", "verif answer": "homerun", "anno approach": "image", "verif wiki answer": "homerun(0.7183)", "verif concept answer": "homerun(0.7276)", "verif image answer": "home run(0.6966)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223718.jpg"}, {"question": "how do tennis players keep water out of their eyes", "gt answer": "umbrella(1.00)", "pred answer": "goggle", "question_id": 2672105, "best approach": "wiki, concept, image", "verif answer": "umbrella", "anno approach": "concept, wiki", "verif wiki answer": "umbrella(0.6752)", "verif concept answer": "umbrella(0.6708)", "verif image answer": "umbrella(0.6267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000267210.jpg"}, {"question": "what profession would need to be called if a fix is needed", "gt answer": "plumber(1.00)", "pred answer": "toilet paper", "question_id": 5517465, "best approach": "wiki, concept", "verif answer": "plumber", "anno approach": "wiki", "verif wiki answer": "plumber(0.7307)", "verif concept answer": "plumber(0.7309)", "verif image answer": "janitor(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000551746.jpg"}, {"question": "what sport is this", "gt answer": "tennis(1.00)", "pred answer": "tennis", "question_id": 402985, "best approach": "concept, image", "verif answer": "tennis", "anno approach": "", "verif wiki answer": "tennis shoe(0.7279)", "verif concept answer": "tennis(0.7220)", "verif image answer": "tennis(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040298.jpg"}, {"question": "which profession is associated with these items", "gt answer": "barber(1.00)<br/>hair stylist(0.60)", "pred answer": "cook", "question_id": 4537725, "best approach": "wiki, concept, image", "verif answer": "barber", "anno approach": "", "verif wiki answer": "barber(0.7139)", "verif concept answer": "barber(0.7075)", "verif image answer": "barber(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453772.jpg"}, {"question": "which dog breed is associated with this vehicle", "gt answer": "dalmation(1.00)<br/>dalmatian(0.60)", "pred answer": "chicago", "question_id": 5436225, "best approach": "wiki", "verif answer": "dalmatian", "anno approach": "wiki", "verif wiki answer": "dalmation(0.6448)", "verif concept answer": "dalmatian(0.6409)", "verif image answer": "dalmatian(0.6975)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543622.jpg"}, {"question": "is the train stopped or moving", "gt answer": "stopped(1.00)<br/>move(1.00)", "pred answer": "go", "question_id": 3921055, "best approach": "image", "verif answer": "move", "anno approach": "image", "verif wiki answer": "balance(0.5792)", "verif concept answer": "balance(0.5753)", "verif image answer": "move(0.5855)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392105.jpg"}, {"question": "what kind of car is this", "gt answer": "bmw(1.00)<br/>mercedes(0.60)", "pred answer": "sedan", "question_id": 2037115, "best approach": "", "verif answer": "kawasaki", "anno approach": "", "verif wiki answer": "kawasaki(0.7095)", "verif concept answer": "kawasaki(0.6735)", "verif image answer": "germany(0.6192)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203711.jpg"}, {"question": "what is another name for cat", "gt answer": "feline(1.00)<br/>kitten(0.60)", "pred answer": "persian", "question_id": 5590735, "best approach": "", "verif answer": "felis catus", "anno approach": "", "verif wiki answer": "felis catus(0.7264)", "verif concept answer": "felis catus(0.7255)", "verif image answer": "felis catus(0.6521)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559073.jpg"}, {"question": "which greek god is associated with this type of scene", "gt answer": "poseidon(1.00)", "pred answer": "alaska", "question_id": 2109895, "best approach": "wiki, concept, image", "verif answer": "poseidon", "anno approach": "concept, wiki", "verif wiki answer": "poseidon(0.6771)", "verif concept answer": "poseidon(0.6996)", "verif image answer": "poseidon(0.6502)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210989.jpg"}, {"question": "what type of aircraft has rotors on top", "gt answer": "helicopter(1.00)", "pred answer": "biplane", "question_id": 4147545, "best approach": "wiki, concept, image", "verif answer": "helicopter", "anno approach": "wiki", "verif wiki answer": "helicopter(0.6672)", "verif concept answer": "helicopter(0.6335)", "verif image answer": "helicopter(0.6285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000414754.jpg"}, {"question": "what types of skills are needed to change tires", "gt answer": "mechanical(1.00)", "pred answer": "cdl", "question_id": 4203725, "best approach": "", "verif answer": "qwerty", "anno approach": "", "verif wiki answer": "qwerty(0.7178)", "verif concept answer": "qwerty(0.7078)", "verif image answer": "qwerty(0.6384)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420372.jpg"}, {"question": "what type of tools is this man using", "gt answer": "scissor(1.00)<br/>sew machine(0.60)", "pred answer": "hammer", "question_id": 3750045, "best approach": "", "verif answer": "hammer", "anno approach": "", "verif wiki answer": "hammer(0.6939)", "verif concept answer": "hammer(0.6896)", "verif image answer": "hammer(0.6883)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375004.jpg"}, {"question": "", "gt answer": "end of day(0.60)<br/>zombies(0.60)", "pred answer": "christianity", "question_id": 3778685, "best approach": "image", "verif answer": "100 years", "anno approach": "image", "verif wiki answer": "100 years(0.6256)", "verif concept answer": "100 years(0.6654)", "verif image answer": "end of day(0.5708)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377868.jpg"}, {"question": "what place is she at", "gt answer": "salon(1.00)", "pred answer": "restaurant", "question_id": 5747605, "best approach": "", "verif answer": "university", "anno approach": "", "verif wiki answer": "university(0.6546)", "verif concept answer": "mall(0.6659)", "verif image answer": "university(0.7118)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000574760.jpg"}, {"question": "what brand of skateboard is he riding", "gt answer": "element(1.00)<br/>wooden(0.60)", "pred answer": "van", "question_id": 2168255, "best approach": "", "verif answer": "van", "anno approach": "", "verif wiki answer": "van(0.6900)", "verif concept answer": "van(0.6382)", "verif image answer": "van(0.6121)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216825.jpg"}, {"question": "is this food real or fake", "gt answer": "fake(1.00)<br/>real(1.00)", "pred answer": "fake", "question_id": 3921525, "best approach": "wiki, concept, image", "verif answer": "fake", "anno approach": "", "verif wiki answer": "fake(0.7310)", "verif concept answer": "fake(0.7310)", "verif image answer": "fake(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392152.jpg"}, {"question": "what material are these suits made of", "gt answer": "neoprene(1.00)<br/>rubber(1.00)<br/>polyester(0.60)", "pred answer": "neoprene", "question_id": 2265775, "best approach": "concept, image", "verif answer": "foam", "anno approach": "concept", "verif wiki answer": "foam(0.7084)", "verif concept answer": "neoprene(0.6877)", "verif image answer": "neoprene(0.6463)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226577.jpg"}, {"question": "what type of animals are used in this sporting event", "gt answer": "horse(1.00)", "pred answer": "horse", "question_id": 2753485, "best approach": "wiki, concept, image", "verif answer": "horse", "anno approach": "wiki", "verif wiki answer": "horse(0.6901)", "verif concept answer": "horse(0.6993)", "verif image answer": "horse(0.6681)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000275348.jpg"}, {"question": "what was the first year a human successfully traveled on one of these", "gt answer": "1903(1.00)<br/>1924(0.60)", "pred answer": "1984", "question_id": 408905, "best approach": "wiki, concept, image", "verif answer": "1903", "anno approach": "wiki", "verif wiki answer": "1903(0.6869)", "verif concept answer": "1903(0.6826)", "verif image answer": "1903(0.6644)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040890.jpg"}, {"question": "how do these animals communicate a sense of contentment to their owners", "gt answer": "purr(1.00)<br/>music(0.60)<br/>pure(0.60)", "pred answer": "clean", "question_id": 436555, "best approach": "wiki, concept, image", "verif answer": "pure", "anno approach": "image, wiki", "verif wiki answer": "pure(0.5251)", "verif concept answer": "pure(0.5225)", "verif image answer": "pure(0.6695)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043655.jpg"}, {"question": "what vegetable here is mainly flowers", "gt answer": "broccoli(1.00)", "pred answer": "broccoli", "question_id": 581725, "best approach": "", "verif answer": "meat", "anno approach": "", "verif wiki answer": "meat(0.6818)", "verif concept answer": "meat(0.6778)", "verif image answer": "meat(0.6538)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058172.jpg"}, {"question": "which mythical creature often appears as part of the architecture of sites such as this", "gt answer": "griffin(1.00)<br/>dolphin(0.60)", "pred answer": "stone", "question_id": 5054895, "best approach": "image", "verif answer": "fish", "anno approach": "image", "verif wiki answer": "fish(0.6555)", "verif concept answer": "octopus(0.6192)", "verif image answer": "griffin(0.6446)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505489.jpg"}, {"question": "what is the name of the band that wrote many famous songs about the pictured activity", "gt answer": "beach boy(1.00)", "pred answer": "beach boy", "question_id": 4120625, "best approach": "", "verif answer": "bongo", "anno approach": "", "verif wiki answer": "bongo(0.7309)", "verif concept answer": "bongo(0.7310)", "verif image answer": "bongo(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412062.jpg"}, {"question": "what is hanging on the ceiling", "gt answer": "lamp(1.00)<br/>chandelier(0.60)<br/>light(0.60)", "pred answer": "light", "question_id": 4326225, "best approach": "wiki, concept", "verif answer": "lamp", "anno approach": "wiki", "verif wiki answer": "lamp(0.7271)", "verif concept answer": "lamp(0.6330)", "verif image answer": "sunlight(0.6291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432622.jpg"}, {"question": "tell me the variety of birds which are seen in this picture", "gt answer": "crow(0.60)<br/>pigeon(1.00)", "pred answer": "pigeon", "question_id": 4734205, "best approach": "", "verif answer": "black", "anno approach": "", "verif wiki answer": "dove(0.6251)", "verif concept answer": "black(0.6299)", "verif image answer": "black(0.6533)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473420.jpg"}, {"question": "what is the largest us restaurant chain that sells this item", "gt answer": "subway(1.00)", "pred answer": "walmart", "question_id": 1106975, "best approach": "", "verif answer": "bristol", "anno approach": "", "verif wiki answer": "bristol(0.7230)", "verif concept answer": "bristol(0.7234)", "verif image answer": "bristol(0.6602)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000110697.jpg"}, {"question": "what time of day would someone use this", "gt answer": "night(1.00)<br/>nighttime(0.60)", "pred answer": "night", "question_id": 3885685, "best approach": "wiki, concept, image", "verif answer": "night", "anno approach": "wiki", "verif wiki answer": "night(0.7191)", "verif concept answer": "night(0.7274)", "verif image answer": "night(0.7187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388568.jpg"}, {"question": "what is the number on the batter 's jersey", "gt answer": "16(1.00)<br/>19(1.00)", "pred answer": "15", "question_id": 5399675, "best approach": "", "verif answer": "17", "anno approach": "", "verif wiki answer": "17(0.6919)", "verif concept answer": "17(0.6906)", "verif image answer": "17(0.6639)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539967.jpg"}, {"question": "what is the nearest relative of this animal", "gt answer": "horse(1.00)<br/>donkey(0.60)", "pred answer": "zebra", "question_id": 3543165, "best approach": "image", "verif answer": "donkey", "anno approach": "image", "verif wiki answer": "sheep(0.6307)", "verif concept answer": "sheep(0.6559)", "verif image answer": "donkey(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354316.jpg"}, {"question": "what do you do here", "gt answer": "sleep(1.00)<br/>bed(0.60)", "pred answer": "sleep", "question_id": 1162205, "best approach": "wiki, concept, image", "verif answer": "sleep", "anno approach": "concept, wiki", "verif wiki answer": "sleep(0.6895)", "verif concept answer": "sleep(0.7009)", "verif image answer": "sleep(0.5313)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116220.jpg"}, {"question": "why do people hold remotes like those", "gt answer": "video game(1.00)<br/>play game(1.00)", "pred answer": "watch", "question_id": 675605, "best approach": "", "verif answer": "wii", "anno approach": "", "verif wiki answer": "wii(0.6865)", "verif concept answer": "wii(0.6911)", "verif image answer": "wii(0.6585)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067560.jpg"}, {"question": "what time of day is this photo taken", "gt answer": "sunset(1.00)<br/>sunrise(0.60)<br/>even(0.60)<br/>dusk(0.60)", "pred answer": "sunset", "question_id": 2505785, "best approach": "concept, image", "verif answer": "sunset", "anno approach": "", "verif wiki answer": "dusk(0.6943)", "verif concept answer": "sunset(0.6940)", "verif image answer": "sunset(0.7067)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250578.jpg"}, {"question": "how much wsa the costume", "gt answer": "$60(1.00)<br/>200(0.60)", "pred answer": "lot", "question_id": 4963395, "best approach": "", "verif answer": "20 grams", "anno approach": "", "verif wiki answer": "20 grams(0.6343)", "verif concept answer": "20 grams(0.6190)", "verif image answer": "20 grams(0.6542)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496339.jpg"}, {"question": "what type of meat is in this meal", "gt answer": "corned beef(1.00)<br/>roast beef(0.60)", "pred answer": "roast beef", "question_id": 680285, "best approach": "wiki, concept", "verif answer": "roast beef", "anno approach": "wiki", "verif wiki answer": "roast beef(0.6908)", "verif concept answer": "roast beef(0.6872)", "verif image answer": "fish(0.6839)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068028.jpg"}, {"question": "what is the most popular topping for these items", "gt answer": "glaze(1.00)<br/>ice(0.60)", "pred answer": "doughnut", "question_id": 3873935, "best approach": "", "verif answer": "ketchup", "anno approach": "", "verif wiki answer": "ketchup(0.7155)", "verif concept answer": "ketchup(0.7064)", "verif image answer": "ketchup(0.7157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387393.jpg"}, {"question": "what is the horse being prepared for", "gt answer": "race(1.00)", "pred answer": "ride", "question_id": 2102055, "best approach": "", "verif answer": "ride", "anno approach": "", "verif wiki answer": "ride(0.6735)", "verif concept answer": "ride(0.6959)", "verif image answer": "ride(0.6506)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210205.jpg"}, {"question": "which model of suitcase is this shown in this picture", "gt answer": "samsonite(1.00)<br/>columbia(0.60)", "pred answer": "suitcase", "question_id": 2954485, "best approach": "", "verif answer": "suitcase", "anno approach": "", "verif wiki answer": "ll bean(0.7071)", "verif concept answer": "ll bean(0.6695)", "verif image answer": "suitcase(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295448.jpg"}, {"question": "what is the relationship between these two people", "gt answer": "mother and child(1.00)<br/>close(0.60)", "pred answer": "married", "question_id": 5325775, "best approach": "image", "verif answer": "family", "anno approach": "image", "verif wiki answer": "family(0.7292)", "verif concept answer": "friend(0.7007)", "verif image answer": "mother and child(0.7271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532577.jpg"}, {"question": "what country is this person in", "gt answer": "uk(1.00)<br/>canada(0.60)<br/>france(0.60)<br/>london(0.60)", "pred answer": "england", "question_id": 1215825, "best approach": "image", "verif answer": "uk", "anno approach": "image", "verif wiki answer": "canada(0.6902)", "verif concept answer": "canada(0.6830)", "verif image answer": "uk(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000121582.jpg"}, {"question": "what country is named here", "gt answer": "tahiti(1.00)", "pred answer": "australia", "question_id": 4515745, "best approach": "wiki, concept", "verif answer": "tahiti", "anno approach": "", "verif wiki answer": "tahiti(0.7162)", "verif concept answer": "tahiti(0.7125)", "verif image answer": "canada(0.6353)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451574.jpg"}, {"question": "what sort of joint distress affecting the middle of the arm borrows its name from the game played with this racket", "gt answer": "tennis elbow(1.00)<br/>tennis(0.60)", "pred answer": "net", "question_id": 2599605, "best approach": "", "verif answer": "wimbledon", "anno approach": "", "verif wiki answer": "wimbledon(0.7264)", "verif concept answer": "wimbledon(0.7309)", "verif image answer": "wimbledon(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259960.jpg"}, {"question": "what kind of fungus is in this picture", "gt answer": "mushroom(1.00)<br/>spinach(0.60)", "pred answer": "wheat", "question_id": 716845, "best approach": "image", "verif answer": "sprite", "anno approach": "image", "verif wiki answer": "sprite(0.7031)", "verif concept answer": "sprite(0.7202)", "verif image answer": "mushroom(0.6428)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071684.jpg"}, {"question": "how many of these kinds of establishments are there in the united states", "gt answer": "thousand(1.00)<br/>10000(1.00)", "pred answer": "3", "question_id": 4223365, "best approach": "", "verif answer": "1000", "anno approach": "", "verif wiki answer": "million(0.5653)", "verif concept answer": "million(0.6001)", "verif image answer": "1000(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422336.jpg"}, {"question": "what kind of board is that", "gt answer": "snowboard(1.00)", "pred answer": "half pipe", "question_id": 4074055, "best approach": "", "verif answer": "half pipe", "anno approach": "", "verif wiki answer": "half pipe(0.7291)", "verif concept answer": "half pipe(0.7270)", "verif image answer": "half pipe(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407405.jpg"}, {"question": "what is the child wearing over their red shirt", "gt answer": "overall(1.00)", "pred answer": "apron", "question_id": 81765, "best approach": "", "verif answer": "scarf", "anno approach": "", "verif wiki answer": "scarf(0.5708)", "verif concept answer": "scarf(0.5967)", "verif image answer": "scarf(0.5762)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008176.jpg"}, {"question": "the shown fruit is good for which parts of the body", "gt answer": "teeth(1.00)<br/>brain(0.60)", "pred answer": "stomach", "question_id": 3696315, "best approach": "", "verif answer": "muscle", "anno approach": "", "verif wiki answer": "muscle(0.6687)", "verif concept answer": "muscle(0.6664)", "verif image answer": "muscle(0.6958)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369631.jpg"}, {"question": "where is this park", "gt answer": "washington dc(1.00)<br/>united state(0.60)<br/>america(0.60)", "pred answer": "washington dc", "question_id": 1692045, "best approach": "wiki, concept, image", "verif answer": "washington dc", "anno approach": "wiki", "verif wiki answer": "washington dc(0.7006)", "verif concept answer": "washington dc(0.6944)", "verif image answer": "washington dc(0.6756)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169204.jpg"}, {"question": "how hard is she gonna hit that ball", "gt answer": "very hard(1.00)", "pred answer": "forehand", "question_id": 4990275, "best approach": "", "verif answer": "forehand", "anno approach": "", "verif wiki answer": "tennis(0.5652)", "verif concept answer": "forehand(0.6027)", "verif image answer": "forehand(0.5304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499027.jpg"}, {"question": "what animal do you see", "gt answer": "giraffe(1.00)", "pred answer": "giraffe", "question_id": 3081705, "best approach": "wiki", "verif answer": "giraffe", "anno approach": "wiki", "verif wiki answer": "giraffe(0.7309)", "verif concept answer": "calf(0.7307)", "verif image answer": "calf(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308170.jpg"}, {"question": "are these animals safe or in danger", "gt answer": "safe(1.00)", "pred answer": "safe", "question_id": 170555, "best approach": "concept, image", "verif answer": "safe", "anno approach": "image", "verif wiki answer": "unsafe(0.5405)", "verif concept answer": "safe(0.6730)", "verif image answer": "safe(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000017055.jpg"}, {"question": "what kind of food might be cooked with the white appliance on the shelf", "gt answer": "popcorn(1.00)<br/>tea(0.60)", "pred answer": "dish", "question_id": 3022305, "best approach": "", "verif answer": "fruit", "anno approach": "", "verif wiki answer": "fruit(0.6833)", "verif concept answer": "fruit(0.6928)", "verif image answer": "fruit(0.5906)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302230.jpg"}, {"question": "how fast can this train go", "gt answer": "120 mph(1.00)<br/>100 mph(0.60)<br/>300(0.60)<br/>80 mph(0.60)", "pred answer": "80 mph", "question_id": 3878495, "best approach": "wiki, concept", "verif answer": "100 mph", "anno approach": "wiki", "verif wiki answer": "120 mph(0.6624)", "verif concept answer": "120 mph(0.6362)", "verif image answer": "100 mph(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387849.jpg"}, {"question": "", "gt answer": "rockies(0.60)<br/>mount ranier(0.60)", "pred answer": "rockies", "question_id": 3070695, "best approach": "wiki, concept, image", "verif answer": "rockies", "anno approach": "", "verif wiki answer": "rockies(0.7005)", "verif concept answer": "rockies(0.7084)", "verif image answer": "rockies(0.7005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307069.jpg"}, {"question": "how is the flavor of the frosting on the donut", "gt answer": "sweet(1.00)<br/>chocolate(1.00)<br/>caramel(0.60)", "pred answer": "vanilla", "question_id": 4735905, "best approach": "concept, image", "verif answer": "sweet", "anno approach": "image", "verif wiki answer": "caramel(0.5178)", "verif concept answer": "sweet(0.5383)", "verif image answer": "sweet(0.5876)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473590.jpg"}, {"question": "how high can that crane reach", "gt answer": "200 feet(1.00)", "pred answer": "15", "question_id": 2566375, "best approach": "image", "verif answer": "200 feet", "anno approach": "image", "verif wiki answer": "3 feet(0.7028)", "verif concept answer": "very high(0.7029)", "verif image answer": "200 feet(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256637.jpg"}, {"question": "which one would a monkey choose", "gt answer": "banana(1.00)", "pred answer": "apple", "question_id": 2767815, "best approach": "", "verif answer": "apple", "anno approach": "", "verif wiki answer": "apple(0.7310)", "verif concept answer": "apple(0.7310)", "verif image answer": "apple(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276781.jpg"}, {"question": "what kind of car is the horse next to", "gt answer": "porch(1.00)<br/>porsche(1.00)", "pred answer": "sedan", "question_id": 337325, "best approach": "wiki", "verif answer": "suv", "anno approach": "wiki", "verif wiki answer": "porsche(0.5367)", "verif concept answer": "suv(0.5531)", "verif image answer": "suv(0.5084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033732.jpg"}, {"question": "what toppings are on this hot dog", "gt answer": "ketchup and relish(1.00)<br/>ketchup(0.60)", "pred answer": "ketchup", "question_id": 531315, "best approach": "wiki, concept, image", "verif answer": "ketchup", "anno approach": "image, wiki", "verif wiki answer": "ketchup(0.5690)", "verif concept answer": "ketchup(0.5572)", "verif image answer": "ketchup(0.6797)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053131.jpg"}, {"question": "how do you make this dish", "gt answer": "bake(1.00)<br/>bake it(0.60)<br/>oven(0.60)", "pred answer": "baked", "question_id": 3137575, "best approach": "concept", "verif answer": "baked", "anno approach": "concept", "verif wiki answer": "baked(0.7177)", "verif concept answer": "bake(0.6999)", "verif image answer": "baked(0.6421)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313757.jpg"}, {"question": "what country was this photograph taken in", "gt answer": "thailand(1.00)<br/>germany(0.60)<br/>england(0.60)<br/>china(0.60)", "pred answer": "england", "question_id": 3730535, "best approach": "wiki, image", "verif answer": "germany", "anno approach": "image, wiki", "verif wiki answer": "germany(0.6619)", "verif concept answer": "spain(0.6666)", "verif image answer": "germany(0.6969)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373053.jpg"}, {"question": "what bridge is this in the background", "gt answer": "golden gate(1.00)", "pred answer": "golden gate", "question_id": 100585, "best approach": "wiki, concept, image", "verif answer": "golden gate", "anno approach": "wiki", "verif wiki answer": "golden gate(0.6852)", "verif concept answer": "golden gate(0.7075)", "verif image answer": "golden gate(0.7124)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000010058.jpg"}, {"question": "what kind of water is in the ocean", "gt answer": "salt water(1.00)<br/>saltwater(1.00)", "pred answer": "lake", "question_id": 5021525, "best approach": "", "verif answer": "wide angle", "anno approach": "", "verif wiki answer": "wide angle(0.7213)", "verif concept answer": "wide angle(0.7151)", "verif image answer": "lake(0.6847)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502152.jpg"}, {"question": "where does this animal usually live", "gt answer": "house(1.00)", "pred answer": "beach", "question_id": 5588635, "best approach": "", "verif answer": "apartment", "anno approach": "", "verif wiki answer": "apartment(0.6691)", "verif concept answer": "home(0.6737)", "verif image answer": "apartment(0.7176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558863.jpg"}, {"question": "what kind of clock is this", "gt answer": "grandfather(1.00)<br/>analog(1.00)", "pred answer": "roman", "question_id": 3521625, "best approach": "", "verif answer": "grandfather clock", "anno approach": "", "verif wiki answer": "grandfather clock(0.7205)", "verif concept answer": "grandfather clock(0.7061)", "verif image answer": "grandfather clock(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000352162.jpg"}, {"question": "which computer operating system is he using", "gt answer": "window(1.00)", "pred answer": "laptop", "question_id": 3106065, "best approach": "", "verif answer": "mac", "anno approach": "", "verif wiki answer": "mac(0.7098)", "verif concept answer": "mac(0.6924)", "verif image answer": "mac(0.6341)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310606.jpg"}, {"question": "how fast can a plane like this fly", "gt answer": "700 mph(1.00)<br/>200 mph(0.60)", "pred answer": "40 mph", "question_id": 2108065, "best approach": "concept", "verif answer": "500 mph", "anno approach": "concept", "verif wiki answer": "500 mph(0.5944)", "verif concept answer": "200 mph(0.5432)", "verif image answer": "500 mph(0.7162)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210806.jpg"}, {"question": "what type of boats are these", "gt answer": "row(1.00)<br/>fish boat(0.60)<br/>canoes(0.60)", "pred answer": "fish", "question_id": 2813305, "best approach": "image", "verif answer": "canoes", "anno approach": "image", "verif wiki answer": "canoe(0.5905)", "verif concept answer": "canoe(0.6224)", "verif image answer": "canoes(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281330.jpg"}, {"question": "what are the mens occupation called", "gt answer": "chef(1.00)", "pred answer": "chef", "question_id": 4278325, "best approach": "wiki, concept, image", "verif answer": "chef", "anno approach": "wiki", "verif wiki answer": "chef(0.7305)", "verif concept answer": "chef(0.7028)", "verif image answer": "chef(0.6787)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427832.jpg"}, {"question": "what municipality does this officer represent", "gt answer": "police(1.00)<br/>london(1.00)", "pred answer": "germany", "question_id": 3218215, "best approach": "", "verif answer": "police officer", "anno approach": "", "verif wiki answer": "police officer(0.6678)", "verif concept answer": "police officer(0.6540)", "verif image answer": "police officer(0.6862)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321821.jpg"}, {"question": "where is this beer 's brand headquartered", "gt answer": "belgium(1.00)<br/>france(0.60)<br/>united state(0.60)<br/>spain(0.60)", "pred answer": "usa", "question_id": 4540725, "best approach": "concept, image", "verif answer": "belgium", "anno approach": "", "verif wiki answer": "spain(0.6144)", "verif concept answer": "belgium(0.6729)", "verif image answer": "belgium(0.6429)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000454072.jpg"}, {"question": "what is the man using", "gt answer": "computer(1.00)", "pred answer": "computer", "question_id": 1145195, "best approach": "", "verif answer": "work", "anno approach": "", "verif wiki answer": "work(0.7156)", "verif concept answer": "work(0.6953)", "verif image answer": "work(0.7275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114519.jpg"}, {"question": "what number did someone call", "gt answer": "911(1.00)", "pred answer": "100", "question_id": 5265145, "best approach": "", "verif answer": "20th", "anno approach": "", "verif wiki answer": "20th(0.7012)", "verif concept answer": "50(0.6692)", "verif image answer": "20th(0.6655)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526514.jpg"}, {"question": "how much weight can this breed of horse pull", "gt answer": "2000(1.00)<br/>500(0.60)", "pred answer": "lot", "question_id": 5643145, "best approach": "", "verif answer": "50", "anno approach": "", "verif wiki answer": "1600 lbs(0.5000)", "verif concept answer": "50(0.5008)", "verif image answer": "50(0.5673)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564314.jpg"}, {"question": "is this a gas or electric stove", "gt answer": "electric(1.00)", "pred answer": "electric", "question_id": 1779775, "best approach": "", "verif answer": "gas", "anno approach": "", "verif wiki answer": "gas(0.7233)", "verif concept answer": "gas(0.6964)", "verif image answer": "gas(0.6386)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177977.jpg"}, {"question": "what style of hat is being worn by the man not seen here", "gt answer": "bowler(1.00)<br/>fedora(1.00)", "pred answer": "fedora", "question_id": 4958605, "best approach": "wiki, concept, image", "verif answer": "fedora", "anno approach": "wiki", "verif wiki answer": "fedora(0.7248)", "verif concept answer": "fedora(0.7297)", "verif image answer": "fedora(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495860.jpg"}, {"question": "what other bird is known to stand like this", "gt answer": "flamingo(1.00)<br/>pelican(0.60)<br/>duck(0.60)", "pred answer": "duck", "question_id": 2853235, "best approach": "wiki, concept", "verif answer": "pelican", "anno approach": "concept, wiki", "verif wiki answer": "flamingo(0.6406)", "verif concept answer": "flamingo(0.6762)", "verif image answer": "pelican(0.6922)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285323.jpg"}, {"question": "what is the title of the person driving this vehicle", "gt answer": "pilot(1.00)", "pred answer": "air force 1", "question_id": 2417905, "best approach": "wiki", "verif answer": "military", "anno approach": "wiki", "verif wiki answer": "pilot(0.5649)", "verif concept answer": "military(0.6342)", "verif image answer": "military(0.6530)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241790.jpg"}, {"question": "what chemical is in the cats that makes them fly", "gt answer": "helium(1.00)<br/>air(0.60)<br/>toxoplasmosis(0.60)", "pred answer": "electricity", "question_id": 3918235, "best approach": "wiki, image", "verif answer": "helium", "anno approach": "image", "verif wiki answer": "helium(0.6505)", "verif concept answer": "balloon(0.6449)", "verif image answer": "helium(0.7114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391823.jpg"}, {"question": "a driver at this intersection makes a u turn and is pulled over by a policeman why did the policeman pull him over", "gt answer": "no u turn(1.00)<br/>red light(0.60)", "pred answer": "stop", "question_id": 2746315, "best approach": "wiki, concept, image", "verif answer": "no u turn", "anno approach": "concept, wiki", "verif wiki answer": "no u turn(0.6925)", "verif concept answer": "no u turn(0.6926)", "verif image answer": "no u turn(0.5297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274631.jpg"}, {"question": "what is the term used to describe this game with this number of players", "gt answer": "double(1.00)<br/>tennis(1.00)", "pred answer": "15", "question_id": 2812075, "best approach": "image", "verif answer": "double", "anno approach": "image", "verif wiki answer": "wimbledon(0.5036)", "verif concept answer": "wimbledon(0.5039)", "verif image answer": "double(0.5102)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281207.jpg"}, {"question": "is this a windows or a mac", "gt answer": "window(1.00)<br/>mac(0.60)", "pred answer": "mac", "question_id": 3204545, "best approach": "wiki, concept, image", "verif answer": "mac", "anno approach": "concept, wiki", "verif wiki answer": "mac(0.6655)", "verif concept answer": "mac(0.7131)", "verif image answer": "mac(0.6565)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320454.jpg"}, {"question": "what is the purpose of the blue object on the front of this bike", "gt answer": "shield(1.00)", "pred answer": "helmet", "question_id": 129335, "best approach": "", "verif answer": "paint", "anno approach": "", "verif wiki answer": "paint(0.6134)", "verif concept answer": "paint(0.6167)", "verif image answer": "paint(0.6381)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012933.jpg"}, {"question": "what is covering the animals' bodies", "gt answer": "fur(1.00)", "pred answer": "fur", "question_id": 973115, "best approach": "wiki, concept", "verif answer": "fur", "anno approach": "wiki", "verif wiki answer": "fur(0.7310)", "verif concept answer": "fur(0.7306)", "verif image answer": "stuffing(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097311.jpg"}, {"question": "what popular type of boot is the girl wearing", "gt answer": "ugg(1.00)", "pred answer": "new balance", "question_id": 3212155, "best approach": "", "verif answer": "espresso", "anno approach": "", "verif wiki answer": "espresso(0.7089)", "verif concept answer": "espresso(0.7211)", "verif image answer": "espresso(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321215.jpg"}, {"question": "what 's about to happen", "gt answer": "fight(1.00)<br/>bark(0.60)", "pred answer": "tour", "question_id": 2738855, "best approach": "", "verif answer": "run", "anno approach": "", "verif wiki answer": "run(0.7242)", "verif concept answer": "run(0.6949)", "verif image answer": "run(0.7091)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273885.jpg"}, {"question": "what tool is used to flush this device", "gt answer": "handle(1.00)", "pred answer": "bleach", "question_id": 3237845, "best approach": "", "verif answer": "paddle", "anno approach": "", "verif wiki answer": "paddle(0.5001)", "verif concept answer": "paddle(0.5002)", "verif image answer": "paddle(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323784.jpg"}, {"question": "what kind of animal is pictured", "gt answer": "bear(1.00)<br/>black bear(1.00)", "pred answer": "bear", "question_id": 2676245, "best approach": "wiki, concept, image", "verif answer": "bear", "anno approach": "concept, wiki", "verif wiki answer": "bear(0.6756)", "verif concept answer": "bear(0.7112)", "verif image answer": "bear(0.7018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000267624.jpg"}, {"question": "what does it take for a pet owner to bond with his dog", "gt answer": "love(1.00)", "pred answer": "wakeboarding", "question_id": 8825, "best approach": "", "verif answer": "3 months", "anno approach": "", "verif wiki answer": "3 months(0.6792)", "verif concept answer": "3 months(0.6733)", "verif image answer": "3 months(0.6558)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000882.jpg"}, {"question": "which item seen is associated with vehicle safety", "gt answer": "seat belt(1.00)", "pred answer": "helmet", "question_id": 567335, "best approach": "", "verif answer": "helmet", "anno approach": "", "verif wiki answer": "helmet(0.5887)", "verif concept answer": "helmet(0.5829)", "verif image answer": "helmet(0.7134)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000056733.jpg"}, {"question": "what operating sytem does this laptop use", "gt answer": "window(1.00)", "pred answer": "window", "question_id": 2070775, "best approach": "", "verif answer": "internet explorer", "anno approach": "", "verif wiki answer": "internet explorer(0.7309)", "verif concept answer": "internet explorer(0.7306)", "verif image answer": "mac(0.7238)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207077.jpg"}, {"question": "what is the store in the picture", "gt answer": "laundromat(1.00)<br/>cloth(0.60)<br/>convenience store(0.60)", "pred answer": "ikea", "question_id": 524425, "best approach": "", "verif answer": "book", "anno approach": "", "verif wiki answer": "book(0.6681)", "verif concept answer": "7 eleven(0.6652)", "verif image answer": "book(0.5828)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052442.jpg"}, {"question": "what airline is this", "gt answer": "transat(1.00)", "pred answer": "american airline", "question_id": 5461405, "best approach": "", "verif answer": "chile", "anno approach": "", "verif wiki answer": "chile(0.7263)", "verif concept answer": "chile(0.7305)", "verif image answer": "chile(0.7202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546140.jpg"}, {"question": "which british comedic series has a main character who has a best friend like one of the toys in the photo", "gt answer": "ted(1.00)<br/>bean(0.60)", "pred answer": "mickey mouse", "question_id": 4772585, "best approach": "wiki, concept, image", "verif answer": "ted", "anno approach": "concept, wiki", "verif wiki answer": "ted(0.5683)", "verif concept answer": "ted(0.6639)", "verif image answer": "ted(0.5264)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477258.jpg"}, {"question": "what type of dog has spots all over", "gt answer": "dalmatian(1.00)<br/>dalmation(1.00)", "pred answer": "beagle", "question_id": 3988135, "best approach": "wiki, concept, image", "verif answer": "dalmatian", "anno approach": "image", "verif wiki answer": "dalmation(0.6206)", "verif concept answer": "dalmatian(0.6334)", "verif image answer": "dalmatian(0.7195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398813.jpg"}, {"question": "what is the name of the person who is responsible for caring for these kinds of animals", "gt answer": "sheep herder(1.00)<br/>farmer(0.60)", "pred answer": "shepherd", "question_id": 3934875, "best approach": "", "verif answer": "shepherd", "anno approach": "", "verif wiki answer": "shepherd(0.7306)", "verif concept answer": "shepherd(0.7250)", "verif image answer": "shepherd(0.7151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393487.jpg"}, {"question": "what kind of train is in this photo", "gt answer": "freight(1.00)<br/>cargo(0.60)", "pred answer": "brown", "question_id": 2241995, "best approach": "", "verif answer": "tanker", "anno approach": "", "verif wiki answer": "locomotive(0.6968)", "verif concept answer": "tanker(0.6866)", "verif image answer": "tanker(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224199.jpg"}, {"question": "who invented the figures on both sides of the woman", "gt answer": "richard steiff(1.00)<br/>morris michtom(0.60)<br/>2(0.60)", "pred answer": "theodore roosevelt", "question_id": 2405455, "best approach": "wiki, concept, image", "verif answer": "morris michtom", "anno approach": "wiki", "verif wiki answer": "morris michtom(0.7210)", "verif concept answer": "morris michtom(0.7218)", "verif image answer": "morris michtom(0.7050)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240545.jpg"}, {"question": "what company 's logo can be seen on this tennis player 's clothing", "gt answer": "nike(1.00)", "pred answer": "adidas", "question_id": 2354995, "best approach": "", "verif answer": "shoemaker", "anno approach": "", "verif wiki answer": "shoemaker(0.6767)", "verif concept answer": "shoemaker(0.6924)", "verif image answer": "shoemaker(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000235499.jpg"}, {"question": "what substance was used to color the man on the left gold", "gt answer": "paint(1.00)<br/>pain(0.60)<br/>spray paint(0.60)", "pred answer": "green", "question_id": 648165, "best approach": "wiki, concept, image", "verif answer": "pain", "anno approach": "image, wiki", "verif wiki answer": "pain(0.5762)", "verif concept answer": "pain(0.5705)", "verif image answer": "pain(0.6544)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064816.jpg"}, {"question": "what would you call this event", "gt answer": "meet(1.00)", "pred answer": "work", "question_id": 740805, "best approach": "", "verif answer": "confer", "anno approach": "", "verif wiki answer": "confer(0.7180)", "verif concept answer": "confer(0.7255)", "verif image answer": "confer(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074080.jpg"}, {"question": "why is this person standing", "gt answer": "paddle board(1.00)<br/>surf(0.60)", "pred answer": "wait", "question_id": 1405075, "best approach": "", "verif answer": "row", "anno approach": "", "verif wiki answer": "row(0.6579)", "verif concept answer": "row(0.6657)", "verif image answer": "surfboard(0.5463)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140507.jpg"}, {"question": "what are kitchens used for", "gt answer": "cook(1.00)", "pred answer": "cook", "question_id": 1032315, "best approach": "", "verif answer": "eat", "anno approach": "", "verif wiki answer": "eat(0.7034)", "verif concept answer": "eat(0.6946)", "verif image answer": "eat(0.6765)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103231.jpg"}, {"question": "what kind of donut is this", "gt answer": "glazed(1.00)", "pred answer": "chocolate", "question_id": 1478945, "best approach": "wiki, concept", "verif answer": "glazed", "anno approach": "wiki", "verif wiki answer": "glazed(0.6809)", "verif concept answer": "glazed(0.7089)", "verif image answer": "bakery(0.6899)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147894.jpg"}, {"question": "what is this man 's profession", "gt answer": "sommelier(1.00)<br/>wine taster(0.60)", "pred answer": "chef", "question_id": 5395895, "best approach": "wiki, concept, image", "verif answer": "sommelier", "anno approach": "wiki", "verif wiki answer": "sommelier(0.7239)", "verif concept answer": "sommelier(0.7196)", "verif image answer": "sommelier(0.6969)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539589.jpg"}, {"question": "what is the average distance per hour covered while doing this activity", "gt answer": "2 miles(1.00)<br/>3(0.60)<br/>1(0.60)", "pred answer": "6000 feet", "question_id": 1344475, "best approach": "image", "verif answer": "1 mile", "anno approach": "image", "verif wiki answer": "1 mile(0.7023)", "verif concept answer": "1 mile(0.7090)", "verif image answer": "2 miles(0.6896)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134447.jpg"}, {"question": "what kind of cat is this", "gt answer": "grey(1.00)<br/>gray(0.60)<br/>ragdoll(0.60)", "pred answer": "siamese", "question_id": 4202155, "best approach": "wiki, concept, image", "verif answer": "gray", "anno approach": "wiki", "verif wiki answer": "gray(0.6949)", "verif concept answer": "gray(0.6960)", "verif image answer": "gray(0.6725)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420215.jpg"}, {"question": "what is normally used to kill the animals mounted on the wall", "gt answer": "gun(1.00)", "pred answer": "shade", "question_id": 2838755, "best approach": "image", "verif answer": "mouse", "anno approach": "image", "verif wiki answer": "mouse(0.7303)", "verif concept answer": "mouse(0.7308)", "verif image answer": "gun(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283875.jpg"}, {"question": "", "gt answer": "bathroom(0.60)", "pred answer": "modern", "question_id": 800855, "best approach": "wiki", "verif answer": "shower", "anno approach": "wiki", "verif wiki answer": "bathroom(0.5004)", "verif concept answer": "shower(0.5004)", "verif image answer": "shower(0.5499)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080085.jpg"}, {"question": "the object on the wall with three vertical dials is most likely used to measure what", "gt answer": "barometric pressure(1.00)<br/>temperature(0.60)<br/>time(0.60)", "pred answer": "light", "question_id": 4621105, "best approach": "wiki, concept, image", "verif answer": "barometric pressure", "anno approach": "", "verif wiki answer": "barometric pressure(0.7291)", "verif concept answer": "barometric pressure(0.7306)", "verif image answer": "barometric pressure(0.7262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000462110.jpg"}, {"question": "how would one describe the way the egg in the sandwich is cooked", "gt answer": "hard boiled(1.00)<br/>fried(0.60)<br/>over easy(0.60)", "pred answer": "grilled", "question_id": 2962675, "best approach": "", "verif answer": "boiled", "anno approach": "", "verif wiki answer": "boiled(0.6214)", "verif concept answer": "boiled(0.6835)", "verif image answer": "boiled(0.6586)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296267.jpg"}, {"question": "what do these animals eat", "gt answer": "hay(1.00)", "pred answer": "grass", "question_id": 13325, "best approach": "", "verif answer": "oat", "anno approach": "", "verif wiki answer": "oat(0.7295)", "verif concept answer": "oat(0.7296)", "verif image answer": "oat(0.7197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001332.jpg"}, {"question": "who is believed to have invented the mode of transportation seen in this image", "gt answer": "john kemp starley(1.00)<br/>russia(0.60)<br/>kid(0.60)", "pred answer": "schwinn", "question_id": 3602115, "best approach": "wiki, concept, image", "verif answer": "kid", "anno approach": "wiki", "verif wiki answer": "kid(0.6540)", "verif concept answer": "kid(0.6733)", "verif image answer": "kid(0.6514)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000360211.jpg"}, {"question": "which part of this animal moves to and fro when the animal is excited", "gt answer": "tail(1.00)", "pred answer": "leg", "question_id": 4964155, "best approach": "", "verif answer": "catch", "anno approach": "", "verif wiki answer": "catch(0.7307)", "verif concept answer": "catch(0.7290)", "verif image answer": "catch(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496415.jpg"}, {"question": "how can i warm my food", "gt answer": "microwave(1.00)", "pred answer": "bake", "question_id": 2612715, "best approach": "wiki", "verif answer": "microwave", "anno approach": "wiki", "verif wiki answer": "microwave(0.7225)", "verif concept answer": "toaster oven(0.6648)", "verif image answer": "dishwasher(0.6561)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261271.jpg"}, {"question": "what country is this", "gt answer": "england(1.00)", "pred answer": "england", "question_id": 4845625, "best approach": "wiki", "verif answer": "ireland", "anno approach": "wiki", "verif wiki answer": "england(0.6649)", "verif concept answer": "ireland(0.6832)", "verif image answer": "ireland(0.7225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484562.jpg"}, {"question": "what position is the player behind thr plate", "gt answer": "catcher(1.00)<br/>shortstop(0.60)", "pred answer": "batter", "question_id": 3592495, "best approach": "wiki, concept", "verif answer": "shortstop", "anno approach": "wiki", "verif wiki answer": "catcher(0.6243)", "verif concept answer": "catcher(0.5469)", "verif image answer": "shortstop(0.6321)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359249.jpg"}, {"question": "what type of animal is this", "gt answer": "llama(1.00)<br/>camel(1.00)<br/>giraffe(0.60)", "pred answer": "cow", "question_id": 536155, "best approach": "wiki, concept", "verif answer": "cow", "anno approach": "concept", "verif wiki answer": "llama(0.6343)", "verif concept answer": "llama(0.6932)", "verif image answer": "cow(0.7028)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053615.jpg"}, {"question": "what athlete won the first olympic gold medal in this sport", "gt answer": "shawn white(1.00)<br/>shaun white(0.60)", "pred answer": "shaun white", "question_id": 399585, "best approach": "", "verif answer": "tony hawk", "anno approach": "", "verif wiki answer": "tony hawk(0.5860)", "verif concept answer": "tony hawk(0.5627)", "verif image answer": "tony hawk(0.6594)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039958.jpg"}, {"question": "what does 'xing' mean", "gt answer": "cross(1.00)<br/>stop(0.60)<br/>row(0.60)", "pred answer": "car", "question_id": 85645, "best approach": "", "verif answer": "crosswalk", "anno approach": "", "verif wiki answer": "crosswalk(0.7224)", "verif concept answer": "crosswalk(0.7308)", "verif image answer": "crosswalk(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008564.jpg"}, {"question": "what company makes this farm equipment", "gt answer": "john deere(1.00)", "pred answer": "richard trevithick", "question_id": 1229525, "best approach": "image", "verif answer": "green", "anno approach": "image", "verif wiki answer": "green(0.7116)", "verif concept answer": "green(0.7189)", "verif image answer": "john deere(0.7121)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122952.jpg"}, {"question": "what kind of vehicles are shown here", "gt answer": "truck(1.00)", "pred answer": "tow", "question_id": 3071825, "best approach": "", "verif answer": "garbage truck", "anno approach": "", "verif wiki answer": "garbage truck(0.5789)", "verif concept answer": "garbage truck(0.6078)", "verif image answer": "garbage truck(0.5775)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307182.jpg"}, {"question": "what kind of cakes are these", "gt answer": "donuts(1.00)<br/>doughnut(0.60)", "pred answer": "doughnut", "question_id": 5740255, "best approach": "concept, image", "verif answer": "doughnut", "anno approach": "", "verif wiki answer": "donut(0.6757)", "verif concept answer": "doughnut(0.6915)", "verif image answer": "doughnut(0.6898)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000574025.jpg"}, {"question": "what kind of dog is this", "gt answer": "lab(1.00)<br/>labrador(0.60)<br/>retriever(0.60)", "pred answer": "mix", "question_id": 4500475, "best approach": "", "verif answer": "black labrador", "anno approach": "", "verif wiki answer": "black lab(0.6351)", "verif concept answer": "black labrador(0.6767)", "verif image answer": "black lab(0.6365)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450047.jpg"}, {"question": "in what year was this plane retired from service", "gt answer": "1979(1.00)<br/>2000(0.60)", "pred answer": "1965", "question_id": 4054415, "best approach": "image", "verif answer": "in operation", "anno approach": "image", "verif wiki answer": "in operation(0.6609)", "verif concept answer": "in operation(0.6846)", "verif image answer": "1979(0.6484)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405441.jpg"}, {"question": "what do these hanging objects keep out usually", "gt answer": "sun(1.00)<br/>fly(0.60)<br/>light(0.60)<br/>sunlight(0.60)", "pred answer": "shade", "question_id": 5522915, "best approach": "wiki, concept, image", "verif answer": "sun", "anno approach": "concept, wiki", "verif wiki answer": "sun(0.6457)", "verif concept answer": "sun(0.6728)", "verif image answer": "sun(0.6190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552291.jpg"}, {"question": "what type of sport is this person doing", "gt answer": "water ski(1.00)<br/>parasailing(1.00)", "pred answer": "wind surf", "question_id": 71235, "best approach": "image", "verif answer": "wind surf", "anno approach": "image", "verif wiki answer": "wind surf(0.6380)", "verif concept answer": "wind surf(0.6108)", "verif image answer": "water ski(0.5945)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007123.jpg"}, {"question": "in what countries does this company operate", "gt answer": "united state(1.00)<br/>usa(0.60)<br/>america(0.60)", "pred answer": "england", "question_id": 3769215, "best approach": "wiki, concept, image", "verif answer": "america", "anno approach": "wiki", "verif wiki answer": "america(0.6885)", "verif concept answer": "america(0.6872)", "verif image answer": "usa(0.6683)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376921.jpg"}, {"question": "is this a wedding or birthday", "gt answer": "wed(1.00)", "pred answer": "wed", "question_id": 2283295, "best approach": "wiki, concept, image", "verif answer": "wed", "anno approach": "wiki", "verif wiki answer": "wed(0.7306)", "verif concept answer": "wed(0.7308)", "verif image answer": "wed(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000228329.jpg"}, {"question": "how many people are killed annually in the us while doing this sport", "gt answer": "10(1.00)<br/>5(0.60)<br/>100(0.60)", "pred answer": "20", "question_id": 782905, "best approach": "image", "verif answer": "10", "anno approach": "image", "verif wiki answer": "0(0.6577)", "verif concept answer": "9(0.6740)", "verif image answer": "10(0.6919)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078290.jpg"}, {"question": "what is the floor cleaned with", "gt answer": "vacuum(1.00)<br/>mop(1.00)<br/>bleach(0.60)", "pred answer": "tile", "question_id": 940495, "best approach": "", "verif answer": "brush", "anno approach": "", "verif wiki answer": "brush(0.6761)", "verif concept answer": "brush(0.6432)", "verif image answer": "brush(0.5861)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094049.jpg"}, {"question": "what food is this", "gt answer": "seafood(1.00)<br/>shrimp(0.60)", "pred answer": "turkey", "question_id": 1875415, "best approach": "", "verif answer": "italian", "anno approach": "", "verif wiki answer": "italian(0.6440)", "verif concept answer": "italian(0.5390)", "verif image answer": "noodle(0.5635)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187541.jpg"}, {"question": "how many hours do these animals sleep daily", "gt answer": "12(1.00)<br/>3(0.60)<br/>5(0.60)<br/>2(0.60)", "pred answer": "20", "question_id": 4226085, "best approach": "wiki, concept", "verif answer": "3", "anno approach": "wiki", "verif wiki answer": "3(0.6568)", "verif concept answer": "2(0.6117)", "verif image answer": "4(0.6145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422608.jpg"}, {"question": "what species of bird is in this photo", "gt answer": "robin(1.00)<br/>finch(0.60)", "pred answer": "robin", "question_id": 3723435, "best approach": "wiki, concept", "verif answer": "robin", "anno approach": "wiki", "verif wiki answer": "robin(0.6415)", "verif concept answer": "robin(0.6103)", "verif image answer": "finch(0.6282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372343.jpg"}, {"question": "what was the board made of", "gt answer": "polyurethane(1.00)<br/>plastic(0.60)<br/>wood(0.60)", "pred answer": "fiberglass", "question_id": 3876055, "best approach": "image", "verif answer": "fiberglass", "anno approach": "image", "verif wiki answer": "fiberglass(0.7083)", "verif concept answer": "fiberglass(0.7164)", "verif image answer": "polyurethane(0.6908)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387605.jpg"}, {"question": "are they studying or having fun", "gt answer": "study(1.00)", "pred answer": "fun", "question_id": 3748465, "best approach": "wiki", "verif answer": "fun", "anno approach": "wiki", "verif wiki answer": "study(0.6146)", "verif concept answer": "fun(0.6874)", "verif image answer": "fun(0.7196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374846.jpg"}, {"question": "what is the girl writing in", "gt answer": "notebook(1.00)<br/>cake(0.60)", "pred answer": "chalk", "question_id": 1666925, "best approach": "", "verif answer": "tv", "anno approach": "", "verif wiki answer": "bowl(0.6813)", "verif concept answer": "tv(0.7186)", "verif image answer": "bowl(0.6968)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166692.jpg"}, {"question": "is the man working on a kitchen island or a peninsula", "gt answer": "peninsula(1.00)", "pred answer": "kitchen", "question_id": 5117895, "best approach": "", "verif answer": "breakfast", "anno approach": "", "verif wiki answer": "breakfast(0.5655)", "verif concept answer": "breakfast(0.5503)", "verif image answer": "breakfast(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511789.jpg"}, {"question": "what shape is within the clear balloon", "gt answer": "heart(1.00)", "pred answer": "square", "question_id": 3249235, "best approach": "", "verif answer": "brain", "anno approach": "", "verif wiki answer": "brain(0.6866)", "verif concept answer": "brain(0.6966)", "verif image answer": "brain(0.7083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324923.jpg"}, {"question": "what base is shown here", "gt answer": "second(1.00)<br/>1st(0.60)<br/>third(0.60)", "pred answer": "second", "question_id": 2250885, "best approach": "wiki, concept", "verif answer": "2nd", "anno approach": "wiki", "verif wiki answer": "second(0.6042)", "verif concept answer": "second(0.5882)", "verif image answer": "2nd(0.6411)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225088.jpg"}, {"question": "what kind of bear is the person holding", "gt answer": "teddy(1.00)", "pred answer": "stuffed", "question_id": 1309715, "best approach": "", "verif answer": "grizzly", "anno approach": "", "verif wiki answer": "grizzly(0.7301)", "verif concept answer": "grizzly(0.7291)", "verif image answer": "grizzly(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130971.jpg"}, {"question": "what brand is this truck", "gt answer": "kenworth(1.00)<br/>mac(0.60)", "pred answer": "ford", "question_id": 528025, "best approach": "wiki, concept, image", "verif answer": "kenworth", "anno approach": "wiki", "verif wiki answer": "kenworth(0.6723)", "verif concept answer": "kenworth(0.6844)", "verif image answer": "kenworth(0.6870)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052802.jpg"}, {"question": "what century is this", "gt answer": "20th(1.00)<br/>england(0.60)<br/>18th(0.60)<br/>19th(0.60)", "pred answer": "20th", "question_id": 5377735, "best approach": "image", "verif answer": "20th", "anno approach": "image", "verif wiki answer": "england(0.6585)", "verif concept answer": "england(0.6564)", "verif image answer": "20th(0.6923)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537773.jpg"}, {"question": "what is the boy on the left doing", "gt answer": "pitch(1.00)<br/>throw(1.00)", "pred answer": "pitch", "question_id": 2766965, "best approach": "", "verif answer": "throw it", "anno approach": "", "verif wiki answer": "throw it(0.7058)", "verif concept answer": "throw it(0.7133)", "verif image answer": "throw it(0.6444)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276696.jpg"}, {"question": "what sport is being scored here", "gt answer": "cricket(1.00)", "pred answer": "kite fly", "question_id": 3813055, "best approach": "", "verif answer": "wii", "anno approach": "", "verif wiki answer": "wii(0.6925)", "verif concept answer": "wii(0.6538)", "verif image answer": "wii(0.5045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381305.jpg"}, {"question": "who is credited with inventing what the man and woman are holding", "gt answer": "samuel fox(1.00)<br/>chinese(0.60)", "pred answer": "ben franklin", "question_id": 5066175, "best approach": "", "verif answer": "mozi and lu ban", "anno approach": "", "verif wiki answer": "mozi and lu ban(0.7309)", "verif concept answer": "mozi and lu ban(0.7310)", "verif image answer": "mozi and lu ban(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506617.jpg"}, {"question": "what is folded underneath the sink", "gt answer": "towel(1.00)", "pred answer": "towel", "question_id": 4839935, "best approach": "wiki, concept, image", "verif answer": "towel", "anno approach": "wiki", "verif wiki answer": "towel(0.7309)", "verif concept answer": "towel(0.7309)", "verif image answer": "towel(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483993.jpg"}, {"question": "what is the fuel this vehicle use", "gt answer": "coal(1.00)<br/>diesel(0.60)", "pred answer": "diesel", "question_id": 4820795, "best approach": "wiki, concept", "verif answer": "diesel", "anno approach": "concept, wiki", "verif wiki answer": "diesel(0.6250)", "verif concept answer": "diesel(0.6567)", "verif image answer": "steam(0.6386)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482079.jpg"}, {"question": "where is this plane", "gt answer": "airport(1.00)<br/>runway(1.00)", "pred answer": "alaska", "question_id": 4047405, "best approach": "", "verif answer": "street", "anno approach": "", "verif wiki answer": "street(0.7242)", "verif concept answer": "street(0.7117)", "verif image answer": "street(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404740.jpg"}, {"question": "what could have caused the hole in the fence", "gt answer": "tree(1.00)", "pred answer": "rain", "question_id": 390165, "best approach": "wiki, concept", "verif answer": "tree", "anno approach": "wiki", "verif wiki answer": "tree(0.6804)", "verif concept answer": "tree(0.5467)", "verif image answer": "umbrella(0.5888)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039016.jpg"}, {"question": "what is on the hot dog", "gt answer": "cheese(1.00)", "pred answer": "onion", "question_id": 5116505, "best approach": "", "verif answer": "onion", "anno approach": "", "verif wiki answer": "onion(0.6403)", "verif concept answer": "onion(0.7029)", "verif image answer": "onion(0.6882)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511650.jpg"}, {"question": "what time of day is it", "gt answer": "morn(1.00)<br/>sunrise(0.60)<br/>afternoon(0.60)<br/>even(0.60)", "pred answer": "afternoon", "question_id": 1777495, "best approach": "wiki, concept, image", "verif answer": "morn", "anno approach": "wiki", "verif wiki answer": "morn(0.6998)", "verif concept answer": "morn(0.6759)", "verif image answer": "morn(0.6822)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177749.jpg"}, {"question": "what famous ice cream dish is made with this fruit", "gt answer": "banana split(1.00)", "pred answer": "smoothie", "question_id": 166805, "best approach": "", "verif answer": "banana bread", "anno approach": "", "verif wiki answer": "banana bread(0.7120)", "verif concept answer": "banana bread(0.7285)", "verif image answer": "banana bread(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016680.jpg"}, {"question": "what type of computers are in the photos", "gt answer": "laptop(1.00)<br/>macbook(0.60)", "pred answer": "laptop", "question_id": 1261355, "best approach": "wiki, concept, image", "verif answer": "laptop", "anno approach": "wiki", "verif wiki answer": "laptop(0.7040)", "verif concept answer": "laptop(0.7065)", "verif image answer": "laptop(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126135.jpg"}, {"question": "based off of the image is this person moving slow or fast", "gt answer": "fast(1.00)<br/>slow(1.00)", "pred answer": "fast", "question_id": 1919955, "best approach": "", "verif answer": "25 mph", "anno approach": "", "verif wiki answer": "25 mph(0.6252)", "verif concept answer": "25 mph(0.5421)", "verif image answer": "25 mph(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191995.jpg"}, {"question": "what artist is famous to painting images similar to the one over the fireplace", "gt answer": "van gogh(1.00)<br/>monet(0.60)", "pred answer": "van gogh", "question_id": 543865, "best approach": "", "verif answer": "bill clinton", "anno approach": "", "verif wiki answer": "bill clinton(0.7210)", "verif concept answer": "ben franklin(0.7268)", "verif image answer": "bill clinton(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054386.jpg"}, {"question": "is this coca cola bus or pepsi", "gt answer": "coca cola(1.00)<br/>coco cola(0.60)", "pred answer": "double decker", "question_id": 3699205, "best approach": "", "verif answer": "american airline", "anno approach": "", "verif wiki answer": "american airline(0.6990)", "verif concept answer": "american airline(0.7011)", "verif image answer": "american airline(0.7155)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369920.jpg"}, {"question": "what do these animals eat", "gt answer": "grass(1.00)", "pred answer": "grass", "question_id": 2682315, "best approach": "wiki, concept", "verif answer": "hay", "anno approach": "wiki", "verif wiki answer": "grass(0.7220)", "verif concept answer": "grass(0.6920)", "verif image answer": "hay(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268231.jpg"}, {"question": "what food does the animal eat", "gt answer": "dog food(1.00)<br/>meat(1.00)<br/>kibble(0.60)", "pred answer": "cat food", "question_id": 2378975, "best approach": "wiki, concept, image", "verif answer": "dog food", "anno approach": "wiki", "verif wiki answer": "dog food(0.7140)", "verif concept answer": "dog food(0.7152)", "verif image answer": "dog food(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237897.jpg"}, {"question": "what kind of rug is shown", "gt answer": "oriental(1.00)<br/>decorative(0.60)<br/>large(0.60)", "pred answer": "carpet", "question_id": 799015, "best approach": "", "verif answer": "lace", "anno approach": "", "verif wiki answer": "quilt(0.6624)", "verif concept answer": "quilt(0.6883)", "verif image answer": "lace(0.7088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079901.jpg"}, {"question": "what 's the name of the walkway to board a plane", "gt answer": "jet bridge(1.00)<br/>walkway(0.60)", "pred answer": "concrete", "question_id": 5061495, "best approach": "image", "verif answer": "walkway", "anno approach": "image", "verif wiki answer": "contrail(0.7151)", "verif concept answer": "contrail(0.7015)", "verif image answer": "walkway(0.7241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506149.jpg"}, {"question": "what is the second letter from the left written on the ground", "gt answer": "o(1.00)", "pred answer": "c", "question_id": 4572075, "best approach": "", "verif answer": "home run", "anno approach": "", "verif wiki answer": "home run(0.6908)", "verif concept answer": "home run(0.7088)", "verif image answer": "home run(0.7246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457207.jpg"}, {"question": "what type of surface is the person standing on", "gt answer": "sand(1.00)<br/>beach(0.60)", "pred answer": "sand", "question_id": 5244535, "best approach": "wiki, concept, image", "verif answer": "sand", "anno approach": "wiki", "verif wiki answer": "sand(0.7278)", "verif concept answer": "sand(0.7309)", "verif image answer": "sand(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000524453.jpg"}, {"question": "what area is this bear habitating", "gt answer": "forest(1.00)<br/>wood(0.60)", "pred answer": "wood", "question_id": 4996345, "best approach": "concept", "verif answer": "wood", "anno approach": "concept", "verif wiki answer": "wood(0.6820)", "verif concept answer": "forest(0.6636)", "verif image answer": "wild(0.6654)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499634.jpg"}, {"question": "who is the highest paid athlete of the sport played in this picture", "gt answer": "clayton kershaw(1.00)<br/>bond(0.60)", "pred answer": "babe ruth", "question_id": 4045335, "best approach": "wiki, concept, image", "verif answer": "clayton kershaw", "anno approach": "concept, wiki", "verif wiki answer": "clayton kershaw(0.6996)", "verif concept answer": "clayton kershaw(0.7052)", "verif image answer": "clayton kershaw(0.6662)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404533.jpg"}, {"question": "what kitchen appliances are shown in the picture", "gt answer": "microwave(1.00)<br/>toaster oven(0.60)", "pred answer": "microwave", "question_id": 226915, "best approach": "", "verif answer": "refrigerator", "anno approach": "", "verif wiki answer": "refrigerator(0.7274)", "verif concept answer": "refrigerator(0.6971)", "verif image answer": "refrigerator(0.7267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000022691.jpg"}, {"question": "what is the material used in snowboard", "gt answer": "fiberglass(1.00)<br/>plastic(0.60)<br/>skateboard(0.60)<br/>foam(0.60)", "pred answer": "wood", "question_id": 4994695, "best approach": "wiki, concept", "verif answer": "fiberglass", "anno approach": "wiki", "verif wiki answer": "fiberglass(0.7310)", "verif concept answer": "fiberglass(0.7310)", "verif image answer": "skateboard(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499469.jpg"}, {"question": "who makes this type of motorcycles", "gt answer": "harley davidson(1.00)<br/>harley(0.60)", "pred answer": "honda", "question_id": 3154625, "best approach": "concept", "verif answer": "honda", "anno approach": "concept", "verif wiki answer": "honda(0.6992)", "verif concept answer": "harley davidson(0.6860)", "verif image answer": "honda(0.7248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315462.jpg"}, {"question": "how was that device powered", "gt answer": "battery(1.00)<br/>electricity(0.60)", "pred answer": "battery", "question_id": 2812885, "best approach": "wiki, concept, image", "verif answer": "battery", "anno approach": "wiki", "verif wiki answer": "battery(0.6232)", "verif concept answer": "battery(0.6201)", "verif image answer": "battery(0.6330)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281288.jpg"}, {"question": "what is the most popular brand of the appliance shown", "gt answer": "kenmore(1.00)<br/>lg(1.00)", "pred answer": "ge", "question_id": 5596525, "best approach": "wiki", "verif answer": "whirlpool", "anno approach": "wiki", "verif wiki answer": "kenmore(0.6948)", "verif concept answer": "whirlpool(0.6988)", "verif image answer": "whirlpool(0.6703)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559652.jpg"}, {"question": "would ajax or tide more likely be used to clean this", "gt answer": "ajax(1.00)", "pred answer": "bleach", "question_id": 4162845, "best approach": "", "verif answer": "1960's", "anno approach": "", "verif wiki answer": "1960's(0.6322)", "verif concept answer": "1960's(0.5608)", "verif image answer": "1960's(0.5777)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416284.jpg"}, {"question": "is this a quiet or busy city", "gt answer": "busy(1.00)<br/>quiet(1.00)", "pred answer": "crowded", "question_id": 5436895, "best approach": "", "verif answer": "not busy", "anno approach": "", "verif wiki answer": "not busy(0.7015)", "verif concept answer": "not busy(0.7283)", "verif image answer": "not busy(0.5797)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543689.jpg"}, {"question": "what is the man laying inside of", "gt answer": "tent(1.00)", "pred answer": "cloth", "question_id": 4452635, "best approach": "concept, image", "verif answer": "tent", "anno approach": "", "verif wiki answer": "desk(0.5167)", "verif concept answer": "tent(0.6555)", "verif image answer": "tent(0.6605)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445263.jpg"}, {"question": "what kind of area is this", "gt answer": "beach(1.00)<br/>coast(0.60)", "pred answer": "beach", "question_id": 3941045, "best approach": "wiki, concept, image", "verif answer": "beach", "anno approach": "image, concept, wiki", "verif wiki answer": "beach(0.6656)", "verif concept answer": "beach(0.7307)", "verif image answer": "beach(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000394104.jpg"}, {"question": "what breed of bird is sitting on the fence", "gt answer": "sparrow(1.00)", "pred answer": "finch", "question_id": 1100235, "best approach": "image", "verif answer": "hummingbird", "anno approach": "image", "verif wiki answer": "hummingbird(0.6928)", "verif concept answer": "hummingbird(0.6711)", "verif image answer": "sparrow(0.6297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000110023.jpg"}, {"question": "what position is the person in the middle of the photo", "gt answer": "pitcher(1.00)", "pred answer": "batter", "question_id": 4059065, "best approach": "", "verif answer": "outfield", "anno approach": "", "verif wiki answer": "catcher(0.5043)", "verif concept answer": "outfield(0.5141)", "verif image answer": "catcher(0.5008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405906.jpg"}, {"question": "what is the weight in oz 's of the food left over on this plate", "gt answer": "8(1.00)<br/>7(0.60)<br/>75(0.60)", "pred answer": "400", "question_id": 4255505, "best approach": "wiki, concept", "verif answer": "75", "anno approach": "wiki", "verif wiki answer": "75(0.5148)", "verif concept answer": "75(0.5401)", "verif image answer": "40(0.5031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425550.jpg"}, {"question": "what food is that", "gt answer": "pot pie(1.00)<br/>pie(0.60)", "pred answer": "cake", "question_id": 2173785, "best approach": "wiki, concept", "verif answer": "cake", "anno approach": "", "verif wiki answer": "pot pie(0.6917)", "verif concept answer": "pot pie(0.6950)", "verif image answer": "cake(0.6974)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217378.jpg"}, {"question": "are these cows real or man made", "gt answer": "man made(1.00)", "pred answer": "manmade", "question_id": 3024245, "best approach": "wiki, concept", "verif answer": "manmade", "anno approach": "", "verif wiki answer": "man made(0.7308)", "verif concept answer": "man made(0.7308)", "verif image answer": "manmade(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302424.jpg"}, {"question": "what type of lettuce is this", "gt answer": "romaine(1.00)<br/>arugula(0.60)", "pred answer": "zucchini", "question_id": 3854235, "best approach": "concept", "verif answer": "iceberg", "anno approach": "concept", "verif wiki answer": "iceberg(0.7109)", "verif concept answer": "arugula(0.7053)", "verif image answer": "iceberg(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385423.jpg"}, {"question": "is this a modern or ancient system", "gt answer": "modern(1.00)", "pred answer": "gothic", "question_id": 1511705, "best approach": "wiki, concept", "verif answer": "gothic", "anno approach": "wiki", "verif wiki answer": "modern(0.6985)", "verif concept answer": "modern(0.7151)", "verif image answer": "gothic(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151170.jpg"}, {"question": "why is the man swinging at a ball", "gt answer": "play tennis(1.00)<br/>tennis(1.00)<br/>serve(0.60)", "pred answer": "play tennis", "question_id": 5470995, "best approach": "", "verif answer": "hit", "anno approach": "", "verif wiki answer": "hit(0.6600)", "verif concept answer": "hit(0.6628)", "verif image answer": "backhand(0.6292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000547099.jpg"}, {"question": "what is the filling", "gt answer": "beef(1.00)<br/>corned beef(0.60)<br/>meat(0.60)", "pred answer": "egg salad", "question_id": 3989245, "best approach": "wiki, concept, image", "verif answer": "meat", "anno approach": "concept, wiki", "verif wiki answer": "meat(0.6626)", "verif concept answer": "meat(0.6614)", "verif image answer": "meat(0.5513)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398924.jpg"}, {"question": "what were the variety of vegetables shown in this picture", "gt answer": "green(1.00)", "pred answer": "broccoli", "question_id": 3464335, "best approach": "", "verif answer": "granny smith", "anno approach": "", "verif wiki answer": "granny smith(0.7226)", "verif concept answer": "granny smith(0.7247)", "verif image answer": "granny smith(0.6975)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346433.jpg"}, {"question": "what brand is the dark brown cowboy hat", "gt answer": "stetson(1.00)", "pred answer": "bridle", "question_id": 1245625, "best approach": "wiki, concept", "verif answer": "thoroughbred", "anno approach": "wiki", "verif wiki answer": "stetson(0.7305)", "verif concept answer": "stetson(0.7305)", "verif image answer": "thoroughbred(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000124562.jpg"}, {"question": "in what city would you see this", "gt answer": "london(1.00)", "pred answer": "philadelphia", "question_id": 1035835, "best approach": "", "verif answer": "france", "anno approach": "", "verif wiki answer": "berlin(0.6588)", "verif concept answer": "berlin(0.6838)", "verif image answer": "france(0.6936)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103583.jpg"}, {"question": "what kind of food would you feed this animal", "gt answer": "tuna(1.00)<br/>cat food(1.00)<br/>meat(0.60)", "pred answer": "cat food", "question_id": 5721255, "best approach": "wiki, concept, image", "verif answer": "cat food", "anno approach": "wiki", "verif wiki answer": "cat food(0.6826)", "verif concept answer": "cat food(0.6911)", "verif image answer": "cat food(0.6881)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572125.jpg"}, {"question": "can you guess the name of the sea where this boat is seen", "gt answer": "english channel(1.00)<br/>black(0.60)<br/>canal(0.60)", "pred answer": "japan", "question_id": 4396145, "best approach": "", "verif answer": "barge", "anno approach": "", "verif wiki answer": "barge(0.6842)", "verif concept answer": "barge(0.7121)", "verif image answer": "barge(0.7125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439614.jpg"}, {"question": "what kind of skateboard trick is this boy doing", "gt answer": "grind(1.00)<br/>ollie(0.60)<br/>ride rail(0.60)", "pred answer": "grind", "question_id": 3447825, "best approach": "wiki, concept, image", "verif answer": "grind", "anno approach": "wiki", "verif wiki answer": "grind(0.7091)", "verif concept answer": "grind(0.7105)", "verif image answer": "grind(0.7040)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344782.jpg"}, {"question": "what position is he playing", "gt answer": "second base(1.00)<br/>second(0.60)", "pred answer": "batter", "question_id": 4602355, "best approach": "", "verif answer": "outfield", "anno approach": "", "verif wiki answer": "outfield(0.5827)", "verif concept answer": "outfield(0.5429)", "verif image answer": "outfield(0.6037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460235.jpg"}, {"question": "what type of protein is in this dish", "gt answer": "tofu(1.00)", "pred answer": "beef", "question_id": 2216965, "best approach": "", "verif answer": "beef", "anno approach": "", "verif wiki answer": "beef(0.6745)", "verif concept answer": "beef(0.6776)", "verif image answer": "stir fry(0.6644)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221696.jpg"}, {"question": "where is this taking place", "gt answer": "racetrack(1.00)<br/>track(1.00)", "pred answer": "street", "question_id": 5752525, "best approach": "", "verif answer": "kentucky", "anno approach": "", "verif wiki answer": "rail(0.6761)", "verif concept answer": "asphalt(0.6732)", "verif image answer": "kentucky(0.7137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575252.jpg"}, {"question": "what is this ball made from", "gt answer": "leather(1.00)<br/>factory(0.60)<br/>rubber(0.60)", "pred answer": "rubber", "question_id": 682525, "best approach": "wiki, concept, image", "verif answer": "rubber", "anno approach": "wiki", "verif wiki answer": "rubber(0.7242)", "verif concept answer": "rubber(0.7289)", "verif image answer": "rubber(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068252.jpg"}, {"question": "what will happen next", "gt answer": "hit ball(1.00)<br/>hit(0.60)", "pred answer": "serve", "question_id": 4116295, "best approach": "wiki, concept", "verif answer": "serve", "anno approach": "wiki", "verif wiki answer": "hit ball(0.7238)", "verif concept answer": "hit ball(0.7283)", "verif image answer": "serve(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000411629.jpg"}, {"question": "what color is the bmw", "gt answer": "silver(1.00)<br/>gray(0.60)<br/>grey(0.60)", "pred answer": "ford", "question_id": 3890375, "best approach": "wiki, concept, image", "verif answer": "gray", "anno approach": "wiki", "verif wiki answer": "gray(0.7058)", "verif concept answer": "gray(0.7145)", "verif image answer": "gray(0.7041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389037.jpg"}, {"question": "what kind of birds are shown", "gt answer": "seagull(1.00)<br/>dove(0.60)<br/>geese(0.60)", "pred answer": "pigeon", "question_id": 2653535, "best approach": "wiki, concept, image", "verif answer": "seagull", "anno approach": "wiki", "verif wiki answer": "seagull(0.6372)", "verif concept answer": "seagull(0.6384)", "verif image answer": "seagull(0.6319)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265353.jpg"}, {"question": "how can one steer this boat", "gt answer": "paddle(1.00)<br/>row(0.60)<br/>oar(0.60)", "pred answer": "boat", "question_id": 5379105, "best approach": "", "verif answer": "tow", "anno approach": "", "verif wiki answer": "tow(0.6500)", "verif concept answer": "tow(0.6571)", "verif image answer": "tow(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537910.jpg"}, {"question": "what is the common name of the orange items seen here", "gt answer": "noodle(1.00)<br/>orange(0.60)", "pred answer": "picture", "question_id": 593675, "best approach": "image", "verif answer": "noodle", "anno approach": "image", "verif wiki answer": "lemonade(0.5209)", "verif concept answer": "lemonade(0.5007)", "verif image answer": "noodle(0.6589)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059367.jpg"}, {"question": "how quickly did one well known chain used to promise to deliver this item", "gt answer": "30 minutes(1.00)<br/>10 minutes(1.00)", "pred answer": "once", "question_id": 3812515, "best approach": "image", "verif answer": "10 minutes", "anno approach": "image", "verif wiki answer": "1 hour(0.5044)", "verif concept answer": "1 hour(0.5004)", "verif image answer": "10 minutes(0.5231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381251.jpg"}, {"question": "what famous monument is this", "gt answer": "fountain(1.00)<br/>duck(0.60)", "pred answer": "big ben", "question_id": 4227745, "best approach": "", "verif answer": "bidet", "anno approach": "", "verif wiki answer": "bidet(0.7022)", "verif concept answer": "bidet(0.7137)", "verif image answer": "bidet(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422774.jpg"}, {"question": "who uses this", "gt answer": "people(1.00)<br/>human(0.60)", "pred answer": "human", "question_id": 5160085, "best approach": "wiki, concept", "verif answer": "steve job", "anno approach": "wiki", "verif wiki answer": "people(0.5961)", "verif concept answer": "people(0.6037)", "verif image answer": "steve job(0.6297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516008.jpg"}, {"question": "what is the technical name for the size of the vegetable cut", "gt answer": "dice(1.00)", "pred answer": "large", "question_id": 2469245, "best approach": "", "verif answer": "first", "anno approach": "", "verif wiki answer": "first(0.6033)", "verif concept answer": "first(0.5936)", "verif image answer": "first(0.5915)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246924.jpg"}, {"question": "what style of hat is being worn by the man in the foreground", "gt answer": "beanie(1.00)<br/>knit(0.60)<br/>ski(0.60)", "pred answer": "fedora", "question_id": 388405, "best approach": "wiki, concept, image", "verif answer": "beanie", "anno approach": "wiki", "verif wiki answer": "beanie(0.6864)", "verif concept answer": "beanie(0.7190)", "verif image answer": "beanie(0.7030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038840.jpg"}, {"question": "what is the man swinging with his hands", "gt answer": "tennis racket(1.00)<br/>racket(0.60)", "pred answer": "tennis ball", "question_id": 4518425, "best approach": "", "verif answer": "string", "anno approach": "", "verif wiki answer": "string(0.7304)", "verif concept answer": "string(0.7277)", "verif image answer": "string(0.7076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451842.jpg"}, {"question": "what material is this toy made of", "gt answer": "balloon(1.00)<br/>rubber(1.00)<br/>plastic(0.60)", "pred answer": "rubber", "question_id": 3085225, "best approach": "", "verif answer": "felt", "anno approach": "", "verif wiki answer": "felt(0.6937)", "verif concept answer": "felt(0.6991)", "verif image answer": "felt(0.6541)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308522.jpg"}, {"question": "what is the penalty for not obeying the law on the sign", "gt answer": "fine(1.00)<br/>jail(0.60)", "pred answer": "protection", "question_id": 1352375, "best approach": "", "verif answer": "ticket", "anno approach": "", "verif wiki answer": "ticket(0.7303)", "verif concept answer": "ticket(0.7308)", "verif image answer": "ticket(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000135237.jpg"}, {"question": "how long as this company been in business", "gt answer": "50 years(1.00)<br/>40 years(1.00)<br/>30 years(0.60)", "pred answer": "2 hours", "question_id": 3834245, "best approach": "concept", "verif answer": "100 years", "anno approach": "concept", "verif wiki answer": "100 years(0.6093)", "verif concept answer": "30 years(0.5860)", "verif image answer": "1960(0.5815)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383424.jpg"}, {"question": "which zodiac sign is represented by this animal", "gt answer": "aries(1.00)<br/>ox(0.60)", "pred answer": "ram", "question_id": 5385305, "best approach": "wiki, concept, image", "verif answer": "aries", "anno approach": "image, wiki", "verif wiki answer": "aries(0.6826)", "verif concept answer": "aries(0.6829)", "verif image answer": "aries(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538530.jpg"}, {"question": "what does the food on the right come from", "gt answer": "pig(1.00)<br/>garden(0.60)", "pred answer": "factory", "question_id": 4990615, "best approach": "", "verif answer": "krispy kreme", "anno approach": "", "verif wiki answer": "mice(0.6146)", "verif concept answer": "mice(0.6015)", "verif image answer": "krispy kreme(0.6283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499061.jpg"}, {"question": "whic type of wood is used to make the cupboards shown in this photo", "gt answer": "pine(1.00)<br/>oak(1.00)", "pred answer": "oak", "question_id": 4472045, "best approach": "wiki, concept, image", "verif answer": "oak", "anno approach": "wiki", "verif wiki answer": "oak(0.7188)", "verif concept answer": "oak(0.7152)", "verif image answer": "oak(0.7051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447204.jpg"}, {"question": "what are these animals called that are black and white stripped", "gt answer": "zebra(1.00)", "pred answer": "zebra", "question_id": 4083935, "best approach": "wiki, concept, image", "verif answer": "zebra", "anno approach": "image, wiki", "verif wiki answer": "zebra(0.5455)", "verif concept answer": "zebra(0.5390)", "verif image answer": "zebra(0.6998)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408393.jpg"}, {"question": "what are these animals known to do in the winter", "gt answer": "hibernate(1.00)", "pred answer": "hibernate", "question_id": 550855, "best approach": "", "verif answer": "fly south", "anno approach": "", "verif wiki answer": "fly south(0.7231)", "verif concept answer": "fly south(0.7115)", "verif image answer": "noise(0.6902)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000055085.jpg"}, {"question": "why does the elephant go to the water", "gt answer": "thirsty(0.60)<br/>drink(1.00)", "pred answer": "thirsty", "question_id": 1803155, "best approach": "", "verif answer": "drink water", "anno approach": "", "verif wiki answer": "drink water(0.7130)", "verif concept answer": "drink water(0.6490)", "verif image answer": "drink water(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180315.jpg"}, {"question": "which cartoon rabbit is associated with this vegetable", "gt answer": "bug bunny(1.00)", "pred answer": "john deere", "question_id": 2014465, "best approach": "wiki, concept, image", "verif answer": "bug bunny", "anno approach": "", "verif wiki answer": "bug bunny(0.7305)", "verif concept answer": "bug bunny(0.7301)", "verif image answer": "bug bunny(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201446.jpg"}, {"question": "what kind of truck is shown", "gt answer": "food truck(1.00)<br/>food(0.60)", "pred answer": "ice cream", "question_id": 334315, "best approach": "wiki, concept", "verif answer": "food truck", "anno approach": "concept, wiki", "verif wiki answer": "food truck(0.5196)", "verif concept answer": "food truck(0.5677)", "verif image answer": "ice cream(0.5104)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033431.jpg"}, {"question": "what climate do these animals live in", "gt answer": "tropical(1.00)<br/>hot(0.60)<br/>grassland(0.60)", "pred answer": "tropical", "question_id": 3088725, "best approach": "wiki", "verif answer": "tropical", "anno approach": "wiki", "verif wiki answer": "tropical(0.7310)", "verif concept answer": "grassland(0.6774)", "verif image answer": "warm(0.7113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308872.jpg"}, {"question": "what do you use these for", "gt answer": "tell time(1.00)", "pred answer": "tell time", "question_id": 334135, "best approach": "", "verif answer": "time", "anno approach": "", "verif wiki answer": "time(0.7109)", "verif concept answer": "time(0.7148)", "verif image answer": "time(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033413.jpg"}, {"question": "what is the pattern of the pillow on the left", "gt answer": "checkered(1.00)<br/>square(1.00)<br/>swirl(0.60)", "pred answer": "floral", "question_id": 1834455, "best approach": "image", "verif answer": "swirl", "anno approach": "image", "verif wiki answer": "swirl(0.5767)", "verif concept answer": "swirl(0.5833)", "verif image answer": "checkered(0.5297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183445.jpg"}, {"question": "how much sleep does this aged person need", "gt answer": "8 hours(1.00)<br/>10 hours(0.60)", "pred answer": "lot", "question_id": 1227525, "best approach": "image", "verif answer": "8 hours", "anno approach": "image", "verif wiki answer": "30(0.5174)", "verif concept answer": "10 hours(0.5220)", "verif image answer": "8 hours(0.5549)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122752.jpg"}, {"question": "what kind of material is the sink", "gt answer": "porcelain(1.00)<br/>copper(0.60)", "pred answer": "marble", "question_id": 3226385, "best approach": "wiki", "verif answer": "porcelain", "anno approach": "wiki", "verif wiki answer": "porcelain(0.6640)", "verif concept answer": "copper(0.6097)", "verif image answer": "metal(0.6037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322638.jpg"}, {"question": "what is the knotted item at the woman 's throat called", "gt answer": "tie(1.00)", "pred answer": "tie", "question_id": 4419055, "best approach": "concept, image", "verif answer": "track", "anno approach": "concept", "verif wiki answer": "track(0.7294)", "verif concept answer": "tie(0.7201)", "verif image answer": "tie(0.6132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441905.jpg"}, {"question": "what is missing that is usually underneath the silverware on the placemat", "gt answer": "napkin(1.00)", "pred answer": "bottle", "question_id": 352725, "best approach": "wiki, concept, image", "verif answer": "napkin", "anno approach": "image, wiki", "verif wiki answer": "napkin(0.6206)", "verif concept answer": "napkin(0.5666)", "verif image answer": "napkin(0.6901)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000035272.jpg"}, {"question": "this vehicle transports medical victims to where", "gt answer": "hospital(1.00)", "pred answer": "airport", "question_id": 5629115, "best approach": "", "verif answer": "office", "anno approach": "", "verif wiki answer": "office(0.6899)", "verif concept answer": "office(0.6446)", "verif image answer": "military(0.6674)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000562911.jpg"}, {"question": "why has the white truck stopped at this building", "gt answer": "deliver mail(1.00)<br/>delivery(0.60)", "pred answer": "stop", "question_id": 1455385, "best approach": "", "verif answer": "school", "anno approach": "", "verif wiki answer": "school(0.6819)", "verif concept answer": "school(0.7027)", "verif image answer": "school(0.6854)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145538.jpg"}, {"question": "what is this horse carrying", "gt answer": "cart(1.00)", "pred answer": "carriage", "question_id": 3145725, "best approach": "", "verif answer": "carriage", "anno approach": "", "verif wiki answer": "carriage(0.6753)", "verif concept answer": "carriage(0.6806)", "verif image answer": "carriage(0.6714)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314572.jpg"}, {"question": "what is it called where people wait for buses", "gt answer": "bus stop(1.00)", "pred answer": "bus stop", "question_id": 612065, "best approach": "wiki, concept", "verif answer": "school", "anno approach": "wiki", "verif wiki answer": "bus stop(0.7226)", "verif concept answer": "bus stop(0.7231)", "verif image answer": "school(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061206.jpg"}, {"question": "where does he need to run to", "gt answer": "first base(1.00)<br/>baseball(0.60)", "pred answer": "first base", "question_id": 4454935, "best approach": "wiki, concept", "verif answer": "first base", "anno approach": "wiki", "verif wiki answer": "first base(0.7016)", "verif concept answer": "first base(0.7170)", "verif image answer": "baseball field(0.7144)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445493.jpg"}, {"question": "why might one suspect that no one actually lives here", "gt answer": "empty(1.00)<br/>clean(0.60)", "pred answer": "privacy", "question_id": 5772395, "best approach": "image", "verif answer": "clean", "anno approach": "image", "verif wiki answer": "not busy(0.5002)", "verif concept answer": "run(0.5001)", "verif image answer": "clean(0.5084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000577239.jpg"}, {"question": "what does the train run on", "gt answer": "track(1.00)<br/>steam(0.60)", "pred answer": "track", "question_id": 1196365, "best approach": "wiki, concept", "verif answer": "track", "anno approach": "wiki", "verif wiki answer": "track(0.7270)", "verif concept answer": "track(0.7185)", "verif image answer": "steam(0.6867)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119636.jpg"}, {"question": "what is the calorie count of one portion of the cake shown", "gt answer": "250(1.00)<br/>200(0.60)", "pred answer": "500", "question_id": 4785375, "best approach": "wiki, concept, image", "verif answer": "250", "anno approach": "wiki", "verif wiki answer": "250(0.5901)", "verif concept answer": "250(0.5762)", "verif image answer": "250(0.5989)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478537.jpg"}, {"question": "what is this vehicle used for", "gt answer": "haul(1.00)<br/>transport(1.00)", "pred answer": "construction", "question_id": 292145, "best approach": "", "verif answer": "transportation", "anno approach": "", "verif wiki answer": "transportation(0.7172)", "verif concept answer": "transportation(0.7111)", "verif image answer": "transportation(0.6747)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029214.jpg"}, {"question": "what could you smell if someone would be sitting on the corner object", "gt answer": "poop(1.00)<br/>feces(1.00)", "pred answer": "water", "question_id": 3468905, "best approach": "wiki, concept", "verif answer": "feces", "anno approach": "concept, wiki", "verif wiki answer": "feces(0.6494)", "verif concept answer": "feces(0.7203)", "verif image answer": "bathroom(0.6428)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346890.jpg"}, {"question": "which type of establishment is this", "gt answer": "mall(1.00)<br/>airport(0.60)", "pred answer": "train station", "question_id": 1708575, "best approach": "", "verif answer": "commercial", "anno approach": "", "verif wiki answer": "commercial(0.5562)", "verif concept answer": "commercial(0.5187)", "verif image answer": "commercial(0.6924)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000170857.jpg"}, {"question": "what disease is killing bananas", "gt answer": "fusarium(1.00)<br/>over ripe(0.60)", "pred answer": "lemonade", "question_id": 1572885, "best approach": "", "verif answer": "tomato", "anno approach": "", "verif wiki answer": "tomato(0.5011)", "verif concept answer": "tomato(0.5001)", "verif image answer": "tomato(0.5006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157288.jpg"}, {"question": "which airline does the plane belong to", "gt answer": "united(1.00)<br/>american(0.60)", "pred answer": "delta", "question_id": 2462875, "best approach": "", "verif answer": "korean air", "anno approach": "", "verif wiki answer": "boeing(0.5028)", "verif concept answer": "korean air(0.5026)", "verif image answer": "korean air(0.5058)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246287.jpg"}, {"question": "what are these animals standing on", "gt answer": "dirt(1.00)<br/>mud(0.60)<br/>bridge(0.60)", "pred answer": "grass", "question_id": 1973185, "best approach": "wiki", "verif answer": "mud", "anno approach": "wiki", "verif wiki answer": "dirt(0.6522)", "verif concept answer": "mud(0.6689)", "verif image answer": "mud(0.6691)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197318.jpg"}, {"question": "what variety of plant you were seeing in this picture", "gt answer": "orange tree(1.00)<br/>orange(1.00)", "pred answer": "succulent", "question_id": 4922915, "best approach": "", "verif answer": "rose", "anno approach": "", "verif wiki answer": "rose(0.6595)", "verif concept answer": "seed(0.6006)", "verif image answer": "lemon(0.5705)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492291.jpg"}, {"question": "what does this arrow sign signify", "gt answer": "look(1.00)<br/>look both way(0.60)", "pred answer": "1 way", "question_id": 767095, "best approach": "wiki, concept, image", "verif answer": "look both way", "anno approach": "wiki", "verif wiki answer": "look both way(0.6890)", "verif concept answer": "look both way(0.6735)", "verif image answer": "look both way(0.6447)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076709.jpg"}, {"question": "what do these types of animals use to eat with", "gt answer": "beak(1.00)<br/>nothing(0.60)", "pred answer": "mice", "question_id": 3596355, "best approach": "wiki, concept", "verif answer": "beak", "anno approach": "wiki", "verif wiki answer": "beak(0.7275)", "verif concept answer": "beak(0.7125)", "verif image answer": "seed(0.6432)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359635.jpg"}, {"question": "where are these signs usually found", "gt answer": "street(1.00)", "pred answer": "airport", "question_id": 2171185, "best approach": "concept", "verif answer": "park lot", "anno approach": "concept", "verif wiki answer": "regent(0.6637)", "verif concept answer": "street(0.6710)", "verif image answer": "park lot(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217118.jpg"}, {"question": "what is the temperature", "gt answer": "freeze(1.00)", "pred answer": "freeze", "question_id": 4738705, "best approach": "wiki, concept, image", "verif answer": "freeze", "anno approach": "concept, wiki", "verif wiki answer": "freeze(0.7217)", "verif concept answer": "freeze(0.7175)", "verif image answer": "freeze(0.6372)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473870.jpg"}, {"question": "what kind of haircut does this girl have", "gt answer": "pixie(1.00)<br/>short(1.00)<br/>boy(0.60)", "pred answer": "bun", "question_id": 5502775, "best approach": "wiki, concept, image", "verif answer": "short", "anno approach": "concept, wiki", "verif wiki answer": "short(0.6708)", "verif concept answer": "short(0.6786)", "verif image answer": "pixie(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550277.jpg"}, {"question": "what utensil was used to create the slice of bread depicted", "gt answer": "knife(1.00)", "pred answer": "sheer", "question_id": 5254435, "best approach": "wiki, concept", "verif answer": "knife", "anno approach": "wiki", "verif wiki answer": "knife(0.5326)", "verif concept answer": "knife(0.5215)", "verif image answer": "scissor(0.5192)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525443.jpg"}, {"question": "who makes chairs like this", "gt answer": "ikea(1.00)<br/>store(0.60)", "pred answer": "human", "question_id": 1238515, "best approach": "wiki, concept", "verif answer": "online", "anno approach": "wiki", "verif wiki answer": "ikea(0.7031)", "verif concept answer": "ikea(0.7110)", "verif image answer": "online(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123851.jpg"}, {"question": "are bananas typically stored in a fridge or room temperature", "gt answer": "room(1.00)", "pred answer": "restaurant", "question_id": 4663785, "best approach": "wiki, concept, image", "verif answer": "room", "anno approach": "wiki", "verif wiki answer": "room(0.7288)", "verif concept answer": "room(0.7301)", "verif image answer": "room(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466378.jpg"}, {"question": "what profession uses this", "gt answer": "fireman(1.00)<br/>firefighter(0.60)", "pred answer": "cross guard", "question_id": 798935, "best approach": "", "verif answer": "fire fighter", "anno approach": "", "verif wiki answer": "fire fighter(0.7175)", "verif concept answer": "fire fighter(0.7120)", "verif image answer": "fire fighter(0.6040)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079893.jpg"}, {"question": "are these animals owned by someone or free", "gt answer": "owned(1.00)<br/>free(0.60)", "pred answer": "free", "question_id": 4541555, "best approach": "wiki, concept, image", "verif answer": "owned", "anno approach": "wiki", "verif wiki answer": "owned(0.7196)", "verif concept answer": "owned(0.7245)", "verif image answer": "owned(0.7166)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000454155.jpg"}, {"question": "what type of train is that", "gt answer": "steam(1.00)<br/>steam locomotive(0.60)<br/>steam engine(0.60)", "pred answer": "steam", "question_id": 5451545, "best approach": "wiki, concept", "verif answer": "steam", "anno approach": "wiki", "verif wiki answer": "steam(0.6970)", "verif concept answer": "steam(0.6938)", "verif image answer": "locomotive(0.6839)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545154.jpg"}, {"question": "what is material is the surface that the girl is one made of", "gt answer": "carpet(1.00)<br/>leather(0.60)", "pred answer": "stone", "question_id": 2565335, "best approach": "wiki, concept, image", "verif answer": "carpet", "anno approach": "image, wiki", "verif wiki answer": "carpet(0.7078)", "verif concept answer": "carpet(0.6578)", "verif image answer": "carpet(0.7130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256533.jpg"}, {"question": "can you guess the area whether it is rural or urban", "gt answer": "rural(1.00)", "pred answer": "rural", "question_id": 4584305, "best approach": "wiki, concept", "verif answer": "rural", "anno approach": "wiki", "verif wiki answer": "rural(0.7196)", "verif concept answer": "rural(0.7038)", "verif image answer": "hot(0.7144)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458430.jpg"}, {"question": "in what country is this hat normally worn", "gt answer": "england(1.00)", "pred answer": "england", "question_id": 3215945, "best approach": "wiki, concept, image", "verif answer": "england", "anno approach": "wiki", "verif wiki answer": "england(0.6903)", "verif concept answer": "england(0.6976)", "verif image answer": "england(0.6647)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321594.jpg"}, {"question": "how long have they waited", "gt answer": "20 minutes(1.00)<br/>hour(0.60)", "pred answer": "1 month", "question_id": 4445035, "best approach": "wiki, concept, image", "verif answer": "hour", "anno approach": "image, wiki", "verif wiki answer": "hour(0.5269)", "verif concept answer": "hour(0.5048)", "verif image answer": "hour(0.6359)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000444503.jpg"}, {"question": "what genus is this animal", "gt answer": "equus(1.00)<br/>horse(0.60)", "pred answer": "zebra", "question_id": 4772305, "best approach": "image", "verif answer": "horse", "anno approach": "image", "verif wiki answer": "zebra(0.6668)", "verif concept answer": "zebra(0.6734)", "verif image answer": "horse(0.7047)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477230.jpg"}, {"question": "what type of shoes is this player wearing", "gt answer": "cleat(1.00)<br/>sneaker(0.60)", "pred answer": "sneaker", "question_id": 1297225, "best approach": "wiki, concept, image", "verif answer": "cleat", "anno approach": "wiki", "verif wiki answer": "cleat(0.7290)", "verif concept answer": "cleat(0.7284)", "verif image answer": "cleat(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129722.jpg"}, {"question": "what is the person in the middle of this boat doing", "gt answer": "row(1.00)<br/>row boat(0.60)", "pred answer": "drink", "question_id": 5588515, "best approach": "wiki, concept", "verif answer": "row", "anno approach": "wiki", "verif wiki answer": "row(0.6798)", "verif concept answer": "row(0.6648)", "verif image answer": "canoe(0.6293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558851.jpg"}, {"question": "are they business partners or enemies", "gt answer": "partner(1.00)", "pred answer": "business", "question_id": 2419055, "best approach": "", "verif answer": "teammate", "anno approach": "", "verif wiki answer": "teammate(0.7307)", "verif concept answer": "teammate(0.7310)", "verif image answer": "teammate(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241905.jpg"}, {"question": "name the material used to make the name board shown in this picture", "gt answer": "aluminum(1.00)<br/>metal(1.00)<br/>steel(0.60)", "pred answer": "wood", "question_id": 3227775, "best approach": "", "verif answer": "nylon", "anno approach": "", "verif wiki answer": "nylon(0.7270)", "verif concept answer": "nylon(0.7194)", "verif image answer": "nylon(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322777.jpg"}, {"question": "how fast could this train move", "gt answer": "320 km h(1.00)<br/>200 mph(0.60)<br/>fast(0.60)", "pred answer": "300 mph", "question_id": 1137245, "best approach": "wiki, concept", "verif answer": "320 km h", "anno approach": "", "verif wiki answer": "320 km h(0.7217)", "verif concept answer": "320 km h(0.6977)", "verif image answer": "80 mph(0.6217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113724.jpg"}, {"question": "what type of fuel do the vehicle in the sky uses", "gt answer": "jet fuel(1.00)", "pred answer": "jet fuel", "question_id": 1080695, "best approach": "", "verif answer": "wind turbine", "anno approach": "", "verif wiki answer": "wind turbine(0.6447)", "verif concept answer": "wind turbine(0.6461)", "verif image answer": "wind turbine(0.6485)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108069.jpg"}, {"question": "what is the meaning of the object on the woman 's finger", "gt answer": "marriage(1.00)<br/>wed(0.60)<br/>brush(0.60)", "pred answer": "music", "question_id": 2327795, "best approach": "wiki, concept, image", "verif answer": "wed", "anno approach": "concept, wiki", "verif wiki answer": "wed(0.6807)", "verif concept answer": "wed(0.6701)", "verif image answer": "brush(0.5128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232779.jpg"}, {"question": "what device is pictured", "gt answer": "remote(1.00)<br/>remote control(0.60)", "pred answer": "flatscreen", "question_id": 854115, "best approach": "wiki, concept", "verif answer": "remote", "anno approach": "wiki", "verif wiki answer": "remote(0.6633)", "verif concept answer": "remote(0.6832)", "verif image answer": "pager(0.6826)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085411.jpg"}, {"question": "what would the red bottle next to the sink probably contain", "gt answer": "dish soap(1.00)<br/>soap(0.60)<br/>water(0.60)", "pred answer": "orange juice", "question_id": 1665335, "best approach": "concept", "verif answer": "dish", "anno approach": "concept", "verif wiki answer": "dawn(0.5129)", "verif concept answer": "water(0.5007)", "verif image answer": "dish(0.6981)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166533.jpg"}, {"question": "how much cholesterol does this plate of food have", "gt answer": "lot(1.00)<br/>0(0.60)<br/>20 grams(0.60)", "pred answer": "fifty", "question_id": 5309065, "best approach": "", "verif answer": "little", "anno approach": "", "verif wiki answer": "little(0.6644)", "verif concept answer": "little(0.6232)", "verif image answer": "little(0.6687)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000530906.jpg"}, {"question": "where was the picture taken", "gt answer": "ski resort(0.60)<br/>mountain(1.00)<br/>snow(0.60)", "pred answer": "snow", "question_id": 1401525, "best approach": "", "verif answer": "ski", "anno approach": "", "verif wiki answer": "ski(0.7296)", "verif concept answer": "ski(0.7067)", "verif image answer": "ski(0.7222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140152.jpg"}, {"question": "how much of the body is made up of what the man is surrounded by", "gt answer": "60%(1.00)<br/>60(0.60)", "pred answer": "stomach", "question_id": 2113895, "best approach": "image", "verif answer": "60", "anno approach": "image", "verif wiki answer": "10 hours(0.6293)", "verif concept answer": "10 hours(0.6321)", "verif image answer": "60(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000211389.jpg"}, {"question": "when was the device pictured invented", "gt answer": "1973(1.00)", "pred answer": "2000", "question_id": 4388675, "best approach": "wiki, concept, image", "verif answer": "1973", "anno approach": "wiki", "verif wiki answer": "1973(0.6655)", "verif concept answer": "1973(0.6577)", "verif image answer": "1973(0.6822)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000438867.jpg"}, {"question": "are the noodles made from rice or wheat", "gt answer": "wheat(1.00)<br/>rice(0.60)", "pred answer": "rice", "question_id": 851765, "best approach": "wiki, concept", "verif answer": "wheat", "anno approach": "wiki", "verif wiki answer": "wheat(0.6235)", "verif concept answer": "wheat(0.5527)", "verif image answer": "corn(0.5788)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085176.jpg"}, {"question": "what is the large black item used for in this room", "gt answer": "refrigerate food(1.00)<br/>keep food cold(0.60)<br/>refrigeration(0.60)", "pred answer": "storage", "question_id": 5158785, "best approach": "wiki, concept, image", "verif answer": "keep food cold", "anno approach": "concept, wiki", "verif wiki answer": "keep food cold(0.5827)", "verif concept answer": "keep food cold(0.5640)", "verif image answer": "keep food cold(0.5006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515878.jpg"}, {"question": "buildings like those seen here are often identified as what kind of scrapers", "gt answer": "sky(1.00)<br/>windy(0.60)", "pred answer": "church", "question_id": 3204835, "best approach": "concept", "verif answer": "sky", "anno approach": "concept", "verif wiki answer": "storm(0.6559)", "verif concept answer": "sky(0.6729)", "verif image answer": "windy(0.6602)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320483.jpg"}, {"question": "", "gt answer": "1920s(0.60)<br/>1800's(0.60)<br/>1800s(0.60)", "pred answer": "1800's", "question_id": 4652115, "best approach": "image", "verif answer": "1670", "anno approach": "image", "verif wiki answer": "1670(0.6862)", "verif concept answer": "1670(0.6793)", "verif image answer": "1920s(0.6380)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465211.jpg"}, {"question": "what is this little girl doing", "gt answer": "brush hair(1.00)<br/>dance(0.60)", "pred answer": "music", "question_id": 869225, "best approach": "image", "verif answer": "dance", "anno approach": "image", "verif wiki answer": "box(0.6014)", "verif concept answer": "wii(0.5957)", "verif image answer": "dance(0.6768)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086922.jpg"}, {"question": "what type of fabric is made from the fur of the animals", "gt answer": "wool(1.00)", "pred answer": "wool", "question_id": 5360415, "best approach": "", "verif answer": "fleece", "anno approach": "", "verif wiki answer": "overcoat(0.5856)", "verif concept answer": "overcoat(0.5992)", "verif image answer": "fleece(0.6272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536041.jpg"}, {"question": "what is the average age this dog will live to be", "gt answer": "10 years(1.00)<br/>12 years(0.60)", "pred answer": "15 years", "question_id": 2021585, "best approach": "wiki, concept", "verif answer": "12 years", "anno approach": "wiki", "verif wiki answer": "12 years(0.7039)", "verif concept answer": "12 years(0.6235)", "verif image answer": "15 years(0.6968)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202158.jpg"}, {"question": "what is the man laying on", "gt answer": "pillow(1.00)<br/>mattress(0.60)", "pred answer": "bed", "question_id": 5478275, "best approach": "wiki", "verif answer": "pillow", "anno approach": "wiki", "verif wiki answer": "pillow(0.6908)", "verif concept answer": "bed(0.6859)", "verif image answer": "bed(0.6559)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000547827.jpg"}, {"question": "how much blood circulates in this animal", "gt answer": "5 liters(1.00)<br/>1 liter(0.60)", "pred answer": "lot", "question_id": 4182825, "best approach": "wiki, concept, image", "verif answer": "1 liter", "anno approach": "image", "verif wiki answer": "1 liter(0.6195)", "verif concept answer": "1 liter(0.6168)", "verif image answer": "1 liter(0.7189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000418282.jpg"}, {"question": "which bird species has a deep red breast and resembles a finch", "gt answer": "cardinal(1.00)", "pred answer": "robin", "question_id": 3233685, "best approach": "wiki, concept, image", "verif answer": "cardinal", "anno approach": "wiki", "verif wiki answer": "cardinal(0.6717)", "verif concept answer": "cardinal(0.6709)", "verif image answer": "cardinal(0.7007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323368.jpg"}, {"question": "where do you think they are heading", "gt answer": "construction(1.00)<br/>construction site(0.60)", "pred answer": "airport", "question_id": 3991955, "best approach": "wiki, concept, image", "verif answer": "construction site", "anno approach": "concept, wiki", "verif wiki answer": "construction site(0.6991)", "verif concept answer": "construction site(0.7029)", "verif image answer": "construction site(0.5947)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399195.jpg"}, {"question": "what are the meters for", "gt answer": "park(1.00)<br/>park meter(0.60)", "pred answer": "park", "question_id": 2740125, "best approach": "wiki, concept, image", "verif answer": "park", "anno approach": "concept, wiki", "verif wiki answer": "park(0.5586)", "verif concept answer": "park(0.6787)", "verif image answer": "park(0.5588)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274012.jpg"}, {"question": "what is the floor made of", "gt answer": "linoleum(1.00)<br/>tile(1.00)", "pred answer": "tile", "question_id": 4373915, "best approach": "wiki, concept, image", "verif answer": "tile", "anno approach": "wiki", "verif wiki answer": "tile(0.6652)", "verif concept answer": "tile(0.6517)", "verif image answer": "tile(0.6714)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437391.jpg"}, {"question": "who invented this sport", "gt answer": "tom sim(1.00)", "pred answer": "shaun white", "question_id": 37135, "best approach": "", "verif answer": "colorado", "anno approach": "", "verif wiki answer": "colorado(0.6420)", "verif concept answer": "colorado(0.6475)", "verif image answer": "colorado(0.5337)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003713.jpg"}, {"question": "what comes before vista", "gt answer": "buena(1.00)", "pred answer": "ski lift", "question_id": 1081015, "best approach": "wiki", "verif answer": "ski", "anno approach": "wiki", "verif wiki answer": "buena(0.6900)", "verif concept answer": "ski(0.6835)", "verif image answer": "ski(0.6962)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108101.jpg"}, {"question": "what size bed is shown", "gt answer": "twin(1.00)<br/>single(1.00)", "pred answer": "full", "question_id": 396435, "best approach": "wiki, concept, image", "verif answer": "twin", "anno approach": "image, wiki", "verif wiki answer": "twin(0.5462)", "verif concept answer": "twin(0.5691)", "verif image answer": "twin(0.6085)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039643.jpg"}, {"question": "what month was this photo taken", "gt answer": "december(1.00)<br/>winter(0.60)<br/>summer(0.60)", "pred answer": "december", "question_id": 1683355, "best approach": "wiki, concept, image", "verif answer": "december", "anno approach": "image, wiki", "verif wiki answer": "december(0.6406)", "verif concept answer": "december(0.6413)", "verif image answer": "december(0.7035)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168335.jpg"}, {"question": "what type of numerals are the numbers on this clock", "gt answer": "roman(1.00)", "pred answer": "roman", "question_id": 2816315, "best approach": "image", "verif answer": "roman numeral", "anno approach": "image", "verif wiki answer": "roman numeral(0.7185)", "verif concept answer": "roman numeral(0.7168)", "verif image answer": "roman(0.7147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281631.jpg"}, {"question": "where is this person farming and what is he harvesting", "gt answer": "banana(1.00)", "pred answer": "south america", "question_id": 502045, "best approach": "", "verif answer": "plantain", "anno approach": "", "verif wiki answer": "plantain(0.7007)", "verif concept answer": "plantain(0.7158)", "verif image answer": "plantain(0.7222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050204.jpg"}, {"question": "what bike brand is he on", "gt answer": "schwinn(1.00)<br/>huffy(0.60)", "pred answer": "schwinn", "question_id": 985965, "best approach": "wiki, concept, image", "verif answer": "huffy", "anno approach": "image", "verif wiki answer": "huffy(0.6801)", "verif concept answer": "huffy(0.7081)", "verif image answer": "huffy(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098596.jpg"}, {"question": "what brand is the game console", "gt answer": "playstation(1.00)<br/>xbox(0.60)<br/>wii(0.60)", "pred answer": "nintendo", "question_id": 3854455, "best approach": "", "verif answer": "nintendo", "anno approach": "", "verif wiki answer": "nintendo(0.7212)", "verif concept answer": "nintendo(0.7186)", "verif image answer": "nintendo(0.6997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385445.jpg"}, {"question": "what type of bird is this", "gt answer": "pelican(1.00)<br/>pigeon(0.60)", "pred answer": "pigeon", "question_id": 5051225, "best approach": "", "verif answer": "crane", "anno approach": "", "verif wiki answer": "crane(0.7308)", "verif concept answer": "crane(0.7211)", "verif image answer": "crane(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505122.jpg"}, {"question": "what branch of the military is this", "gt answer": "army(1.00)<br/>marine(1.00)", "pred answer": "air force", "question_id": 3881495, "best approach": "", "verif answer": "navy", "anno approach": "", "verif wiki answer": "navy(0.7209)", "verif concept answer": "air force(0.6794)", "verif image answer": "navy(0.7243)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388149.jpg"}, {"question": "what soda appears in the photo near the young girl", "gt answer": "sprite(1.00)<br/>coke(0.60)", "pred answer": "beer", "question_id": 2372335, "best approach": "wiki, concept, image", "verif answer": "coke", "anno approach": "concept, wiki", "verif wiki answer": "coke(0.7110)", "verif concept answer": "coke(0.6712)", "verif image answer": "coke(0.5828)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237233.jpg"}, {"question": "is this a mountain or foothill", "gt answer": "mountain(1.00)", "pred answer": "mountain", "question_id": 967025, "best approach": "", "verif answer": "snow", "anno approach": "", "verif wiki answer": "snow(0.5174)", "verif concept answer": "snow(0.5431)", "verif image answer": "snow(0.5115)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096702.jpg"}, {"question": "is this a casual or formal occasion", "gt answer": "casual(1.00)", "pred answer": "casual", "question_id": 5173825, "best approach": "wiki, image", "verif answer": "casually", "anno approach": "", "verif wiki answer": "casual(0.7154)", "verif concept answer": "casually(0.7235)", "verif image answer": "casual(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517382.jpg"}, {"question": "what kind of bottoms do the women who play this sport usually wear", "gt answer": "skirt(1.00)<br/>short(0.60)<br/>tennis(0.60)", "pred answer": "dress", "question_id": 3272995, "best approach": "wiki, concept, image", "verif answer": "skirt", "anno approach": "image, wiki", "verif wiki answer": "skirt(0.6888)", "verif concept answer": "skirt(0.6973)", "verif image answer": "skirt(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327299.jpg"}, {"question": "what fleetwood mac song describes this image", "gt answer": "7 wonders(1.00)<br/>horse(0.60)<br/>0(0.60)", "pred answer": "graffiti", "question_id": 2455505, "best approach": "image", "verif answer": "0", "anno approach": "image", "verif wiki answer": "panda(0.5015)", "verif concept answer": "panda(0.5019)", "verif image answer": "0(0.5162)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245550.jpg"}, {"question": "the tall houses with beacons that are often found in areas like this are called what", "gt answer": "lighthouse(1.00)<br/>light house(0.60)", "pred answer": "surf", "question_id": 1342655, "best approach": "wiki, concept", "verif answer": "light house", "anno approach": "concept", "verif wiki answer": "light house(0.6296)", "verif concept answer": "light house(0.7233)", "verif image answer": "beach(0.6830)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134265.jpg"}, {"question": "is this a lake or ocean", "gt answer": "lake(1.00)<br/>ocean(1.00)", "pred answer": "lake", "question_id": 4875395, "best approach": "wiki, concept", "verif answer": "lake", "anno approach": "wiki", "verif wiki answer": "lake(0.7291)", "verif concept answer": "lake(0.7309)", "verif image answer": "river(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487539.jpg"}, {"question": "what does the black street sign say", "gt answer": "1 way(1.00)", "pred answer": "1 way", "question_id": 3714825, "best approach": "wiki, concept", "verif answer": "1 way", "anno approach": "", "verif wiki answer": "1 way(0.7184)", "verif concept answer": "1 way(0.7286)", "verif image answer": "shop(0.6784)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371482.jpg"}, {"question": "what type of fish are in this picture", "gt answer": "sardine(1.00)", "pred answer": "parakeet", "question_id": 3195945, "best approach": "image", "verif answer": "sardine", "anno approach": "image", "verif wiki answer": "banana(0.6105)", "verif concept answer": "banana(0.6254)", "verif image answer": "sardine(0.6461)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319594.jpg"}, {"question": "which continent does the langue shown derive from", "gt answer": "asia(1.00)<br/>asian(0.60)", "pred answer": "united kingdom", "question_id": 4928945, "best approach": "", "verif answer": "american", "anno approach": "", "verif wiki answer": "chinese(0.5418)", "verif concept answer": "american(0.5431)", "verif image answer": "american(0.6560)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492894.jpg"}, {"question": "what kind of jacket is she wearing", "gt answer": "ski jacket(1.00)<br/>ski(0.60)", "pred answer": "rain", "question_id": 2242425, "best approach": "wiki, concept", "verif answer": "ski jacket", "anno approach": "wiki", "verif wiki answer": "ski jacket(0.7012)", "verif concept answer": "ski jacket(0.7016)", "verif image answer": "aluminum(0.7015)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224242.jpg"}, {"question": "is this legal or illegal", "gt answer": "illegal(1.00)", "pred answer": "legal", "question_id": 1777055, "best approach": "concept", "verif answer": "legal", "anno approach": "concept", "verif wiki answer": "legal(0.7306)", "verif concept answer": "illegal(0.7283)", "verif image answer": "legal(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177705.jpg"}, {"question": "where is the parking lot", "gt answer": "to left(1.00)<br/>park(0.60)<br/>italy(0.60)", "pred answer": "london", "question_id": 2811085, "best approach": "wiki, concept, image", "verif answer": "park", "anno approach": "wiki", "verif wiki answer": "park(0.7000)", "verif concept answer": "park(0.6388)", "verif image answer": "park(0.6645)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281108.jpg"}, {"question": "on average how many pounds of food do animals of this type eat per week", "gt answer": "75(1.00)<br/>africa(0.60)<br/>hundred(0.60)<br/>500(0.60)", "pred answer": "leaf", "question_id": 4318255, "best approach": "wiki, concept, image", "verif answer": "africa", "anno approach": "image, wiki", "verif wiki answer": "africa(0.6725)", "verif concept answer": "africa(0.6709)", "verif image answer": "africa(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431825.jpg"}, {"question": "what type of soda is in the refrigerator", "gt answer": "coke(1.00)", "pred answer": "sprite", "question_id": 4667105, "best approach": "", "verif answer": "pepsi", "anno approach": "", "verif wiki answer": "pepsi(0.6274)", "verif concept answer": "pepsi(0.6487)", "verif image answer": "pepsi(0.7131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466710.jpg"}, {"question": "what app is this person using", "gt answer": "bank(1.00)<br/>cell phone(0.60)<br/>mint(0.60)", "pred answer": "cellphone", "question_id": 3994565, "best approach": "wiki, concept, image", "verif answer": "cell phone", "anno approach": "wiki", "verif wiki answer": "cell phone(0.6506)", "verif concept answer": "cell phone(0.6292)", "verif image answer": "cell phone(0.6134)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399456.jpg"}, {"question": "how tall is this bus", "gt answer": "2 stories(1.00)<br/>15 feet(0.60)<br/>double decker(0.60)", "pred answer": "double decker", "question_id": 1258485, "best approach": "wiki, concept, image", "verif answer": "double decker", "anno approach": "wiki", "verif wiki answer": "double decker(0.7233)", "verif concept answer": "double decker(0.7231)", "verif image answer": "double decker(0.7109)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125848.jpg"}, {"question": "what is the weather in this picture", "gt answer": "cold(1.00)", "pred answer": "cold", "question_id": 2584395, "best approach": "", "verif answer": "hot", "anno approach": "", "verif wiki answer": "hot(0.6850)", "verif concept answer": "hot(0.6471)", "verif image answer": "hot(0.6669)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258439.jpg"}, {"question": "what fruits are these", "gt answer": "blueberry(1.00)<br/>cherry(0.60)", "pred answer": "apple", "question_id": 5029115, "best approach": "wiki, concept, image", "verif answer": "blueberry", "anno approach": "wiki", "verif wiki answer": "blueberry(0.6149)", "verif concept answer": "blueberry(0.6327)", "verif image answer": "blueberry(0.6393)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502911.jpg"}, {"question": "what food do these animals eat", "gt answer": "hay(1.00)", "pred answer": "hay", "question_id": 3642225, "best approach": "wiki", "verif answer": "hay", "anno approach": "wiki", "verif wiki answer": "hay(0.7094)", "verif concept answer": "oat(0.6910)", "verif image answer": "saddle(0.6856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364222.jpg"}, {"question": "what is the largest competition for this sport", "gt answer": "o'neill world cup of surf(1.00)", "pred answer": "wind surf", "question_id": 5193565, "best approach": "wiki, concept", "verif answer": "o'neill world cup of surf", "anno approach": "", "verif wiki answer": "o'neill world cup of surf(0.6701)", "verif concept answer": "o'neill world cup of surf(0.6754)", "verif image answer": "surf board(0.6345)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000519356.jpg"}, {"question": "what is the player about to do", "gt answer": "hit ball(1.00)<br/>serve(0.60)", "pred answer": "backhand", "question_id": 840845, "best approach": "wiki, image", "verif answer": "hit ball", "anno approach": "image, wiki", "verif wiki answer": "hit ball(0.5613)", "verif concept answer": "hit(0.5127)", "verif image answer": "hit ball(0.7120)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084084.jpg"}, {"question": "who manfactures the helmet", "gt answer": "doc(1.00)<br/>oakley(0.60)", "pred answer": "bode miller", "question_id": 5356855, "best approach": "wiki, concept", "verif answer": "oakley", "anno approach": "wiki", "verif wiki answer": "oakley(0.6481)", "verif concept answer": "oakley(0.5938)", "verif image answer": "ski pole(0.5564)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535685.jpg"}, {"question": "what ancient general famously used animals like these when invading rome", "gt answer": "hannibal(1.00)", "pred answer": "hindu", "question_id": 2850935, "best approach": "wiki, concept, image", "verif answer": "hannibal", "anno approach": "wiki", "verif wiki answer": "hannibal(0.7016)", "verif concept answer": "hannibal(0.6932)", "verif image answer": "hannibal(0.6826)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285093.jpg"}, {"question": "what kind of bear in the middle", "gt answer": "koala(1.00)<br/>teddy bear(0.60)", "pred answer": "stuffed", "question_id": 2668805, "best approach": "", "verif answer": "bear", "anno approach": "", "verif wiki answer": "bear(0.6147)", "verif concept answer": "bear(0.6201)", "verif image answer": "bear(0.5980)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266880.jpg"}, {"question": "are the two girls best friends or just coworkers", "gt answer": "best friend(1.00)<br/>friend(0.60)", "pred answer": "family", "question_id": 3152945, "best approach": "wiki, concept", "verif answer": "friend", "anno approach": "wiki", "verif wiki answer": "friend(0.7297)", "verif concept answer": "friend(0.7293)", "verif image answer": "family(0.7005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315294.jpg"}, {"question": "what is the punishment of doing this in the usa", "gt answer": "prison(1.00)<br/>death(0.60)<br/>knife(0.60)", "pred answer": "cut", "question_id": 2802285, "best approach": "", "verif answer": "jail", "anno approach": "", "verif wiki answer": "jail(0.6090)", "verif concept answer": "jail(0.6122)", "verif image answer": "jail(0.5075)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280228.jpg"}, {"question": "assuming by an attribute in the picture what gender is the babt", "gt answer": "girl(1.00)<br/>female(0.60)<br/>boy(0.60)", "pred answer": "female", "question_id": 2313225, "best approach": "wiki, image", "verif answer": "female", "anno approach": "wiki", "verif wiki answer": "female(0.7180)", "verif concept answer": "pitcher(0.6518)", "verif image answer": "female(0.6101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231322.jpg"}, {"question": "where is the boat at", "gt answer": "alaska(1.00)<br/>norway(0.60)<br/>harbor(0.60)", "pred answer": "harbor", "question_id": 4510365, "best approach": "wiki, concept", "verif answer": "alaska", "anno approach": "wiki", "verif wiki answer": "alaska(0.6409)", "verif concept answer": "alaska(0.6476)", "verif image answer": "harbor(0.6160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451036.jpg"}, {"question": "what are these toys filled with", "gt answer": "stuffing(1.00)<br/>cotton(0.60)<br/>polyester(0.60)", "pred answer": "ice", "question_id": 401815, "best approach": "wiki, concept", "verif answer": "stuffing", "anno approach": "wiki", "verif wiki answer": "stuffing(0.7262)", "verif concept answer": "stuffing(0.7105)", "verif image answer": "cotton(0.6915)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040181.jpg"}, {"question": "what kind of person lives here", "gt answer": "single(1.00)<br/>mother(0.60)<br/>woman(0.60)<br/>kid(0.60)", "pred answer": "female", "question_id": 5032745, "best approach": "wiki, concept", "verif answer": "single", "anno approach": "wiki", "verif wiki answer": "single(0.6515)", "verif concept answer": "single(0.6420)", "verif image answer": "female(0.6147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503274.jpg"}, {"question": "what are these horses on top of", "gt answer": "hill(1.00)", "pred answer": "mountain", "question_id": 4637385, "best approach": "", "verif answer": "snow", "anno approach": "", "verif wiki answer": "snow(0.6919)", "verif concept answer": "snow(0.6803)", "verif image answer": "snow(0.7007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463738.jpg"}, {"question": "what breed of birds are these", "gt answer": "dove(0.60)<br/>finch(0.60)<br/>monkey(0.60)<br/>robin(1.00)", "pred answer": "pigeon", "question_id": 4872645, "best approach": "image", "verif answer": "robin", "anno approach": "image", "verif wiki answer": "dove(0.6506)", "verif concept answer": "monkey(0.6372)", "verif image answer": "robin(0.6704)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487264.jpg"}, {"question": "how do you cook this dish", "gt answer": "bake(1.00)<br/>fry(0.60)<br/>bake it(0.60)<br/>baked(0.60)", "pred answer": "grill", "question_id": 4283455, "best approach": "concept", "verif answer": "baked", "anno approach": "concept", "verif wiki answer": "baked(0.6859)", "verif concept answer": "bake(0.6305)", "verif image answer": "protein(0.6641)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428345.jpg"}, {"question": "what heats your food faster than an oven", "gt answer": "microwave(1.00)", "pred answer": "fan", "question_id": 4055635, "best approach": "wiki, concept, image", "verif answer": "microwave", "anno approach": "wiki", "verif wiki answer": "microwave(0.7291)", "verif concept answer": "microwave(0.6791)", "verif image answer": "microwave(0.6624)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405563.jpg"}, {"question": "what brand is this girls racket", "gt answer": "wilson(1.00)<br/>head(0.60)<br/>tennis(0.60)", "pred answer": "adidas", "question_id": 3902135, "best approach": "", "verif answer": "adidas", "anno approach": "", "verif wiki answer": "adidas(0.7080)", "verif concept answer": "adidas(0.7065)", "verif image answer": "adidas(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390213.jpg"}, {"question": "what kind of sauce is this", "gt answer": "ranch dress(1.00)<br/>ranch(0.60)", "pred answer": "vegetable", "question_id": 4216565, "best approach": "wiki", "verif answer": "tomato", "anno approach": "wiki", "verif wiki answer": "ranch dress(0.6426)", "verif concept answer": "tomato(0.6513)", "verif image answer": "tomato(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421656.jpg"}, {"question": "what toy is the child attempting to use the wind to lift", "gt answer": "kite(1.00)", "pred answer": "kite fly", "question_id": 428185, "best approach": "", "verif answer": "kite fly", "anno approach": "", "verif wiki answer": "kite fly(0.7307)", "verif concept answer": "kite fly(0.7302)", "verif image answer": "kite fly(0.5737)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042818.jpg"}, {"question": "why are the animals here", "gt answer": "drink(1.00)<br/>drink water(0.60)<br/>thirsty(0.60)", "pred answer": "thirsty", "question_id": 4842875, "best approach": "wiki, concept", "verif answer": "thirsty", "anno approach": "concept, wiki", "verif wiki answer": "thirsty(0.6554)", "verif concept answer": "thirsty(0.6997)", "verif image answer": "tusk(0.6632)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484287.jpg"}, {"question": "what are the people trying to fly", "gt answer": "kite(1.00)", "pred answer": "kite", "question_id": 5467035, "best approach": "image", "verif answer": "fly kite", "anno approach": "image", "verif wiki answer": "fly kite(0.7309)", "verif concept answer": "fly kite(0.7305)", "verif image answer": "kite(0.6989)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546703.jpg"}, {"question": "what kind of appliance is next to the sink", "gt answer": "dryer(1.00)<br/>wash machine(1.00)", "pred answer": "stove", "question_id": 4082275, "best approach": "", "verif answer": "toilet", "anno approach": "", "verif wiki answer": "toilet(0.6988)", "verif concept answer": "toilet(0.7237)", "verif image answer": "oven(0.7007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408227.jpg"}, {"question": "what brand of sunglasses are those", "gt answer": "oakley(1.00)<br/>rayban(0.60)<br/>ray ban(0.60)", "pred answer": "rayban", "question_id": 4803135, "best approach": "wiki, concept, image", "verif answer": "rayban", "anno approach": "image", "verif wiki answer": "rayban(0.5062)", "verif concept answer": "rayban(0.5206)", "verif image answer": "rayban(0.5383)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480313.jpg"}, {"question": "what orbiting body is said to influence these waves", "gt answer": "moon(1.00)<br/>gravity(0.60)", "pred answer": "wave", "question_id": 189355, "best approach": "wiki, concept, image", "verif answer": "gravity", "anno approach": "wiki", "verif wiki answer": "gravity(0.5589)", "verif concept answer": "gravity(0.5554)", "verif image answer": "gravity(0.5737)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000018935.jpg"}, {"question": "what type of swing is this", "gt answer": "overhand(1.00)<br/>backhand(0.60)<br/>overhead(0.60)", "pred answer": "forehand", "question_id": 443855, "best approach": "", "verif answer": "fastball", "anno approach": "", "verif wiki answer": "fastball(0.7302)", "verif concept answer": "fastball(0.7307)", "verif image answer": "fastball(0.7156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000044385.jpg"}, {"question": "what is tied to this animal 's horns", "gt answer": "rope(1.00)", "pred answer": "bridle", "question_id": 24155, "best approach": "wiki", "verif answer": "strap", "anno approach": "wiki", "verif wiki answer": "rope(0.5052)", "verif concept answer": "string(0.5072)", "verif image answer": "strap(0.5649)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002415.jpg"}, {"question": "what is the man doing", "gt answer": "play tennis(1.00)<br/>tennis(1.00)<br/>hit(0.60)", "pred answer": "serve", "question_id": 2462805, "best approach": "concept, image", "verif answer": "play tennis", "anno approach": "", "verif wiki answer": "serve(0.6979)", "verif concept answer": "play tennis(0.7107)", "verif image answer": "play tennis(0.6944)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246280.jpg"}, {"question": "what type of cloud is in the sky", "gt answer": "storm(1.00)<br/>nimbus(0.60)<br/>cumulus(0.60)", "pred answer": "storm", "question_id": 1786515, "best approach": "wiki, concept, image", "verif answer": "cumulus", "anno approach": "wiki", "verif wiki answer": "cumulus(0.7016)", "verif concept answer": "cumulus(0.6558)", "verif image answer": "cumulus(0.6845)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178651.jpg"}, {"question": "what is he supposed to be doing", "gt answer": "work(1.00)<br/>code(0.60)<br/>study(0.60)", "pred answer": "work", "question_id": 5352025, "best approach": "wiki, concept, image", "verif answer": "work", "anno approach": "concept, wiki", "verif wiki answer": "work(0.6264)", "verif concept answer": "work(0.6446)", "verif image answer": "work(0.5702)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535202.jpg"}, {"question": "where would you find this type of transportation", "gt answer": "pennsylvania(1.00)<br/>country(0.60)<br/>countryside(0.60)", "pred answer": "england", "question_id": 2776885, "best approach": "wiki, concept, image", "verif answer": "countryside", "anno approach": "wiki", "verif wiki answer": "countryside(0.7219)", "verif concept answer": "countryside(0.7009)", "verif image answer": "country(0.6982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277688.jpg"}, {"question": "what kind of cheese is used on this deep dish", "gt answer": "mozzarella(1.00)", "pred answer": "mozzarella", "question_id": 5181945, "best approach": "wiki, concept", "verif answer": "mozzarella", "anno approach": "wiki", "verif wiki answer": "mozzarella(0.7108)", "verif concept answer": "mozzarella(0.7087)", "verif image answer": "red(0.5401)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518194.jpg"}, {"question": "what kind of bird is this", "gt answer": "penguin(1.00)", "pred answer": "pelican", "question_id": 4160085, "best approach": "wiki", "verif answer": "penguin", "anno approach": "wiki", "verif wiki answer": "penguin(0.6449)", "verif concept answer": "pelican(0.6364)", "verif image answer": "san diego(0.6317)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416008.jpg"}, {"question": "what person was this toy named after", "gt answer": "teddy roosevelt(1.00)", "pred answer": "bear", "question_id": 1627285, "best approach": "", "verif answer": "theodore roosevelt", "anno approach": "", "verif wiki answer": "theodore roosevelt(0.7259)", "verif concept answer": "theodore roosevelt(0.7205)", "verif image answer": "theodore roosevelt(0.5597)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162728.jpg"}, {"question": "what position are the people in the picture in", "gt answer": "cross legged(1.00)", "pred answer": "batter", "question_id": 52155, "best approach": "wiki, concept, image", "verif answer": "cross legged", "anno approach": "", "verif wiki answer": "cross legged(0.7250)", "verif concept answer": "cross legged(0.7238)", "verif image answer": "cross legged(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005215.jpg"}, {"question": "what type of headpiece is this woman wearing", "gt answer": "tiara(1.00)", "pred answer": "fedora", "question_id": 4403395, "best approach": "wiki, concept", "verif answer": "donut", "anno approach": "", "verif wiki answer": "tiara(0.7295)", "verif concept answer": "tiara(0.7264)", "verif image answer": "donut(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440339.jpg"}, {"question": "which insect does this plane look like", "gt answer": "bee(1.00)<br/>fly(1.00)", "pred answer": "hummingbird", "question_id": 761605, "best approach": "wiki, concept, image", "verif answer": "bee", "anno approach": "wiki", "verif wiki answer": "bee(0.6018)", "verif concept answer": "bee(0.6195)", "verif image answer": "bee(0.5967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076160.jpg"}, {"question": "what video character is shown here", "gt answer": "pac man(1.00)", "pred answer": "looney tune", "question_id": 2349005, "best approach": "wiki, concept, image", "verif answer": "pac man", "anno approach": "", "verif wiki answer": "pac man(0.7305)", "verif concept answer": "pac man(0.7308)", "verif image answer": "pac man(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000234900.jpg"}, {"question": "what kind of aircraft is this", "gt answer": "bomber(1.00)<br/>fighter jet(0.60)<br/>military(0.60)", "pred answer": "passenger", "question_id": 1768965, "best approach": "", "verif answer": "biplane", "anno approach": "", "verif wiki answer": "biplane(0.6460)", "verif concept answer": "biplane(0.6323)", "verif image answer": "biplane(0.5586)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176896.jpg"}, {"question": "what kind of job does this person have", "gt answer": "police officer(1.00)<br/>police(0.60)<br/>policeman(0.60)", "pred answer": "policeman", "question_id": 2709125, "best approach": "wiki", "verif answer": "tow", "anno approach": "wiki", "verif wiki answer": "policeman(0.7270)", "verif concept answer": "cross guard(0.7088)", "verif image answer": "tow(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270912.jpg"}, {"question": "do these colors indicate high noon or the start end of the day", "gt answer": "end(1.00)<br/>end of day(1.00)<br/>noon(0.60)", "pred answer": "land", "question_id": 1767635, "best approach": "concept", "verif answer": "end of day", "anno approach": "concept", "verif wiki answer": "morn(0.7309)", "verif concept answer": "end of day(0.7310)", "verif image answer": "noon(0.7237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176763.jpg"}, {"question": "what is the complimentary color of the road sign", "gt answer": "green(1.00)<br/>red(1.00)<br/>white(0.60)", "pred answer": "stop", "question_id": 2493635, "best approach": "image", "verif answer": "white", "anno approach": "image", "verif wiki answer": "spire(0.6539)", "verif concept answer": "spire(0.5476)", "verif image answer": "white(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249363.jpg"}, {"question": "what is this person doing", "gt answer": "cross country ski(1.00)<br/>ski(1.00)<br/>snow(0.60)", "pred answer": "ski", "question_id": 1701225, "best approach": "concept, image", "verif answer": "ski", "anno approach": "concept", "verif wiki answer": "snow(0.6108)", "verif concept answer": "ski(0.7281)", "verif image answer": "cross country ski(0.5790)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000170122.jpg"}, {"question": "which type of fruits are seen here", "gt answer": "apple and orange(1.00)<br/>orange(0.60)", "pred answer": "apple", "question_id": 5253425, "best approach": "", "verif answer": "apple", "anno approach": "", "verif wiki answer": "apple(0.7290)", "verif concept answer": "apple(0.7292)", "verif image answer": "apple(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525342.jpg"}, {"question": "what is the complimentary color to the helmet of the batter", "gt answer": "blue(1.00)<br/>white(0.60)<br/>red(0.60)<br/>green(0.60)", "pred answer": "red", "question_id": 1201795, "best approach": "wiki, concept, image", "verif answer": "red", "anno approach": "wiki", "verif wiki answer": "red(0.6739)", "verif concept answer": "red(0.6572)", "verif image answer": "red(0.6372)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000120179.jpg"}, {"question": "do you see two blue birds or two seagulls", "gt answer": "seagull(1.00)<br/>2 seagulls(1.00)", "pred answer": "sparrow", "question_id": 4274915, "best approach": "wiki, concept, image", "verif answer": "seagull", "anno approach": "image, wiki", "verif wiki answer": "seagull(0.7127)", "verif concept answer": "seagull(0.6708)", "verif image answer": "seagull(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427491.jpg"}, {"question": "is this set in an urban or rural area", "gt answer": "rural(1.00)", "pred answer": "rural", "question_id": 2108995, "best approach": "wiki, concept, image", "verif answer": "rural", "anno approach": "wiki", "verif wiki answer": "rural(0.7239)", "verif concept answer": "rural(0.7277)", "verif image answer": "rural(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210899.jpg"}, {"question": "what healthy orange vegetable is on this plate", "gt answer": "carrot(1.00)", "pred answer": "carrot", "question_id": 3019275, "best approach": "wiki, concept, image", "verif answer": "carrot", "anno approach": "wiki", "verif wiki answer": "carrot(0.7172)", "verif concept answer": "carrot(0.7288)", "verif image answer": "carrot(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301927.jpg"}, {"question": "what is the monkey on the child 's backpack doing", "gt answer": "eat banana(1.00)<br/>eat(1.00)", "pred answer": "travel", "question_id": 4485315, "best approach": "wiki, concept, image", "verif answer": "eat banana", "anno approach": "", "verif wiki answer": "eat banana(0.7248)", "verif concept answer": "eat banana(0.7118)", "verif image answer": "eat banana(0.7221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448531.jpg"}, {"question": "in which city are the headquarters of the company that manufactures this type of computers located", "gt answer": "cupertino(1.00)<br/>seattle(0.60)", "pred answer": "los angeles", "question_id": 4788855, "best approach": "wiki, concept, image", "verif answer": "seattle", "anno approach": "wiki", "verif wiki answer": "seattle(0.6955)", "verif concept answer": "seattle(0.7004)", "verif image answer": "seattle(0.7131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478885.jpg"}, {"question": "what fruit is shown", "gt answer": "blueberry(1.00)", "pred answer": "blueberry", "question_id": 3600315, "best approach": "wiki, concept, image", "verif answer": "blueberry", "anno approach": "wiki", "verif wiki answer": "blueberry(0.7309)", "verif concept answer": "blueberry(0.7310)", "verif image answer": "blueberry(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000360031.jpg"}, {"question": "what ingredients were used for this dessert", "gt answer": "chocolate(1.00)", "pred answer": "green", "question_id": 2380185, "best approach": "", "verif answer": "flour", "anno approach": "", "verif wiki answer": "flour(0.6680)", "verif concept answer": "flour(0.6618)", "verif image answer": "flour(0.6958)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238018.jpg"}, {"question": "what adult achievement recognized by three letters is comparable to a high school diploma", "gt answer": "ged(1.00)<br/>5(0.60)", "pred answer": "cat", "question_id": 4598535, "best approach": "wiki, concept, image", "verif answer": "ged", "anno approach": "", "verif wiki answer": "ged(0.7270)", "verif concept answer": "ged(0.7304)", "verif image answer": "ged(0.7040)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459853.jpg"}, {"question": "what is the use for this vehicle", "gt answer": "dig(1.00)<br/>construction(0.60)", "pred answer": "construction", "question_id": 3682935, "best approach": "image", "verif answer": "dump", "anno approach": "image", "verif wiki answer": "construction(0.7231)", "verif concept answer": "dump(0.7279)", "verif image answer": "dig(0.6480)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000368293.jpg"}, {"question": "what type of car is the gray car", "gt answer": "jeep(1.00)<br/>corolla(0.60)<br/>suv(0.60)", "pred answer": "sedan", "question_id": 4767615, "best approach": "image", "verif answer": "sedan", "anno approach": "image", "verif wiki answer": "sedan(0.7199)", "verif concept answer": "corolla(0.5988)", "verif image answer": "jeep(0.6073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476761.jpg"}, {"question": "what kind of fish is on that plate", "gt answer": "salmon(1.00)", "pred answer": "salmon", "question_id": 989445, "best approach": "wiki, concept, image", "verif answer": "salmon", "anno approach": "wiki", "verif wiki answer": "salmon(0.6916)", "verif concept answer": "salmon(0.6897)", "verif image answer": "salmon(0.6807)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098944.jpg"}, {"question": "who invented the toy the girl in holding", "gt answer": "mozi and lu ban(1.00)<br/>chinese(0.60)<br/>ben franklin(0.60)", "pred answer": "benjamin franklin", "question_id": 5445615, "best approach": "concept, image", "verif answer": "benjamin franklin", "anno approach": "", "verif wiki answer": "benjamin franklin(0.7309)", "verif concept answer": "mozi and lu ban(0.7172)", "verif image answer": "mozi and lu ban(0.7132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544561.jpg"}, {"question": "what types of boats are in this picture", "gt answer": "sail(1.00)<br/>sailboat(1.00)<br/>yacht(0.60)", "pred answer": "sail", "question_id": 2052435, "best approach": "concept", "verif answer": "yacht", "anno approach": "concept", "verif wiki answer": "yacht(0.7263)", "verif concept answer": "sail(0.7246)", "verif image answer": "yacht(0.7104)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205243.jpg"}, {"question": "what position did the man on the shirt hold", "gt answer": "president(1.00)<br/>wine taster(0.60)", "pred answer": "batter", "question_id": 5136835, "best approach": "wiki, concept, image", "verif answer": "president", "anno approach": "wiki", "verif wiki answer": "president(0.7209)", "verif concept answer": "president(0.7271)", "verif image answer": "president(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513683.jpg"}, {"question": "of what airplane is this a model", "gt answer": "biplane(1.00)<br/>boat(0.60)<br/>glider(0.60)", "pred answer": "boeing", "question_id": 11685, "best approach": "", "verif answer": "private", "anno approach": "", "verif wiki answer": "private(0.6956)", "verif concept answer": "private(0.6855)", "verif image answer": "private(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001168.jpg"}, {"question": "what two chemical elements make up the substance that is most prevalent in this picture", "gt answer": "hydrogen and oxygen(1.00)", "pred answer": "ship", "question_id": 2020505, "best approach": "wiki, concept, image", "verif answer": "hydrogen and oxygen", "anno approach": "wiki", "verif wiki answer": "hydrogen and oxygen(0.7287)", "verif concept answer": "hydrogen and oxygen(0.7291)", "verif image answer": "hydrogen and oxygen(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202050.jpg"}, {"question": "what is the use of that pink object over her head", "gt answer": "keep dry(1.00)", "pred answer": "umbrella", "question_id": 4705325, "best approach": "wiki, concept, image", "verif answer": "keep dry", "anno approach": "", "verif wiki answer": "keep dry(0.6834)", "verif concept answer": "keep dry(0.6838)", "verif image answer": "keep dry(0.6980)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470532.jpg"}, {"question": "what physical feature seen here looks the way dirt that has been baked in the sun starts to look", "gt answer": "cracked(1.00)<br/>spot(0.60)", "pred answer": "rainbow", "question_id": 1306815, "best approach": "", "verif answer": "gate", "anno approach": "", "verif wiki answer": "long neck(0.6185)", "verif concept answer": "long neck(0.6552)", "verif image answer": "gate(0.6680)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130681.jpg"}, {"question": "what sport is this", "gt answer": "kite(1.00)<br/>kite fly(0.60)", "pred answer": "kite fly", "question_id": 3851085, "best approach": "", "verif answer": "fly kite", "anno approach": "", "verif wiki answer": "fly kite(0.7175)", "verif concept answer": "fly kite(0.6994)", "verif image answer": "fly kite(0.5489)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385108.jpg"}, {"question": "where was this motorcycle manufactured", "gt answer": "japan(1.00)<br/>europe(0.60)<br/>kawasaki(0.60)", "pred answer": "america", "question_id": 5495325, "best approach": "wiki, concept, image", "verif answer": "kawasaki", "anno approach": "wiki", "verif wiki answer": "kawasaki(0.6963)", "verif concept answer": "kawasaki(0.7161)", "verif image answer": "kawasaki(0.7008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000549532.jpg"}, {"question": "what part of town are we located", "gt answer": "downtown(1.00)<br/>center(0.60)<br/>city(0.60)<br/>china(0.60)", "pred answer": "downtown", "question_id": 4058005, "best approach": "wiki, concept, image", "verif answer": "downtown", "anno approach": "wiki", "verif wiki answer": "downtown(0.7309)", "verif concept answer": "downtown(0.7307)", "verif image answer": "downtown(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405800.jpg"}, {"question": "this statue is used to track what", "gt answer": "time(1.00)<br/>horse race(0.60)", "pred answer": "time", "question_id": 5339415, "best approach": "image", "verif answer": "horse race", "anno approach": "image", "verif wiki answer": "horse race(0.6579)", "verif concept answer": "horse race(0.6876)", "verif image answer": "time(0.5467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000533941.jpg"}, {"question": "what kind of hat is the person on the left of the photo wearing", "gt answer": "beanie(1.00)", "pred answer": "fedora", "question_id": 1712625, "best approach": "wiki, concept, image", "verif answer": "beanie", "anno approach": "wiki", "verif wiki answer": "beanie(0.7286)", "verif concept answer": "beanie(0.7309)", "verif image answer": "beanie(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171262.jpg"}, {"question": "are those cabinets painted or plastic", "gt answer": "painted(1.00)<br/>plastic(0.60)", "pred answer": "paint", "question_id": 1261825, "best approach": "wiki, concept", "verif answer": "mirrored", "anno approach": "wiki", "verif wiki answer": "plastic(0.7184)", "verif concept answer": "plastic(0.7291)", "verif image answer": "mirrored(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126182.jpg"}, {"question": "what would someone do with the object in the photo", "gt answer": "sit(1.00)", "pred answer": "read", "question_id": 2228715, "best approach": "wiki, concept, image", "verif answer": "sit", "anno approach": "wiki", "verif wiki answer": "sit(0.6647)", "verif concept answer": "sit(0.6809)", "verif image answer": "sit(0.6656)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222871.jpg"}, {"question": "what is this room used for", "gt answer": "sleep(1.00)", "pred answer": "sleep", "question_id": 2280435, "best approach": "wiki, concept, image", "verif answer": "sleep", "anno approach": "wiki", "verif wiki answer": "sleep(0.7308)", "verif concept answer": "sleep(0.7290)", "verif image answer": "sleep(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000228043.jpg"}, {"question": "what type of day is it", "gt answer": "windy(1.00)<br/>sunny(1.00)", "pred answer": "cloudy", "question_id": 1490855, "best approach": "", "verif answer": "cloudy", "anno approach": "", "verif wiki answer": "cloudy(0.7310)", "verif concept answer": "cloudy(0.7310)", "verif image answer": "cloudy(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149085.jpg"}, {"question": "how is the mouse connected to the computer", "gt answer": "bluetooth(1.00)<br/>wireless(1.00)", "pred answer": "bluetooth", "question_id": 124635, "best approach": "wiki, concept", "verif answer": "bluetooth", "anno approach": "wiki", "verif wiki answer": "wireless(0.7198)", "verif concept answer": "bluetooth(0.7204)", "verif image answer": "cord(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012463.jpg"}, {"question": "what type of architecture is this", "gt answer": "gothic(1.00)<br/>victorian(0.60)", "pred answer": "roman", "question_id": 3101555, "best approach": "", "verif answer": "roman", "anno approach": "", "verif wiki answer": "roman(0.6989)", "verif concept answer": "roman(0.7032)", "verif image answer": "roman(0.7018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310155.jpg"}, {"question": "what form of entertainment is depicted in the photo", "gt answer": "bowl(1.00)<br/>video game(1.00)", "pred answer": "video game", "question_id": 5734825, "best approach": "", "verif answer": "wii bowl", "anno approach": "", "verif wiki answer": "wii(0.7000)", "verif concept answer": "wii(0.6620)", "verif image answer": "wii bowl(0.7004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000573482.jpg"}, {"question": "what other utensil could be used to eat this dish", "gt answer": "fork(1.00)", "pred answer": "spoon", "question_id": 5202085, "best approach": "", "verif answer": "fork and knife", "anno approach": "", "verif wiki answer": "fork and knife(0.7307)", "verif concept answer": "fork and knife(0.7305)", "verif image answer": "fork and knife(0.6637)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520208.jpg"}, {"question": "who made this bed at the hotel", "gt answer": "maid(1.00)<br/>serta(0.60)", "pred answer": "owner", "question_id": 3971815, "best approach": "", "verif answer": "queen", "anno approach": "", "verif wiki answer": "queen(0.6250)", "verif concept answer": "queen(0.5965)", "verif image answer": "queen(0.6240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397181.jpg"}, {"question": "what does this girl need in order to surf", "gt answer": "wave(1.00)<br/>surfboard(0.60)", "pred answer": "surfboard", "question_id": 3240365, "best approach": "wiki, concept, image", "verif answer": "surfboard", "anno approach": "wiki", "verif wiki answer": "surfboard(0.6890)", "verif concept answer": "surfboard(0.6829)", "verif image answer": "surfboard(0.6744)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324036.jpg"}, {"question": "what type of cows are pictured here", "gt answer": "dairy(1.00)<br/>baby(0.60)", "pred answer": "holstein", "question_id": 3481805, "best approach": "", "verif answer": "dairy cow", "anno approach": "", "verif wiki answer": "dairy cow(0.6860)", "verif concept answer": "dairy cow(0.6660)", "verif image answer": "dairy cow(0.6847)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348180.jpg"}, {"question": "besides horses what animals are these that you can ride", "gt answer": "elephant(1.00)", "pred answer": "cow", "question_id": 2146995, "best approach": "wiki, concept, image", "verif answer": "elephant", "anno approach": "image, wiki", "verif wiki answer": "elephant(0.6882)", "verif concept answer": "elephant(0.7119)", "verif image answer": "elephant(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214699.jpg"}, {"question": "the open location where the animals are is called what", "gt answer": "savannah(1.00)<br/>plain(0.60)", "pred answer": "savannah", "question_id": 4606425, "best approach": "wiki, concept", "verif answer": "savannah", "anno approach": "wiki", "verif wiki answer": "savannah(0.7304)", "verif concept answer": "savannah(0.7141)", "verif image answer": "outside(0.6705)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460642.jpg"}, {"question": "where are the mountains located", "gt answer": "peru(1.00)<br/>grand canyon(0.60)", "pred answer": "nevada", "question_id": 599535, "best approach": "", "verif answer": "mountain", "anno approach": "", "verif wiki answer": "mountain(0.7282)", "verif concept answer": "mountain(0.7264)", "verif image answer": "mountain(0.7146)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059953.jpg"}, {"question": "where is this carriage displayed", "gt answer": "museum(1.00)<br/>horse(0.60)<br/>mall(0.60)<br/>china(0.60)", "pred answer": "lobby", "question_id": 3117265, "best approach": "wiki, concept, image", "verif answer": "horse", "anno approach": "concept, wiki", "verif wiki answer": "horse(0.6693)", "verif concept answer": "horse(0.6881)", "verif image answer": "china(0.6498)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311726.jpg"}, {"question": "for what purpose did this breed of dog originate for", "gt answer": "hunt(1.00)<br/>race(0.60)<br/>work(0.60)", "pred answer": "race", "question_id": 4314405, "best approach": "wiki, concept, image", "verif answer": "hunt", "anno approach": "wiki", "verif wiki answer": "hunt(0.6577)", "verif concept answer": "hunt(0.6534)", "verif image answer": "hunt(0.6814)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431440.jpg"}, {"question": "what musical instrument used to be made with parts from these animals", "gt answer": "piano(1.00)<br/>horn(0.60)", "pred answer": "guitar", "question_id": 1381335, "best approach": "wiki, concept, image", "verif answer": "piano", "anno approach": "wiki", "verif wiki answer": "piano(0.5013)", "verif concept answer": "piano(0.5139)", "verif image answer": "piano(0.5055)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138133.jpg"}, {"question": "what type of transportation is this", "gt answer": "motorcycle(1.00)", "pred answer": "motorcycle", "question_id": 1395945, "best approach": "wiki, concept, image", "verif answer": "motorcycle", "anno approach": "wiki", "verif wiki answer": "motorcycle(0.7247)", "verif concept answer": "motorcycle(0.7083)", "verif image answer": "motorcycle(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139594.jpg"}, {"question": "what are the two vegetables on the counter", "gt answer": "broccoli and carrot(1.00)", "pred answer": "carrot", "question_id": 2650745, "best approach": "", "verif answer": "veggie", "anno approach": "", "verif wiki answer": "broccoli cauliflower(0.6698)", "verif concept answer": "veggie(0.6733)", "verif image answer": "broccoli(0.6149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265074.jpg"}, {"question": "this sort of narrow space is called a what", "gt answer": "alley(1.00)", "pred answer": "concrete", "question_id": 619515, "best approach": "", "verif answer": "street", "anno approach": "", "verif wiki answer": "street(0.5390)", "verif concept answer": "street(0.5750)", "verif image answer": "store(0.5071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061951.jpg"}, {"question": "the horizontal slats connecting the rails seen here are generally called railroad what", "gt answer": "tie(1.00)<br/>track(0.60)", "pred answer": "electric", "question_id": 5115085, "best approach": "", "verif answer": "attach to surfer", "anno approach": "", "verif wiki answer": "attach to surfer(0.7012)", "verif concept answer": "attach to surfer(0.7015)", "verif image answer": "attach to surfer(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511508.jpg"}, {"question": "what other fruit would go goood with that", "gt answer": "blueberry(1.00)<br/>cherry(0.60)<br/>strawberry(0.60)", "pred answer": "tomato", "question_id": 3514945, "best approach": "wiki, concept, image", "verif answer": "blueberry", "anno approach": "concept, wiki", "verif wiki answer": "blueberry(0.6815)", "verif concept answer": "blueberry(0.6892)", "verif image answer": "blueberry(0.5772)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351494.jpg"}, {"question": "what was that item the child was holding used for", "gt answer": "brush teeth(1.00)<br/>toothbrush(0.60)<br/>clean teeth(0.60)", "pred answer": "clean teeth", "question_id": 1513185, "best approach": "concept, image", "verif answer": "toothbrush", "anno approach": "", "verif wiki answer": "teeth(0.7243)", "verif concept answer": "toothbrush(0.7166)", "verif image answer": "toothbrush(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151318.jpg"}, {"question": "what company manufactured the water faucet seen here", "gt answer": "moen(1.00)<br/>kohler(1.00)", "pred answer": "colgate", "question_id": 1259955, "best approach": "wiki, concept, image", "verif answer": "kohler", "anno approach": "wiki", "verif wiki answer": "kohler(0.6930)", "verif concept answer": "kohler(0.7017)", "verif image answer": "kohler(0.7204)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125995.jpg"}, {"question": "what 's that birds species", "gt answer": "cardinal(1.00)<br/>parakeet(0.60)<br/>robin(0.60)", "pred answer": "cardinal", "question_id": 4350455, "best approach": "wiki, concept, image", "verif answer": "cardinal", "anno approach": "wiki", "verif wiki answer": "cardinal(0.7220)", "verif concept answer": "cardinal(0.7191)", "verif image answer": "cardinal(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435045.jpg"}, {"question": "what type of skiing is going on here", "gt answer": "cross country(1.00)<br/>downhill(0.60)", "pred answer": "downhill", "question_id": 2373855, "best approach": "wiki, concept, image", "verif answer": "cross country", "anno approach": "", "verif wiki answer": "cross country(0.7302)", "verif concept answer": "cross country(0.7290)", "verif image answer": "cross country(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237385.jpg"}, {"question": "what causes these waves", "gt answer": "tide(1.00)<br/>gravity(0.60)<br/>wind(0.60)", "pred answer": "wave", "question_id": 1228965, "best approach": "", "verif answer": "moon", "anno approach": "", "verif wiki answer": "moon(0.6458)", "verif concept answer": "moon(0.6412)", "verif image answer": "moon(0.7275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122896.jpg"}, {"question": "what is the building called", "gt answer": "skyscraper(1.00)", "pred answer": "office", "question_id": 2638265, "best approach": "wiki, concept, image", "verif answer": "skyscraper", "anno approach": "image", "verif wiki answer": "skyscraper(0.6946)", "verif concept answer": "skyscraper(0.6777)", "verif image answer": "skyscraper(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263826.jpg"}, {"question": "how long does it take for this fruit to become ripe once germinated", "gt answer": "1 week(1.00)<br/>4 months(0.60)<br/>1 month(0.60)<br/>2 weeks(0.60)", "pred answer": "4 days", "question_id": 1136545, "best approach": "wiki, concept", "verif answer": "1 month", "anno approach": "concept, wiki", "verif wiki answer": "1 month(0.5762)", "verif concept answer": "1 month(0.6520)", "verif image answer": "4 days(0.5136)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113654.jpg"}, {"question": "", "gt answer": "steamed(0.60)<br/>5 minutes(0.60)<br/>grill(0.60)<br/>grilled(0.60)<br/>steam(0.60)", "pred answer": "grilled", "question_id": 2807215, "best approach": "wiki, concept, image", "verif answer": "grilled", "anno approach": "", "verif wiki answer": "grilled(0.6284)", "verif concept answer": "grilled(0.6288)", "verif image answer": "grilled(0.6411)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280721.jpg"}, {"question": "what do these animals eat", "gt answer": "pet food(1.00)<br/>cat food(0.60)<br/>meat(0.60)", "pred answer": "cat food", "question_id": 331115, "best approach": "concept", "verif answer": "cat food", "anno approach": "concept", "verif wiki answer": "cat food(0.7300)", "verif concept answer": "pet food(0.7298)", "verif image answer": "cat food(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033111.jpg"}, {"question": "what design is drawn on the plate", "gt answer": "spider web(1.00)", "pred answer": "checkered", "question_id": 4177515, "best approach": "", "verif answer": "stripe", "anno approach": "", "verif wiki answer": "stripe(0.7099)", "verif concept answer": "stripe(0.6929)", "verif image answer": "stripe(0.6790)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417751.jpg"}, {"question": "how do mirrors distort light", "gt answer": "reflection(0.60)<br/>reflect(1.00)", "pred answer": "remote", "question_id": 4421545, "best approach": "", "verif answer": "wash it", "anno approach": "", "verif wiki answer": "wash it(0.6242)", "verif concept answer": "wash it(0.5963)", "verif image answer": "wash it(0.5369)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442154.jpg"}, {"question": "which type of glass is used to make this table", "gt answer": "tempered(1.00)<br/>clear(0.60)<br/>pane(0.60)", "pred answer": "glass", "question_id": 1795195, "best approach": "wiki, concept", "verif answer": "pane", "anno approach": "wiki", "verif wiki answer": "pane(0.7194)", "verif concept answer": "pane(0.7179)", "verif image answer": "black and white(0.7067)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000179519.jpg"}, {"question": "is it day time or night time", "gt answer": "day time(1.00)<br/>day(0.60)<br/>daytime(0.60)", "pred answer": "day", "question_id": 4799355, "best approach": "wiki, concept, image", "verif answer": "day", "anno approach": "concept, wiki", "verif wiki answer": "day(0.7231)", "verif concept answer": "day(0.7295)", "verif image answer": "day(0.5651)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479935.jpg"}, {"question": "are the tomatoes on this salad a fruit or vegetable", "gt answer": "vegetable(1.00)<br/>fruit(0.60)", "pred answer": "veggies", "question_id": 3388645, "best approach": "concept", "verif answer": "vegetable", "anno approach": "concept", "verif wiki answer": "produce(0.6079)", "verif concept answer": "vegetable(0.6494)", "verif image answer": "produce(0.5798)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338864.jpg"}, {"question": "what floor is this room on", "gt answer": "first(1.00)<br/>main(0.60)", "pred answer": "concrete", "question_id": 4150895, "best approach": "", "verif answer": "kindergarten", "anno approach": "", "verif wiki answer": "kindergarten(0.6118)", "verif concept answer": "kindergarten(0.6470)", "verif image answer": "walkway(0.6450)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415089.jpg"}, {"question": "", "gt answer": "little(0.60)<br/>$10(0.60)<br/>200(0.60)", "pred answer": "$100", "question_id": 145365, "best approach": "wiki, concept, image", "verif answer": "$10", "anno approach": "concept, wiki", "verif wiki answer": "$10(0.7197)", "verif concept answer": "$10(0.7226)", "verif image answer": "$10(0.5887)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000014536.jpg"}, {"question": "which form is the wood", "gt answer": "log(1.00)<br/>arm(0.60)<br/>board(0.60)", "pred answer": "oak", "question_id": 3825825, "best approach": "wiki, concept", "verif answer": "bamboo", "anno approach": "wiki", "verif wiki answer": "log(0.7118)", "verif concept answer": "log(0.7053)", "verif image answer": "bamboo(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382582.jpg"}, {"question": "what city is shown in the photo", "gt answer": "tokyo(1.00)<br/>new york(1.00)", "pred answer": "san francisco", "question_id": 903245, "best approach": "", "verif answer": "chicago", "anno approach": "", "verif wiki answer": "chicago(0.5000)", "verif concept answer": "chicago(0.5000)", "verif image answer": "chicago(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090324.jpg"}, {"question": "what kind of serve is he using", "gt answer": "underhand(1.00)<br/>backhand(1.00)", "pred answer": "backhand", "question_id": 2674995, "best approach": "image", "verif answer": "backhand", "anno approach": "image", "verif wiki answer": "overhand(0.6941)", "verif concept answer": "overhand(0.6882)", "verif image answer": "backhand(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000267499.jpg"}, {"question": "the tip of the tallest building is what color", "gt answer": "green(1.00)<br/>spire(0.60)<br/>red(0.60)", "pred answer": "white", "question_id": 627405, "best approach": "wiki, concept, image", "verif answer": "spire", "anno approach": "concept, wiki", "verif wiki answer": "spire(0.6951)", "verif concept answer": "spire(0.7131)", "verif image answer": "spire(0.6593)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000062740.jpg"}, {"question": "how long will it take them to drink this coffee", "gt answer": "forever(1.00)", "pred answer": "10 minutes", "question_id": 2646995, "best approach": "", "verif answer": "5 days", "anno approach": "", "verif wiki answer": "5 days(0.6494)", "verif concept answer": "5 days(0.5292)", "verif image answer": "5 days(0.5376)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000264699.jpg"}, {"question": "what is the formal name of pipe exhausting smoke from the woodburning stove", "gt answer": "chimney(1.00)", "pred answer": "heater", "question_id": 1284345, "best approach": "", "verif answer": "chimney sweep", "anno approach": "", "verif wiki answer": "bleach(0.7141)", "verif concept answer": "chimney sweep(0.7295)", "verif image answer": "chimney sweep(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128434.jpg"}, {"question": "what raquet brand is he using", "gt answer": "wilson(1.00)", "pred answer": "wimbledon", "question_id": 5345135, "best approach": "wiki, concept, image", "verif answer": "wilson", "anno approach": "wiki", "verif wiki answer": "wilson(0.6195)", "verif concept answer": "wilson(0.5984)", "verif image answer": "wilson(0.5980)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534513.jpg"}, {"question": "what type of owl is this", "gt answer": "snow owl(1.00)<br/>barn(0.60)<br/>night(0.60)", "pred answer": "pigeon", "question_id": 2770505, "best approach": "image", "verif answer": "barn", "anno approach": "image", "verif wiki answer": "barn(0.5013)", "verif concept answer": "barn(0.5006)", "verif image answer": "snow owl(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277050.jpg"}, {"question": "what kind of house is here", "gt answer": "apartment(1.00)<br/>apart(1.00)", "pred answer": "gothic", "question_id": 771545, "best approach": "wiki, concept, image", "verif answer": "apart", "anno approach": "concept, wiki", "verif wiki answer": "apart(0.6390)", "verif concept answer": "apart(0.6237)", "verif image answer": "apart(0.5667)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077154.jpg"}, {"question": "what kind of sandwhich is on the plate", "gt answer": "ham and cheese(1.00)<br/>ham(0.60)", "pred answer": "blackberry", "question_id": 2498565, "best approach": "", "verif answer": "grilled", "anno approach": "", "verif wiki answer": "grilled(0.6586)", "verif concept answer": "grilled(0.6397)", "verif image answer": "grilled(0.6494)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249856.jpg"}, {"question": "what type of food is this", "gt answer": "sandwich(1.00)<br/>burger(0.60)", "pred answer": "fast food", "question_id": 2910195, "best approach": "", "verif answer": "slider", "anno approach": "", "verif wiki answer": "slider(0.6826)", "verif concept answer": "slider(0.6885)", "verif image answer": "cake(0.6765)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291019.jpg"}, {"question": "what skateboarding trick is he attempting", "gt answer": "ollie(1.00)<br/>extreme(0.60)<br/>kickflip(0.60)", "pred answer": "ollie", "question_id": 3710155, "best approach": "wiki, concept, image", "verif answer": "kickflip", "anno approach": "wiki", "verif wiki answer": "kickflip(0.7235)", "verif concept answer": "kickflip(0.7262)", "verif image answer": "extreme(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371015.jpg"}, {"question": "what is the professional name of the group in which these pilots fly", "gt answer": "blue angel(1.00)", "pred answer": "military", "question_id": 901065, "best approach": "", "verif answer": "starbucks", "anno approach": "", "verif wiki answer": "biker(0.5061)", "verif concept answer": "airshow(0.5047)", "verif image answer": "starbucks(0.6916)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090106.jpg"}, {"question": "what did the animal in the clock jump over in a nursery rhyme", "gt answer": "moon(1.00)", "pred answer": "mouse", "question_id": 2569085, "best approach": "wiki, concept, image", "verif answer": "moon", "anno approach": "concept, wiki", "verif wiki answer": "moon(0.7204)", "verif concept answer": "moon(0.7213)", "verif image answer": "moon(0.6598)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256908.jpg"}, {"question": "known to be on a very fast car", "gt answer": "mustang(1.00)", "pred answer": "secretariat", "question_id": 5585815, "best approach": "wiki, concept, image", "verif answer": "mustang", "anno approach": "wiki", "verif wiki answer": "mustang(0.7189)", "verif concept answer": "mustang(0.7241)", "verif image answer": "mustang(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558581.jpg"}, {"question": "what voltage is that electrial outlet in the wall rated at", "gt answer": "120v(1.00)<br/>low(0.60)", "pred answer": "usb", "question_id": 2432315, "best approach": "wiki, concept, image", "verif answer": "120v", "anno approach": "", "verif wiki answer": "120v(0.6636)", "verif concept answer": "120v(0.6407)", "verif image answer": "120v(0.6549)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243231.jpg"}, {"question": "what was the name of the brothers who first created one of these", "gt answer": "wright(1.00)<br/>wright brother(0.60)", "pred answer": "pilot", "question_id": 4988135, "best approach": "", "verif answer": "boeing", "anno approach": "", "verif wiki answer": "boeing(0.6280)", "verif concept answer": "boeing(0.6036)", "verif image answer": "boeing(0.6564)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000498813.jpg"}, {"question": "how many people can be seated in the furniture", "gt answer": "4(1.00)", "pred answer": "50", "question_id": 2570205, "best approach": "", "verif answer": "2", "anno approach": "", "verif wiki answer": "3(0.6062)", "verif concept answer": "3(0.6600)", "verif image answer": "2(0.7197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257020.jpg"}, {"question": "what type of pizza is this", "gt answer": "vegetarian(1.00)", "pred answer": "veggie", "question_id": 5281515, "best approach": "", "verif answer": "vegan", "anno approach": "", "verif wiki answer": "vegetable(0.6099)", "verif concept answer": "vegetable(0.6278)", "verif image answer": "vegan(0.6487)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528151.jpg"}, {"question": "who owns the company that manufactures this type of truck", "gt answer": "harrisons(1.00)<br/>toyota(0.60)<br/>ford(0.60)", "pred answer": "boeing", "question_id": 2629765, "best approach": "wiki, concept, image", "verif answer": "toyota", "anno approach": "wiki", "verif wiki answer": "toyota(0.7210)", "verif concept answer": "toyota(0.7137)", "verif image answer": "toyota(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262976.jpg"}, {"question": "what is the cause of the orange dust like breakdown shown on these cars", "gt answer": "rust(1.00)<br/>oxidation(1.00)", "pred answer": "fire", "question_id": 1997325, "best approach": "", "verif answer": "reflection", "anno approach": "", "verif wiki answer": "shadow(0.6540)", "verif concept answer": "shadow(0.5269)", "verif image answer": "reflection(0.6883)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199732.jpg"}, {"question": "how many teeth does this animal have", "gt answer": "42(1.00)<br/>45(0.60)<br/>25(0.60)<br/>lot(0.60)", "pred answer": "42", "question_id": 3961945, "best approach": "wiki, concept", "verif answer": "45", "anno approach": "wiki", "verif wiki answer": "42(0.7052)", "verif concept answer": "42(0.6937)", "verif image answer": "45(0.7134)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396194.jpg"}, {"question": "what distinguishes these trees from many other north american trees during the autumn season", "gt answer": "remain green(1.00)", "pred answer": "alp", "question_id": 1767575, "best approach": "", "verif answer": "bear", "anno approach": "", "verif wiki answer": "bear(0.6980)", "verif concept answer": "bear(0.6762)", "verif image answer": "native(0.5519)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176757.jpg"}, {"question": "is this a king or queen bed", "gt answer": "queen(1.00)<br/>king(1.00)", "pred answer": "single", "question_id": 2933065, "best approach": "", "verif answer": "full", "anno approach": "", "verif wiki answer": "full(0.7307)", "verif concept answer": "full(0.7267)", "verif image answer": "full(0.6391)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293306.jpg"}, {"question": "what rank do each of these men hold", "gt answer": "captain(1.00)<br/>police(0.60)", "pred answer": "captain", "question_id": 4798555, "best approach": "wiki, concept, image", "verif answer": "captain", "anno approach": "wiki", "verif wiki answer": "captain(0.7282)", "verif concept answer": "captain(0.7285)", "verif image answer": "captain(0.7214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479855.jpg"}, {"question": "how many of this animal are in the us", "gt answer": "85.8 million(1.00)<br/>thousand(0.60)", "pred answer": "7", "question_id": 5667655, "best approach": "concept", "verif answer": "thousand", "anno approach": "concept", "verif wiki answer": "million(0.6274)", "verif concept answer": "thousand(0.6435)", "verif image answer": "million(0.5656)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566765.jpg"}, {"question": "what kind of hat is this man wearing", "gt answer": "sombrero(1.00)<br/>big(0.60)", "pred answer": "bowler", "question_id": 4994255, "best approach": "wiki", "verif answer": "fedora", "anno approach": "wiki", "verif wiki answer": "sombrero(0.7306)", "verif concept answer": "hijab(0.7310)", "verif image answer": "fedora(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499425.jpg"}, {"question": "what does this animal eat", "gt answer": "seed(1.00)<br/>grain(0.60)<br/>nut(0.60)", "pred answer": "seed", "question_id": 5002715, "best approach": "wiki, concept", "verif answer": "grain", "anno approach": "wiki", "verif wiki answer": "grain(0.7161)", "verif concept answer": "grain(0.6282)", "verif image answer": "mice(0.6052)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500271.jpg"}, {"question": "when were stoves invented", "gt answer": "1820s(1.00)<br/>1950s(0.60)<br/>1850(0.60)", "pred answer": "1800's", "question_id": 96205, "best approach": "wiki, concept, image", "verif answer": "1950s", "anno approach": "image, wiki", "verif wiki answer": "1950s(0.5849)", "verif concept answer": "1950s(0.5641)", "verif image answer": "1950s(0.6271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009620.jpg"}, {"question": "what force pulls the skier down the hill", "gt answer": "gravity(1.00)", "pred answer": "skiis", "question_id": 4000945, "best approach": "concept, image", "verif answer": "gravity", "anno approach": "image", "verif wiki answer": "aerodynamic(0.6205)", "verif concept answer": "gravity(0.5696)", "verif image answer": "gravity(0.6298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400094.jpg"}, {"question": "what is the animals offspring called", "gt answer": "foal(1.00)<br/>colt(1.00)<br/>zebra(0.60)", "pred answer": "calf", "question_id": 5103335, "best approach": "wiki, concept, image", "verif answer": "zebra", "anno approach": "image, wiki", "verif wiki answer": "zebra(0.6632)", "verif concept answer": "zebra(0.5926)", "verif image answer": "zebra(0.6254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510333.jpg"}, {"question": "do you think he just landed a trick or did he fail", "gt answer": "landed(1.00)", "pred answer": "jump", "question_id": 5012125, "best approach": "", "verif answer": "strike", "anno approach": "", "verif wiki answer": "strike(0.7098)", "verif concept answer": "strike(0.7160)", "verif image answer": "strike(0.6772)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501212.jpg"}, {"question": "is this airplane on the ground or flying in the air", "gt answer": "on ground(1.00)<br/>parked(0.60)", "pred answer": "take off", "question_id": 5299055, "best approach": "wiki", "verif answer": "take off", "anno approach": "wiki", "verif wiki answer": "on ground(0.6887)", "verif concept answer": "take off(0.7051)", "verif image answer": "take off(0.7271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529905.jpg"}, {"question": "what is strange about these cars", "gt answer": "stuffed animal(1.00)<br/>bear(0.60)<br/>teddy bear(0.60)", "pred answer": "crowded", "question_id": 4283015, "best approach": "concept, image", "verif answer": "people", "anno approach": "", "verif wiki answer": "people(0.5270)", "verif concept answer": "bear(0.5181)", "verif image answer": "bear(0.5060)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428301.jpg"}, {"question": "what protects this building from the people on the outside", "gt answer": "fence(1.00)", "pred answer": "blind", "question_id": 193875, "best approach": "wiki, concept, image", "verif answer": "fence", "anno approach": "wiki", "verif wiki answer": "fence(0.7174)", "verif concept answer": "fence(0.7024)", "verif image answer": "fence(0.7004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019387.jpg"}, {"question": "what car accessory are you required by law to keep on at all times during the night while you are driving", "gt answer": "head light(1.00)<br/>light(0.60)", "pred answer": "stop", "question_id": 5586395, "best approach": "wiki, concept, image", "verif answer": "head light", "anno approach": "image, concept", "verif wiki answer": "head light(0.5975)", "verif concept answer": "head light(0.6781)", "verif image answer": "head light(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558639.jpg"}, {"question": "what is this room called when it is off the owner 's bedroom", "gt answer": "master(1.00)", "pred answer": "bathroom", "question_id": 3336535, "best approach": "", "verif answer": "bedroom", "anno approach": "", "verif wiki answer": "bedroom(0.6311)", "verif concept answer": "bedroom(0.6139)", "verif image answer": "bedroom(0.6443)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333653.jpg"}, {"question": "this boat travels using wooden what", "gt answer": "oar(1.00)", "pred answer": "canoe", "question_id": 494025, "best approach": "", "verif answer": "row", "anno approach": "", "verif wiki answer": "tow(0.6536)", "verif concept answer": "tow(0.6486)", "verif image answer": "row(0.6655)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049402.jpg"}, {"question": "what type of building is in the background", "gt answer": "stable(1.00)<br/>barn(0.60)", "pred answer": "barn", "question_id": 2366735, "best approach": "image", "verif answer": "barn", "anno approach": "image", "verif wiki answer": "barn(0.7305)", "verif concept answer": "barn(0.7284)", "verif image answer": "stable(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236673.jpg"}, {"question": "what is this woman about to do", "gt answer": "snowboard(1.00)", "pred answer": "jump", "question_id": 1856815, "best approach": "wiki, concept, image", "verif answer": "snowboard", "anno approach": "wiki", "verif wiki answer": "snowboard(0.5152)", "verif concept answer": "snowboard(0.5162)", "verif image answer": "snowboard(0.5284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185681.jpg"}, {"question": "what is the man in the white shirt drinking", "gt answer": "gatorade(1.00)", "pred answer": "wine", "question_id": 1874425, "best approach": "", "verif answer": "juice", "anno approach": "", "verif wiki answer": "juice(0.7175)", "verif concept answer": "baseball(0.6227)", "verif image answer": "juice(0.7052)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187442.jpg"}, {"question": "what year was this photograph taken in", "gt answer": "1945(1.00)<br/>1920(0.60)<br/>1930(0.60)", "pred answer": "1930", "question_id": 4704425, "best approach": "image", "verif answer": "1945", "anno approach": "image", "verif wiki answer": "1920s(0.6058)", "verif concept answer": "1920s(0.6264)", "verif image answer": "1945(0.6313)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470442.jpg"}, {"question": "how old is this little leaguer", "gt answer": "6(1.00)<br/>7(0.60)<br/>5(0.60)", "pred answer": "5 years", "question_id": 4484315, "best approach": "wiki, concept", "verif answer": "3", "anno approach": "wiki", "verif wiki answer": "7(0.5448)", "verif concept answer": "7(0.5353)", "verif image answer": "3(0.5546)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448431.jpg"}, {"question": "what fabric objects are normally put at these glass parts of the building", "gt answer": "curtain(1.00)<br/>blind(0.60)", "pred answer": "cloth", "question_id": 1289035, "best approach": "image", "verif answer": "blind", "anno approach": "image", "verif wiki answer": "paint(0.6811)", "verif concept answer": "paint(0.6595)", "verif image answer": "blind(0.7223)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128903.jpg"}, {"question": "what country is seen here", "gt answer": "egypt(1.00)", "pred answer": "alaska", "question_id": 959405, "best approach": "wiki, concept, image", "verif answer": "egypt", "anno approach": "", "verif wiki answer": "egypt(0.6175)", "verif concept answer": "egypt(0.6050)", "verif image answer": "egypt(0.6319)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000095940.jpg"}, {"question": "what kind of meat is in this sandwich", "gt answer": "ham(1.00)<br/>turkey(1.00)", "pred answer": "beef", "question_id": 2230685, "best approach": "wiki, concept", "verif answer": "chicken", "anno approach": "wiki", "verif wiki answer": "ham(0.7282)", "verif concept answer": "ham(0.7082)", "verif image answer": "chicken(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223068.jpg"}, {"question": "what fruit flavored ice cream can this be", "gt answer": "blueberry(1.00)", "pred answer": "new york", "question_id": 39925, "best approach": "wiki, concept, image", "verif answer": "blueberry", "anno approach": "wiki", "verif wiki answer": "blueberry(0.7046)", "verif concept answer": "blueberry(0.6796)", "verif image answer": "blueberry(0.7109)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003992.jpg"}, {"question": "what electrical items might you find in this room", "gt answer": "mixer(1.00)<br/>stove(0.60)", "pred answer": "electric", "question_id": 4877965, "best approach": "wiki", "verif answer": "blender", "anno approach": "wiki", "verif wiki answer": "mixer(0.6807)", "verif concept answer": "blender(0.7203)", "verif image answer": "stove(0.5369)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487796.jpg"}, {"question": "don't run with these in your hands", "gt answer": "scissor(1.00)", "pred answer": "woman", "question_id": 3050145, "best approach": "wiki, concept", "verif answer": "scissor", "anno approach": "wiki", "verif wiki answer": "scissor(0.7265)", "verif concept answer": "scissor(0.7298)", "verif image answer": "hurt(0.7039)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305014.jpg"}, {"question": "what are those for", "gt answer": "knit(1.00)<br/>crochet(1.00)", "pred answer": "work", "question_id": 5702155, "best approach": "wiki, concept, image", "verif answer": "knit", "anno approach": "image, concept, wiki", "verif wiki answer": "knit(0.6452)", "verif concept answer": "knit(0.6787)", "verif image answer": "knit(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570215.jpg"}, {"question": "which country does this type of parking meter appear", "gt answer": "usa(1.00)<br/>canada(0.60)<br/>united state(0.60)", "pred answer": "england", "question_id": 1501515, "best approach": "wiki, concept, image", "verif answer": "canada", "anno approach": "image, wiki", "verif wiki answer": "canada(0.6704)", "verif concept answer": "canada(0.6765)", "verif image answer": "canada(0.7078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000150151.jpg"}, {"question": "what is the horse doing", "gt answer": "stand(1.00)<br/>wait(0.60)", "pred answer": "plow", "question_id": 115195, "best approach": "", "verif answer": "plow", "anno approach": "", "verif wiki answer": "plow(0.7091)", "verif concept answer": "plow(0.7241)", "verif image answer": "plow(0.6561)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011519.jpg"}, {"question": "what 's he jumping", "gt answer": "road block(1.00)", "pred answer": "skateboard", "question_id": 3106745, "best approach": "", "verif answer": "skateboard", "anno approach": "", "verif wiki answer": "skateboard(0.6434)", "verif concept answer": "ollie(0.6749)", "verif image answer": "skateboard(0.7168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310674.jpg"}, {"question": "what kind of plants are in this terrarium", "gt answer": "moss(1.00)<br/>fern(0.60)<br/>cactus(0.60)<br/>succulent(0.60)", "pred answer": "hydrangea", "question_id": 2036925, "best approach": "wiki, concept, image", "verif answer": "succulent", "anno approach": "concept, wiki", "verif wiki answer": "cactus(0.6411)", "verif concept answer": "succulent(0.6767)", "verif image answer": "succulent(0.6518)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203692.jpg"}, {"question": "where do these fryut grow", "gt answer": "tree(1.00)<br/>africa(0.60)<br/>tropic(0.60)", "pred answer": "tree", "question_id": 3078575, "best approach": "wiki", "verif answer": "south america", "anno approach": "wiki", "verif wiki answer": "africa(0.6222)", "verif concept answer": "florida(0.6660)", "verif image answer": "south america(0.7262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307857.jpg"}, {"question": "what model of refrigerator is seen here", "gt answer": "kenmore(1.00)<br/>frigidaire(0.60)<br/>ge(0.60)", "pred answer": "ge", "question_id": 4356325, "best approach": "", "verif answer": "lg", "anno approach": "", "verif wiki answer": "lg(0.7073)", "verif concept answer": "lg(0.7195)", "verif image answer": "lg(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435632.jpg"}, {"question": "what city is that", "gt answer": "tokyo(1.00)<br/>beijing(0.60)", "pred answer": "san francisco", "question_id": 1713395, "best approach": "wiki, concept, image", "verif answer": "beijing", "anno approach": "wiki", "verif wiki answer": "beijing(0.6942)", "verif concept answer": "beijing(0.6668)", "verif image answer": "beijing(0.6976)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171339.jpg"}, {"question": "how many years in total is most likely represented by the candles", "gt answer": "51(1.00)<br/>80(0.60)", "pred answer": "15", "question_id": 1394945, "best approach": "image", "verif answer": "80", "anno approach": "image", "verif wiki answer": "3 feet(0.6529)", "verif concept answer": "35(0.6296)", "verif image answer": "80(0.6529)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139494.jpg"}, {"question": "who painted the mural on the side of this bus", "gt answer": "artist(1.00)<br/>banksy(0.60)", "pred answer": "graffiti", "question_id": 2359765, "best approach": "wiki, concept, image", "verif answer": "banksy", "anno approach": "concept, wiki", "verif wiki answer": "banksy(0.5862)", "verif concept answer": "banksy(0.6125)", "verif image answer": "banksy(0.5124)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000235976.jpg"}, {"question": "this type of chair is also what type of musician", "gt answer": "rock(1.00)", "pred answer": "modern", "question_id": 3626435, "best approach": "", "verif answer": "stone", "anno approach": "", "verif wiki answer": "stone(0.6059)", "verif concept answer": "stone(0.6554)", "verif image answer": "wood(0.6395)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362643.jpg"}, {"question": "what are these brushes used for", "gt answer": "brush teeth(1.00)<br/>teeth(1.00)<br/>clean teeth(0.60)", "pred answer": "brush teeth", "question_id": 2493485, "best approach": "", "verif answer": "toothbrush", "anno approach": "", "verif wiki answer": "toothbrush(0.5272)", "verif concept answer": "toothbrush(0.7106)", "verif image answer": "toothbrush(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249348.jpg"}, {"question": "what brand of tennis racket is this", "gt answer": "wilson(1.00)", "pred answer": "prince", "question_id": 381235, "best approach": "wiki", "verif answer": "louisville slugger", "anno approach": "wiki", "verif wiki answer": "wilson(0.5265)", "verif concept answer": "louisville slugger(0.5391)", "verif image answer": "louisville slugger(0.6427)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038123.jpg"}, {"question": "where is this", "gt answer": "desert(1.00)<br/>beach(0.60)", "pred answer": "desert", "question_id": 1558455, "best approach": "", "verif answer": "saudi arabia", "anno approach": "", "verif wiki answer": "saudi arabia(0.7294)", "verif concept answer": "saudi arabia(0.7295)", "verif image answer": "saudi arabia(0.7064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155845.jpg"}, {"question": "what is the name of the law this driver is breaking", "gt answer": "distracted drive(1.00)<br/>phone(0.60)", "pred answer": "phone", "question_id": 5295805, "best approach": "", "verif answer": "cellphone", "anno approach": "", "verif wiki answer": "cell phone(0.7296)", "verif concept answer": "cell phone(0.7292)", "verif image answer": "cellphone(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529580.jpg"}, {"question": "what time is it in this photo", "gt answer": "6:50(1.00)", "pred answer": "afternoon", "question_id": 136035, "best approach": "", "verif answer": "5:37", "anno approach": "", "verif wiki answer": "5:37(0.7308)", "verif concept answer": "5:37(0.7309)", "verif image answer": "5:37(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013603.jpg"}, {"question": "what does those green cluster behind him inhale", "gt answer": "oxygen(1.00)<br/>tree(0.60)", "pred answer": "fence", "question_id": 314435, "best approach": "wiki, concept", "verif answer": "photosynthesis", "anno approach": "wiki", "verif wiki answer": "tree(0.6505)", "verif concept answer": "tree(0.6384)", "verif image answer": "photosynthesis(0.7019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000031443.jpg"}, {"question": "which direction is the skier headed", "gt answer": "down(1.00)<br/>downhill(0.60)<br/>south(0.60)<br/>north(0.60)", "pred answer": "north", "question_id": 1794805, "best approach": "wiki, concept, image", "verif answer": "north", "anno approach": "image, wiki", "verif wiki answer": "north(0.7203)", "verif concept answer": "north(0.5851)", "verif image answer": "north(0.6953)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000179480.jpg"}, {"question": "where is this", "gt answer": "florida(1.00)<br/>london(0.60)<br/>pennsylvania(0.60)<br/>new york(0.60)", "pred answer": "field", "question_id": 5050465, "best approach": "wiki, concept, image", "verif answer": "new york", "anno approach": "wiki", "verif wiki answer": "new york(0.6861)", "verif concept answer": "new york(0.6909)", "verif image answer": "new york(0.7133)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505046.jpg"}, {"question": "why are fire hydrants yellow", "gt answer": "visibility(1.00)", "pred answer": "caution", "question_id": 920985, "best approach": "image", "verif answer": "visibility", "anno approach": "image", "verif wiki answer": "art(0.6324)", "verif concept answer": "to be seen(0.6035)", "verif image answer": "visibility(0.6821)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092098.jpg"}, {"question": "what type of seafood do you see in the picture", "gt answer": "shrimp(1.00)", "pred answer": "vegetable", "question_id": 5077695, "best approach": "wiki, concept", "verif answer": "crab", "anno approach": "", "verif wiki answer": "shrimp(0.5444)", "verif concept answer": "shrimp(0.5571)", "verif image answer": "crab(0.6131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507769.jpg"}, {"question": "what flag is on the bike", "gt answer": "british(1.00)<br/>britain(0.60)", "pred answer": "china", "question_id": 1985475, "best approach": "image", "verif answer": "british", "anno approach": "image", "verif wiki answer": "england(0.6552)", "verif concept answer": "england(0.6876)", "verif image answer": "british(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198547.jpg"}, {"question": "what is the bird", "gt answer": "vulture(1.00)<br/>pelican(0.60)<br/>crow(0.60)<br/>egret(0.60)", "pred answer": "vulture", "question_id": 3189246, "best approach": "wiki, concept, image", "verif answer": "vulture", "anno approach": "wiki", "verif wiki answer": "vulture(0.7286)", "verif concept answer": "vulture(0.7291)", "verif image answer": "vulture(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318924.jpg"}, {"question": "what kind of phone is on the table", "gt answer": "cell(1.00)<br/>iphone(0.60)", "pred answer": "iphone", "question_id": 2241645, "best approach": "", "verif answer": "smartphone", "anno approach": "", "verif wiki answer": "smartphone(0.6035)", "verif concept answer": "smartphone(0.6162)", "verif image answer": "blackberry(0.5356)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224164.jpg"}, {"question": "what is missing from this man 's body", "gt answer": "shirt(1.00)<br/>hair(0.60)", "pred answer": "arm", "question_id": 2694905, "best approach": "image", "verif answer": "elbow pad", "anno approach": "image", "verif wiki answer": "elbow pad(0.6281)", "verif concept answer": "elbow pad(0.5225)", "verif image answer": "hair(0.6165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269490.jpg"}, {"question": "what airline is this", "gt answer": "lufthansa(1.00)", "pred answer": "delta", "question_id": 4507635, "best approach": "", "verif answer": "delta", "anno approach": "", "verif wiki answer": "delta(0.7291)", "verif concept answer": "delta(0.7244)", "verif image answer": "delta(0.6876)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450763.jpg"}, {"question": "", "gt answer": "1920's(0.60)<br/>1980(0.60)", "pred answer": "60s", "question_id": 4905185, "best approach": "wiki, concept, image", "verif answer": "1980", "anno approach": "wiki", "verif wiki answer": "1980(0.6456)", "verif concept answer": "1980(0.6422)", "verif image answer": "1980(0.6140)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490518.jpg"}, {"question": "what is this type of hat called", "gt answer": "cowboy(1.00)<br/>fedora(0.60)", "pred answer": "fedora", "question_id": 639595, "best approach": "wiki, concept, image", "verif answer": "fedora", "anno approach": "wiki", "verif wiki answer": "fedora(0.7307)", "verif concept answer": "fedora(0.7310)", "verif image answer": "fedora(0.6968)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063959.jpg"}, {"question": "what is he floor made out of", "gt answer": "tile(1.00)<br/>ceramic(0.60)", "pred answer": "tile", "question_id": 892325, "best approach": "wiki, concept, image", "verif answer": "tile", "anno approach": "concept, wiki", "verif wiki answer": "tile(0.6754)", "verif concept answer": "tile(0.6924)", "verif image answer": "tile(0.6192)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089232.jpg"}, {"question": "what sort of wares is the merchant selling", "gt answer": "fruit(1.00)<br/>vegetable(1.00)<br/>live(0.60)", "pred answer": "bread", "question_id": 2741305, "best approach": "wiki, concept, image", "verif answer": "fruit", "anno approach": "wiki", "verif wiki answer": "fruit(0.6866)", "verif concept answer": "fruit(0.6792)", "verif image answer": "fruit(0.6872)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274130.jpg"}, {"question": "what country is this in", "gt answer": "us(1.00)<br/>usa(0.60)<br/>asia(0.60)<br/>america(0.60)", "pred answer": "china", "question_id": 4653535, "best approach": "wiki, concept", "verif answer": "china", "anno approach": "wiki", "verif wiki answer": "america(0.6631)", "verif concept answer": "america(0.6699)", "verif image answer": "china(0.6742)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465353.jpg"}, {"question": "is this a government or private function", "gt answer": "government(1.00)<br/>private(1.00)", "pred answer": "public", "question_id": 355325, "best approach": "", "verif answer": "public", "anno approach": "", "verif wiki answer": "public(0.7310)", "verif concept answer": "public(0.7310)", "verif image answer": "public(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000035532.jpg"}, {"question": "what season would this take place in", "gt answer": "summer(1.00)", "pred answer": "summer", "question_id": 3992275, "best approach": "wiki, concept", "verif answer": "spring", "anno approach": "wiki", "verif wiki answer": "summer(0.7197)", "verif concept answer": "summer(0.7270)", "verif image answer": "spring(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399227.jpg"}, {"question": "if you had to guess the color of the skin of the woman would you say pinkish or blue", "gt answer": "pinkish(1.00)", "pred answer": "black and white", "question_id": 452765, "best approach": "", "verif answer": "cat", "anno approach": "", "verif wiki answer": "cat(0.5222)", "verif concept answer": "cat(0.5241)", "verif image answer": "cat(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045276.jpg"}, {"question": "which player of this sport has a bird last name", "gt answer": "tony hawk(1.00)<br/>hawk(1.00)", "pred answer": "tony hawk", "question_id": 3229345, "best approach": "wiki, concept, image", "verif answer": "tony hawk", "anno approach": "wiki", "verif wiki answer": "tony hawk(0.7310)", "verif concept answer": "tony hawk(0.7310)", "verif image answer": "tony hawk(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322934.jpg"}, {"question": "what attire is this", "gt answer": "tuxedo(1.00)<br/>formal(0.60)", "pred answer": "suit", "question_id": 3788465, "best approach": "", "verif answer": "suit", "anno approach": "", "verif wiki answer": "suit(0.7043)", "verif concept answer": "suit(0.7220)", "verif image answer": "suit(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378846.jpg"}, {"question": "what pattern is on the bench", "gt answer": "heart(1.00)<br/>stone(0.60)", "pred answer": "floral", "question_id": 4503145, "best approach": "wiki, concept", "verif answer": "stone", "anno approach": "wiki", "verif wiki answer": "stone(0.5753)", "verif concept answer": "stone(0.5817)", "verif image answer": "brick(0.5745)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450314.jpg"}, {"question": "what team do they play for", "gt answer": "red sox(1.00)", "pred answer": "nation", "question_id": 1341005, "best approach": "wiki, concept, image", "verif answer": "red sox", "anno approach": "concept, wiki", "verif wiki answer": "red sox(0.7091)", "verif concept answer": "red sox(0.7138)", "verif image answer": "red sox(0.6715)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134100.jpg"}, {"question": "where are these mountains located", "gt answer": "colorado(1.00)<br/>alaska(1.00)<br/>west(0.60)", "pred answer": "mountain", "question_id": 3889605, "best approach": "wiki, concept", "verif answer": "west", "anno approach": "wiki", "verif wiki answer": "west(0.6391)", "verif concept answer": "west(0.6307)", "verif image answer": "alp(0.5927)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388960.jpg"}, {"question": "what musical instrument is this man playing", "gt answer": "guitar(1.00)", "pred answer": "guitar", "question_id": 3907925, "best approach": "wiki, concept, image", "verif answer": "guitar", "anno approach": "wiki", "verif wiki answer": "guitar(0.7294)", "verif concept answer": "guitar(0.7307)", "verif image answer": "guitar(0.7177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390792.jpg"}, {"question": "which item is associated with ireland", "gt answer": "alcohol(1.00)<br/>food(0.60)<br/>potato(1.00)", "pred answer": "potato", "question_id": 4282085, "best approach": "wiki, concept, image", "verif answer": "potato", "anno approach": "image, concept, wiki", "verif wiki answer": "potato(0.5268)", "verif concept answer": "potato(0.6257)", "verif image answer": "potato(0.6347)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428208.jpg"}, {"question": "what are these sheep doing", "gt answer": "graze(1.00)<br/>herd(0.60)<br/>eat(0.60)", "pred answer": "graze", "question_id": 642835, "best approach": "concept, image", "verif answer": "graze", "anno approach": "", "verif wiki answer": "walk(0.7131)", "verif concept answer": "graze(0.7202)", "verif image answer": "graze(0.7169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064283.jpg"}, {"question": "what type of neckline is the yellow shirt", "gt answer": "scoop(1.00)<br/>low(0.60)", "pred answer": "button up", "question_id": 5200395, "best approach": "", "verif answer": "120v", "anno approach": "", "verif wiki answer": "120v(0.7037)", "verif concept answer": "120v(0.6610)", "verif image answer": "120v(0.6791)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520039.jpg"}, {"question": "who 's the image on the tie", "gt answer": "bill clinton(1.00)<br/>van gogh(0.60)<br/>clinton(0.60)", "pred answer": "woman", "question_id": 2346375, "best approach": "", "verif answer": "samuel fox", "anno approach": "", "verif wiki answer": "samuel fox(0.7225)", "verif concept answer": "samuel fox(0.7137)", "verif image answer": "samuel fox(0.6995)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000234637.jpg"}, {"question": "what 's in the white bag on the left", "gt answer": "flour(1.00)", "pred answer": "coke", "question_id": 395485, "best approach": "", "verif answer": "sugar", "anno approach": "", "verif wiki answer": "sugar(0.7298)", "verif concept answer": "sugar(0.7206)", "verif image answer": "sugar(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039548.jpg"}, {"question": "what are of the store was this picture taken", "gt answer": "pharmacy(1.00)<br/>convenience store(0.60)<br/>toothbrush(0.60)", "pred answer": "walmart", "question_id": 885145, "best approach": "wiki, concept, image", "verif answer": "toothbrush", "anno approach": "image, wiki", "verif wiki answer": "toothbrush(0.7102)", "verif concept answer": "toothbrush(0.6846)", "verif image answer": "toothbrush(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088514.jpg"}, {"question": "where could someone sit", "gt answer": "bench(1.00)<br/>table(1.00)", "pred answer": "bench", "question_id": 2604485, "best approach": "wiki", "verif answer": "bench", "anno approach": "wiki", "verif wiki answer": "bench(0.7176)", "verif concept answer": "on table(0.6520)", "verif image answer": "on table(0.6900)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260448.jpg"}, {"question": "what type of stone was used in the building", "gt answer": "limestone(1.00)<br/>cobblestone(0.60)<br/>concrete(0.60)", "pred answer": "limestone", "question_id": 2466395, "best approach": "concept", "verif answer": "concrete", "anno approach": "concept", "verif wiki answer": "brick(0.6391)", "verif concept answer": "limestone(0.6588)", "verif image answer": "concrete(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246639.jpg"}, {"question": "a typical recipe yields how many of the items shown above", "gt answer": "12(1.00)<br/>10(0.60)", "pred answer": "6", "question_id": 2187175, "best approach": "wiki, concept", "verif answer": "12", "anno approach": "wiki", "verif wiki answer": "12(0.5471)", "verif concept answer": "12(0.5433)", "verif image answer": "5(0.5169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218717.jpg"}, {"question": "who makes these trucks", "gt answer": "volkswagen(1.00)", "pred answer": "ford", "question_id": 2325515, "best approach": "", "verif answer": "vw", "anno approach": "", "verif wiki answer": "vw(0.6854)", "verif concept answer": "vw(0.6964)", "verif image answer": "vw(0.7184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232551.jpg"}, {"question": "how many of this type of animal typically live together", "gt answer": "6(1.00)<br/>40(0.60)<br/>8(0.60)", "pred answer": "million", "question_id": 4315695, "best approach": "", "verif answer": "thousand", "anno approach": "", "verif wiki answer": "thousand(0.6853)", "verif concept answer": "thousand(0.7149)", "verif image answer": "thousand(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431569.jpg"}, {"question": "where are these people", "gt answer": "library(1.00)<br/>student(0.60)", "pred answer": "office", "question_id": 3315445, "best approach": "image", "verif answer": "bookstore", "anno approach": "image", "verif wiki answer": "bookstore(0.7294)", "verif concept answer": "bookstore(0.7303)", "verif image answer": "library(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331544.jpg"}, {"question": "who is going faster", "gt answer": "scooter(1.00)<br/>bike(0.60)", "pred answer": "horse", "question_id": 3728045, "best approach": "wiki, concept, image", "verif answer": "scooter", "anno approach": "image, wiki", "verif wiki answer": "scooter(0.6816)", "verif concept answer": "scooter(0.7152)", "verif image answer": "scooter(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372804.jpg"}, {"question": "what kind of pampering is this", "gt answer": "haircut(1.00)", "pred answer": "silver", "question_id": 2340885, "best approach": "", "verif answer": "toothbrush", "anno approach": "", "verif wiki answer": "toothbrush(0.7306)", "verif concept answer": "clean teeth(0.7287)", "verif image answer": "toothbrush(0.6953)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000234088.jpg"}, {"question": "what size bed is this", "gt answer": "king(1.00)<br/>queen(1.00)", "pred answer": "full", "question_id": 5813515, "best approach": "wiki, concept, image", "verif answer": "queen", "anno approach": "wiki", "verif wiki answer": "queen(0.7307)", "verif concept answer": "queen(0.7294)", "verif image answer": "queen(0.7204)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000581351.jpg"}, {"question": "what is the vitamin that can be got in the upper fruit", "gt answer": "vitamin c(1.00)<br/>(0.60)<br/>c(0.60)", "pred answer": "c", "question_id": 1050665, "best approach": "wiki, concept", "verif answer": "d", "anno approach": "concept, wiki", "verif wiki answer": "c(0.5334)", "verif concept answer": "c(0.5829)", "verif image answer": "d(0.5836)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105066.jpg"}, {"question": "what holiday do we use this for", "gt answer": "christmas(1.00)", "pred answer": "christmas", "question_id": 3965485, "best approach": "wiki, concept, image", "verif answer": "christmas", "anno approach": "image, concept, wiki", "verif wiki answer": "christmas(0.6306)", "verif concept answer": "christmas(0.7015)", "verif image answer": "christmas(0.7239)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396548.jpg"}, {"question": "what are the bananas hanging on", "gt answer": "hook(1.00)", "pred answer": "trailer", "question_id": 3896155, "best approach": "", "verif answer": "street", "anno approach": "", "verif wiki answer": "street(0.7004)", "verif concept answer": "street(0.7000)", "verif image answer": "street(0.5017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389615.jpg"}, {"question": "what do these birds produce", "gt answer": "egg(1.00)", "pred answer": "fish", "question_id": 3166995, "best approach": "image", "verif answer": "chicken", "anno approach": "image", "verif wiki answer": "chicken(0.6635)", "verif concept answer": "chicken(0.6045)", "verif image answer": "egg(0.6618)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316699.jpg"}, {"question": "which age group of childrens love to play with this toy", "gt answer": "toddler(1.00)<br/>3 years(0.60)", "pred answer": "baby", "question_id": 3228075, "best approach": "wiki, concept, image", "verif answer": "toddler", "anno approach": "wiki", "verif wiki answer": "toddler(0.6779)", "verif concept answer": "toddler(0.6985)", "verif image answer": "toddler(0.6718)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322807.jpg"}, {"question": "what two animals are pictured", "gt answer": "giraffe and ostrich(1.00)", "pred answer": "giraffe", "question_id": 4335685, "best approach": "wiki, concept, image", "verif answer": "giraffe and ostrich", "anno approach": "", "verif wiki answer": "giraffe and ostrich(0.7307)", "verif concept answer": "giraffe and ostrich(0.7300)", "verif image answer": "giraffe and ostrich(0.7202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433568.jpg"}, {"question": "how many compartments are in this picture", "gt answer": "8(1.00)", "pred answer": "15", "question_id": 2366295, "best approach": "", "verif answer": "12", "anno approach": "", "verif wiki answer": "12(0.7245)", "verif concept answer": "12(0.7039)", "verif image answer": "12(0.7164)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236629.jpg"}, {"question": "in france what would this food be called", "gt answer": "gateau(1.00)<br/>dessert(0.60)", "pred answer": "cake", "question_id": 1256395, "best approach": "wiki, concept, image", "verif answer": "gateau", "anno approach": "", "verif wiki answer": "gateau(0.6660)", "verif concept answer": "gateau(0.6908)", "verif image answer": "gateau(0.6656)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125639.jpg"}, {"question": "what type of place is this", "gt answer": "farm(1.00)<br/>field(1.00)", "pred answer": "field", "question_id": 673555, "best approach": "wiki, concept", "verif answer": "farm", "anno approach": "wiki", "verif wiki answer": "farm(0.6672)", "verif concept answer": "farm(0.6585)", "verif image answer": "desert(0.6499)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067355.jpg"}, {"question": "what is the cage where the other players are sitting behind called", "gt answer": "dugout(1.00)<br/>bat(0.60)", "pred answer": "bleacher", "question_id": 4244045, "best approach": "", "verif answer": "ballpark", "anno approach": "", "verif wiki answer": "ballpark(0.7113)", "verif concept answer": "ballpark(0.7217)", "verif image answer": "ballpark(0.7196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424404.jpg"}, {"question": "what is this item designed to carry", "gt answer": "people(1.00)<br/>passenger(0.60)", "pred answer": "passenger", "question_id": 802835, "best approach": "wiki, concept, image", "verif answer": "passenger", "anno approach": "wiki", "verif wiki answer": "passenger(0.7180)", "verif concept answer": "passenger(0.7068)", "verif image answer": "passenger(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080283.jpg"}, {"question": "what is the name of the aeroline", "gt answer": "airbus(1.00)<br/>4300(0.60)", "pred answer": "boeing", "question_id": 2742485, "best approach": "wiki, concept", "verif answer": "4300", "anno approach": "wiki", "verif wiki answer": "airbus(0.5981)", "verif concept answer": "airbus(0.5585)", "verif image answer": "4300(0.7001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274248.jpg"}, {"question": "what kind of bike is depicted here", "gt answer": "motorcycle(1.00)<br/>chopper(0.60)<br/>motorbike(0.60)", "pred answer": "motorcycle", "question_id": 3732125, "best approach": "concept, image", "verif answer": "motorcycle", "anno approach": "image", "verif wiki answer": "harley(0.6208)", "verif concept answer": "motorcycle(0.6194)", "verif image answer": "motorcycle(0.6977)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373212.jpg"}, {"question": "what type of flowers are in the white vase", "gt answer": "rose(1.00)<br/>orchid(0.60)<br/>tulip(0.60)<br/>daisy(0.60)", "pred answer": "rose", "question_id": 5048005, "best approach": "wiki, concept, image", "verif answer": "rose", "anno approach": "wiki", "verif wiki answer": "rose(0.7178)", "verif concept answer": "rose(0.7235)", "verif image answer": "rose(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000504800.jpg"}, {"question": "what is this vehicle driving on", "gt answer": "rail(1.00)<br/>track(1.00)", "pred answer": "track", "question_id": 4922865, "best approach": "wiki, concept, image", "verif answer": "track", "anno approach": "image, wiki", "verif wiki answer": "rail(0.6837)", "verif concept answer": "rail(0.7173)", "verif image answer": "track(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492286.jpg"}, {"question": "what do couples use the top layer of this for traditionally", "gt answer": "anniversary(1.00)", "pred answer": "married", "question_id": 3455785, "best approach": "", "verif answer": "christmas", "anno approach": "", "verif wiki answer": "christmas(0.5060)", "verif concept answer": "christmas(0.5007)", "verif image answer": "christmas(0.5027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345578.jpg"}, {"question": "in what disney film is the everyday accessory seen in the photo used to help her character fly", "gt answer": "mary poppins(1.00)", "pred answer": "mary poppins", "question_id": 2319875, "best approach": "wiki, image", "verif answer": "mary poppins", "anno approach": "image, wiki", "verif wiki answer": "mary poppins(0.5191)", "verif concept answer": "air force 1(0.5252)", "verif image answer": "mary poppins(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231987.jpg"}, {"question": "what is the temperature like", "gt answer": "cool(1.00)<br/>cold(0.60)<br/>warm(0.60)", "pred answer": "cool", "question_id": 2130365, "best approach": "wiki, concept, image", "verif answer": "cool", "anno approach": "wiki", "verif wiki answer": "cool(0.7016)", "verif concept answer": "cool(0.6495)", "verif image answer": "cool(0.6597)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000213036.jpg"}, {"question": "what religious group uses this mode of transportation", "gt answer": "amish(1.00)", "pred answer": "catholic", "question_id": 2221805, "best approach": "", "verif answer": "catholic", "anno approach": "", "verif wiki answer": "catholic(0.7202)", "verif concept answer": "catholic(0.7234)", "verif image answer": "catholic(0.6842)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222180.jpg"}, {"question": "what type of topping is on top of the orange balls", "gt answer": "coconut(1.00)", "pred answer": "fondant", "question_id": 36715, "best approach": "", "verif answer": "sugar", "anno approach": "", "verif wiki answer": "pine(0.6048)", "verif concept answer": "pine(0.6133)", "verif image answer": "sugar(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003671.jpg"}, {"question": "what type of tree is the tallest in the picture", "gt answer": "palm tree(1.00)<br/>mahogany(0.60)<br/>palm(0.60)", "pred answer": "palm", "question_id": 2554185, "best approach": "image", "verif answer": "passenger", "anno approach": "image", "verif wiki answer": "passenger(0.7275)", "verif concept answer": "passenger(0.7285)", "verif image answer": "palm(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255418.jpg"}, {"question": "what are the yellow flowers in this photo called", "gt answer": "daffodil(1.00)<br/>marigold(0.60)<br/>daisy(0.60)", "pred answer": "fern", "question_id": 4079055, "best approach": "wiki, concept, image", "verif answer": "marigold", "anno approach": "", "verif wiki answer": "marigold(0.7305)", "verif concept answer": "marigold(0.7306)", "verif image answer": "marigold(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407905.jpg"}, {"question": "what type of gasoline does this vehicle use", "gt answer": "unleaded(1.00)<br/>diesel(0.60)<br/>regular(0.60)", "pred answer": "diesel", "question_id": 1393895, "best approach": "", "verif answer": "pickup", "anno approach": "", "verif wiki answer": "gasoline(0.7027)", "verif concept answer": "gasoline(0.6789)", "verif image answer": "pickup(0.7122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139389.jpg"}, {"question": "why will the people probably not get sunburned", "gt answer": "it rain(1.00)<br/>rain(0.60)", "pred answer": "umbrella", "question_id": 57565, "best approach": "", "verif answer": "umbrella", "anno approach": "", "verif wiki answer": "sunny(0.5162)", "verif concept answer": "umbrella(0.5701)", "verif image answer": "umbrella(0.6187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005756.jpg"}, {"question": "what is the name of the flotation device this man is holding", "gt answer": "boogie board(1.00)<br/>board(0.60)", "pred answer": "surfboard", "question_id": 1075275, "best approach": "", "verif answer": "surf", "anno approach": "", "verif wiki answer": "surf(0.6917)", "verif concept answer": "surf(0.7077)", "verif image answer": "water(0.5813)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000107527.jpg"}, {"question": "is the animal on the beach male or female", "gt answer": "male(1.00)<br/>female(1.00)", "pred answer": "male", "question_id": 849565, "best approach": "wiki, concept, image", "verif answer": "male", "anno approach": "wiki", "verif wiki answer": "male(0.7310)", "verif concept answer": "male(0.7308)", "verif image answer": "male(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084956.jpg"}, {"question": "is this plane landing or taking off", "gt answer": "take off(1.00)", "pred answer": "take off", "question_id": 3801635, "best approach": "", "verif answer": "land", "anno approach": "", "verif wiki answer": "land(0.7152)", "verif concept answer": "land(0.7266)", "verif image answer": "land(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000380163.jpg"}, {"question": "what is this trick called", "gt answer": "olly(1.00)<br/>skateboard(0.60)<br/>ollie(0.60)", "pred answer": "kickflip", "question_id": 4588275, "best approach": "image", "verif answer": "skateboard", "anno approach": "image", "verif wiki answer": "half pipe(0.6659)", "verif concept answer": "half pipe(0.6511)", "verif image answer": "skateboard(0.6816)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458827.jpg"}, {"question": "what could you enter through", "gt answer": "door(1.00)", "pred answer": "window", "question_id": 1112805, "best approach": "image", "verif answer": "window", "anno approach": "image", "verif wiki answer": "window(0.7300)", "verif concept answer": "window(0.6143)", "verif image answer": "door(0.7189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111280.jpg"}, {"question": "what breed of dog is this", "gt answer": "collie(1.00)<br/>border collie(0.60)<br/>retriever(0.60)<br/>mixed(0.60)", "pred answer": "collie", "question_id": 5454285, "best approach": "wiki, concept, image", "verif answer": "border collie", "anno approach": "wiki", "verif wiki answer": "border collie(0.7283)", "verif concept answer": "border collie(0.7282)", "verif image answer": "border collie(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545428.jpg"}, {"question": "what kind of oil is typically found in the orange food depicted", "gt answer": "fish(1.00)<br/>omega 3(1.00)", "pred answer": "vegetable", "question_id": 4089465, "best approach": "", "verif answer": "salmon", "anno approach": "", "verif wiki answer": "salmon(0.6568)", "verif concept answer": "salmon(0.6998)", "verif image answer": "salmon(0.6752)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408946.jpg"}, {"question": "what speed should the ceiling fan run in this room", "gt answer": "slow(1.00)<br/>low(0.60)", "pred answer": "300 mph", "question_id": 4365195, "best approach": "", "verif answer": "25 mph", "anno approach": "", "verif wiki answer": "25 mph(0.5943)", "verif concept answer": "25 mph(0.6399)", "verif image answer": "25 mph(0.6451)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436519.jpg"}, {"question": "what country will you find this market", "gt answer": "brazil(1.00)<br/>thailand(0.60)<br/>nigeria(0.60)", "pred answer": "vietnam", "question_id": 452305, "best approach": "wiki, concept, image", "verif answer": "thailand", "anno approach": "wiki", "verif wiki answer": "thailand(0.6884)", "verif concept answer": "thailand(0.6801)", "verif image answer": "thailand(0.6579)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045230.jpg"}, {"question": "what type of grass is best for their growth", "gt answer": "green grass(1.00)<br/>bent(0.60)<br/>hay(0.60)<br/>green(0.60)", "pred answer": "fern", "question_id": 2735485, "best approach": "wiki, concept, image", "verif answer": "hay", "anno approach": "image", "verif wiki answer": "bent(0.5628)", "verif concept answer": "bent(0.5593)", "verif image answer": "hay(0.6228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273548.jpg"}, {"question": "was the white pot hand made or factory made", "gt answer": "handmade(1.00)<br/>hand(0.60)<br/>factory(0.60)", "pred answer": "pottery", "question_id": 2446665, "best approach": "", "verif answer": "manmade", "anno approach": "", "verif wiki answer": "home(0.5062)", "verif concept answer": "home(0.5135)", "verif image answer": "manmade(0.5469)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244666.jpg"}, {"question": "what is this event", "gt answer": "lecture(1.00)<br/>snow(0.60)", "pred answer": "work", "question_id": 5059495, "best approach": "", "verif answer": "ski lift", "anno approach": "", "verif wiki answer": "ski lift(0.7243)", "verif concept answer": "ski lift(0.7306)", "verif image answer": "ski lift(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505949.jpg"}, {"question": "can you name a sport this person could be a part of", "gt answer": "race(1.00)<br/>motocross(0.60)<br/>dirt bike(0.60)", "pred answer": "motorcross", "question_id": 1537305, "best approach": "wiki, concept", "verif answer": "motorcross", "anno approach": "concept, wiki", "verif wiki answer": "race(0.6190)", "verif concept answer": "race(0.6575)", "verif image answer": "motorcross(0.6779)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153730.jpg"}, {"question": "which breed of dog is still the most popular", "gt answer": "labrador(1.00)<br/>golden retriever(0.60)", "pred answer": "beagle", "question_id": 3052475, "best approach": "wiki, concept", "verif answer": "retriever", "anno approach": "wiki", "verif wiki answer": "golden retriever(0.6261)", "verif concept answer": "golden retriever(0.6223)", "verif image answer": "retriever(0.7098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305247.jpg"}, {"question": "what breed of bovine is this", "gt answer": "ox(1.00)<br/>cow(0.60)<br/>angus(0.60)", "pred answer": "cow", "question_id": 1347475, "best approach": "concept", "verif answer": "jersey", "anno approach": "concept", "verif wiki answer": "jersey(0.7142)", "verif concept answer": "angus(0.7065)", "verif image answer": "jersey(0.7147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134747.jpg"}, {"question": "who is the manufactuer of the black keyboard in front of the three monitos", "gt answer": "logitech(1.00)<br/>acer(0.60)<br/>hp(0.60)<br/>samsung(0.60)", "pred answer": "steve job", "question_id": 1362305, "best approach": "wiki, concept, image", "verif answer": "acer", "anno approach": "", "verif wiki answer": "acer(0.5053)", "verif concept answer": "acer(0.5006)", "verif image answer": "acer(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136230.jpg"}, {"question": "is this photo under or over exposed", "gt answer": "under(1.00)", "pred answer": "above", "question_id": 1082015, "best approach": "wiki, concept", "verif answer": "play", "anno approach": "wiki", "verif wiki answer": "under(0.5161)", "verif concept answer": "under(0.5040)", "verif image answer": "play(0.5814)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108201.jpg"}, {"question": "what does the yellow street sign mean", "gt answer": "pedestrian cross(1.00)<br/>crosswalk(0.60)<br/>pedestrian(0.60)", "pred answer": "caution", "question_id": 2854935, "best approach": "concept", "verif answer": "caution", "anno approach": "concept", "verif wiki answer": "caution(0.6955)", "verif concept answer": "pedestrian cross(0.6954)", "verif image answer": "caution(0.6812)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285493.jpg"}, {"question": "what animal might attack while surfing", "gt answer": "shark(1.00)", "pred answer": "shark", "question_id": 1809355, "best approach": "wiki, concept, image", "verif answer": "shark", "anno approach": "concept, wiki", "verif wiki answer": "shark(0.7310)", "verif concept answer": "shark(0.7307)", "verif image answer": "shark(0.6912)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180935.jpg"}, {"question": "where are these signs typically found", "gt answer": "school(1.00)", "pred answer": "park", "question_id": 4283795, "best approach": "", "verif answer": "cafeteria", "anno approach": "", "verif wiki answer": "home(0.7301)", "verif concept answer": "cafeteria(0.7104)", "verif image answer": "cafeteria(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428379.jpg"}, {"question": "what was the use of the device beside the food", "gt answer": "tablet(1.00)", "pred answer": "trash", "question_id": 4676745, "best approach": "wiki, concept, image", "verif answer": "tablet", "anno approach": "concept, wiki", "verif wiki answer": "tablet(0.7306)", "verif concept answer": "tablet(0.7301)", "verif image answer": "tablet(0.6748)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467674.jpg"}, {"question": "what company makes this type of appliance", "gt answer": "frigidaire(1.00)<br/>samsung(0.60)<br/>ge(0.60)", "pred answer": "refrigerator", "question_id": 3130615, "best approach": "wiki, concept, image", "verif answer": "samsung", "anno approach": "image, wiki", "verif wiki answer": "samsung(0.6490)", "verif concept answer": "samsung(0.5885)", "verif image answer": "samsung(0.6640)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313061.jpg"}, {"question": "which fruit in the scene has the most potassium", "gt answer": "banana(1.00)", "pred answer": "apple", "question_id": 4283045, "best approach": "wiki, concept, image", "verif answer": "banana", "anno approach": "wiki", "verif wiki answer": "banana(0.7310)", "verif concept answer": "banana(0.7309)", "verif image answer": "banana(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428304.jpg"}, {"question": "what 's the bus hiding behind it", "gt answer": "build(1.00)<br/>passenger(0.60)<br/>people(0.60)", "pred answer": "step", "question_id": 1225835, "best approach": "", "verif answer": "carriage", "anno approach": "", "verif wiki answer": "carriage(0.7206)", "verif concept answer": "carriage(0.7244)", "verif image answer": "carriage(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122583.jpg"}, {"question": "what kind of contest is this", "gt answer": "eat(1.00)<br/>donut(0.60)", "pred answer": "race", "question_id": 3235885, "best approach": "", "verif answer": "dinner", "anno approach": "", "verif wiki answer": "dinner(0.6894)", "verif concept answer": "dinner(0.6579)", "verif image answer": "dinner(0.7276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323588.jpg"}, {"question": "what food does this animal eat", "gt answer": "berry(1.00)<br/>plant(0.60)<br/>salmon(0.60)<br/>meat(0.60)", "pred answer": "grass", "question_id": 192275, "best approach": "image", "verif answer": "meat", "anno approach": "image", "verif wiki answer": "meat(0.6672)", "verif concept answer": "meat(0.6870)", "verif image answer": "berry(0.6526)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019227.jpg"}, {"question": "what kind of bug are these", "gt answer": "dragon fly(0.60)<br/>butterfly(1.00)", "pred answer": "domestic", "question_id": 993885, "best approach": "wiki, concept, image", "verif answer": "dragon fly", "anno approach": "", "verif wiki answer": "dragon fly(0.7260)", "verif concept answer": "dragon fly(0.7240)", "verif image answer": "dragon fly(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099388.jpg"}, {"question": "what branch of skiing is this woman doing", "gt answer": "cross country(1.00)", "pred answer": "ski", "question_id": 345395, "best approach": "wiki, concept, image", "verif answer": "cross country", "anno approach": "", "verif wiki answer": "cross country(0.7310)", "verif concept answer": "cross country(0.7310)", "verif image answer": "cross country(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000034539.jpg"}, {"question": "what are these people doing as they sit on a couch", "gt answer": "watch tv(1.00)<br/>play(0.60)<br/>video game(0.60)<br/>talk(0.60)", "pred answer": "read", "question_id": 3962665, "best approach": "wiki, concept, image", "verif answer": "watch tv", "anno approach": "concept, wiki", "verif wiki answer": "watch tv(0.7168)", "verif concept answer": "watch tv(0.7103)", "verif image answer": "watch tv(0.5557)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396266.jpg"}, {"question": "what is the name for her headdress", "gt answer": "hijab(1.00)", "pred answer": "tuxedo", "question_id": 3781795, "best approach": "", "verif answer": "sombrero", "anno approach": "", "verif wiki answer": "fedora(0.7215)", "verif concept answer": "turban(0.7180)", "verif image answer": "sombrero(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378179.jpg"}, {"question": "is this a school bus or a passenger bus", "gt answer": "passenger bus(1.00)<br/>passenger(0.60)", "pred answer": "passenger", "question_id": 1952945, "best approach": "wiki, concept", "verif answer": "passenger", "anno approach": "concept, wiki", "verif wiki answer": "passenger(0.6482)", "verif concept answer": "passenger(0.7150)", "verif image answer": "people(0.6812)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195294.jpg"}, {"question": "what type of spelling is being used for the word under candy", "gt answer": "british(1.00)<br/>english(0.60)", "pred answer": "graffiti", "question_id": 5070285, "best approach": "image", "verif answer": "spanish", "anno approach": "image", "verif wiki answer": "spanish(0.5102)", "verif concept answer": "spanish(0.5019)", "verif image answer": "english(0.5013)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507028.jpg"}, {"question": "how long does the big white electronic item shown normally last before needing to be replaced", "gt answer": "5 years(1.00)<br/>4 years(0.60)", "pred answer": "8 hours", "question_id": 5066055, "best approach": "image", "verif answer": "4 years", "anno approach": "image", "verif wiki answer": "2 years(0.5291)", "verif concept answer": "3 years(0.5103)", "verif image answer": "4 years(0.5675)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506605.jpg"}, {"question": "the animal on the bottom of the photo is commonly referred to as man 's best what", "gt answer": "friend(1.00)<br/>cow(0.60)", "pred answer": "beagle", "question_id": 2113405, "best approach": "image", "verif answer": "cow", "anno approach": "image", "verif wiki answer": "cow(0.6779)", "verif concept answer": "cow(0.6560)", "verif image answer": "friend(0.6555)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000211340.jpg"}, {"question": "what kind have cake is that", "gt answer": "cheesecake(1.00)<br/>chocolate(0.60)<br/>icecream(0.60)<br/>pie(0.60)", "pred answer": "red velvet", "question_id": 4045785, "best approach": "image", "verif answer": "cheesecake", "anno approach": "image", "verif wiki answer": "icecream(0.6127)", "verif concept answer": "icecream(0.6108)", "verif image answer": "cheesecake(0.6609)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404578.jpg"}, {"question": "what does this gesture mean", "gt answer": "good game(1.00)", "pred answer": "serve", "question_id": 1159175, "best approach": "wiki, concept, image", "verif answer": "good game", "anno approach": "image", "verif wiki answer": "good game(0.6975)", "verif concept answer": "good game(0.6773)", "verif image answer": "good game(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115917.jpg"}, {"question": "what buttons are the cats paws covering", "gt answer": "number(1.00)<br/>remote(0.60)", "pred answer": "delete", "question_id": 3829265, "best approach": "", "verif answer": "cd", "anno approach": "", "verif wiki answer": "cd(0.6673)", "verif concept answer": "cd(0.6605)", "verif image answer": "cd(0.6904)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382926.jpg"}, {"question": "", "gt answer": "drop(0.60)", "pred answer": "propeller", "question_id": 3499475, "best approach": "wiki, concept", "verif answer": "drop", "anno approach": "", "verif wiki answer": "drop(0.6957)", "verif concept answer": "drop(0.7188)", "verif image answer": "arch(0.6401)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000349947.jpg"}, {"question": "what is the power consumption of that laptop", "gt answer": "battery(1.00)", "pred answer": "window", "question_id": 5179985, "best approach": "image", "verif answer": "music", "anno approach": "image", "verif wiki answer": "music(0.6354)", "verif concept answer": "music(0.6243)", "verif image answer": "battery(0.5207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517998.jpg"}, {"question": "what is this building called", "gt answer": "courthouse(1.00)<br/>court(0.60)", "pred answer": "church", "question_id": 5433715, "best approach": "", "verif answer": "church", "anno approach": "", "verif wiki answer": "church(0.6809)", "verif concept answer": "church(0.6674)", "verif image answer": "church(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543371.jpg"}, {"question": "what does this animal eat", "gt answer": "mice(1.00)<br/>cat food(1.00)<br/>fish(0.60)", "pred answer": "cat food", "question_id": 54355, "best approach": "wiki, concept, image", "verif answer": "cat food", "anno approach": "wiki", "verif wiki answer": "cat food(0.7276)", "verif concept answer": "cat food(0.7232)", "verif image answer": "cat food(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005435.jpg"}, {"question": "they make is a lot in italy what do you call it", "gt answer": "pizza(1.00)", "pred answer": "cheese", "question_id": 2558985, "best approach": "", "verif answer": "italian", "anno approach": "", "verif wiki answer": "italian(0.6662)", "verif concept answer": "italian(0.6766)", "verif image answer": "italian(0.7245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255898.jpg"}, {"question": "eating this fruit can prevent what disease that commonly afflicted sailors", "gt answer": "scurvy(1.00)<br/>cancer(0.60)<br/>orange(0.60)", "pred answer": "citrus", "question_id": 2655315, "best approach": "wiki, concept, image", "verif answer": "cancer", "anno approach": "image, wiki", "verif wiki answer": "cancer(0.5014)", "verif concept answer": "cancer(0.5002)", "verif image answer": "cancer(0.5943)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265531.jpg"}, {"question": "what is the long wooden object that man is holding used for", "gt answer": "bat(1.00)<br/>baseball bat(0.60)", "pred answer": "bat", "question_id": 1220935, "best approach": "wiki, concept", "verif answer": "bat", "anno approach": "wiki", "verif wiki answer": "bat(0.7255)", "verif concept answer": "bat(0.6901)", "verif image answer": "hit baseball(0.6357)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122093.jpg"}, {"question": "is this boat in this image moving to the right or the left", "gt answer": "right(1.00)<br/>left(1.00)", "pred answer": "left", "question_id": 2012135, "best approach": "image", "verif answer": "coach", "anno approach": "image", "verif wiki answer": "coach(0.7241)", "verif concept answer": "coach(0.7005)", "verif image answer": "left(0.5475)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201213.jpg"}, {"question": "why is the boat floating above water", "gt answer": "buoyancy(1.00)", "pred answer": "fish", "question_id": 4800055, "best approach": "", "verif answer": "canoe", "anno approach": "", "verif wiki answer": "canoe(0.7193)", "verif concept answer": "canoe(0.6957)", "verif image answer": "15 feet(0.6279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480005.jpg"}, {"question": "what is this cutting instrument used for", "gt answer": "fabric(1.00)<br/>scissor(0.60)<br/>sew(0.60)", "pred answer": "cut", "question_id": 2007945, "best approach": "", "verif answer": "thread", "anno approach": "", "verif wiki answer": "thread(0.6816)", "verif concept answer": "cut(0.6578)", "verif image answer": "cut(0.6703)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200794.jpg"}, {"question": "what disney character uses the everyday accessory that can be seen in the photo to help her fly", "gt answer": "mary poppins(1.00)", "pred answer": "mary poppins", "question_id": 4759845, "best approach": "wiki, concept, image", "verif answer": "mary poppins", "anno approach": "wiki", "verif wiki answer": "mary poppins(0.7149)", "verif concept answer": "mary poppins(0.7153)", "verif image answer": "mary poppins(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475984.jpg"}, {"question": "does this animal normally live in a hot or cold climate", "gt answer": "hot(1.00)", "pred answer": "hot", "question_id": 5090955, "best approach": "", "verif answer": "warm", "anno approach": "", "verif wiki answer": "warm(0.7300)", "verif concept answer": "warm(0.7306)", "verif image answer": "warm(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509095.jpg"}, {"question": "what event is this", "gt answer": "race(1.00)<br/>car show(0.60)", "pred answer": "race", "question_id": 5669385, "best approach": "wiki, concept, image", "verif answer": "car show", "anno approach": "wiki", "verif wiki answer": "car show(0.6713)", "verif concept answer": "car show(0.6551)", "verif image answer": "car show(0.6369)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566938.jpg"}, {"question": "where can you buy a sofa like this", "gt answer": "ikea(1.00)", "pred answer": "ikea", "question_id": 2762085, "best approach": "", "verif answer": "furniture store", "anno approach": "", "verif wiki answer": "furniture store(0.7050)", "verif concept answer": "furniture store(0.7157)", "verif image answer": "furniture store(0.6940)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276208.jpg"}, {"question": "what happened to the train", "gt answer": "derailed(1.00)<br/>stopped(0.60)", "pred answer": "broken", "question_id": 249805, "best approach": "concept", "verif answer": "light", "anno approach": "concept", "verif wiki answer": "crash(0.5839)", "verif concept answer": "stopped(0.6202)", "verif image answer": "light(0.6245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024980.jpg"}, {"question": "how much water do this animal consume in a day", "gt answer": "5 gallons(1.00)<br/>gallon(0.60)", "pred answer": "lot", "question_id": 4154925, "best approach": "", "verif answer": "10 gallons", "anno approach": "", "verif wiki answer": "10 gallons(0.6800)", "verif concept answer": "10 gallons(0.6505)", "verif image answer": "10 gallons(0.5720)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415492.jpg"}, {"question": "name a famous person who does this activity", "gt answer": "shawn white(1.00)<br/>shaun white(0.60)", "pred answer": "shaun white", "question_id": 5569555, "best approach": "wiki, concept, image", "verif answer": "shaun white", "anno approach": "wiki", "verif wiki answer": "shaun white(0.7187)", "verif concept answer": "shaun white(0.7133)", "verif image answer": "shaun white(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556955.jpg"}, {"question": "which brothers invented this machine", "gt answer": "wright(1.00)<br/>wright brother(1.00)", "pred answer": "wright brother", "question_id": 1457485, "best approach": "wiki, concept", "verif answer": "wright brother", "anno approach": "wiki", "verif wiki answer": "wright brother(0.6927)", "verif concept answer": "wright brother(0.6296)", "verif image answer": "company(0.5900)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145748.jpg"}, {"question": "what kinds of boats are these", "gt answer": "yacht(1.00)<br/>passenger(0.60)", "pred answer": "fish", "question_id": 1941596, "best approach": "image", "verif answer": "passenger", "anno approach": "image", "verif wiki answer": "speedboat(0.6967)", "verif concept answer": "boat(0.7027)", "verif image answer": "passenger(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194159.jpg"}, {"question": "what model of truck is this", "gt answer": "chevy(1.00)<br/>toyota(0.60)<br/>pickup(0.60)", "pred answer": "passenger", "question_id": 3846985, "best approach": "wiki, concept", "verif answer": "ford", "anno approach": "wiki", "verif wiki answer": "toyota(0.7178)", "verif concept answer": "toyota(0.7086)", "verif image answer": "ford(0.7222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384698.jpg"}, {"question": "what mood are these ladies in", "gt answer": "happy(1.00)", "pred answer": "happy", "question_id": 3699315, "best approach": "wiki, concept", "verif answer": "happy", "anno approach": "wiki", "verif wiki answer": "happy(0.6534)", "verif concept answer": "happy(0.6168)", "verif image answer": "happiness(0.5153)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369931.jpg"}, {"question": "the fruits before you is good for which parts of the body", "gt answer": "brain(1.00)<br/>muscle(0.60)<br/>hair(0.60)", "pred answer": "stomach", "question_id": 4649375, "best approach": "", "verif answer": "skin", "anno approach": "", "verif wiki answer": "skin(0.6106)", "verif concept answer": "skin(0.6335)", "verif image answer": "skin(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464937.jpg"}, {"question": "is this a mac or pc", "gt answer": "pc(1.00)<br/>mac(1.00)", "pred answer": "mac", "question_id": 2332425, "best approach": "wiki, concept, image", "verif answer": "mac", "anno approach": "wiki", "verif wiki answer": "mac(0.7310)", "verif concept answer": "mac(0.7301)", "verif image answer": "mac(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233242.jpg"}, {"question": "when were these planes in service", "gt answer": "ww2(1.00)<br/>2000(0.60)<br/>1940(0.60)<br/>airshow(0.60)", "pred answer": "1940s", "question_id": 5296475, "best approach": "wiki, concept, image", "verif answer": "ww2", "anno approach": "image, wiki", "verif wiki answer": "ww2(0.6670)", "verif concept answer": "ww2(0.6676)", "verif image answer": "ww2(0.7184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529647.jpg"}, {"question": "", "gt answer": "16(0.60)<br/>1800's(0.60)<br/>18th(0.60)<br/>1800s(0.60)<br/>19th(0.60)", "pred answer": "19th", "question_id": 1879785, "best approach": "wiki, concept, image", "verif answer": "19th", "anno approach": "", "verif wiki answer": "19th(0.6163)", "verif concept answer": "19th(0.6405)", "verif image answer": "19th(0.6402)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187978.jpg"}, {"question": "what animal is this", "gt answer": "sheep(1.00)", "pred answer": "sheep", "question_id": 3482045, "best approach": "", "verif answer": "merino", "anno approach": "", "verif wiki answer": "merino(0.5022)", "verif concept answer": "merino(0.5016)", "verif image answer": "merino(0.5284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348204.jpg"}, {"question": "what powerful objects are used to help this vehicle move", "gt answer": "engine(1.00)", "pred answer": "cargo", "question_id": 2532855, "best approach": "", "verif answer": "fuel", "anno approach": "", "verif wiki answer": "fuel(0.6570)", "verif concept answer": "fuel(0.6767)", "verif image answer": "fuel(0.6513)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253285.jpg"}, {"question": "what species of trees are behind this snowboarder", "gt answer": "evergreen(1.00)<br/>fir(0.60)<br/>pine(0.60)<br/>bear(0.60)", "pred answer": "pine tree", "question_id": 2430725, "best approach": "wiki, concept, image", "verif answer": "pine", "anno approach": "wiki", "verif wiki answer": "pine(0.6888)", "verif concept answer": "pine(0.6782)", "verif image answer": "pine(0.6513)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243072.jpg"}, {"question": "why would peanuts be relevant to this picture", "gt answer": "elephant(1.00)", "pred answer": "tusk", "question_id": 3048335, "best approach": "", "verif answer": "brain", "anno approach": "", "verif wiki answer": "brain(0.6049)", "verif concept answer": "brain(0.6235)", "verif image answer": "brain(0.6886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304833.jpg"}, {"question": "what is the animal 's collar for", "gt answer": "identification(1.00)<br/>name(0.60)<br/>cat(0.60)", "pred answer": "collar", "question_id": 4165595, "best approach": "image", "verif answer": "bear", "anno approach": "image", "verif wiki answer": "bear(0.7036)", "verif concept answer": "bear(0.6767)", "verif image answer": "cat(0.6450)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416559.jpg"}, {"question": "name the type of ceramic used to make this toilet shown in this picture", "gt answer": "porcelain(0.60)<br/>clay(0.60)<br/>tile(1.00)", "pred answer": "porcelain", "question_id": 215355, "best approach": "wiki, concept, image", "verif answer": "porcelain", "anno approach": "wiki", "verif wiki answer": "porcelain(0.7006)", "verif concept answer": "porcelain(0.6882)", "verif image answer": "porcelain(0.6777)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000021535.jpg"}, {"question": "what does this man have on his lip", "gt answer": "mustache(1.00)", "pred answer": "cheese", "question_id": 1802675, "best approach": "", "verif answer": "goatee", "anno approach": "", "verif wiki answer": "goatee(0.5006)", "verif concept answer": "goatee(0.5056)", "verif image answer": "goatee(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180267.jpg"}, {"question": "which famous disney host animal also wears gloves not unlike these shown here", "gt answer": "mickey mouse(1.00)", "pred answer": "lance armstrong", "question_id": 1056055, "best approach": "", "verif answer": "disney", "anno approach": "", "verif wiki answer": "disney(0.5990)", "verif concept answer": "disney(0.7126)", "verif image answer": "disney(0.7199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105605.jpg"}, {"question": "what kind of bed is pictured", "gt answer": "4 poster(1.00)<br/>canopy(0.60)", "pred answer": "queen", "question_id": 4765855, "best approach": "wiki, concept, image", "verif answer": "canopy", "anno approach": "concept, wiki", "verif wiki answer": "canopy(0.7169)", "verif concept answer": "canopy(0.7122)", "verif image answer": "canopy(0.6679)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476585.jpg"}, {"question": "what brand of shoes is he wearing", "gt answer": "van(1.00)", "pred answer": "converse", "question_id": 130825, "best approach": "", "verif answer": "converse", "anno approach": "", "verif wiki answer": "element(0.6719)", "verif concept answer": "element(0.6713)", "verif image answer": "converse(0.7014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013082.jpg"}, {"question": "what is the material the couch is made of in the photo", "gt answer": "leather(1.00)", "pred answer": "leather", "question_id": 3937195, "best approach": "", "verif answer": "fabric", "anno approach": "", "verif wiki answer": "carpet(0.7219)", "verif concept answer": "fabric(0.7298)", "verif image answer": "fabric(0.7011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393719.jpg"}, {"question": "what material is used to cover the tables", "gt answer": "cloth(1.00)<br/>paper(0.60)<br/>cotton(0.60)<br/>tablecloth(0.60)", "pred answer": "paper", "question_id": 4688265, "best approach": "concept", "verif answer": "polyester", "anno approach": "concept", "verif wiki answer": "polyester(0.7252)", "verif concept answer": "paper(0.7250)", "verif image answer": "polyester(0.6958)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000468826.jpg"}, {"question": "what kind of drink can you get here", "gt answer": "alcoholic(1.00)<br/>alcohol(0.60)<br/>coffee(0.60)<br/>cocktail(0.60)", "pred answer": "beer", "question_id": 4025635, "best approach": "concept", "verif answer": "wine", "anno approach": "concept", "verif wiki answer": "wine(0.5700)", "verif concept answer": "coffee(0.5908)", "verif image answer": "wine(0.6241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402563.jpg"}, {"question": "who is this famous surfer", "gt answer": "kelly slater(1.00)", "pred answer": "tony hawk", "question_id": 4503405, "best approach": "wiki, concept, image", "verif answer": "kelly slater", "anno approach": "image, wiki", "verif wiki answer": "kelly slater(0.6453)", "verif concept answer": "kelly slater(0.6260)", "verif image answer": "kelly slater(0.7078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450340.jpg"}, {"question": "what does the item in this photo do", "gt answer": "fly(1.00)", "pred answer": "fly", "question_id": 1777555, "best approach": "", "verif answer": "land", "anno approach": "", "verif wiki answer": "land(0.7305)", "verif concept answer": "land(0.7195)", "verif image answer": "takeoff(0.6137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177755.jpg"}, {"question": "what kind of structure is that", "gt answer": "tent(1.00)", "pred answer": "boat", "question_id": 3364895, "best approach": "wiki, concept, image", "verif answer": "tent", "anno approach": "wiki", "verif wiki answer": "tent(0.7124)", "verif concept answer": "tent(0.7108)", "verif image answer": "tent(0.6849)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000336489.jpg"}, {"question": "is this animal full grown or a younger animal", "gt answer": "younger(1.00)<br/>young(0.60)", "pred answer": "full", "question_id": 5418805, "best approach": "wiki, concept, image", "verif answer": "younger", "anno approach": "concept, wiki", "verif wiki answer": "younger(0.7082)", "verif concept answer": "younger(0.7254)", "verif image answer": "younger(0.5118)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541880.jpg"}, {"question": "who invented the device shown in the right side of the image", "gt answer": "alexander graham bell(1.00)<br/>bill gate(0.60)", "pred answer": "ibm", "question_id": 964975, "best approach": "image", "verif answer": "alexander graham bell", "anno approach": "image", "verif wiki answer": "bill gate(0.7117)", "verif concept answer": "martin cooper(0.6931)", "verif image answer": "alexander graham bell(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096497.jpg"}, {"question": "is this a girls or boy room", "gt answer": "boy(1.00)", "pred answer": "girl", "question_id": 1412655, "best approach": "", "verif answer": "girl", "anno approach": "", "verif wiki answer": "girl(0.7308)", "verif concept answer": "girl(0.7303)", "verif image answer": "girl(0.6718)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000141265.jpg"}, {"question": "what kind of flowers are in the background", "gt answer": "tulip(1.00)<br/>daffodil(1.00)", "pred answer": "daisy", "question_id": 5693495, "best approach": "wiki, concept, image", "verif answer": "daffodil", "anno approach": "concept, wiki", "verif wiki answer": "daffodil(0.6293)", "verif concept answer": "daffodil(0.6092)", "verif image answer": "daffodil(0.5283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569349.jpg"}, {"question": "what are the round black objects next to the computer used for", "gt answer": "hear(1.00)<br/>headphone(0.60)<br/>listen(0.60)<br/>ear(0.60)", "pred answer": "computer", "question_id": 1888265, "best approach": "wiki", "verif answer": "headphone", "anno approach": "wiki", "verif wiki answer": "hear(0.6518)", "verif concept answer": "stab(0.6709)", "verif image answer": "headphone(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188826.jpg"}, {"question": "what kind of lighting fixture is hanging from the ceiling", "gt answer": "chandelier(1.00)", "pred answer": "lamp", "question_id": 5552115, "best approach": "", "verif answer": "string", "anno approach": "", "verif wiki answer": "string(0.7213)", "verif concept answer": "string(0.7217)", "verif image answer": "lava(0.7143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555211.jpg"}, {"question": "what part of the body is used in the picture", "gt answer": "butt(1.00)<br/>hand(1.00)<br/>neck(0.60)", "pred answer": "front", "question_id": 2103225, "best approach": "concept", "verif answer": "butt", "anno approach": "concept", "verif wiki answer": "neck(0.6213)", "verif concept answer": "butt(0.6878)", "verif image answer": "neck(0.6588)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210322.jpg"}, {"question": "what type of soda can is on the table", "gt answer": "pepsi(1.00)", "pred answer": "soda", "question_id": 2968435, "best approach": "", "verif answer": "coca cola", "anno approach": "", "verif wiki answer": "coca cola(0.6497)", "verif concept answer": "coca cola(0.6585)", "verif image answer": "aloe(0.6350)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296843.jpg"}, {"question": "what kind of flowers are these", "gt answer": "tulip(1.00)<br/>rose(1.00)", "pred answer": "rose", "question_id": 202135, "best approach": "image", "verif answer": "daffodil", "anno approach": "image", "verif wiki answer": "daffodil(0.7245)", "verif concept answer": "daffodil(0.6950)", "verif image answer": "rose(0.6726)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020213.jpg"}, {"question": "what vitamin is associated with the vegetable found in this picture", "gt answer": "vitamin k(1.00)<br/>calcium(0.60)<br/>(0.60)<br/>potassium(0.60)", "pred answer": "c", "question_id": 10365, "best approach": "wiki, image", "verif answer": "potassium", "anno approach": "image, wiki", "verif wiki answer": "potassium(0.6656)", "verif concept answer": "vitamin(0.6494)", "verif image answer": "potassium(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001036.jpg"}, {"question": "which brand of cycles are seen in this picture", "gt answer": "huffy(1.00)<br/>schwinn(1.00)", "pred answer": "schwinn", "question_id": 3655735, "best approach": "wiki, image", "verif answer": "huffy", "anno approach": "wiki", "verif wiki answer": "huffy(0.7067)", "verif concept answer": "10 speed(0.6824)", "verif image answer": "huffy(0.6896)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365573.jpg"}, {"question": "what movie does the poster in the back come from", "gt answer": "star war(1.00)<br/>0(0.60)", "pred answer": "lion king", "question_id": 5531765, "best approach": "", "verif answer": "forrest gump", "anno approach": "", "verif wiki answer": "forrest gump(0.7309)", "verif concept answer": "forrest gump(0.7309)", "verif image answer": "forrest gump(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553176.jpg"}, {"question": "what is the weather forecasting on this day", "gt answer": "overcast(1.00)<br/>rain(0.60)", "pred answer": "cloudy", "question_id": 102225, "best approach": "image", "verif answer": "overcast", "anno approach": "image", "verif wiki answer": "storm(0.6754)", "verif concept answer": "storm(0.7003)", "verif image answer": "overcast(0.7150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000010222.jpg"}, {"question": "what food in this picture is not edible by a vegetarian", "gt answer": "chicken(1.00)<br/>steak(0.60)", "pred answer": "lettuce", "question_id": 2875855, "best approach": "wiki, image", "verif answer": "pork", "anno approach": "wiki", "verif wiki answer": "steak(0.5303)", "verif concept answer": "pork(0.6029)", "verif image answer": "steak(0.5051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287585.jpg"}, {"question": "what happened to his wrist", "gt answer": "sprained it(1.00)", "pred answer": "broken", "question_id": 4180575, "best approach": "", "verif answer": "sweat", "anno approach": "", "verif wiki answer": "sweat(0.7141)", "verif concept answer": "sweat(0.6554)", "verif image answer": "sweat(0.6780)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000418057.jpg"}, {"question": "what style of pants is the lady wearing", "gt answer": "jean(1.00)<br/>sweat(0.60)", "pred answer": "jean", "question_id": 4741185, "best approach": "wiki, concept, image", "verif answer": "jean", "anno approach": "wiki", "verif wiki answer": "jean(0.6988)", "verif concept answer": "jean(0.7106)", "verif image answer": "jean(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000474118.jpg"}, {"question": "this animal has what kind of feet", "gt answer": "webbed(1.00)", "pred answer": "goose", "question_id": 4315985, "best approach": "wiki, concept, image", "verif answer": "webbed", "anno approach": "", "verif wiki answer": "webbed(0.7183)", "verif concept answer": "webbed(0.7206)", "verif image answer": "webbed(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431598.jpg"}, {"question": "what are some manufacturers of the same style of oven shown", "gt answer": "ge(1.00)", "pred answer": "ge", "question_id": 5434475, "best approach": "image", "verif answer": "general electric", "anno approach": "image", "verif wiki answer": "general electric(0.7229)", "verif concept answer": "general electric(0.7139)", "verif image answer": "ge(0.7017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543447.jpg"}, {"question": "name the type of paper material used to print this photo", "gt answer": "photo paper(1.00)<br/>paper(0.60)", "pred answer": "cotton", "question_id": 4220645, "best approach": "", "verif answer": "plastic", "anno approach": "", "verif wiki answer": "frost(0.5510)", "verif concept answer": "frost(0.5718)", "verif image answer": "plastic(0.6467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422064.jpg"}, {"question": "what type of ball is used in the game that bears the same name as this one", "gt answer": "soccer ball(1.00)<br/>football(0.60)<br/>soccer(0.60)", "pred answer": "soccer", "question_id": 3569085, "best approach": "image", "verif answer": "soccer", "anno approach": "image", "verif wiki answer": "adidas(0.7310)", "verif concept answer": "adidas(0.7310)", "verif image answer": "soccer(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356908.jpg"}, {"question": "who normally uses these items to make men 's clothes", "gt answer": "tailor(1.00)", "pred answer": "paper crafter", "question_id": 2445825, "best approach": "", "verif answer": "paper crafter", "anno approach": "", "verif wiki answer": "paper crafter(0.7103)", "verif concept answer": "paper crafter(0.7129)", "verif image answer": "paper crafter(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244582.jpg"}, {"question": "what type of bird is shown in the picture", "gt answer": "robin(1.00)", "pred answer": "finch", "question_id": 4614985, "best approach": "", "verif answer": "sparrow", "anno approach": "", "verif wiki answer": "sparrow(0.6903)", "verif concept answer": "sparrow(0.6677)", "verif image answer": "sparrow(0.6578)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461498.jpg"}, {"question": "what is this guy pretending to be", "gt answer": "pirate(1.00)", "pred answer": "parrot", "question_id": 5366075, "best approach": "wiki, concept, image", "verif answer": "pirate", "anno approach": "image, concept", "verif wiki answer": "pirate(0.5766)", "verif concept answer": "pirate(0.6237)", "verif image answer": "pirate(0.6394)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536607.jpg"}, {"question": "what kind of covering is on this bed", "gt answer": "comforter(1.00)<br/>blanket(0.60)", "pred answer": "bed", "question_id": 3139145, "best approach": "wiki, concept", "verif answer": "duvet", "anno approach": "wiki", "verif wiki answer": "comforter(0.6967)", "verif concept answer": "comforter(0.6573)", "verif image answer": "duvet(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313914.jpg"}, {"question": "are the cats indoors our outdoors", "gt answer": "indoor(1.00)", "pred answer": "outdoor", "question_id": 123075, "best approach": "", "verif answer": "outdoor", "anno approach": "", "verif wiki answer": "outdoor(0.7186)", "verif concept answer": "outdoor(0.5505)", "verif image answer": "succulent(0.5064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012307.jpg"}, {"question": "who makes this product", "gt answer": "citikitty(1.00)", "pred answer": "ford", "question_id": 5763175, "best approach": "wiki, concept, image", "verif answer": "citikitty", "anno approach": "", "verif wiki answer": "citikitty(0.7112)", "verif concept answer": "citikitty(0.6964)", "verif image answer": "citikitty(0.7245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000576317.jpg"}, {"question": "what could be made out of the skin", "gt answer": "sweater(1.00)<br/>wool(0.60)<br/>belt(0.60)", "pred answer": "fur", "question_id": 4921555, "best approach": "wiki, image", "verif answer": "belt", "anno approach": "", "verif wiki answer": "belt(0.7189)", "verif concept answer": "scarf(0.7089)", "verif image answer": "belt(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492155.jpg"}, {"question": "what geometric shape is this", "gt answer": "circle(1.00)<br/>round(0.60)", "pred answer": "circle", "question_id": 3896545, "best approach": "wiki, concept", "verif answer": "round", "anno approach": "wiki", "verif wiki answer": "circle(0.7188)", "verif concept answer": "circle(0.7165)", "verif image answer": "round(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389654.jpg"}, {"question": "what are the two gentleman at the forefront of the picture doing", "gt answer": "shake hand(1.00)", "pred answer": "cut cake", "question_id": 5795335, "best approach": "wiki, image", "verif answer": "shake hand", "anno approach": "image, wiki", "verif wiki answer": "shake hand(0.6243)", "verif concept answer": "hand shake(0.6329)", "verif image answer": "shake hand(0.6605)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000579533.jpg"}, {"question": "what type of couch is this", "gt answer": "sectional(1.00)", "pred answer": "loveseat", "question_id": 218725, "best approach": "", "verif answer": "pug", "anno approach": "", "verif wiki answer": "pug(0.7002)", "verif concept answer": "pug(0.7172)", "verif image answer": "pug(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000021872.jpg"}, {"question": "what is the material the bracelet worn by the arm in the middle", "gt answer": "gold(1.00)<br/>metal(0.60)<br/>nylon(0.60)<br/>rubber(0.60)", "pred answer": "leather", "question_id": 4593635, "best approach": "wiki, image", "verif answer": "gold", "anno approach": "wiki", "verif wiki answer": "gold(0.6707)", "verif concept answer": "nylon(0.6569)", "verif image answer": "gold(0.5846)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459363.jpg"}, {"question": "the fruit shown in this photo is good for which parts of the body", "gt answer": "skin(1.00)<br/>brain(0.60)<br/>heart(0.60)<br/>immune system(0.60)", "pred answer": "stomach", "question_id": 1869525, "best approach": "wiki, concept, image", "verif answer": "brain", "anno approach": "image, wiki", "verif wiki answer": "brain(0.6733)", "verif concept answer": "brain(0.6477)", "verif image answer": "brain(0.6949)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186952.jpg"}, {"question": "which country did this food originate from", "gt answer": "italy(1.00)<br/>mexico(0.60)", "pred answer": "chicago", "question_id": 4094545, "best approach": "wiki, concept, image", "verif answer": "mexico", "anno approach": "concept, wiki", "verif wiki answer": "mexico(0.7059)", "verif concept answer": "mexico(0.6970)", "verif image answer": "mexico(0.6450)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409454.jpg"}, {"question": "what fruit is the baby eating", "gt answer": "peach(0.60)<br/>strawberry(1.00)", "pred answer": "strawberry", "question_id": 2382005, "best approach": "wiki, concept, image", "verif answer": "strawberry", "anno approach": "concept, wiki", "verif wiki answer": "strawberry(0.5704)", "verif concept answer": "strawberry(0.6051)", "verif image answer": "strawberry(0.5860)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238200.jpg"}, {"question": "what is the highest one of these in the world", "gt answer": "mt everest(1.00)<br/>mount everest(0.60)<br/>everest(0.60)", "pred answer": "alp", "question_id": 5118485, "best approach": "concept", "verif answer": "shaun white", "anno approach": "concept", "verif wiki answer": "shaun white(0.5493)", "verif concept answer": "mt everest(0.5680)", "verif image answer": "shaun white(0.5878)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511848.jpg"}, {"question": "how long will this need to cook", "gt answer": "0 minutes(1.00)<br/>1 hour(0.60)", "pred answer": "10 minutes", "question_id": 124285, "best approach": "concept", "verif answer": "0 minutes", "anno approach": "concept", "verif wiki answer": "3 hours(0.6543)", "verif concept answer": "0 minutes(0.7112)", "verif image answer": "15 minutes(0.6689)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012428.jpg"}, {"question": "", "gt answer": "1804(0.60)<br/>1950(0.60)<br/>1800's(0.60)<br/>1670(0.60)<br/>1800s(0.60)", "pred answer": "1800's", "question_id": 3213025, "best approach": "wiki, concept, image", "verif answer": "1804", "anno approach": "", "verif wiki answer": "1804(0.7066)", "verif concept answer": "1804(0.7202)", "verif image answer": "1804(0.6976)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321302.jpg"}, {"question": "what would you do with this", "gt answer": "drink(1.00)<br/>smell(0.60)", "pred answer": "glass", "question_id": 5780025, "best approach": "wiki, concept, image", "verif answer": "drink", "anno approach": "wiki", "verif wiki answer": "drink(0.7309)", "verif concept answer": "drink(0.7271)", "verif image answer": "drink(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578002.jpg"}, {"question": "what type of cheese is used in this food", "gt answer": "mozzarella(1.00)", "pred answer": "mozzarella", "question_id": 1220175, "best approach": "wiki, concept, image", "verif answer": "mozzarella", "anno approach": "wiki", "verif wiki answer": "mozzarella(0.6989)", "verif concept answer": "mozzarella(0.7155)", "verif image answer": "mozzarella(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122017.jpg"}, {"question": "why does he have two shadows", "gt answer": "light(1.00)", "pred answer": "sun", "question_id": 2288765, "best approach": "", "verif answer": "sunlight", "anno approach": "", "verif wiki answer": "filter(0.5203)", "verif concept answer": "computer(0.5143)", "verif image answer": "sunlight(0.5782)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000228876.jpg"}, {"question": "what is the white food in the pic", "gt answer": "rice(1.00)", "pred answer": "vegetable", "question_id": 5454115, "best approach": "", "verif answer": "snack", "anno approach": "", "verif wiki answer": "snack(0.7109)", "verif concept answer": "vegetable(0.6643)", "verif image answer": "snack(0.6885)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545411.jpg"}, {"question": "why are they standing with wire in their hands", "gt answer": "play video game(1.00)<br/>video game(1.00)<br/>play(0.60)", "pred answer": "play game", "question_id": 2452095, "best approach": "wiki, concept", "verif answer": "play video game", "anno approach": "", "verif wiki answer": "play video game(0.6408)", "verif concept answer": "play video game(0.6633)", "verif image answer": "wii(0.6615)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245209.jpg"}, {"question": "what can happen the objects shown are thrown on the ground", "gt answer": "break(1.00)<br/>shatter(1.00)", "pred answer": "blend", "question_id": 2400745, "best approach": "", "verif answer": "glaze", "anno approach": "", "verif wiki answer": "glaze(0.6049)", "verif concept answer": "glaze(0.5637)", "verif image answer": "glaze(0.5818)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240074.jpg"}, {"question": "what animal enjoys this fruit", "gt answer": "monkey(1.00)", "pred answer": "monkey", "question_id": 4558935, "best approach": "wiki, concept", "verif answer": "monkey", "anno approach": "wiki", "verif wiki answer": "monkey(0.7285)", "verif concept answer": "monkey(0.7283)", "verif image answer": "bird(0.7096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455893.jpg"}, {"question": "what is that scooter in the background called", "gt answer": "vespa(1.00)", "pred answer": "honda", "question_id": 2096545, "best approach": "", "verif answer": "scooter", "anno approach": "", "verif wiki answer": "bmw(0.6414)", "verif concept answer": "scooter(0.6850)", "verif image answer": "scooter(0.7091)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209654.jpg"}, {"question": "who made this bus", "gt answer": "andesmar(1.00)<br/>ford(0.60)", "pred answer": "ford", "question_id": 2134365, "best approach": "", "verif answer": "mercedes benz", "anno approach": "", "verif wiki answer": "mercedes benz(0.7239)", "verif concept answer": "mercedes benz(0.7224)", "verif image answer": "mercedes benz(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000213436.jpg"}, {"question": "what is the large blue vehicle called", "gt answer": "crane(1.00)", "pred answer": "pickup", "question_id": 1493315, "best approach": "", "verif answer": "bucket truck", "anno approach": "", "verif wiki answer": "bucket truck(0.7044)", "verif concept answer": "bucket truck(0.6974)", "verif image answer": "bucket truck(0.7051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149331.jpg"}, {"question": "what type of boat is this", "gt answer": "raft(1.00)", "pred answer": "canoe", "question_id": 2730355, "best approach": "", "verif answer": "board ship", "anno approach": "", "verif wiki answer": "board ship(0.7192)", "verif concept answer": "board ship(0.7208)", "verif image answer": "board ship(0.6835)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273035.jpg"}, {"question": "what kind of device is this", "gt answer": "laptop(1.00)", "pred answer": "laptop", "question_id": 3665275, "best approach": "", "verif answer": "work", "anno approach": "", "verif wiki answer": "macbook(0.5684)", "verif concept answer": "macbook(0.5312)", "verif image answer": "work(0.6635)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366527.jpg"}, {"question": "how was the broccoli made", "gt answer": "steamed(1.00)", "pred answer": "baked", "question_id": 3994615, "best approach": "", "verif answer": "steam", "anno approach": "", "verif wiki answer": "boiled(0.5888)", "verif concept answer": "boiled(0.6225)", "verif image answer": "steam(0.6352)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399461.jpg"}, {"question": "", "gt answer": "50(0.60)<br/>80(0.60)<br/>$50(0.60)", "pred answer": "15", "question_id": 1005795, "best approach": "wiki, concept, image", "verif answer": "80", "anno approach": "concept", "verif wiki answer": "80(0.5888)", "verif concept answer": "80(0.6182)", "verif image answer": "80(0.5791)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100579.jpg"}, {"question": "what sport is played", "gt answer": "cycling(1.00)<br/>bicycling(0.60)", "pred answer": "motorcross", "question_id": 2922265, "best approach": "", "verif answer": "bike", "anno approach": "", "verif wiki answer": "bike(0.6256)", "verif concept answer": "road(0.6491)", "verif image answer": "bike(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292226.jpg"}, {"question": "what would this shelter be called", "gt answer": "barn(1.00)<br/>sheep(0.60)<br/>shed(0.60)", "pred answer": "barn", "question_id": 2927205, "best approach": "wiki, concept, image", "verif answer": "barn", "anno approach": "wiki", "verif wiki answer": "barn(0.7223)", "verif concept answer": "barn(0.7286)", "verif image answer": "barn(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292720.jpg"}, {"question": "how many different types of fruit and vegetables are in this picture", "gt answer": "8(1.00)<br/>12(0.60)", "pred answer": "vegetable", "question_id": 3022165, "best approach": "image", "verif answer": "6", "anno approach": "image", "verif wiki answer": "6(0.7232)", "verif concept answer": "6(0.6933)", "verif image answer": "12(0.6457)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302216.jpg"}, {"question": "what do you call the kind of pants that the man on the right is wearing", "gt answer": "flannel(1.00)<br/>pajama(1.00)", "pred answer": "denim", "question_id": 758425, "best approach": "image", "verif answer": "flannel", "anno approach": "image", "verif wiki answer": "plaid(0.5884)", "verif concept answer": "plaid(0.5159)", "verif image answer": "flannel(0.7273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075842.jpg"}, {"question": "what brand of grill is this", "gt answer": "webber(1.00)<br/>coleman(0.60)", "pred answer": "honda", "question_id": 3504975, "best approach": "image", "verif answer": "ice cream", "anno approach": "image", "verif wiki answer": "ice cream(0.6129)", "verif concept answer": "ice cream(0.6171)", "verif image answer": "webber(0.5101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350497.jpg"}, {"question": "is the man playing with a nintendo product or a sony product", "gt answer": "nintendo(1.00)", "pred answer": "wii", "question_id": 1602555, "best approach": "wiki, concept, image", "verif answer": "nintendo", "anno approach": "wiki", "verif wiki answer": "nintendo(0.7227)", "verif concept answer": "nintendo(0.7233)", "verif image answer": "nintendo(0.6984)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160255.jpg"}, {"question": "what type of machine is this", "gt answer": "conveyor belt(1.00)<br/>line(0.60)", "pred answer": "grill", "question_id": 3057035, "best approach": "", "verif answer": "coffee", "anno approach": "", "verif wiki answer": "coffee(0.5427)", "verif concept answer": "roast(0.5113)", "verif image answer": "coffee(0.5728)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305703.jpg"}, {"question": "brand of bus", "gt answer": "macbraynes(1.00)<br/>vw(0.60)", "pred answer": "ford", "question_id": 3004415, "best approach": "", "verif answer": "mercedes benz", "anno approach": "", "verif wiki answer": "mercedes benz(0.7181)", "verif concept answer": "mercedes benz(0.7180)", "verif image answer": "mercedes benz(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300441.jpg"}, {"question": "what children 's movie does this picture remind you of", "gt answer": "black stallion(1.00)", "pred answer": "horse race", "question_id": 2836665, "best approach": "", "verif answer": "dumbo", "anno approach": "", "verif wiki answer": "dumbo(0.7266)", "verif concept answer": "dumbo(0.7201)", "verif image answer": "dumbo(0.7158)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283666.jpg"}, {"question": "how is this toothbrush powered", "gt answer": "battery(1.00)<br/>electricity(1.00)", "pred answer": "electric", "question_id": 1960825, "best approach": "wiki, concept, image", "verif answer": "battery", "anno approach": "concept, wiki", "verif wiki answer": "battery(0.7091)", "verif concept answer": "battery(0.6888)", "verif image answer": "battery(0.6549)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196082.jpg"}, {"question": "why is the man 's arm like that", "gt answer": "throw(1.00)<br/>catch(0.60)", "pred answer": "catch", "question_id": 3226985, "best approach": "", "verif answer": "throw it", "anno approach": "", "verif wiki answer": "throw it(0.6971)", "verif concept answer": "throw it(0.7004)", "verif image answer": "throw it(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322698.jpg"}, {"question": "what grade is the child in", "gt answer": "kindergarten(1.00)<br/>first(0.60)", "pred answer": "1st", "question_id": 804725, "best approach": "concept, image", "verif answer": "lazy", "anno approach": "", "verif wiki answer": "lazy(0.5276)", "verif concept answer": "kindergarten(0.5050)", "verif image answer": "kindergarten(0.5111)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080472.jpg"}, {"question": "what photography technique was used to make this image", "gt answer": "fade(1.00)<br/>old(0.60)", "pred answer": "black and white", "question_id": 1745215, "best approach": "", "verif answer": "black and white", "anno approach": "", "verif wiki answer": "black and white(0.7296)", "verif concept answer": "black and white(0.7276)", "verif image answer": "black and white(0.6540)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174521.jpg"}, {"question": "what is being loaded in the airplane", "gt answer": "luggage(1.00)<br/>people(0.60)<br/>car(0.60)", "pred answer": "passenger", "question_id": 303455, "best approach": "wiki, concept", "verif answer": "airplane", "anno approach": "wiki", "verif wiki answer": "people(0.6754)", "verif concept answer": "people(0.6759)", "verif image answer": "airplane(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030345.jpg"}, {"question": "what game are they playing", "gt answer": "wiffleball(1.00)<br/>baseball(0.60)<br/>catch(0.60)", "pred answer": "disc golf", "question_id": 1431585, "best approach": "concept, image", "verif answer": "wiffleball", "anno approach": "image", "verif wiki answer": "baseball(0.5426)", "verif concept answer": "wiffleball(0.5925)", "verif image answer": "wiffleball(0.7112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143158.jpg"}, {"question": "what is the calve doing", "gt answer": "feed(1.00)<br/>drink(0.60)<br/>stand(0.60)<br/>nursing(0.60)", "pred answer": "walk", "question_id": 4079365, "best approach": "wiki, image", "verif answer": "feed", "anno approach": "wiki", "verif wiki answer": "feed(0.7163)", "verif concept answer": "stand(0.7095)", "verif image answer": "feed(0.6999)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407936.jpg"}, {"question": "what are the messages this object can leave behind called", "gt answer": "skywriting(1.00)<br/>contrail(0.60)<br/>steam(0.60)", "pred answer": "air", "question_id": 1685585, "best approach": "", "verif answer": "smoke", "anno approach": "", "verif wiki answer": "smoke(0.6409)", "verif concept answer": "smoke(0.6384)", "verif image answer": "smoke(0.6487)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168558.jpg"}, {"question": "what is the name of this sleeve type", "gt answer": "short(1.00)<br/>cap(0.60)", "pred answer": "tank top", "question_id": 153545, "best approach": "", "verif answer": "pixie", "anno approach": "", "verif wiki answer": "pixie(0.7158)", "verif concept answer": "pixie(0.7257)", "verif image answer": "pixie(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015354.jpg"}, {"question": "a female adult one of these is called a what", "gt answer": "mare(1.00)", "pred answer": "jockey", "question_id": 3176195, "best approach": "image", "verif answer": "giraffe", "anno approach": "image", "verif wiki answer": "giraffe(0.6793)", "verif concept answer": "herbivore(0.6694)", "verif image answer": "mare(0.6509)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317619.jpg"}, {"question": "what is the man wearing", "gt answer": "suit(1.00)<br/>tie(0.60)", "pred answer": "suit", "question_id": 1217205, "best approach": "wiki, concept", "verif answer": "suit", "anno approach": "wiki", "verif wiki answer": "suit(0.7304)", "verif concept answer": "suit(0.6694)", "verif image answer": "suit and tie(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000121720.jpg"}, {"question": "what feature on this clock is very different from most clocks", "gt answer": "letter(1.00)<br/>face(0.60)", "pred answer": "time", "question_id": 3978265, "best approach": "", "verif answer": "sun", "anno approach": "", "verif wiki answer": "sun(0.6309)", "verif concept answer": "sun(0.6515)", "verif image answer": "sun(0.6584)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397826.jpg"}, {"question": "who 's better at this sport venus or jordan", "gt answer": "venus(1.00)", "pred answer": "venus williams", "question_id": 3827075, "best approach": "", "verif answer": "venus williams", "anno approach": "", "verif wiki answer": "venus williams(0.6972)", "verif concept answer": "venus williams(0.6828)", "verif image answer": "venus williams(0.6751)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382707.jpg"}, {"question": "how long does it take for this animal to reach adulthood", "gt answer": "4 years(1.00)<br/>2 years(0.60)<br/>5 years(0.60)", "pred answer": "5 minutes", "question_id": 2651005, "best approach": "", "verif answer": "1 year", "anno approach": "", "verif wiki answer": "3 years(0.6924)", "verif concept answer": "3 years(0.6790)", "verif image answer": "1 year(0.7072)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265100.jpg"}, {"question": "what is the maker of these trucks", "gt answer": "volkswagen(1.00)", "pred answer": "ford", "question_id": 5474225, "best approach": "", "verif answer": "ford", "anno approach": "", "verif wiki answer": "ford(0.6412)", "verif concept answer": "ford(0.6723)", "verif image answer": "vw(0.6713)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000547422.jpg"}, {"question": "what is the name for this collection of images", "gt answer": "collage(1.00)", "pred answer": "beach", "question_id": 2117255, "best approach": "", "verif answer": "wine taster", "anno approach": "", "verif wiki answer": "wine taster(0.7190)", "verif concept answer": "wine taster(0.6858)", "verif image answer": "salad(0.7033)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000211725.jpg"}, {"question": "is the woman on the bike following or breaking the rules of the road", "gt answer": "break(1.00)", "pred answer": "safe", "question_id": 1625475, "best approach": "wiki, concept", "verif answer": "break", "anno approach": "concept, wiki", "verif wiki answer": "break(0.5951)", "verif concept answer": "break(0.6588)", "verif image answer": "light(0.5153)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162547.jpg"}, {"question": "what is the appropriate place to walk in this scene", "gt answer": "sidewalk(1.00)", "pred answer": "crosswalk", "question_id": 3219595, "best approach": "image", "verif answer": "sidewalk", "anno approach": "image", "verif wiki answer": "new york(0.5586)", "verif concept answer": "new york(0.6122)", "verif image answer": "sidewalk(0.6594)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321959.jpg"}, {"question": "what is one thing the person pictured would have to change in order to accomplish a task on the computer in her lap", "gt answer": "turn it on(1.00)", "pred answer": "intel", "question_id": 4943415, "best approach": "", "verif answer": "person", "anno approach": "", "verif wiki answer": "person(0.5643)", "verif concept answer": "person(0.5352)", "verif image answer": "person(0.6727)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494341.jpg"}, {"question": "what kind of group is named by the word seen here", "gt answer": "osage(1.00)<br/>camper(0.60)", "pred answer": "scout", "question_id": 1402845, "best approach": "wiki, concept, image", "verif answer": "camper", "anno approach": "wiki", "verif wiki answer": "camper(0.7223)", "verif concept answer": "camper(0.7265)", "verif image answer": "camper(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140284.jpg"}, {"question": "what species of bird is this", "gt answer": "pelican(0.60)<br/>egret(0.60)<br/>heron(1.00)<br/>stork(0.60)", "pred answer": "duck", "question_id": 977055, "best approach": "wiki, concept", "verif answer": "crane", "anno approach": "wiki", "verif wiki answer": "heron(0.6694)", "verif concept answer": "heron(0.6791)", "verif image answer": "crane(0.6958)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097705.jpg"}, {"question": "what type of television would display this fuzzy image", "gt answer": "tube tv(1.00)<br/>analog(0.60)", "pred answer": "old", "question_id": 388965, "best approach": "", "verif answer": "cell phone", "anno approach": "", "verif wiki answer": "cell phone(0.6170)", "verif concept answer": "flatscreen(0.6146)", "verif image answer": "cell phone(0.6080)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038896.jpg"}, {"question": "what is a young lamb called", "gt answer": "ewe(1.00)<br/>lamb(1.00)<br/>kid(0.60)", "pred answer": "calf", "question_id": 5013465, "best approach": "wiki, concept, image", "verif answer": "kid", "anno approach": "wiki", "verif wiki answer": "kid(0.6743)", "verif concept answer": "kid(0.6848)", "verif image answer": "kid(0.6905)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501346.jpg"}, {"question": "what part of this image is most likely to have been designed by a civil engineer", "gt answer": "bridge(1.00)", "pred answer": "boat", "question_id": 1668645, "best approach": "wiki, image", "verif answer": "bridge", "anno approach": "wiki", "verif wiki answer": "bridge(0.5057)", "verif concept answer": "forest(0.5058)", "verif image answer": "bridge(0.5162)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166864.jpg"}, {"question": "what brand is this tie", "gt answer": "halston(1.00)", "pred answer": "dell", "question_id": 2734665, "best approach": "wiki, concept, image", "verif answer": "halston", "anno approach": "", "verif wiki answer": "halston(0.6999)", "verif concept answer": "halston(0.7087)", "verif image answer": "halston(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273466.jpg"}, {"question": "what country is this place", "gt answer": "nigeria(1.00)<br/>india(0.60)", "pred answer": "china", "question_id": 4334415, "best approach": "", "verif answer": "brazil", "anno approach": "", "verif wiki answer": "thailand(0.6783)", "verif concept answer": "thailand(0.6679)", "verif image answer": "brazil(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433441.jpg"}, {"question": "", "gt answer": "$10000(0.60)", "pred answer": "20th", "question_id": 1889025, "best approach": "wiki, concept, image", "verif answer": "$10000", "anno approach": "image", "verif wiki answer": "$10000(0.5807)", "verif concept answer": "$10000(0.5922)", "verif image answer": "$10000(0.6244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188902.jpg"}, {"question": "what type of flower is on the table in this photo", "gt answer": "lily(1.00)<br/>rose(0.60)", "pred answer": "rose", "question_id": 5267945, "best approach": "", "verif answer": "hydrangea", "anno approach": "", "verif wiki answer": "hydrangea(0.7256)", "verif concept answer": "hydrangea(0.7078)", "verif image answer": "hydrangea(0.7089)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526794.jpg"}, {"question": "", "gt answer": "brick tile(0.60)<br/>dark(0.60)", "pred answer": "shingle", "question_id": 1722555, "best approach": "image", "verif answer": "brick tile", "anno approach": "image", "verif wiki answer": "blue(0.6357)", "verif concept answer": "blue(0.6382)", "verif image answer": "brick tile(0.6445)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000172255.jpg"}, {"question": "what emotion is this person feeling", "gt answer": "anger(1.00)<br/>sad(0.60)", "pred answer": "happiness", "question_id": 2888535, "best approach": "", "verif answer": "despair", "anno approach": "", "verif wiki answer": "despair(0.6638)", "verif concept answer": "despair(0.6757)", "verif image answer": "fear(0.5812)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288853.jpg"}, {"question": "what sport is performed by jumping out of a vehicle like this one", "gt answer": "parachute(1.00)<br/>taxi(0.60)", "pred answer": "fly", "question_id": 2059185, "best approach": "", "verif answer": "rope", "anno approach": "", "verif wiki answer": "rope(0.7142)", "verif concept answer": "rope(0.6700)", "verif image answer": "rope(0.5898)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205918.jpg"}, {"question": "what is the name of the bridge in the background", "gt answer": "golden gate(1.00)", "pred answer": "golden gate", "question_id": 598435, "best approach": "concept, image", "verif answer": "golden gate", "anno approach": "", "verif wiki answer": "san francisco(0.7191)", "verif concept answer": "golden gate(0.7230)", "verif image answer": "golden gate(0.7237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059843.jpg"}, {"question": "who sponsors this player", "gt answer": "nike(1.00)<br/>adidas(1.00)<br/>tennis(0.60)", "pred answer": "adidas", "question_id": 3442545, "best approach": "image", "verif answer": "adidas", "anno approach": "image", "verif wiki answer": "tennis(0.6882)", "verif concept answer": "tennis(0.6936)", "verif image answer": "adidas(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344254.jpg"}, {"question": "what type of material is the wall made of", "gt answer": "sheetrock(1.00)<br/>concrete(0.60)", "pred answer": "stone", "question_id": 400715, "best approach": "", "verif answer": "tile", "anno approach": "", "verif wiki answer": "stone(0.6622)", "verif concept answer": "stone(0.6551)", "verif image answer": "tile(0.7092)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040071.jpg"}, {"question": "what is the temperature like", "gt answer": "cool(1.00)<br/>hot(0.60)<br/>cold(0.60)<br/>chilly(0.60)", "pred answer": "cold", "question_id": 1465105, "best approach": "wiki, concept, image", "verif answer": "hot", "anno approach": "wiki", "verif wiki answer": "hot(0.7107)", "verif concept answer": "hot(0.7040)", "verif image answer": "hot(0.7103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146510.jpg"}, {"question": "which action depicted is a sign of respect", "gt answer": "hat over heart(1.00)", "pred answer": "helmet", "question_id": 4867135, "best approach": "wiki, image", "verif answer": "hat over heart", "anno approach": "image", "verif wiki answer": "hat over heart(0.6383)", "verif concept answer": "backhand(0.6501)", "verif image answer": "hat over heart(0.7018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000486713.jpg"}, {"question": "what section of the grocery store would these be in", "gt answer": "produce(1.00)<br/>fruit(0.60)", "pred answer": "kitchen", "question_id": 791725, "best approach": "", "verif answer": "supermarket", "anno approach": "", "verif wiki answer": "supermarket(0.7298)", "verif concept answer": "supermarket(0.7246)", "verif image answer": "supermarket(0.6305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079172.jpg"}, {"question": "what object in the photo is used to remember dictation", "gt answer": "recorder(1.00)<br/>gun(0.60)", "pred answer": "hat", "question_id": 5635455, "best approach": "wiki", "verif answer": "shadow", "anno approach": "wiki", "verif wiki answer": "recorder(0.6719)", "verif concept answer": "shadow(0.7134)", "verif image answer": "shadow(0.6253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000563545.jpg"}, {"question": "what type of people drive the vehicle on the left", "gt answer": "firemen(1.00)<br/>firefight(0.60)<br/>human(0.60)", "pred answer": "adult", "question_id": 2376995, "best approach": "", "verif answer": "passenger", "anno approach": "", "verif wiki answer": "passenger(0.6646)", "verif concept answer": "passenger(0.6792)", "verif image answer": "passenger(0.5761)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237699.jpg"}, {"question": "what is the thing over the water for", "gt answer": "bridge(1.00)<br/>train track(0.60)<br/>cross(0.60)", "pred answer": "control traffic", "question_id": 3989675, "best approach": "", "verif answer": "train bridge", "anno approach": "", "verif wiki answer": "train bridge(0.7074)", "verif concept answer": "train bridge(0.7185)", "verif image answer": "train bridge(0.5901)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398967.jpg"}, {"question": "how long can their horns grow", "gt answer": "2 feet(1.00)<br/>15 feet(0.60)<br/>3 feet(0.60)", "pred answer": "8 inches", "question_id": 5503565, "best approach": "", "verif answer": "11 feet", "anno approach": "", "verif wiki answer": "11 feet(0.5081)", "verif concept answer": "11 feet(0.5177)", "verif image answer": "11 feet(0.6632)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550356.jpg"}, {"question": "is this legal or illegal", "gt answer": "legal(1.00)<br/>illegal(0.60)", "pred answer": "legal", "question_id": 2433825, "best approach": "image", "verif answer": "legal", "anno approach": "image", "verif wiki answer": "illegal(0.6544)", "verif concept answer": "illegal(0.7270)", "verif image answer": "legal(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243382.jpg"}, {"question": "the name on the first bus is the name of a coffee worker in what show", "gt answer": "friend(1.00)<br/>central park(0.60)", "pred answer": "greyhound", "question_id": 2214755, "best approach": "wiki, concept", "verif answer": "couple", "anno approach": "concept, wiki", "verif wiki answer": "friend(0.5532)", "verif concept answer": "friend(0.5906)", "verif image answer": "couple(0.6413)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221475.jpg"}, {"question": "what is the size of this bed", "gt answer": "queen(1.00)<br/>king(0.60)", "pred answer": "full", "question_id": 3255845, "best approach": "", "verif answer": "full", "anno approach": "", "verif wiki answer": "full(0.7272)", "verif concept answer": "full(0.7288)", "verif image answer": "full(0.7142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325584.jpg"}, {"question": "what was the use of that item in his hand", "gt answer": "take picture(1.00)<br/>picture(0.60)", "pred answer": "camera", "question_id": 4101905, "best approach": "", "verif answer": "reflector", "anno approach": "", "verif wiki answer": "reflector(0.5778)", "verif concept answer": "reflector(0.5802)", "verif image answer": "reflector(0.6288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000410190.jpg"}, {"question": "what kind of plane is this", "gt answer": "private(1.00)<br/>seaplane(0.60)<br/>commercial(0.60)", "pred answer": "propeller", "question_id": 2455035, "best approach": "wiki, concept, image", "verif answer": "seaplane", "anno approach": "wiki", "verif wiki answer": "commercial(0.6182)", "verif concept answer": "seaplane(0.6440)", "verif image answer": "commercial(0.6341)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245503.jpg"}, {"question": "how fast does this vehicle typically go", "gt answer": "80 mph(1.00)<br/>fast(0.60)", "pred answer": "100 mph", "question_id": 4368785, "best approach": "", "verif answer": "100 mph", "anno approach": "", "verif wiki answer": "100 mph(0.6683)", "verif concept answer": "100 mph(0.6525)", "verif image answer": "100 mph(0.6912)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436878.jpg"}, {"question": "what vegetables were used in the creation of this food", "gt answer": "pepper(1.00)", "pred answer": "pepper", "question_id": 2756305, "best approach": "", "verif answer": "spinach", "anno approach": "", "verif wiki answer": "spinach(0.6192)", "verif concept answer": "spinach(0.7016)", "verif image answer": "spinach(0.7060)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000275630.jpg"}, {"question": "what materials where used for the lights", "gt answer": "glass(1.00)", "pred answer": "paint", "question_id": 4758045, "best approach": "image", "verif answer": "metal", "anno approach": "image", "verif wiki answer": "metal(0.6697)", "verif concept answer": "lcd(0.5385)", "verif image answer": "glass(0.6309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475804.jpg"}, {"question": "what type of skateboard is being used", "gt answer": "regular(1.00)<br/>small(0.60)<br/>van(0.60)", "pred answer": "grind", "question_id": 2734255, "best approach": "", "verif answer": "kickflip", "anno approach": "", "verif wiki answer": "kickflip(0.7236)", "verif concept answer": "kickflip(0.7259)", "verif image answer": "kickflip(0.6939)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273425.jpg"}, {"question": "who makes the video game console that the people are playing", "gt answer": "nintendo(1.00)<br/>wii(1.00)", "pred answer": "wii", "question_id": 603505, "best approach": "wiki, concept, image", "verif answer": "nintendo", "anno approach": "wiki", "verif wiki answer": "nintendo(0.7304)", "verif concept answer": "nintendo(0.7303)", "verif image answer": "nintendo(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060350.jpg"}, {"question": "who is holding the umbrella", "gt answer": "man(1.00)", "pred answer": "old woman", "question_id": 2656255, "best approach": "", "verif answer": "rafael nadal", "anno approach": "", "verif wiki answer": "rafael nadal(0.7301)", "verif concept answer": "rafael nadal(0.7284)", "verif image answer": "rafael nadal(0.7053)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265625.jpg"}, {"question": "what is the name of this type of cake", "gt answer": "sponge(1.00)<br/>carrot(0.60)", "pred answer": "house", "question_id": 1769235, "best approach": "image", "verif answer": "sponge", "anno approach": "image", "verif wiki answer": "stew(0.5367)", "verif concept answer": "stew(0.5486)", "verif image answer": "sponge(0.5863)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176923.jpg"}, {"question": "what are the green items on the plate", "gt answer": "pickle(1.00)", "pred answer": "pickle", "question_id": 5509125, "best approach": "wiki, concept, image", "verif answer": "pickle", "anno approach": "wiki", "verif wiki answer": "pickle(0.7296)", "verif concept answer": "pickle(0.7297)", "verif image answer": "pickle(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550912.jpg"}, {"question": "what 's the name of the flowers in the middle pot", "gt answer": "daisy(1.00)<br/>rose(0.60)", "pred answer": "rose", "question_id": 1450875, "best approach": "wiki, concept, image", "verif answer": "rose", "anno approach": "wiki", "verif wiki answer": "rose(0.6861)", "verif concept answer": "rose(0.6776)", "verif image answer": "rose(0.6965)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145087.jpg"}, {"question": "what fruit is shown", "gt answer": "lime(1.00)<br/>banana(0.60)", "pred answer": "cucumber", "question_id": 4927295, "best approach": "", "verif answer": "blueberry", "anno approach": "", "verif wiki answer": "blueberry(0.5029)", "verif concept answer": "blueberry(0.5080)", "verif image answer": "blueberry(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492729.jpg"}, {"question": "what is this man on", "gt answer": "snowboard(1.00)<br/>snow(0.60)", "pred answer": "ski", "question_id": 2361415, "best approach": "image", "verif answer": "snow board", "anno approach": "image", "verif wiki answer": "snow board(0.6657)", "verif concept answer": "snow board(0.6519)", "verif image answer": "snow(0.6487)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236141.jpg"}, {"question": "how long does a soccer game last", "gt answer": "90 minutes(1.00)<br/>1 hour(0.60)<br/>hour(0.60)", "pred answer": "1 year", "question_id": 412315, "best approach": "concept", "verif answer": "6 hours", "anno approach": "concept", "verif wiki answer": "15 minutes(0.6068)", "verif concept answer": "hour(0.5892)", "verif image answer": "6 hours(0.6300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041231.jpg"}, {"question": "what plant is put into these objects", "gt answer": "flower(1.00)<br/>bamboo(0.60)", "pred answer": "flower", "question_id": 3686595, "best approach": "wiki, concept, image", "verif answer": "flower", "anno approach": "image, wiki", "verif wiki answer": "flower(0.6628)", "verif concept answer": "flower(0.6833)", "verif image answer": "flower(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000368659.jpg"}, {"question": "what is the lifespan of this animal", "gt answer": "20 years(1.00)<br/>25 years(0.60)<br/>12 years(0.60)<br/>5 years(0.60)", "pred answer": "30 years", "question_id": 3573015, "best approach": "wiki, concept, image", "verif answer": "12 years", "anno approach": "image, wiki", "verif wiki answer": "5 years(0.5423)", "verif concept answer": "12 years(0.5672)", "verif image answer": "12 years(0.6277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357301.jpg"}, {"question": "what stage of life would this animal be in", "gt answer": "puppy(1.00)<br/>infant(1.00)<br/>early(0.60)", "pred answer": "15 years", "question_id": 3851865, "best approach": "", "verif answer": "2 months", "anno approach": "", "verif wiki answer": "2 months(0.6242)", "verif concept answer": "2 months(0.6414)", "verif image answer": "2 months(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385186.jpg"}, {"question": "what meat is this", "gt answer": "shrimp(1.00)", "pred answer": "beef", "question_id": 843395, "best approach": "image", "verif answer": "shrimp", "anno approach": "image", "verif wiki answer": "chicken(0.6842)", "verif concept answer": "pasta(0.6513)", "verif image answer": "shrimp(0.7134)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084339.jpg"}, {"question": "what is this animal doing", "gt answer": "bath(1.00)<br/>cross river(0.60)", "pred answer": "sleep", "question_id": 5456895, "best approach": "wiki, concept", "verif answer": "cross river", "anno approach": "", "verif wiki answer": "cross river(0.7303)", "verif concept answer": "cross river(0.7306)", "verif image answer": "walk(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545689.jpg"}, {"question": "what is he wearing around his neck", "gt answer": "bib(1.00)", "pred answer": "necklace", "question_id": 1739985, "best approach": "", "verif answer": "necklace", "anno approach": "", "verif wiki answer": "necklace(0.5568)", "verif concept answer": "necklace(0.6957)", "verif image answer": "necklace(0.6888)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000173998.jpg"}, {"question": "what do you think their job is", "gt answer": "fisherman(1.00)<br/>sail(0.60)<br/>military(0.60)", "pred answer": "fish", "question_id": 3462665, "best approach": "image", "verif answer": "fisherman", "anno approach": "image", "verif wiki answer": "military(0.6499)", "verif concept answer": "cargo(0.6671)", "verif image answer": "fisherman(0.6997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346266.jpg"}, {"question": "what popular alcoholic drink features a stalk the same color as this couch", "gt answer": "bloody mary(1.00)<br/>beer(0.60)<br/>vodka(0.60)", "pred answer": "lemonade", "question_id": 5413195, "best approach": "wiki, concept, image", "verif answer": "bloody mary", "anno approach": "wiki", "verif wiki answer": "bloody mary(0.7282)", "verif concept answer": "bloody mary(0.7040)", "verif image answer": "bloody mary(0.7169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541319.jpg"}, {"question": "how often are you supposed to water this surface", "gt answer": "daily(1.00)", "pred answer": "daily", "question_id": 1301885, "best approach": "wiki, concept, image", "verif answer": "daily", "anno approach": "image, wiki", "verif wiki answer": "daily(0.5558)", "verif concept answer": "daily(0.5306)", "verif image answer": "daily(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130188.jpg"}, {"question": "what kind of shape or style is the kite", "gt answer": "dragon(1.00)<br/>bird(0.60)", "pred answer": "square", "question_id": 853495, "best approach": "", "verif answer": "octopus", "anno approach": "", "verif wiki answer": "octopus(0.7309)", "verif concept answer": "octopus(0.7295)", "verif image answer": "octopus(0.7065)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085349.jpg"}, {"question": "what position is the person playing in blue", "gt answer": "catcher(1.00)<br/>umpire(0.60)", "pred answer": "batter", "question_id": 4121345, "best approach": "", "verif answer": "glove", "anno approach": "", "verif wiki answer": "glove(0.6708)", "verif concept answer": "glove(0.6189)", "verif image answer": "glove(0.7208)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412134.jpg"}, {"question": "what is the style of jean that is worn by the women", "gt answer": "bell bottom(1.00)", "pred answer": "jean", "question_id": 2771505, "best approach": "", "verif answer": "down", "anno approach": "", "verif wiki answer": "down(0.6381)", "verif concept answer": "down(0.6318)", "verif image answer": "classic(0.5706)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277150.jpg"}, {"question": "what continent are these animals native to", "gt answer": "africa(1.00)", "pred answer": "africa", "question_id": 1187245, "best approach": "wiki, concept", "verif answer": "africa", "anno approach": "wiki", "verif wiki answer": "africa(0.6608)", "verif concept answer": "africa(0.6488)", "verif image answer": "kenya(0.6453)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118724.jpg"}, {"question": "why would we suspect this picture what not shot within the last decade", "gt answer": "color(1.00)", "pred answer": "mirror", "question_id": 4329475, "best approach": "", "verif answer": "trunk", "anno approach": "", "verif wiki answer": "trunk(0.6627)", "verif concept answer": "trunk(0.5531)", "verif image answer": "trunk(0.5521)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432947.jpg"}, {"question": "what kind of horses are these", "gt answer": "stallion(1.00)<br/>draft(0.60)", "pred answer": "arabian", "question_id": 3443195, "best approach": "", "verif answer": "clydesdale", "anno approach": "", "verif wiki answer": "calico(0.6664)", "verif concept answer": "calico(0.6732)", "verif image answer": "clydesdale(0.7025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344319.jpg"}, {"question": "what man made vehicle could follow these animals", "gt answer": "atv(1.00)<br/>4 wheeler(0.60)<br/>bike(0.60)<br/>helicopter(0.60)", "pred answer": "bus", "question_id": 5551025, "best approach": "wiki, concept, image", "verif answer": "helicopter", "anno approach": "wiki", "verif wiki answer": "helicopter(0.7271)", "verif concept answer": "helicopter(0.7237)", "verif image answer": "helicopter(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555102.jpg"}, {"question": "what superhero is on the box", "gt answer": "batman(1.00)", "pred answer": "mickey mouse", "question_id": 4650605, "best approach": "", "verif answer": "wonder woman", "anno approach": "", "verif wiki answer": "wonder woman(0.7016)", "verif concept answer": "wonder woman(0.7044)", "verif image answer": "wonder woman(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465060.jpg"}, {"question": "what does this sign show", "gt answer": "direct(1.00)<br/>arrow(0.60)<br/>turn(0.60)<br/>speed limit(0.60)", "pred answer": "park", "question_id": 1180815, "best approach": "image", "verif answer": "speed limit", "anno approach": "image", "verif wiki answer": "direction(0.5316)", "verif concept answer": "direction(0.5438)", "verif image answer": "speed limit(0.5603)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118081.jpg"}, {"question": "can you guess the place name shown in this picture", "gt answer": "bus stop(1.00)", "pred answer": "ford", "question_id": 1696405, "best approach": "wiki, concept, image", "verif answer": "bus stop", "anno approach": "wiki", "verif wiki answer": "bus stop(0.7057)", "verif concept answer": "bus stop(0.7255)", "verif image answer": "bus stop(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169640.jpg"}, {"question": "is this legal or illegal", "gt answer": "legal(1.00)<br/>illegal(0.60)", "pred answer": "illegal", "question_id": 3316805, "best approach": "image", "verif answer": "legal", "anno approach": "image", "verif wiki answer": "illegal(0.7187)", "verif concept answer": "illegal(0.7288)", "verif image answer": "legal(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331680.jpg"}, {"question": "", "gt answer": "al fresco(0.60)<br/>dome(0.60)<br/>stone(0.60)", "pred answer": "church", "question_id": 690545, "best approach": "wiki, concept", "verif answer": "arch", "anno approach": "wiki", "verif wiki answer": "dome(0.6220)", "verif concept answer": "dome(0.5729)", "verif image answer": "arch(0.6284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069054.jpg"}, {"question": "what are the wood structures at the top called", "gt answer": "cabinet(1.00)<br/>counter(0.60)", "pred answer": "beam", "question_id": 4806835, "best approach": "", "verif answer": "fridge", "anno approach": "", "verif wiki answer": "fridge(0.5007)", "verif concept answer": "fridge(0.5003)", "verif image answer": "fridge(0.5006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480683.jpg"}, {"question": "what type of tv is this", "gt answer": "analog(1.00)<br/>tube tv(0.60)", "pred answer": "flat screen", "question_id": 833525, "best approach": "", "verif answer": "flatscreen", "anno approach": "", "verif wiki answer": "flatscreen(0.6587)", "verif concept answer": "flatscreen(0.7008)", "verif image answer": "flatscreen(0.6462)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083352.jpg"}, {"question": "in what style is the protein in this dish cooked", "gt answer": "sunny side up(1.00)<br/>egg(0.60)", "pred answer": "grilled", "question_id": 5610825, "best approach": "wiki, concept, image", "verif answer": "egg", "anno approach": "wiki", "verif wiki answer": "egg(0.6861)", "verif concept answer": "egg(0.6579)", "verif image answer": "egg(0.6495)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561082.jpg"}, {"question": "how fast does this vehicle go", "gt answer": "100 mph(1.00)<br/>80 mph(0.60)", "pred answer": "200 mph", "question_id": 1498335, "best approach": "image", "verif answer": "80 mph", "anno approach": "image", "verif wiki answer": "80 mph(0.6925)", "verif concept answer": "30 mph(0.6429)", "verif image answer": "100 mph(0.5989)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149833.jpg"}, {"question": "aww what kind of cat is that", "gt answer": "tabby(1.00)<br/>domestic(1.00)", "pred answer": "calico", "question_id": 3412705, "best approach": "", "verif answer": "domestic shorthair", "anno approach": "", "verif wiki answer": "american shorthair(0.7136)", "verif concept answer": "domestic shorthair(0.7117)", "verif image answer": "domestic shorthair(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341270.jpg"}, {"question": "what company manufacture the television in this picture", "gt answer": "sony(1.00)<br/>samsung(0.60)<br/>lg(0.60)<br/>saturn(0.60)", "pred answer": "sony", "question_id": 776245, "best approach": "", "verif answer": "motorola", "anno approach": "", "verif wiki answer": "motorola(0.6601)", "verif concept answer": "motorola(0.6547)", "verif image answer": "motorola(0.6811)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077624.jpg"}, {"question": "is this a public or private bathroom", "gt answer": "private(1.00)<br/>public(0.60)", "pred answer": "public", "question_id": 4156025, "best approach": "wiki, concept, image", "verif answer": "public", "anno approach": "concept, wiki", "verif wiki answer": "public(0.7138)", "verif concept answer": "public(0.7294)", "verif image answer": "public(0.5274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415602.jpg"}, {"question": "what is the name of the tournament for this sport in england", "gt answer": "wimbledon(1.00)<br/>tennis(0.60)<br/>open(0.60)", "pred answer": "tennis", "question_id": 2304335, "best approach": "wiki, concept, image", "verif answer": "wimbledon", "anno approach": "wiki", "verif wiki answer": "wimbledon(0.7214)", "verif concept answer": "wimbledon(0.7242)", "verif image answer": "wimbledon(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000230433.jpg"}, {"question": "what does the flag in this represent", "gt answer": "gay pride(1.00)", "pred answer": "pirate", "question_id": 4966465, "best approach": "", "verif answer": "graduation", "anno approach": "", "verif wiki answer": "graduation(0.7041)", "verif concept answer": "graduation(0.6940)", "verif image answer": "graduation(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496646.jpg"}, {"question": "what candy resembles the man 's tie", "gt answer": "candy cane(1.00)", "pred answer": "doughnut", "question_id": 2783475, "best approach": "image", "verif answer": "peanut", "anno approach": "image", "verif wiki answer": "peanut(0.5007)", "verif concept answer": "peanut(0.5001)", "verif image answer": "candy cane(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278347.jpg"}, {"question": "what type of truck is this", "gt answer": "garbage(1.00)<br/>dump truck(0.60)<br/>garbage truck(0.60)", "pred answer": "tow", "question_id": 127265, "best approach": "wiki", "verif answer": "dump", "anno approach": "wiki", "verif wiki answer": "garbage(0.6948)", "verif concept answer": "dump(0.7089)", "verif image answer": "dump(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012726.jpg"}, {"question": "what state you think this is", "gt answer": "nevada(1.00)<br/>los angeles(0.60)", "pred answer": "texas", "question_id": 1203755, "best approach": "", "verif answer": "florida", "anno approach": "", "verif wiki answer": "florida(0.7250)", "verif concept answer": "florida(0.6904)", "verif image answer": "washington(0.6019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000120375.jpg"}, {"question": "what type of phone is this", "gt answer": "cell(1.00)", "pred answer": "flip phone", "question_id": 2897905, "best approach": "", "verif answer": "smartphone", "anno approach": "", "verif wiki answer": "smartphone(0.6483)", "verif concept answer": "flip(0.6259)", "verif image answer": "smartphone(0.6525)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000289790.jpg"}, {"question": "what is the name of the disney version of the animal", "gt answer": "dumbo(1.00)", "pred answer": "tantor", "question_id": 4342345, "best approach": "", "verif answer": "lion king", "anno approach": "", "verif wiki answer": "lion king(0.7282)", "verif concept answer": "lion king(0.7302)", "verif image answer": "lion king(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434234.jpg"}, {"question": "why is this person wearing a headband", "gt answer": "sweat(1.00)", "pred answer": "watch", "question_id": 1396865, "best approach": "", "verif answer": "sweat band", "anno approach": "", "verif wiki answer": "sweat band(0.7219)", "verif concept answer": "sweat band(0.5264)", "verif image answer": "serve(0.5053)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139686.jpg"}, {"question": "which two continents are these animals native to", "gt answer": "africa and asia(1.00)<br/>africa(0.60)<br/>asia and africa(0.60)", "pred answer": "africa", "question_id": 2742865, "best approach": "wiki, concept", "verif answer": "africa", "anno approach": "wiki", "verif wiki answer": "africa and asia(0.6665)", "verif concept answer": "africa and asia(0.6433)", "verif image answer": "africa(0.6991)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274286.jpg"}, {"question": "how many miles of track for that type of transportation exists", "gt answer": "million(1.00)<br/>thousand(0.60)<br/>1500(0.60)", "pred answer": "9", "question_id": 4258365, "best approach": "", "verif answer": "6", "anno approach": "", "verif wiki answer": "6(0.7038)", "verif concept answer": "6(0.6958)", "verif image answer": "6(0.6981)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425836.jpg"}, {"question": "which famous mary poppins song talks about flying one of these", "gt answer": "let go fly kite(1.00)", "pred answer": "mary poppins", "question_id": 665395, "best approach": "wiki, concept, image", "verif answer": "let go fly kite", "anno approach": "concept, wiki", "verif wiki answer": "let go fly kite(0.6633)", "verif concept answer": "let go fly kite(0.6925)", "verif image answer": "let go fly kite(0.5631)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000066539.jpg"}, {"question": "when was the object in this picture invented", "gt answer": "1948(1.00)<br/>1960's(0.60)", "pred answer": "1970", "question_id": 346805, "best approach": "", "verif answer": "1960", "anno approach": "", "verif wiki answer": "1960(0.6005)", "verif concept answer": "1968(0.5997)", "verif image answer": "1946(0.5927)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000034680.jpg"}, {"question": "what part of the body do you wear the rightmost objects on", "gt answer": "neck(1.00)", "pred answer": "leg", "question_id": 160095, "best approach": "", "verif answer": "arm", "anno approach": "", "verif wiki answer": "arm(0.6777)", "verif concept answer": "arm(0.6448)", "verif image answer": "arm(0.6570)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016009.jpg"}, {"question": "what breed are these two ducks", "gt answer": "american pekin(1.00)", "pred answer": "pelican", "question_id": 1692825, "best approach": "wiki, concept", "verif answer": "american pekin", "anno approach": "", "verif wiki answer": "american pekin(0.7244)", "verif concept answer": "american pekin(0.7241)", "verif image answer": "pelican(0.6944)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169282.jpg"}, {"question": "what is this thing doing", "gt answer": "land(1.00)<br/>fly(1.00)<br/>sit(0.60)", "pred answer": "take off", "question_id": 1479695, "best approach": "wiki", "verif answer": "land", "anno approach": "wiki", "verif wiki answer": "land(0.7160)", "verif concept answer": "take off(0.6934)", "verif image answer": "take off(0.6493)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147969.jpg"}, {"question": "what is the dog laying on", "gt answer": "blanket(1.00)", "pred answer": "bed", "question_id": 4884405, "best approach": "wiki, concept, image", "verif answer": "blanket", "anno approach": "wiki", "verif wiki answer": "blanket(0.5741)", "verif concept answer": "blanket(0.5520)", "verif image answer": "blanket(0.5394)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488440.jpg"}, {"question": "what type of cake is this", "gt answer": "vanilla(1.00)<br/>birthday(0.60)<br/>carrot cake(0.60)", "pred answer": "stuffed", "question_id": 1502546, "best approach": "wiki, concept, image", "verif answer": "carrot cake", "anno approach": "concept, wiki", "verif wiki answer": "carrot cake(0.6439)", "verif concept answer": "carrot cake(0.6844)", "verif image answer": "birthday(0.6639)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000150254.jpg"}, {"question": "how far into the air do you think this snowboarder is", "gt answer": "30 feet(1.00)<br/>20 feet(1.00)", "pred answer": "3 feet", "question_id": 4151315, "best approach": "", "verif answer": "3 feet", "anno approach": "", "verif wiki answer": "3 feet(0.7021)", "verif concept answer": "3 feet(0.6402)", "verif image answer": "3 feet(0.5012)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415131.jpg"}, {"question": "what is the vehicle on the right side called", "gt answer": "train(1.00)<br/>scooter(0.60)", "pred answer": "bus", "question_id": 4542055, "best approach": "wiki", "verif answer": "scooter", "anno approach": "wiki", "verif wiki answer": "train(0.6730)", "verif concept answer": "scooter(0.6974)", "verif image answer": "scooter(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000454205.jpg"}, {"question": "what is the white truck used for", "gt answer": "taxi(1.00)<br/>haul(0.60)<br/>delivery(0.60)<br/>transport(0.60)", "pred answer": "tow", "question_id": 4558605, "best approach": "wiki, concept, image", "verif answer": "transport", "anno approach": "wiki", "verif wiki answer": "transport(0.6862)", "verif concept answer": "transport(0.6384)", "verif image answer": "transport(0.6606)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455860.jpg"}, {"question": "what type of event is this", "gt answer": "motorcycle rally(1.00)<br/>rally(0.60)", "pred answer": "motorcycle", "question_id": 389235, "best approach": "wiki, concept, image", "verif answer": "rally", "anno approach": "wiki", "verif wiki answer": "rally(0.6884)", "verif concept answer": "rally(0.6718)", "verif image answer": "rally(0.6494)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038923.jpg"}, {"question": "how often does the typical american ride to work in this manner", "gt answer": "never(1.00)", "pred answer": "daily", "question_id": 1809685, "best approach": "wiki, concept", "verif answer": "never", "anno approach": "wiki", "verif wiki answer": "never(0.5515)", "verif concept answer": "never(0.5279)", "verif image answer": "dinner(0.5166)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180968.jpg"}, {"question": "what is on the round plate", "gt answer": "croissant(1.00)<br/>pastry(0.60)", "pred answer": "lemon", "question_id": 3161705, "best approach": "", "verif answer": "tea time", "anno approach": "", "verif wiki answer": "tea time(0.7152)", "verif concept answer": "tea time(0.7220)", "verif image answer": "tea time(0.7031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316170.jpg"}, {"question": "what is the name of the items inside the cup", "gt answer": "candy cane(1.00)", "pred answer": "mug", "question_id": 4696485, "best approach": "", "verif answer": "peanut", "anno approach": "", "verif wiki answer": "peanut(0.6547)", "verif concept answer": "peanut(0.6614)", "verif image answer": "peanut(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469648.jpg"}, {"question": "what are this baby animals called", "gt answer": "ewe(1.00)<br/>calf(0.60)<br/>lamb(1.00)", "pred answer": "lamb", "question_id": 4709775, "best approach": "", "verif answer": "kid", "anno approach": "", "verif wiki answer": "kid(0.7280)", "verif concept answer": "kid(0.7273)", "verif image answer": "kid(0.6164)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470977.jpg"}, {"question": "what kind of bird is this", "gt answer": "finch(1.00)<br/>woodpecker(0.60)<br/>toucan(0.60)<br/>robin(0.60)", "pred answer": "finch", "question_id": 1297195, "best approach": "image", "verif answer": "toucan", "anno approach": "image", "verif wiki answer": "parrot(0.6518)", "verif concept answer": "parrot(0.6667)", "verif image answer": "toucan(0.6886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129719.jpg"}, {"question": "the vehicle pictured is good for what kind of transportation", "gt answer": "public(1.00)", "pred answer": "bus", "question_id": 1978515, "best approach": "", "verif answer": "tour bus", "anno approach": "", "verif wiki answer": "tour bus(0.7115)", "verif concept answer": "tour bus(0.7110)", "verif image answer": "tour bus(0.6795)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197851.jpg"}, {"question": "what 's it called if one of these crashes", "gt answer": "train crash(1.00)<br/>death(0.60)<br/>crash(0.60)", "pred answer": "transport", "question_id": 2450865, "best approach": "wiki", "verif answer": "slice", "anno approach": "wiki", "verif wiki answer": "death(0.5477)", "verif concept answer": "slice(0.5789)", "verif image answer": "slice(0.6392)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245086.jpg"}, {"question": "what form of eye wear does she have on", "gt answer": "sunglasses(1.00)", "pred answer": "goggle", "question_id": 3732595, "best approach": "", "verif answer": "goggle", "anno approach": "", "verif wiki answer": "goggle(0.7307)", "verif concept answer": "goggle(0.7307)", "verif image answer": "goggle(0.7129)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373259.jpg"}, {"question": "what company is responsible for the sign on the right", "gt answer": "under armour(1.00)", "pred answer": "factory", "question_id": 92875, "best approach": "wiki, concept, image", "verif answer": "under armour", "anno approach": "image", "verif wiki answer": "under armour(0.5709)", "verif concept answer": "under armour(0.5883)", "verif image answer": "under armour(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009287.jpg"}, {"question": "where is this taken", "gt answer": "circus(1.00)<br/>parade(0.60)", "pred answer": "india", "question_id": 3558575, "best approach": "image", "verif answer": "parade", "anno approach": "image", "verif wiki answer": "parade(0.6916)", "verif concept answer": "elephant(0.6876)", "verif image answer": "circus(0.6829)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355857.jpg"}, {"question": "of the objects in the background what is the name of the tallest one in the world", "gt answer": "mount everest(1.00)<br/>mountain(0.60)", "pred answer": "alp", "question_id": 2517585, "best approach": "image", "verif answer": "mount saint elias", "anno approach": "image", "verif wiki answer": "mount saint elias(0.6260)", "verif concept answer": "mount saint elias(0.5034)", "verif image answer": "mountain(0.5011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251758.jpg"}, {"question": "how long will the flowers last", "gt answer": "week(1.00)<br/>3 days(0.60)<br/>2 weeks(0.60)", "pred answer": "4 days", "question_id": 5617565, "best approach": "concept", "verif answer": "2 days", "anno approach": "concept", "verif wiki answer": "5 days(0.5921)", "verif concept answer": "3 days(0.5504)", "verif image answer": "2 days(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561756.jpg"}, {"question": "what type of light bulb is in the lamp", "gt answer": "led(1.00)", "pred answer": "spot light", "question_id": 3439995, "best approach": "", "verif answer": "string", "anno approach": "", "verif wiki answer": "samsung(0.6132)", "verif concept answer": "samsung(0.6182)", "verif image answer": "string(0.6868)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343999.jpg"}, {"question": "what kind of planes are these", "gt answer": "steel(0.60)<br/>jet(1.00)<br/>fighter jet(0.60)", "pred answer": "military", "question_id": 5696975, "best approach": "", "verif answer": "aluminum", "anno approach": "", "verif wiki answer": "fighter(0.6312)", "verif concept answer": "aluminum(0.6809)", "verif image answer": "fighter(0.5460)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569697.jpg"}, {"question": "what kind of handlebars does that motorcycle have", "gt answer": "ape hanger(1.00)<br/>large(0.60)", "pred answer": "aluminum", "question_id": 3275725, "best approach": "image", "verif answer": "large", "anno approach": "image", "verif wiki answer": "silver(0.5934)", "verif concept answer": "32 in(0.5632)", "verif image answer": "large(0.6437)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327572.jpg"}, {"question": "what was the first movie was the character in this image first featured", "gt answer": "star war(1.00)", "pred answer": "dumbo", "question_id": 1823175, "best approach": "", "verif answer": "forrest gump", "anno approach": "", "verif wiki answer": "disney(0.6051)", "verif concept answer": "disney(0.6456)", "verif image answer": "forrest gump(0.6551)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182317.jpg"}, {"question": "what brand is the toothbrush", "gt answer": "colgate(1.00)<br/>crest(0.60)<br/>oral b(0.60)", "pred answer": "oral b", "question_id": 5151025, "best approach": "wiki, concept, image", "verif answer": "oral b", "anno approach": "wiki", "verif wiki answer": "oral b(0.7293)", "verif concept answer": "oral b(0.7297)", "verif image answer": "oral b(0.7243)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515102.jpg"}, {"question": "what do most people eat chili in", "gt answer": "bowl(1.00)<br/>bread(0.60)", "pred answer": "tea", "question_id": 3390425, "best approach": "concept", "verif answer": "soup", "anno approach": "concept", "verif wiki answer": "fan(0.7181)", "verif concept answer": "bowl(0.7023)", "verif image answer": "soup(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000339042.jpg"}, {"question": "if an animal eats the greenery these animals are consuming as its sole sustenance it is said to be a what", "gt answer": "herbivore(1.00)<br/>vegetarian(0.60)", "pred answer": "safe", "question_id": 5671865, "best approach": "wiki, concept, image", "verif answer": "vegetarian", "anno approach": "image, wiki", "verif wiki answer": "vegetarian(0.5162)", "verif concept answer": "vegetarian(0.5051)", "verif image answer": "vegetarian(0.5310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567186.jpg"}, {"question": "what part of the government do these belong to", "gt answer": "air force(1.00)<br/>airforce(0.60)<br/>military(0.60)", "pred answer": "airforce", "question_id": 2689215, "best approach": "wiki, concept", "verif answer": "air force", "anno approach": "wiki", "verif wiki answer": "air force(0.7300)", "verif concept answer": "air force(0.7148)", "verif image answer": "army(0.5649)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268921.jpg"}, {"question": "what town is the road in this photo in", "gt answer": "tarana(1.00)<br/>london(0.60)", "pred answer": "druid hill", "question_id": 2377185, "best approach": "wiki", "verif answer": "druid hill", "anno approach": "wiki", "verif wiki answer": "london(0.6046)", "verif concept answer": "druid hill(0.6535)", "verif image answer": "druid hill(0.7051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237718.jpg"}, {"question": "what is the family of this animal", "gt answer": "sheep(1.00)", "pred answer": "sheep", "question_id": 2028505, "best approach": "", "verif answer": "merino", "anno approach": "", "verif wiki answer": "merino(0.7085)", "verif concept answer": "merino(0.7161)", "verif image answer": "merino(0.6856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202850.jpg"}, {"question": "is this a really big cow or just a huge simulation", "gt answer": "simulation(1.00)", "pred answer": "big", "question_id": 1788015, "best approach": "", "verif answer": "no saddle", "anno approach": "", "verif wiki answer": "no saddle(0.7147)", "verif concept answer": "no saddle(0.7166)", "verif image answer": "no saddle(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178801.jpg"}, {"question": "what is this type of ball made of", "gt answer": "rubber(1.00)", "pred answer": "rubber", "question_id": 520945, "best approach": "wiki, concept, image", "verif answer": "rubber", "anno approach": "wiki", "verif wiki answer": "rubber(0.6689)", "verif concept answer": "rubber(0.6573)", "verif image answer": "rubber(0.6472)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052094.jpg"}, {"question": "what season was this picture taken in", "gt answer": "spring(1.00)<br/>summer(1.00)", "pred answer": "spring", "question_id": 4888575, "best approach": "", "verif answer": "fall", "anno approach": "", "verif wiki answer": "fall(0.7304)", "verif concept answer": "fall(0.7217)", "verif image answer": "winter(0.6949)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488857.jpg"}, {"question": "what is the largest of this type of waterway", "gt answer": "canal(1.00)<br/>pacific(0.60)<br/>panama canal(0.60)", "pred answer": "lake", "question_id": 4567925, "best approach": "", "verif answer": "mississippi", "anno approach": "", "verif wiki answer": "river(0.6856)", "verif concept answer": "river(0.6709)", "verif image answer": "mississippi(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456792.jpg"}, {"question": "what were the symbols in this picture denotes", "gt answer": "park(1.00)<br/>no park(0.60)", "pred answer": "street", "question_id": 5327795, "best approach": "concept, image", "verif answer": "park", "anno approach": "image", "verif wiki answer": "direct(0.6842)", "verif concept answer": "park(0.6392)", "verif image answer": "park(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532779.jpg"}, {"question": "what is the oldest ancient artifact", "gt answer": "tool(1.00)", "pred answer": "peacock", "question_id": 4190285, "best approach": "", "verif answer": "daisy", "anno approach": "", "verif wiki answer": "catholic(0.6741)", "verif concept answer": "daisy(0.7302)", "verif image answer": "king(0.7083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419028.jpg"}, {"question": "what kind of book could the girl in the picture be reading", "gt answer": "fairytale(1.00)<br/>picture(0.60)", "pred answer": "newspaper", "question_id": 3692135, "best approach": "wiki, concept, image", "verif answer": "fairytale", "anno approach": "concept", "verif wiki answer": "fairytale(0.6877)", "verif concept answer": "fairytale(0.7055)", "verif image answer": "fairytale(0.6683)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369213.jpg"}, {"question": "what food does the animal eat", "gt answer": "seed(1.00)", "pred answer": "seed", "question_id": 460785, "best approach": "wiki, concept, image", "verif answer": "seed", "anno approach": "image, wiki", "verif wiki answer": "seed(0.7018)", "verif concept answer": "seed(0.6569)", "verif image answer": "seed(0.6977)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046078.jpg"}, {"question": "how many spokes are on the average wheel of this type of bicycle", "gt answer": "36(1.00)<br/>22(0.60)<br/>28(0.60)", "pred answer": "50", "question_id": 4814545, "best approach": "wiki, concept", "verif answer": "42", "anno approach": "wiki", "verif wiki answer": "36(0.6666)", "verif concept answer": "36(0.6462)", "verif image answer": "42(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481454.jpg"}, {"question": "what company is this yellow truck from", "gt answer": "penske(1.00)", "pred answer": "toshiba", "question_id": 4354455, "best approach": "wiki, concept", "verif answer": "whirlpool", "anno approach": "", "verif wiki answer": "penske(0.6988)", "verif concept answer": "penske(0.7106)", "verif image answer": "whirlpool(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435445.jpg"}, {"question": "these boats are in a", "gt answer": "marina(1.00)<br/>harbor(0.60)<br/>dock(0.60)", "pred answer": "marina", "question_id": 3473195, "best approach": "image", "verif answer": "boat", "anno approach": "image", "verif wiki answer": "boat(0.6978)", "verif concept answer": "boat(0.7116)", "verif image answer": "marina(0.6630)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347319.jpg"}, {"question": "what is the maximum wind speed the sailboat shown in the image can reach", "gt answer": "20 knots(1.00)<br/>30 mph(0.60)<br/>50 mph(0.60)", "pred answer": "30mph", "question_id": 1289225, "best approach": "wiki", "verif answer": "20 knots", "anno approach": "wiki", "verif wiki answer": "20 knots(0.7114)", "verif concept answer": "100 mph(0.6741)", "verif image answer": "60 mph(0.7021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128922.jpg"}, {"question": "what are the brand of shoes shown on the skateboarder", "gt answer": "dc(1.00)<br/>nike(0.60)<br/>converse(0.60)<br/>van(0.60)", "pred answer": "converse", "question_id": 1723515, "best approach": "wiki, concept, image", "verif answer": "converse", "anno approach": "wiki", "verif wiki answer": "converse(0.7299)", "verif concept answer": "converse(0.7241)", "verif image answer": "converse(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000172351.jpg"}, {"question": "what animal do these come from", "gt answer": "pig(1.00)<br/>cow(1.00)", "pred answer": "cow", "question_id": 5680985, "best approach": "wiki, concept", "verif answer": "pig", "anno approach": "wiki", "verif wiki answer": "pig(0.7293)", "verif concept answer": "cow(0.7284)", "verif image answer": "food(0.5358)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568098.jpg"}, {"question": "where is this photo taken", "gt answer": "stable(1.00)<br/>barn(0.60)<br/>racetrack(0.60)", "pred answer": "street", "question_id": 4009715, "best approach": "wiki, concept, image", "verif answer": "barn", "anno approach": "image, wiki", "verif wiki answer": "barn(0.6901)", "verif concept answer": "barn(0.6788)", "verif image answer": "barn(0.7130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400971.jpg"}, {"question": "what is the driver of this vehicle called", "gt answer": "train conductor(1.00)<br/>conductor(0.60)<br/>engineer(0.60)", "pred answer": "conductor", "question_id": 67335, "best approach": "wiki, concept, image", "verif answer": "engineer", "anno approach": "wiki", "verif wiki answer": "engineer(0.7309)", "verif concept answer": "engineer(0.7309)", "verif image answer": "conductor(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006733.jpg"}, {"question": "when did this model of tv come out", "gt answer": "1990's(1.00)<br/>1970(0.60)<br/>1990(0.60)", "pred answer": "2000", "question_id": 2464915, "best approach": "wiki, image", "verif answer": "1990's", "anno approach": "", "verif wiki answer": "1990's(0.6973)", "verif concept answer": "1980's(0.6796)", "verif image answer": "1990's(0.7066)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246491.jpg"}, {"question": "how is this food made", "gt answer": "oven(1.00)<br/>in oven(0.60)<br/>bake(0.60)", "pred answer": "oven", "question_id": 5058765, "best approach": "wiki", "verif answer": "baked", "anno approach": "wiki", "verif wiki answer": "in oven(0.6926)", "verif concept answer": "baked(0.6780)", "verif image answer": "baked(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505876.jpg"}, {"question": "what is this guy 's profession", "gt answer": "security(1.00)<br/>horse race(0.60)", "pred answer": "cook", "question_id": 703475, "best approach": "", "verif answer": "police", "anno approach": "", "verif wiki answer": "police(0.5511)", "verif concept answer": "ride(0.5255)", "verif image answer": "police(0.5163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070347.jpg"}, {"question": "what drink is this", "gt answer": "whiskey(1.00)", "pred answer": "beer", "question_id": 4420265, "best approach": "", "verif answer": "soda", "anno approach": "", "verif wiki answer": "soda(0.6248)", "verif concept answer": "soda(0.6101)", "verif image answer": "beer(0.5123)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442026.jpg"}, {"question": "tell me the name of the vehichle seen in the picture", "gt answer": "cargo van(1.00)<br/>van(1.00)", "pred answer": "pepsi", "question_id": 2992445, "best approach": "image", "verif answer": "cargo van", "anno approach": "image", "verif wiki answer": "suv(0.5821)", "verif concept answer": "suv(0.5314)", "verif image answer": "cargo van(0.6863)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000299244.jpg"}, {"question": "what might the girl slip on after this picture", "gt answer": "banana peel(1.00)<br/>peel(1.00)", "pred answer": "paint", "question_id": 5285625, "best approach": "", "verif answer": "shirt", "anno approach": "", "verif wiki answer": "shirt(0.6805)", "verif concept answer": "shirt(0.7227)", "verif image answer": "shirt(0.5935)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528562.jpg"}, {"question": "what is this activity called", "gt answer": "pole dance(1.00)", "pred answer": "volleyball", "question_id": 282305, "best approach": "", "verif answer": "aerial", "anno approach": "", "verif wiki answer": "aerial(0.5889)", "verif concept answer": "aerial(0.6731)", "verif image answer": "aerial(0.7239)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028230.jpg"}, {"question": "what kind of food is this", "gt answer": "salad(1.00)<br/>stirfry(0.60)<br/>fruit(0.60)<br/>vegetarian(0.60)", "pred answer": "pasta", "question_id": 5071485, "best approach": "wiki, concept, image", "verif answer": "vegetarian", "anno approach": "wiki", "verif wiki answer": "vegetarian(0.6535)", "verif concept answer": "vegetarian(0.6469)", "verif image answer": "vegetarian(0.6625)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507148.jpg"}, {"question": "what country are these animals found", "gt answer": "india(1.00)<br/>thailand(0.60)<br/>africa(0.60)<br/>asia(0.60)", "pred answer": "africa", "question_id": 4047955, "best approach": "wiki, concept, image", "verif answer": "africa", "anno approach": "image, wiki", "verif wiki answer": "africa(0.7110)", "verif concept answer": "africa(0.6717)", "verif image answer": "africa(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404795.jpg"}, {"question": "what is the meat used in this sandwhich", "gt answer": "meatloaf(1.00)<br/>ham(0.60)<br/>beef(0.60)", "pred answer": "beef", "question_id": 2014195, "best approach": "concept, image", "verif answer": "pork", "anno approach": "", "verif wiki answer": "pork(0.6471)", "verif concept answer": "beef(0.6346)", "verif image answer": "beef(0.6382)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201419.jpg"}, {"question": "is this a professional or amatuer cyclist", "gt answer": "professional(1.00)<br/>amateur(0.60)<br/>amatuer(0.60)", "pred answer": "professional", "question_id": 740995, "best approach": "", "verif answer": "professionally", "anno approach": "", "verif wiki answer": "professionally(0.7310)", "verif concept answer": "professionally(0.7310)", "verif image answer": "professionally(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074099.jpg"}, {"question": "what is the design on this chair", "gt answer": "stripe(1.00)<br/>striped(0.60)", "pred answer": "striped", "question_id": 5811365, "best approach": "wiki, concept", "verif answer": "stripe", "anno approach": "wiki", "verif wiki answer": "stripe(0.6985)", "verif concept answer": "stripe(0.7265)", "verif image answer": "striped(0.7187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000581136.jpg"}, {"question": "what bay is that", "gt answer": "san francisco(1.00)", "pred answer": "lake", "question_id": 2821585, "best approach": "", "verif answer": "chicago", "anno approach": "", "verif wiki answer": "city(0.7076)", "verif concept answer": "city(0.7246)", "verif image answer": "chicago(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282158.jpg"}, {"question": "what kind of cream is on the cake", "gt answer": "whipped(1.00)<br/>sour(0.60)", "pred answer": "vanilla", "question_id": 1078865, "best approach": "", "verif answer": "vanilla", "anno approach": "", "verif wiki answer": "vanilla(0.6271)", "verif concept answer": "vanilla(0.6132)", "verif image answer": "pastry(0.6252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000107886.jpg"}, {"question": "what brand is the girls outfit from", "gt answer": "gap(1.00)", "pred answer": "nintendo", "question_id": 3223625, "best approach": "", "verif answer": "levis", "anno approach": "", "verif wiki answer": "levis(0.7306)", "verif concept answer": "levis(0.7292)", "verif image answer": "levis(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322362.jpg"}, {"question": "what is the life span of this animal", "gt answer": "25 years(1.00)<br/>25(1.00)<br/>40 years(0.60)", "pred answer": "10 years", "question_id": 5356515, "best approach": "", "verif answer": "30 years", "anno approach": "", "verif wiki answer": "30 years(0.6645)", "verif concept answer": "30 years(0.6357)", "verif image answer": "30 years(0.6940)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535651.jpg"}, {"question": "", "gt answer": "12450(0.60)", "pred answer": "tell time", "question_id": 3587245, "best approach": "wiki, concept, image", "verif answer": "12450", "anno approach": "", "verif wiki answer": "12450(0.6815)", "verif concept answer": "12450(0.6935)", "verif image answer": "12450(0.6820)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358724.jpg"}, {"question": "what make of truck is this", "gt answer": "chevrolet(1.00)<br/>dodge(0.60)<br/>chevy(0.60)", "pred answer": "ford", "question_id": 1197985, "best approach": "", "verif answer": "harley davidson", "anno approach": "", "verif wiki answer": "harley davidson(0.5468)", "verif concept answer": "harley davidson(0.6483)", "verif image answer": "harley davidson(0.6179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119798.jpg"}, {"question": "what fabric is the little girl 's sweater", "gt answer": "fleece(1.00)<br/>cotton(0.60)<br/>knit(0.60)<br/>wool(0.60)", "pred answer": "wool", "question_id": 950295, "best approach": "wiki, concept", "verif answer": "peacoat", "anno approach": "wiki", "verif wiki answer": "knit(0.7256)", "verif concept answer": "knit(0.6878)", "verif image answer": "peacoat(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000095029.jpg"}, {"question": "what type of water is this", "gt answer": "salt(1.00)<br/>bay(0.60)<br/>ocean(0.60)<br/>lake(0.60)", "pred answer": "ocean", "question_id": 1604025, "best approach": "wiki, concept", "verif answer": "ocean", "anno approach": "wiki", "verif wiki answer": "salt(0.7063)", "verif concept answer": "salt(0.7189)", "verif image answer": "ocean(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160402.jpg"}, {"question": "what is this wave doing", "gt answer": "roll(1.00)<br/>crest(1.00)", "pred answer": "surf", "question_id": 2307085, "best approach": "", "verif answer": "surf", "anno approach": "", "verif wiki answer": "surf(0.6942)", "verif concept answer": "surf(0.6682)", "verif image answer": "surf(0.7154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000230708.jpg"}, {"question": "who won the championship in this sport last year", "gt answer": "houston astros(1.00)<br/>giant(0.60)<br/>astros(0.60)<br/>team(0.60)", "pred answer": "babe ruth", "question_id": 3217005, "best approach": "wiki, concept, image", "verif answer": "houston astros", "anno approach": "wiki", "verif wiki answer": "houston astros(0.7301)", "verif concept answer": "houston astros(0.7288)", "verif image answer": "houston astros(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321700.jpg"}, {"question": "what level of baseball is this", "gt answer": "minor league(1.00)<br/>college(0.60)<br/>professional(0.60)<br/>minor(0.60)", "pred answer": "15", "question_id": 3874805, "best approach": "wiki, concept", "verif answer": "major", "anno approach": "wiki", "verif wiki answer": "college(0.6606)", "verif concept answer": "college(0.6506)", "verif image answer": "major(0.6853)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387480.jpg"}, {"question": "which fruit associated with the state of georgia is the color of this umbrella", "gt answer": "peach(1.00)", "pred answer": "red", "question_id": 484085, "best approach": "", "verif answer": "apple", "anno approach": "", "verif wiki answer": "apple(0.6206)", "verif concept answer": "apple(0.6598)", "verif image answer": "apple(0.6110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048408.jpg"}, {"question": "which of these streets is famous for theater", "gt answer": "broadway(1.00)", "pred answer": "new york", "question_id": 4899145, "best approach": "wiki, concept", "verif answer": "broadway", "anno approach": "", "verif wiki answer": "broadway(0.6178)", "verif concept answer": "broadway(0.6248)", "verif image answer": "orange(0.6189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489914.jpg"}, {"question": "what famous mountain is in the background", "gt answer": "everest(1.00)<br/>fuji(0.60)", "pred answer": "mountain", "question_id": 423855, "best approach": "", "verif answer": "northern", "anno approach": "", "verif wiki answer": "northern(0.7164)", "verif concept answer": "mt everest(0.7280)", "verif image answer": "northern(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042385.jpg"}, {"question": "what is the hairstyle of the blond called", "gt answer": "pony tail(1.00)<br/>braid(0.60)<br/>ponytail(0.60)", "pred answer": "pony tail", "question_id": 516065, "best approach": "wiki, concept, image", "verif answer": "pony tail", "anno approach": "wiki", "verif wiki answer": "pony tail(0.7249)", "verif concept answer": "pony tail(0.7307)", "verif image answer": "pony tail(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000051606.jpg"}, {"question": "what is the electronic device doing in this photo", "gt answer": "charge(1.00)", "pred answer": "use laptop", "question_id": 5403215, "best approach": "", "verif answer": "macbook", "anno approach": "", "verif wiki answer": "macbook(0.5347)", "verif concept answer": "macbook(0.6271)", "verif image answer": "fly(0.6145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540321.jpg"}, {"question": "what breed is the dog", "gt answer": "shitzu(1.00)<br/>pug(0.60)", "pred answer": "collie", "question_id": 5187855, "best approach": "image", "verif answer": "shitzu", "anno approach": "image", "verif wiki answer": "pug(0.6568)", "verif concept answer": "pug(0.6388)", "verif image answer": "shitzu(0.7130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518785.jpg"}, {"question": "what is he doing on his notebook", "gt answer": "type(1.00)<br/>work(0.60)<br/>code(0.60)", "pred answer": "work", "question_id": 5764275, "best approach": "wiki, concept", "verif answer": "work", "anno approach": "", "verif wiki answer": "work(0.6883)", "verif concept answer": "work(0.6668)", "verif image answer": "study(0.5587)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000576427.jpg"}, {"question": "what country is this most popular in", "gt answer": "america(1.00)<br/>usa(0.60)", "pred answer": "france", "question_id": 5704185, "best approach": "wiki, concept", "verif answer": "usa", "anno approach": "wiki", "verif wiki answer": "usa(0.6844)", "verif concept answer": "usa(0.6844)", "verif image answer": "factory(0.6644)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570418.jpg"}, {"question": "what food does the animal eat", "gt answer": "meat(1.00)<br/>dog food(0.60)<br/>milk(0.60)", "pred answer": "cat food", "question_id": 5695385, "best approach": "wiki, concept, image", "verif answer": "dog food", "anno approach": "wiki", "verif wiki answer": "dog food(0.6960)", "verif concept answer": "dog food(0.7194)", "verif image answer": "dog food(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569538.jpg"}, {"question": "what kind of balloon is in the photo", "gt answer": "hot air(1.00)<br/>parade(0.60)", "pred answer": "dragon", "question_id": 1899515, "best approach": "image", "verif answer": "parade", "anno approach": "image", "verif wiki answer": "stuffed(0.5905)", "verif concept answer": "stuffed(0.6085)", "verif image answer": "parade(0.6307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000189951.jpg"}, {"question": "on which continents do these trees grow", "gt answer": "north america(1.00)<br/>america(1.00)", "pred answer": "europe", "question_id": 743285, "best approach": "wiki, concept, image", "verif answer": "north america", "anno approach": "wiki", "verif wiki answer": "north america(0.6475)", "verif concept answer": "north america(0.6527)", "verif image answer": "north america(0.6519)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074328.jpg"}, {"question": "", "gt answer": "50(0.60)<br/>1950's(0.60)<br/>1930s(0.60)<br/>60s(0.60)", "pred answer": "1800's", "question_id": 426805, "best approach": "wiki, concept, image", "verif answer": "60s", "anno approach": "concept, wiki", "verif wiki answer": "60s(0.6756)", "verif concept answer": "60s(0.6771)", "verif image answer": "1950's(0.6381)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042680.jpg"}, {"question": "what kind of store would sell this", "gt answer": "gift shop(1.00)<br/>decor(0.60)<br/>craft(0.60)<br/>home depot(0.60)", "pred answer": "furniture", "question_id": 2826695, "best approach": "wiki, concept, image", "verif answer": "gift shop", "anno approach": "concept, wiki", "verif wiki answer": "gift shop(0.6967)", "verif concept answer": "gift shop(0.7092)", "verif image answer": "gift shop(0.6702)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282669.jpg"}, {"question": "what kind of band is around the mans wrist", "gt answer": "sweat band(1.00)<br/>sweat(1.00)", "pred answer": "nylon", "question_id": 3000575, "best approach": "wiki, concept, image", "verif answer": "sweat", "anno approach": "wiki", "verif wiki answer": "sweat(0.5137)", "verif concept answer": "sweat band(0.5136)", "verif image answer": "sweat band(0.5137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300057.jpg"}, {"question": "what hairstyle does this girl have", "gt answer": "pigtail(1.00)<br/>braid(0.60)<br/>ponytail(0.60)", "pred answer": "ponytail", "question_id": 44425, "best approach": "image", "verif answer": "pigtail", "anno approach": "image", "verif wiki answer": "ponytail(0.7293)", "verif concept answer": "bun(0.7295)", "verif image answer": "pigtail(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004442.jpg"}, {"question": "what is this made on", "gt answer": "pan(1.00)<br/>dough(0.60)", "pred answer": "paper", "question_id": 99935, "best approach": "", "verif answer": "oven", "anno approach": "", "verif wiki answer": "cheese(0.5933)", "verif concept answer": "cheese(0.5662)", "verif image answer": "oven(0.6232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009993.jpg"}, {"question": "what is the name of this scene", "gt answer": "nativity(1.00)", "pred answer": "bedroom", "question_id": 4973225, "best approach": "image", "verif answer": "model", "anno approach": "image", "verif wiki answer": "model(0.6228)", "verif concept answer": "model(0.6074)", "verif image answer": "nativity(0.6041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497322.jpg"}, {"question": "what kind of cake", "gt answer": "cupcake(1.00)", "pred answer": "red velvet", "question_id": 3933755, "best approach": "", "verif answer": "coffee cake", "anno approach": "", "verif wiki answer": "coffee cake(0.7183)", "verif concept answer": "coffee cake(0.7209)", "verif image answer": "coffee cake(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393375.jpg"}, {"question": "which disney movie featured this type of garb", "gt answer": "mulan(1.00)", "pred answer": "forrest gump", "question_id": 3046255, "best approach": "wiki, concept, image", "verif answer": "mulan", "anno approach": "", "verif wiki answer": "mulan(0.6058)", "verif concept answer": "mulan(0.6109)", "verif image answer": "mulan(0.5912)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304625.jpg"}, {"question": "what is the purpose of the objects these people are carrying", "gt answer": "stay dry(1.00)<br/>protection(0.60)", "pred answer": "umbrella", "question_id": 5297455, "best approach": "wiki, concept, image", "verif answer": "stay dry", "anno approach": "wiki", "verif wiki answer": "stay dry(0.6850)", "verif concept answer": "stay dry(0.6800)", "verif image answer": "stay dry(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529745.jpg"}, {"question": "how are they moving the boat", "gt answer": "oar(1.00)<br/>tow(0.60)<br/>row(0.60)", "pred answer": "rope", "question_id": 525625, "best approach": "concept, image", "verif answer": "tow", "anno approach": "concept", "verif wiki answer": "paddle(0.5286)", "verif concept answer": "tow(0.6393)", "verif image answer": "row(0.5828)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052562.jpg"}, {"question": "what room of the house is this", "gt answer": "bedroom(1.00)", "pred answer": "bedroom", "question_id": 3777725, "best approach": "wiki, concept", "verif answer": "live room", "anno approach": "wiki", "verif wiki answer": "bedroom(0.6959)", "verif concept answer": "bedroom(0.7180)", "verif image answer": "live room(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377772.jpg"}, {"question": "what healthy oil is this dish a source of", "gt answer": "olive(1.00)<br/>olive oil(1.00)", "pred answer": "mozzarella", "question_id": 5488745, "best approach": "", "verif answer": "canola", "anno approach": "", "verif wiki answer": "canola(0.6114)", "verif concept answer": "canola(0.6484)", "verif image answer": "canola(0.7081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548874.jpg"}, {"question": "what kind of effect was used on this image", "gt answer": "sepia(1.00)<br/>black and white(1.00)", "pred answer": "black and white", "question_id": 2272955, "best approach": "wiki, concept, image", "verif answer": "black and white", "anno approach": "wiki", "verif wiki answer": "sepia(0.7214)", "verif concept answer": "black and white(0.7250)", "verif image answer": "black and white(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000227295.jpg"}, {"question": "how is the dog carrying this", "gt answer": "mouth(1.00)<br/>teeth(0.60)", "pred answer": "leash", "question_id": 4800165, "best approach": "", "verif answer": "stomach", "anno approach": "", "verif wiki answer": "stomach(0.7030)", "verif concept answer": "stomach(0.7266)", "verif image answer": "stomach(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480016.jpg"}, {"question": "what type of flowers are in this photo", "gt answer": "lily(1.00)<br/>tulip(0.60)", "pred answer": "hydrangea", "question_id": 1561515, "best approach": "", "verif answer": "hydrangea", "anno approach": "", "verif wiki answer": "hydrangea(0.6568)", "verif concept answer": "rose(0.6490)", "verif image answer": "hydrangea(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000156151.jpg"}, {"question": "what team is this player on", "gt answer": "clearwater(1.00)", "pred answer": "dodger", "question_id": 3220905, "best approach": "", "verif answer": "brewer", "anno approach": "", "verif wiki answer": "brewer(0.7138)", "verif concept answer": "brewer(0.6670)", "verif image answer": "brewer(0.6780)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322090.jpg"}, {"question": "which actress playing dory in finding nemo", "gt answer": "ellen degeneres(1.00)", "pred answer": "boy", "question_id": 79215, "best approach": "wiki, concept, image", "verif answer": "ellen degeneres", "anno approach": "", "verif wiki answer": "ellen degeneres(0.7298)", "verif concept answer": "ellen degeneres(0.7153)", "verif image answer": "ellen degeneres(0.7088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007921.jpg"}, {"question": "what kind of knife is this", "gt answer": "butter(1.00)", "pred answer": "craft", "question_id": 3736395, "best approach": "", "verif answer": "spoon", "anno approach": "", "verif wiki answer": "spoon(0.7297)", "verif concept answer": "spoon(0.7151)", "verif image answer": "spoon(0.5477)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373639.jpg"}, {"question": "what kind of tower is this", "gt answer": "clock tower(1.00)<br/>clock(1.00)<br/>castle(0.60)", "pred answer": "clock", "question_id": 2656295, "best approach": "wiki, concept", "verif answer": "clock", "anno approach": "wiki", "verif wiki answer": "clock(0.7302)", "verif concept answer": "clock(0.7302)", "verif image answer": "bell(0.6992)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265629.jpg"}, {"question": "what type of function is going on", "gt answer": "party(1.00)<br/>family reunion(0.60)<br/>celebration(0.60)", "pred answer": "birthday", "question_id": 4837695, "best approach": "", "verif answer": "picnic", "anno approach": "", "verif wiki answer": "picnic(0.6020)", "verif concept answer": "picnic(0.5930)", "verif image answer": "picnic(0.5618)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483769.jpg"}, {"question": "what are the item beside the sandwich called", "gt answer": "french fry(1.00)<br/>fry(0.60)", "pred answer": "fry", "question_id": 5491685, "best approach": "", "verif answer": "steak", "anno approach": "", "verif wiki answer": "steak(0.7031)", "verif concept answer": "steak(0.7107)", "verif image answer": "steak(0.6555)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000549168.jpg"}, {"question": "what type of industry would use this truck", "gt answer": "construction(1.00)<br/>tow(1.00)", "pred answer": "dump", "question_id": 132745, "best approach": "", "verif answer": "truck", "anno approach": "", "verif wiki answer": "truck(0.6398)", "verif concept answer": "truck(0.6574)", "verif image answer": "truck(0.7033)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013274.jpg"}, {"question": "what does this sign signify", "gt answer": "do not enter(1.00)<br/>stall(0.60)", "pred answer": "no park", "question_id": 5605635, "best approach": "image", "verif answer": "stall", "anno approach": "image", "verif wiki answer": "sad(0.6529)", "verif concept answer": "sad(0.6585)", "verif image answer": "stall(0.6792)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560563.jpg"}, {"question": "what kind of truck is that", "gt answer": "tow(1.00)<br/>tractor trailer(0.60)<br/>tow truck(0.60)", "pred answer": "dump", "question_id": 1844775, "best approach": "wiki, concept, image", "verif answer": "tow", "anno approach": "wiki", "verif wiki answer": "tow(0.6978)", "verif concept answer": "tow(0.6818)", "verif image answer": "tow(0.6966)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184477.jpg"}, {"question": "why is this woman wearing a coat", "gt answer": "cold(1.00)<br/>rain(0.60)<br/>cold weather(0.60)", "pred answer": "rain", "question_id": 461065, "best approach": "wiki, concept, image", "verif answer": "cold", "anno approach": "image, wiki", "verif wiki answer": "cold(0.6944)", "verif concept answer": "cold(0.7006)", "verif image answer": "cold(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046106.jpg"}, {"question": "what type of uniform is the man wearing", "gt answer": "marine(1.00)<br/>military(1.00)<br/>suit(0.60)", "pred answer": "suit", "question_id": 2480235, "best approach": "wiki, concept, image", "verif answer": "military", "anno approach": "concept, wiki", "verif wiki answer": "military(0.5958)", "verif concept answer": "military(0.5851)", "verif image answer": "marine(0.5136)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248023.jpg"}, {"question": "what style of tiling is exhibited by this tile pattern", "gt answer": "star(1.00)<br/>spanish(0.60)<br/>clock(0.60)", "pred answer": "victorian", "question_id": 4407925, "best approach": "wiki, image", "verif answer": "spanish", "anno approach": "wiki", "verif wiki answer": "spanish(0.6721)", "verif concept answer": "light(0.5843)", "verif image answer": "spanish(0.6657)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440792.jpg"}, {"question": "what do you see", "gt answer": "luggage(1.00)<br/>graffiti(0.60)<br/>garbage can(0.60)", "pred answer": "car", "question_id": 1481845, "best approach": "wiki, concept", "verif answer": "luggage", "anno approach": "concept, wiki", "verif wiki answer": "luggage(0.5084)", "verif concept answer": "luggage(0.5964)", "verif image answer": "chair(0.5549)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148184.jpg"}, {"question": "how common is it for people to use the type of transportation pictured here in new york", "gt answer": "common(1.00)", "pred answer": "easy", "question_id": 1938785, "best approach": "image", "verif answer": "fun", "anno approach": "image", "verif wiki answer": "fun(0.6154)", "verif concept answer": "fun(0.7181)", "verif image answer": "common(0.6515)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193878.jpg"}, {"question": "what brand is the fridge", "gt answer": "frigidaire(1.00)<br/>kenmore(0.60)<br/>maytag(0.60)<br/>ge(0.60)", "pred answer": "kenmore", "question_id": 1818855, "best approach": "wiki, concept, image", "verif answer": "maytag", "anno approach": "wiki", "verif wiki answer": "maytag(0.7241)", "verif concept answer": "maytag(0.7266)", "verif image answer": "maytag(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181885.jpg"}, {"question": "how does the boat propel itself across the water", "gt answer": "motor(1.00)<br/>paddle(0.60)", "pred answer": "float", "question_id": 4524705, "best approach": "image", "verif answer": "canoe", "anno approach": "image", "verif wiki answer": "canoe(0.7288)", "verif concept answer": "oar(0.7215)", "verif image answer": "paddle(0.6955)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000452470.jpg"}, {"question": "what emotion is this orange", "gt answer": "sad(1.00)", "pred answer": "happiness", "question_id": 1659365, "best approach": "", "verif answer": "despair", "anno approach": "", "verif wiki answer": "despair(0.6351)", "verif concept answer": "despair(0.6663)", "verif image answer": "despair(0.6617)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000165936.jpg"}, {"question": "what style of tie knot does this man have", "gt answer": "windsor(1.00)<br/>traditional(0.60)<br/>tie(0.60)", "pred answer": "windsor", "question_id": 4563095, "best approach": "wiki, concept, image", "verif answer": "windsor", "anno approach": "wiki", "verif wiki answer": "windsor(0.6912)", "verif concept answer": "windsor(0.6416)", "verif image answer": "windsor(0.6363)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456309.jpg"}, {"question": "who threw the baseball", "gt answer": "pitcher(1.00)<br/>girl(0.60)", "pred answer": "baby", "question_id": 1558235, "best approach": "", "verif answer": "boy", "anno approach": "", "verif wiki answer": "boy(0.7119)", "verif concept answer": "boy(0.6953)", "verif image answer": "boy(0.7190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155823.jpg"}, {"question": "can these vehicles become safely airborne or are they ground based", "gt answer": "ground based(1.00)<br/>ground(0.60)", "pred answer": "electricity", "question_id": 5184335, "best approach": "", "verif answer": "fast", "anno approach": "", "verif wiki answer": "fast(0.5005)", "verif concept answer": "fast(0.5005)", "verif image answer": "fast(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518433.jpg"}, {"question": "what is the breed of the dog", "gt answer": "black lab(1.00)<br/>black labrador(0.60)<br/>labrador(0.60)<br/>lab(0.60)", "pred answer": "lab", "question_id": 171715, "best approach": "wiki, concept, image", "verif answer": "lab", "anno approach": "wiki", "verif wiki answer": "lab(0.7022)", "verif concept answer": "lab(0.6845)", "verif image answer": "lab(0.6656)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000017171.jpg"}, {"question": "what famous symbol is on the glass", "gt answer": "playboy bunny(1.00)", "pred answer": "sun", "question_id": 124225, "best approach": "", "verif answer": "steve job", "anno approach": "", "verif wiki answer": "steve job(0.6907)", "verif concept answer": "steve job(0.6606)", "verif image answer": "steve job(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012422.jpg"}, {"question": "this bird evolved from which subspecies", "gt answer": "crane(1.00)<br/>pelican(0.60)<br/>fish(0.60)", "pred answer": "pelican", "question_id": 2121745, "best approach": "wiki, concept, image", "verif answer": "pelican", "anno approach": "wiki", "verif wiki answer": "pelican(0.7169)", "verif concept answer": "pelican(0.6769)", "verif image answer": "pelican(0.6769)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212174.jpg"}, {"question": "what is the baby doing", "gt answer": "brush teeth(1.00)", "pred answer": "clean teeth", "question_id": 4331225, "best approach": "", "verif answer": "clean teeth", "anno approach": "", "verif wiki answer": "clean teeth(0.5836)", "verif concept answer": "clean teeth(0.7296)", "verif image answer": "toothbrush(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433122.jpg"}, {"question": "what is the name of the color tone of this photograph", "gt answer": "sepia(1.00)<br/>black and white(0.60)", "pred answer": "sepia", "question_id": 2724895, "best approach": "image", "verif answer": "dark", "anno approach": "image", "verif wiki answer": "dark(0.6737)", "verif concept answer": "dark(0.6045)", "verif image answer": "black and white(0.6230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000272489.jpg"}, {"question": "what field position is being played by the child throwing the baseball", "gt answer": "catcher(1.00)<br/>pitcher(1.00)", "pred answer": "batter", "question_id": 4763415, "best approach": "", "verif answer": "glove", "anno approach": "", "verif wiki answer": "glove(0.6986)", "verif concept answer": "glove(0.7032)", "verif image answer": "glove(0.7282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476341.jpg"}, {"question": "what is this person doing", "gt answer": "collect trash(1.00)<br/>work(0.60)<br/>ride(0.60)", "pred answer": "tow", "question_id": 1612515, "best approach": "", "verif answer": "construction", "anno approach": "", "verif wiki answer": "construction(0.5654)", "verif concept answer": "construction(0.6670)", "verif image answer": "delivery(0.5323)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161251.jpg"}, {"question": "what element is in side the brightly lit sign", "gt answer": "neon gas(1.00)<br/>neon(0.60)", "pred answer": "helmet", "question_id": 4470915, "best approach": "wiki, concept, image", "verif answer": "neon gas", "anno approach": "wiki", "verif wiki answer": "neon gas(0.6518)", "verif concept answer": "neon gas(0.6489)", "verif image answer": "neon gas(0.6483)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447091.jpg"}, {"question": "what breed of cat is this", "gt answer": "tuxedo(1.00)<br/>tabby(0.60)", "pred answer": "calico", "question_id": 4990545, "best approach": "wiki, concept", "verif answer": "calico", "anno approach": "wiki", "verif wiki answer": "tuxedo(0.7243)", "verif concept answer": "tuxedo(0.7216)", "verif image answer": "calico(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499054.jpg"}, {"question": "what era are the hats from", "gt answer": "wwii(1.00)<br/>world war 2(0.60)", "pred answer": "1970", "question_id": 4436535, "best approach": "wiki, concept, image", "verif answer": "wwii", "anno approach": "concept, wiki", "verif wiki answer": "wwii(0.6605)", "verif concept answer": "wwii(0.6665)", "verif image answer": "wwii(0.6200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443653.jpg"}, {"question": "how many mpg does the silver scooter get", "gt answer": "60(1.00)<br/>15(0.60)<br/>20(0.60)<br/>8(0.60)", "pred answer": "16", "question_id": 3453455, "best approach": "wiki, concept, image", "verif answer": "20", "anno approach": "wiki", "verif wiki answer": "20(0.7260)", "verif concept answer": "20(0.6921)", "verif image answer": "20(0.7052)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345345.jpg"}, {"question": "what type of event is this", "gt answer": "press conference(1.00)<br/>wed(0.60)", "pred answer": "retirement", "question_id": 391955, "best approach": "wiki, concept", "verif answer": "press conference", "anno approach": "", "verif wiki answer": "press conference(0.7165)", "verif concept answer": "press conference(0.7290)", "verif image answer": "wed(0.7257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039195.jpg"}, {"question": "what year was this activity invented", "gt answer": "1950(1.00)", "pred answer": "1950", "question_id": 2750575, "best approach": "", "verif answer": "skateboard", "anno approach": "", "verif wiki answer": "1800(0.6468)", "verif concept answer": "1800(0.6518)", "verif image answer": "skateboard(0.6562)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000275057.jpg"}, {"question": "what is the device sitting on top of the tv", "gt answer": "dvd player(1.00)<br/>remote(0.60)", "pred answer": "microwave", "question_id": 2410035, "best approach": "", "verif answer": "flatscreen", "anno approach": "", "verif wiki answer": "flatscreen(0.6709)", "verif concept answer": "flatscreen(0.6463)", "verif image answer": "flatscreen(0.5920)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241003.jpg"}, {"question": "what could be on fire", "gt answer": "car(1.00)<br/>book(1.00)<br/>city(0.60)", "pred answer": "clock", "question_id": 3758265, "best approach": "wiki, concept, image", "verif answer": "book", "anno approach": "image, wiki", "verif wiki answer": "car(0.5620)", "verif concept answer": "car(0.5299)", "verif image answer": "book(0.6369)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375826.jpg"}, {"question": "what traffic sign is backwards", "gt answer": "yield(1.00)<br/>0(0.60)", "pred answer": "park", "question_id": 2710065, "best approach": "", "verif answer": "firetruck", "anno approach": "", "verif wiki answer": "firetruck(0.7242)", "verif concept answer": "firetruck(0.6569)", "verif image answer": "firetruck(0.6992)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000271006.jpg"}, {"question": "how long does the babies of this animal stay with the parents", "gt answer": "18 years(1.00)<br/>18(0.60)", "pred answer": "hour", "question_id": 4870615, "best approach": "image", "verif answer": "2 weeks", "anno approach": "image", "verif wiki answer": "2 weeks(0.5782)", "verif concept answer": "2 weeks(0.5884)", "verif image answer": "18 years(0.5405)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487061.jpg"}, {"question": "what shoes is this person wearing", "gt answer": "loafer(1.00)<br/>sneaker(0.60)", "pred answer": "dress", "question_id": 4416085, "best approach": "", "verif answer": "dress", "anno approach": "", "verif wiki answer": "dress(0.6504)", "verif concept answer": "dress(0.6481)", "verif image answer": "dress(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441608.jpg"}, {"question": "what would you place in the black container", "gt answer": "trash(1.00)<br/>garbage(0.60)", "pred answer": "trash", "question_id": 4040135, "best approach": "wiki, concept, image", "verif answer": "trash", "anno approach": "wiki", "verif wiki answer": "trash(0.7099)", "verif concept answer": "trash(0.6962)", "verif image answer": "trash(0.7092)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404013.jpg"}, {"question": "what is a group of these animals known as", "gt answer": "herd(1.00)<br/>elephant(0.60)", "pred answer": "herd", "question_id": 5216105, "best approach": "wiki, concept", "verif answer": "herd", "anno approach": "wiki", "verif wiki answer": "herd(0.6463)", "verif concept answer": "herd(0.6735)", "verif image answer": "pack(0.5644)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521610.jpg"}, {"question": "what bird flies in this formation", "gt answer": "geese(1.00)<br/>safety(0.60)", "pred answer": "airplane", "question_id": 3002605, "best approach": "image", "verif answer": "seagull", "anno approach": "image", "verif wiki answer": "seagull(0.6694)", "verif concept answer": "crane(0.6375)", "verif image answer": "geese(0.6253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300260.jpg"}, {"question": "what is the bridge for", "gt answer": "cross river(1.00)<br/>cross(0.60)<br/>transportation(0.60)", "pred answer": "travel", "question_id": 5602385, "best approach": "concept", "verif answer": "cross river", "anno approach": "concept", "verif wiki answer": "transportation(0.7176)", "verif concept answer": "cross river(0.7185)", "verif image answer": "transportation(0.6869)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560238.jpg"}, {"question": "the lunch lady in the movie billy madison says she made this dish a certain way for the students", "gt answer": "sloppy(1.00)", "pred answer": "fry", "question_id": 612155, "best approach": "", "verif answer": "french fry", "anno approach": "", "verif wiki answer": "imported(0.5152)", "verif concept answer": "imported(0.5298)", "verif image answer": "french fry(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061215.jpg"}, {"question": "", "gt answer": "hobby(0.60)<br/>ride rail(0.60)<br/>transportation(0.60)<br/>transport good(0.60)<br/>transport(0.60)", "pred answer": "transport", "question_id": 1624195, "best approach": "wiki, concept, image", "verif answer": "transport", "anno approach": "", "verif wiki answer": "transport(0.6573)", "verif concept answer": "transport(0.6737)", "verif image answer": "transport(0.6458)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162419.jpg"}, {"question": "who is famous for allegedly doing this in a lightning storm", "gt answer": "ben franklin(1.00)<br/>benjamin franklin(1.00)", "pred answer": "benjamin franklin", "question_id": 1421535, "best approach": "wiki, concept, image", "verif answer": "benjamin franklin", "anno approach": "wiki", "verif wiki answer": "benjamin franklin(0.7299)", "verif concept answer": "benjamin franklin(0.7210)", "verif image answer": "benjamin franklin(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142153.jpg"}, {"question": "what is this food 's orgin", "gt answer": "south america(1.00)<br/>banana(0.60)<br/>tree(0.60)<br/>brazil(0.60)", "pred answer": "boat", "question_id": 3514045, "best approach": "wiki, concept, image", "verif answer": "tree", "anno approach": "image, wiki", "verif wiki answer": "tree(0.6510)", "verif concept answer": "tree(0.6801)", "verif image answer": "tree(0.6965)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351404.jpg"}, {"question": "the man in this picture is handling what", "gt answer": "luggage(1.00)", "pred answer": "airplane", "question_id": 1871115, "best approach": "", "verif answer": "airplane", "anno approach": "", "verif wiki answer": "crutch(0.7132)", "verif concept answer": "crutch(0.7101)", "verif image answer": "airplane(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187111.jpg"}, {"question": "what shape is the food", "gt answer": "round(1.00)<br/>circle(0.60)", "pred answer": "circle", "question_id": 3543805, "best approach": "image", "verif answer": "round", "anno approach": "image", "verif wiki answer": "circle(0.7081)", "verif concept answer": "circle(0.7120)", "verif image answer": "round(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354380.jpg"}, {"question": "how high can this kite fly", "gt answer": "300 feet(1.00)<br/>wind(0.60)<br/>200 feet(0.60)<br/>very high(0.60)", "pred answer": "30000 feet", "question_id": 3011945, "best approach": "wiki, concept, image", "verif answer": "very high", "anno approach": "wiki", "verif wiki answer": "very high(0.7072)", "verif concept answer": "very high(0.7182)", "verif image answer": "very high(0.7125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301194.jpg"}, {"question": "how would you best describe these people", "gt answer": "student(1.00)<br/>asian(0.60)", "pred answer": "counter", "question_id": 1908825, "best approach": "wiki, concept", "verif answer": "student", "anno approach": "wiki", "verif wiki answer": "student(0.6386)", "verif concept answer": "student(0.6210)", "verif image answer": "asian(0.6118)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190882.jpg"}, {"question": "what device is helping the man to stay afloat overhead", "gt answer": "parachute(1.00)<br/>kite(0.60)", "pred answer": "string", "question_id": 3287325, "best approach": "concept", "verif answer": "wind", "anno approach": "concept", "verif wiki answer": "wind(0.5584)", "verif concept answer": "parachute(0.5487)", "verif image answer": "wind(0.6012)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328732.jpg"}, {"question": "what type of party is this", "gt answer": "bachelorette(1.00)<br/>birthday(1.00)<br/>banana(0.60)", "pred answer": "dinner", "question_id": 1283345, "best approach": "wiki, concept, image", "verif answer": "bachelorette", "anno approach": "wiki", "verif wiki answer": "bachelorette(0.7288)", "verif concept answer": "bachelorette(0.7221)", "verif image answer": "bachelorette(0.7196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128334.jpg"}, {"question": "name a sport this animal is used in", "gt answer": "polo(1.00)<br/>horse race(0.60)<br/>race(0.60)", "pred answer": "horse race", "question_id": 1627755, "best approach": "wiki, concept, image", "verif answer": "horse race", "anno approach": "wiki", "verif wiki answer": "horse race(0.7204)", "verif concept answer": "horse race(0.7171)", "verif image answer": "horse race(0.7119)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162775.jpg"}, {"question": "what are they watching on the tv", "gt answer": "football(1.00)<br/>sport(0.60)<br/>tennis(0.60)<br/>soccer(0.60)", "pred answer": "wii", "question_id": 5676635, "best approach": "image", "verif answer": "sport", "anno approach": "image", "verif wiki answer": "sport(0.5232)", "verif concept answer": "sport(0.5044)", "verif image answer": "football(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567663.jpg"}, {"question": "simply based on the picture is this a 1st or 3rd world country", "gt answer": "3rd(1.00)<br/>3rd world(0.60)", "pred answer": "3rd world", "question_id": 2240055, "best approach": "wiki, concept, image", "verif answer": "3rd", "anno approach": "", "verif wiki answer": "3rd(0.7279)", "verif concept answer": "3rd(0.7277)", "verif image answer": "3rd(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224005.jpg"}, {"question": "how long would it have taken for this animal to walk after being born", "gt answer": "immediately(1.00)<br/>2 days(0.60)", "pred answer": "4 days", "question_id": 5684555, "best approach": "", "verif answer": "2 years", "anno approach": "", "verif wiki answer": "2 years(0.6740)", "verif concept answer": "2 years(0.6919)", "verif image answer": "2 years(0.7076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568455.jpg"}, {"question": "where are the men standing", "gt answer": "outside(1.00)<br/>outdoor(0.60)", "pred answer": "tent", "question_id": 4964445, "best approach": "", "verif answer": "banana", "anno approach": "", "verif wiki answer": "above(0.6186)", "verif concept answer": "above(0.6885)", "verif image answer": "banana(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496444.jpg"}, {"question": "where can i buy that bedspread", "gt answer": "online(1.00)<br/>store(0.60)<br/>walmart(0.60)<br/>amazon(0.60)", "pred answer": "store", "question_id": 2877825, "best approach": "wiki, concept, image", "verif answer": "amazon", "anno approach": "wiki", "verif wiki answer": "amazon(0.7035)", "verif concept answer": "amazon(0.6689)", "verif image answer": "amazon(0.6680)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287782.jpg"}, {"question": "what is in the mans mouth", "gt answer": "cigarette(1.00)", "pred answer": "toothbrush", "question_id": 5361385, "best approach": "", "verif answer": "toothbrush", "anno approach": "", "verif wiki answer": "toothbrush(0.7308)", "verif concept answer": "toothbrush(0.7310)", "verif image answer": "toothbrush(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536138.jpg"}, {"question": "what is the average speed of this vehicle", "gt answer": "20 mph(1.00)<br/>30 mph(0.60)<br/>30mph(0.60)<br/>60 mph(0.60)", "pred answer": "80 mph", "question_id": 1069735, "best approach": "wiki, concept", "verif answer": "30 mph", "anno approach": "wiki", "verif wiki answer": "20 mph(0.6933)", "verif concept answer": "20 mph(0.6665)", "verif image answer": "30 mph(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106973.jpg"}, {"question": "what food is this", "gt answer": "cookies(1.00)<br/>donut(0.60)<br/>cake(0.60)", "pred answer": "cake", "question_id": 5653115, "best approach": "concept", "verif answer": "doughnut", "anno approach": "concept", "verif wiki answer": "doughnut(0.7295)", "verif concept answer": "cake(0.7298)", "verif image answer": "doughnut(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000565311.jpg"}, {"question": "is this safe or dangerous for the dog", "gt answer": "danger(1.00)", "pred answer": "danger", "question_id": 4941905, "best approach": "", "verif answer": "safe", "anno approach": "", "verif wiki answer": "unsafe(0.7067)", "verif concept answer": "unsafe(0.7259)", "verif image answer": "safe(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494190.jpg"}, {"question": "what is on top of this pie", "gt answer": "cheese(1.00)", "pred answer": "spinach", "question_id": 2870065, "best approach": "", "verif answer": "fry", "anno approach": "", "verif wiki answer": "fry(0.7266)", "verif concept answer": "fry(0.6378)", "verif image answer": "fry(0.6308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287006.jpg"}, {"question": "what materials were used for these stuffed animals", "gt answer": "cotton(1.00)<br/>polyester(1.00)<br/>foam(0.60)", "pred answer": "cloth", "question_id": 1802855, "best approach": "wiki, concept, image", "verif answer": "polyester", "anno approach": "wiki", "verif wiki answer": "polyester(0.7202)", "verif concept answer": "polyester(0.7145)", "verif image answer": "polyester(0.6863)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180285.jpg"}, {"question": "what makes the hardwood floor shiny", "gt answer": "polish(1.00)", "pred answer": "light", "question_id": 5423915, "best approach": "", "verif answer": "light", "anno approach": "", "verif wiki answer": "light(0.6324)", "verif concept answer": "light(0.6437)", "verif image answer": "light(0.5896)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542391.jpg"}, {"question": "is this a snack or meal", "gt answer": "meal(1.00)<br/>snack(0.60)", "pred answer": "meal", "question_id": 5239475, "best approach": "wiki, concept", "verif answer": "meal", "anno approach": "wiki", "verif wiki answer": "meal(0.7309)", "verif concept answer": "meal(0.7103)", "verif image answer": "breakfast(0.5563)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523947.jpg"}, {"question": "what team is this player on", "gt answer": "brewer(1.00)", "pred answer": "yankees", "question_id": 247235, "best approach": "wiki, concept", "verif answer": "england", "anno approach": "", "verif wiki answer": "brewer(0.7089)", "verif concept answer": "brewer(0.7122)", "verif image answer": "england(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024723.jpg"}, {"question": "the woman in this scene is touching an item usually worn on what part of the body", "gt answer": "foot(1.00)", "pred answer": "stomach", "question_id": 3143785, "best approach": "wiki, concept", "verif answer": "foot", "anno approach": "concept, wiki", "verif wiki answer": "foot(0.5907)", "verif concept answer": "foot(0.6684)", "verif image answer": "12 inches(0.6117)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314378.jpg"}, {"question": "what object is this", "gt answer": "clock(1.00)", "pred answer": "clock", "question_id": 1116715, "best approach": "", "verif answer": "roman numeral", "anno approach": "", "verif wiki answer": "roman numeral(0.7310)", "verif concept answer": "roman numeral(0.7308)", "verif image answer": "roman numeral(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111671.jpg"}, {"question": "what do you call this type of window covering", "gt answer": "blind(1.00)<br/>shade(0.60)", "pred answer": "shade", "question_id": 2471215, "best approach": "wiki, concept, image", "verif answer": "shade", "anno approach": "wiki", "verif wiki answer": "shade(0.6995)", "verif concept answer": "shade(0.7091)", "verif image answer": "shade(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247121.jpg"}, {"question": "which group likes to ride these venicles", "gt answer": "biker(1.00)<br/>hell angel(0.60)", "pred answer": "racer", "question_id": 1369435, "best approach": "wiki, concept, image", "verif answer": "hell angel", "anno approach": "wiki", "verif wiki answer": "hell angel(0.6947)", "verif concept answer": "hell angel(0.6661)", "verif image answer": "hell angel(0.6494)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136943.jpg"}, {"question": "what rooms are pictured here", "gt answer": "kitchen and dine room(1.00)", "pred answer": "kitchen", "question_id": 1761745, "best approach": "image", "verif answer": "kitchen and dine room", "anno approach": "image", "verif wiki answer": "underhand(0.6175)", "verif concept answer": "friend(0.6199)", "verif image answer": "kitchen and dine room(0.7227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176174.jpg"}, {"question": "can you name the brand of the bike shown in the photo", "gt answer": "harley(1.00)<br/>honda(0.60)<br/>bicycle(0.60)<br/>schwinn(0.60)", "pred answer": "harley davidson", "question_id": 2056795, "best approach": "wiki, concept, image", "verif answer": "schwinn", "anno approach": "image, wiki", "verif wiki answer": "schwinn(0.6632)", "verif concept answer": "schwinn(0.6627)", "verif image answer": "schwinn(0.7257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205679.jpg"}, {"question": "this animal is known to not get along with what other animal", "gt answer": "dog(1.00)<br/>mice(0.60)", "pred answer": "dog", "question_id": 2937235, "best approach": "wiki, concept, image", "verif answer": "dog", "anno approach": "concept, wiki", "verif wiki answer": "dog(0.7127)", "verif concept answer": "dog(0.7051)", "verif image answer": "dog(0.6545)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293723.jpg"}, {"question": "how do i prepare the eggs in this photo", "gt answer": "over easy(1.00)<br/>fry(0.60)", "pred answer": "fry", "question_id": 1451885, "best approach": "concept, image", "verif answer": "over easy", "anno approach": "concept", "verif wiki answer": "fried(0.6026)", "verif concept answer": "over easy(0.6031)", "verif image answer": "over easy(0.5651)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145188.jpg"}, {"question": "what size bed is this", "gt answer": "king(1.00)<br/>double(0.60)<br/>queen(0.60)", "pred answer": "full", "question_id": 3327825, "best approach": "wiki, concept, image", "verif answer": "queen", "anno approach": "wiki", "verif wiki answer": "queen(0.7294)", "verif concept answer": "queen(0.7269)", "verif image answer": "queen(0.7008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332782.jpg"}, {"question": "what kind of cars are near the people", "gt answer": "cadillac(1.00)<br/>family(0.60)", "pred answer": "van", "question_id": 2433335, "best approach": "image", "verif answer": "mercedes", "anno approach": "image", "verif wiki answer": "mercedes(0.6244)", "verif concept answer": "mercedes(0.6288)", "verif image answer": "cadillac(0.5521)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243333.jpg"}, {"question": "where is this celebration taking place", "gt answer": "ship(1.00)<br/>graduation(0.60)", "pred answer": "wed", "question_id": 784825, "best approach": "wiki, image", "verif answer": "graduation", "anno approach": "wiki", "verif wiki answer": "graduation(0.6721)", "verif concept answer": "birthday(0.6687)", "verif image answer": "graduation(0.6836)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078482.jpg"}, {"question": "what are the health benefits of this vegetable", "gt answer": "fiber(1.00)<br/>vitamin(0.60)<br/>vision(0.60)", "pred answer": "vitamin", "question_id": 667375, "best approach": "", "verif answer": "protein", "anno approach": "", "verif wiki answer": "protein(0.7154)", "verif concept answer": "protein(0.6898)", "verif image answer": "calcium(0.6171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000066737.jpg"}, {"question": "what year was this sport invented", "gt answer": "1839(1.00)", "pred answer": "baseball", "question_id": 1512365, "best approach": "wiki, concept, image", "verif answer": "1839", "anno approach": "", "verif wiki answer": "1839(0.7198)", "verif concept answer": "1839(0.7136)", "verif image answer": "1839(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151236.jpg"}, {"question": "what material are the three colorful swaths made of", "gt answer": "silk(1.00)", "pred answer": "metal", "question_id": 5128455, "best approach": "wiki, concept, image", "verif answer": "silk", "anno approach": "wiki", "verif wiki answer": "silk(0.7133)", "verif concept answer": "silk(0.7243)", "verif image answer": "silk(0.7276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512845.jpg"}, {"question": "what console does the controller belong to", "gt answer": "xbox(1.00)", "pred answer": "wii", "question_id": 2459325, "best approach": "", "verif answer": "wii", "anno approach": "", "verif wiki answer": "wii(0.7310)", "verif concept answer": "wii(0.7309)", "verif image answer": "wii(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245932.jpg"}, {"question": "what object is this", "gt answer": "vase(1.00)", "pred answer": "flower", "question_id": 3103155, "best approach": "", "verif answer": "pottery", "anno approach": "", "verif wiki answer": "cookie cutter(0.5899)", "verif concept answer": "pot(0.5666)", "verif image answer": "pottery(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310315.jpg"}, {"question": "what cuisine is this", "gt answer": "german(1.00)<br/>italian(0.60)<br/>american(0.60)<br/>chicago(0.60)", "pred answer": "italian", "question_id": 1788125, "best approach": "image", "verif answer": "french", "anno approach": "image", "verif wiki answer": "french(0.7266)", "verif concept answer": "french(0.7294)", "verif image answer": "italian(0.7027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178812.jpg"}, {"question": "how much can they eat in a day", "gt answer": "lot(1.00)<br/>10 pounds(0.60)<br/>100 lbs(0.60)", "pred answer": "500", "question_id": 3219645, "best approach": "wiki, concept", "verif answer": "100 lbs", "anno approach": "", "verif wiki answer": "100 lbs(0.5998)", "verif concept answer": "100 lbs(0.6189)", "verif image answer": "20 pounds(0.6188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321964.jpg"}, {"question": "how do you cook this meat", "gt answer": "grill(1.00)", "pred answer": "grilled", "question_id": 1653735, "best approach": "", "verif answer": "fry", "anno approach": "", "verif wiki answer": "bbq(0.5817)", "verif concept answer": "bbq(0.5910)", "verif image answer": "fry(0.6186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000165373.jpg"}, {"question": "if you had to take a guess would you say that these are likely sweet or bitter", "gt answer": "sweet(1.00)", "pred answer": "sweet", "question_id": 1435015, "best approach": "wiki, concept", "verif answer": "sweet", "anno approach": "wiki", "verif wiki answer": "sweet(0.7240)", "verif concept answer": "sweet(0.7268)", "verif image answer": "salty(0.6652)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143501.jpg"}, {"question": "what is the silver item with many steps used for in this situation", "gt answer": "ladder(1.00)<br/>stair(0.60)", "pred answer": "transport", "question_id": 927315, "best approach": "", "verif answer": "rope", "anno approach": "", "verif wiki answer": "rope(0.6880)", "verif concept answer": "rope(0.6267)", "verif image answer": "rope(0.6530)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092731.jpg"}, {"question": "what kind of cheese is commonly on this dish", "gt answer": "mozzarella(1.00)", "pred answer": "mozzarella", "question_id": 524485, "best approach": "wiki, concept", "verif answer": "mozzarella", "anno approach": "wiki", "verif wiki answer": "mozzarella(0.7068)", "verif concept answer": "mozzarella(0.7067)", "verif image answer": "feta(0.6443)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052448.jpg"}, {"question": "what well known organization would offer this for adoption", "gt answer": "spca(1.00)<br/>aspca(0.60)", "pred answer": "aspca", "question_id": 1790885, "best approach": "image", "verif answer": "aspca", "anno approach": "image", "verif wiki answer": "ikea(0.6256)", "verif concept answer": "ikea(0.6638)", "verif image answer": "aspca(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000179088.jpg"}, {"question": "what material is the court surface", "gt answer": "concrete(1.00)<br/>wooden(0.60)<br/>asphalt(0.60)", "pred answer": "asphalt", "question_id": 868035, "best approach": "wiki, concept, image", "verif answer": "asphalt", "anno approach": "image, wiki", "verif wiki answer": "asphalt(0.7009)", "verif concept answer": "asphalt(0.6729)", "verif image answer": "asphalt(0.7256)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086803.jpg"}, {"question": "what is the ratio for hitting the ball called", "gt answer": "bat average(1.00)<br/>bat(0.60)", "pred answer": "homerun", "question_id": 5156385, "best approach": "", "verif answer": "baseball bat", "anno approach": "", "verif wiki answer": "baseball bat(0.5019)", "verif concept answer": "baseball bat(0.5060)", "verif image answer": "baseball bat(0.6276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515638.jpg"}, {"question": "what is the meaning of the white flowers in this arrangement", "gt answer": "purity(1.00)", "pred answer": "decoration", "question_id": 4636255, "best approach": "", "verif answer": "orchid", "anno approach": "", "verif wiki answer": "orchid(0.5898)", "verif concept answer": "orchid(0.5963)", "verif image answer": "orchid(0.6036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463625.jpg"}, {"question": "this young man is demonstrating something you shouldn't do what is it", "gt answer": "run with scissor(1.00)<br/>run(0.60)", "pred answer": "skateboard", "question_id": 817045, "best approach": "image", "verif answer": "play dead", "anno approach": "image", "verif wiki answer": "play dead(0.5010)", "verif concept answer": "play dead(0.5041)", "verif image answer": "run with scissor(0.5022)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081704.jpg"}, {"question": "what teams are playing in this image", "gt answer": "angel and dodger(1.00)", "pred answer": "dodger", "question_id": 4735535, "best approach": "", "verif answer": "dodger", "anno approach": "", "verif wiki answer": "dodger(0.7184)", "verif concept answer": "dodger(0.7177)", "verif image answer": "dodger(0.7221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473553.jpg"}, {"question": "who made those shoes", "gt answer": "shoemaker(1.00)<br/>nike(0.60)", "pred answer": "levis", "question_id": 2681905, "best approach": "wiki", "verif answer": "hardware store", "anno approach": "wiki", "verif wiki answer": "nike(0.5315)", "verif concept answer": "hardware store(0.5644)", "verif image answer": "walmart(0.5023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268190.jpg"}, {"question": "what type of event are the motorcyclists going to", "gt answer": "rally(1.00)<br/>party(0.60)", "pred answer": "race", "question_id": 3348405, "best approach": "wiki, concept, image", "verif answer": "rally", "anno approach": "wiki", "verif wiki answer": "rally(0.7180)", "verif concept answer": "rally(0.7266)", "verif image answer": "rally(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334840.jpg"}, {"question": "what dish is being prepared in this photo", "gt answer": "taco(1.00)", "pred answer": "cake", "question_id": 4251375, "best approach": "", "verif answer": "hotdog", "anno approach": "", "verif wiki answer": "hotdog(0.7273)", "verif concept answer": "hotdog(0.7306)", "verif image answer": "hotdog(0.7080)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425137.jpg"}, {"question": "what type of sound does this animal make", "gt answer": "neigh(1.00)", "pred answer": "moo", "question_id": 5194905, "best approach": "", "verif answer": "meow", "anno approach": "", "verif wiki answer": "meow(0.7233)", "verif concept answer": "moo(0.7230)", "verif image answer": "moo(0.7069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000519490.jpg"}, {"question": "why is this person using their foot", "gt answer": "flush(1.00)", "pred answer": "wash hand", "question_id": 4987825, "best approach": "wiki", "verif answer": "wash hand", "anno approach": "wiki", "verif wiki answer": "flush(0.6921)", "verif concept answer": "wash hand(0.6539)", "verif image answer": "wash hand(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000498782.jpg"}, {"question": "where on the body might this device be placed while working", "gt answer": "lap(1.00)<br/>shoulder(0.60)<br/>hand(0.60)", "pred answer": "head", "question_id": 5583175, "best approach": "", "verif answer": "butt", "anno approach": "", "verif wiki answer": "butt(0.5909)", "verif concept answer": "butt(0.5838)", "verif image answer": "butt(0.6501)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558317.jpg"}, {"question": "", "gt answer": "5 months(0.60)<br/>6 months(0.60)<br/>half(0.60)", "pred answer": "4 months", "question_id": 5314575, "best approach": "", "verif answer": "2 years", "anno approach": "", "verif wiki answer": "2 years(0.7292)", "verif concept answer": "2 years(0.6815)", "verif image answer": "2 years(0.5209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531457.jpg"}, {"question": "what is this sign used for", "gt answer": "traffic control(0.60)<br/>stop(1.00)<br/>stop traffic(0.60)", "pred answer": "stop", "question_id": 4652665, "best approach": "wiki, concept, image", "verif answer": "stop", "anno approach": "wiki", "verif wiki answer": "stop(0.6878)", "verif concept answer": "stop(0.7006)", "verif image answer": "stop(0.6805)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465266.jpg"}, {"question": "is this a laptop or desktop", "gt answer": "desktop(1.00)<br/>laptop(0.60)", "pred answer": "desktop", "question_id": 2648885, "best approach": "wiki, concept, image", "verif answer": "desktop", "anno approach": "wiki", "verif wiki answer": "desktop(0.7261)", "verif concept answer": "desktop(0.7161)", "verif image answer": "desktop(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000264888.jpg"}, {"question": "what skyline is this city in", "gt answer": "new york(1.00)<br/>chicago(0.60)", "pred answer": "harbor", "question_id": 2685235, "best approach": "", "verif answer": "boston", "anno approach": "", "verif wiki answer": "boston(0.5272)", "verif concept answer": "boston(0.5790)", "verif image answer": "boston(0.6073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268523.jpg"}, {"question": "what kind of jersey is this dog wearing", "gt answer": "football(1.00)<br/>sport(0.60)<br/>blue(0.60)", "pred answer": "polo", "question_id": 4506725, "best approach": "", "verif answer": "shirt", "anno approach": "", "verif wiki answer": "shirt(0.5235)", "verif concept answer": "shirt(0.6125)", "verif image answer": "shirt(0.5820)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450672.jpg"}, {"question": "is this an actual game of soccer or is just goofing around", "gt answer": "actual(1.00)", "pred answer": "soccer", "question_id": 1948455, "best approach": "wiki, concept", "verif answer": "normal", "anno approach": "wiki", "verif wiki answer": "actual(0.7260)", "verif concept answer": "actual(0.7309)", "verif image answer": "normal(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194845.jpg"}, {"question": "how old is that building", "gt answer": "200 years(1.00)", "pred answer": "100 years", "question_id": 5647335, "best approach": "", "verif answer": "100 years", "anno approach": "", "verif wiki answer": "roman(0.6777)", "verif concept answer": "100 years(0.6800)", "verif image answer": "roman(0.6639)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564733.jpg"}, {"question": "what type of mac is that", "gt answer": "desktop(1.00)<br/>macbook(0.60)", "pred answer": "mac", "question_id": 936345, "best approach": "wiki, concept", "verif answer": "macbook", "anno approach": "concept, wiki", "verif wiki answer": "macbook(0.5507)", "verif concept answer": "macbook(0.6053)", "verif image answer": "notebook(0.5677)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093634.jpg"}, {"question": "on what two continents do these animals live in the wild", "gt answer": "asia and africa(1.00)<br/>africa and asia(0.60)", "pred answer": "africa", "question_id": 3477365, "best approach": "", "verif answer": "africa", "anno approach": "", "verif wiki answer": "africa(0.6028)", "verif concept answer": "africa(0.5207)", "verif image answer": "africa(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347736.jpg"}, {"question": "what is the most popular type of this drink", "gt answer": "chardonnay(1.00)<br/>wine(0.60)<br/>alcoholic(0.60)", "pred answer": "wine", "question_id": 1976635, "best approach": "image", "verif answer": "chardonnay", "anno approach": "image", "verif wiki answer": "wine(0.6071)", "verif concept answer": "wine(0.6236)", "verif image answer": "chardonnay(0.6711)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197663.jpg"}, {"question": "where is this", "gt answer": "switzerland(1.00)<br/>scotland(0.60)", "pred answer": "farm", "question_id": 3414205, "best approach": "", "verif answer": "colorado", "anno approach": "", "verif wiki answer": "colorado(0.6182)", "verif concept answer": "colorado(0.6063)", "verif image answer": "colorado(0.6594)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341420.jpg"}, {"question": "what type of climate does this bird enjoy", "gt answer": "warm(1.00)<br/>rain(0.60)<br/>temperate(0.60)<br/>stormy(0.60)", "pred answer": "tropical", "question_id": 3316975, "best approach": "image", "verif answer": "tropical", "anno approach": "image", "verif wiki answer": "tropical(0.7310)", "verif concept answer": "tropical(0.7217)", "verif image answer": "temperate(0.6470)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331697.jpg"}, {"question": "what kind of clothing is this child wearing", "gt answer": "wetsuit(1.00)<br/>wet suit(0.60)", "pred answer": "wet suit", "question_id": 4174755, "best approach": "image", "verif answer": "wetsuit", "anno approach": "image", "verif wiki answer": "wet suit(0.7106)", "verif concept answer": "wet suit(0.7092)", "verif image answer": "wetsuit(0.7151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417475.jpg"}, {"question": "what type of animal is seen here", "gt answer": "bird(1.00)<br/>monkey(0.60)", "pred answer": "crow", "question_id": 4853695, "best approach": "wiki, concept, image", "verif answer": "bird", "anno approach": "image, concept, wiki", "verif wiki answer": "bird(0.6070)", "verif concept answer": "bird(0.6703)", "verif image answer": "bird(0.7271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485369.jpg"}, {"question": "where would you store this item in the kitchen", "gt answer": "fridge(1.00)<br/>refridgerator(0.60)", "pred answer": "produce", "question_id": 4876875, "best approach": "wiki", "verif answer": "refrigerator", "anno approach": "wiki", "verif wiki answer": "fridge(0.6903)", "verif concept answer": "refrigerator(0.7180)", "verif image answer": "refrigerator(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487687.jpg"}, {"question": "what are each scoring group in the sport called", "gt answer": "set(1.00)<br/>player(0.60)", "pred answer": "tennis", "question_id": 4006445, "best approach": "wiki, concept", "verif answer": "minor", "anno approach": "concept, wiki", "verif wiki answer": "player(0.5109)", "verif concept answer": "player(0.6180)", "verif image answer": "minor(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400644.jpg"}, {"question": "what kind of beverage is in the french press", "gt answer": "tea(1.00)<br/>coffee(1.00)", "pred answer": "coffee", "question_id": 3060805, "best approach": "concept, image", "verif answer": "coffee", "anno approach": "", "verif wiki answer": "breakfast(0.7302)", "verif concept answer": "coffee(0.7300)", "verif image answer": "coffee(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306080.jpg"}, {"question": "what is attached to this item when it is in use", "gt answer": "hose(1.00)", "pred answer": "hose", "question_id": 4445715, "best approach": "", "verif answer": "fire hydrant", "anno approach": "", "verif wiki answer": "fire hydrant(0.7300)", "verif concept answer": "fire hydrant(0.7278)", "verif image answer": "fire hydrant(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000444571.jpg"}, {"question": "what does this truck serve", "gt answer": "icecream(1.00)<br/>ice cream(0.60)", "pred answer": "ice cream", "question_id": 3448935, "best approach": "wiki, concept, image", "verif answer": "ice cream", "anno approach": "concept", "verif wiki answer": "ice cream(0.6644)", "verif concept answer": "ice cream(0.7069)", "verif image answer": "ice cream(0.6751)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344893.jpg"}, {"question": "what material is the backsplash made of", "gt answer": "tile(1.00)<br/>glass(1.00)", "pred answer": "tile", "question_id": 3211945, "best approach": "concept, image", "verif answer": "tile", "anno approach": "concept", "verif wiki answer": "window(0.6543)", "verif concept answer": "tile(0.6550)", "verif image answer": "tile(0.6206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321194.jpg"}, {"question": "what do they call this outside shopping area", "gt answer": "market(1.00)", "pred answer": "grocery", "question_id": 4604425, "best approach": "", "verif answer": "sell", "anno approach": "", "verif wiki answer": "sell(0.6582)", "verif concept answer": "sell(0.6700)", "verif image answer": "sell(0.6451)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460442.jpg"}, {"question": "what brand of tissues are in the picture", "gt answer": "kleenex(1.00)", "pred answer": "walmart", "question_id": 5696725, "best approach": "wiki, concept, image", "verif answer": "kleenex", "anno approach": "wiki", "verif wiki answer": "kleenex(0.6296)", "verif concept answer": "kleenex(0.6359)", "verif image answer": "kleenex(0.6329)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569672.jpg"}, {"question": "what species of bird is this", "gt answer": "sparrow(1.00)<br/>small(0.60)", "pred answer": "finch", "question_id": 4497275, "best approach": "", "verif answer": "finch", "anno approach": "", "verif wiki answer": "finch(0.6638)", "verif concept answer": "finch(0.6692)", "verif image answer": "finch(0.6621)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449727.jpg"}, {"question": "what fruit makes the liquid in the glass", "gt answer": "grape(1.00)", "pred answer": "orange", "question_id": 3893315, "best approach": "wiki, concept", "verif answer": "grape", "anno approach": "wiki", "verif wiki answer": "grape(0.5170)", "verif concept answer": "grape(0.5135)", "verif image answer": "tomato(0.5019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389331.jpg"}, {"question": "is the canine domestic or wild", "gt answer": "domestic(1.00)", "pred answer": "domestic", "question_id": 4048125, "best approach": "wiki, concept, image", "verif answer": "domestic", "anno approach": "image, wiki", "verif wiki answer": "domestic(0.6588)", "verif concept answer": "domestic(0.6664)", "verif image answer": "domestic(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404812.jpg"}, {"question": "what city is this", "gt answer": "new york city(1.00)<br/>new york(0.60)", "pred answer": "new york", "question_id": 80065, "best approach": "image", "verif answer": "new york city", "anno approach": "image", "verif wiki answer": "los angeles(0.5003)", "verif concept answer": "new york(0.5012)", "verif image answer": "new york city(0.6116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008006.jpg"}, {"question": "why is this happening to the dog 's ears", "gt answer": "sad(1.00)<br/>curious(0.60)<br/>fold(0.60)", "pred answer": "broken", "question_id": 2384525, "best approach": "wiki, concept", "verif answer": "fold", "anno approach": "wiki", "verif wiki answer": "fold(0.5070)", "verif concept answer": "fold(0.5089)", "verif image answer": "confused(0.5006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238452.jpg"}, {"question": "where is this train currently parked at", "gt answer": "station(1.00)", "pred answer": "train station", "question_id": 3358045, "best approach": "", "verif answer": "bus stop", "anno approach": "", "verif wiki answer": "bus stop(0.7207)", "verif concept answer": "midwest(0.6874)", "verif image answer": "bus stop(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335804.jpg"}, {"question": "what kind of architecture is shown", "gt answer": "greek(1.00)<br/>italian(0.60)<br/>gothic(0.60)", "pred answer": "greek", "question_id": 5273145, "best approach": "image", "verif answer": "roman", "anno approach": "image", "verif wiki answer": "roman(0.6814)", "verif concept answer": "roman(0.6750)", "verif image answer": "gothic(0.6738)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527314.jpg"}, {"question": "what decade was this", "gt answer": "1940's(1.00)<br/>1800s(0.60)", "pred answer": "1800's", "question_id": 4362885, "best approach": "image", "verif answer": "1800's", "anno approach": "image", "verif wiki answer": "1800's(0.6539)", "verif concept answer": "1800's(0.6621)", "verif image answer": "1940's(0.6412)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436288.jpg"}, {"question": "what type of sandwiches is she making", "gt answer": "sub(1.00)<br/>hotdogs(0.60)", "pred answer": "pastry", "question_id": 1676835, "best approach": "wiki, concept", "verif answer": "sub", "anno approach": "wiki", "verif wiki answer": "sub(0.6835)", "verif concept answer": "sub(0.7145)", "verif image answer": "hot dog(0.6992)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167683.jpg"}, {"question": "what kind of dog is surfing", "gt answer": "pitbull(1.00)<br/>labrador(0.60)", "pred answer": "collie", "question_id": 3652935, "best approach": "image", "verif answer": "labrador", "anno approach": "image", "verif wiki answer": "lab(0.6246)", "verif concept answer": "lab(0.6295)", "verif image answer": "labrador(0.6406)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365293.jpg"}, {"question": "what animal is chassing this sheep", "gt answer": "cat(1.00)<br/>dog(0.60)<br/>penguin(0.60)<br/>wolf(0.60)", "pred answer": "lion", "question_id": 128245, "best approach": "wiki, concept, image", "verif answer": "dog", "anno approach": "image, wiki", "verif wiki answer": "dog(0.6626)", "verif concept answer": "dog(0.6704)", "verif image answer": "dog(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012824.jpg"}, {"question": "what kind of pound cake is this", "gt answer": "lemon(1.00)<br/>vanilla(0.60)<br/>coffee(0.60)", "pred answer": "cake", "question_id": 5406335, "best approach": "", "verif answer": "carrot cake", "anno approach": "", "verif wiki answer": "carrot cake(0.6860)", "verif concept answer": "carrot cake(0.7114)", "verif image answer": "carrot cake(0.6732)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540633.jpg"}, {"question": "how much do you have to pay in order to take one of these", "gt answer": "$2.75(1.00)<br/>2 dollars(0.60)", "pred answer": "$2", "question_id": 4051315, "best approach": "wiki, concept", "verif answer": "2 dollars", "anno approach": "wiki", "verif wiki answer": "2 dollars(0.7302)", "verif concept answer": "2 dollars(0.7263)", "verif image answer": "online(0.7226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405131.jpg"}, {"question": "does this image depict political or apolitical speech", "gt answer": "political(1.00)", "pred answer": "sport event", "question_id": 5506425, "best approach": "image", "verif answer": "political", "anno approach": "image", "verif wiki answer": "roosevelt(0.5003)", "verif concept answer": "roosevelt(0.5011)", "verif image answer": "political(0.5154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550642.jpg"}, {"question": "what brand of computer is shown in this picture", "gt answer": "dell(1.00)<br/>ibm(0.60)<br/>hp(0.60)", "pred answer": "toshiba", "question_id": 315875, "best approach": "", "verif answer": "acer", "anno approach": "", "verif wiki answer": "acer(0.5739)", "verif concept answer": "acer(0.5613)", "verif image answer": "apple(0.5207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000031587.jpg"}, {"question": "where is this man standing in this photo", "gt answer": "sidewalk(1.00)<br/>center(0.60)", "pred answer": "sidewalk", "question_id": 1058535, "best approach": "", "verif answer": "crosswalk", "anno approach": "", "verif wiki answer": "crosswalk(0.6272)", "verif concept answer": "crosswalk(0.6753)", "verif image answer": "crosswalk(0.6693)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105853.jpg"}, {"question": "what fabric was used to construct the red suitcase the woman is pulling behind herself", "gt answer": "canvas(1.00)<br/>plastic(0.60)<br/>nylon(0.60)", "pred answer": "leather", "question_id": 69355, "best approach": "wiki, image", "verif answer": "nylon", "anno approach": "image, wiki", "verif wiki answer": "nylon(0.5392)", "verif concept answer": "metal(0.5682)", "verif image answer": "nylon(0.6729)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006935.jpg"}, {"question": "which one should wear sunscreen", "gt answer": "man(1.00)<br/>human(0.60)<br/>person(0.60)", "pred answer": "bull", "question_id": 2802065, "best approach": "image", "verif answer": "person", "anno approach": "image", "verif wiki answer": "coachman(0.5979)", "verif concept answer": "coachman(0.6058)", "verif image answer": "person(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280206.jpg"}, {"question": "what type of water sport is this", "gt answer": "kayak(1.00)<br/>canoe(0.60)", "pred answer": "wind surf", "question_id": 5117845, "best approach": "wiki, concept, image", "verif answer": "canoe", "anno approach": "concept, wiki", "verif wiki answer": "canoe(0.6538)", "verif concept answer": "canoe(0.6297)", "verif image answer": "canoe(0.5447)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511784.jpg"}, {"question": "what is the name of the children 's television show named after the vehicle in this picture", "gt answer": "thomas(1.00)<br/>thomas train(0.60)<br/>thomas tank engine(0.60)", "pred answer": "john henry", "question_id": 1510495, "best approach": "", "verif answer": "train", "anno approach": "", "verif wiki answer": "train(0.5267)", "verif concept answer": "train(0.5043)", "verif image answer": "train(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151049.jpg"}, {"question": "what does the remote need to work", "gt answer": "battery(1.00)", "pred answer": "bottle", "question_id": 5667135, "best approach": "", "verif answer": "bluetooth", "anno approach": "", "verif wiki answer": "bluetooth(0.6451)", "verif concept answer": "bluetooth(0.6724)", "verif image answer": "bluetooth(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566713.jpg"}, {"question": "what kind of bird is this", "gt answer": "parrot(1.00)<br/>tropical(0.60)<br/>parakeet(0.60)", "pred answer": "parakeet", "question_id": 2361985, "best approach": "concept, image", "verif answer": "parakeet", "anno approach": "", "verif wiki answer": "toucan(0.7276)", "verif concept answer": "parakeet(0.7287)", "verif image answer": "parakeet(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236198.jpg"}, {"question": "what tool is there", "gt answer": "scissor(1.00)", "pred answer": "hammer", "question_id": 371575, "best approach": "wiki, concept, image", "verif answer": "scissor", "anno approach": "wiki", "verif wiki answer": "scissor(0.5688)", "verif concept answer": "scissor(0.5204)", "verif image answer": "scissor(0.5078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000037157.jpg"}, {"question": "what famous singer dances and sings while holding one of these", "gt answer": "gene kelly(1.00)", "pred answer": "babe ruth", "question_id": 1960355, "best approach": "wiki, concept, image", "verif answer": "gene kelly", "anno approach": "concept", "verif wiki answer": "gene kelly(0.5453)", "verif concept answer": "gene kelly(0.5729)", "verif image answer": "gene kelly(0.5395)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196035.jpg"}, {"question": "what are the doors in the background called", "gt answer": "slide(1.00)<br/>sleep(0.60)", "pred answer": "window", "question_id": 4414935, "best approach": "", "verif answer": "steal", "anno approach": "", "verif wiki answer": "steal(0.7185)", "verif concept answer": "steal(0.7090)", "verif image answer": "steal(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441493.jpg"}, {"question": "which brand of car is shown in this picture", "gt answer": "chevrolet(1.00)<br/>gmc(0.60)", "pred answer": "ford", "question_id": 2074555, "best approach": "wiki, concept, image", "verif answer": "chevrolet", "anno approach": "wiki", "verif wiki answer": "chevrolet(0.5766)", "verif concept answer": "chevrolet(0.6047)", "verif image answer": "chevrolet(0.5972)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207455.jpg"}, {"question": "what substance was used to create this painting", "gt answer": "oil(1.00)<br/>paint(0.60)", "pred answer": "paint", "question_id": 4079675, "best approach": "wiki, concept", "verif answer": "transport good", "anno approach": "wiki", "verif wiki answer": "paint(0.6367)", "verif concept answer": "paint(0.6653)", "verif image answer": "transport good(0.7107)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407967.jpg"}]
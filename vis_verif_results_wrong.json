[{"question": "why might one assume that at least some of these people listened to a weather forecast before going out", "gt answer": "they have umbrella(1.00)<br/>umbrella(0.60)", "pred answer": "rain", "question_id": 4048525, "best approach": "", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "rain(0.6851)", "verif concept answer": "roof(0.5560)", "verif image answer": "roof(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404852.jpg"}, {"question": "what is the purpose of the hanging object", "gt answer": "light(1.00)", "pred answer": "decor", "question_id": 5317255, "best approach": "concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "illumination(0.6058)", "verif concept answer": "light(0.6223)", "verif image answer": "illumination(0.6939)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531725.jpg"}, {"question": "what type of shirt is the blue one known as", "gt answer": "button up(1.00)<br/>flannel(0.60)", "pred answer": "button down", "question_id": 5016255, "best approach": "image", "verif answer": "button down", "anno approach": "wiki, concept, image", "verif wiki answer": "jean(0.5262)", "verif concept answer": "cotton(0.5409)", "verif image answer": "flannel(0.7049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501625.jpg"}, {"question": "what breed of cat is this", "gt answer": "ragdoll(1.00)<br/>persian(0.60)", "pred answer": "domestic shorthair", "question_id": 2736075, "best approach": "", "verif answer": "domestic", "anno approach": "wiki, concept, image", "verif wiki answer": "calico(0.6111)", "verif concept answer": "calico(0.6545)", "verif image answer": "calico(0.7141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273607.jpg"}, {"question": "is the dog sad or just sleepy", "gt answer": "sleepy(1.00)<br/>sad(0.60)", "pred answer": "tired", "question_id": 4999305, "best approach": "image", "verif answer": "tired", "anno approach": "wiki, concept, image", "verif wiki answer": "happy(0.5666)", "verif concept answer": "happy(0.5641)", "verif image answer": "sad(0.5972)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499930.jpg"}, {"question": "what kitchen machine is being used to make food", "gt answer": "blender(1.00)<br/>chopper(0.60)<br/>mixer(0.60)", "pred answer": "microwave", "question_id": 1144685, "best approach": "wiki, concept", "verif answer": "blender", "anno approach": "wiki, concept, image", "verif wiki answer": "mixer(0.5460)", "verif concept answer": "mixer(0.6766)", "verif image answer": "smoothie(0.6570)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114468.jpg"}, {"question": "what quadruped has lent a part of its body to furnish the name of this hairdo", "gt answer": "pony tail(1.00)<br/>pony(1.00)<br/>horse(0.60)", "pred answer": "neck", "question_id": 1378295, "best approach": "wiki, concept", "verif answer": "donkey", "anno approach": "wiki, concept, image", "verif wiki answer": "pony tail(0.5470)", "verif concept answer": "pony tail(0.6138)", "verif image answer": "clydesdale(0.5126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000137829.jpg"}, {"question": "when was the first of these lights installed", "gt answer": "1914(1.00)<br/>1912(0.60)", "pred answer": "2000", "question_id": 533305, "best approach": "wiki, concept", "verif answer": "1914", "anno approach": "wiki, concept, image", "verif wiki answer": "1914(0.6331)", "verif concept answer": "1914(0.6525)", "verif image answer": "1948(0.5953)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053330.jpg"}, {"question": "what is the relationship between these two animals", "gt answer": "family(1.00)<br/>mother and child(1.00)", "pred answer": "friend", "question_id": 1889225, "best approach": "wiki, concept", "verif answer": "family", "anno approach": "wiki, concept, image", "verif wiki answer": "mother and child(0.6641)", "verif concept answer": "family(0.6970)", "verif image answer": "0(0.6707)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188922.jpg"}, {"question": "where do you think we are", "gt answer": "baseball stadium(1.00)<br/>school(0.60)<br/>texas(0.60)<br/>america(0.60)", "pred answer": "train station", "question_id": 829805, "best approach": "", "verif answer": "school", "anno approach": "wiki, concept, image", "verif wiki answer": "usa(0.6559)", "verif concept answer": "usa(0.6782)", "verif image answer": "usa(0.7106)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082980.jpg"}, {"question": "what type of exercises can you do to work out this portion of the body", "gt answer": "pushups(1.00)", "pred answer": "arm", "question_id": 85925, "best approach": "wiki, image", "verif answer": "modern", "anno approach": "wiki, concept, image", "verif wiki answer": "pushups(0.6014)", "verif concept answer": "modern(0.6430)", "verif image answer": "pushups(0.7142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008592.jpg"}, {"question": "what are the boxes for", "gt answer": "storage(1.00)", "pred answer": "travel", "question_id": 4293185, "best approach": "", "verif answer": "storage", "anno approach": "wiki, concept, image", "verif wiki answer": "protection(0.6542)", "verif concept answer": "protection(0.5753)", "verif image answer": "cook(0.7124)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429318.jpg"}, {"question": "what process is used to make most of the foods in this image", "gt answer": "fermentation(1.00)<br/>age(0.60)<br/>mix(0.60)", "pred answer": "bake", "question_id": 586095, "best approach": "wiki, concept", "verif answer": "bake", "anno approach": "wiki, concept, image", "verif wiki answer": "age(0.6402)", "verif concept answer": "age(0.6583)", "verif image answer": "bake(0.6931)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058609.jpg"}, {"question": "what year is this plane", "gt answer": "1945(1.00)<br/>1946(0.60)<br/>1948(0.60)", "pred answer": "2000", "question_id": 5265065, "best approach": "wiki, concept", "verif answer": "1948", "anno approach": "wiki, concept, image", "verif wiki answer": "1945(0.7217)", "verif concept answer": "1945(0.6905)", "verif image answer": "1948(0.7053)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526506.jpg"}, {"question": "what mountain ridge are they near", "gt answer": "alp(1.00)", "pred answer": "rockies", "question_id": 3246695, "best approach": "wiki, concept", "verif answer": "rockies", "anno approach": "wiki, concept, image", "verif wiki answer": "alp(0.6820)", "verif concept answer": "alp(0.6955)", "verif image answer": "snowy(0.7155)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324669.jpg"}, {"question": "what kind of truck is that and what is in the truck", "gt answer": "sushi(1.00)<br/>food(0.60)<br/>ice cream(0.60)", "pred answer": "garbage", "question_id": 5150205, "best approach": "image", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "meat(0.5506)", "verif concept answer": "meat(0.6523)", "verif image answer": "food(0.6645)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515020.jpg"}, {"question": "can you guess the place name shown in this picture where these sheeps are standing", "gt answer": "scotland(1.00)<br/>pasture(0.60)<br/>ireland(0.60)", "pred answer": "meadow", "question_id": 2533075, "best approach": "wiki, concept", "verif answer": "pasture", "anno approach": "wiki, concept, image", "verif wiki answer": "ireland(0.6077)", "verif concept answer": "ireland(0.6403)", "verif image answer": "england(0.6564)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253307.jpg"}, {"question": "what is the man in the white shirt doing", "gt answer": "dive(1.00)<br/>fall(0.60)", "pred answer": "rugby", "question_id": 2664415, "best approach": "wiki", "verif answer": "catch", "anno approach": "wiki, concept, image", "verif wiki answer": "dive(0.5976)", "verif concept answer": "catch(0.6232)", "verif image answer": "play soccer(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266441.jpg"}, {"question": "is this a custom car or a restoration", "gt answer": "restoration(1.00)<br/>custom(0.60)", "pred answer": "antique", "question_id": 5789455, "best approach": "concept", "verif answer": "antique", "anno approach": "wiki, concept, image", "verif wiki answer": "brand(0.6613)", "verif concept answer": "restoration(0.6152)", "verif image answer": "modern(0.7137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578945.jpg"}, {"question": "what religion is being catered to at the stores shown", "gt answer": "catholic(1.00)<br/>christianity(0.60)<br/>buddhism(0.60)", "pred answer": "christian", "question_id": 3001985, "best approach": "image", "verif answer": "catholic", "anno approach": "wiki, concept, image", "verif wiki answer": "christianity(0.7163)", "verif concept answer": "christianity(0.6929)", "verif image answer": "catholic(0.6520)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300198.jpg"}, {"question": "what type of veggies was used in this dish", "gt answer": "kale(1.00)<br/>broccoli(0.60)<br/>spinach(0.60)<br/>green(0.60)", "pred answer": "lettuce", "question_id": 982205, "best approach": "wiki, concept", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "green(0.6657)", "verif concept answer": "green(0.7101)", "verif image answer": "vegetable(0.5835)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098220.jpg"}, {"question": "what event is he skiing for", "gt answer": "race(1.00)<br/>downhill(0.60)<br/>competition(0.60)<br/>cross country(0.60)", "pred answer": "ski", "question_id": 1197995, "best approach": "wiki, concept", "verif answer": "competition", "anno approach": "wiki, concept, image", "verif wiki answer": "cross country(0.6227)", "verif concept answer": "competition(0.6906)", "verif image answer": "run(0.7248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119799.jpg"}, {"question": "who is credited with creating the first of this object", "gt answer": "frederick graff(1.00)<br/>frederick graff sr(0.60)", "pred answer": "artist", "question_id": 5560885, "best approach": "concept, image", "verif answer": "russia", "anno approach": "wiki, concept, image", "verif wiki answer": "russia(0.5699)", "verif concept answer": "frederick graff(0.6362)", "verif image answer": "frederick graff(0.7131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556088.jpg"}, {"question": "what type of cuisine are they eating", "gt answer": "french(1.00)<br/>cheese(0.60)<br/>asian(0.60)<br/>american(0.60)", "pred answer": "italian", "question_id": 627435, "best approach": "wiki, concept", "verif answer": "french", "anno approach": "wiki, concept, image", "verif wiki answer": "asian(0.6716)", "verif concept answer": "american(0.6357)", "verif image answer": "western(0.6925)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000062743.jpg"}, {"question": "first car of this is also called a", "gt answer": "engine(1.00)", "pred answer": "locomotive", "question_id": 4074665, "best approach": "concept", "verif answer": "engine", "anno approach": "wiki, concept, image", "verif wiki answer": "motor(0.6780)", "verif concept answer": "engine(0.6289)", "verif image answer": "motor(0.6791)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407466.jpg"}, {"question": "what is the name of this flower", "gt answer": "daffodil(1.00)", "pred answer": "dandelion", "question_id": 3175215, "best approach": "image", "verif answer": "daffodil", "anno approach": "wiki, concept, image", "verif wiki answer": "tulip(0.5889)", "verif concept answer": "tulip(0.6985)", "verif image answer": "daffodil(0.7146)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317521.jpg"}, {"question": "what kind of macaroni is this", "gt answer": "elbow(1.00)<br/>kraft(0.60)", "pred answer": "shrimp", "question_id": 3732945, "best approach": "wiki, concept", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "elbow(0.6841)", "verif concept answer": "elbow(0.6892)", "verif image answer": "pistachio(0.7096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373294.jpg"}, {"question": "what brand of shoes is the white woman wearing", "gt answer": "converse(1.00)<br/>new balance(0.60)", "pred answer": "nike", "question_id": 3704935, "best approach": "wiki", "verif answer": "nike", "anno approach": "wiki, concept, image", "verif wiki answer": "converse(0.6821)", "verif concept answer": "nike(0.6334)", "verif image answer": "nike(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370493.jpg"}, {"question": "what activity do the objects in this picture suggest is taking place", "gt answer": "homework(1.00)<br/>study(1.00)", "pred answer": "work", "question_id": 2905495, "best approach": "wiki", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "study(0.5889)", "verif concept answer": "laptop(0.6002)", "verif image answer": "work(0.6435)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000290549.jpg"}, {"question": "is the horse pulling people or resting", "gt answer": "rest(1.00)", "pred answer": "walk", "question_id": 3129585, "best approach": "", "verif answer": "rest", "anno approach": "wiki, concept, image", "verif wiki answer": "tired(0.5204)", "verif concept answer": "tired(0.5390)", "verif image answer": "tired(0.5469)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312958.jpg"}, {"question": "what type of herb is on top of this slice", "gt answer": "basil(1.00)<br/>spinach(0.60)<br/>parsley(0.60)", "pred answer": "pepper", "question_id": 615025, "best approach": "wiki, concept", "verif answer": "pepper", "anno approach": "wiki, concept, image", "verif wiki answer": "spinach(0.6362)", "verif concept answer": "parsley(0.5434)", "verif image answer": "pepper(0.7166)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061502.jpg"}, {"question": "what olympic event is this person participating in", "gt answer": "ski(1.00)<br/>slalom(0.60)", "pred answer": "olympics", "question_id": 3725115, "best approach": "wiki, concept, image", "verif answer": "olympics", "anno approach": "wiki, concept, image", "verif wiki answer": "ski(0.6178)", "verif concept answer": "ski(0.6758)", "verif image answer": "ski(0.6908)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372511.jpg"}, {"question": "where would you typically eat this in the house", "gt answer": "dine room(1.00)<br/>kitchen(1.00)<br/>live room(0.60)", "pred answer": "restaurant", "question_id": 5509605, "best approach": "wiki, concept", "verif answer": "kitchen", "anno approach": "wiki, concept, image", "verif wiki answer": "kitchen(0.5563)", "verif concept answer": "kitchen(0.5918)", "verif image answer": "dine(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550960.jpg"}, {"question": "in what cultural did the decoration hanging on the wall originate", "gt answer": "native american(1.00)<br/>china(0.60)", "pred answer": "country", "question_id": 5577685, "best approach": "wiki, concept", "verif answer": "china", "anno approach": "wiki, concept, image", "verif wiki answer": "native american(0.5513)", "verif concept answer": "native american(0.5951)", "verif image answer": "china(0.6248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557768.jpg"}, {"question": "what other kind of food could you pour this sauce on", "gt answer": "turkey(1.00)<br/>potato(0.60)", "pred answer": "meat", "question_id": 4913305, "best approach": "wiki, concept, image", "verif answer": "potato", "anno approach": "wiki, concept, image", "verif wiki answer": "potato(0.5638)", "verif concept answer": "potato(0.5555)", "verif image answer": "potato(0.7012)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491330.jpg"}, {"question": "what type of tree is growing behind this couple", "gt answer": "fir(1.00)<br/>pine(1.00)", "pred answer": "oak", "question_id": 3636565, "best approach": "wiki, concept, image", "verif answer": "fir", "anno approach": "wiki, concept, image", "verif wiki answer": "fir(0.5520)", "verif concept answer": "fir(0.5978)", "verif image answer": "pine(0.6973)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363656.jpg"}, {"question": "the metal object over the stove goes by what name similar to a garment", "gt answer": "hood(1.00)<br/>pan(0.60)", "pred answer": "fan", "question_id": 2901535, "best approach": "image", "verif answer": "pan", "anno approach": "wiki, concept, image", "verif wiki answer": "pan(0.6140)", "verif concept answer": "pan(0.5526)", "verif image answer": "hood(0.6942)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000290153.jpg"}, {"question": "who rides in this", "gt answer": "firemen(1.00)<br/>passenger(0.60)<br/>firefight(0.60)", "pred answer": "driver", "question_id": 1331455, "best approach": "wiki", "verif answer": "human", "anno approach": "wiki, concept, image", "verif wiki answer": "passenger(0.5621)", "verif concept answer": "kid(0.5646)", "verif image answer": "human(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000133145.jpg"}, {"question": "what kind of truck is this", "gt answer": "fire truck(1.00)<br/>firetruck(1.00)<br/>fire(0.60)", "pred answer": "food truck", "question_id": 1164625, "best approach": "wiki, concept", "verif answer": "food truck", "anno approach": "wiki, concept, image", "verif wiki answer": "fire(0.6630)", "verif concept answer": "fire(0.6418)", "verif image answer": "tow truck(0.6923)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116462.jpg"}, {"question": "which item depicted here is also associated with lattes", "gt answer": "whipped cream(1.00)<br/>cream(1.00)", "pred answer": "spoon", "question_id": 2195905, "best approach": "wiki, concept", "verif answer": "pie", "anno approach": "wiki, concept, image", "verif wiki answer": "whipped cream(0.6678)", "verif concept answer": "whipped cream(0.6814)", "verif image answer": "pie(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219590.jpg"}, {"question": "for what reason the yellow colored lines are painted", "gt answer": "boundary(1.00)<br/>basketball(0.60)", "pred answer": "paint", "question_id": 3412065, "best approach": "wiki, concept", "verif answer": "football", "anno approach": "wiki, concept, image", "verif wiki answer": "boundary(0.6250)", "verif concept answer": "boundary(0.6689)", "verif image answer": "low(0.6705)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341206.jpg"}, {"question": "what is the man putting in the microwave", "gt answer": "bowl(1.00)<br/>soup(0.60)", "pred answer": "bread", "question_id": 3747265, "best approach": "", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "juice(0.6035)", "verif concept answer": "juice(0.6594)", "verif image answer": "juice(0.7156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374726.jpg"}, {"question": "how often would these bowls need food in them", "gt answer": "twice day(1.00)<br/>daily(1.00)", "pred answer": "never", "question_id": 2661655, "best approach": "concept, image", "verif answer": "twice day", "anno approach": "wiki, concept, image", "verif wiki answer": "monthly(0.5911)", "verif concept answer": "daily(0.5971)", "verif image answer": "twice day(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266165.jpg"}, {"question": "what breed of dog is this", "gt answer": "terrier(1.00)<br/>sheep(0.60)<br/>schnauzer(0.60)", "pred answer": "lab", "question_id": 2925875, "best approach": "wiki, concept", "verif answer": "terrier", "anno approach": "wiki, concept, image", "verif wiki answer": "terrier(0.6458)", "verif concept answer": "terrier(0.7016)", "verif image answer": "labradoodle(0.6283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292587.jpg"}, {"question": "what is the white part of this water called", "gt answer": "foam(1.00)<br/>tide(0.60)<br/>surf(0.60)", "pred answer": "wave", "question_id": 5766535, "best approach": "concept", "verif answer": "wave", "anno approach": "wiki, concept, image", "verif wiki answer": "boogie board(0.6197)", "verif concept answer": "foam(0.6273)", "verif image answer": "boogie board(0.6783)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000576653.jpg"}, {"question": "what type of airplane is shown in this image", "gt answer": "biplane(1.00)<br/>prop(0.60)", "pred answer": "glider", "question_id": 5276375, "best approach": "wiki, concept, image", "verif answer": "biplane", "anno approach": "wiki, concept, image", "verif wiki answer": "biplane(0.7086)", "verif concept answer": "biplane(0.6973)", "verif image answer": "biplane(0.7219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527637.jpg"}, {"question": "where is this animal found in the wild", "gt answer": "wood(1.00)<br/>mountain(0.60)<br/>bear(0.60)", "pred answer": "forest", "question_id": 1365875, "best approach": "wiki", "verif answer": "forest", "anno approach": "wiki, concept, image", "verif wiki answer": "wood(0.6247)", "verif concept answer": "mountain(0.6732)", "verif image answer": "zoo(0.6661)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136587.jpg"}, {"question": "from what animal does this meat come from", "gt answer": "pig(1.00)<br/>lamb(1.00)", "pred answer": "pork", "question_id": 1256895, "best approach": "wiki, concept, image", "verif answer": "lamb", "anno approach": "wiki, concept, image", "verif wiki answer": "pig(0.5240)", "verif concept answer": "lamb(0.5220)", "verif image answer": "lamb(0.6064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125689.jpg"}, {"question": "what company manufactured this skateboard", "gt answer": "hasbro(1.00)", "pred answer": "burton", "question_id": 1272675, "best approach": "", "verif answer": "element", "anno approach": "wiki, concept, image", "verif wiki answer": "build bear(0.6362)", "verif concept answer": "wilson(0.6165)", "verif image answer": "wilson(0.7100)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127267.jpg"}, {"question": "what city does the team in blue play for", "gt answer": "cleveland(1.00)<br/>los angeles(0.60)", "pred answer": "baltimore", "question_id": 527515, "best approach": "wiki, concept", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "cleveland(0.7168)", "verif concept answer": "cleveland(0.7196)", "verif image answer": "ohio(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052751.jpg"}, {"question": "what does this womans hand gesture mean", "gt answer": "peace(1.00)", "pred answer": "hello", "question_id": 2770385, "best approach": "wiki, concept", "verif answer": "peace", "anno approach": "wiki, concept, image", "verif wiki answer": "peace(0.6541)", "verif concept answer": "peace(0.6230)", "verif image answer": "0(0.5982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277038.jpg"}, {"question": "what powers the front most vehicle", "gt answer": "feet(1.00)<br/>people(0.60)<br/>pedal(0.60)<br/>person(0.60)", "pred answer": "gas", "question_id": 832195, "best approach": "concept, image", "verif answer": "people", "anno approach": "wiki, concept, image", "verif wiki answer": "person(0.5334)", "verif concept answer": "feet(0.5853)", "verif image answer": "feet(0.6648)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083219.jpg"}, {"question": "what is the name of the tennis play", "gt answer": "serve(1.00)<br/>swing(0.60)<br/>boy(0.60)<br/>forehand(0.60)", "pred answer": "tennis", "question_id": 4181785, "best approach": "image", "verif answer": "swing", "anno approach": "wiki, concept, image", "verif wiki answer": "hit ball(0.6467)", "verif concept answer": "hit ball(0.6609)", "verif image answer": "boy(0.5073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000418178.jpg"}, {"question": "what kind of sandwich is this", "gt answer": "ham and cheese(1.00)<br/>breakfast(0.60)<br/>grilled(0.60)", "pred answer": "turkey", "question_id": 3122825, "best approach": "wiki", "verif answer": "ham", "anno approach": "wiki, concept, image", "verif wiki answer": "ham and cheese(0.6915)", "verif concept answer": "breakfast(0.7196)", "verif image answer": "grilled(0.6872)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312282.jpg"}, {"question": "which item depicted is also a word that means to filter", "gt answer": "screen(1.00)", "pred answer": "sunlight", "question_id": 4794615, "best approach": "wiki, concept, image", "verif answer": "screen", "anno approach": "wiki, concept, image", "verif wiki answer": "screen(0.6647)", "verif concept answer": "screen(0.6510)", "verif image answer": "screen(0.6964)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479461.jpg"}, {"question": "what is a large group of these animals called", "gt answer": "herd(1.00)<br/>flock(1.00)<br/>ram(0.60)", "pred answer": "sheep", "question_id": 2538295, "best approach": "wiki, concept, image", "verif answer": "flock", "anno approach": "wiki, concept, image", "verif wiki answer": "herd(0.7182)", "verif concept answer": "flock(0.7272)", "verif image answer": "herd(0.6739)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253829.jpg"}, {"question": "what is the state of the business on the left", "gt answer": "open(1.00)<br/>cafe(0.60)", "pred answer": "good", "question_id": 3468175, "best approach": "image", "verif answer": "market", "anno approach": "wiki, concept, image", "verif wiki answer": "market(0.6577)", "verif concept answer": "market(0.6213)", "verif image answer": "cafe(0.6867)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346817.jpg"}, {"question": "are these mosquito nets for guests or students", "gt answer": "guest(1.00)<br/>student(0.60)", "pred answer": "tourist", "question_id": 3497915, "best approach": "wiki, concept", "verif answer": "student", "anno approach": "wiki, concept, image", "verif wiki answer": "guest(0.7297)", "verif concept answer": "guest(0.7249)", "verif image answer": "student(0.7105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000349791.jpg"}, {"question": "which languages use non latin letters like those depicted", "gt answer": "indian(1.00)<br/>chinese(0.60)<br/>india(0.60)", "pred answer": "english", "question_id": 3913975, "best approach": "wiki, concept, image", "verif answer": "chinese", "anno approach": "wiki, concept, image", "verif wiki answer": "chinese(0.6465)", "verif concept answer": "india(0.7096)", "verif image answer": "india(0.7043)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391397.jpg"}, {"question": "this montage is reminiscent of which card game that requires matching pairs", "gt answer": "memory(1.00)", "pred answer": "taxi", "question_id": 3830145, "best approach": "", "verif answer": "pizza", "anno approach": "wiki, concept, image", "verif wiki answer": "eat(0.5322)", "verif concept answer": "eat(0.5438)", "verif image answer": "ivory(0.6628)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383014.jpg"}, {"question": "what type of puzzle do you see", "gt answer": "crossword(1.00)", "pred answer": "square", "question_id": 3652985, "best approach": "wiki", "verif answer": "checkered", "anno approach": "wiki, concept, image", "verif wiki answer": "crossword(0.5356)", "verif concept answer": "tie(0.6307)", "verif image answer": "tie(0.7113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365298.jpg"}, {"question": "how many servings of this food does the average american consume yearly", "gt answer": "46(1.00)<br/>300(0.60)<br/>20(0.60)<br/>400(0.60)", "pred answer": "12", "question_id": 3006295, "best approach": "wiki, concept, image", "verif answer": "12", "anno approach": "wiki, concept, image", "verif wiki answer": "20(0.6221)", "verif concept answer": "400(0.6383)", "verif image answer": "300(0.6857)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300629.jpg"}, {"question": "what are a bundle of these fruits called", "gt answer": "bunch(1.00)", "pred answer": "apple", "question_id": 1229395, "best approach": "", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "orange(0.5097)", "verif concept answer": "orange(0.5683)", "verif image answer": "plantain(0.6395)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122939.jpg"}, {"question": "what could this picture be an advertisement for", "gt answer": "toothpaste(1.00)<br/>shave(0.60)", "pred answer": "sing", "question_id": 1388465, "best approach": "concept", "verif answer": "shave", "anno approach": "wiki, concept, image", "verif wiki answer": "mirror(0.5260)", "verif concept answer": "toothpaste(0.5601)", "verif image answer": "shave(0.5921)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138846.jpg"}, {"question": "what airline is this plane", "gt answer": "southwest(1.00)<br/>american airline(0.60)", "pred answer": "boeing", "question_id": 5556585, "best approach": "wiki, concept", "verif answer": "boeing", "anno approach": "wiki, concept, image", "verif wiki answer": "southwest(0.6930)", "verif concept answer": "southwest(0.6700)", "verif image answer": "american(0.6736)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555658.jpg"}, {"question": "what breed are these racehorses", "gt answer": "new(0.60)<br/>stallion(1.00)", "pred answer": "mustang", "question_id": 2453265, "best approach": "wiki, concept", "verif answer": "arabian", "anno approach": "wiki, concept, image", "verif wiki answer": "stallion(0.7243)", "verif concept answer": "stallion(0.6770)", "verif image answer": "draft(0.6940)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245326.jpg"}, {"question": "how old must you be to drink this legally", "gt answer": "21(1.00)", "pred answer": "18", "question_id": 4779435, "best approach": "wiki", "verif answer": "21", "anno approach": "wiki, concept, image", "verif wiki answer": "21(0.7019)", "verif concept answer": "18(0.6256)", "verif image answer": "51(0.6410)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477943.jpg"}, {"question": "what type of oil was used if any", "gt answer": "olive(1.00)<br/>olive oil(0.60)", "pred answer": "omega 3", "question_id": 1579115, "best approach": "image", "verif answer": "olive oil", "anno approach": "wiki, concept, image", "verif wiki answer": "vegetable(0.6381)", "verif concept answer": "sesame(0.6734)", "verif image answer": "olive(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157911.jpg"}, {"question": "who makes these scooters", "gt answer": "yamaha(1.00)<br/>bmw(0.60)<br/>honda(0.60)", "pred answer": "harley davidson", "question_id": 3187805, "best approach": "wiki", "verif answer": "harley", "anno approach": "wiki, concept, image", "verif wiki answer": "honda(0.6543)", "verif concept answer": "kawasaki(0.6902)", "verif image answer": "harley(0.6883)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318780.jpg"}, {"question": "how are these women able to talk to each other", "gt answer": "skype(1.00)<br/>video(0.60)", "pred answer": "haircut", "question_id": 979995, "best approach": "image", "verif answer": "scissor", "anno approach": "wiki, concept, image", "verif wiki answer": "scissor(0.6778)", "verif concept answer": "scissor(0.7141)", "verif image answer": "video(0.6662)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097999.jpg"}, {"question": "what is this fixture used for", "gt answer": "potty(1.00)", "pred answer": "toilet", "question_id": 2374135, "best approach": "", "verif answer": "puke", "anno approach": "wiki, concept, image", "verif wiki answer": "park meter(0.6279)", "verif concept answer": "puke(0.6227)", "verif image answer": "cat(0.6534)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237413.jpg"}, {"question": "which object is the biggest parenting hazzard", "gt answer": "fireplace(1.00)<br/>tv(1.00)", "pred answer": "chair", "question_id": 189385, "best approach": "", "verif answer": "tv", "anno approach": "wiki, concept, image", "verif wiki answer": "screen(0.6992)", "verif concept answer": "screen(0.7000)", "verif image answer": "screen(0.7226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000018938.jpg"}, {"question": "how much does this animal usually weigh", "gt answer": "300 pounds(1.00)<br/>500 pounds(0.60)<br/>400 lbs(0.60)<br/>1000 lbs(0.60)", "pred answer": "100 lbs", "question_id": 5717745, "best approach": "wiki, concept, image", "verif answer": "1000 lbs", "anno approach": "wiki, concept, image", "verif wiki answer": "1000 lbs(0.5935)", "verif concept answer": "500 pounds(0.6654)", "verif image answer": "500 pounds(0.7006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571774.jpg"}, {"question": "what sporting event is this", "gt answer": "motorcross(1.00)<br/>dirt bike(0.60)<br/>motorbike(0.60)", "pred answer": "bike", "question_id": 3653145, "best approach": "wiki, concept", "verif answer": "motocross", "anno approach": "wiki, concept, image", "verif wiki answer": "dirt bike(0.6925)", "verif concept answer": "dirt bike(0.6578)", "verif image answer": "motocross(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365314.jpg"}, {"question": "home much does a train tank weigh", "gt answer": "3 tons(1.00)<br/>10000(0.60)", "pred answer": "million", "question_id": 4879525, "best approach": "wiki", "verif answer": "million", "anno approach": "wiki, concept, image", "verif wiki answer": "3 tons(0.6505)", "verif concept answer": "million(0.6639)", "verif image answer": "police(0.5808)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487952.jpg"}, {"question": "what event is this", "gt answer": "ted talk(1.00)<br/>train(0.60)", "pred answer": "meet", "question_id": 3939545, "best approach": "wiki", "verif answer": "kite", "anno approach": "wiki, concept, image", "verif wiki answer": "ted talk(0.5857)", "verif concept answer": "birthday(0.6084)", "verif image answer": "train(0.7016)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393954.jpg"}, {"question": "what decade did this sport first become popular", "gt answer": "70s(1.00)<br/>1950(0.60)<br/>1970's(0.60)", "pred answer": "1960's", "question_id": 719085, "best approach": "image", "verif answer": "1960's", "anno approach": "wiki, concept, image", "verif wiki answer": "1980's(0.7143)", "verif concept answer": "1960's(0.5977)", "verif image answer": "1950(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071908.jpg"}, {"question": "where was the sauce made at", "gt answer": "tomato(1.00)<br/>factory(0.60)<br/>kitchen(0.60)<br/>home(0.60)", "pred answer": "restaurant", "question_id": 2149555, "best approach": "wiki, concept, image", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "home(0.6640)", "verif concept answer": "home(0.6609)", "verif image answer": "home(0.7035)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214955.jpg"}, {"question": "what language is on the sign", "gt answer": "english(1.00)<br/>french(1.00)", "pred answer": "spanish", "question_id": 5725855, "best approach": "wiki, image", "verif answer": "spanish", "anno approach": "wiki, concept, image", "verif wiki answer": "french(0.7103)", "verif concept answer": "spanish(0.7112)", "verif image answer": "french(0.7148)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572585.jpg"}, {"question": "name the dress material of this boy shown in this picture", "gt answer": "nylon(1.00)<br/>ski suit(0.60)<br/>snowsuit(0.60)", "pred answer": "neoprene", "question_id": 2746905, "best approach": "image", "verif answer": "neoprene", "anno approach": "wiki, concept, image", "verif wiki answer": "ski suit(0.7056)", "verif concept answer": "snowsuit(0.7176)", "verif image answer": "nylon(0.6612)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274690.jpg"}, {"question": "what type of pastry is in front of the man", "gt answer": "donut(1.00)", "pred answer": "doughnut", "question_id": 586945, "best approach": "wiki", "verif answer": "doughnut", "anno approach": "wiki, concept, image", "verif wiki answer": "donut(0.6577)", "verif concept answer": "doughnut(0.6971)", "verif image answer": "doughnut(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058694.jpg"}, {"question": "what are the long objects in the water", "gt answer": "canoes(1.00)<br/>canoe(0.60)<br/>boat(0.60)<br/>row boat(0.60)", "pred answer": "surfboard", "question_id": 3356305, "best approach": "wiki", "verif answer": "row boat", "anno approach": "wiki, concept, image", "verif wiki answer": "canoes(0.6478)", "verif concept answer": "row boat(0.6177)", "verif image answer": "row(0.6940)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335630.jpg"}, {"question": "what is this animals stage of life", "gt answer": "early(1.00)<br/>baby(0.60)", "pred answer": "infant", "question_id": 161125, "best approach": "concept", "verif answer": "infant", "anno approach": "wiki, concept, image", "verif wiki answer": "infant(0.6044)", "verif concept answer": "early(0.6189)", "verif image answer": "child(0.7181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016112.jpg"}, {"question": "when you return a product and it must be placed back on the floor typically in spaces like these you might be charged a re what fee", "gt answer": "restock(1.00)<br/>money(0.60)", "pred answer": "office", "question_id": 1797705, "best approach": "", "verif answer": "camera", "anno approach": "wiki, concept, image", "verif wiki answer": "video(0.5138)", "verif concept answer": "camera(0.5426)", "verif image answer": "video(0.5232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000179770.jpg"}, {"question": "how many stomachs does this animal have", "gt answer": "1(1.00)<br/>2(1.00)<br/>4(0.60)", "pred answer": "7", "question_id": 4091315, "best approach": "wiki", "verif answer": "3", "anno approach": "wiki, concept, image", "verif wiki answer": "2(0.6818)", "verif concept answer": "1 year(0.6629)", "verif image answer": "3(0.6783)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409131.jpg"}, {"question": "what do you call a racing event for this mode of transportation", "gt answer": "regatta(1.00)<br/>sailboat(0.60)", "pred answer": "sail", "question_id": 4128485, "best approach": "image", "verif answer": "sail", "anno approach": "wiki, concept, image", "verif wiki answer": "wind surf(0.6813)", "verif concept answer": "sailboat(0.6481)", "verif image answer": "regatta(0.5812)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412848.jpg"}, {"question": "why are the leaves not green", "gt answer": "autumn(1.00)", "pred answer": "spring", "question_id": 3237205, "best approach": "", "verif answer": "spring", "anno approach": "wiki, concept, image", "verif wiki answer": "fall(0.6802)", "verif concept answer": "fall(0.6402)", "verif image answer": "spring(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323720.jpg"}, {"question": "what type of bird is this", "gt answer": "goose(1.00)<br/>duck(0.60)", "pred answer": "pelican", "question_id": 4693735, "best approach": "image", "verif answer": "pelican", "anno approach": "wiki, concept, image", "verif wiki answer": "pelican(0.7210)", "verif concept answer": "pelican(0.7221)", "verif image answer": "goose(0.7093)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469373.jpg"}, {"question": "", "gt answer": "danish(0.60)<br/>fire(0.60)<br/>creme brule(0.60)", "pred answer": "cake", "question_id": 2961695, "best approach": "wiki, concept, image", "verif answer": "pancake", "anno approach": "wiki, concept, image", "verif wiki answer": "danish(0.5837)", "verif concept answer": "danish(0.6149)", "verif image answer": "danish(0.6646)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296169.jpg"}, {"question": "where would this usually happen", "gt answer": "on lake(1.00)<br/>airport(0.60)<br/>alaska(0.60)<br/>lake(0.60)", "pred answer": "beach", "question_id": 1562045, "best approach": "image", "verif answer": "alaska", "anno approach": "wiki, concept, image", "verif wiki answer": "airport(0.6604)", "verif concept answer": "airport(0.6530)", "verif image answer": "on lake(0.6767)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000156204.jpg"}, {"question": "what is the name of the attatchment being pointed to", "gt answer": "bidet(1.00)<br/>fountain(0.60)", "pred answer": "fire", "question_id": 3234705, "best approach": "wiki", "verif answer": "toilet", "anno approach": "wiki, concept, image", "verif wiki answer": "bidet(0.5647)", "verif concept answer": "toilet(0.5937)", "verif image answer": "urinal(0.7149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323470.jpg"}, {"question": "what do the peas represent", "gt answer": "mouth(1.00)<br/>tongue(0.60)<br/>eye(0.60)<br/>hair(0.60)", "pred answer": "eat", "question_id": 3693975, "best approach": "wiki", "verif answer": "hair", "anno approach": "wiki, concept, image", "verif wiki answer": "mouth(0.5114)", "verif concept answer": "cucumber(0.5666)", "verif image answer": "hair(0.5522)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369397.jpg"}, {"question": "what could he be in danger of triggering", "gt answer": "avalanche(1.00)", "pred answer": "fall", "question_id": 4589085, "best approach": "wiki, concept", "verif answer": "fall", "anno approach": "wiki, concept, image", "verif wiki answer": "avalanche(0.6916)", "verif concept answer": "avalanche(0.6949)", "verif image answer": "fall(0.6179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458908.jpg"}, {"question": "what is the brand of the keyboard shown", "gt answer": "sony(1.00)<br/>motorola(0.60)<br/>ibm(0.60)<br/>hp(0.60)", "pred answer": "samsung", "question_id": 1261805, "best approach": "wiki", "verif answer": "dell", "anno approach": "wiki, concept, image", "verif wiki answer": "sony(0.5896)", "verif concept answer": "motorola(0.5461)", "verif image answer": "motorola(0.6843)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126180.jpg"}, {"question": "what model of boat is this", "gt answer": "speed(1.00)<br/>motor boat(0.60)", "pred answer": "outboard", "question_id": 5086785, "best approach": "wiki, concept", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "motor boat(0.6903)", "verif concept answer": "motor boat(0.6688)", "verif image answer": "wooden(0.5615)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000508678.jpg"}, {"question": "what on this plate is an animal", "gt answer": "turkey(1.00)<br/>cow(0.60)<br/>chicken(0.60)", "pred answer": "shrimp", "question_id": 250455, "best approach": "wiki, concept, image", "verif answer": "cow", "anno approach": "wiki, concept, image", "verif wiki answer": "chicken(0.6146)", "verif concept answer": "chicken(0.6688)", "verif image answer": "cow(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025045.jpg"}, {"question": "are these items raw or cooked", "gt answer": "raw(1.00)", "pred answer": "cooked", "question_id": 1861315, "best approach": "", "verif answer": "cooked", "anno approach": "wiki, concept, image", "verif wiki answer": "cooked(0.6775)", "verif concept answer": "boiled(0.6324)", "verif image answer": "boiled(0.7169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186131.jpg"}, {"question": "what does the pole display", "gt answer": "flag(1.00)", "pred answer": "light", "question_id": 5357135, "best approach": "", "verif answer": "book", "anno approach": "wiki, concept, image", "verif wiki answer": "name(0.5863)", "verif concept answer": "shield(0.5946)", "verif image answer": "name(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535713.jpg"}, {"question": "the fish in the scene is in which pixar movie", "gt answer": "find nemo(1.00)", "pred answer": "despicable me", "question_id": 2963775, "best approach": "wiki, concept, image", "verif answer": "hotdog", "anno approach": "wiki, concept, image", "verif wiki answer": "find nemo(0.7258)", "verif concept answer": "find nemo(0.6311)", "verif image answer": "find nemo(0.6083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296377.jpg"}, {"question": "what genus of flower is placed inside the vase", "gt answer": "daisy(1.00)<br/>orchid(0.60)", "pred answer": "rose", "question_id": 3153745, "best approach": "", "verif answer": "rose", "anno approach": "wiki, concept, image", "verif wiki answer": "lily(0.6580)", "verif concept answer": "rose(0.6927)", "verif image answer": "pansy(0.6683)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315374.jpg"}, {"question": "", "gt answer": "horse jump(0.60)<br/>ride(0.60)<br/>equestrian(0.60)", "pred answer": "horse race", "question_id": 5128385, "best approach": "", "verif answer": "horse race", "anno approach": "wiki, concept, image", "verif wiki answer": "horse race(0.6031)", "verif concept answer": "horse race(0.7021)", "verif image answer": "horse race(0.5775)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512838.jpg"}, {"question": "what south american singer is famous for wearing these on her head", "gt answer": "carmen miranda(1.00)", "pred answer": "gene kelly", "question_id": 5045545, "best approach": "", "verif answer": "gene kelly", "anno approach": "wiki, concept, image", "verif wiki answer": "gene kelly(0.5360)", "verif concept answer": "gene kelly(0.5901)", "verif image answer": "gene kelly(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000504554.jpg"}, {"question": "what activity is this", "gt answer": "sing(1.00)<br/>baseball(0.60)<br/>national anthem(0.60)", "pred answer": "rodeo", "question_id": 328455, "best approach": "wiki, concept, image", "verif answer": "national anthem", "anno approach": "wiki, concept, image", "verif wiki answer": "national anthem(0.6384)", "verif concept answer": "baseball(0.7150)", "verif image answer": "national anthem(0.6977)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032845.jpg"}, {"question": "how many tiers is this dish", "gt answer": "3(1.00)", "pred answer": "12", "question_id": 55875, "best approach": "", "verif answer": "3", "anno approach": "wiki, concept, image", "verif wiki answer": "4(0.6758)", "verif concept answer": "5(0.6190)", "verif image answer": "1(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005587.jpg"}, {"question": "how often does this animal participate in this activity daily", "gt answer": "20 hours(1.00)<br/>less(0.60)<br/>very(0.60)", "pred answer": "monthly", "question_id": 1781935, "best approach": "wiki", "verif answer": "million", "anno approach": "wiki, concept, image", "verif wiki answer": "20 hours(0.6140)", "verif concept answer": "million(0.6594)", "verif image answer": "million(0.6876)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178193.jpg"}, {"question": "what is the minimum speed this plane must achieve to lift off from the ground", "gt answer": "150 mph(1.00)<br/>150mph(0.60)<br/>100(0.60)", "pred answer": "30000 feet", "question_id": 3973535, "best approach": "wiki", "verif answer": "100", "anno approach": "wiki, concept, image", "verif wiki answer": "150 mph(0.7002)", "verif concept answer": "150mph(0.5332)", "verif image answer": "100(0.5964)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397353.jpg"}, {"question": "what part of the traffic day is this", "gt answer": "rush hour(1.00)", "pred answer": "city", "question_id": 1084465, "best approach": "wiki, concept, image", "verif answer": "rush hour", "anno approach": "wiki, concept, image", "verif wiki answer": "rush hour(0.7255)", "verif concept answer": "rush hour(0.6731)", "verif image answer": "rush hour(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108446.jpg"}, {"question": "what is an elephant trainer called", "gt answer": "elephant trainer(1.00)<br/>mahout(0.60)", "pred answer": "mother", "question_id": 3007825, "best approach": "concept", "verif answer": "little bo peep", "anno approach": "wiki, concept, image", "verif wiki answer": "lassie(0.6332)", "verif concept answer": "mahout(0.6285)", "verif image answer": "lassie(0.6745)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300782.jpg"}, {"question": "what type of animals are these", "gt answer": "cow(0.60)<br/>rhino(1.00)", "pred answer": "elephant", "question_id": 5291175, "best approach": "", "verif answer": "rhino", "anno approach": "wiki, concept, image", "verif wiki answer": "bull(0.5941)", "verif concept answer": "horse(0.6478)", "verif image answer": "bull(0.5213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529117.jpg"}, {"question": "", "gt answer": "direction(0.60)<br/>1 way(0.60)", "pred answer": "street name", "question_id": 116055, "best approach": "", "verif answer": "direct", "anno approach": "wiki, concept, image", "verif wiki answer": "direct(0.5487)", "verif concept answer": "direct(0.6252)", "verif image answer": "turn(0.5221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011605.jpg"}, {"question": "what institution are these men a part of", "gt answer": "university(1.00)", "pred answer": "subway", "question_id": 249725, "best approach": "", "verif answer": "college", "anno approach": "wiki, concept, image", "verif wiki answer": "college(0.6481)", "verif concept answer": "police(0.6322)", "verif image answer": "police(0.6715)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024972.jpg"}, {"question": "what type of leavening does the bread use", "gt answer": "yeast(1.00)<br/>0(1.00)", "pred answer": "wheat", "question_id": 2912075, "best approach": "wiki, concept", "verif answer": "0", "anno approach": "wiki, concept, image", "verif wiki answer": "0(0.6762)", "verif concept answer": "yeast(0.6989)", "verif image answer": "glazed(0.6695)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291207.jpg"}, {"question": "what period of the day does this image look like", "gt answer": "day(1.00)<br/>even(0.60)<br/>afternoon(0.60)<br/>sunset(0.60)", "pred answer": "747", "question_id": 494345, "best approach": "wiki", "verif answer": "day", "anno approach": "wiki, concept, image", "verif wiki answer": "day(0.7017)", "verif concept answer": "afternoon(0.6099)", "verif image answer": "sunset(0.6376)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049434.jpg"}, {"question": "what kind of phone is this child holding", "gt answer": "cell(1.00)<br/>cellphone(0.60)", "pred answer": "flip phone", "question_id": 3675235, "best approach": "", "verif answer": "smartphone", "anno approach": "wiki, concept, image", "verif wiki answer": "phone(0.6832)", "verif concept answer": "smartphone(0.6292)", "verif image answer": "smartphone(0.6219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367523.jpg"}, {"question": "what was the type of plastic in the dogs mouth", "gt answer": "bottle(1.00)<br/>regular(0.60)", "pred answer": "milk", "question_id": 2881575, "best approach": "wiki, concept", "verif answer": "bottle", "anno approach": "wiki, concept, image", "verif wiki answer": "bottle(0.5351)", "verif concept answer": "bottle(0.5393)", "verif image answer": "chair(0.7112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288157.jpg"}, {"question": "what ingredients are in this", "gt answer": "ice cream(1.00)<br/>sugar(0.60)<br/>cashew(0.60)", "pred answer": "meat", "question_id": 4311125, "best approach": "image", "verif answer": "cashew", "anno approach": "wiki, concept, image", "verif wiki answer": "cashew(0.5998)", "verif concept answer": "cashew(0.6606)", "verif image answer": "ice cream(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431112.jpg"}, {"question": "this guy is skate boarding in front of what city building", "gt answer": "court house(1.00)<br/>courthouse(0.60)", "pred answer": "new york", "question_id": 5357775, "best approach": "wiki", "verif answer": "philadelphia", "anno approach": "wiki, concept, image", "verif wiki answer": "courthouse(0.6339)", "verif concept answer": "philadelphia(0.6292)", "verif image answer": "philadelphia(0.6302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535777.jpg"}, {"question": "what are these horses doing", "gt answer": "plow(1.00)<br/>mow(0.60)", "pred answer": "stand", "question_id": 558795, "best approach": "concept, image", "verif answer": "farm", "anno approach": "wiki, concept, image", "verif wiki answer": "cart(0.5305)", "verif concept answer": "plow(0.6394)", "verif image answer": "plow(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000055879.jpg"}, {"question": "what is the name of the baby animals shown here", "gt answer": "cub(1.00)", "pred answer": "polar bear", "question_id": 814765, "best approach": "", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "red sox(0.6524)", "verif concept answer": "red sox(0.6963)", "verif image answer": "yankees(0.6889)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081476.jpg"}, {"question": "what low to the ground position is the umpire in", "gt answer": "squat(1.00)<br/>crouch(1.00)", "pred answer": "pitcher", "question_id": 5216635, "best approach": "wiki, concept, image", "verif answer": "batter", "anno approach": "wiki, concept, image", "verif wiki answer": "crouch(0.7099)", "verif concept answer": "squat(0.6854)", "verif image answer": "crouch(0.7165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521663.jpg"}, {"question": "are they remodeling or is it just a mess", "gt answer": "mess(1.00)", "pred answer": "clean", "question_id": 1738435, "best approach": "", "verif answer": "broken", "anno approach": "wiki, concept, image", "verif wiki answer": "broken(0.5436)", "verif concept answer": "broken(0.5463)", "verif image answer": "graffiti(0.6048)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000173843.jpg"}, {"question": "what juice is advertized on the truck", "gt answer": "coconut(1.00)", "pred answer": "juice", "question_id": 1044435, "best approach": "", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "pineapple(0.5667)", "verif concept answer": "pineapple(0.6058)", "verif image answer": "apple(0.5647)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000104443.jpg"}, {"question": "what is the boy doing", "gt answer": "cut paper(1.00)<br/>cut(0.60)<br/>play(0.60)", "pred answer": "brush teeth", "question_id": 4736785, "best approach": "concept", "verif answer": "cut", "anno approach": "wiki, concept, image", "verif wiki answer": "sew(0.6366)", "verif concept answer": "cut(0.6260)", "verif image answer": "sew(0.7151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473678.jpg"}, {"question": "what are two common cooking methods for this food", "gt answer": "grill(1.00)", "pred answer": "bake", "question_id": 803865, "best approach": "", "verif answer": "fry", "anno approach": "wiki, concept, image", "verif wiki answer": "bbq(0.5523)", "verif concept answer": "bbq(0.5927)", "verif image answer": "fry(0.7276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080386.jpg"}, {"question": "what do they use to clean off the side walk", "gt answer": "shovel(1.00)", "pred answer": "water", "question_id": 5230345, "best approach": "wiki, concept", "verif answer": "park meter", "anno approach": "wiki, concept, image", "verif wiki answer": "shovel(0.6172)", "verif concept answer": "shovel(0.7019)", "verif image answer": "plate(0.7198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523034.jpg"}, {"question": "what team is that", "gt answer": "red(1.00)", "pred answer": "cardinal", "question_id": 1290045, "best approach": "", "verif answer": "cardinal", "anno approach": "wiki, concept, image", "verif wiki answer": "cardinal(0.6678)", "verif concept answer": "cardinal(0.6382)", "verif image answer": "cardinal(0.6837)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129004.jpg"}, {"question": "what is the average life span of this type of animal", "gt answer": "20(1.00)<br/>40 years(0.60)<br/>20 years(0.60)", "pred answer": "30 years", "question_id": 5293795, "best approach": "image", "verif answer": "20 years", "anno approach": "wiki, concept, image", "verif wiki answer": "15 years(0.6871)", "verif concept answer": "15 years(0.6471)", "verif image answer": "20 years(0.6321)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529379.jpg"}, {"question": "when did these communication devices become popular", "gt answer": "2000s(1.00)<br/>2000(0.60)<br/>1990's(0.60)", "pred answer": "1973", "question_id": 4478835, "best approach": "wiki, concept, image", "verif answer": "2000", "anno approach": "wiki, concept, image", "verif wiki answer": "2000(0.6591)", "verif concept answer": "1990's(0.6053)", "verif image answer": "1990's(0.5995)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447883.jpg"}, {"question": "this sport can be found in what international sports event every four years", "gt answer": "olympics(1.00)<br/>ski(0.60)", "pred answer": "downhill", "question_id": 3421905, "best approach": "wiki, concept", "verif answer": "downhill", "anno approach": "wiki, concept, image", "verif wiki answer": "olympics(0.7185)", "verif concept answer": "olympics(0.6993)", "verif image answer": "downhill(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342190.jpg"}, {"question": "what animal is being mimicked in this food art", "gt answer": "dolphin(1.00)", "pred answer": "monkey", "question_id": 1340725, "best approach": "", "verif answer": "ladybug", "anno approach": "wiki, concept, image", "verif wiki answer": "griffin(0.5035)", "verif concept answer": "ladybug(0.5365)", "verif image answer": "fish(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134072.jpg"}, {"question": "what is the purpose of this picture", "gt answer": "advertising(1.00)<br/>fun(0.60)", "pred answer": "swim", "question_id": 1546675, "best approach": "image", "verif answer": "fun", "anno approach": "wiki, concept, image", "verif wiki answer": "sponsor(0.5860)", "verif concept answer": "sponsor(0.6555)", "verif image answer": "advertising(0.6589)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154667.jpg"}, {"question": "what movie focuses around two of these vehicles", "gt answer": "chip(1.00)", "pred answer": "easy rider", "question_id": 3885035, "best approach": "wiki, concept, image", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "chip(0.5558)", "verif concept answer": "chip(0.6550)", "verif image answer": "chip(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388503.jpg"}, {"question": "what type of sandwich is this", "gt answer": "egg salad(1.00)<br/>egg(1.00)", "pred answer": "steak", "question_id": 2845295, "best approach": "wiki, concept", "verif answer": "vegetarian", "anno approach": "wiki, concept, image", "verif wiki answer": "egg(0.6986)", "verif concept answer": "egg(0.6980)", "verif image answer": "vegetarian(0.7086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284529.jpg"}, {"question": "what do these animals eat", "gt answer": "peanut(1.00)<br/>leaf(0.60)<br/>vegetation(0.60)<br/>grass(0.60)", "pred answer": "plant", "question_id": 5573345, "best approach": "wiki, image", "verif answer": "plant", "anno approach": "wiki, concept, image", "verif wiki answer": "vegetation(0.6712)", "verif concept answer": "plant(0.6516)", "verif image answer": "leaf(0.6884)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557334.jpg"}, {"question": "where can you buy a bed like this", "gt answer": "furniture store(1.00)<br/>japan(0.60)<br/>ikea(0.60)", "pred answer": "store", "question_id": 1759235, "best approach": "wiki", "verif answer": "store", "anno approach": "wiki, concept, image", "verif wiki answer": "ikea(0.6860)", "verif concept answer": "store(0.6477)", "verif image answer": "store(0.6050)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000175923.jpg"}, {"question": "what are these people doing that shows they are relaxing", "gt answer": "sit(1.00)", "pred answer": "watch tv", "question_id": 4299605, "best approach": "image", "verif answer": "sleep", "anno approach": "wiki, concept, image", "verif wiki answer": "reflection(0.6098)", "verif concept answer": "forest gump(0.6917)", "verif image answer": "sit(0.7059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429960.jpg"}, {"question": "", "gt answer": "direction(0.60)", "pred answer": "float", "question_id": 3756655, "best approach": "", "verif answer": "direct", "anno approach": "wiki, concept, image", "verif wiki answer": "1 way(0.5657)", "verif concept answer": "turn(0.6420)", "verif image answer": "1 way(0.6270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375665.jpg"}, {"question": "is this a hotel or a residential area", "gt answer": "hotel(1.00)<br/>residential(0.60)", "pred answer": "private", "question_id": 3824475, "best approach": "image", "verif answer": "house", "anno approach": "wiki, concept, image", "verif wiki answer": "house(0.7013)", "verif concept answer": "queen(0.6911)", "verif image answer": "residential(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382447.jpg"}, {"question": "what sport are they playing", "gt answer": "soccer(1.00)<br/>football(0.60)", "pred answer": "baseball", "question_id": 609045, "best approach": "", "verif answer": "football", "anno approach": "wiki, concept, image", "verif wiki answer": "tennis(0.6755)", "verif concept answer": "frisbee(0.6682)", "verif image answer": "soccer ball(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060904.jpg"}, {"question": "what is the object that is on the red thing called", "gt answer": "hat(1.00)<br/>bonnet(0.60)", "pred answer": "face", "question_id": 749475, "best approach": "wiki", "verif answer": "bonnet", "anno approach": "wiki, concept, image", "verif wiki answer": "hat(0.6622)", "verif concept answer": "beanie(0.6460)", "verif image answer": "tie(0.6721)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074947.jpg"}, {"question": "what 's inside the item the cat is sleeping on", "gt answer": "stuffing(1.00)<br/>bat(0.60)", "pred answer": "cloth", "question_id": 3231645, "best approach": "", "verif answer": "stuffing", "anno approach": "wiki, concept, image", "verif wiki answer": "toy(0.6351)", "verif concept answer": "teddy bear(0.6231)", "verif image answer": "toy(0.7213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323164.jpg"}, {"question": "which team won the most recent championship in the pictured sport", "gt answer": "houston astros(1.00)<br/>dodger(0.60)", "pred answer": "cardinal", "question_id": 1867915, "best approach": "wiki, concept", "verif answer": "astros", "anno approach": "wiki, concept, image", "verif wiki answer": "dodger(0.7121)", "verif concept answer": "dodger(0.6973)", "verif image answer": "astros(0.7258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186791.jpg"}, {"question": "what bird appears in this picture", "gt answer": "eagle(1.00)", "pred answer": "hawk", "question_id": 4731005, "best approach": "", "verif answer": "hawk", "anno approach": "wiki, concept, image", "verif wiki answer": "pelican(0.7160)", "verif concept answer": "pelican(0.7232)", "verif image answer": "pelican(0.6385)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473100.jpg"}, {"question": "where might i find this", "gt answer": "flower shop(1.00)<br/>wed(0.60)<br/>garden(0.60)", "pred answer": "museum", "question_id": 1275435, "best approach": "wiki, concept, image", "verif answer": "wed", "anno approach": "wiki, concept, image", "verif wiki answer": "garden(0.7220)", "verif concept answer": "garden(0.7219)", "verif image answer": "garden(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127543.jpg"}, {"question": "what safety precaution did both of these people take", "gt answer": "helmet(1.00)<br/>yield(0.60)", "pred answer": "ladder", "question_id": 5055015, "best approach": "wiki, concept, image", "verif answer": "helmet", "anno approach": "wiki, concept, image", "verif wiki answer": "helmet(0.5258)", "verif concept answer": "helmet(0.5369)", "verif image answer": "helmet(0.5963)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505501.jpg"}, {"question": "what is the floating vest constructed from", "gt answer": "foam(1.00)<br/>neoprene(0.60)", "pred answer": "polyester", "question_id": 4609955, "best approach": "wiki", "verif answer": "polyester", "anno approach": "wiki, concept, image", "verif wiki answer": "neoprene(0.7093)", "verif concept answer": "polyester(0.7036)", "verif image answer": "polyester(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460995.jpg"}, {"question": "what happens next", "gt answer": "horse jump(1.00)<br/>jump(0.60)<br/>ride(0.60)", "pred answer": "race", "question_id": 5295005, "best approach": "wiki, concept, image", "verif answer": "ride", "anno approach": "wiki, concept, image", "verif wiki answer": "ride(0.6988)", "verif concept answer": "jump(0.6741)", "verif image answer": "jump(0.6876)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529500.jpg"}, {"question": "the potatoes are refered to what based on their shape", "gt answer": "wedge(1.00)<br/>fry(1.00)", "pred answer": "eye", "question_id": 681835, "best approach": "image", "verif answer": "wedge", "anno approach": "wiki, concept, image", "verif wiki answer": "fried(0.5451)", "verif concept answer": "french fry(0.5231)", "verif image answer": "fry(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068183.jpg"}, {"question": "what kind of job does the lady do", "gt answer": "cross guard(1.00)<br/>traffic control(0.60)", "pred answer": "construction", "question_id": 487595, "best approach": "wiki", "verif answer": "police officer", "anno approach": "wiki, concept, image", "verif wiki answer": "traffic control(0.6518)", "verif concept answer": "police officer(0.6596)", "verif image answer": "guard(0.7003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048759.jpg"}, {"question": "is the hat shown in this photo cowboy style or sombrero", "gt answer": "sombrero(1.00)", "pred answer": "cowboy", "question_id": 5407465, "best approach": "", "verif answer": "cowboy", "anno approach": "wiki, concept, image", "verif wiki answer": "beanie(0.7080)", "verif concept answer": "beanie(0.7265)", "verif image answer": "beanie(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540746.jpg"}, {"question": "what tool do you need to take those off", "gt answer": "wrench(1.00)", "pred answer": "fire hydrant", "question_id": 121085, "best approach": "", "verif answer": "shovel", "anno approach": "wiki, concept, image", "verif wiki answer": "meter(0.6077)", "verif concept answer": "meter(0.6416)", "verif image answer": "ring(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012108.jpg"}, {"question": "what is this positive gesture of praise or appreciation called", "gt answer": "high 5(1.00)<br/>tennis(0.60)", "pred answer": "love", "question_id": 4298295, "best approach": "wiki", "verif answer": "tennis elbow", "anno approach": "wiki, concept, image", "verif wiki answer": "high 5(0.6864)", "verif concept answer": "wimbledon(0.6225)", "verif image answer": "popular(0.5734)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429829.jpg"}, {"question": "what are the panels on the wall used for", "gt answer": "privacy(1.00)", "pred answer": "toilet", "question_id": 2173065, "best approach": "", "verif answer": "toilet", "anno approach": "wiki, concept, image", "verif wiki answer": "toilet(0.6171)", "verif concept answer": "toilet(0.6510)", "verif image answer": "metal(0.6950)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217306.jpg"}, {"question": "which items shown here are used for drinking wine", "gt answer": "wine glass(1.00)<br/>glass(1.00)", "pred answer": "wine", "question_id": 1669595, "best approach": "", "verif answer": "glass", "anno approach": "wiki, concept, image", "verif wiki answer": "spoon(0.6047)", "verif concept answer": "spoon(0.6127)", "verif image answer": "spoon(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166959.jpg"}, {"question": "what vegetables are present in this photo", "gt answer": "tomato carrot cauliflower(1.00)", "pred answer": "carrot", "question_id": 3838885, "best approach": "image", "verif answer": "tomato", "anno approach": "wiki, concept, image", "verif wiki answer": "broccoli(0.6737)", "verif concept answer": "broccoli(0.6827)", "verif image answer": "tomato carrot cauliflower(0.6997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383888.jpg"}, {"question": "what kind of processor do these have", "gt answer": "intel(1.00)<br/>computer(0.60)", "pred answer": "window", "question_id": 758295, "best approach": "wiki, concept", "verif answer": "window", "anno approach": "wiki, concept, image", "verif wiki answer": "computer(0.6974)", "verif concept answer": "computer(0.6504)", "verif image answer": "window(0.6162)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075829.jpg"}, {"question": "what does the shop whose sign is in the background mainly sell", "gt answer": "book(1.00)<br/>grocery(0.60)<br/>cloth(0.60)", "pred answer": "newspaper", "question_id": 5129245, "best approach": "image", "verif answer": "furniture", "anno approach": "wiki, concept, image", "verif wiki answer": "furniture(0.6827)", "verif concept answer": "paper(0.6755)", "verif image answer": "book(0.5815)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512924.jpg"}, {"question": "how much would this meal cost on average", "gt answer": "5 dollars(1.00)<br/>5(0.60)<br/>baked(0.60)", "pred answer": "10 pounds", "question_id": 1493435, "best approach": "wiki, concept, image", "verif answer": "5 dollars", "anno approach": "wiki, concept, image", "verif wiki answer": "5 dollars(0.7119)", "verif concept answer": "5 dollars(0.6850)", "verif image answer": "5 dollars(0.6416)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149343.jpg"}, {"question": "how much longer until these are cooked", "gt answer": "1 minute(1.00)<br/>5 minutes(0.60)", "pred answer": "1 hour", "question_id": 3714895, "best approach": "concept", "verif answer": "1 hour", "anno approach": "wiki, concept, image", "verif wiki answer": "1 hour(0.6666)", "verif concept answer": "1 minute(0.6185)", "verif image answer": "3 minutes(0.6867)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371489.jpg"}, {"question": "what type of boats are these", "gt answer": "canoes(1.00)<br/>row boat(0.60)", "pred answer": "fish boat", "question_id": 4091635, "best approach": "concept, image", "verif answer": "fish boat", "anno approach": "wiki, concept, image", "verif wiki answer": "canoe(0.7100)", "verif concept answer": "canoes(0.6372)", "verif image answer": "canoes(0.6925)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409163.jpg"}, {"question": "what kind of plant is next to the sheets", "gt answer": "house(1.00)<br/>fern(0.60)<br/>lily(0.60)<br/>indoor(0.60)", "pred answer": "flower", "question_id": 382045, "best approach": "image", "verif answer": "fern", "anno approach": "wiki, concept, image", "verif wiki answer": "fern(0.5676)", "verif concept answer": "fern(0.6310)", "verif image answer": "house(0.5192)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038204.jpg"}, {"question": "can you name the bird sitting on the rock", "gt answer": "eagle(1.00)<br/>hawk(0.60)", "pred answer": "pigeon", "question_id": 3253845, "best approach": "wiki, image", "verif answer": "owl", "anno approach": "wiki, concept, image", "verif wiki answer": "hawk(0.6495)", "verif concept answer": "finch(0.6712)", "verif image answer": "hawk(0.7218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325384.jpg"}, {"question": "what is the name of the food strapped together with the red bands", "gt answer": "asparagus(1.00)", "pred answer": "fruit", "question_id": 4849645, "best approach": "wiki", "verif answer": "asparagus", "anno approach": "wiki, concept, image", "verif wiki answer": "asparagus(0.6593)", "verif concept answer": "broccoli(0.6391)", "verif image answer": "aloe(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484964.jpg"}, {"question": "where is this a native meal", "gt answer": "poland(1.00)<br/>peru(0.60)<br/>germany(0.60)<br/>america(0.60)", "pred answer": "cafe", "question_id": 2002725, "best approach": "wiki, concept, image", "verif answer": "germany", "anno approach": "wiki, concept, image", "verif wiki answer": "germany(0.6518)", "verif concept answer": "germany(0.6574)", "verif image answer": "america(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200272.jpg"}, {"question": "what breed of dog is this", "gt answer": "pomeranian(1.00)", "pred answer": "poodle", "question_id": 267325, "best approach": "wiki, concept, image", "verif answer": "pomeranian", "anno approach": "wiki, concept, image", "verif wiki answer": "pomeranian(0.7110)", "verif concept answer": "pomeranian(0.7188)", "verif image answer": "pomeranian(0.6890)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000026732.jpg"}, {"question": "what type of lighting is found in this room", "gt answer": "overhead(1.00)<br/>indoor(0.60)", "pred answer": "track", "question_id": 3223945, "best approach": "", "verif answer": "fluorescent", "anno approach": "wiki, concept, image", "verif wiki answer": "fluorescent(0.6537)", "verif concept answer": "fluorescent(0.6034)", "verif image answer": "fluorescent(0.7241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322394.jpg"}, {"question": "", "gt answer": "screen(0.60)<br/>glass(0.60)<br/>bay(0.60)", "pred answer": "outdoor", "question_id": 2651145, "best approach": "wiki, concept, image", "verif answer": "pane", "anno approach": "wiki, concept, image", "verif wiki answer": "glass(0.6610)", "verif concept answer": "glass(0.7013)", "verif image answer": "glass(0.7105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265114.jpg"}, {"question": "what is the length of the surfboard the man in the black shorts at the back of the line of people is holding", "gt answer": "7 feet(1.00)", "pred answer": "80 ft", "question_id": 5636175, "best approach": "", "verif answer": "10 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "20 feet(0.6787)", "verif concept answer": "20 feet(0.6341)", "verif image answer": "20 feet(0.6834)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000563617.jpg"}, {"question": "is this a flat screen or projection tv", "gt answer": "flat screen(1.00)", "pred answer": "crt", "question_id": 4922435, "best approach": "wiki, concept", "verif answer": "flat screen", "anno approach": "wiki, concept, image", "verif wiki answer": "flat screen(0.5287)", "verif concept answer": "flat screen(0.5602)", "verif image answer": "remote(0.7096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492243.jpg"}, {"question": "what type of lighting is shown here", "gt answer": "overhead(1.00)<br/>ceiling(0.60)<br/>pot(0.60)", "pred answer": "track", "question_id": 2789365, "best approach": "concept, image", "verif answer": "fluorescent", "anno approach": "wiki, concept, image", "verif wiki answer": "fluorescent(0.6836)", "verif concept answer": "overhead(0.6322)", "verif image answer": "overhead(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278936.jpg"}, {"question": "what is the temperature like", "gt answer": "hot(1.00)<br/>warm(0.60)", "pred answer": "cool", "question_id": 204505, "best approach": "wiki, concept, image", "verif answer": "hot", "anno approach": "wiki, concept, image", "verif wiki answer": "hot(0.6631)", "verif concept answer": "hot(0.7023)", "verif image answer": "hot(0.7013)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020450.jpg"}, {"question": "where can a similar chair be purchased", "gt answer": "furniture store(1.00)<br/>walmart(0.60)", "pred answer": "ikea", "question_id": 3154285, "best approach": "image", "verif answer": "store", "anno approach": "wiki, concept, image", "verif wiki answer": "store(0.5720)", "verif concept answer": "store(0.5965)", "verif image answer": "furniture store(0.6664)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315428.jpg"}, {"question": "what season has obviously gone by in this photo", "gt answer": "fall(1.00)<br/>winter(1.00)", "pred answer": "spring", "question_id": 2760095, "best approach": "concept, image", "verif answer": "spring", "anno approach": "wiki, concept, image", "verif wiki answer": "spring(0.7228)", "verif concept answer": "fall(0.6928)", "verif image answer": "winter(0.7026)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276009.jpg"}, {"question": "what is the woman selling", "gt answer": "smoothies(1.00)<br/>ride(0.60)<br/>smoothie(0.60)", "pred answer": "tea", "question_id": 4085285, "best approach": "", "verif answer": "cloth", "anno approach": "wiki, concept, image", "verif wiki answer": "cloth(0.6732)", "verif concept answer": "cloth(0.6984)", "verif image answer": "cloth(0.7132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408528.jpg"}, {"question": "what does this machine do", "gt answer": "bake(1.00)<br/>cook(0.60)", "pred answer": "boil water", "question_id": 5728595, "best approach": "image", "verif answer": "cook", "anno approach": "wiki, concept, image", "verif wiki answer": "bake it(0.6219)", "verif concept answer": "bake it(0.7072)", "verif image answer": "cook(0.5296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572859.jpg"}, {"question": "what do people do in this room", "gt answer": "poop(1.00)<br/>bathroom(0.60)<br/>wash(0.60)", "pred answer": "wash hand", "question_id": 2362945, "best approach": "", "verif answer": "wash hand", "anno approach": "wiki, concept, image", "verif wiki answer": "wash hand(0.6892)", "verif concept answer": "wash hand(0.6982)", "verif image answer": "wash hand(0.7019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236294.jpg"}, {"question": "what substance is normally being dispensed by this vehicle", "gt answer": "pesticide(1.00)", "pred answer": "exhaust", "question_id": 392725, "best approach": "", "verif answer": "grain", "anno approach": "wiki, concept, image", "verif wiki answer": "straw(0.5753)", "verif concept answer": "grain(0.6539)", "verif image answer": "straw(0.5405)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039272.jpg"}, {"question": "what is filled in that oval object the boy is holding", "gt answer": "balloon(1.00)<br/>helium(0.60)<br/>cheese(0.60)", "pred answer": "food", "question_id": 5083825, "best approach": "wiki, image", "verif answer": "cheese", "anno approach": "wiki, concept, image", "verif wiki answer": "balloon(0.6804)", "verif concept answer": "chocolate(0.6775)", "verif image answer": "balloon(0.6894)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000508382.jpg"}, {"question": "what city is that landmark in", "gt answer": "st louis(1.00)<br/>washington dc(0.60)", "pred answer": "washington", "question_id": 590415, "best approach": "image", "verif answer": "washington", "anno approach": "wiki, concept, image", "verif wiki answer": "washington dc(0.7102)", "verif concept answer": "washington(0.7247)", "verif image answer": "st louis(0.7175)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059041.jpg"}, {"question": "how much water does this require to grow", "gt answer": "gallon(1.00)", "pred answer": "2 gallons", "question_id": 297555, "best approach": "concept", "verif answer": "5 gallons", "anno approach": "wiki, concept, image", "verif wiki answer": "50 gallons(0.6751)", "verif concept answer": "gallon(0.5757)", "verif image answer": "baked(0.6725)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029755.jpg"}, {"question": "what time of day is depicted", "gt answer": "dusk(1.00)<br/>sunrise(0.60)<br/>day(0.60)<br/>morn(0.60)", "pred answer": "sunset", "question_id": 2578135, "best approach": "wiki, concept, image", "verif answer": "dusk", "anno approach": "wiki, concept, image", "verif wiki answer": "dusk(0.7024)", "verif concept answer": "dusk(0.6602)", "verif image answer": "dusk(0.7225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257813.jpg"}, {"question": "what 's rhe difference between a black bear and a brown bear", "gt answer": "color(1.00)", "pred answer": "tusk", "question_id": 851635, "best approach": "wiki", "verif answer": "tusk", "anno approach": "wiki, concept, image", "verif wiki answer": "color(0.6051)", "verif concept answer": "trunk(0.6639)", "verif image answer": "brand(0.6707)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085163.jpg"}, {"question": "what is the position of the skis", "gt answer": "horizontal(1.00)<br/>left(0.60)", "pred answer": "snowplow", "question_id": 2182845, "best approach": "wiki, image", "verif answer": "downhill", "anno approach": "wiki, concept, image", "verif wiki answer": "horizontal(0.6192)", "verif concept answer": "left(0.6416)", "verif image answer": "horizontal(0.7065)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218284.jpg"}, {"question": "what 's the summertime version of this sport", "gt answer": "water ski(1.00)<br/>skate(0.60)<br/>hike(0.60)", "pred answer": "cross country", "question_id": 235395, "best approach": "concept", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "skate(0.6304)", "verif concept answer": "water ski(0.6934)", "verif image answer": "ski(0.6489)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023539.jpg"}, {"question": "what is the name for a group of birds", "gt answer": "flock(1.00)<br/>robin(0.60)", "pred answer": "sparrow", "question_id": 5392835, "best approach": "wiki, image", "verif answer": "sparrow", "anno approach": "wiki, concept, image", "verif wiki answer": "flock(0.6101)", "verif concept answer": "herd(0.7070)", "verif image answer": "flock(0.6993)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539283.jpg"}, {"question": "is this veggies or fruits", "gt answer": "veggies(1.00)", "pred answer": "fruit", "question_id": 3179985, "best approach": "image", "verif answer": "fruit", "anno approach": "wiki, concept, image", "verif wiki answer": "broccoli(0.6760)", "verif concept answer": "broccoli(0.7046)", "verif image answer": "veggies(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317998.jpg"}, {"question": "how old do you estimate this man to be", "gt answer": "forty(1.00)<br/>45(0.60)<br/>48(0.60)<br/>30(0.60)", "pred answer": "21", "question_id": 14035, "best approach": "image", "verif answer": "forty", "anno approach": "wiki, concept, image", "verif wiki answer": "50(0.6271)", "verif concept answer": "50(0.6248)", "verif image answer": "45(0.6756)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001403.jpg"}, {"question": "what did this person jump off", "gt answer": "boat(1.00)<br/>dock(1.00)<br/>water ski(0.60)", "pred answer": "surfboard", "question_id": 483815, "best approach": "concept, image", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "sail(0.7030)", "verif concept answer": "boat(0.6285)", "verif image answer": "boat(0.5728)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048381.jpg"}, {"question": "the net shown in the picture is made up of which material", "gt answer": "nylon(1.00)", "pred answer": "plastic", "question_id": 3886415, "best approach": "", "verif answer": "plastic", "anno approach": "wiki, concept, image", "verif wiki answer": "plastic(0.6397)", "verif concept answer": "wire(0.6514)", "verif image answer": "vinyl(0.7124)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388641.jpg"}, {"question": "what is the diameter of the red umbrella", "gt answer": "40 inches(1.00)<br/>3(0.60)", "pred answer": "8 inches", "question_id": 5744565, "best approach": "concept", "verif answer": "4", "anno approach": "wiki, concept, image", "verif wiki answer": "10 inches(0.6577)", "verif concept answer": "40 inches(0.6146)", "verif image answer": "3(0.5709)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000574456.jpg"}, {"question": "what kind of bread is this", "gt answer": "foccacia(1.00)<br/>pita(0.60)<br/>french(0.60)", "pred answer": "bagel", "question_id": 375395, "best approach": "wiki, concept, image", "verif answer": "french", "anno approach": "wiki, concept, image", "verif wiki answer": "french(0.6295)", "verif concept answer": "french(0.6089)", "verif image answer": "french(0.5919)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000037539.jpg"}, {"question": "where can donuts such as this one be purchased", "gt answer": "bakery(1.00)<br/>krispy kreme(0.60)<br/>dunkin donuts(0.60)", "pred answer": "cafe", "question_id": 3549365, "best approach": "wiki, image", "verif answer": "bakery", "anno approach": "wiki, concept, image", "verif wiki answer": "bakery(0.6186)", "verif concept answer": "krispy kreme(0.6401)", "verif image answer": "bakery(0.6849)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354936.jpg"}, {"question": "what is this cake commonly made of", "gt answer": "butter(1.00)<br/>sponge(0.60)<br/>flour(0.60)", "pred answer": "frost", "question_id": 4852345, "best approach": "wiki, concept", "verif answer": "sugar", "anno approach": "wiki, concept, image", "verif wiki answer": "flour(0.6515)", "verif concept answer": "flour(0.7187)", "verif image answer": "vanilla(0.7000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485234.jpg"}, {"question": "what is the man in the middle selling", "gt answer": "bed(1.00)<br/>furniture(0.60)", "pred answer": "cloth", "question_id": 5023795, "best approach": "concept", "verif answer": "furniture", "anno approach": "wiki, concept, image", "verif wiki answer": "furniture(0.5966)", "verif concept answer": "bed(0.6475)", "verif image answer": "furniture(0.7230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502379.jpg"}, {"question": "what kind of red car is this", "gt answer": "bmw(1.00)<br/>sedan(0.60)", "pred answer": "jeep", "question_id": 542865, "best approach": "image", "verif answer": "sedan", "anno approach": "wiki, concept, image", "verif wiki answer": "harley davidson(0.6376)", "verif concept answer": "kawasaki(0.6675)", "verif image answer": "sedan(0.7198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054286.jpg"}, {"question": "how fast does this machine travel", "gt answer": "80 mph(1.00)", "pred answer": "very fast", "question_id": 455435, "best approach": "image", "verif answer": "80 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "200 mph(0.6548)", "verif concept answer": "fast(0.6336)", "verif image answer": "80 mph(0.7014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045543.jpg"}, {"question": "these people are wearing straps so they don't destroy what", "gt answer": "television(1.00)<br/>control(0.60)<br/>wall(0.60)", "pred answer": "tie", "question_id": 3719655, "best approach": "wiki, concept, image", "verif answer": "television", "anno approach": "wiki, concept, image", "verif wiki answer": "control(0.5444)", "verif concept answer": "control(0.6634)", "verif image answer": "control(0.7153)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371965.jpg"}, {"question": "what event or climb is this group undertaking", "gt answer": "cross country ski(1.00)", "pred answer": "olympics", "question_id": 528195, "best approach": "wiki", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "cross country ski(0.6820)", "verif concept answer": "ski(0.6523)", "verif image answer": "ski(0.5698)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052819.jpg"}, {"question": "who can fix a broken urinal", "gt answer": "plumber(1.00)", "pred answer": "janitor", "question_id": 1615855, "best approach": "", "verif answer": "maid", "anno approach": "wiki, concept, image", "verif wiki answer": "clean(0.5527)", "verif concept answer": "clean(0.5265)", "verif image answer": "maid(0.6127)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161585.jpg"}, {"question": "what company owns the truck", "gt answer": "u haul(1.00)", "pred answer": "ford", "question_id": 4898905, "best approach": "wiki, image", "verif answer": "citilink", "anno approach": "wiki, concept, image", "verif wiki answer": "u haul(0.7030)", "verif concept answer": "kelly slater(0.6689)", "verif image answer": "u haul(0.6690)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489890.jpg"}, {"question": "how are the cucumbers chopped", "gt answer": "knife(1.00)<br/>small(0.60)", "pred answer": "with knife", "question_id": 2147335, "best approach": "", "verif answer": "knife", "anno approach": "wiki, concept, image", "verif wiki answer": "spatula(0.6912)", "verif concept answer": "spatula(0.7058)", "verif image answer": "spatula(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214733.jpg"}, {"question": "what move is this tennis player currently using", "gt answer": "serve(1.00)<br/>forehand(0.60)", "pred answer": "backhand", "question_id": 4397565, "best approach": "wiki, image", "verif answer": "serve", "anno approach": "wiki, concept, image", "verif wiki answer": "serve(0.5678)", "verif concept answer": "swing(0.6037)", "verif image answer": "serve(0.7065)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439756.jpg"}, {"question": "name the ingredients used for preparing this dish", "gt answer": "dough spinach cheese(1.00)<br/>flour(0.60)", "pred answer": "vegetable", "question_id": 2525185, "best approach": "wiki", "verif answer": "cheese", "anno approach": "wiki, concept, image", "verif wiki answer": "dough spinach cheese(0.6608)", "verif concept answer": "sugar(0.6436)", "verif image answer": "flour(0.7051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252518.jpg"}, {"question": "what type of wave is this image showing", "gt answer": "small(1.00)", "pred answer": "roll", "question_id": 4071025, "best approach": "", "verif answer": "crest", "anno approach": "wiki, concept, image", "verif wiki answer": "regular(0.6295)", "verif concept answer": "8 inches(0.6506)", "verif image answer": "crest(0.6890)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407102.jpg"}, {"question": "is this a truck or train stop", "gt answer": "truck(1.00)", "pred answer": "ambulance", "question_id": 2945455, "best approach": "wiki, image", "verif answer": "truck", "anno approach": "wiki, concept, image", "verif wiki answer": "truck(0.6780)", "verif concept answer": "vehicle(0.5897)", "verif image answer": "truck(0.6814)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000294545.jpg"}, {"question": "what movie genre is referenced here", "gt answer": "scifi(1.00)", "pred answer": "mulan", "question_id": 3404125, "best approach": "image", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "wii(0.5677)", "verif concept answer": "wii(0.5854)", "verif image answer": "scifi(0.5171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340412.jpg"}, {"question": "what is the marking on these animals calle", "gt answer": "brand(1.00)<br/>marker(0.60)<br/>number(0.60)", "pred answer": "long neck", "question_id": 2190305, "best approach": "concept", "verif answer": "letter", "anno approach": "wiki, concept, image", "verif wiki answer": "shear(0.5645)", "verif concept answer": "marker(0.5662)", "verif image answer": "shear(0.5683)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219030.jpg"}, {"question": "what are these weapons used for", "gt answer": "cut(1.00)<br/>stab(0.60)<br/>protection(0.60)", "pred answer": "scissor", "question_id": 5438145, "best approach": "wiki, concept", "verif answer": "sew", "anno approach": "wiki, concept, image", "verif wiki answer": "cut(0.6106)", "verif concept answer": "cut(0.6178)", "verif image answer": "sew(0.6658)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543814.jpg"}, {"question": "who won the gold medal in women 's slalom skiing at the 2018 winter olympics", "gt answer": "frida hansdotter(1.00)<br/>tiffany(0.60)", "pred answer": "shawn white", "question_id": 1665995, "best approach": "concept, image", "verif answer": "bode miller", "anno approach": "wiki, concept, image", "verif wiki answer": "bode miller(0.6868)", "verif concept answer": "tiffany(0.6890)", "verif image answer": "tiffany(0.7138)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166599.jpg"}, {"question": "why does this man have his foot on the ground", "gt answer": "stopped(1.00)<br/>asphalt(0.60)<br/>balance(0.60)", "pred answer": "accident", "question_id": 4498476, "best approach": "wiki, concept", "verif answer": "balance", "anno approach": "wiki, concept, image", "verif wiki answer": "stopped(0.5806)", "verif concept answer": "stopped(0.6503)", "verif image answer": "balance(0.6211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449847.jpg"}, {"question": "what move in surfing is this man performing", "gt answer": "flip(1.00)<br/>jump(0.60)", "pred answer": "ride wave", "question_id": 1032675, "best approach": "image", "verif answer": "jump", "anno approach": "wiki, concept, image", "verif wiki answer": "kick flip(0.6849)", "verif concept answer": "jump(0.6452)", "verif image answer": "flip(0.7217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103267.jpg"}, {"question": "what is the function of the black area in the middle of the item next to the keyboard", "gt answer": "scroll(1.00)", "pred answer": "work", "question_id": 1274185, "best approach": "", "verif answer": "read", "anno approach": "wiki, concept, image", "verif wiki answer": "talk and eat(0.6126)", "verif concept answer": "krispy kreme(0.6037)", "verif image answer": "krispy kreme(0.5426)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127418.jpg"}, {"question": "what is the culinary term for this dish", "gt answer": "slider(1.00)<br/>burger(0.60)", "pred answer": "butter", "question_id": 1901355, "best approach": "image", "verif answer": "italian", "anno approach": "wiki, concept, image", "verif wiki answer": "sandwich(0.6583)", "verif concept answer": "hotdog(0.6891)", "verif image answer": "slider(0.6310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190135.jpg"}, {"question": "what type of brain power is this large animal known for", "gt answer": "memory(1.00)", "pred answer": "tusk", "question_id": 4472435, "best approach": "", "verif answer": "ivory", "anno approach": "wiki, concept, image", "verif wiki answer": "ivory(0.6355)", "verif concept answer": "ivory(0.6456)", "verif image answer": "ivory(0.6451)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447243.jpg"}, {"question": "if five hits the ball hard enough that no one catches it and then runs through all the bases then that is called a what", "gt answer": "home run(1.00)<br/>homerun(0.60)", "pred answer": "out", "question_id": 3120505, "best approach": "", "verif answer": "out", "anno approach": "wiki, concept, image", "verif wiki answer": "out(0.7086)", "verif concept answer": "out(0.5905)", "verif image answer": "court(0.6972)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312050.jpg"}, {"question": "what type of function is this man at", "gt answer": "wine taste(1.00)<br/>party(0.60)", "pred answer": "sommelier", "question_id": 472135, "best approach": "", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "restaurant(0.6357)", "verif concept answer": "anniversary(0.6076)", "verif image answer": "restaurant(0.6354)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047213.jpg"}, {"question": "what is the goal of the game these boys are playing", "gt answer": "catch(1.00)<br/>catch frisbee(1.00)", "pred answer": "frisbee", "question_id": 4452445, "best approach": "wiki", "verif answer": "frisbee", "anno approach": "wiki, concept, image", "verif wiki answer": "catch(0.7046)", "verif concept answer": "frisbee(0.6751)", "verif image answer": "goal(0.6626)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445244.jpg"}, {"question": "what company is this plane owned by", "gt answer": "united(1.00)<br/>american(0.60)", "pred answer": "boeing", "question_id": 3896825, "best approach": "", "verif answer": "boeing", "anno approach": "wiki, concept, image", "verif wiki answer": "korean air(0.7183)", "verif concept answer": "korean air(0.6987)", "verif image answer": "korean air(0.6973)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389682.jpg"}, {"question": "", "gt answer": "walkway(0.60)<br/>airstair(0.60)", "pred answer": "jet bridge", "question_id": 4295735, "best approach": "", "verif answer": "jet bridge", "anno approach": "wiki, concept, image", "verif wiki answer": "jet bridge(0.5469)", "verif concept answer": "jet bridge(0.5683)", "verif image answer": "jet bridge(0.5159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429573.jpg"}, {"question": "what are the squares behind the animal", "gt answer": "screen(1.00)<br/>fence(0.60)<br/>white(0.60)", "pred answer": "stripe", "question_id": 3384685, "best approach": "concept", "verif answer": "fence", "anno approach": "wiki, concept, image", "verif wiki answer": "white(0.6136)", "verif concept answer": "screen(0.6703)", "verif image answer": "white(0.7225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338468.jpg"}, {"question": "how many children play this sport a year", "gt answer": "million(1.00)<br/>thousand(0.60)", "pred answer": "5", "question_id": 1517565, "best approach": "", "verif answer": "6", "anno approach": "wiki, concept, image", "verif wiki answer": "6(0.6826)", "verif concept answer": "20000(0.6231)", "verif image answer": "20000(0.7022)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151756.jpg"}, {"question": "what are these vehicles used for", "gt answer": "fish(1.00)<br/>sail(0.60)", "pred answer": "boat", "question_id": 1479245, "best approach": "", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "boat(0.6705)", "verif concept answer": "boat(0.6555)", "verif image answer": "boat(0.6707)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147924.jpg"}, {"question": "what trick is being performed", "gt answer": "backflip(1.00)<br/>flip(0.60)", "pred answer": "jump", "question_id": 3577595, "best approach": "wiki, image", "verif answer": "jump", "anno approach": "wiki, concept, image", "verif wiki answer": "flip(0.6690)", "verif concept answer": "trick(0.7136)", "verif image answer": "flip(0.7146)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357759.jpg"}, {"question": "is the cat awake or sleep", "gt answer": "awake(1.00)", "pred answer": "sleep", "question_id": 1093935, "best approach": "", "verif answer": "window", "anno approach": "wiki, concept, image", "verif wiki answer": "sad(0.6007)", "verif concept answer": "window(0.6775)", "verif image answer": "sad(0.5527)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000109393.jpg"}, {"question": "what lines the separation in this photo", "gt answer": "fence(1.00)", "pred answer": "island", "question_id": 3814035, "best approach": "", "verif answer": "fence", "anno approach": "wiki, concept, image", "verif wiki answer": "stair(0.5827)", "verif concept answer": "hurdle(0.6368)", "verif image answer": "stair(0.7153)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381403.jpg"}, {"question": "what kind of haircut does this girl have", "gt answer": "bob(1.00)", "pred answer": "short", "question_id": 2294945, "best approach": "wiki, image", "verif answer": "bang", "anno approach": "wiki, concept, image", "verif wiki answer": "bob(0.7135)", "verif concept answer": "pony tail(0.6745)", "verif image answer": "bob(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000229494.jpg"}, {"question": "what type of cooktop does the stove have", "gt answer": "gas(1.00)<br/>glass(0.60)", "pred answer": "marble", "question_id": 4033255, "best approach": "", "verif answer": "electric", "anno approach": "wiki, concept, image", "verif wiki answer": "electric(0.7139)", "verif concept answer": "electric(0.6870)", "verif image answer": "outdoor(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403325.jpg"}, {"question": "what is required to do what the man on the left is doing", "gt answer": "camera(1.00)<br/>plate(0.60)<br/>film(0.60)", "pred answer": "compute", "question_id": 4603625, "best approach": "image", "verif answer": "camera", "anno approach": "wiki, concept, image", "verif wiki answer": "screen(0.6449)", "verif concept answer": "plate(0.6163)", "verif image answer": "camera(0.7094)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460362.jpg"}, {"question": "what kind of job is this", "gt answer": "athlete(1.00)", "pred answer": "tennis", "question_id": 2129985, "best approach": "", "verif answer": "referee", "anno approach": "wiki, concept, image", "verif wiki answer": "referee(0.5762)", "verif concept answer": "referee(0.5946)", "verif image answer": "referee(0.7238)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212998.jpg"}, {"question": "what is the freeway portion over the street called", "gt answer": "overpass(1.00)<br/>bridge(0.60)", "pred answer": "cross", "question_id": 4012295, "best approach": "wiki, image", "verif answer": "crosswalk", "anno approach": "wiki, concept, image", "verif wiki answer": "overpass(0.7043)", "verif concept answer": "crosswalk(0.6987)", "verif image answer": "overpass(0.7230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401229.jpg"}, {"question": "is this a meal or snack", "gt answer": "snack(1.00)", "pred answer": "meal", "question_id": 5220745, "best approach": "image", "verif answer": "meal", "anno approach": "wiki, concept, image", "verif wiki answer": "meal(0.6670)", "verif concept answer": "meal(0.7004)", "verif image answer": "snack(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522074.jpg"}, {"question": "is the sun rising or setting", "gt answer": "set(1.00)", "pred answer": "sunrise", "question_id": 702615, "best approach": "wiki", "verif answer": "triangle", "anno approach": "wiki, concept, image", "verif wiki answer": "set(0.7058)", "verif concept answer": "simulation(0.7047)", "verif image answer": "simulation(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070261.jpg"}, {"question": "what kind of boat is being used", "gt answer": "motor boat(1.00)<br/>wooden(0.60)<br/>row boat(0.60)", "pred answer": "surfboard", "question_id": 3105735, "best approach": "image", "verif answer": "row", "anno approach": "wiki, concept, image", "verif wiki answer": "wooden(0.5787)", "verif concept answer": "wooden(0.6195)", "verif image answer": "motor boat(0.6738)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310573.jpg"}, {"question": "what is the menu at this restaurant", "gt answer": "taco(1.00)", "pred answer": "mcdonalds", "question_id": 4746145, "best approach": "", "verif answer": "deli", "anno approach": "wiki, concept, image", "verif wiki answer": "deli(0.5408)", "verif concept answer": "deli(0.5730)", "verif image answer": "salad(0.5495)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000474614.jpg"}, {"question": "what kind of media is she reading", "gt answer": "magazine(1.00)", "pred answer": "tv", "question_id": 4975585, "best approach": "concept", "verif answer": "better home", "anno approach": "wiki, concept, image", "verif wiki answer": "full(0.5467)", "verif concept answer": "magazine(0.5904)", "verif image answer": "better home(0.6919)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497558.jpg"}, {"question": "how many seconds does the player have to hold the item before he has to pass", "gt answer": "30(1.00)<br/>3(0.60)<br/>5(0.60)", "pred answer": "10", "question_id": 2423615, "best approach": "wiki, image", "verif answer": "30", "anno approach": "wiki, concept, image", "verif wiki answer": "5(0.6523)", "verif concept answer": "20(0.6396)", "verif image answer": "5(0.6863)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000242361.jpg"}, {"question": "what does this symbol mean", "gt answer": "stop(1.00)", "pred answer": "cross", "question_id": 5724875, "best approach": "", "verif answer": "stop", "anno approach": "wiki, concept, image", "verif wiki answer": "stop traffic(0.7077)", "verif concept answer": "wrong way(0.6369)", "verif image answer": "stop traffic(0.7063)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572487.jpg"}, {"question": "how old do you believe this building is", "gt answer": "100 years(1.00)", "pred answer": "50 years", "question_id": 3844125, "best approach": "", "verif answer": "50 years", "anno approach": "wiki, concept, image", "verif wiki answer": "1886(0.6075)", "verif concept answer": "1886(0.6326)", "verif image answer": "old(0.7059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384412.jpg"}, {"question": "what nickname for the furry animal starts with the same letter as the food in the box", "gt answer": "pussy(1.00)", "pred answer": "cat", "question_id": 4378575, "best approach": "wiki", "verif answer": "taxi", "anno approach": "wiki, concept, image", "verif wiki answer": "pussy(0.5258)", "verif concept answer": "taxi(0.6953)", "verif image answer": "strawberry(0.5302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437857.jpg"}, {"question": "what is he walking on", "gt answer": "sidewalk(1.00)<br/>pavement(0.60)", "pred answer": "park meter", "question_id": 603875, "best approach": "image", "verif answer": "sidewalk", "anno approach": "wiki, concept, image", "verif wiki answer": "crosswalk(0.6392)", "verif concept answer": "crosswalk(0.6848)", "verif image answer": "sidewalk(0.6880)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060387.jpg"}, {"question": "would you say these objects are organized or disorganized", "gt answer": "disorganized(1.00)", "pred answer": "broken", "question_id": 1306105, "best approach": "", "verif answer": "not very", "anno approach": "wiki, concept, image", "verif wiki answer": "not very(0.5254)", "verif concept answer": "danger(0.5185)", "verif image answer": "not very(0.5619)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130610.jpg"}, {"question": "what walking aid is this man using", "gt answer": "cane(1.00)<br/>crutch(0.60)", "pred answer": "scissor", "question_id": 5358985, "best approach": "concept", "verif answer": "cane", "anno approach": "wiki, concept, image", "verif wiki answer": "sidewalk(0.5441)", "verif concept answer": "crutch(0.6216)", "verif image answer": "suitcase(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535898.jpg"}, {"question": "what holiday do many people drink guinness on", "gt answer": "st patrick's day(1.00)", "pred answer": "valentine", "question_id": 2765145, "best approach": "image", "verif answer": "valentine", "anno approach": "wiki, concept, image", "verif wiki answer": "valentine(0.6475)", "verif concept answer": "thanksgiving(0.6650)", "verif image answer": "st patrick's day(0.7168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276514.jpg"}, {"question": "this dog is being held back by what", "gt answer": "leash(1.00)", "pred answer": "stick", "question_id": 291895, "best approach": "wiki, concept, image", "verif answer": "leash", "anno approach": "wiki, concept, image", "verif wiki answer": "leash(0.6572)", "verif concept answer": "leash(0.7067)", "verif image answer": "leash(0.7173)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029189.jpg"}, {"question": "would this person be more likely to be a type a or b person", "gt answer": "(1.00)<br/>type(1.00)<br/>b(0.60)", "pred answer": "normal", "question_id": 1782755, "best approach": "image", "verif answer": "vitamin c", "anno approach": "wiki, concept, image", "verif wiki answer": "b(0.6779)", "verif concept answer": "b(0.6671)", "verif image answer": "(0.5740)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178275.jpg"}, {"question": "what companies sell the outdoor gear the people are wearing", "gt answer": "rei(1.00)<br/>columbia(0.60)", "pred answer": "burton", "question_id": 2650235, "best approach": "wiki, image", "verif answer": "north face", "anno approach": "wiki, concept, image", "verif wiki answer": "rei(0.6166)", "verif concept answer": "adidas(0.6635)", "verif image answer": "rei(0.6957)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265023.jpg"}, {"question": "what brand of cell phone is the man in green using", "gt answer": "iphone(1.00)<br/>nokia(0.60)<br/>samsung(0.60)<br/>sony(0.60)", "pred answer": "apple", "question_id": 3264805, "best approach": "wiki, concept", "verif answer": "iphone", "anno approach": "wiki, concept, image", "verif wiki answer": "iphone(0.6988)", "verif concept answer": "iphone(0.6623)", "verif image answer": "nokia(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000326480.jpg"}, {"question": "what kind of cocktail is this woman drinking", "gt answer": "martini(1.00)", "pred answer": "alcoholic", "question_id": 862215, "best approach": "", "verif answer": "vodka cranberry", "anno approach": "wiki, concept, image", "verif wiki answer": "vodka cranberry(0.7009)", "verif concept answer": "bottle(0.6466)", "verif image answer": "vodka cranberry(0.6775)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086221.jpg"}, {"question": "what is the guy on the horse doing with the cattle", "gt answer": "herd(1.00)<br/>drive(0.60)", "pred answer": "feed", "question_id": 1787545, "best approach": "wiki, concept", "verif answer": "herd", "anno approach": "wiki, concept, image", "verif wiki answer": "herd(0.6303)", "verif concept answer": "herd(0.6579)", "verif image answer": "cow(0.6340)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178754.jpg"}, {"question": "where is all the pie", "gt answer": "eaten(1.00)", "pred answer": "table", "question_id": 2622615, "best approach": "wiki", "verif answer": "trash", "anno approach": "wiki, concept, image", "verif wiki answer": "eaten(0.6367)", "verif concept answer": "bitten(0.6246)", "verif image answer": "vanilla(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262261.jpg"}, {"question": "who is the leading player of this sport", "gt answer": "babe ruth(1.00)<br/>batter(0.60)", "pred answer": "pitcher", "question_id": 2525675, "best approach": "", "verif answer": "babe ruth", "anno approach": "wiki, concept, image", "verif wiki answer": "randy johnson(0.6505)", "verif concept answer": "randy johnson(0.7172)", "verif image answer": "hitter(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252567.jpg"}, {"question": "are they racing or playing a game", "gt answer": "play game(1.00)<br/>game(1.00)<br/>play(0.60)", "pred answer": "polo", "question_id": 3127445, "best approach": "wiki", "verif answer": "play", "anno approach": "wiki, concept, image", "verif wiki answer": "play game(0.5993)", "verif concept answer": "play(0.5921)", "verif image answer": "watch(0.6075)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312744.jpg"}, {"question": "what kind of plant is the bird looking at", "gt answer": "cactus(1.00)<br/>aloe(0.60)", "pred answer": "tree", "question_id": 2370985, "best approach": "", "verif answer": "cactus", "anno approach": "wiki, concept, image", "verif wiki answer": "succulent(0.6817)", "verif concept answer": "succulent(0.6869)", "verif image answer": "moss(0.6420)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237098.jpg"}, {"question": "what is this part of the house used for", "gt answer": "bath(1.00)<br/>defecation(0.60)", "pred answer": "wash hand", "question_id": 534255, "best approach": "wiki", "verif answer": "bath", "anno approach": "wiki, concept, image", "verif wiki answer": "defecation(0.6907)", "verif concept answer": "watch tv(0.6880)", "verif image answer": "bathroom(0.7145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053425.jpg"}, {"question": "how much did this motorcycle cost", "gt answer": "5000(1.00)", "pred answer": "20 pounds", "question_id": 828005, "best approach": "", "verif answer": "2 dollars", "anno approach": "wiki, concept, image", "verif wiki answer": "2 dollars(0.6218)", "verif concept answer": "2 dollars(0.5942)", "verif image answer": "4000(0.6682)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082800.jpg"}, {"question": "what is on the tv", "gt answer": "video game(1.00)<br/>game(0.60)", "pred answer": "speed skate", "question_id": 2762445, "best approach": "", "verif answer": "video game", "anno approach": "wiki, concept, image", "verif wiki answer": "play game(0.6814)", "verif concept answer": "play game(0.6451)", "verif image answer": "play game(0.7058)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276244.jpg"}, {"question": "where are the eating out of the same bowl", "gt answer": "kitchen(1.00)", "pred answer": "table", "question_id": 5420605, "best approach": "", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "restaurant(0.6328)", "verif concept answer": "museum(0.6254)", "verif image answer": "restaurant(0.7127)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542060.jpg"}, {"question": "what family of fruits is shown", "gt answer": "citrus(1.00)", "pred answer": "orange", "question_id": 5535425, "best approach": "", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "apple(0.5904)", "verif concept answer": "apple(0.6813)", "verif image answer": "orange(0.7096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553542.jpg"}, {"question": "the bright color that can be seen over the window shade is often associated with which february holiday", "gt answer": "valentine's day(1.00)<br/>valentine's(1.00)", "pred answer": "fourth of july", "question_id": 3370685, "best approach": "wiki", "verif answer": "valentine", "anno approach": "wiki, concept, image", "verif wiki answer": "valentine's(0.5977)", "verif concept answer": "christmas(0.5788)", "verif image answer": "valentine(0.7214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337068.jpg"}, {"question": "what does this sign signify", "gt answer": "speed limit(1.00)", "pred answer": "stop", "question_id": 1372815, "best approach": "", "verif answer": "direct", "anno approach": "wiki, concept, image", "verif wiki answer": "direct(0.6655)", "verif concept answer": "direct(0.5812)", "verif image answer": "letter(0.6958)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000137281.jpg"}, {"question": "what device is this person pointing at", "gt answer": "microwave(1.00)<br/>computer(0.60)", "pred answer": "tv", "question_id": 5006945, "best approach": "concept, image", "verif answer": "television", "anno approach": "wiki, concept, image", "verif wiki answer": "television(0.6449)", "verif concept answer": "microwave(0.5540)", "verif image answer": "microwave(0.6798)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500694.jpg"}, {"question": "is this hygienic or unhygienic", "gt answer": "unhygienic(1.00)", "pred answer": "unhealthy", "question_id": 3639335, "best approach": "image", "verif answer": "unhealthy", "anno approach": "wiki, concept, image", "verif wiki answer": "unhealthy(0.7192)", "verif concept answer": "unhealthy(0.7198)", "verif image answer": "unhygienic(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363933.jpg"}, {"question": "how do you score in this game", "gt answer": "catch frisbee(1.00)<br/>goal(0.60)", "pred answer": "hit ball", "question_id": 3786215, "best approach": "", "verif answer": "goal", "anno approach": "wiki, concept, image", "verif wiki answer": "catch(0.6262)", "verif concept answer": "catch(0.5833)", "verif image answer": "tan(0.6983)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378621.jpg"}, {"question": "in what type of events would multiple planes fly in formation", "gt answer": "airshow(1.00)<br/>show(0.60)", "pred answer": "air show", "question_id": 5812185, "best approach": "", "verif answer": "air show", "anno approach": "wiki, concept, image", "verif wiki answer": "air show(0.7262)", "verif concept answer": "air show(0.7032)", "verif image answer": "air show(0.7068)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000581218.jpg"}, {"question": "what typeof dress material the children is wearing in this picture", "gt answer": "costume(1.00)<br/>cotton(0.60)<br/>sleep(0.60)", "pred answer": "flannel", "question_id": 616065, "best approach": "concept", "verif answer": "sleep", "anno approach": "wiki, concept, image", "verif wiki answer": "wool(0.5376)", "verif concept answer": "costume(0.6657)", "verif image answer": "sleep(0.5961)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061606.jpg"}, {"question": "the smoking woman can develop what illness if she makes her habit lifelong", "gt answer": "cancer(1.00)<br/>lung cancer(0.60)", "pred answer": "drown", "question_id": 2225885, "best approach": "image", "verif answer": "scurvy", "anno approach": "wiki, concept, image", "verif wiki answer": "breast cancer(0.6436)", "verif concept answer": "scurvy(0.6206)", "verif image answer": "lung cancer(0.5568)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222588.jpg"}, {"question": "what is the name of that toy in the background", "gt answer": "ring(1.00)", "pred answer": "teddy bear", "question_id": 5440465, "best approach": "", "verif answer": "walmart", "anno approach": "wiki, concept, image", "verif wiki answer": "walmart(0.5310)", "verif concept answer": "walmart(0.5173)", "verif image answer": "walmart(0.6575)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544046.jpg"}, {"question": "would species of bird is this", "gt answer": "woodpecker(1.00)<br/>hummingbird(1.00)", "pred answer": "parakeet", "question_id": 1148985, "best approach": "wiki, concept", "verif answer": "woodpecker", "anno approach": "wiki, concept, image", "verif wiki answer": "woodpecker(0.6705)", "verif concept answer": "woodpecker(0.5627)", "verif image answer": "bird(0.6273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114898.jpg"}, {"question": "what restaurant was this dish cooked at", "gt answer": "ihop(1.00)<br/>diner(0.60)", "pred answer": "subway", "question_id": 3517705, "best approach": "wiki", "verif answer": "martha", "anno approach": "wiki, concept, image", "verif wiki answer": "ihop(0.5617)", "verif concept answer": "diner(0.5713)", "verif image answer": "restaurant(0.7130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351770.jpg"}, {"question": "what pork dish does big j 's serve", "gt answer": "pulled pork(1.00)<br/>bacon(0.60)", "pred answer": "food", "question_id": 5262915, "best approach": "", "verif answer": "bbq", "anno approach": "wiki, concept, image", "verif wiki answer": "barbeque(0.6222)", "verif concept answer": "bbq(0.6665)", "verif image answer": "bbq(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526291.jpg"}, {"question": "what is the name of the person that designed these", "gt answer": "george stephenson(1.00)<br/>richard trevithick(0.60)", "pred answer": "engineer", "question_id": 2069755, "best approach": "wiki, concept", "verif answer": "engineer", "anno approach": "wiki, concept, image", "verif wiki answer": "richard trevithick(0.7234)", "verif concept answer": "richard trevithick(0.6880)", "verif image answer": "bell(0.7068)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206975.jpg"}, {"question": "what style of skiing is this", "gt answer": "mogul(1.00)<br/>normal(0.60)<br/>alpine(0.60)", "pred answer": "downhill", "question_id": 3901206, "best approach": "", "verif answer": "downhill", "anno approach": "wiki, concept, image", "verif wiki answer": "downhill(0.6945)", "verif concept answer": "downhill(0.6895)", "verif image answer": "downhill(0.5978)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390120.jpg"}, {"question": "what is the name of the mascot shown in the picture", "gt answer": "oriole(1.00)<br/>penguin(0.60)", "pred answer": "phillie phanatic", "question_id": 3891455, "best approach": "wiki, concept", "verif answer": "penguin", "anno approach": "wiki, concept, image", "verif wiki answer": "oriole(0.7190)", "verif concept answer": "oriole(0.6587)", "verif image answer": "american(0.6983)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389145.jpg"}, {"question": "did he miss or score a point", "gt answer": "score(1.00)", "pred answer": "hit", "question_id": 2194075, "best approach": "", "verif answer": "hit", "anno approach": "wiki, concept, image", "verif wiki answer": "player(0.7145)", "verif concept answer": "serve(0.6761)", "verif image answer": "serve(0.6405)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219407.jpg"}, {"question": "what is the name of this motorcycle", "gt answer": "dirt bike(1.00)<br/>tour(0.60)<br/>honda(0.60)", "pred answer": "kawasaki", "question_id": 2630315, "best approach": "concept, image", "verif answer": "kawasaki", "anno approach": "wiki, concept, image", "verif wiki answer": "motorbike(0.7127)", "verif concept answer": "honda(0.6647)", "verif image answer": "honda(0.7122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263031.jpg"}, {"question": "at what age do these open their eyes", "gt answer": "2 weeks(1.00)<br/>1 week(0.60)", "pred answer": "14", "question_id": 3159445, "best approach": "image", "verif answer": "2 weeks", "anno approach": "wiki, concept, image", "verif wiki answer": "1 week(0.6720)", "verif concept answer": "1 week(0.5955)", "verif image answer": "2 weeks(0.6874)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315944.jpg"}, {"question": "what would his room be classified as", "gt answer": "dine(1.00)", "pred answer": "office", "question_id": 561165, "best approach": "", "verif answer": "dine room", "anno approach": "wiki, concept, image", "verif wiki answer": "tv(0.6405)", "verif concept answer": "adult(0.6015)", "verif image answer": "adult(0.7010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000056116.jpg"}, {"question": "what holiday might they be celebrating", "gt answer": "st patrick's day(1.00)", "pred answer": "4th of july", "question_id": 1217825, "best approach": "", "verif answer": "july 4th", "anno approach": "wiki, concept, image", "verif wiki answer": "valentine(0.7119)", "verif concept answer": "july 4th(0.6942)", "verif image answer": "july 4th(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000121782.jpg"}, {"question": "where would you typically find this animal", "gt answer": "forest(1.00)<br/>wood(0.60)", "pred answer": "zoo", "question_id": 5461935, "best approach": "image", "verif answer": "forest", "anno approach": "wiki, concept, image", "verif wiki answer": "wild(0.6785)", "verif concept answer": "wood(0.6644)", "verif image answer": "forest(0.6659)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546193.jpg"}, {"question": "what food is being made in this kitchen", "gt answer": "soup(1.00)<br/>pasta(1.00)", "pred answer": "meat", "question_id": 4215425, "best approach": "wiki, concept", "verif answer": "pasta", "anno approach": "wiki, concept, image", "verif wiki answer": "pasta(0.6158)", "verif concept answer": "pasta(0.6572)", "verif image answer": "noodle(0.6868)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421542.jpg"}, {"question": "what motor powers this bus", "gt answer": "diesel(1.00)<br/>electric(0.60)", "pred answer": "gas", "question_id": 3992365, "best approach": "", "verif answer": "gasoline", "anno approach": "wiki, concept, image", "verif wiki answer": "gasoline(0.5641)", "verif concept answer": "gasoline(0.6562)", "verif image answer": "gasoline(0.6436)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399236.jpg"}, {"question": "what year was this sport invented", "gt answer": "1965(1.00)<br/>1800(0.60)", "pred answer": "2010", "question_id": 2844065, "best approach": "concept, image", "verif answer": "1950", "anno approach": "wiki, concept, image", "verif wiki answer": "1950(0.7031)", "verif concept answer": "1965(0.5694)", "verif image answer": "1965(0.7071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284406.jpg"}, {"question": "what is the name for the popular statue in the background", "gt answer": "christ redeemer(1.00)<br/>air(0.60)<br/>cross(0.60)", "pred answer": "big ben", "question_id": 3487825, "best approach": "wiki, concept, image", "verif answer": "cross", "anno approach": "wiki, concept, image", "verif wiki answer": "cross(0.7259)", "verif concept answer": "cross(0.5908)", "verif image answer": "cross(0.6925)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348782.jpg"}, {"question": "what time is shown", "gt answer": "1:15(1.00)", "pred answer": "3:00", "question_id": 4329645, "best approach": "", "verif answer": "3:52", "anno approach": "wiki, concept, image", "verif wiki answer": "3:52(0.5498)", "verif concept answer": "3:52(0.7200)", "verif image answer": "3:52(0.5487)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432964.jpg"}, {"question": "what type of clouds appear in the picture", "gt answer": "nimbus(1.00)<br/>storm(0.60)", "pred answer": "cumulus", "question_id": 675715, "best approach": "concept", "verif answer": "cumulus", "anno approach": "wiki, concept, image", "verif wiki answer": "cumulus(0.6761)", "verif concept answer": "nimbus(0.6862)", "verif image answer": "even(0.7107)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067571.jpg"}, {"question": "what book is that", "gt answer": "paperback(1.00)<br/>cook(0.60)", "pred answer": "yearbook", "question_id": 5266665, "best approach": "wiki", "verif answer": "cook", "anno approach": "wiki, concept, image", "verif wiki answer": "paperback(0.7042)", "verif concept answer": "chef(0.6079)", "verif image answer": "chef(0.6435)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526666.jpg"}, {"question": "how would the water taste that the man is riding on", "gt answer": "salty(1.00)", "pred answer": "sweet", "question_id": 2152885, "best approach": "", "verif answer": "sweet", "anno approach": "wiki, concept, image", "verif wiki answer": "fresh(0.6305)", "verif concept answer": "danger(0.6719)", "verif image answer": "danger(0.6184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215288.jpg"}, {"question": "to what animal kingdom does this animal belong", "gt answer": "feline(1.00)<br/>lion(0.60)<br/>mammal(0.60)", "pred answer": "cat", "question_id": 1938215, "best approach": "wiki, concept", "verif answer": "cat", "anno approach": "wiki, concept, image", "verif wiki answer": "lion(0.6742)", "verif concept answer": "lion(0.6941)", "verif image answer": "cat(0.6920)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193821.jpg"}, {"question": "what disney movie is this object the center of", "gt answer": "beauty and beast(1.00)", "pred answer": "wizard of oz", "question_id": 2505665, "best approach": "", "verif answer": "wizard of oz", "anno approach": "wiki, concept, image", "verif wiki answer": "wizard of oz(0.5280)", "verif concept answer": "wizard of oz(0.7128)", "verif image answer": "karaoke(0.7088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250566.jpg"}, {"question": "what type of contest is featured at a show of this nature", "gt answer": "car show(1.00)<br/>car(1.00)<br/>race(0.60)", "pred answer": "horse race", "question_id": 280585, "best approach": "wiki", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "car(0.6428)", "verif concept answer": "speed(0.6563)", "verif image answer": "rv(0.6797)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028058.jpg"}, {"question": "how do a plane 's wings help them to fly", "gt answer": "lift(1.00)", "pred answer": "engine", "question_id": 3487155, "best approach": "", "verif answer": "lift", "anno approach": "wiki, concept, image", "verif wiki answer": "flight(0.6047)", "verif concept answer": "flight(0.6119)", "verif image answer": "flight(0.7013)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348715.jpg"}, {"question": "when is it legal for the driver to resume driving", "gt answer": "green light(1.00)", "pred answer": "summer", "question_id": 2504175, "best approach": "wiki, image", "verif answer": "illegal", "anno approach": "wiki, concept, image", "verif wiki answer": "green light(0.6085)", "verif concept answer": "direct(0.5861)", "verif image answer": "green light(0.6011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250417.jpg"}, {"question": "where was this photo taken", "gt answer": "intersection(1.00)<br/>above(0.60)<br/>outside(0.60)", "pred answer": "street", "question_id": 901945, "best approach": "", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "park lot(0.6861)", "verif concept answer": "park lot(0.6267)", "verif image answer": "park lot(0.6696)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090194.jpg"}, {"question": "what type of plant is on this table", "gt answer": "succulent(1.00)<br/>indoor(0.60)", "pred answer": "flower", "question_id": 432565, "best approach": "wiki, concept", "verif answer": "fern", "anno approach": "wiki, concept, image", "verif wiki answer": "succulent(0.6519)", "verif concept answer": "succulent(0.6857)", "verif image answer": "aloe(0.7059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043256.jpg"}, {"question": "what time period were these devices made in", "gt answer": "1800's(1.00)<br/>industrial(0.60)<br/>1800s(0.60)", "pred answer": "1850", "question_id": 3778785, "best approach": "wiki, concept", "verif answer": "1800's", "anno approach": "wiki, concept, image", "verif wiki answer": "1800s(0.6750)", "verif concept answer": "1800s(0.5600)", "verif image answer": "western(0.7060)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377878.jpg"}, {"question": "what type of home to these animals build", "gt answer": "nest(1.00)<br/>bird house(0.60)", "pred answer": "house", "question_id": 1881815, "best approach": "image", "verif answer": "barn", "anno approach": "wiki, concept, image", "verif wiki answer": "barn(0.6593)", "verif concept answer": "van(0.6947)", "verif image answer": "nest(0.6812)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188181.jpg"}, {"question": "what is the purpose of the light attached to the picture", "gt answer": "illumination(1.00)<br/>display(0.60)", "pred answer": "light", "question_id": 5557975, "best approach": "wiki", "verif answer": "decoration", "anno approach": "wiki, concept, image", "verif wiki answer": "display(0.6699)", "verif concept answer": "decoration(0.6292)", "verif image answer": "decoration(0.6662)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555797.jpg"}, {"question": "is this product manufactured by apple or another brand", "gt answer": "another brand(1.00)<br/>motorola(0.60)", "pred answer": "apple", "question_id": 3730775, "best approach": "", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "apple(0.6358)", "verif concept answer": "paper(0.6235)", "verif image answer": "apple(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373077.jpg"}, {"question": "what is the name of the car this dog is sitting in", "gt answer": "fiat(1.00)", "pred answer": "van", "question_id": 4474245, "best approach": "wiki, concept, image", "verif answer": "toyota", "anno approach": "wiki, concept, image", "verif wiki answer": "fiat(0.6676)", "verif concept answer": "fiat(0.6932)", "verif image answer": "fiat(0.6903)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447424.jpg"}, {"question": "what year was the style of this kitchen popular", "gt answer": "1970(1.00)<br/>1950s(0.60)<br/>1940(0.60)", "pred answer": "1969", "question_id": 2583705, "best approach": "concept", "verif answer": "1970", "anno approach": "wiki, concept, image", "verif wiki answer": "1940(0.6957)", "verif concept answer": "1970(0.6434)", "verif image answer": "1950s(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258370.jpg"}, {"question": "the mouth of an animal like this one is called a what", "gt answer": "beak(1.00)", "pred answer": "tongue", "question_id": 5481075, "best approach": "", "verif answer": "beak", "anno approach": "wiki, concept, image", "verif wiki answer": "canine(0.7063)", "verif concept answer": "canine(0.6802)", "verif image answer": "nothing(0.6835)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548107.jpg"}, {"question": "what is the person in the background saying with their hands", "gt answer": "out(1.00)<br/>safe(1.00)", "pred answer": "pitch", "question_id": 3336345, "best approach": "image", "verif answer": "out", "anno approach": "wiki, concept, image", "verif wiki answer": "water(0.6036)", "verif concept answer": "strike(0.6289)", "verif image answer": "safe(0.7083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333634.jpg"}, {"question": "what is the person in this picture doing", "gt answer": "bike(1.00)<br/>bicycling(1.00)", "pred answer": "ride", "question_id": 4837815, "best approach": "wiki", "verif answer": "bike", "anno approach": "wiki, concept, image", "verif wiki answer": "bicycling(0.6623)", "verif concept answer": "bicycle(0.5704)", "verif image answer": "bicycle(0.6913)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483781.jpg"}, {"question": "what type of flower is pictured in the vase", "gt answer": "lavendar(1.00)<br/>lavender(0.60)", "pred answer": "rose", "question_id": 2838145, "best approach": "wiki", "verif answer": "rose", "anno approach": "wiki, concept, image", "verif wiki answer": "lavendar(0.6748)", "verif concept answer": "rose(0.6811)", "verif image answer": "rose(0.6390)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283814.jpg"}, {"question": "why are they cutting this cake", "gt answer": "married(1.00)<br/>to eat(0.60)", "pred answer": "birthday", "question_id": 4853645, "best approach": "", "verif answer": "holiday", "anno approach": "wiki, concept, image", "verif wiki answer": "holiday(0.5976)", "verif concept answer": "holiday(0.6470)", "verif image answer": "holiday(0.6607)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485364.jpg"}, {"question": "the chocolate pie in the girl 's hand is liked by which other category of people", "gt answer": "adult(1.00)<br/>police(0.60)<br/>donut(0.60)", "pred answer": "chinese", "question_id": 1213515, "best approach": "wiki, concept, image", "verif answer": "adult", "anno approach": "wiki, concept, image", "verif wiki answer": "adult(0.6082)", "verif concept answer": "adult(0.6749)", "verif image answer": "adult(0.6312)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000121351.jpg"}, {"question": "what are the buildings called", "gt answer": "skyscraper(1.00)", "pred answer": "sky", "question_id": 3770445, "best approach": "concept, image", "verif answer": "skyscraper", "anno approach": "wiki, concept, image", "verif wiki answer": "build(0.7180)", "verif concept answer": "skyscraper(0.6748)", "verif image answer": "skyscraper(0.6916)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377044.jpg"}, {"question": "where is an arrangement like this likely to be", "gt answer": "live room(1.00)<br/>table(0.60)", "pred answer": "hotel", "question_id": 2701865, "best approach": "", "verif answer": "live", "anno approach": "wiki, concept, image", "verif wiki answer": "bedroom(0.6586)", "verif concept answer": "live(0.6778)", "verif image answer": "bedroom(0.6253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270186.jpg"}, {"question": "what material are the umbrellas made of", "gt answer": "straw(1.00)", "pred answer": "canvas", "question_id": 4594715, "best approach": "", "verif answer": "nylon", "anno approach": "wiki, concept, image", "verif wiki answer": "rattan(0.6719)", "verif concept answer": "nylon(0.6784)", "verif image answer": "rattan(0.7249)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459471.jpg"}, {"question": "what type of penguin is this", "gt answer": "emperor(1.00)<br/>king(0.60)<br/>puffin(0.60)", "pred answer": "vulture", "question_id": 859455, "best approach": "image", "verif answer": "pelican", "anno approach": "wiki, concept, image", "verif wiki answer": "finch(0.6449)", "verif concept answer": "finch(0.6928)", "verif image answer": "emperor(0.5629)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085945.jpg"}, {"question": "what kind of dog is this", "gt answer": "dalmation(1.00)<br/>dalmatian(0.60)", "pred answer": "border collie", "question_id": 3018955, "best approach": "wiki, concept, image", "verif answer": "dalmation", "anno approach": "wiki, concept, image", "verif wiki answer": "dalmation(0.7267)", "verif concept answer": "dalmation(0.7223)", "verif image answer": "dalmation(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301895.jpg"}, {"question": "name the material used to make this sofa shown in this picture", "gt answer": "microfiber(1.00)<br/>cloth(0.60)", "pred answer": "leather", "question_id": 1163535, "best approach": "image", "verif answer": "cloth", "anno approach": "wiki, concept, image", "verif wiki answer": "polyester(0.5584)", "verif concept answer": "lace(0.5364)", "verif image answer": "cloth(0.5781)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116353.jpg"}, {"question": "what was the machine beside the bowl used for", "gt answer": "timer(1.00)<br/>toast(1.00)", "pred answer": "cook", "question_id": 18105, "best approach": "concept", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "nursing(0.5490)", "verif concept answer": "timer(0.5920)", "verif image answer": "food(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001810.jpg"}, {"question": "when did this sport become popular", "gt answer": "1846(1.00)<br/>1940(0.60)", "pred answer": "1948", "question_id": 236395, "best approach": "image", "verif answer": "1968", "anno approach": "wiki, concept, image", "verif wiki answer": "1930's(0.5432)", "verif concept answer": "1930's(0.6650)", "verif image answer": "1846(0.5965)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023639.jpg"}, {"question": "what piece of furniture is the television on top of", "gt answer": "desk(1.00)", "pred answer": "couch", "question_id": 1448815, "best approach": "image", "verif answer": "table", "anno approach": "wiki, concept, image", "verif wiki answer": "crib(0.5817)", "verif concept answer": "crib(0.6499)", "verif image answer": "desk(0.7227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144881.jpg"}, {"question": "what math concept is often taught with these objects", "gt answer": "fraction(1.00)", "pred answer": "math", "question_id": 5212665, "best approach": "concept", "verif answer": "math", "anno approach": "wiki, concept, image", "verif wiki answer": "math(0.6050)", "verif concept answer": "fraction(0.5717)", "verif image answer": "magazine(0.5198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521266.jpg"}, {"question": "what is a popular food served in this event", "gt answer": "hotdog(1.00)<br/>hotdogs(0.60)", "pred answer": "hot dog", "question_id": 3769125, "best approach": "", "verif answer": "hot dog", "anno approach": "wiki, concept, image", "verif wiki answer": "fast food(0.6957)", "verif concept answer": "hot dog(0.6549)", "verif image answer": "pepperoni(0.7190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376912.jpg"}, {"question": "what is the name of the stone on the right", "gt answer": "brick(1.00)<br/>walmart(0.60)", "pred answer": "limestone", "question_id": 5240445, "best approach": "wiki, image", "verif answer": "brick", "anno approach": "wiki, concept, image", "verif wiki answer": "brick(0.7004)", "verif concept answer": "chicago(0.6825)", "verif image answer": "brick(0.6957)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000524044.jpg"}, {"question": "why is the animal there", "gt answer": "curious(1.00)<br/>hot(0.60)", "pred answer": "pet", "question_id": 2014065, "best approach": "wiki", "verif answer": "warmth", "anno approach": "wiki, concept, image", "verif wiki answer": "hot(0.5733)", "verif concept answer": "warmth(0.6693)", "verif image answer": "warmth(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201406.jpg"}, {"question": "what is the breaded portion of this edible called", "gt answer": "crust(1.00)<br/>dough(0.60)", "pred answer": "bread", "question_id": 987395, "best approach": "wiki", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "crust(0.5288)", "verif concept answer": "dough(0.5670)", "verif image answer": "pita(0.6757)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098739.jpg"}, {"question": "where is this landmark", "gt answer": "philadelphia(1.00)<br/>boston(0.60)<br/>new york city(0.60)", "pred answer": "cafe", "question_id": 4202915, "best approach": "wiki, concept, image", "verif answer": "new york city", "anno approach": "wiki, concept, image", "verif wiki answer": "boston(0.5733)", "verif concept answer": "boston(0.6606)", "verif image answer": "new york city(0.7177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420291.jpg"}, {"question": "what is the technical term for this automobile", "gt answer": "cart(1.00)<br/>buggy(0.60)", "pred answer": "log", "question_id": 3364145, "best approach": "wiki, concept, image", "verif answer": "cart", "anno approach": "wiki, concept, image", "verif wiki answer": "cart(0.5979)", "verif concept answer": "cart(0.6409)", "verif image answer": "cart(0.6081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000336414.jpg"}, {"question": "what do the arrows on the road mean", "gt answer": "turn(1.00)<br/>direction(0.60)", "pred answer": "crosswalk", "question_id": 4171295, "best approach": "concept", "verif answer": "direction", "anno approach": "wiki, concept, image", "verif wiki answer": "direct(0.6884)", "verif concept answer": "direction(0.6317)", "verif image answer": "run(0.6737)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417129.jpg"}, {"question": "who invented the two wheel transportation in this photo", "gt answer": "segway(1.00)<br/>dean kamen(1.00)", "pred answer": "larry stevenson", "question_id": 716035, "best approach": "wiki, concept, image", "verif answer": "wright brother", "anno approach": "wiki, concept, image", "verif wiki answer": "segway(0.5581)", "verif concept answer": "dean kamen(0.6132)", "verif image answer": "dean kamen(0.6959)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071603.jpg"}, {"question": "why are these sheep marked", "gt answer": "shear(1.00)<br/>number(0.60)", "pred answer": "wool", "question_id": 1110025, "best approach": "", "verif answer": "shear", "anno approach": "wiki, concept, image", "verif wiki answer": "brand(0.5463)", "verif concept answer": "brand(0.7095)", "verif image answer": "clip(0.6744)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111002.jpg"}, {"question": "how much calorie can be got from eating that food", "gt answer": "500(1.00)<br/>300(0.60)", "pred answer": "250", "question_id": 4634325, "best approach": "", "verif answer": "200", "anno approach": "wiki, concept, image", "verif wiki answer": "200(0.6918)", "verif concept answer": "200(0.6692)", "verif image answer": "400(0.7202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463432.jpg"}, {"question": "which brand of dog is sitting in the picture shown", "gt answer": "shepherd(1.00)<br/>mutt(0.60)<br/>german shepherd(0.60)", "pred answer": "collie", "question_id": 2676115, "best approach": "concept", "verif answer": "collie", "anno approach": "wiki, concept, image", "verif wiki answer": "collie(0.6957)", "verif concept answer": "shepherd(0.7142)", "verif image answer": "collie(0.6883)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000267611.jpg"}, {"question": "what is being done", "gt answer": "surgery(1.00)", "pred answer": "travel", "question_id": 326755, "best approach": "wiki", "verif answer": "sew", "anno approach": "wiki, concept, image", "verif wiki answer": "surgery(0.6496)", "verif concept answer": "air(0.6541)", "verif image answer": "office(0.6689)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032675.jpg"}, {"question": "what kind of laptop is the child using", "gt answer": "macbook(1.00)<br/>apple(0.60)<br/>microsoft(0.60)", "pred answer": "dell", "question_id": 536325, "best approach": "wiki, concept, image", "verif answer": "dell", "anno approach": "wiki, concept, image", "verif wiki answer": "apple(0.6275)", "verif concept answer": "apple(0.5544)", "verif image answer": "apple(0.6975)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053632.jpg"}, {"question": "this picture is lit up with the help of what part of a camera", "gt answer": "flash(1.00)", "pred answer": "screen", "question_id": 3523995, "best approach": "", "verif answer": "lamp", "anno approach": "wiki, concept, image", "verif wiki answer": "reflector(0.6745)", "verif concept answer": "lamp(0.6177)", "verif image answer": "light(0.7102)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000352399.jpg"}, {"question": "people with this color hair are often found in which island nation", "gt answer": "ireland(1.00)<br/>play(0.60)", "pred answer": "china", "question_id": 1269675, "best approach": "concept", "verif answer": "england", "anno approach": "wiki, concept, image", "verif wiki answer": "england(0.6879)", "verif concept answer": "ireland(0.7074)", "verif image answer": "tiger(0.6728)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126967.jpg"}, {"question": "which food item here has the most protein", "gt answer": "egg(1.00)<br/>fish(0.60)<br/>salmon(0.60)", "pred answer": "meat", "question_id": 5388615, "best approach": "wiki, concept, image", "verif answer": "salmon", "anno approach": "wiki, concept, image", "verif wiki answer": "egg(0.6150)", "verif concept answer": "egg(0.6447)", "verif image answer": "egg(0.7171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538861.jpg"}, {"question": "what popular vacation vessel is this", "gt answer": "cruise ship(1.00)<br/>cruise(0.60)", "pred answer": "boat", "question_id": 3481435, "best approach": "wiki", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "cruise ship(0.6846)", "verif concept answer": "boat(0.6603)", "verif image answer": "yacht(0.7203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348143.jpg"}, {"question": "what animals are surrounding the giraffe 's legs", "gt answer": "gazelle(1.00)<br/>deer(0.60)<br/>goat(0.60)", "pred answer": "zebra", "question_id": 435455, "best approach": "image", "verif answer": "goat", "anno approach": "wiki, concept, image", "verif wiki answer": "aries(0.6501)", "verif concept answer": "wolf(0.6873)", "verif image answer": "gazelle(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043545.jpg"}, {"question": "what is the main goal of the game he is playing", "gt answer": "hit ball(1.00)", "pred answer": "tennis", "question_id": 592625, "best approach": "wiki, concept", "verif answer": "point", "anno approach": "wiki, concept, image", "verif wiki answer": "hit ball(0.7212)", "verif concept answer": "hit ball(0.6934)", "verif image answer": "point(0.7181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059262.jpg"}, {"question": "who determines whether a baseball player is out at base", "gt answer": "umpire(1.00)<br/>referee(0.60)", "pred answer": "out", "question_id": 927535, "best approach": "concept", "verif answer": "umpire", "anno approach": "wiki, concept, image", "verif wiki answer": "catcher(0.6845)", "verif concept answer": "referee(0.6733)", "verif image answer": "catcher(0.7193)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092753.jpg"}, {"question": "what country invented this food", "gt answer": "germany(1.00)<br/>usa(0.60)", "pred answer": "italy", "question_id": 3159725, "best approach": "image", "verif answer": "united state", "anno approach": "wiki, concept, image", "verif wiki answer": "usa(0.7106)", "verif concept answer": "usa(0.6637)", "verif image answer": "germany(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315972.jpg"}, {"question": "why won't the pedestrians need to worry about the truck", "gt answer": "on sidewalk(1.00)<br/>sidewalk(0.60)", "pred answer": "turn", "question_id": 303955, "best approach": "wiki", "verif answer": "crosswalk", "anno approach": "wiki, concept, image", "verif wiki answer": "on sidewalk(0.6309)", "verif concept answer": "crosswalk(0.6878)", "verif image answer": "crosswalk(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030395.jpg"}, {"question": "what time is it", "gt answer": "9:25(1.00)", "pred answer": "12:24", "question_id": 535735, "best approach": "wiki, concept, image", "verif answer": "afternoon", "anno approach": "wiki, concept, image", "verif wiki answer": "9:25(0.5177)", "verif concept answer": "9:25(0.5961)", "verif image answer": "9:25(0.5342)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053573.jpg"}, {"question": "where did this surfer get his board", "gt answer": "shop(1.00)<br/>store(0.60)", "pred answer": "under wave", "question_id": 3023725, "best approach": "concept", "verif answer": "store", "anno approach": "wiki, concept, image", "verif wiki answer": "online(0.5427)", "verif concept answer": "store(0.5887)", "verif image answer": "online(0.6636)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302372.jpg"}, {"question": "what common skin condition does the boy to the left have", "gt answer": "acne(1.00)", "pred answer": "bald", "question_id": 3130715, "best approach": "", "verif answer": "cold", "anno approach": "wiki, concept, image", "verif wiki answer": "cold(0.6811)", "verif concept answer": "cold(0.6393)", "verif image answer": "hot(0.7142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313071.jpg"}, {"question": "what other sodas taste like coca cola", "gt answer": "pepsi(1.00)", "pred answer": "coke", "question_id": 4612675, "best approach": "image", "verif answer": "coke", "anno approach": "wiki, concept, image", "verif wiki answer": "van(0.6479)", "verif concept answer": "coke(0.5587)", "verif image answer": "pepsi(0.5649)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461267.jpg"}, {"question": "which airlines is portrayed in this photo", "gt answer": "air france(1.00)<br/>france(0.60)", "pred answer": "boeing", "question_id": 936575, "best approach": "wiki, image", "verif answer": "air france", "anno approach": "wiki, concept, image", "verif wiki answer": "air france(0.6089)", "verif concept answer": "france(0.5488)", "verif image answer": "air france(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093657.jpg"}, {"question": "what store is known for the type of coffee table seen in the image", "gt answer": "ikea(1.00)<br/>starbucks(0.60)<br/>walmart(0.60)", "pred answer": "furniture store", "question_id": 429725, "best approach": "wiki, image", "verif answer": "ikea", "anno approach": "wiki, concept, image", "verif wiki answer": "ikea(0.5315)", "verif concept answer": "ashley(0.5328)", "verif image answer": "ikea(0.5428)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042972.jpg"}, {"question": "which material choice would lead one to suspect this decor is in a tropical region", "gt answer": "bamboo(1.00)", "pred answer": "rock", "question_id": 3690865, "best approach": "wiki", "verif answer": "wicker", "anno approach": "wiki, concept, image", "verif wiki answer": "bamboo(0.6458)", "verif concept answer": "flower(0.6915)", "verif image answer": "grass(0.6209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369086.jpg"}, {"question": "how old is the child", "gt answer": "1(1.00)<br/>young(0.60)", "pred answer": "3", "question_id": 2432115, "best approach": "concept", "verif answer": "2", "anno approach": "wiki, concept, image", "verif wiki answer": "6 months(0.6657)", "verif concept answer": "young(0.6193)", "verif image answer": "2(0.7064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243211.jpg"}, {"question": "what does the animal use hay for", "gt answer": "bed(1.00)<br/>to eat(0.60)<br/>eat(0.60)", "pred answer": "food", "question_id": 5597285, "best approach": "wiki, concept, image", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "to eat(0.6099)", "verif concept answer": "eat(0.6961)", "verif image answer": "to eat(0.5392)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559728.jpg"}, {"question": "what piece of furniture is housing the white clothing", "gt answer": "wardrobe(1.00)", "pred answer": "bed", "question_id": 4384485, "best approach": "image", "verif answer": "scarf", "anno approach": "wiki, concept, image", "verif wiki answer": "breakfast(0.5172)", "verif concept answer": "breakfast(0.5306)", "verif image answer": "wardrobe(0.7067)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000438448.jpg"}, {"question": "what shade of blue was used for his shirt", "gt answer": "baby blue(1.00)<br/>ocean(0.60)", "pred answer": "blue", "question_id": 4008625, "best approach": "", "verif answer": "purple", "anno approach": "wiki, concept, image", "verif wiki answer": "purple(0.5747)", "verif concept answer": "purple(0.5894)", "verif image answer": "sky(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400862.jpg"}, {"question": "this surfer might be in shark infested waters what movie could this picture be taken from", "gt answer": "jaw(1.00)", "pred answer": "mulan", "question_id": 5192875, "best approach": "image", "verif answer": "forest gump", "anno approach": "wiki, concept, image", "verif wiki answer": "lion king(0.6692)", "verif concept answer": "friend(0.6910)", "verif image answer": "jaw(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000519287.jpg"}, {"question": "what is the frame made of", "gt answer": "wood(1.00)", "pred answer": "glass", "question_id": 5419735, "best approach": "", "verif answer": "wood", "anno approach": "wiki, concept, image", "verif wiki answer": "laminate(0.5916)", "verif concept answer": "laminate(0.6338)", "verif image answer": "hardwood(0.6867)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541973.jpg"}, {"question": "what kind of dog is in the photo", "gt answer": "saint bernard(1.00)<br/>bulldog(0.60)", "pred answer": "collie", "question_id": 1832405, "best approach": "image", "verif answer": "collie", "anno approach": "wiki, concept, image", "verif wiki answer": "pug(0.7099)", "verif concept answer": "bulldog(0.6944)", "verif image answer": "saint bernard(0.6274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183240.jpg"}, {"question": "what brand are these", "gt answer": "boyds(1.00)<br/>toy r us(0.60)", "pred answer": "build bear", "question_id": 2072505, "best approach": "wiki", "verif answer": "walmart", "anno approach": "wiki, concept, image", "verif wiki answer": "toy r us(0.5637)", "verif concept answer": "heinz(0.5913)", "verif image answer": "walmart(0.7123)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207250.jpg"}, {"question": "how is power transmitted from the power lines shown to the vehicle in the photo", "gt answer": "cable(1.00)<br/>power line(0.60)<br/>overhead(0.60)<br/>electricity(0.60)", "pred answer": "electric", "question_id": 1864105, "best approach": "image", "verif answer": "electricity", "anno approach": "wiki, concept, image", "verif wiki answer": "overhead(0.7037)", "verif concept answer": "electricity(0.6443)", "verif image answer": "cable(0.7146)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186410.jpg"}, {"question": "how are these people related", "gt answer": "teammate(1.00)<br/>team(0.60)<br/>family(0.60)<br/>same team(0.60)", "pred answer": "friend", "question_id": 2153415, "best approach": "wiki", "verif answer": "family", "anno approach": "wiki, concept, image", "verif wiki answer": "family(0.6626)", "verif concept answer": "partner(0.6406)", "verif image answer": "partner(0.7165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215341.jpg"}, {"question": "what animal enjoys eating the orange food", "gt answer": "rabbit(1.00)<br/>horse(0.60)", "pred answer": "monkey", "question_id": 1785205, "best approach": "image", "verif answer": "cow", "anno approach": "wiki, concept, image", "verif wiki answer": "cow(0.7068)", "verif concept answer": "pony(0.7127)", "verif image answer": "horse(0.7034)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178520.jpg"}, {"question": "what casino game does this clock resemble", "gt answer": "roulette(1.00)", "pred answer": "cinderella", "question_id": 3512505, "best approach": "concept, image", "verif answer": "thomas", "anno approach": "wiki, concept, image", "verif wiki answer": "thomas(0.5887)", "verif concept answer": "roulette(0.5850)", "verif image answer": "roulette(0.5187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351250.jpg"}, {"question": "what are they watching", "gt answer": "game(1.00)<br/>football(0.60)<br/>television(0.60)", "pred answer": "video game", "question_id": 3930915, "best approach": "wiki, concept, image", "verif answer": "video game", "anno approach": "wiki, concept, image", "verif wiki answer": "television(0.6539)", "verif concept answer": "television(0.6133)", "verif image answer": "television(0.7177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393091.jpg"}, {"question": "what kind of coffee shop pastry is this", "gt answer": "coffee cake(1.00)<br/>starbucks(0.60)<br/>bread(0.60)", "pred answer": "cake", "question_id": 15225, "best approach": "", "verif answer": "pie", "anno approach": "wiki, concept, image", "verif wiki answer": "bun(0.6534)", "verif concept answer": "bun(0.6703)", "verif image answer": "bun(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001522.jpg"}, {"question": "what common juice is made from the yellow fruit depicted", "gt answer": "lemonade(1.00)<br/>lemon(0.60)", "pred answer": "orange", "question_id": 3566545, "best approach": "image", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "orange(0.6205)", "verif concept answer": "orange(0.6286)", "verif image answer": "lemonade(0.6625)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356654.jpg"}, {"question": "what type of drink is present in the photo", "gt answer": "margarita(1.00)<br/>cocktail(0.60)<br/>beer(0.60)", "pred answer": "alcoholic", "question_id": 1557955, "best approach": "wiki", "verif answer": "alcoholic", "anno approach": "wiki, concept, image", "verif wiki answer": "margarita(0.6679)", "verif concept answer": "cocktail(0.6717)", "verif image answer": "cocktail(0.7051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155795.jpg"}, {"question": "what is the best brand of tool for repairing toilets", "gt answer": "black and decker(1.00)<br/>snake(0.60)", "pred answer": "citikitty", "question_id": 4280855, "best approach": "concept", "verif answer": "kenmore", "anno approach": "wiki, concept, image", "verif wiki answer": "frigidaire(0.6577)", "verif concept answer": "black and decker(0.7133)", "verif image answer": "frigidaire(0.6269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428085.jpg"}, {"question": "what are the three players in this picture doing with the ball", "gt answer": "play soccer(1.00)<br/>kick(0.60)<br/>soccer(0.60)", "pred answer": "talk", "question_id": 1653195, "best approach": "concept", "verif answer": "soccer", "anno approach": "wiki, concept, image", "verif wiki answer": "soccer(0.5946)", "verif concept answer": "play soccer(0.5858)", "verif image answer": "block(0.6823)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000165319.jpg"}, {"question": "how is food being kept at the proper temperature", "gt answer": "crock pot(1.00)", "pred answer": "boil", "question_id": 2591375, "best approach": "", "verif answer": "fan", "anno approach": "wiki, concept, image", "verif wiki answer": "oven(0.7190)", "verif concept answer": "oven(0.6371)", "verif image answer": "oven(0.7085)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259137.jpg"}, {"question": "how does the animal in this image produce its distinctive sound", "gt answer": "pure(1.00)<br/>purr(0.60)<br/>meow(0.60)", "pred answer": "bark", "question_id": 3171625, "best approach": "concept", "verif answer": "bark", "anno approach": "wiki, concept, image", "verif wiki answer": "bark(0.6880)", "verif concept answer": "purr(0.6513)", "verif image answer": "cat(0.5356)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317162.jpg"}, {"question": "what do you call the area of the window the cat is sitting on", "gt answer": "sill(1.00)", "pred answer": "glass", "question_id": 2887705, "best approach": "", "verif answer": "shelf", "anno approach": "wiki, concept, image", "verif wiki answer": "shelf(0.6970)", "verif concept answer": "shelf(0.6198)", "verif image answer": "light(0.7044)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288770.jpg"}, {"question": "what happened just before this picture was taken", "gt answer": "jump(1.00)<br/>he jumped(0.60)", "pred answer": "trick", "question_id": 1002265, "best approach": "concept, image", "verif answer": "fall", "anno approach": "wiki, concept, image", "verif wiki answer": "jumped(0.6403)", "verif concept answer": "jump(0.6774)", "verif image answer": "jump(0.7044)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100226.jpg"}, {"question": "what skateboard trick is this man performing", "gt answer": "barrel roll(1.00)<br/>pipe(0.60)", "pred answer": "kickflip", "question_id": 4214525, "best approach": "wiki", "verif answer": "grind", "anno approach": "wiki, concept, image", "verif wiki answer": "barrel roll(0.6637)", "verif concept answer": "grind(0.6892)", "verif image answer": "grind(0.6741)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421452.jpg"}, {"question": "to what are the boats tied", "gt answer": "anchor(1.00)<br/>pole(0.60)", "pred answer": "pier", "question_id": 2980505, "best approach": "", "verif answer": "pier", "anno approach": "wiki, concept, image", "verif wiki answer": "pier(0.6105)", "verif concept answer": "pier(0.6283)", "verif image answer": "pier(0.5652)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000298050.jpg"}, {"question": "what year were these first ever flown", "gt answer": "1903(1.00)<br/>1912(0.60)<br/>1880(0.60)", "pred answer": "1930", "question_id": 4776365, "best approach": "concept", "verif answer": "1903", "anno approach": "wiki, concept, image", "verif wiki answer": "1900's(0.6097)", "verif concept answer": "1912(0.6163)", "verif image answer": "1900's(0.7013)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477636.jpg"}, {"question": "where does the content of this bottle come from", "gt answer": "spring(1.00)<br/>earth(0.60)<br/>lake(0.60)", "pred answer": "america", "question_id": 5239955, "best approach": "wiki, concept", "verif answer": "inside", "anno approach": "wiki, concept, image", "verif wiki answer": "spring(0.5331)", "verif concept answer": "spring(0.5967)", "verif image answer": "inside(0.7222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523995.jpg"}, {"question": "what kind of container might someone carry these things in", "gt answer": "backpack(1.00)<br/>suitcase(0.60)<br/>case(0.60)", "pred answer": "purse", "question_id": 2487095, "best approach": "wiki, concept", "verif answer": "purse", "anno approach": "wiki, concept, image", "verif wiki answer": "suitcase(0.6433)", "verif concept answer": "suitcase(0.5842)", "verif image answer": "bag(0.6851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248709.jpg"}, {"question": "what kind of competition is this", "gt answer": "sheep herd(1.00)<br/>rodeo(0.60)<br/>herd(0.60)", "pred answer": "horse race", "question_id": 2395585, "best approach": "concept, image", "verif answer": "horse show", "anno approach": "wiki, concept, image", "verif wiki answer": "horse show(0.6435)", "verif concept answer": "herd(0.6912)", "verif image answer": "rodeo(0.6080)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000239558.jpg"}, {"question": "what is the function of this sewer drain", "gt answer": "drain water(1.00)", "pred answer": "urine", "question_id": 5170705, "best approach": "image", "verif answer": "fire", "anno approach": "wiki, concept, image", "verif wiki answer": "fire(0.5465)", "verif concept answer": "fire(0.5898)", "verif image answer": "drain water(0.7038)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517070.jpg"}, {"question": "what are those flags symbolizing", "gt answer": "sale(1.00)<br/>mcdonalds(0.60)", "pred answer": "gay pride", "question_id": 2243955, "best approach": "wiki, image", "verif answer": "sale", "anno approach": "wiki, concept, image", "verif wiki answer": "sale(0.6058)", "verif concept answer": "mcdonalds(0.6240)", "verif image answer": "sale(0.6642)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224395.jpg"}, {"question": "what brand of phone is this woman holding", "gt answer": "nokia(1.00)", "pred answer": "apple", "question_id": 2576705, "best approach": "image", "verif answer": "nokia", "anno approach": "wiki, concept, image", "verif wiki answer": "samsung(0.6992)", "verif concept answer": "samsung(0.6741)", "verif image answer": "nokia(0.7105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257670.jpg"}, {"question": "a biblical story tells of a similar event pictured name the protagonist", "gt answer": "noah(1.00)", "pred answer": "elizabeth", "question_id": 2872285, "best approach": "wiki", "verif answer": "sunset", "anno approach": "wiki, concept, image", "verif wiki answer": "noah(0.5502)", "verif concept answer": "sunset(0.7200)", "verif image answer": "sunset(0.7245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287228.jpg"}, {"question": "when did this sport begin", "gt answer": "1800s(1.00)<br/>1945(0.60)", "pred answer": "1970", "question_id": 4763605, "best approach": "wiki", "verif answer": "1950", "anno approach": "wiki, concept, image", "verif wiki answer": "1945(0.6049)", "verif concept answer": "1920s(0.6182)", "verif image answer": "1920s(0.6660)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476360.jpg"}, {"question": "what nutrients does this meal provide", "gt answer": "calcium(1.00)<br/>vegetable(0.60)", "pred answer": "protein", "question_id": 5649825, "best approach": "concept", "verif answer": "protein", "anno approach": "wiki, concept, image", "verif wiki answer": "potassium(0.6834)", "verif concept answer": "vegetable(0.6437)", "verif image answer": "potassium(0.6954)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564982.jpg"}, {"question": "what type of beds are these", "gt answer": "double(1.00)<br/>queen(0.60)<br/>twin(0.60)", "pred answer": "canopy", "question_id": 543185, "best approach": "wiki, image", "verif answer": "king", "anno approach": "wiki, concept, image", "verif wiki answer": "double(0.6420)", "verif concept answer": "queen(0.7111)", "verif image answer": "double(0.6886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054318.jpg"}, {"question": "", "gt answer": "by magnet(0.60)", "pred answer": "magnet", "question_id": 3821895, "best approach": "", "verif answer": "magnet", "anno approach": "wiki, concept, image", "verif wiki answer": "magnet(0.5890)", "verif concept answer": "magnet(0.6224)", "verif image answer": "magnet(0.5809)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382189.jpg"}, {"question": "what kind of facility", "gt answer": "harbor(1.00)<br/>boat(0.60)", "pred answer": "marina", "question_id": 561455, "best approach": "concept", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "boat(0.7007)", "verif concept answer": "harbor(0.6092)", "verif image answer": "sail(0.6678)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000056145.jpg"}, {"question": "name the place where this horse is running in this picture", "gt answer": "rodeo(1.00)<br/>ring(0.60)", "pred answer": "field", "question_id": 2848885, "best approach": "", "verif answer": "stadium", "anno approach": "wiki, concept, image", "verif wiki answer": "horse show(0.6571)", "verif concept answer": "circus(0.6558)", "verif image answer": "stadium(0.6239)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284888.jpg"}, {"question": "what town is featured in this photo", "gt answer": "san francisco(1.00)<br/>chicago(0.60)", "pred answer": "china", "question_id": 4211345, "best approach": "image", "verif answer": "china", "anno approach": "wiki, concept, image", "verif wiki answer": "new york city(0.7106)", "verif concept answer": "new york city(0.6692)", "verif image answer": "san francisco(0.6851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421134.jpg"}, {"question": "the lights seen here look like what sort of orbiting bodies", "gt answer": "star(1.00)<br/>traffic light(0.60)", "pred answer": "airplane", "question_id": 5640745, "best approach": "wiki, concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "star(0.6195)", "verif concept answer": "star(0.6634)", "verif image answer": "traffic light(0.6443)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564074.jpg"}, {"question": "why is this cat laying on a laptop", "gt answer": "warmth(1.00)<br/>rest(0.60)", "pred answer": "tired", "question_id": 5729935, "best approach": "image", "verif answer": "warmth", "anno approach": "wiki, concept, image", "verif wiki answer": "relax(0.6060)", "verif concept answer": "relax(0.6288)", "verif image answer": "warmth(0.6775)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572993.jpg"}, {"question": "which of the items in this dish might be collected underground", "gt answer": "green bean(1.00)<br/>mushroom(1.00)<br/>carrot(0.60)", "pred answer": "lettuce", "question_id": 4878245, "best approach": "wiki", "verif answer": "potato", "anno approach": "wiki, concept, image", "verif wiki answer": "carrot(0.5857)", "verif concept answer": "potato(0.6490)", "verif image answer": "potato(0.6790)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487824.jpg"}, {"question": "this vehicle can typically hold how many gallons of fuel", "gt answer": "100(1.00)<br/>250(0.60)<br/>60(0.60)<br/>200(0.60)", "pred answer": "150", "question_id": 2787315, "best approach": "concept", "verif answer": "250", "anno approach": "wiki, concept, image", "verif wiki answer": "250(0.6610)", "verif concept answer": "100(0.5912)", "verif image answer": "250(0.6876)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278731.jpg"}, {"question": "why might we suspect that this is a model home that is not in use yet", "gt answer": "no furniture(1.00)", "pred answer": "clean", "question_id": 4093385, "best approach": "", "verif answer": "clean", "anno approach": "wiki, concept, image", "verif wiki answer": "bent(0.6989)", "verif concept answer": "clean(0.6635)", "verif image answer": "dumbo(0.7022)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409338.jpg"}, {"question": "does that cat seem content or agitated", "gt answer": "content(1.00)", "pred answer": "tired", "question_id": 1038775, "best approach": "wiki, concept", "verif answer": "warmth", "anno approach": "wiki, concept, image", "verif wiki answer": "content(0.5298)", "verif concept answer": "content(0.6660)", "verif image answer": "warmth(0.5233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103877.jpg"}, {"question": "what type of sandwich is this", "gt answer": "mcrib(1.00)<br/>hoagie(0.60)", "pred answer": "sub", "question_id": 2064755, "best approach": "wiki, concept, image", "verif answer": "hoagie", "anno approach": "wiki, concept, image", "verif wiki answer": "hoagie(0.7112)", "verif concept answer": "hoagie(0.7193)", "verif image answer": "hoagie(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206475.jpg"}, {"question": "how much do these types of dogs weigh when they're born", "gt answer": "1 pound(1.00)", "pred answer": "20 pounds", "question_id": 2072895, "best approach": "", "verif answer": "5 pounds", "anno approach": "wiki, concept, image", "verif wiki answer": "money(0.6240)", "verif concept answer": "money(0.5918)", "verif image answer": "5 pounds(0.7079)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207289.jpg"}, {"question": "where are these chairs most commonly found", "gt answer": "poolside(1.00)<br/>pool(0.60)", "pred answer": "park", "question_id": 776395, "best approach": "wiki, concept, image", "verif answer": "sofa", "anno approach": "wiki, concept, image", "verif wiki answer": "poolside(0.5679)", "verif concept answer": "poolside(0.6131)", "verif image answer": "poolside(0.7115)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077639.jpg"}, {"question": "can you name the variety of the trees shown in this picture", "gt answer": "aspen(1.00)<br/>pine tree(0.60)<br/>pine(0.60)", "pred answer": "oak", "question_id": 4853035, "best approach": "wiki", "verif answer": "oak", "anno approach": "wiki, concept, image", "verif wiki answer": "pine tree(0.6861)", "verif concept answer": "oak(0.6858)", "verif image answer": "oak(0.7245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485303.jpg"}, {"question": "what type of body of water would this be considered", "gt answer": "river(1.00)<br/>canal(0.60)", "pred answer": "lake", "question_id": 260335, "best approach": "wiki", "verif answer": "lake", "anno approach": "wiki, concept, image", "verif wiki answer": "river(0.6679)", "verif concept answer": "lake(0.6961)", "verif image answer": "lake(0.7178)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000026033.jpg"}, {"question": "what sport are these people playing a round of", "gt answer": "golf(1.00)<br/>cricket(0.60)<br/>frisbee(0.60)", "pred answer": "disc golf", "question_id": 3956735, "best approach": "wiki, concept", "verif answer": "cricket", "anno approach": "wiki, concept, image", "verif wiki answer": "cricket(0.6968)", "verif concept answer": "cricket(0.5934)", "verif image answer": "soccer(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395673.jpg"}, {"question": "how did the man change his facial hair", "gt answer": "shave(1.00)", "pred answer": "goatee", "question_id": 3185255, "best approach": "", "verif answer": "reflection", "anno approach": "wiki, concept, image", "verif wiki answer": "reflection(0.6479)", "verif concept answer": "reflection(0.6469)", "verif image answer": "reflection(0.7219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318525.jpg"}, {"question": "why do people wear these suits", "gt answer": "stay warm(1.00)<br/>cold(0.60)", "pred answer": "wet suit", "question_id": 4310775, "best approach": "wiki, concept, image", "verif answer": "wet", "anno approach": "wiki, concept, image", "verif wiki answer": "stay warm(0.7210)", "verif concept answer": "stay warm(0.6938)", "verif image answer": "stay warm(0.7108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431077.jpg"}, {"question": "what style is the light fixture", "gt answer": "tiffany(1.00)<br/>art deco(0.60)", "pred answer": "spot light", "question_id": 313295, "best approach": "", "verif answer": "chandelier", "anno approach": "wiki, concept, image", "verif wiki answer": "chandelier(0.6798)", "verif concept answer": "chandelier(0.6731)", "verif image answer": "chandelier(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000031329.jpg"}, {"question": "what is the best position to read in bed", "gt answer": "lay down(1.00)", "pred answer": "library", "question_id": 2016445, "best approach": "wiki, concept, image", "verif answer": "relax", "anno approach": "wiki, concept, image", "verif wiki answer": "lay down(0.6799)", "verif concept answer": "lay down(0.6686)", "verif image answer": "lay down(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201644.jpg"}, {"question": "what gauge of sheet metal was used to make the stainless steel refrigerator", "gt answer": "24 gauge(1.00)<br/>3(0.60)<br/>aluminium(0.60)", "pred answer": "stainless steel", "question_id": 4221615, "best approach": "wiki, concept, image", "verif answer": "copper", "anno approach": "wiki, concept, image", "verif wiki answer": "aluminium(0.5978)", "verif concept answer": "aluminium(0.6054)", "verif image answer": "aluminium(0.7195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422161.jpg"}, {"question": "where can you find these at the grocery store", "gt answer": "freezer(1.00)", "pred answer": "cafe", "question_id": 4328775, "best approach": "", "verif answer": "deli", "anno approach": "wiki, concept, image", "verif wiki answer": "mcdonalds(0.6673)", "verif concept answer": "diner(0.6337)", "verif image answer": "deli(0.7030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432877.jpg"}, {"question": "what kind of road are the vehicles on", "gt answer": "city(1.00)<br/>highway(0.60)<br/>concrete(0.60)", "pred answer": "asphalt", "question_id": 2006195, "best approach": "", "verif answer": "asphalt", "anno approach": "wiki, concept, image", "verif wiki answer": "asphalt(0.6477)", "verif concept answer": "asphalt(0.5879)", "verif image answer": "urban(0.6514)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200619.jpg"}, {"question": "which brand of gray car is shown in this picture", "gt answer": "mazda(1.00)<br/>mercedes(0.60)", "pred answer": "bmw", "question_id": 1609105, "best approach": "image", "verif answer": "ford", "anno approach": "wiki, concept, image", "verif wiki answer": "mercedes benz(0.7117)", "verif concept answer": "ford(0.6662)", "verif image answer": "mercedes(0.7144)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160910.jpg"}, {"question": "what is the name of the object used to fasten the luggage to the car", "gt answer": "strap(1.00)<br/>rack(0.60)", "pred answer": "hose", "question_id": 771855, "best approach": "wiki", "verif answer": "strap", "anno approach": "wiki, concept, image", "verif wiki answer": "strap(0.7006)", "verif concept answer": "rack(0.6127)", "verif image answer": "motor(0.6954)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077185.jpg"}, {"question": "what holiday is this platter used for", "gt answer": "thanksgiving(1.00)<br/>july 4th(0.60)<br/>easter(0.60)", "pred answer": "christmas", "question_id": 1142595, "best approach": "concept, image", "verif answer": "christmas", "anno approach": "wiki, concept, image", "verif wiki answer": "christmas(0.5436)", "verif concept answer": "july 4th(0.6962)", "verif image answer": "july 4th(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114259.jpg"}, {"question": "how do you care for this equipment", "gt answer": "wax(1.00)<br/>clean(0.60)<br/>storage(0.60)", "pred answer": "surfboard", "question_id": 192515, "best approach": "wiki, concept, image", "verif answer": "wind", "anno approach": "wiki, concept, image", "verif wiki answer": "clean(0.5355)", "verif concept answer": "clean(0.6056)", "verif image answer": "clean(0.6340)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019251.jpg"}, {"question": "what is the jet of white called", "gt answer": "smoke(1.00)<br/>trail(0.60)<br/>exhaust(0.60)", "pred answer": "airplane", "question_id": 1252275, "best approach": "", "verif answer": "contrail", "anno approach": "wiki, concept, image", "verif wiki answer": "stripe(0.5527)", "verif concept answer": "stripe(0.6443)", "verif image answer": "contrail(0.5328)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125227.jpg"}, {"question": "what is this made of", "gt answer": "silver(1.00)<br/>bronze(0.60)<br/>metal(0.60)", "pred answer": "steel", "question_id": 5138815, "best approach": "wiki, concept, image", "verif answer": "metal", "anno approach": "wiki, concept, image", "verif wiki answer": "metal(0.6512)", "verif concept answer": "metal(0.6676)", "verif image answer": "metal(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513881.jpg"}, {"question": "is this a team or individual sport", "gt answer": "individual(1.00)<br/>snow(0.60)", "pred answer": "beginner", "question_id": 5600155, "best approach": "wiki, concept", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "individual(0.6046)", "verif concept answer": "individual(0.6829)", "verif image answer": "snow(0.6747)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560015.jpg"}, {"question": "the dishes shown before you are cooked with which type of oil", "gt answer": "olive(1.00)<br/>vegetable(0.60)<br/>sesame(0.60)", "pred answer": "canola", "question_id": 5112085, "best approach": "wiki, concept", "verif answer": "canola", "anno approach": "wiki, concept, image", "verif wiki answer": "sesame(0.6210)", "verif concept answer": "vegetable(0.6594)", "verif image answer": "olive oil(0.6580)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511208.jpg"}, {"question": "can you guess where the meeting is taking place", "gt answer": "white house(1.00)<br/>washington dc(0.60)<br/>usa(0.60)", "pred answer": "cafe", "question_id": 4865815, "best approach": "", "verif answer": "china", "anno approach": "wiki, concept, image", "verif wiki answer": "america(0.5623)", "verif concept answer": "america(0.7043)", "verif image answer": "america(0.6758)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000486581.jpg"}, {"question": "what is the couch in the photo made out of", "gt answer": "fabric(1.00)<br/>wool(0.60)", "pred answer": "cloth", "question_id": 4575875, "best approach": "", "verif answer": "cloth", "anno approach": "wiki, concept, image", "verif wiki answer": "cloth(0.6513)", "verif concept answer": "cloth(0.6903)", "verif image answer": "cotton(0.6710)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457587.jpg"}, {"question": "is it safe or unsafe to be that close to train tracks", "gt answer": "unsafe(1.00)", "pred answer": "safe", "question_id": 3533445, "best approach": "image", "verif answer": "safe", "anno approach": "wiki, concept, image", "verif wiki answer": "safe(0.5921)", "verif concept answer": "safe(0.6381)", "verif image answer": "unsafe(0.6820)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353344.jpg"}, {"question": "what job function would use these", "gt answer": "spy(1.00)<br/>cook(0.60)", "pred answer": "police", "question_id": 5805385, "best approach": "", "verif answer": "office", "anno approach": "wiki, concept, image", "verif wiki answer": "office(0.6196)", "verif concept answer": "office(0.6963)", "verif image answer": "office(0.6911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580538.jpg"}, {"question": "which type of bridge is this", "gt answer": "train bridge(1.00)", "pred answer": "golden gate", "question_id": 547365, "best approach": "concept", "verif answer": "bridge", "anno approach": "wiki, concept, image", "verif wiki answer": "highway(0.6970)", "verif concept answer": "train bridge(0.6661)", "verif image answer": "highway(0.7196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054736.jpg"}, {"question": "the vehicle in this photo is also known as a rocket", "gt answer": "crotch(1.00)", "pred answer": "scooter", "question_id": 3407635, "best approach": "image", "verif answer": "harley", "anno approach": "wiki, concept, image", "verif wiki answer": "fountain(0.5289)", "verif concept answer": "dell(0.5761)", "verif image answer": "crotch(0.6539)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340763.jpg"}, {"question": "is this english or american riding", "gt answer": "american(1.00)<br/>english(1.00)", "pred answer": "3rd world", "question_id": 2076985, "best approach": "wiki, concept, image", "verif answer": "english", "anno approach": "wiki, concept, image", "verif wiki answer": "english(0.5786)", "verif concept answer": "english(0.7005)", "verif image answer": "english(0.7064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207698.jpg"}, {"question": "which zoos allow visitors to do this", "gt answer": "pet zoo(1.00)<br/>0(0.60)", "pred answer": "zoo", "question_id": 2461195, "best approach": "image", "verif answer": "zoo", "anno approach": "wiki, concept, image", "verif wiki answer": "zoo(0.7084)", "verif concept answer": "zoo(0.7236)", "verif image answer": "0(0.7249)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246119.jpg"}, {"question": "what city is this", "gt answer": "washington dc(1.00)", "pred answer": "london", "question_id": 3717915, "best approach": "", "verif answer": "washington dc", "anno approach": "wiki, concept, image", "verif wiki answer": "rome(0.6871)", "verif concept answer": "washington(0.7172)", "verif image answer": "washington(0.7091)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371791.jpg"}, {"question": "in what state are these mountain ranges", "gt answer": "nevada(1.00)<br/>idaho(0.60)<br/>washington(0.60)", "pred answer": "colorado", "question_id": 301755, "best approach": "image", "verif answer": "colorado", "anno approach": "wiki, concept, image", "verif wiki answer": "colorado(0.6070)", "verif concept answer": "colorado(0.6886)", "verif image answer": "idaho(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030175.jpg"}, {"question": "what kind of book is the boy reading", "gt answer": "fiction(1.00)", "pred answer": "fairytale", "question_id": 465806, "best approach": "", "verif answer": "fairytale", "anno approach": "wiki, concept, image", "verif wiki answer": "fairytale(0.7093)", "verif concept answer": "fairytale(0.5987)", "verif image answer": "fairytale(0.6207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046580.jpg"}, {"question": "this is meant to do what to the birds", "gt answer": "scare(1.00)", "pred answer": "fly", "question_id": 1887225, "best approach": "", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "fly(0.5982)", "verif concept answer": "fly(0.6709)", "verif image answer": "dry(0.5743)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188722.jpg"}, {"question": "how heavy can this mammal get in pounds", "gt answer": "1600 lbs(1.00)<br/>2000(0.60)<br/>800(0.60)", "pred answer": "100 lbs", "question_id": 3758695, "best approach": "", "verif answer": "2000", "anno approach": "wiki, concept, image", "verif wiki answer": "baby(0.6215)", "verif concept answer": "baby(0.6253)", "verif image answer": "baby(0.7143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375869.jpg"}, {"question": "what team did the player on the left begin his mlb career with", "gt answer": "yankees(1.00)<br/>red sox(0.60)", "pred answer": "dodger", "question_id": 2894255, "best approach": "", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "cardinal(0.6443)", "verif concept answer": "met(0.6462)", "verif image answer": "cardinal(0.7221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000289425.jpg"}, {"question": "what is the waist measurement of the girls jeans", "gt answer": "28(1.00)<br/>32(0.60)<br/>20 inches(0.60)", "pred answer": "short", "question_id": 3563445, "best approach": "wiki, concept", "verif answer": "32", "anno approach": "wiki, concept, image", "verif wiki answer": "20 inches(0.5714)", "verif concept answer": "20 inches(0.5739)", "verif image answer": "36(0.6932)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356344.jpg"}, {"question": "what breed of dog is in the truck", "gt answer": "german shepherd(1.00)<br/>german shepard(0.60)", "pred answer": "shepard", "question_id": 1822425, "best approach": "", "verif answer": "shepard", "anno approach": "wiki, concept, image", "verif wiki answer": "shepard(0.6713)", "verif concept answer": "shepard(0.5838)", "verif image answer": "shepard(0.5411)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182242.jpg"}, {"question": "what type of boat is this", "gt answer": "cruise ship(1.00)<br/>ship(0.60)<br/>freight(0.60)", "pred answer": "sailboat", "question_id": 60045, "best approach": "wiki, concept", "verif answer": "cruise ship", "anno approach": "wiki, concept, image", "verif wiki answer": "cruise ship(0.6742)", "verif concept answer": "cruise ship(0.7008)", "verif image answer": "freight(0.7150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006004.jpg"}, {"question": "what kind of boat is pictured", "gt answer": "tug(1.00)<br/>tugboat(1.00)", "pred answer": "yacht", "question_id": 1608485, "best approach": "wiki", "verif answer": "barge", "anno approach": "wiki, concept, image", "verif wiki answer": "tug(0.7222)", "verif concept answer": "barge(0.6570)", "verif image answer": "barge(0.6567)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160848.jpg"}, {"question": "what kind of crotch rocket is in the photo", "gt answer": "suzuki(1.00)<br/>motorcycle(0.60)", "pred answer": "car", "question_id": 794815, "best approach": "image", "verif answer": "motorcycle", "anno approach": "wiki, concept, image", "verif wiki answer": "honda(0.5923)", "verif concept answer": "kawasaki(0.6242)", "verif image answer": "suzuki(0.6964)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079481.jpg"}, {"question": "where does that door lead to", "gt answer": "outside(1.00)<br/>hall(0.60)", "pred answer": "house", "question_id": 2339705, "best approach": "wiki", "verif answer": "inside", "anno approach": "wiki, concept, image", "verif wiki answer": "outside(0.7164)", "verif concept answer": "dock(0.6403)", "verif image answer": "inside(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233970.jpg"}, {"question": "", "gt answer": "45(0.60)<br/>30 degrees(0.60)", "pred answer": "aerial", "question_id": 3322045, "best approach": "concept, image", "verif answer": "wide angle", "anno approach": "wiki, concept, image", "verif wiki answer": "wide angle(0.6205)", "verif concept answer": "45(0.6147)", "verif image answer": "45(0.6144)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332204.jpg"}, {"question": "why is the grass discolored", "gt answer": "drought(1.00)<br/>dry(0.60)<br/>sun(0.60)", "pred answer": "shade", "question_id": 603165, "best approach": "concept", "verif answer": "sun", "anno approach": "wiki, concept, image", "verif wiki answer": "fly(0.6851)", "verif concept answer": "sun(0.6261)", "verif image answer": "sun protection(0.7213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060316.jpg"}, {"question": "why is the smoke black", "gt answer": "coal(1.00)", "pred answer": "fire", "question_id": 3719785, "best approach": "concept", "verif answer": "water vapor", "anno approach": "wiki, concept, image", "verif wiki answer": "water vapor(0.6996)", "verif concept answer": "coal(0.5567)", "verif image answer": "steam(0.7144)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371978.jpg"}, {"question": "what breed of dog is that", "gt answer": "husky(1.00)<br/>german shepard(0.60)", "pred answer": "chihuahua", "question_id": 4123635, "best approach": "wiki, image", "verif answer": "german shepherd", "anno approach": "wiki, concept, image", "verif wiki answer": "husky(0.7042)", "verif concept answer": "collie(0.6899)", "verif image answer": "husky(0.6925)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412363.jpg"}, {"question": "what sort of nut has the same name as this color green", "gt answer": "pistachio(1.00)", "pred answer": "walnut", "question_id": 3626185, "best approach": "", "verif answer": "walnut", "anno approach": "wiki, concept, image", "verif wiki answer": "walnut(0.6110)", "verif concept answer": "walnut(0.6085)", "verif image answer": "cherry(0.6202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362618.jpg"}, {"question": "what is the process that allows the bear to stay on the window", "gt answer": "suction(1.00)", "pred answer": "wind", "question_id": 2450895, "best approach": "", "verif answer": "flush", "anno approach": "wiki, concept, image", "verif wiki answer": "flush(0.6517)", "verif concept answer": "bleach(0.5981)", "verif image answer": "bleach(0.6859)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245089.jpg"}, {"question": "what would you call the man behind the catcher", "gt answer": "umpire(1.00)", "pred answer": "referee", "question_id": 3283465, "best approach": "", "verif answer": "referee", "anno approach": "wiki, concept, image", "verif wiki answer": "referee(0.6850)", "verif concept answer": "bleacher(0.7139)", "verif image answer": "bleacher(0.5553)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328346.jpg"}, {"question": "why would they need those", "gt answer": "extra seat(1.00)", "pred answer": "travel", "question_id": 3642515, "best approach": "", "verif answer": "travel", "anno approach": "wiki, concept, image", "verif wiki answer": "travel(0.7189)", "verif concept answer": "travel(0.6903)", "verif image answer": "vitamin(0.5116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364251.jpg"}, {"question": "what kind of tennis stroke is this", "gt answer": "forehand(1.00)", "pred answer": "backhand", "question_id": 5281085, "best approach": "", "verif answer": "backhand", "anno approach": "wiki, concept, image", "verif wiki answer": "backhand(0.6783)", "verif concept answer": "backhand(0.6867)", "verif image answer": "serve(0.5859)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528108.jpg"}, {"question": "why would we suspect the person eating this is not diabetic", "gt answer": "sugar(1.00)", "pred answer": "presentation", "question_id": 2294075, "best approach": "", "verif answer": "carbohydrate", "anno approach": "wiki, concept, image", "verif wiki answer": "carbohydrate(0.6068)", "verif concept answer": "grain(0.6020)", "verif image answer": "grain(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000229407.jpg"}, {"question": "what type of motorcycle is that", "gt answer": "chopper(1.00)<br/>harley(0.60)", "pred answer": "honda", "question_id": 3722925, "best approach": "concept", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "motorcycle(0.5698)", "verif concept answer": "harley(0.6277)", "verif image answer": "motorcycle(0.6757)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372292.jpg"}, {"question": "what is this person about to do", "gt answer": "slide(1.00)", "pred answer": "pitch", "question_id": 4024065, "best approach": "", "verif answer": "sleep", "anno approach": "wiki, concept, image", "verif wiki answer": "jump(0.6645)", "verif concept answer": "steal(0.7211)", "verif image answer": "jump(0.7137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402406.jpg"}, {"question": "why is this place so crowded", "gt answer": "rush hour(1.00)<br/>bus(0.60)", "pred answer": "rally", "question_id": 490925, "best approach": "wiki", "verif answer": "rush hour", "anno approach": "wiki, concept, image", "verif wiki answer": "rush hour(0.7071)", "verif concept answer": "traffic jam(0.6633)", "verif image answer": "traffic jam(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049092.jpg"}, {"question": "what is the newest model of apple laptops", "gt answer": "macbook pro(1.00)<br/>macbook(0.60)", "pred answer": "apple", "question_id": 5781285, "best approach": "", "verif answer": "dell", "anno approach": "wiki, concept, image", "verif wiki answer": "laptop(0.6803)", "verif concept answer": "laptop(0.6663)", "verif image answer": "dell(0.6909)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578128.jpg"}, {"question": "what is the process called that produces the red area on the chair", "gt answer": "rust(1.00)<br/>oxidation(0.60)", "pred answer": "paint", "question_id": 1052805, "best approach": "", "verif answer": "scratch", "anno approach": "wiki, concept, image", "verif wiki answer": "camouflage(0.6653)", "verif concept answer": "scratch(0.5822)", "verif image answer": "scratch(0.6860)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105280.jpg"}, {"question": "what is the dental difference between these two animals", "gt answer": "canine(1.00)", "pred answer": "long neck", "question_id": 4563765, "best approach": "wiki, concept", "verif answer": "color", "anno approach": "wiki, concept, image", "verif wiki answer": "canine(0.5932)", "verif concept answer": "canine(0.6539)", "verif image answer": "cat(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456376.jpg"}, {"question": "what is the name for this creatures offspring", "gt answer": "puppy(1.00)", "pred answer": "calf", "question_id": 473875, "best approach": "wiki, concept, image", "verif answer": "puppy", "anno approach": "wiki, concept, image", "verif wiki answer": "puppy(0.7230)", "verif concept answer": "puppy(0.6212)", "verif image answer": "puppy(0.7246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047387.jpg"}, {"question": "what is a general function of the item she is holding", "gt answer": "shade(1.00)", "pred answer": "sun protection", "question_id": 2556235, "best approach": "image", "verif answer": "sun protection", "anno approach": "wiki, concept, image", "verif wiki answer": "sun protection(0.6657)", "verif concept answer": "block sun(0.6222)", "verif image answer": "shade(0.6122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255623.jpg"}, {"question": "are there an even number of wheels or an odd number of wheels in this parking lot", "gt answer": "even(1.00)", "pred answer": "large", "question_id": 622165, "best approach": "wiki, concept", "verif answer": "even", "anno approach": "wiki, concept, image", "verif wiki answer": "even(0.5880)", "verif concept answer": "even(0.6984)", "verif image answer": "filter(0.7227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000062216.jpg"}, {"question": "what kind of road is this", "gt answer": "highway(1.00)<br/>interstate(1.00)", "pred answer": "asphalt", "question_id": 487425, "best approach": "wiki, image", "verif answer": "concrete", "anno approach": "wiki, concept, image", "verif wiki answer": "highway(0.6449)", "verif concept answer": "concrete(0.6545)", "verif image answer": "highway(0.7069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048742.jpg"}, {"question": "what brand of soap is the man in the photo holding", "gt answer": "palmolive(1.00)", "pred answer": "colgate", "question_id": 2238755, "best approach": "wiki, concept", "verif answer": "colgate", "anno approach": "wiki, concept, image", "verif wiki answer": "palmolive(0.5159)", "verif concept answer": "palmolive(0.5573)", "verif image answer": "heinz(0.5652)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223875.jpg"}, {"question": "are giraffee carnivorous or herbivorous animals", "gt answer": "herbivorous(1.00)", "pred answer": "herbivore", "question_id": 5276185, "best approach": "concept, image", "verif answer": "herbivore", "anno approach": "wiki, concept, image", "verif wiki answer": "herbivore(0.6549)", "verif concept answer": "herbivorous(0.7297)", "verif image answer": "herbivorous(0.7172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527618.jpg"}, {"question": "what brand is the carpetting", "gt answer": "dupont(1.00)", "pred answer": "ashley", "question_id": 5717735, "best approach": "concept", "verif answer": "ikea", "anno approach": "wiki, concept, image", "verif wiki answer": "ikea(0.7021)", "verif concept answer": "dupont(0.6271)", "verif image answer": "ikea(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571773.jpg"}, {"question": "what company made the accordian that the man is playing", "gt answer": "castiglione(1.00)<br/>yamaha(0.60)", "pred answer": "kenmore", "question_id": 2063845, "best approach": "", "verif answer": "hasbro", "anno approach": "wiki, concept, image", "verif wiki answer": "hasbro(0.6727)", "verif concept answer": "hasbro(0.5919)", "verif image answer": "hasbro(0.6008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206384.jpg"}, {"question": "which popular video game do you think she is playing right now", "gt answer": "mario(1.00)", "pred answer": "wii", "question_id": 3435145, "best approach": "", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "wii(0.7254)", "verif concept answer": "wii(0.6966)", "verif image answer": "wii bowl(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343514.jpg"}, {"question": "what kind of transportation is this man on", "gt answer": "submarine(1.00)<br/>bus(1.00)", "pred answer": "truck", "question_id": 5073905, "best approach": "", "verif answer": "train", "anno approach": "wiki, concept, image", "verif wiki answer": "train(0.6628)", "verif concept answer": "train(0.6018)", "verif image answer": "train(0.6116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507390.jpg"}, {"question": "what is the calorie count for a slice of the pizza shown in the image", "gt answer": "400(1.00)<br/>800(0.60)<br/>300(0.60)", "pred answer": "250", "question_id": 870785, "best approach": "concept", "verif answer": "200", "anno approach": "wiki, concept, image", "verif wiki answer": "46(0.6339)", "verif concept answer": "800(0.6389)", "verif image answer": "46(0.7150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087078.jpg"}, {"question": "what type of electrical lighting is in this kitchen", "gt answer": "fluorescent(1.00)<br/>led(0.60)", "pred answer": "track", "question_id": 2681515, "best approach": "wiki, image", "verif answer": "fluorescent", "anno approach": "wiki, concept, image", "verif wiki answer": "fluorescent(0.6768)", "verif concept answer": "lamp(0.6030)", "verif image answer": "fluorescent(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268151.jpg"}, {"question": "its a bird its a blank", "gt answer": "plane(1.00)<br/>airplane(0.60)", "pred answer": "pigeon", "question_id": 4715895, "best approach": "wiki, concept, image", "verif answer": "plane", "anno approach": "wiki, concept, image", "verif wiki answer": "plane(0.5128)", "verif concept answer": "plane(0.6203)", "verif image answer": "plane(0.7016)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471589.jpg"}, {"question": "who designed this area", "gt answer": "architect(1.00)<br/>engineer(0.60)", "pred answer": "wright brother", "question_id": 3444565, "best approach": "wiki", "verif answer": "conductor", "anno approach": "wiki, concept, image", "verif wiki answer": "architect(0.6771)", "verif concept answer": "conductor(0.7130)", "verif image answer": "conductor(0.7100)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344456.jpg"}, {"question": "what is another name for elephant", "gt answer": "pacaderm(1.00)<br/>african(0.60)<br/>dumbo(0.60)", "pred answer": "buffalo", "question_id": 1024605, "best approach": "wiki, concept", "verif answer": "elephant", "anno approach": "wiki, concept, image", "verif wiki answer": "pacaderm(0.7170)", "verif concept answer": "pacaderm(0.6602)", "verif image answer": "african(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000102460.jpg"}, {"question": "how well cooked is this pizza", "gt answer": "raw(1.00)<br/>undercooked(0.60)", "pred answer": "grilled", "question_id": 3650345, "best approach": "wiki, concept", "verif answer": "very", "anno approach": "wiki, concept, image", "verif wiki answer": "undercooked(0.6191)", "verif concept answer": "undercooked(0.6461)", "verif image answer": "very(0.7086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365034.jpg"}, {"question": "what kind of meat is in the picture", "gt answer": "chicken(1.00)", "pred answer": "shrimp", "question_id": 4565635, "best approach": "", "verif answer": "pork", "anno approach": "wiki, concept, image", "verif wiki answer": "steak(0.6508)", "verif concept answer": "pork(0.5904)", "verif image answer": "pork(0.6841)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456563.jpg"}, {"question": "what is on the bush", "gt answer": "light(1.00)", "pred answer": "orange", "question_id": 3840705, "best approach": "concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "illumination(0.5640)", "verif concept answer": "light(0.5908)", "verif image answer": "chandelier(0.6875)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384070.jpg"}, {"question": "when was snowboard first introduced as an olympic sport", "gt answer": "1998(1.00)<br/>1980's(0.60)", "pred answer": "1924", "question_id": 1191575, "best approach": "wiki, concept", "verif answer": "1924", "anno approach": "wiki, concept, image", "verif wiki answer": "1980's(0.6369)", "verif concept answer": "1980's(0.6615)", "verif image answer": "winter(0.7221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119157.jpg"}, {"question": "what is the bun topped with", "gt answer": "onion(1.00)<br/>cheese(0.60)", "pred answer": "flour", "question_id": 5061365, "best approach": "wiki", "verif answer": "cheese", "anno approach": "wiki, concept, image", "verif wiki answer": "onion(0.6417)", "verif concept answer": "ketchup(0.6777)", "verif image answer": "cheese(0.6434)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506136.jpg"}, {"question": "", "gt answer": "africa(0.60)<br/>tropic(0.60)<br/>rainforest(0.60)<br/>pet store(0.60)", "pred answer": "south", "question_id": 1374205, "best approach": "wiki, concept, image", "verif answer": "tropic", "anno approach": "wiki, concept, image", "verif wiki answer": "africa(0.5826)", "verif concept answer": "africa(0.6203)", "verif image answer": "africa(0.6921)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000137420.jpg"}, {"question": "what will the batter try to do", "gt answer": "hit(1.00)<br/>homerun(0.60)<br/>swing(0.60)<br/>hit ball(0.60)", "pred answer": "pitch", "question_id": 4700535, "best approach": "concept", "verif answer": "hit", "anno approach": "wiki, concept, image", "verif wiki answer": "hit ball(0.6963)", "verif concept answer": "hit(0.6805)", "verif image answer": "swing(0.7122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470053.jpg"}, {"question": "why is this person holding an umbrella", "gt answer": "for shade(1.00)<br/>shade(1.00)<br/>block sun(0.60)", "pred answer": "rain", "question_id": 4914005, "best approach": "concept", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "rain(0.7094)", "verif concept answer": "block sun(0.6345)", "verif image answer": "rain(0.7249)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491400.jpg"}, {"question": "what material is this mans suit made of", "gt answer": "cotton(1.00)<br/>wool(1.00)<br/>polyester(0.60)", "pred answer": "leather", "question_id": 1082935, "best approach": "", "verif answer": "wool", "anno approach": "wiki, concept, image", "verif wiki answer": "cloth(0.7120)", "verif concept answer": "cloth(0.6922)", "verif image answer": "cloth(0.6668)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108293.jpg"}, {"question": "what kind of house is on this truck", "gt answer": "mobile home(1.00)<br/>trailer(0.60)", "pred answer": "apart", "question_id": 794985, "best approach": "", "verif answer": "semi", "anno approach": "wiki, concept, image", "verif wiki answer": "semi(0.6712)", "verif concept answer": "delivery(0.6375)", "verif image answer": "food(0.6433)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079498.jpg"}, {"question": "what kind of dish is the woman eating", "gt answer": "mexican(1.00)", "pred answer": "cake", "question_id": 5718675, "best approach": "concept", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "taco(0.6820)", "verif concept answer": "mexican(0.5319)", "verif image answer": "hispanic(0.6370)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571867.jpg"}, {"question": "where do you think this place could be located", "gt answer": "skatepark(1.00)<br/>skate park(1.00)", "pred answer": "airport", "question_id": 2567485, "best approach": "", "verif answer": "skate park", "anno approach": "wiki, concept, image", "verif wiki answer": "park(0.6833)", "verif concept answer": "park(0.6749)", "verif image answer": "park(0.7176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256748.jpg"}, {"question": "", "gt answer": "coffee shop(0.60)<br/>dunkin donuts(0.60)", "pred answer": "restaurant", "question_id": 1057335, "best approach": "", "verif answer": "bakery", "anno approach": "wiki, concept, image", "verif wiki answer": "low(0.5724)", "verif concept answer": "low(0.5876)", "verif image answer": "low(0.6362)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105733.jpg"}, {"question": "what direction is the wind blowing from in this photo", "gt answer": "west(1.00)<br/>right(0.60)<br/>left(0.60)", "pred answer": "north", "question_id": 5272165, "best approach": "image", "verif answer": "south", "anno approach": "wiki, concept, image", "verif wiki answer": "south(0.6258)", "verif concept answer": "south(0.6176)", "verif image answer": "right(0.6590)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527216.jpg"}, {"question": "what items did the suit case contain before it was emptied", "gt answer": "cloth(1.00)<br/>food(0.60)<br/>paper(0.60)", "pred answer": "money", "question_id": 670575, "best approach": "wiki, image", "verif answer": "cloth", "anno approach": "wiki, concept, image", "verif wiki answer": "cloth(0.5575)", "verif concept answer": "paper(0.6443)", "verif image answer": "cloth(0.6708)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067057.jpg"}, {"question": "what type of bikes are these people riding", "gt answer": "motorbike(1.00)<br/>bmx(0.60)<br/>motocross(0.60)<br/>motorcycle(0.60)", "pred answer": "dirt bike", "question_id": 3504355, "best approach": "image", "verif answer": "motorcycle", "anno approach": "wiki, concept, image", "verif wiki answer": "motocross(0.6383)", "verif concept answer": "motorcross(0.6758)", "verif image answer": "motorbike(0.7044)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350435.jpg"}, {"question": "what is the average weight of this animal at birth", "gt answer": "100lbs(1.00)<br/>500(0.60)", "pred answer": "75", "question_id": 466095, "best approach": "image", "verif answer": "50", "anno approach": "wiki, concept, image", "verif wiki answer": "50(0.5988)", "verif concept answer": "50(0.5240)", "verif image answer": "100lbs(0.6227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046609.jpg"}, {"question": "what brewery is the beer from", "gt answer": "brew dog(1.00)<br/>scotland(0.60)", "pred answer": "budweiser", "question_id": 4543725, "best approach": "wiki", "verif answer": "paris", "anno approach": "wiki, concept, image", "verif wiki answer": "brew dog(0.6885)", "verif concept answer": "scotland(0.6653)", "verif image answer": "canada(0.6278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000454372.jpg"}, {"question": "how can i get up on a snowboard", "gt answer": "carefully(1.00)<br/>balance(0.60)", "pred answer": "snowboard", "question_id": 1961975, "best approach": "wiki, concept", "verif answer": "practice", "anno approach": "wiki, concept, image", "verif wiki answer": "balance(0.6456)", "verif concept answer": "balance(0.6267)", "verif image answer": "helmet(0.7176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196197.jpg"}, {"question": "what is the average lifespan of this animal", "gt answer": "30 years(1.00)<br/>20 years(0.60)", "pred answer": "25 years", "question_id": 4183525, "best approach": "", "verif answer": "25 years", "anno approach": "wiki, concept, image", "verif wiki answer": "25 years(0.6596)", "verif concept answer": "25 years(0.6615)", "verif image answer": "25 years(0.6478)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000418352.jpg"}, {"question": "which beatles song features a road like this", "gt answer": "abbey(1.00)", "pred answer": "let go fly kite", "question_id": 2017285, "best approach": "", "verif answer": "boot", "anno approach": "wiki, concept, image", "verif wiki answer": "boot(0.6823)", "verif concept answer": "boot(0.6841)", "verif image answer": "cherry(0.7223)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201728.jpg"}, {"question": "which farmer of song fame is often associated with these animals", "gt answer": "old macdonald(1.00)<br/>dell(0.60)", "pred answer": "shepherd", "question_id": 2426565, "best approach": "wiki", "verif answer": "herbivore", "anno approach": "wiki, concept, image", "verif wiki answer": "old macdonald(0.5287)", "verif concept answer": "herbivore(0.6316)", "verif image answer": "herbivore(0.7145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000242656.jpg"}, {"question": "what kind of company 's do these trucks work for", "gt answer": "construction(1.00)<br/>carnival(0.60)<br/>transport(0.60)", "pred answer": "tow", "question_id": 3629735, "best approach": "", "verif answer": "transport", "anno approach": "wiki, concept, image", "verif wiki answer": "taxi(0.7171)", "verif concept answer": "haul(0.7133)", "verif image answer": "taxi(0.6080)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362973.jpg"}, {"question": "what is special about the sports items in the case", "gt answer": "old(1.00)<br/>antique(0.60)<br/>racket(0.60)", "pred answer": "cloth", "question_id": 1332985, "best approach": "wiki, concept", "verif answer": "racket", "anno approach": "wiki, concept, image", "verif wiki answer": "old(0.5667)", "verif concept answer": "old(0.5882)", "verif image answer": "antique(0.7093)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000133298.jpg"}, {"question": "what food is this", "gt answer": "candy apple(1.00)<br/>apple(1.00)", "pred answer": "pie", "question_id": 2236875, "best approach": "wiki, concept", "verif answer": "candy apple", "anno approach": "wiki, concept, image", "verif wiki answer": "apple(0.6084)", "verif concept answer": "apple(0.6791)", "verif image answer": "tomato(0.6581)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223687.jpg"}, {"question": "which wearable item shown here is associated with ball games", "gt answer": "cap(1.00)<br/>baseball cap(0.60)", "pred answer": "hat", "question_id": 3929745, "best approach": "", "verif answer": "hat", "anno approach": "wiki, concept, image", "verif wiki answer": "beanie(0.6911)", "verif concept answer": "beanie(0.7071)", "verif image answer": "beanie(0.7282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392974.jpg"}, {"question": "what breed of dogs are these", "gt answer": "dachshund(1.00)<br/>doberman(0.60)", "pred answer": "lab", "question_id": 3776095, "best approach": "", "verif answer": "doberman", "anno approach": "wiki, concept, image", "verif wiki answer": "chihuahua(0.7157)", "verif concept answer": "chihuahua(0.7229)", "verif image answer": "brown(0.6855)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377609.jpg"}, {"question": "what type of palm tree is picured here t", "gt answer": "coconut(1.00)<br/>pine(0.60)", "pred answer": "palm", "question_id": 1174975, "best approach": "image", "verif answer": "oak", "anno approach": "wiki, concept, image", "verif wiki answer": "pine(0.6969)", "verif concept answer": "pine(0.6888)", "verif image answer": "coconut(0.6716)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117497.jpg"}, {"question": "what size are the tires on that truck", "gt answer": "big(1.00)<br/>huge(0.60)", "pred answer": "large", "question_id": 3625555, "best approach": "concept", "verif answer": "large", "anno approach": "wiki, concept, image", "verif wiki answer": "large(0.6514)", "verif concept answer": "huge(0.6293)", "verif image answer": "3 feet(0.6991)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362555.jpg"}, {"question": "these long necked creatures live in what environment", "gt answer": "africa(1.00)<br/>hot(0.60)<br/>wild(0.60)", "pred answer": "grassland", "question_id": 5267135, "best approach": "wiki, concept", "verif answer": "africa", "anno approach": "wiki, concept, image", "verif wiki answer": "hot(0.7142)", "verif concept answer": "hot(0.6842)", "verif image answer": "india(0.6842)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526713.jpg"}, {"question": "which branch of mathematics teaches learners about angular shapes like the ones seen here", "gt answer": "geometry(1.00)", "pred answer": "english", "question_id": 4599595, "best approach": "", "verif answer": "fry", "anno approach": "wiki, concept, image", "verif wiki answer": "modern(0.6271)", "verif concept answer": "retro(0.7167)", "verif image answer": "modern(0.7075)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459959.jpg"}, {"question": "what is this boat doing", "gt answer": "float(1.00)<br/>cruise(0.60)<br/>boat(0.60)", "pred answer": "dock", "question_id": 841625, "best approach": "image", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "barge(0.5763)", "verif concept answer": "barge(0.6597)", "verif image answer": "cruise(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084162.jpg"}, {"question": "what were those buildings for originally", "gt answer": "storage(1.00)<br/>farm(0.60)<br/>time(0.60)", "pred answer": "church", "question_id": 76855, "best approach": "wiki, concept, image", "verif answer": "farm", "anno approach": "wiki, concept, image", "verif wiki answer": "farm(0.6877)", "verif concept answer": "farm(0.6520)", "verif image answer": "farm(0.7176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007685.jpg"}, {"question": "what type of dog is this", "gt answer": "boxer(1.00)<br/>labrador(0.60)", "pred answer": "chihuahua", "question_id": 3169075, "best approach": "", "verif answer": "golden retriever", "anno approach": "wiki, concept, image", "verif wiki answer": "bulldog(0.6366)", "verif concept answer": "bulldog(0.7106)", "verif image answer": "golden retriever(0.7217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316907.jpg"}, {"question": "how many times has this apple been cut", "gt answer": "once(1.00)", "pred answer": "10", "question_id": 5782315, "best approach": "image", "verif answer": "never", "anno approach": "wiki, concept, image", "verif wiki answer": "once year(0.6535)", "verif concept answer": "eaten(0.6093)", "verif image answer": "once(0.6951)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578231.jpg"}, {"question": "what is terr short for", "gt answer": "terrace(1.00)", "pred answer": "stop", "question_id": 4872455, "best approach": "", "verif answer": "cross", "anno approach": "wiki, concept, image", "verif wiki answer": "train(0.5421)", "verif concept answer": "train(0.6319)", "verif image answer": "honk(0.5815)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487245.jpg"}, {"question": "what major tennis tournament is played on the surface seen here", "gt answer": "wimbledon(1.00)", "pred answer": "us open", "question_id": 4355545, "best approach": "", "verif answer": "us open", "anno approach": "wiki, concept, image", "verif wiki answer": "open(0.6742)", "verif concept answer": "us open(0.6695)", "verif image answer": "us open(0.7223)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435554.jpg"}, {"question": "what is the significance of this man 's tie", "gt answer": "business(1.00)<br/>collar(0.60)", "pred answer": "tie", "question_id": 4280935, "best approach": "", "verif answer": "tie", "anno approach": "wiki, concept, image", "verif wiki answer": "tie(0.7215)", "verif concept answer": "tie(0.7255)", "verif image answer": "tie(0.7215)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428093.jpg"}, {"question": "what city is this plane taking off from", "gt answer": "paris(1.00)", "pred answer": "london", "question_id": 1843005, "best approach": "", "verif answer": "london", "anno approach": "wiki, concept, image", "verif wiki answer": "philadelphia(0.6517)", "verif concept answer": "philadelphia(0.7137)", "verif image answer": "london(0.7172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184300.jpg"}, {"question": "people who use this equipment are typically called what", "gt answer": "surfer(1.00)", "pred answer": "surfboard", "question_id": 2733525, "best approach": "concept, image", "verif answer": "surf", "anno approach": "wiki, concept, image", "verif wiki answer": "surf board(0.5906)", "verif concept answer": "surfer(0.5812)", "verif image answer": "surfer(0.7267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273352.jpg"}, {"question": "which muscle group is used in the move shown", "gt answer": "leg(1.00)", "pred answer": "arm", "question_id": 5596475, "best approach": "", "verif answer": "arm", "anno approach": "wiki, concept, image", "verif wiki answer": "arm(0.6873)", "verif concept answer": "feet(0.7023)", "verif image answer": "foot(0.7195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559647.jpg"}, {"question": "when were motorcycles invented", "gt answer": "1885(1.00)<br/>2010(0.60)<br/>1960(0.60)<br/>1930s(0.60)", "pred answer": "1970", "question_id": 1440895, "best approach": "wiki, concept, image", "verif answer": "1930s", "anno approach": "wiki, concept, image", "verif wiki answer": "1960(0.7071)", "verif concept answer": "1960(0.7064)", "verif image answer": "1930s(0.7074)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144089.jpg"}, {"question": "who invented the sport that the women are playing", "gt answer": "walter wingfield(1.00)<br/>man(0.60)", "pred answer": "wilson", "question_id": 4826595, "best approach": "image", "verif answer": "serena williams", "anno approach": "wiki, concept, image", "verif wiki answer": "serena williams(0.6172)", "verif concept answer": "federer(0.6311)", "verif image answer": "man(0.6636)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482659.jpg"}, {"question": "why is the sign standing in the street", "gt answer": "advertising(1.00)<br/>park(0.60)", "pred answer": "stop", "question_id": 2802705, "best approach": "wiki", "verif answer": "turn", "anno approach": "wiki, concept, image", "verif wiki answer": "park(0.5932)", "verif concept answer": "turn(0.5734)", "verif image answer": "turn(0.6657)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280270.jpg"}, {"question": "what does this truck do", "gt answer": "transport(1.00)<br/>haul(0.60)", "pred answer": "construction", "question_id": 4071355, "best approach": "concept, image", "verif answer": "tow", "anno approach": "wiki, concept, image", "verif wiki answer": "tow(0.6620)", "verif concept answer": "haul(0.6673)", "verif image answer": "haul(0.7199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407135.jpg"}, {"question": "what 's the bear for", "gt answer": "decoration(1.00)<br/>kid(0.60)", "pred answer": "comfort", "question_id": 5453645, "best approach": "", "verif answer": "kid", "anno approach": "wiki, concept, image", "verif wiki answer": "display(0.5929)", "verif concept answer": "display(0.6556)", "verif image answer": "display(0.6673)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545364.jpg"}, {"question": "what part of group does this man belong", "gt answer": "navy(1.00)<br/>catcher(0.60)<br/>military(0.60)", "pred answer": "batter", "question_id": 2155115, "best approach": "wiki, concept", "verif answer": "batter", "anno approach": "wiki, concept, image", "verif wiki answer": "catcher(0.5916)", "verif concept answer": "catcher(0.6903)", "verif image answer": "marine(0.5305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215511.jpg"}, {"question": "how far can this ladder go for", "gt answer": "105 feet(1.00)<br/>far(0.60)", "pred answer": "low", "question_id": 5179755, "best approach": "image", "verif answer": "8 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "far(0.6817)", "verif concept answer": "8 feet(0.6093)", "verif image answer": "105 feet(0.7103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517975.jpg"}, {"question": "what type of phone does he have", "gt answer": "flip(1.00)<br/>motorola(0.60)", "pred answer": "flip phone", "question_id": 989405, "best approach": "image", "verif answer": "flip phone", "anno approach": "wiki, concept, image", "verif wiki answer": "flip phone(0.6465)", "verif concept answer": "iphone(0.6731)", "verif image answer": "flip(0.6886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098940.jpg"}, {"question": "what brand are the rear view mirrors on the bus", "gt answer": "honda(1.00)<br/>toshiba(0.60)<br/>ford(0.60)", "pred answer": "double decker", "question_id": 2024105, "best approach": "image", "verif answer": "ford", "anno approach": "wiki, concept, image", "verif wiki answer": "ford(0.6898)", "verif concept answer": "dodge(0.6879)", "verif image answer": "honda(0.6893)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202410.jpg"}, {"question": "what is the name of this kind of blind", "gt answer": "vertical(1.00)<br/>horizontal(0.60)<br/>metal(0.60)", "pred answer": "blind", "question_id": 2204085, "best approach": "", "verif answer": "metal", "anno approach": "wiki, concept, image", "verif wiki answer": "checkered(0.5790)", "verif concept answer": "checkered(0.6524)", "verif image answer": "brown(0.6709)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220408.jpg"}, {"question": "the poles in the background are called what", "gt answer": "electric(1.00)", "pred answer": "telephone", "question_id": 1457385, "best approach": "", "verif answer": "telephone", "anno approach": "wiki, concept, image", "verif wiki answer": "power line(0.7152)", "verif concept answer": "power line(0.6711)", "verif image answer": "telephone(0.7243)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145738.jpg"}, {"question": "is it raining or just overcast", "gt answer": "overcast(1.00)", "pred answer": "cloudy", "question_id": 5536335, "best approach": "", "verif answer": "cloudy", "anno approach": "wiki, concept, image", "verif wiki answer": "cloudy(0.7223)", "verif concept answer": "cloudy(0.7162)", "verif image answer": "cloudy(0.6006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553633.jpg"}, {"question": "which of the devices laying on top of the laptop keyboard was manufactured first", "gt answer": "1 on far right(1.00)<br/>right(0.60)", "pred answer": "apple", "question_id": 3201255, "best approach": "wiki, concept", "verif answer": "mouse", "anno approach": "wiki, concept, image", "verif wiki answer": "1 on far right(0.6644)", "verif concept answer": "1 on far right(0.6377)", "verif image answer": "remote(0.6952)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320125.jpg"}, {"question": "what common design does this appear to be a part of", "gt answer": "smiley face(1.00)", "pred answer": "spider web", "question_id": 794625, "best approach": "image", "verif answer": "country", "anno approach": "wiki, concept, image", "verif wiki answer": "face(0.6295)", "verif concept answer": "country(0.6639)", "verif image answer": "smiley face(0.7021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079462.jpg"}, {"question": "how many professional teams are there in the us for this sport", "gt answer": "30(1.00)", "pred answer": "5", "question_id": 83295, "best approach": "", "verif answer": "5", "anno approach": "wiki, concept, image", "verif wiki answer": "15(0.7018)", "verif concept answer": "15(0.5793)", "verif image answer": "15(0.6839)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008329.jpg"}, {"question": "what category of food is being displayed", "gt answer": "fruit(1.00)", "pred answer": "banana", "question_id": 1548685, "best approach": "concept, image", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "orange(0.5212)", "verif concept answer": "fruit(0.5769)", "verif image answer": "fruit(0.6502)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154868.jpg"}, {"question": "what is this tool used for", "gt answer": "stay dry(1.00)<br/>keep dry(0.60)", "pred answer": "heat", "question_id": 1226055, "best approach": "image", "verif answer": "protection", "anno approach": "wiki, concept, image", "verif wiki answer": "keep dry(0.5894)", "verif concept answer": "bus(0.6721)", "verif image answer": "stay dry(0.7056)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122605.jpg"}, {"question": "how much does the skateboard in the photo cost", "gt answer": "$50(1.00)<br/>40(0.60)", "pred answer": "20 pounds", "question_id": 1962905, "best approach": "image", "verif answer": "50", "anno approach": "wiki, concept, image", "verif wiki answer": "50(0.5485)", "verif concept answer": "$18(0.5338)", "verif image answer": "40(0.6856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196290.jpg"}, {"question": "what is this type of vessel called specifically", "gt answer": "ship(1.00)", "pred answer": "boat", "question_id": 3881715, "best approach": "image", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "cargo(0.6894)", "verif concept answer": "cargo(0.6787)", "verif image answer": "ship(0.6976)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388171.jpg"}, {"question": "what food are these people endorsing", "gt answer": "hotdogs(1.00)<br/>dessert(0.60)<br/>hot dog(0.60)", "pred answer": "sandwich", "question_id": 3773315, "best approach": "wiki, concept, image", "verif answer": "sandwich", "anno approach": "wiki, concept, image", "verif wiki answer": "hot dog(0.6974)", "verif concept answer": "hot dog(0.6701)", "verif image answer": "dessert(0.6863)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377331.jpg"}, {"question": "what part of the body is the object in the person 's hand worn on", "gt answer": "head(1.00)", "pred answer": "feet", "question_id": 4593495, "best approach": "", "verif answer": "feet", "anno approach": "wiki, concept, image", "verif wiki answer": "feet(0.6864)", "verif concept answer": "mane(0.6624)", "verif image answer": "feet(0.7223)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459349.jpg"}, {"question": "what type of shoes are pictured", "gt answer": "loafer(1.00)<br/>summer(0.60)<br/>dress(0.60)", "pred answer": "sneaker", "question_id": 5310765, "best approach": "wiki, concept, image", "verif answer": "sneaker", "anno approach": "wiki, concept, image", "verif wiki answer": "loafer(0.6725)", "verif concept answer": "loafer(0.6428)", "verif image answer": "loafer(0.7183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531076.jpg"}, {"question": "where did they purchases their uniforms", "gt answer": "store(0.60)<br/>dick sport good(1.00)<br/>mlb(0.60)", "pred answer": "stadium", "question_id": 3859345, "best approach": "image", "verif answer": "stadium", "anno approach": "wiki, concept, image", "verif wiki answer": "stadium(0.6529)", "verif concept answer": "stadium(0.6553)", "verif image answer": "dick sport good(0.6593)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385934.jpg"}, {"question": "where do people usually use this contraption", "gt answer": "construction site(1.00)<br/>dig(0.60)", "pred answer": "highway", "question_id": 324745, "best approach": "", "verif answer": "construction", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.6657)", "verif concept answer": "street(0.6252)", "verif image answer": "construction(0.7112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032474.jpg"}, {"question": "what is this object for", "gt answer": "traffic control(1.00)<br/>traffic(0.60)<br/>control traffic(0.60)", "pred answer": "light", "question_id": 4575195, "best approach": "", "verif answer": "control traffic", "anno approach": "wiki, concept, image", "verif wiki answer": "stop light(0.7119)", "verif concept answer": "stop light(0.6710)", "verif image answer": "stop(0.6267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457519.jpg"}, {"question": "the man eating likely had parents that both had what color hair", "gt answer": "blonde(1.00)<br/>donut(0.60)", "pred answer": "white", "question_id": 3222125, "best approach": "wiki, concept, image", "verif answer": "adult", "anno approach": "wiki, concept, image", "verif wiki answer": "blonde(0.7152)", "verif concept answer": "blonde(0.6513)", "verif image answer": "blonde(0.7057)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322212.jpg"}, {"question": "what country does the flag represent", "gt answer": "malaysia(1.00)<br/>china(0.60)", "pred answer": "england", "question_id": 2811775, "best approach": "image", "verif answer": "us", "anno approach": "wiki, concept, image", "verif wiki answer": "japan(0.7026)", "verif concept answer": "us(0.6556)", "verif image answer": "malaysia(0.6666)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281177.jpg"}, {"question": "why does he have glasses on", "gt answer": "to see(1.00)<br/>sunny(0.60)<br/>shade(0.60)", "pred answer": "light", "question_id": 3924745, "best approach": "concept", "verif answer": "sunny", "anno approach": "wiki, concept, image", "verif wiki answer": "block sun(0.6782)", "verif concept answer": "sunny(0.5883)", "verif image answer": "block sun(0.7196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392474.jpg"}, {"question": "what type of flowers are those on the counter", "gt answer": "lily(1.00)<br/>hydrangea(0.60)<br/>plastic(0.60)<br/>rose(0.60)", "pred answer": "white", "question_id": 4756595, "best approach": "image", "verif answer": "rose", "anno approach": "wiki, concept, image", "verif wiki answer": "tulip(0.6614)", "verif concept answer": "tulip(0.6956)", "verif image answer": "rose(0.6965)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475659.jpg"}, {"question": "what is a staple of the diet of these animals", "gt answer": "fish(1.00)<br/>salmon(0.60)", "pred answer": "meat", "question_id": 5209805, "best approach": "wiki", "verif answer": "berry", "anno approach": "wiki, concept, image", "verif wiki answer": "fish(0.6312)", "verif concept answer": "salmon(0.6399)", "verif image answer": "egg(0.6318)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520980.jpg"}, {"question": "what brands of this riding instrument are the best", "gt answer": "van(1.00)<br/>skateboard(0.60)<br/>element(0.60)", "pred answer": "burton", "question_id": 3803445, "best approach": "wiki, concept", "verif answer": "skateboard", "anno approach": "wiki, concept, image", "verif wiki answer": "skateboard(0.6817)", "verif concept answer": "skateboard(0.6068)", "verif image answer": "shoe(0.7029)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000380344.jpg"}, {"question": "what does it mean if this were to light up yellow", "gt answer": "slow down(1.00)<br/>yield(0.60)<br/>caution(0.60)", "pred answer": "brake", "question_id": 2844546, "best approach": "wiki, concept", "verif answer": "go", "anno approach": "wiki, concept, image", "verif wiki answer": "yield(0.6567)", "verif concept answer": "yield(0.6549)", "verif image answer": "pedestrian cross(0.7117)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284454.jpg"}, {"question": "what type of birds are these", "gt answer": "flamingo(1.00)", "pred answer": "stork", "question_id": 4899425, "best approach": "", "verif answer": "stork", "anno approach": "wiki, concept, image", "verif wiki answer": "duck(0.7038)", "verif concept answer": "pelican(0.7174)", "verif image answer": "duck(0.7100)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489942.jpg"}, {"question": "when would a person do this", "gt answer": "night(1.00)<br/>bed(0.60)", "pred answer": "smuggle", "question_id": 1692495, "best approach": "wiki", "verif answer": "night", "anno approach": "wiki, concept, image", "verif wiki answer": "night(0.6202)", "verif concept answer": "nighttime(0.6559)", "verif image answer": "day(0.5963)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169249.jpg"}, {"question": "what gender are the statues", "gt answer": "male(1.00)<br/>men(0.60)", "pred answer": "female", "question_id": 5038835, "best approach": "wiki, concept", "verif answer": "female", "anno approach": "wiki, concept, image", "verif wiki answer": "male(0.7185)", "verif concept answer": "male(0.6476)", "verif image answer": "female(0.5716)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503883.jpg"}, {"question": "what does the red and yellow triangular sign mean", "gt answer": "pedestrian cross(1.00)<br/>caution(0.60)<br/>crosswalk(0.60)", "pred answer": "cow cross", "question_id": 4956415, "best approach": "wiki, concept", "verif answer": "pedestrian cross", "anno approach": "wiki, concept, image", "verif wiki answer": "pedestrian cross(0.7043)", "verif concept answer": "pedestrian cross(0.6467)", "verif image answer": "caution(0.6633)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495641.jpg"}, {"question": "what brand of bat is the batter using", "gt answer": "louisville slugger(1.00)", "pred answer": "wilson", "question_id": 5222335, "best approach": "", "verif answer": "wilson", "anno approach": "wiki, concept, image", "verif wiki answer": "baseball(0.6201)", "verif concept answer": "wilson(0.5922)", "verif image answer": "baseball(0.5977)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522233.jpg"}, {"question": "what part of the city would this be located in", "gt answer": "park(1.00)<br/>downtown(1.00)<br/>center(0.60)", "pred answer": "city", "question_id": 3071375, "best approach": "wiki, concept, image", "verif answer": "park", "anno approach": "wiki, concept, image", "verif wiki answer": "park(0.6853)", "verif concept answer": "park(0.6888)", "verif image answer": "park(0.6663)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307137.jpg"}, {"question": "what green vegetable is that", "gt answer": "pea(1.00)", "pred answer": "pickle", "question_id": 3560685, "best approach": "image", "verif answer": "pickle", "anno approach": "wiki, concept, image", "verif wiki answer": "pickle(0.6073)", "verif concept answer": "pickle(0.6084)", "verif image answer": "pea(0.5573)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356068.jpg"}, {"question": "can you tell me which type of cloth is used on the floor of this photo", "gt answer": "carpet(1.00)<br/>cotton(0.60)", "pred answer": "quilt", "question_id": 2373405, "best approach": "", "verif answer": "rug", "anno approach": "wiki, concept, image", "verif wiki answer": "rug(0.7106)", "verif concept answer": "rug(0.6074)", "verif image answer": "leather(0.7197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237340.jpg"}, {"question": "what species of bear is this", "gt answer": "black bear(1.00)<br/>brown bear(0.60)<br/>grizzly(0.60)<br/>black(0.60)", "pred answer": "brown", "question_id": 4055275, "best approach": "wiki", "verif answer": "brown", "anno approach": "wiki, concept, image", "verif wiki answer": "grizzly(0.7043)", "verif concept answer": "brown(0.6751)", "verif image answer": "brown(0.7226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405527.jpg"}, {"question": "is he seeling those fruits or going to eat them", "gt answer": "sell(1.00)<br/>eat(1.00)", "pred answer": "drink", "question_id": 3323115, "best approach": "wiki", "verif answer": "drink", "anno approach": "wiki, concept, image", "verif wiki answer": "eat(0.7060)", "verif concept answer": "drink(0.6511)", "verif image answer": "drink(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332311.jpg"}, {"question": "working together or alone", "gt answer": "together(1.00)<br/>alone(0.60)", "pred answer": "family", "question_id": 5740765, "best approach": "concept, image", "verif answer": "family", "anno approach": "wiki, concept, image", "verif wiki answer": "family(0.6918)", "verif concept answer": "together(0.6571)", "verif image answer": "together(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000574076.jpg"}, {"question": "why is one urinal smaller than the others", "gt answer": "children(1.00)<br/>kid(0.60)", "pred answer": "clean", "question_id": 444205, "best approach": "image", "verif answer": "child", "anno approach": "wiki, concept, image", "verif wiki answer": "toy(0.6058)", "verif concept answer": "kid(0.6343)", "verif image answer": "children(0.6987)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000044420.jpg"}, {"question": "what holiday theme is represented on the donut", "gt answer": "halloween(1.00)", "pred answer": "4th of july", "question_id": 25705, "best approach": "concept", "verif answer": "halloween", "anno approach": "wiki, concept, image", "verif wiki answer": "birthday(0.7204)", "verif concept answer": "halloween(0.7017)", "verif image answer": "easter(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002570.jpg"}, {"question": "which northeast american state has a name that sounds exactly like a part of this animal", "gt answer": "maine(1.00)<br/>massachusetts(0.60)", "pred answer": "texas", "question_id": 2694625, "best approach": "", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "new york(0.6720)", "verif concept answer": "new york(0.6219)", "verif image answer": "colorado(0.6840)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269462.jpg"}, {"question": "what was the main food on the larger plate", "gt answer": "pancake(1.00)<br/>danish(0.60)<br/>desert(0.60)", "pred answer": "croissant", "question_id": 3836205, "best approach": "wiki, concept, image", "verif answer": "pancake", "anno approach": "wiki, concept, image", "verif wiki answer": "pancake(0.5941)", "verif concept answer": "pancake(0.5967)", "verif image answer": "pancake(0.7065)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383620.jpg"}, {"question": "why style of numbering is seen here", "gt answer": "roman numeral(1.00)<br/>roman(1.00)<br/>numeral(0.60)", "pred answer": "clock", "question_id": 593995, "best approach": "wiki", "verif answer": "time", "anno approach": "wiki, concept, image", "verif wiki answer": "roman numeral(0.6214)", "verif concept answer": "hour(0.5603)", "verif image answer": "time(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059399.jpg"}, {"question": "what browser is this laptop using", "gt answer": "chrome(1.00)", "pred answer": "window", "question_id": 89995, "best approach": "wiki, image", "verif answer": "chrome", "anno approach": "wiki, concept, image", "verif wiki answer": "chrome(0.6306)", "verif concept answer": "steel(0.5473)", "verif image answer": "chrome(0.7089)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008999.jpg"}, {"question": "what activity does the person in burgundy want to do", "gt answer": "fly kite(1.00)<br/>kite(0.60)", "pred answer": "ride", "question_id": 5090495, "best approach": "image", "verif answer": "kite fly", "anno approach": "wiki, concept, image", "verif wiki answer": "kite fly(0.6389)", "verif concept answer": "kite(0.6259)", "verif image answer": "fly kite(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509049.jpg"}, {"question": "what type of vehicle the officer is in", "gt answer": "segway(1.00)<br/>police(0.60)<br/>scooter(0.60)", "pred answer": "car", "question_id": 2481945, "best approach": "", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "car(0.6031)", "verif concept answer": "dean kamen(0.6332)", "verif image answer": "dean kamen(0.7211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248194.jpg"}, {"question": "what does the man with the frisbee 's back tattoo represent", "gt answer": "peace(1.00)", "pred answer": "gay", "question_id": 1660695, "best approach": "", "verif answer": "flag", "anno approach": "wiki, concept, image", "verif wiki answer": "equal right(0.6462)", "verif concept answer": "0(0.6630)", "verif image answer": "flag(0.6926)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166069.jpg"}, {"question": "what is the average diameter of the toy shown here", "gt answer": "10 inches(1.00)", "pred answer": "80 ft", "question_id": 5604815, "best approach": "wiki, concept", "verif answer": "8 inches", "anno approach": "wiki, concept, image", "verif wiki answer": "10 inches(0.6499)", "verif concept answer": "10 inches(0.5730)", "verif image answer": "8 inches(0.6952)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560481.jpg"}, {"question": "what style shirt is the man wearing", "gt answer": "t shirt(1.00)<br/>polo(0.60)", "pred answer": "button up", "question_id": 3479815, "best approach": "concept", "verif answer": "t shirt", "anno approach": "wiki, concept, image", "verif wiki answer": "polo(0.6945)", "verif concept answer": "t shirt(0.6868)", "verif image answer": "tee(0.6945)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347981.jpg"}, {"question": "a big shot at using the item depicted here might be called the big what", "gt answer": "kahuna(1.00)<br/>professional(0.60)<br/>cheese(0.60)", "pred answer": "aerial", "question_id": 672595, "best approach": "wiki, concept, image", "verif answer": "cheese", "anno approach": "wiki, concept, image", "verif wiki answer": "cheese(0.5789)", "verif concept answer": "cheese(0.6242)", "verif image answer": "cheese(0.6915)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067259.jpg"}, {"question": "how hot does this appliance become", "gt answer": "350 degrees(1.00)<br/>250(0.60)", "pred answer": "10 minutes", "question_id": 1290065, "best approach": "wiki, concept, image", "verif answer": "medium", "anno approach": "wiki, concept, image", "verif wiki answer": "350 degrees(0.5434)", "verif concept answer": "350 degrees(0.6088)", "verif image answer": "350 degrees(0.6901)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129006.jpg"}, {"question": "what kind of flower is this", "gt answer": "lilac(1.00)<br/>daisy(0.60)<br/>brocoli(0.60)", "pred answer": "tulip", "question_id": 404745, "best approach": "concept", "verif answer": "broccoli", "anno approach": "wiki, concept, image", "verif wiki answer": "broccoli(0.6190)", "verif concept answer": "lilac(0.7204)", "verif image answer": "brocoli(0.7023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040474.jpg"}, {"question": "were these shoes popular in the 1980 's or the present", "gt answer": "1980's(1.00)", "pred answer": "tour bus", "question_id": 908335, "best approach": "", "verif answer": "1980's", "anno approach": "wiki, concept, image", "verif wiki answer": "1990(0.5015)", "verif concept answer": "1990(0.5014)", "verif image answer": "70s(0.5013)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090833.jpg"}, {"question": "what are the types of lights shown called", "gt answer": "lamp(1.00)<br/>overhead(0.60)<br/>wall(0.60)", "pred answer": "spot light", "question_id": 3246825, "best approach": "wiki, image", "verif answer": "lamp", "anno approach": "wiki, concept, image", "verif wiki answer": "lamp(0.6538)", "verif concept answer": "overhead(0.5927)", "verif image answer": "lamp(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324682.jpg"}, {"question": "what kind of bird is this", "gt answer": "woodpecker(1.00)", "pred answer": "parrot", "question_id": 4298195, "best approach": "", "verif answer": "parrot", "anno approach": "wiki, concept, image", "verif wiki answer": "finch(0.6327)", "verif concept answer": "parrot(0.7213)", "verif image answer": "finch(0.6200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429819.jpg"}, {"question": "what is the woman in the gray sweatshirt pushing", "gt answer": "stroller(1.00)", "pred answer": "luggage", "question_id": 5679765, "best approach": "concept", "verif answer": "luggage", "anno approach": "wiki, concept, image", "verif wiki answer": "carriage(0.6985)", "verif concept answer": "stroller(0.6034)", "verif image answer": "carriage(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567976.jpg"}, {"question": "what type of meat is on top of the pizza", "gt answer": "bacon(1.00)<br/>ham(0.60)", "pred answer": "beef", "question_id": 3120175, "best approach": "image", "verif answer": "beef", "anno approach": "wiki, concept, image", "verif wiki answer": "beef(0.6171)", "verif concept answer": "cheese(0.6261)", "verif image answer": "bacon(0.7098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312017.jpg"}, {"question": "what is this dish called", "gt answer": "ramen(1.00)<br/>stir fry(0.60)", "pred answer": "salad", "question_id": 2073315, "best approach": "wiki, concept", "verif answer": "pasta", "anno approach": "wiki, concept, image", "verif wiki answer": "stir fry(0.6523)", "verif concept answer": "stir fry(0.6895)", "verif image answer": "pasta(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207331.jpg"}, {"question": "what type of food is this", "gt answer": "bread(1.00)<br/>banana bread(0.60)<br/>cake(0.60)<br/>meatloaf(0.60)", "pred answer": "pie", "question_id": 2550185, "best approach": "wiki, concept, image", "verif answer": "pie", "anno approach": "wiki, concept, image", "verif wiki answer": "meatloaf(0.6170)", "verif concept answer": "cake(0.6909)", "verif image answer": "banana bread(0.6342)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255018.jpg"}, {"question": "what kind of ramps are these called", "gt answer": "half pipe(1.00)<br/>pipe(0.60)<br/>skateboard(0.60)", "pred answer": "skate park", "question_id": 3593965, "best approach": "wiki", "verif answer": "pipe", "anno approach": "wiki, concept, image", "verif wiki answer": "half pipe(0.6549)", "verif concept answer": "skateboard(0.6816)", "verif image answer": "jump(0.6861)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359396.jpg"}, {"question": "what is the pizza topped with", "gt answer": "egg(1.00)", "pred answer": "cheese", "question_id": 4190525, "best approach": "image", "verif answer": "cheese", "anno approach": "wiki, concept, image", "verif wiki answer": "cheese(0.6936)", "verif concept answer": "cheese(0.6416)", "verif image answer": "egg(0.7200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419052.jpg"}, {"question": "what is it called when you consume too much of the fluid contained in these bottles", "gt answer": "intoxication(1.00)<br/>drunk(0.60)", "pred answer": "drink", "question_id": 545415, "best approach": "image", "verif answer": "drunk", "anno approach": "wiki, concept, image", "verif wiki answer": "calm(0.6693)", "verif concept answer": "calm(0.6846)", "verif image answer": "intoxication(0.7162)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054541.jpg"}, {"question": "when is this dish normally served", "gt answer": "after meal(1.00)<br/>dessert(0.60)<br/>desert(0.60)", "pred answer": "dinner", "question_id": 4818895, "best approach": "wiki, concept", "verif answer": "desert", "anno approach": "wiki, concept, image", "verif wiki answer": "after meal(0.6894)", "verif concept answer": "after meal(0.6165)", "verif image answer": "cake(0.6744)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481889.jpg"}, {"question": "what might be unsafe in this picture", "gt answer": "wire(1.00)<br/>electrical(0.60)", "pred answer": "computer", "question_id": 995395, "best approach": "image", "verif answer": "wire", "anno approach": "wiki, concept, image", "verif wiki answer": "power(0.5729)", "verif concept answer": "power(0.6563)", "verif image answer": "electrical(0.7225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099539.jpg"}, {"question": "why does the man have this backpack on", "gt answer": "hike(1.00)<br/>camp(0.60)", "pred answer": "vacation", "question_id": 3296615, "best approach": "wiki, concept, image", "verif answer": "run", "anno approach": "wiki, concept, image", "verif wiki answer": "hike(0.7155)", "verif concept answer": "hike(0.6624)", "verif image answer": "hike(0.6930)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329661.jpg"}, {"question": "are the motorcycles shown being used professionally or just for fun", "gt answer": "professionally(1.00)<br/>fun(0.60)<br/>professional(0.60)", "pred answer": "competition", "question_id": 4108985, "best approach": "wiki, concept, image", "verif answer": "fun", "anno approach": "wiki, concept, image", "verif wiki answer": "fun(0.6648)", "verif concept answer": "fun(0.6243)", "verif image answer": "fun(0.7225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000410898.jpg"}, {"question": "what is the white remote used for", "gt answer": "game(1.00)<br/>tv(0.60)<br/>video game(0.60)<br/>wii(0.60)", "pred answer": "music", "question_id": 4223435, "best approach": "wiki, concept, image", "verif answer": "tv", "anno approach": "wiki, concept, image", "verif wiki answer": "wii(0.6895)", "verif concept answer": "tv(0.6667)", "verif image answer": "tv(0.6867)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422343.jpg"}, {"question": "why is this unusual for an animal", "gt answer": "animal don't watch tv(1.00)", "pred answer": "siamese", "question_id": 5602425, "best approach": "", "verif answer": "dog", "anno approach": "wiki, concept, image", "verif wiki answer": "car(0.5592)", "verif concept answer": "car(0.6092)", "verif image answer": "car(0.6461)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560242.jpg"}, {"question": "what kind of playground this is", "gt answer": "bat cage(1.00)<br/>pitch(0.60)<br/>yard(0.60)", "pred answer": "baseball", "question_id": 915815, "best approach": "wiki", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "bat cage(0.6855)", "verif concept answer": "pitch(0.6392)", "verif image answer": "yard(0.7090)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000091581.jpg"}, {"question": "is this a recreational or work activity", "gt answer": "recreational(1.00)<br/>surf(0.60)", "pred answer": "fun", "question_id": 3791055, "best approach": "concept, image", "verif answer": "recreational", "anno approach": "wiki, concept, image", "verif wiki answer": "commercial(0.5820)", "verif concept answer": "recreational(0.5487)", "verif image answer": "recreational(0.6954)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379105.jpg"}, {"question": "what kind off bag is it", "gt answer": "purse(1.00)", "pred answer": "backpack", "question_id": 3159945, "best approach": "", "verif answer": "backpack", "anno approach": "wiki, concept, image", "verif wiki answer": "backpack(0.6932)", "verif concept answer": "backpack(0.6905)", "verif image answer": "backpack(0.6738)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315994.jpg"}, {"question": "what kind of television is this", "gt answer": "flat screen(1.00)<br/>flatscreen(1.00)", "pred answer": "led", "question_id": 3957585, "best approach": "wiki, image", "verif answer": "flat screen", "anno approach": "wiki, concept, image", "verif wiki answer": "flat screen(0.6759)", "verif concept answer": "led(0.6496)", "verif image answer": "flat screen(0.7105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395758.jpg"}, {"question": "what iconic badass women trio recreated this in a movie", "gt answer": "blue crush(1.00)", "pred answer": "mary poppins", "question_id": 1649515, "best approach": "", "verif answer": "santa", "anno approach": "wiki, concept, image", "verif wiki answer": "theodore roosevelt(0.6411)", "verif concept answer": "theodore roosevelt(0.5457)", "verif image answer": "santa(0.6498)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000164951.jpg"}, {"question": "who is the largest manufacturer of this piece of sports equipment", "gt answer": "wham o(1.00)<br/>rawlings(0.60)<br/>frisbee(0.60)<br/>wilson(0.60)", "pred answer": "america", "question_id": 4600975, "best approach": "wiki, concept, image", "verif answer": "frisbee", "anno approach": "wiki, concept, image", "verif wiki answer": "frisbee(0.6031)", "verif concept answer": "frisbee(0.5968)", "verif image answer": "frisbee(0.6261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460097.jpg"}, {"question": "which city in europe has the most of these", "gt answer": "copenhagen(1.00)<br/>france(0.60)<br/>venice(0.60)<br/>paris(0.60)", "pred answer": "new york", "question_id": 5206795, "best approach": "wiki, image", "verif answer": "paris", "anno approach": "wiki, concept, image", "verif wiki answer": "copenhagen(0.7045)", "verif concept answer": "paris(0.7074)", "verif image answer": "copenhagen(0.7055)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520679.jpg"}, {"question": "what ethnicty is the man", "gt answer": "indian(1.00)<br/>asian(0.60)<br/>black(0.60)<br/>spanish(0.60)", "pred answer": "caucasian", "question_id": 5414915, "best approach": "wiki, image", "verif answer": "indian", "anno approach": "wiki, concept, image", "verif wiki answer": "indian(0.6975)", "verif concept answer": "african(0.7064)", "verif image answer": "indian(0.7055)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541491.jpg"}, {"question": "what can i put here", "gt answer": "pizza(1.00)<br/>food(0.60)<br/>stove(0.60)", "pred answer": "cloth", "question_id": 1858665, "best approach": "image", "verif answer": "stove", "anno approach": "wiki, concept, image", "verif wiki answer": "food(0.6786)", "verif concept answer": "food(0.6523)", "verif image answer": "pizza(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185866.jpg"}, {"question": "what do these animals eat", "gt answer": "dog food(1.00)<br/>kibble(0.60)<br/>meat(0.60)", "pred answer": "cat food", "question_id": 5328575, "best approach": "wiki, concept, image", "verif answer": "dog food", "anno approach": "wiki, concept, image", "verif wiki answer": "dog food(0.7284)", "verif concept answer": "dog food(0.7222)", "verif image answer": "dog food(0.7140)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532857.jpg"}, {"question": "these sea faring vehicles are often christened by bottles of what vintage", "gt answer": "champagne(1.00)<br/>wine(0.60)", "pred answer": "boat", "question_id": 2984685, "best approach": "image", "verif answer": "wine", "anno approach": "wiki, concept, image", "verif wiki answer": "intoxication(0.5279)", "verif concept answer": "intoxication(0.5455)", "verif image answer": "champagne(0.5748)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000298468.jpg"}, {"question": "what body of water is this", "gt answer": "atlantic(1.00)<br/>ocean(1.00)<br/>pacific ocean(0.60)", "pred answer": "lake", "question_id": 3202175, "best approach": "wiki, concept", "verif answer": "atlantic", "anno approach": "wiki, concept, image", "verif wiki answer": "atlantic(0.6311)", "verif concept answer": "atlantic(0.6707)", "verif image answer": "river(0.7102)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320217.jpg"}, {"question": "", "gt answer": "braid(0.60)", "pred answer": "mane", "question_id": 1088025, "best approach": "", "verif answer": "pigtail", "anno approach": "wiki, concept, image", "verif wiki answer": "pony tail(0.5444)", "verif concept answer": "pony tail(0.6110)", "verif image answer": "pony tail(0.5278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108802.jpg"}, {"question": "what is the main vitamin is broccoli", "gt answer": "c(1.00)<br/>vitamin c(0.60)<br/>potassium(0.60)", "pred answer": "vitamin", "question_id": 5694365, "best approach": "wiki, image", "verif answer": "d", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin c(0.6774)", "verif concept answer": "d(0.6774)", "verif image answer": "potassium(0.7088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569436.jpg"}, {"question": "is this a gift you can send or is it too fragile", "gt answer": "fragile(1.00)", "pred answer": "inedible", "question_id": 1859545, "best approach": "wiki, concept", "verif answer": "annual", "anno approach": "wiki, concept, image", "verif wiki answer": "fragile(0.6464)", "verif concept answer": "fragile(0.5959)", "verif image answer": "very(0.6799)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185954.jpg"}, {"question": "what is the metal structure everyone is sitting behind called", "gt answer": "fence(1.00)", "pred answer": "bleacher", "question_id": 483405, "best approach": "wiki", "verif answer": "fence", "anno approach": "wiki, concept, image", "verif wiki answer": "fence(0.5770)", "verif concept answer": "step(0.5835)", "verif image answer": "hurdle(0.7237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048340.jpg"}, {"question": "where could i find this", "gt answer": "jungle(1.00)<br/>south america(0.60)<br/>brazil(0.60)", "pred answer": "garden", "question_id": 339405, "best approach": "wiki", "verif answer": "garden", "anno approach": "wiki, concept, image", "verif wiki answer": "jungle(0.7201)", "verif concept answer": "africa(0.7150)", "verif image answer": "brazil(0.6676)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033940.jpg"}, {"question": "which food group is this age group constantly being encouraged to eat from", "gt answer": "vegetable(1.00)", "pred answer": "toddler", "question_id": 517355, "best approach": "", "verif answer": "fruit", "anno approach": "wiki, concept, image", "verif wiki answer": "meat(0.5665)", "verif concept answer": "hot dog(0.6064)", "verif image answer": "veggies(0.7225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000051735.jpg"}, {"question": "what language is pictured on the right vases", "gt answer": "chinese(1.00)<br/>arabic(1.00)", "pred answer": "english", "question_id": 605265, "best approach": "wiki, concept, image", "verif answer": "chinese", "anno approach": "wiki, concept, image", "verif wiki answer": "chinese(0.6801)", "verif concept answer": "chinese(0.7074)", "verif image answer": "chinese(0.7195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060526.jpg"}, {"question": "what is the name of the eye condition this cat has", "gt answer": "heterochromia(1.00)", "pred answer": "bad", "question_id": 5802345, "best approach": "wiki", "verif answer": "bad", "anno approach": "wiki, concept, image", "verif wiki answer": "heterochromia(0.5881)", "verif concept answer": "meow(0.5350)", "verif image answer": "meow(0.5156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580234.jpg"}, {"question": "what platform is this sport being played on", "gt answer": "street(1.00)<br/>road(0.60)<br/>pavement(0.60)", "pred answer": "baseball", "question_id": 4755765, "best approach": "wiki, concept", "verif answer": "pavement", "anno approach": "wiki, concept, image", "verif wiki answer": "pavement(0.5301)", "verif concept answer": "pavement(0.6096)", "verif image answer": "street sign(0.6722)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475576.jpg"}, {"question": "who invented this device", "gt answer": "frederick graff sr(1.00)<br/>frederick graff(0.60)<br/>fireman(0.60)", "pred answer": "plumber", "question_id": 4436935, "best approach": "concept", "verif answer": "artist", "anno approach": "wiki, concept, image", "verif wiki answer": "artist(0.6645)", "verif concept answer": "frederick graff sr(0.6505)", "verif image answer": "firefighter(0.7064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443693.jpg"}, {"question": "", "gt answer": "vandalism(0.60)<br/>graffiti(0.60)", "pred answer": "stop", "question_id": 42455, "best approach": "", "verif answer": "graffiti", "anno approach": "wiki, concept, image", "verif wiki answer": "grafitti(0.5344)", "verif concept answer": "caution(0.5253)", "verif image answer": "grafitti(0.5531)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004245.jpg"}, {"question": "where is the monument located", "gt answer": "washington dc(1.00)<br/>dc(0.60)", "pred answer": "europe", "question_id": 5349655, "best approach": "wiki", "verif answer": "washington", "anno approach": "wiki, concept, image", "verif wiki answer": "washington dc(0.6940)", "verif concept answer": "washington(0.6951)", "verif image answer": "rome(0.7002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534965.jpg"}, {"question": "what is the wooden object with the words written on it", "gt answer": "sign(1.00)<br/>plaque(0.60)<br/>desk(0.60)<br/>crib(0.60)", "pred answer": "picture", "question_id": 5164635, "best approach": "wiki", "verif answer": "wood", "anno approach": "wiki, concept, image", "verif wiki answer": "sign(0.5445)", "verif concept answer": "plaque(0.5725)", "verif image answer": "wood(0.7169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516463.jpg"}, {"question": "what would be a good call for this play in baseball", "gt answer": "strike(1.00)<br/>play(0.60)<br/>safe(0.60)", "pred answer": "foul", "question_id": 5660885, "best approach": "wiki", "verif answer": "out", "anno approach": "wiki, concept, image", "verif wiki answer": "strike(0.7152)", "verif concept answer": "hit(0.6593)", "verif image answer": "hit(0.6737)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566088.jpg"}, {"question": "is this an example of work or distraction", "gt answer": "distraction(1.00)", "pred answer": "work", "question_id": 5487235, "best approach": "", "verif answer": "vacation", "anno approach": "wiki, concept, image", "verif wiki answer": "vacation(0.6515)", "verif concept answer": "vacation(0.5407)", "verif image answer": "danger(0.6477)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548723.jpg"}, {"question": "penalty for what", "gt answer": "honk(1.00)<br/>noise(0.60)", "pred answer": "street name", "question_id": 3226705, "best approach": "concept", "verif answer": "money", "anno approach": "wiki, concept, image", "verif wiki answer": "money(0.6703)", "verif concept answer": "noise(0.6323)", "verif image answer": "money(0.6975)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322670.jpg"}, {"question": "what is used to eat the food in the bowl", "gt answer": "spoon(1.00)", "pred answer": "chopstick", "question_id": 4475745, "best approach": "wiki, concept", "verif answer": "fork", "anno approach": "wiki, concept, image", "verif wiki answer": "spoon(0.6436)", "verif concept answer": "spoon(0.6438)", "verif image answer": "fork(0.7202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447574.jpg"}, {"question": "what kind of dessert is this", "gt answer": "pud(1.00)<br/>banana(0.60)", "pred answer": "chocolate", "question_id": 2224445, "best approach": "image", "verif answer": "banana bread", "anno approach": "wiki, concept, image", "verif wiki answer": "toast(0.6265)", "verif concept answer": "stew(0.6986)", "verif image answer": "pud(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222444.jpg"}, {"question": "what is the name of show in which these antique vehicles are participating", "gt answer": "car show(1.00)<br/>rv(0.60)", "pred answer": "camp", "question_id": 5715415, "best approach": "", "verif answer": "bus", "anno approach": "wiki, concept, image", "verif wiki answer": "bus(0.6852)", "verif concept answer": "bus(0.6475)", "verif image answer": "car(0.6471)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571541.jpg"}, {"question": "what species of animal is this", "gt answer": "egret(1.00)<br/>pelican(0.60)<br/>bird(0.60)", "pred answer": "stork", "question_id": 4178235, "best approach": "wiki, concept, image", "verif answer": "bird", "anno approach": "wiki, concept, image", "verif wiki answer": "bird(0.6821)", "verif concept answer": "bird(0.6917)", "verif image answer": "pelican(0.6814)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417823.jpg"}, {"question": "which hairstyle is this women doing", "gt answer": "blowout(1.00)<br/>bang(0.60)<br/>messy(0.60)", "pred answer": "bun", "question_id": 2080005, "best approach": "concept", "verif answer": "messy", "anno approach": "wiki, concept, image", "verif wiki answer": "bob(0.6240)", "verif concept answer": "bang(0.6785)", "verif image answer": "man(0.7073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208000.jpg"}, {"question": "art or vandalism", "gt answer": "vandalism(1.00)", "pred answer": "graffiti", "question_id": 663515, "best approach": "", "verif answer": "graffiti", "anno approach": "wiki, concept, image", "verif wiki answer": "crash(0.5102)", "verif concept answer": "graffiti(0.5580)", "verif image answer": "crash(0.6211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000066351.jpg"}, {"question": "what is the full name of this store", "gt answer": "super fish(1.00)", "pred answer": "7 eleven", "question_id": 2730885, "best approach": "wiki", "verif answer": "heinz", "anno approach": "wiki, concept, image", "verif wiki answer": "super fish(0.5274)", "verif concept answer": "heinz(0.6071)", "verif image answer": "3(0.6262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273088.jpg"}, {"question": "where could you sit", "gt answer": "chair(1.00)", "pred answer": "bench", "question_id": 3190575, "best approach": "", "verif answer": "chair", "anno approach": "wiki, concept, image", "verif wiki answer": "sofa(0.6809)", "verif concept answer": "luggage(0.6295)", "verif image answer": "sofa(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319057.jpg"}, {"question": "what is the name of those flowers", "gt answer": "carnation(1.00)<br/>rose(0.60)", "pred answer": "orchid", "question_id": 2897665, "best approach": "image", "verif answer": "daisy", "anno approach": "wiki, concept, image", "verif wiki answer": "daisy(0.6399)", "verif concept answer": "tulip(0.7141)", "verif image answer": "rose(0.7192)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000289766.jpg"}, {"question": "what grocery store is this", "gt answer": "whole food(1.00)<br/>walmart(0.60)", "pred answer": "grocery", "question_id": 3228475, "best approach": "", "verif answer": "store", "anno approach": "wiki, concept, image", "verif wiki answer": "store(0.7141)", "verif concept answer": "store(0.6282)", "verif image answer": "store(0.6968)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322847.jpg"}, {"question": "what is this road most likely used for", "gt answer": "bike(1.00)<br/>walk(0.60)<br/>cycling(0.60)", "pred answer": "ride", "question_id": 2474935, "best approach": "wiki", "verif answer": "ride", "anno approach": "wiki, concept, image", "verif wiki answer": "bike(0.6517)", "verif concept answer": "bicycle(0.6397)", "verif image answer": "walk(0.6607)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247493.jpg"}, {"question": "what kind of soup is this", "gt answer": "vegetable(1.00)", "pred answer": "italian", "question_id": 2445285, "best approach": "", "verif answer": "vegetable", "anno approach": "wiki, concept, image", "verif wiki answer": "carrot and cauliflower(0.6389)", "verif concept answer": "fruit(0.5633)", "verif image answer": "carrot(0.5730)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244528.jpg"}, {"question": "is this meal healthy or unhealthy", "gt answer": "unhealthy(1.00)", "pred answer": "healthy", "question_id": 4539075, "best approach": "concept, image", "verif answer": "healthy", "anno approach": "wiki, concept, image", "verif wiki answer": "very healthy(0.6890)", "verif concept answer": "unhealthy(0.7037)", "verif image answer": "unhealthy(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453907.jpg"}, {"question": "why are all these planes in a line", "gt answer": "airshow(1.00)", "pred answer": "parked", "question_id": 720305, "best approach": "", "verif answer": "air show", "anno approach": "wiki, concept, image", "verif wiki answer": "military(0.6613)", "verif concept answer": "fighter jet(0.6697)", "verif image answer": "show(0.6125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072030.jpg"}, {"question": "how much will this animal weigh when fully grown", "gt answer": "50 lbs(1.00)", "pred answer": "10 pounds", "question_id": 2231145, "best approach": "", "verif answer": "lot", "anno approach": "wiki, concept, image", "verif wiki answer": "$350(0.6153)", "verif concept answer": "lot(0.6038)", "verif image answer": "1 pound(0.7038)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223114.jpg"}, {"question": "to whom is the tennis player depicted in the photo married to", "gt answer": "alexis ohanian(1.00)<br/>bieber(0.60)", "pred answer": "opponent", "question_id": 1885185, "best approach": "concept", "verif answer": "williams", "anno approach": "wiki, concept, image", "verif wiki answer": "williams(0.6923)", "verif concept answer": "alexis ohanian(0.6367)", "verif image answer": "bieber(0.5563)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188518.jpg"}, {"question": "what is a common condition that affects a person after they eat too much of this", "gt answer": "indigestion(1.00)", "pred answer": "eye", "question_id": 345235, "best approach": "", "verif answer": "eye", "anno approach": "wiki, concept, image", "verif wiki answer": "skin(0.6401)", "verif concept answer": "eye(0.6682)", "verif image answer": "chicago(0.7086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000034523.jpg"}, {"question": "what kind of bears are these", "gt answer": "grizzly(1.00)", "pred answer": "brown", "question_id": 1836115, "best approach": "", "verif answer": "brown", "anno approach": "wiki, concept, image", "verif wiki answer": "brown(0.6938)", "verif concept answer": "brown(0.6987)", "verif image answer": "brown(0.6507)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183611.jpg"}, {"question": "what item handle does the an appear to have resting next to him", "gt answer": "luggage(1.00)<br/>crutch(1.00)<br/>suitcase(0.60)", "pred answer": "fan", "question_id": 899025, "best approach": "wiki, concept", "verif answer": "luggage", "anno approach": "wiki, concept, image", "verif wiki answer": "luggage(0.5678)", "verif concept answer": "luggage(0.6440)", "verif image answer": "suitcase(0.6918)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089902.jpg"}, {"question": "what denomination is the church", "gt answer": "christian(1.00)<br/>catholic(1.00)", "pred answer": "everest", "question_id": 3933965, "best approach": "concept", "verif answer": "church", "anno approach": "wiki, concept, image", "verif wiki answer": "church(0.6933)", "verif concept answer": "catholic(0.7145)", "verif image answer": "christianity(0.6533)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393396.jpg"}, {"question": "what object does not belong in this room", "gt answer": "chair(1.00)", "pred answer": "toilet", "question_id": 3158955, "best approach": "wiki", "verif answer": "chair", "anno approach": "wiki, concept, image", "verif wiki answer": "chair(0.6703)", "verif concept answer": "sofa(0.6439)", "verif image answer": "luggage(0.7214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315895.jpg"}, {"question": "what is the diameter of the toy in this picture", "gt answer": "12 inches(1.00)<br/>8 inches(0.60)<br/>6(0.60)", "pred answer": "4 feet", "question_id": 4653605, "best approach": "image", "verif answer": "8 inches", "anno approach": "wiki, concept, image", "verif wiki answer": "1 foot(0.6236)", "verif concept answer": "1 foot(0.5828)", "verif image answer": "6(0.6981)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465360.jpg"}, {"question": "what city is wmata in", "gt answer": "washington(1.00)<br/>washington dc(0.60)", "pred answer": "philadelphia", "question_id": 2621915, "best approach": "concept, image", "verif answer": "philadelphia", "anno approach": "wiki, concept, image", "verif wiki answer": "rome(0.6286)", "verif concept answer": "washington(0.7087)", "verif image answer": "washington(0.6633)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262191.jpg"}, {"question": "why is one animal smaller", "gt answer": "baby(1.00)<br/>child(0.60)", "pred answer": "calf", "question_id": 4997385, "best approach": "wiki, concept, image", "verif answer": "elephant", "anno approach": "wiki, concept, image", "verif wiki answer": "baby(0.6993)", "verif concept answer": "baby(0.6254)", "verif image answer": "baby(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499738.jpg"}, {"question": "what brand is this snowboard", "gt answer": "nitro(1.00)", "pred answer": "burton", "question_id": 2086215, "best approach": "image", "verif answer": "burton", "anno approach": "wiki, concept, image", "verif wiki answer": "burton(0.6993)", "verif concept answer": "manmade(0.6473)", "verif image answer": "nitro(0.6146)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208621.jpg"}, {"question": "what holiday do those candles represent", "gt answer": "hanukkah(1.00)<br/>christmas(0.60)", "pred answer": "valentine", "question_id": 2550455, "best approach": "", "verif answer": "christmas", "anno approach": "wiki, concept, image", "verif wiki answer": "st patrick's day(0.6238)", "verif concept answer": "disney(0.6450)", "verif image answer": "st patrick's day(0.7099)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255045.jpg"}, {"question": "for what events where these trophies given", "gt answer": "golf(1.00)<br/>sport(0.60)", "pred answer": "movie", "question_id": 3259035, "best approach": "", "verif answer": "party", "anno approach": "wiki, concept, image", "verif wiki answer": "party(0.5343)", "verif concept answer": "wii(0.6166)", "verif image answer": "party(0.6824)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325903.jpg"}, {"question": "what is the woman using to cut the cake", "gt answer": "sword(1.00)", "pred answer": "knife", "question_id": 4886825, "best approach": "", "verif answer": "scissor", "anno approach": "wiki, concept, image", "verif wiki answer": "clip(0.5375)", "verif concept answer": "scissor(0.5794)", "verif image answer": "scissor(0.6390)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488682.jpg"}, {"question": "what type of beverage are lemons popular igredient in", "gt answer": "lemonade(1.00)", "pred answer": "juice", "question_id": 4121945, "best approach": "", "verif answer": "orange juice", "anno approach": "wiki, concept, image", "verif wiki answer": "alcohol(0.6536)", "verif concept answer": "orange(0.6628)", "verif image answer": "alcohol(0.6853)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412194.jpg"}, {"question": "how long does this type of animal live when it 's real", "gt answer": "20 years(1.00)<br/>12 years(0.60)", "pred answer": "30 years", "question_id": 462555, "best approach": "image", "verif answer": "20 years", "anno approach": "wiki, concept, image", "verif wiki answer": "12 years(0.6011)", "verif concept answer": "12 years(0.5703)", "verif image answer": "20 years(0.6902)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046255.jpg"}, {"question": "how is this dish cooked", "gt answer": "toasted(1.00)<br/>fried(0.60)", "pred answer": "grilled", "question_id": 4454115, "best approach": "wiki, concept", "verif answer": "fried", "anno approach": "wiki, concept, image", "verif wiki answer": "toasted(0.6524)", "verif concept answer": "toasted(0.6525)", "verif image answer": "bread(0.7013)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445411.jpg"}, {"question": "what is the yellow stuff on top of this hotdog", "gt answer": "mustard(1.00)<br/>cheese(0.60)", "pred answer": "ketchup", "question_id": 4480695, "best approach": "image", "verif answer": "mustard", "anno approach": "wiki, concept, image", "verif wiki answer": "cheese(0.5686)", "verif concept answer": "cheese(0.5309)", "verif image answer": "mustard(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448069.jpg"}, {"question": "what are these people working on", "gt answer": "laptop(1.00)<br/>work(0.60)<br/>homework(0.60)", "pred answer": "computer", "question_id": 2595145, "best approach": "wiki, concept", "verif answer": "laptop", "anno approach": "wiki, concept, image", "verif wiki answer": "laptop(0.6363)", "verif concept answer": "laptop(0.5748)", "verif image answer": "homework(0.6521)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259514.jpg"}, {"question": "what are the toys made from", "gt answer": "plastic(1.00)", "pred answer": "rubber", "question_id": 549765, "best approach": "image", "verif answer": "plastic", "anno approach": "wiki, concept, image", "verif wiki answer": "paper(0.6905)", "verif concept answer": "paper(0.6986)", "verif image answer": "plastic(0.7208)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054976.jpg"}, {"question": "what sport is this in the united states", "gt answer": "soccer(1.00)", "pred answer": "football", "question_id": 477295, "best approach": "", "verif answer": "football", "anno approach": "wiki, concept, image", "verif wiki answer": "soccer ball(0.6318)", "verif concept answer": "soccer ball(0.7120)", "verif image answer": "play soccer(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047729.jpg"}, {"question": "what is the fastest one on earth", "gt answer": "bullet(1.00)<br/>amtrak(0.60)", "pred answer": "bullet train", "question_id": 2518605, "best approach": "", "verif answer": "bullet train", "anno approach": "wiki, concept, image", "verif wiki answer": "bullet train(0.6702)", "verif concept answer": "bullet train(0.5966)", "verif image answer": "driver(0.6934)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251860.jpg"}, {"question": "what was used to stain the boys' shirts", "gt answer": "fake blood(1.00)<br/>dye(0.60)<br/>food color(0.60)<br/>ketchup(0.60)", "pred answer": "frost", "question_id": 1070725, "best approach": "concept", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "paint(0.6849)", "verif concept answer": "fake blood(0.6467)", "verif image answer": "paint(0.6793)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000107072.jpg"}, {"question": "what is the man made of", "gt answer": "cast iron(1.00)<br/>iron(0.60)<br/>bronze(0.60)<br/>metal(0.60)", "pred answer": "brick", "question_id": 463735, "best approach": "wiki, concept, image", "verif answer": "iron", "anno approach": "wiki, concept, image", "verif wiki answer": "bronze(0.6509)", "verif concept answer": "bronze(0.6324)", "verif image answer": "bronze(0.7166)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046373.jpg"}, {"question": "what is this object used for", "gt answer": "fight fire(1.00)<br/>firefight(1.00)", "pred answer": "fire hydrant", "question_id": 3110315, "best approach": "", "verif answer": "fire hydrant", "anno approach": "wiki, concept, image", "verif wiki answer": "fire hydrant(0.6534)", "verif concept answer": "fire hydrant(0.6731)", "verif image answer": "fire(0.6757)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311031.jpg"}, {"question": "how fast can this machine go", "gt answer": "slow(1.00)<br/>30mph(0.60)<br/>25(0.60)<br/>25 mph(0.60)", "pred answer": "100 mph", "question_id": 2715925, "best approach": "wiki", "verif answer": "slow", "anno approach": "wiki, concept, image", "verif wiki answer": "slow(0.5650)", "verif concept answer": "very high(0.6157)", "verif image answer": "30mph(0.6843)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000271592.jpg"}, {"question": "what is in the drink on the table", "gt answer": "lemon(1.00)<br/>coke(0.60)<br/>tea(0.60)", "pred answer": "spinach", "question_id": 3402675, "best approach": "", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "coffee(0.6448)", "verif concept answer": "coffee(0.6016)", "verif image answer": "coffee(0.7103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340267.jpg"}, {"question": "what do you do to that item before putting it in your pocket", "gt answer": "close(1.00)<br/>talk(0.60)", "pred answer": "hold", "question_id": 2530655, "best approach": "image", "verif answer": "call", "anno approach": "wiki, concept, image", "verif wiki answer": "take picture(0.6791)", "verif concept answer": "take picture(0.6484)", "verif image answer": "talk(0.6442)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253065.jpg"}, {"question": "on average how old does this breed of cat live to be", "gt answer": "12 years(1.00)<br/>15 years(0.60)<br/>15(0.60)", "pred answer": "20 years", "question_id": 5646555, "best approach": "concept", "verif answer": "20 years", "anno approach": "wiki, concept, image", "verif wiki answer": "20 years(0.6650)", "verif concept answer": "12 years(0.6798)", "verif image answer": "20 years(0.6162)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564655.jpg"}, {"question": "how old are the two children in this photo", "gt answer": "10(1.00)", "pred answer": "21", "question_id": 3078845, "best approach": "", "verif answer": "12", "anno approach": "wiki, concept, image", "verif wiki answer": "9(0.6947)", "verif concept answer": "9(0.6710)", "verif image answer": "12(0.6726)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307884.jpg"}, {"question": "what type of day is this", "gt answer": "sunny(1.00)<br/>clear(0.60)<br/>cloudy(0.60)", "pred answer": "windy", "question_id": 3661355, "best approach": "wiki, concept, image", "verif answer": "sunny", "anno approach": "wiki, concept, image", "verif wiki answer": "sunny(0.6450)", "verif concept answer": "sunny(0.6411)", "verif image answer": "sunny(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366135.jpg"}, {"question": "what is the blue item called", "gt answer": "bus stop(1.00)", "pred answer": "park", "question_id": 5602545, "best approach": "", "verif answer": "stop", "anno approach": "wiki, concept, image", "verif wiki answer": "stop(0.5513)", "verif concept answer": "stop(0.5516)", "verif image answer": "mcdonalds(0.5876)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560254.jpg"}, {"question": "what appliance the device shown control", "gt answer": "tv(1.00)<br/>television(0.60)", "pred answer": "xbox", "question_id": 3581585, "best approach": "image", "verif answer": "television", "anno approach": "wiki, concept, image", "verif wiki answer": "screen(0.6983)", "verif concept answer": "fireplace(0.5468)", "verif image answer": "tv(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358158.jpg"}, {"question": "what safety equipment should the sup user be wearing", "gt answer": "life jacket(1.00)", "pred answer": "wetsuit", "question_id": 1135985, "best approach": "", "verif answer": "wet suit", "anno approach": "wiki, concept, image", "verif wiki answer": "wet suit(0.7269)", "verif concept answer": "wet suit(0.6506)", "verif image answer": "bikini(0.5323)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113598.jpg"}, {"question": "what needed repair in this room", "gt answer": "toilet(1.00)", "pred answer": "wash hand", "question_id": 595155, "best approach": "", "verif answer": "toilet", "anno approach": "wiki, concept, image", "verif wiki answer": "plastic(0.5719)", "verif concept answer": "toilet seat(0.7078)", "verif image answer": "toilet seat(0.7110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059515.jpg"}, {"question": "who is considered the best man at this sport", "gt answer": "roger federer(1.00)", "pred answer": "rafael nadal", "question_id": 4833045, "best approach": "wiki, concept, image", "verif answer": "roger federer", "anno approach": "wiki, concept, image", "verif wiki answer": "roger federer(0.7186)", "verif concept answer": "roger federer(0.6518)", "verif image answer": "roger federer(0.6832)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483304.jpg"}, {"question": "what type of oil was used to paint this picture", "gt answer": "linseed(1.00)<br/>grease(0.60)", "pred answer": "oil", "question_id": 393155, "best approach": "concept", "verif answer": "glaze", "anno approach": "wiki, concept, image", "verif wiki answer": "bad(0.5793)", "verif concept answer": "linseed(0.6272)", "verif image answer": "glaze(0.5587)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039315.jpg"}, {"question": "how many inches is this tv display", "gt answer": "32(1.00)<br/>40(0.60)<br/>50(0.60)", "pred answer": "3", "question_id": 4299185, "best approach": "wiki, concept, image", "verif answer": "20", "anno approach": "wiki, concept, image", "verif wiki answer": "50(0.6643)", "verif concept answer": "50(0.5951)", "verif image answer": "40(0.6662)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429918.jpg"}, {"question": "how many points does it take to win in badminton", "gt answer": "21(1.00)<br/>12(0.60)<br/>20(0.60)<br/>5(0.60)", "pred answer": "40", "question_id": 1092085, "best approach": "image", "verif answer": "21", "anno approach": "wiki, concept, image", "verif wiki answer": "12(0.6811)", "verif concept answer": "12(0.6478)", "verif image answer": "21(0.7017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000109208.jpg"}, {"question": "is the bird migrating or native", "gt answer": "native(1.00)<br/>(0.60)", "pred answer": "robin", "question_id": 1642875, "best approach": "", "verif answer": "wild", "anno approach": "wiki, concept, image", "verif wiki answer": "wild(0.7196)", "verif concept answer": "wild(0.7288)", "verif image answer": "wild(0.7217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000164287.jpg"}, {"question": "why is one person lying down", "gt answer": "tired(1.00)<br/>sleep(1.00)", "pred answer": "sick", "question_id": 2310195, "best approach": "concept, image", "verif answer": "sick", "anno approach": "wiki, concept, image", "verif wiki answer": "sick(0.6817)", "verif concept answer": "sleep(0.6301)", "verif image answer": "sleep(0.6113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231019.jpg"}, {"question": "what is the name of the national organization that oversees this sport", "gt answer": "major league baseball(1.00)<br/>mlb(0.60)", "pred answer": "baseball", "question_id": 1366415, "best approach": "", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "world series(0.6700)", "verif concept answer": "world series(0.7244)", "verif image answer": "world series(0.7134)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136641.jpg"}, {"question": "what type of bread is this", "gt answer": "banana bread(1.00)<br/>wheat(0.60)<br/>banana(0.60)<br/>whole grain(0.60)", "pred answer": "sourdough", "question_id": 5428175, "best approach": "wiki, concept, image", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "wheat(0.6106)", "verif concept answer": "wheat(0.6110)", "verif image answer": "wheat(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542817.jpg"}, {"question": "name the bird", "gt answer": "wren(1.00)<br/>finch(0.60)", "pred answer": "robin", "question_id": 1685745, "best approach": "", "verif answer": "robin", "anno approach": "wiki, concept, image", "verif wiki answer": "robin(0.6353)", "verif concept answer": "robin(0.6971)", "verif image answer": "sparrow(0.6776)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168574.jpg"}, {"question": "when was this sport invented", "gt answer": "1839(1.00)<br/>1885(0.60)<br/>1800's(0.60)<br/>1880(0.60)", "pred answer": "1948", "question_id": 2209895, "best approach": "wiki, concept, image", "verif answer": "1880", "anno approach": "wiki, concept, image", "verif wiki answer": "1839(0.7144)", "verif concept answer": "1839(0.6914)", "verif image answer": "1839(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220989.jpg"}, {"question": "are these trains in operation right now or are they shut down for the night", "gt answer": "shut down(1.00)<br/>in operation(0.60)", "pred answer": "brake", "question_id": 1367365, "best approach": "wiki, concept", "verif answer": "in operation", "anno approach": "wiki, concept, image", "verif wiki answer": "shut down(0.5287)", "verif concept answer": "shut down(0.5988)", "verif image answer": "1977(0.6416)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136736.jpg"}, {"question": "what type of food is this", "gt answer": "sushi(1.00)<br/>japanese(0.60)<br/>asian(0.60)<br/>meat(0.60)", "pred answer": "breakfast", "question_id": 505565, "best approach": "wiki, concept, image", "verif answer": "japanese", "anno approach": "wiki, concept, image", "verif wiki answer": "sushi(0.6616)", "verif concept answer": "sushi(0.7112)", "verif image answer": "sushi(0.7048)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050556.jpg"}, {"question": "what does the yellow color of these fruit mean", "gt answer": "ripe(1.00)<br/>good(0.60)", "pred answer": "banana", "question_id": 1979625, "best approach": "wiki", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "good(0.5809)", "verif concept answer": "over ripe(0.6530)", "verif image answer": "over ripe(0.6849)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197962.jpg"}, {"question": "who owns the horses", "gt answer": "farmer(1.00)<br/>rancher(0.60)", "pred answer": "jockey", "question_id": 2476415, "best approach": "concept, image", "verif answer": "farmer", "anno approach": "wiki, concept, image", "verif wiki answer": "public(0.6627)", "verif concept answer": "farmer(0.5910)", "verif image answer": "farmer(0.6779)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247641.jpg"}, {"question": "is the orange motorcycle used for sport or long distance travel", "gt answer": "long distance(1.00)<br/>sport(1.00)", "pred answer": "transportation", "question_id": 3905655, "best approach": "concept", "verif answer": "race", "anno approach": "wiki, concept, image", "verif wiki answer": "race(0.5833)", "verif concept answer": "long distance(0.5698)", "verif image answer": "race(0.6181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390565.jpg"}, {"question": "what are the lines on the potato chips called", "gt answer": "ridge(1.00)<br/>ruffle(0.60)", "pred answer": "mustard", "question_id": 4175405, "best approach": "", "verif answer": "ruffle", "anno approach": "wiki, concept, image", "verif wiki answer": "cracker(0.6295)", "verif concept answer": "cracker(0.5763)", "verif image answer": "foot(0.5938)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417540.jpg"}, {"question": "what is the name of the music player", "gt answer": "record player(1.00)", "pred answer": "guitar", "question_id": 4285355, "best approach": "wiki, concept, image", "verif answer": "samsung", "anno approach": "wiki, concept, image", "verif wiki answer": "record player(0.7084)", "verif concept answer": "record player(0.6376)", "verif image answer": "record player(0.5612)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428535.jpg"}, {"question": "why might one suspect the emblem at the front is meant to reference the us", "gt answer": "eagle(1.00)<br/>railroad(0.60)", "pred answer": "light", "question_id": 3515375, "best approach": "wiki, image", "verif answer": "track", "anno approach": "wiki, concept, image", "verif wiki answer": "eagle(0.5329)", "verif concept answer": "train(0.5213)", "verif image answer": "eagle(0.6376)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351537.jpg"}, {"question": "what country eats the most of this food", "gt answer": "norway(1.00)<br/>united state(0.60)", "pred answer": "italy", "question_id": 4917275, "best approach": "wiki", "verif answer": "italy", "anno approach": "wiki, concept, image", "verif wiki answer": "united state(0.6805)", "verif concept answer": "italy(0.6533)", "verif image answer": "italy(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491727.jpg"}, {"question": "is this a gerbil or hamster", "gt answer": "hamster(1.00)", "pred answer": "kitten", "question_id": 2435045, "best approach": "", "verif answer": "domestic", "anno approach": "wiki, concept, image", "verif wiki answer": "long(0.5234)", "verif concept answer": "long(0.5890)", "verif image answer": "mop(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243504.jpg"}, {"question": "what is the purpose of the truck being so close to the water", "gt answer": "unload boat(1.00)", "pred answer": "boat", "question_id": 279805, "best approach": "", "verif answer": "transportation", "anno approach": "wiki, concept, image", "verif wiki answer": "transport(0.6539)", "verif concept answer": "haul(0.6744)", "verif image answer": "transportation(0.6859)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027980.jpg"}, {"question": "what paint style is on the bike on the right", "gt answer": "flame(1.00)", "pred answer": "neon", "question_id": 5126445, "best approach": "image", "verif answer": "new balance", "anno approach": "wiki, concept, image", "verif wiki answer": "modern(0.6770)", "verif concept answer": "modern(0.6575)", "verif image answer": "flame(0.6453)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512644.jpg"}, {"question": "how old is this bird", "gt answer": "1 year(1.00)<br/>5 years(0.60)", "pred answer": "30 years", "question_id": 743905, "best approach": "concept", "verif answer": "5 years", "anno approach": "wiki, concept, image", "verif wiki answer": "4(0.6609)", "verif concept answer": "1 year(0.6331)", "verif image answer": "1(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074390.jpg"}, {"question": "what type of eatery is this", "gt answer": "pizzeria(1.00)<br/>italian(0.60)<br/>pizza(0.60)", "pred answer": "deli", "question_id": 3250125, "best approach": "wiki, concept, image", "verif answer": "italian", "anno approach": "wiki, concept, image", "verif wiki answer": "pizza(0.7072)", "verif concept answer": "pizza(0.6121)", "verif image answer": "pizza(0.7256)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325012.jpg"}, {"question": "what are these guys on there way to do", "gt answer": "camp(1.00)<br/>backpack(0.60)<br/>hike(1.00)", "pred answer": "vacation", "question_id": 741565, "best approach": "wiki, image", "verif answer": "golf", "anno approach": "wiki, concept, image", "verif wiki answer": "camp(0.6680)", "verif concept answer": "backpack(0.6537)", "verif image answer": "camp(0.6388)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074156.jpg"}, {"question": "when was this made", "gt answer": "1903(1.00)<br/>1900(0.60)<br/>1900's(0.60)", "pred answer": "1930s", "question_id": 5251695, "best approach": "wiki, concept", "verif answer": "1900", "anno approach": "wiki, concept, image", "verif wiki answer": "1903(0.6643)", "verif concept answer": "1903(0.6977)", "verif image answer": "1900(0.7185)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525169.jpg"}, {"question": "what should this woman be careful of", "gt answer": "car(1.00)<br/>traffic(0.60)", "pred answer": "people", "question_id": 4614965, "best approach": "", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "stop light(0.6946)", "verif concept answer": "vehicle(0.6805)", "verif image answer": "stop light(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461496.jpg"}, {"question": "what are the kids looking at", "gt answer": "camera(1.00)<br/>skier(0.60)", "pred answer": "snow", "question_id": 2497305, "best approach": "", "verif answer": "person", "anno approach": "wiki, concept, image", "verif wiki answer": "person(0.6614)", "verif concept answer": "person(0.6501)", "verif image answer": "person(0.7098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249730.jpg"}, {"question": "what famous dancing video game franchise was created for this gaming console system", "gt answer": "just dance(1.00)<br/>dance(0.60)<br/>karaoke(0.60)", "pred answer": "wii", "question_id": 1270765, "best approach": "wiki, concept", "verif answer": "dance", "anno approach": "wiki, concept, image", "verif wiki answer": "just dance(0.7068)", "verif concept answer": "just dance(0.6390)", "verif image answer": "purina(0.6443)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127076.jpg"}, {"question": "what is being sold", "gt answer": "surf board(1.00)", "pred answer": "surfboard", "question_id": 3770155, "best approach": "concept", "verif answer": "surfboard", "anno approach": "wiki, concept, image", "verif wiki answer": "surfboard(0.6885)", "verif concept answer": "surf board(0.6680)", "verif image answer": "money(0.6581)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377015.jpg"}, {"question": "what electrical item is in front of the children on the table", "gt answer": "projector(1.00)", "pred answer": "tv", "question_id": 1975035, "best approach": "wiki, concept", "verif answer": "tv", "anno approach": "wiki, concept, image", "verif wiki answer": "projector(0.6144)", "verif concept answer": "projector(0.5484)", "verif image answer": "fry(0.6670)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197503.jpg"}, {"question": "what brand of computer", "gt answer": "samsung(1.00)<br/>toshiba(0.60)", "pred answer": "dell", "question_id": 475025, "best approach": "wiki, concept, image", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "samsung(0.6649)", "verif concept answer": "samsung(0.6843)", "verif image answer": "samsung(0.6907)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047502.jpg"}, {"question": "what movie involves a cat and dog that are best friends venturing home like those in the picture", "gt answer": "homeward bound(1.00)", "pred answer": "cinderella", "question_id": 116355, "best approach": "", "verif answer": "dumbo", "anno approach": "wiki, concept, image", "verif wiki answer": "dumbo(0.5459)", "verif concept answer": "dumbo(0.6573)", "verif image answer": "friend(0.7161)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011635.jpg"}, {"question": "what is about to happen", "gt answer": "horseback ride(0.60)<br/>horse ride(1.00)<br/>horse race(0.60)", "pred answer": "race", "question_id": 5292265, "best approach": "image", "verif answer": "race", "anno approach": "wiki, concept, image", "verif wiki answer": "race(0.5722)", "verif concept answer": "race(0.6302)", "verif image answer": "horse race(0.7008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529226.jpg"}, {"question": "", "gt answer": "levi(0.60)<br/>cowboy(0.60)", "pred answer": "levis", "question_id": 2571635, "best approach": "", "verif answer": "north face", "anno approach": "wiki, concept, image", "verif wiki answer": "north face(0.5570)", "verif concept answer": "ll bean(0.5607)", "verif image answer": "north face(0.6756)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257163.jpg"}, {"question": "what type of shells are on the table", "gt answer": "pistachio(1.00)", "pred answer": "fruit", "question_id": 5034785, "best approach": "concept", "verif answer": "cherry", "anno approach": "wiki, concept, image", "verif wiki answer": "cashew(0.5106)", "verif concept answer": "pistachio(0.6241)", "verif image answer": "cashew(0.6646)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503478.jpg"}, {"question": "what does this guys shirt say", "gt answer": "park(1.00)", "pred answer": "hello", "question_id": 287975, "best approach": "", "verif answer": "no park", "anno approach": "wiki, concept, image", "verif wiki answer": "advertising(0.5358)", "verif concept answer": "bench(0.5091)", "verif image answer": "advertising(0.5061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028797.jpg"}, {"question": "what is the name of the ancient greek sport that evolved into the sport featured above", "gt answer": "discus(1.00)<br/>soccer(0.60)<br/>frisbee(0.60)", "pred answer": "volleyball", "question_id": 2978665, "best approach": "wiki, concept", "verif answer": "disc golf", "anno approach": "wiki, concept, image", "verif wiki answer": "soccer(0.6917)", "verif concept answer": "soccer(0.5921)", "verif image answer": "disc golf(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297866.jpg"}, {"question": "what kind of train is this", "gt answer": "commuter(1.00)", "pred answer": "electric", "question_id": 578015, "best approach": "", "verif answer": "passenger", "anno approach": "wiki, concept, image", "verif wiki answer": "passenger(0.7247)", "verif concept answer": "passenger(0.7155)", "verif image answer": "train(0.7119)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000057801.jpg"}, {"question": "what popular grilled sandwich is made of these animals", "gt answer": "hamburger(1.00)<br/>roast beef(0.60)<br/>burger(0.60)", "pred answer": "steak", "question_id": 4891145, "best approach": "wiki, image", "verif answer": "beef", "anno approach": "wiki, concept, image", "verif wiki answer": "hamburger(0.6805)", "verif concept answer": "burger(0.6870)", "verif image answer": "hamburger(0.7047)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489114.jpg"}, {"question": "what 's the normal size of these animal 's ear", "gt answer": "big(1.00)<br/>3 feet(0.60)<br/>5 feet(0.60)<br/>large(0.60)", "pred answer": "medium", "question_id": 2182835, "best approach": "wiki, concept", "verif answer": "large", "anno approach": "wiki, concept, image", "verif wiki answer": "3 feet(0.5924)", "verif concept answer": "5 feet(0.6440)", "verif image answer": "huge(0.7053)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218283.jpg"}, {"question": "what will happen next", "gt answer": "serve(1.00)<br/>swing(0.60)<br/>hit ball(0.60)", "pred answer": "hit", "question_id": 5575075, "best approach": "wiki, concept", "verif answer": "hit ball", "anno approach": "wiki, concept, image", "verif wiki answer": "serve(0.6935)", "verif concept answer": "serve(0.6426)", "verif image answer": "hit ball(0.7092)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557507.jpg"}, {"question": "what brand is the horseradish", "gt answer": "kraft(1.00)<br/>french(0.60)<br/>heinz(0.60)", "pred answer": "dixie", "question_id": 4183945, "best approach": "concept, image", "verif answer": "dixie", "anno approach": "wiki, concept, image", "verif wiki answer": "elbow(0.5927)", "verif concept answer": "heinz(0.7173)", "verif image answer": "heinz(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000418394.jpg"}, {"question": "what is the state bird for the location pictured", "gt answer": "seagull(1.00)<br/>robin(0.60)<br/>cardinal(0.60)", "pred answer": "washington", "question_id": 3663855, "best approach": "wiki, concept, image", "verif answer": "cardinal", "anno approach": "wiki, concept, image", "verif wiki answer": "robin(0.6899)", "verif concept answer": "robin(0.6971)", "verif image answer": "robin(0.6452)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366385.jpg"}, {"question": "what type of cuisine is pictured here", "gt answer": "asian(1.00)<br/>japanese(0.60)<br/>coconut(0.60)<br/>indian(0.60)", "pred answer": "pastry", "question_id": 4512835, "best approach": "image", "verif answer": "chinese", "anno approach": "wiki, concept, image", "verif wiki answer": "japanese(0.6501)", "verif concept answer": "japanese(0.6126)", "verif image answer": "asian(0.6582)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451283.jpg"}, {"question": "in what country is the airline shown in the photo based", "gt answer": "canada(1.00)<br/>france(0.60)<br/>chile(0.60)", "pred answer": "australia", "question_id": 1754185, "best approach": "image", "verif answer": "alaska", "anno approach": "wiki, concept, image", "verif wiki answer": "alaska(0.6876)", "verif concept answer": "alaska(0.6989)", "verif image answer": "france(0.7142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000175418.jpg"}, {"question": "is it warm or cold", "gt answer": "warm(1.00)<br/>hot(0.60)", "pred answer": "cold", "question_id": 1404165, "best approach": "wiki, concept, image", "verif answer": "hot", "anno approach": "wiki, concept, image", "verif wiki answer": "hot(0.5796)", "verif concept answer": "hot(0.7107)", "verif image answer": "hot(0.6803)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140416.jpg"}, {"question": "where must the ball go for a score", "gt answer": "goal(1.00)<br/>net(0.60)", "pred answer": "field", "question_id": 3675195, "best approach": "", "verif answer": "goal", "anno approach": "wiki, concept, image", "verif wiki answer": "homerun(0.5673)", "verif concept answer": "homerun(0.6190)", "verif image answer": "to catch ball(0.6756)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367519.jpg"}, {"question": "what is this behavior called", "gt answer": "perch(1.00)<br/>relax(0.60)<br/>fish(0.60)<br/>rest(0.60)", "pred answer": "swim", "question_id": 1414605, "best approach": "wiki", "verif answer": "relax", "anno approach": "wiki, concept, image", "verif wiki answer": "perch(0.5684)", "verif concept answer": "relax(0.6441)", "verif image answer": "bath(0.7241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000141460.jpg"}, {"question": "what is keeping people in", "gt answer": "rail(1.00)<br/>rain(0.60)<br/>wall(0.60)<br/>fence(0.60)", "pred answer": "bridge", "question_id": 2131035, "best approach": "wiki, concept, image", "verif answer": "wall", "anno approach": "wiki, concept, image", "verif wiki answer": "wall(0.6513)", "verif concept answer": "wall(0.6478)", "verif image answer": "rain(0.6245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000213103.jpg"}, {"question": "where would one usually find this animal", "gt answer": "wood(1.00)<br/>forest(0.60)<br/>mountain(0.60)<br/>zoo(0.60)", "pred answer": "north pole", "question_id": 5076055, "best approach": "image", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "zoo(0.6762)", "verif concept answer": "zoo(0.6931)", "verif image answer": "wood(0.6869)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507605.jpg"}, {"question": "why doesn't he have on safety gear", "gt answer": "he is reckless(1.00)<br/>0(0.60)", "pred answer": "run", "question_id": 132785, "best approach": "wiki, concept, image", "verif answer": "2", "anno approach": "wiki, concept, image", "verif wiki answer": "he is reckless(0.6725)", "verif concept answer": "he is reckless(0.5295)", "verif image answer": "he is reckless(0.6035)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013278.jpg"}, {"question": "what are the plate on the ground of this game", "gt answer": "base(1.00)", "pred answer": "home", "question_id": 632635, "best approach": "", "verif answer": "home plate", "anno approach": "wiki, concept, image", "verif wiki answer": "home plate(0.6835)", "verif concept answer": "baseball bat(0.6910)", "verif image answer": "baseball bat(0.7073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063263.jpg"}, {"question": "what type of vegetable is in the bowl", "gt answer": "zucchini(1.00)<br/>pepper(0.60)", "pred answer": "potato", "question_id": 2934895, "best approach": "concept", "verif answer": "cucumber", "anno approach": "wiki, concept, image", "verif wiki answer": "cucumber(0.6809)", "verif concept answer": "zucchini(0.6483)", "verif image answer": "pepper(0.7142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293489.jpg"}, {"question": "what usually contains these objects", "gt answer": "drawer(1.00)<br/>purse(0.60)", "pred answer": "book", "question_id": 3711575, "best approach": "image", "verif answer": "desk", "anno approach": "wiki, concept, image", "verif wiki answer": "backpack(0.6970)", "verif concept answer": "backpack(0.7013)", "verif image answer": "drawer(0.6405)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371157.jpg"}, {"question": "specify direction of traffic that need to stop", "gt answer": "right(1.00)", "pred answer": "straight", "question_id": 1463895, "best approach": "", "verif answer": "right", "anno approach": "wiki, concept, image", "verif wiki answer": "left(0.6669)", "verif concept answer": "right handed(0.6307)", "verif image answer": "left(0.6586)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146389.jpg"}, {"question": "what is the name of a famous manufacturer of these items", "gt answer": "ty(1.00)", "pred answer": "build bear", "question_id": 3518295, "best approach": "image", "verif answer": "build bear", "anno approach": "wiki, concept, image", "verif wiki answer": "toy r us(0.6753)", "verif concept answer": "toy r us(0.6394)", "verif image answer": "ty(0.6805)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351829.jpg"}, {"question": "what types of fats are in a dessert like this", "gt answer": "saturated(1.00)<br/>milk(0.60)<br/>solid(0.60)", "pred answer": "protein", "question_id": 5173215, "best approach": "wiki", "verif answer": "solid", "anno approach": "wiki, concept, image", "verif wiki answer": "saturated(0.6830)", "verif concept answer": "milk(0.6729)", "verif image answer": "solid(0.7164)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517321.jpg"}, {"question": "what is the reflective body called", "gt answer": "water(1.00)<br/>lake(1.00)", "pred answer": "hydrogen and oxygen", "question_id": 4831185, "best approach": "", "verif answer": "island", "anno approach": "wiki, concept, image", "verif wiki answer": "island(0.5334)", "verif concept answer": "island(0.5896)", "verif image answer": "ocean(0.5164)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483118.jpg"}, {"question": "what does this object do", "gt answer": "cook(1.00)<br/>bake(0.60)", "pred answer": "eat", "question_id": 4550815, "best approach": "concept", "verif answer": "cook", "anno approach": "wiki, concept, image", "verif wiki answer": "roast(0.5604)", "verif concept answer": "bake(0.5921)", "verif image answer": "food(0.7102)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455081.jpg"}, {"question": "which of the seven deadly sins has the same name as an item seen here", "gt answer": "vanity(1.00)<br/>cleanliness(0.60)<br/>bathroom(0.60)", "pred answer": "towel", "question_id": 2808085, "best approach": "wiki, concept", "verif answer": "sink", "anno approach": "wiki, concept, image", "verif wiki answer": "vanity(0.5740)", "verif concept answer": "vanity(0.6535)", "verif image answer": "jack and jill(0.7168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280808.jpg"}, {"question": "how many times should you do this in a day", "gt answer": "twice(1.00)<br/>3(0.60)", "pred answer": "5", "question_id": 2757935, "best approach": "", "verif answer": "5", "anno approach": "wiki, concept, image", "verif wiki answer": "noon(0.6746)", "verif concept answer": "noon(0.6084)", "verif image answer": "2(0.6834)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000275793.jpg"}, {"question": "", "gt answer": "regular(0.60)<br/>crouch(0.60)", "pred answer": "surf", "question_id": 1485175, "best approach": "", "verif answer": "surf", "anno approach": "wiki, concept, image", "verif wiki answer": "squat(0.5876)", "verif concept answer": "squat(0.6565)", "verif image answer": "squat(0.5992)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148517.jpg"}, {"question": "what are these spoons used for", "gt answer": "measure(1.00)", "pred answer": "brush teeth", "question_id": 4652045, "best approach": "image", "verif answer": "brush teeth", "anno approach": "wiki, concept, image", "verif wiki answer": "brush teeth(0.6689)", "verif concept answer": "brush teeth(0.6836)", "verif image answer": "measure(0.6759)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465204.jpg"}, {"question": "what kind of bag that 's holding these apples called", "gt answer": "mesh(1.00)", "pred answer": "backpack", "question_id": 3297655, "best approach": "", "verif answer": "wrap paper", "anno approach": "wiki, concept, image", "verif wiki answer": "yarn(0.7180)", "verif concept answer": "wax(0.6802)", "verif image answer": "wrap paper(0.7169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329765.jpg"}, {"question": "what kind of sandwich is this", "gt answer": "chicken(1.00)<br/>reuben(0.60)<br/>roast(0.60)", "pred answer": "turkey", "question_id": 704795, "best approach": "", "verif answer": "reuben", "anno approach": "wiki, concept, image", "verif wiki answer": "grilled(0.6235)", "verif concept answer": "grilled(0.7225)", "verif image answer": "grilled(0.7177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070479.jpg"}, {"question": "what is the item draped over the stop sign", "gt answer": "measure tape(1.00)", "pred answer": "wire", "question_id": 5640435, "best approach": "", "verif answer": "fold", "anno approach": "wiki, concept, image", "verif wiki answer": "fold(0.5633)", "verif concept answer": "fold(0.6111)", "verif image answer": "fold(0.6915)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564043.jpg"}, {"question": "what is it called when you use this mode of transportation overnight", "gt answer": "red eye(1.00)", "pred answer": "fly", "question_id": 4892975, "best approach": "", "verif answer": "take off", "anno approach": "wiki, concept, image", "verif wiki answer": "take off(0.6984)", "verif concept answer": "normal(0.6421)", "verif image answer": "takeoff(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489297.jpg"}, {"question": "what kind of fish is used to make this meal", "gt answer": "salmon(1.00)<br/>tuna(1.00)", "pred answer": "shrimp", "question_id": 5427155, "best approach": "wiki, concept", "verif answer": "tuna", "anno approach": "wiki, concept, image", "verif wiki answer": "tuna(0.6527)", "verif concept answer": "salmon(0.6154)", "verif image answer": "chicken(0.6656)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542715.jpg"}, {"question": "is this train arriving or departing the station", "gt answer": "arrive(1.00)", "pred answer": "leave", "question_id": 5704065, "best approach": "wiki, concept", "verif answer": "arrive", "anno approach": "wiki, concept, image", "verif wiki answer": "arrive(0.6852)", "verif concept answer": "arrive(0.6724)", "verif image answer": "bullet train(0.6839)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570406.jpg"}, {"question": "what event is this", "gt answer": "baby shower(1.00)<br/>st patrick's day(0.60)<br/>baby(0.60)", "pred answer": "party", "question_id": 1045645, "best approach": "image", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "celebration(0.6988)", "verif concept answer": "birthday(0.6698)", "verif image answer": "baby(0.7153)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000104564.jpg"}, {"question": "where did this sport originate", "gt answer": "usa(1.00)<br/>california(0.60)<br/>us(0.60)", "pred answer": "america", "question_id": 2447115, "best approach": "concept, image", "verif answer": "usa", "anno approach": "wiki, concept, image", "verif wiki answer": "united state(0.6825)", "verif concept answer": "usa(0.6613)", "verif image answer": "usa(0.7199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244711.jpg"}, {"question": "seattle is known for what object seen in this photograph", "gt answer": "kite(1.00)<br/>fog(0.60)", "pred answer": "wind", "question_id": 4585965, "best approach": "wiki", "verif answer": "kite", "anno approach": "wiki, concept, image", "verif wiki answer": "kite(0.5790)", "verif concept answer": "helicopter(0.6171)", "verif image answer": "kite fly(0.7263)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458596.jpg"}, {"question": "what might i dress like this for", "gt answer": "halloween(1.00)<br/>wed(0.60)<br/>church(0.60)<br/>party(0.60)", "pred answer": "business", "question_id": 931065, "best approach": "wiki, concept", "verif answer": "church", "anno approach": "wiki, concept, image", "verif wiki answer": "party(0.6424)", "verif concept answer": "church(0.6278)", "verif image answer": "birthday(0.7120)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093106.jpg"}, {"question": "who was the first president of the nation on the flag in this photo", "gt answer": "george washington(1.00)<br/>washington(0.60)", "pred answer": "obama", "question_id": 4903285, "best approach": "", "verif answer": "air force 1", "anno approach": "wiki, concept, image", "verif wiki answer": "air force 1(0.7242)", "verif concept answer": "richard trevithick(0.6555)", "verif image answer": "richard trevithick(0.7002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490328.jpg"}, {"question": "what are the two types of washroom fixtures shown here", "gt answer": "toilet(1.00)", "pred answer": "men", "question_id": 3377485, "best approach": "", "verif answer": "sink", "anno approach": "wiki, concept, image", "verif wiki answer": "toilet seat(0.6226)", "verif concept answer": "toilet seat(0.6819)", "verif image answer": "ceramic(0.6359)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337748.jpg"}, {"question": "what will this plane do", "gt answer": "take off(1.00)", "pred answer": "fly", "question_id": 68195, "best approach": "concept", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "land(0.6314)", "verif concept answer": "take off(0.6476)", "verif image answer": "land(0.6931)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006819.jpg"}, {"question": "what iconic brand of motorcycle is in the picture", "gt answer": "harley davidson(1.00)", "pred answer": "honda", "question_id": 5568865, "best approach": "", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "honda(0.7022)", "verif concept answer": "bmw(0.6099)", "verif image answer": "harley(0.6355)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556886.jpg"}, {"question": "what team is this", "gt answer": "pirate(1.00)<br/>oriole(0.60)<br/>baseball(0.60)<br/>cub(0.60)", "pred answer": "yankees", "question_id": 5392705, "best approach": "concept", "verif answer": "cub", "anno approach": "wiki, concept, image", "verif wiki answer": "oriole(0.6347)", "verif concept answer": "pirate(0.6376)", "verif image answer": "cub(0.6867)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539270.jpg"}, {"question": "what kind of bird is on tv", "gt answer": "hummingbird(1.00)<br/>bluejay(0.60)<br/>robin(0.60)", "pred answer": "crow", "question_id": 5361755, "best approach": "concept", "verif answer": "hummingbird", "anno approach": "wiki, concept, image", "verif wiki answer": "bluejay(0.5386)", "verif concept answer": "hummingbird(0.6616)", "verif image answer": "bluejay(0.5650)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536175.jpg"}, {"question": "what is this room used for", "gt answer": "urine(1.00)<br/>urinate(0.60)<br/>pee(0.60)<br/>bathroom(0.60)", "pred answer": "shower", "question_id": 5817665, "best approach": "concept, image", "verif answer": "bathroom", "anno approach": "wiki, concept, image", "verif wiki answer": "toilet(0.6080)", "verif concept answer": "urine(0.6794)", "verif image answer": "urine(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000581766.jpg"}, {"question": "where is this picture taken", "gt answer": "lake(1.00)<br/>harbor(0.60)<br/>bay(0.60)", "pred answer": "marina", "question_id": 239355, "best approach": "wiki, concept, image", "verif answer": "bay", "anno approach": "wiki, concept, image", "verif wiki answer": "bay(0.7073)", "verif concept answer": "bay(0.6361)", "verif image answer": "harbor(0.6437)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023935.jpg"}, {"question": "if this woman 's bikini top were not present she would be said to be going what", "gt answer": "topless(1.00)", "pred answer": "swim", "question_id": 3961435, "best approach": "", "verif answer": "selfie", "anno approach": "wiki, concept, image", "verif wiki answer": "hardware store(0.6752)", "verif concept answer": "hardware store(0.6495)", "verif image answer": "hardware store(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396143.jpg"}, {"question": "what number is on the jersey of this dodgers player", "gt answer": "47(1.00)", "pred answer": "19", "question_id": 1357945, "best approach": "", "verif answer": "19", "anno approach": "wiki, concept, image", "verif wiki answer": "15(0.6549)", "verif concept answer": "15(0.6712)", "verif image answer": "cleat(0.7005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000135794.jpg"}, {"question": "what religion is in this church", "gt answer": "catholic(1.00)", "pred answer": "christian", "question_id": 4808185, "best approach": "", "verif answer": "christianity", "anno approach": "wiki, concept, image", "verif wiki answer": "amish(0.7244)", "verif concept answer": "christianity(0.7263)", "verif image answer": "christianity(0.6679)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480818.jpg"}, {"question": "is this a primary color or a pastel that is depicted on the board", "gt answer": "pastel(1.00)<br/>blue(0.60)", "pred answer": "green", "question_id": 2721435, "best approach": "", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "light blue(0.6730)", "verif concept answer": "primary(0.6443)", "verif image answer": "green(0.6571)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000272143.jpg"}, {"question": "where did this style of portable tv come from", "gt answer": "sony(1.00)<br/>usa(0.60)", "pred answer": "ikea", "question_id": 4643305, "best approach": "image", "verif answer": "america", "anno approach": "wiki, concept, image", "verif wiki answer": "china(0.5578)", "verif concept answer": "motorola(0.6018)", "verif image answer": "usa(0.7136)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464330.jpg"}, {"question": "what is on her head", "gt answer": "veil(1.00)", "pred answer": "hat", "question_id": 5727895, "best approach": "wiki", "verif answer": "scarf", "anno approach": "wiki, concept, image", "verif wiki answer": "veil(0.5592)", "verif concept answer": "scarf(0.6702)", "verif image answer": "hijab(0.6532)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572789.jpg"}, {"question": "how many jets are on this type of plane", "gt answer": "4(1.00)<br/>1(1.00)", "pred answer": "200", "question_id": 3965725, "best approach": "image", "verif answer": "2", "anno approach": "wiki, concept, image", "verif wiki answer": "2(0.6112)", "verif concept answer": "0(0.6471)", "verif image answer": "1(0.6901)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396572.jpg"}, {"question": "what year is this car", "gt answer": "1960(1.00)<br/>1965(0.60)<br/>1940(0.60)", "pred answer": "1969", "question_id": 3078355, "best approach": "wiki, image", "verif answer": "1940", "anno approach": "wiki, concept, image", "verif wiki answer": "1940(0.6909)", "verif concept answer": "1946(0.6634)", "verif image answer": "1965(0.6775)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307835.jpg"}, {"question": "what medium was this photo taken in", "gt answer": "film(1.00)<br/>camera(0.60)", "pred answer": "shadow", "question_id": 2388165, "best approach": "image", "verif answer": "black and white", "anno approach": "wiki, concept, image", "verif wiki answer": "black and white(0.7008)", "verif concept answer": "black and white(0.6661)", "verif image answer": "film(0.7258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238816.jpg"}, {"question": "which country exports the most of the fruit shown in this picture", "gt answer": "guatemala(1.00)<br/>india(0.60)<br/>mexico(0.60)<br/>ecuador(0.60)", "pred answer": "south america", "question_id": 2027425, "best approach": "concept", "verif answer": "india", "anno approach": "wiki, concept, image", "verif wiki answer": "ecuador(0.6198)", "verif concept answer": "guatemala(0.6531)", "verif image answer": "ecuador(0.6901)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202742.jpg"}, {"question": "would the luggage in this photo be considered new or vintage", "gt answer": "vintage(1.00)", "pred answer": "old", "question_id": 5447195, "best approach": "", "verif answer": "old", "anno approach": "wiki, concept, image", "verif wiki answer": "1900(0.5135)", "verif concept answer": "old(0.6632)", "verif image answer": "old(0.7211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544719.jpg"}, {"question": "what country is this hair color most common", "gt answer": "ireland(1.00)<br/>scotland(1.00)", "pred answer": "red", "question_id": 600355, "best approach": "wiki, concept", "verif answer": "england", "anno approach": "wiki, concept, image", "verif wiki answer": "ireland(0.6922)", "verif concept answer": "ireland(0.7060)", "verif image answer": "england(0.7213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060035.jpg"}, {"question": "what sport are the dogs pictured known for", "gt answer": "hunt(1.00)<br/>race(0.60)", "pred answer": "run", "question_id": 2179785, "best approach": "wiki", "verif answer": "hunt", "anno approach": "wiki, concept, image", "verif wiki answer": "hunt(0.5968)", "verif concept answer": "race(0.6826)", "verif image answer": "race(0.6588)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217978.jpg"}, {"question": "what editing tools was used to create this", "gt answer": "photoshop(1.00)<br/>color(0.60)<br/>paint(0.60)", "pred answer": "light", "question_id": 4243005, "best approach": "concept", "verif answer": "long exposure", "anno approach": "wiki, concept, image", "verif wiki answer": "picture(0.6160)", "verif concept answer": "paint(0.5586)", "verif image answer": "long exposure(0.7175)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424300.jpg"}, {"question": "would this dish be served at mcdonald 's or someplace fancier", "gt answer": "someplace fancier(1.00)<br/>restaurant(0.60)", "pred answer": "bakery", "question_id": 2695505, "best approach": "wiki, concept, image", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "restaurant(0.5899)", "verif concept answer": "restaurant(0.6815)", "verif image answer": "restaurant(0.5989)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269550.jpg"}, {"question": "who took this photo", "gt answer": "dave hayward(1.00)<br/>woman(0.60)<br/>photographer(0.60)", "pred answer": "jockey", "question_id": 4825635, "best approach": "wiki, concept, image", "verif answer": "photographer", "anno approach": "wiki, concept, image", "verif wiki answer": "dave hayward(0.6192)", "verif concept answer": "dave hayward(0.7200)", "verif image answer": "dave hayward(0.7017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482563.jpg"}, {"question": "which computer accessory is the person touching", "gt answer": "keyboard(1.00)", "pred answer": "bluetooth", "question_id": 3423815, "best approach": "wiki, concept, image", "verif answer": "keyboard", "anno approach": "wiki, concept, image", "verif wiki answer": "keyboard(0.7145)", "verif concept answer": "keyboard(0.6644)", "verif image answer": "keyboard(0.5054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342381.jpg"}, {"question": "why is she holding that", "gt answer": "rain(1.00)<br/>umbrella(0.60)<br/>protection(0.60)", "pred answer": "stay dry", "question_id": 5263625, "best approach": "", "verif answer": "stay dry", "anno approach": "wiki, concept, image", "verif wiki answer": "stay dry(0.7238)", "verif concept answer": "stay dry(0.7028)", "verif image answer": "stay dry(0.5186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526362.jpg"}, {"question": "what is the name of this sport in england", "gt answer": "football(1.00)", "pred answer": "soccer", "question_id": 1938245, "best approach": "wiki, concept", "verif answer": "soccer", "anno approach": "wiki, concept, image", "verif wiki answer": "football(0.7154)", "verif concept answer": "football(0.7008)", "verif image answer": "rat(0.6261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193824.jpg"}, {"question": "how many teeth do these animals have in their mouths", "gt answer": "32(1.00)<br/>20(0.60)<br/>100(0.60)", "pred answer": "7", "question_id": 5719535, "best approach": "image", "verif answer": "40", "anno approach": "wiki, concept, image", "verif wiki answer": "50(0.6809)", "verif concept answer": "40(0.5782)", "verif image answer": "32(0.5491)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571953.jpg"}, {"question": "how many times do you wind up a fireman 's hose before it is completely wound up", "gt answer": "50(1.00)<br/>15(0.60)<br/>20(0.60)<br/>100(0.60)", "pred answer": "3", "question_id": 296715, "best approach": "wiki", "verif answer": "100", "anno approach": "wiki, concept, image", "verif wiki answer": "50(0.5961)", "verif concept answer": "15(0.5278)", "verif image answer": "15(0.5705)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029671.jpg"}, {"question": "what meat do we get from the animal on the front of the food truck", "gt answer": "pork(1.00)<br/>0(0.60)<br/>beef(0.60)", "pred answer": "chicken", "question_id": 1363695, "best approach": "wiki", "verif answer": "0", "anno approach": "wiki, concept, image", "verif wiki answer": "pork(0.6978)", "verif concept answer": "lamb(0.5407)", "verif image answer": "meat(0.7011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136369.jpg"}, {"question": "when the orange items on the trees fall some people like to save them by pressing them into what", "gt answer": "book(1.00)", "pred answer": "light", "question_id": 3433195, "best approach": "", "verif answer": "cloth", "anno approach": "wiki, concept, image", "verif wiki answer": "city(0.5298)", "verif concept answer": "shield(0.6503)", "verif image answer": "shield(0.5790)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343319.jpg"}, {"question": "the fruit eaten by the boy is good for which part of the body", "gt answer": "muscle(1.00)", "pred answer": "brain", "question_id": 4563025, "best approach": "wiki, concept, image", "verif answer": "muscle", "anno approach": "wiki, concept, image", "verif wiki answer": "muscle(0.7245)", "verif concept answer": "muscle(0.6292)", "verif image answer": "muscle(0.6578)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456302.jpg"}, {"question": "what kind of beer is this", "gt answer": "budweiser(1.00)<br/>dark(0.60)", "pred answer": "ale", "question_id": 5473155, "best approach": "wiki, concept", "verif answer": "budweiser", "anno approach": "wiki, concept, image", "verif wiki answer": "budweiser(0.7211)", "verif concept answer": "budweiser(0.6225)", "verif image answer": "black(0.7014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000547315.jpg"}, {"question": "the red chair that the cat is on is commonly referred to as a what kind of chair", "gt answer": "fold(1.00)<br/>calico(0.60)", "pred answer": "sofa", "question_id": 1829955, "best approach": "wiki, image", "verif answer": "calico", "anno approach": "wiki, concept, image", "verif wiki answer": "fold(0.7152)", "verif concept answer": "collar(0.6496)", "verif image answer": "fold(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182995.jpg"}, {"question": "what materials were used to make the fake mouse and keyboard", "gt answer": "clay(1.00)<br/>rubber(0.60)", "pred answer": "cotton", "question_id": 3627515, "best approach": "concept", "verif answer": "plastic", "anno approach": "wiki, concept, image", "verif wiki answer": "rubber(0.7067)", "verif concept answer": "clay(0.6757)", "verif image answer": "ceramic(0.6480)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362751.jpg"}, {"question": "is it hot or cold in this image", "gt answer": "cold(1.00)", "pred answer": "hot", "question_id": 4576565, "best approach": "wiki", "verif answer": "hot", "anno approach": "wiki, concept, image", "verif wiki answer": "cold(0.6121)", "verif concept answer": "hot(0.7249)", "verif image answer": "very cold(0.5669)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457656.jpg"}, {"question": "what is the breed of this dog", "gt answer": "retriever(1.00)<br/>black lab(0.60)", "pred answer": "lab", "question_id": 2581765, "best approach": "wiki, concept", "verif answer": "labrador", "anno approach": "wiki, concept, image", "verif wiki answer": "retriever(0.6246)", "verif concept answer": "retriever(0.6746)", "verif image answer": "mix(0.5487)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258176.jpg"}, {"question": "approximately how tall is the building behind the animal shown here", "gt answer": "20 feet(1.00)<br/>30 feet(1.00)", "pred answer": "12 feet", "question_id": 3912165, "best approach": "wiki", "verif answer": "20 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "20 feet(0.6792)", "verif concept answer": "50 feet(0.6212)", "verif image answer": "50 feet(0.5683)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391216.jpg"}, {"question": "what kind of chair is the woman relaxing in", "gt answer": "recliner(1.00)", "pred answer": "sofa", "question_id": 539295, "best approach": "concept", "verif answer": "couch", "anno approach": "wiki, concept, image", "verif wiki answer": "couch(0.5861)", "verif concept answer": "recliner(0.7092)", "verif image answer": "couch(0.6769)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053929.jpg"}, {"question": "what substance is used to clean these windows", "gt answer": "windex(1.00)<br/>water(1.00)", "pred answer": "plastic", "question_id": 658555, "best approach": "wiki, concept, image", "verif answer": "water", "anno approach": "wiki, concept, image", "verif wiki answer": "water(0.5399)", "verif concept answer": "windex(0.6793)", "verif image answer": "windex(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065855.jpg"}, {"question": "who invented this device in the second world war", "gt answer": "alan turing(1.00)", "pred answer": "bill gate", "question_id": 4560715, "best approach": "wiki, concept", "verif answer": "steve job", "anno approach": "wiki, concept, image", "verif wiki answer": "alan turing(0.7278)", "verif concept answer": "alan turing(0.6673)", "verif image answer": "irma s rombauer(0.6528)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456071.jpg"}, {"question": "what is the purpose of the striped object", "gt answer": "pillow(1.00)<br/>rest(1.00)", "pred answer": "sleep", "question_id": 1580775, "best approach": "wiki, concept", "verif answer": "pillow", "anno approach": "wiki, concept, image", "verif wiki answer": "pillow(0.7050)", "verif concept answer": "pillow(0.5593)", "verif image answer": "person(0.6030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000158077.jpg"}, {"question": "what kind of gas could be used to fill the balloons", "gt answer": "helium(1.00)", "pred answer": "gas", "question_id": 2588825, "best approach": "wiki, concept", "verif answer": "helium", "anno approach": "wiki, concept, image", "verif wiki answer": "helium(0.6774)", "verif concept answer": "helium(0.6605)", "verif image answer": "lot(0.5613)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258882.jpg"}, {"question": "what is this room used for", "gt answer": "confer(1.00)<br/>meet(1.00)", "pred answer": "work", "question_id": 4005345, "best approach": "wiki, concept, image", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "confer(0.6511)", "verif concept answer": "meet(0.6751)", "verif image answer": "meet(0.6972)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400534.jpg"}, {"question": "what cultures have this as a common meal", "gt answer": "western(1.00)<br/>american(0.60)<br/>french(0.60)", "pred answer": "chinese", "question_id": 5490985, "best approach": "wiki", "verif answer": "american", "anno approach": "wiki, concept, image", "verif wiki answer": "french(0.7067)", "verif concept answer": "english(0.7075)", "verif image answer": "english(0.7213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000549098.jpg"}, {"question": "what does this animal use it 's long appendage for", "gt answer": "drink water(0.60)<br/>grab(1.00)", "pred answer": "tusk", "question_id": 3220955, "best approach": "wiki, concept", "verif answer": "drink", "anno approach": "wiki, concept, image", "verif wiki answer": "grab(0.7164)", "verif concept answer": "grab(0.7212)", "verif image answer": "drink(0.7181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322095.jpg"}, {"question": "what stunt is this", "gt answer": "jump(1.00)<br/>skateboard(0.60)", "pred answer": "ollie", "question_id": 3666655, "best approach": "wiki, concept, image", "verif answer": "skateboard", "anno approach": "wiki, concept, image", "verif wiki answer": "skateboard(0.6541)", "verif concept answer": "skateboard(0.6423)", "verif image answer": "skateboard(0.6739)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366665.jpg"}, {"question": "what kind of camera is the man using", "gt answer": "webcam(1.00)", "pred answer": "digital", "question_id": 1942355, "best approach": "wiki, concept", "verif answer": "canon", "anno approach": "wiki, concept, image", "verif wiki answer": "webcam(0.7196)", "verif concept answer": "webcam(0.6350)", "verif image answer": "sony(0.5139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194235.jpg"}, {"question": "which food item seen here is famous for having good fats", "gt answer": "avocado(1.00)", "pred answer": "bread", "question_id": 3474055, "best approach": "", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "bread(0.6955)", "verif concept answer": "bread(0.6802)", "verif image answer": "bread(0.5952)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347405.jpg"}, {"question": "what health benefit does the vegetable in this photo promote", "gt answer": "fiber(1.00)<br/>vitamin c(0.60)<br/>vitamin(0.60)", "pred answer": "cancer", "question_id": 1841165, "best approach": "image", "verif answer": "vitamin c", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin c(0.6940)", "verif concept answer": "vitamin c(0.6987)", "verif image answer": "fiber(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184116.jpg"}, {"question": "what sauce is commonly served with this food", "gt answer": "tartar(1.00)", "pred answer": "ranch dress", "question_id": 2157465, "best approach": "wiki, concept", "verif answer": "butter", "anno approach": "wiki, concept, image", "verif wiki answer": "tartar(0.5486)", "verif concept answer": "tartar(0.6372)", "verif image answer": "fried(0.6488)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215746.jpg"}, {"question": "how long does this animal live", "gt answer": "50 years(1.00)<br/>60 years(0.60)<br/>100 years(0.60)", "pred answer": "30 years", "question_id": 5044545, "best approach": "concept", "verif answer": "30 years", "anno approach": "wiki, concept, image", "verif wiki answer": "30 years(0.6214)", "verif concept answer": "50 years(0.6458)", "verif image answer": "40 years(0.6369)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000504454.jpg"}, {"question": "what type of drum is that in the picture", "gt answer": "snare(1.00)<br/>bongo(0.60)<br/>electronic(0.60)", "pred answer": "brass", "question_id": 2929125, "best approach": "wiki, concept, image", "verif answer": "brass", "anno approach": "wiki, concept, image", "verif wiki answer": "snare(0.6587)", "verif concept answer": "snare(0.6366)", "verif image answer": "snare(0.5836)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292912.jpg"}, {"question": "what does this sign mean", "gt answer": "park(1.00)<br/>vehicle(0.60)<br/>car(0.60)", "pred answer": "no park", "question_id": 4269835, "best approach": "image", "verif answer": "park", "anno approach": "wiki, concept, image", "verif wiki answer": "park meter(0.5269)", "verif concept answer": "truck(0.5700)", "verif image answer": "car(0.5317)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426983.jpg"}, {"question": "what is this person making", "gt answer": "pottery(1.00)<br/>vase(1.00)<br/>pot(0.60)", "pred answer": "tea", "question_id": 2445975, "best approach": "wiki, concept", "verif answer": "vase", "anno approach": "wiki, concept, image", "verif wiki answer": "pottery(0.6435)", "verif concept answer": "pottery(0.5920)", "verif image answer": "pot(0.7086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244597.jpg"}, {"question": "originating in japan what is this leisure activity called", "gt answer": "karaoke(1.00)", "pred answer": "wed", "question_id": 3298885, "best approach": "", "verif answer": "dance", "anno approach": "wiki, concept, image", "verif wiki answer": "toxoplasmosis(0.6448)", "verif concept answer": "just dance(0.5441)", "verif image answer": "just dance(0.6854)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329888.jpg"}, {"question": "what is the first name of the famous golfer with the name pictures as his last name", "gt answer": "arnold(1.00)", "pred answer": "jack and jill", "question_id": 4312405, "best approach": "", "verif answer": "soul surfer", "anno approach": "wiki, concept, image", "verif wiki answer": "soul surfer(0.5506)", "verif concept answer": "soul surfer(0.7187)", "verif image answer": "soul surfer(0.5023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431240.jpg"}, {"question": "what sound that also is a word for masticating is used by infants to signify this vehicle", "gt answer": "chew(1.00)", "pred answer": "moo", "question_id": 610485, "best approach": "", "verif answer": "bark", "anno approach": "wiki, concept, image", "verif wiki answer": "indian(0.6294)", "verif concept answer": "track(0.5491)", "verif image answer": "indian(0.5462)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061048.jpg"}, {"question": "why 's his dog wearing clouths", "gt answer": "warmth(1.00)<br/>christmas(0.60)<br/>party(0.60)", "pred answer": "cold", "question_id": 364395, "best approach": "wiki, concept, image", "verif answer": "warmth", "anno approach": "wiki, concept, image", "verif wiki answer": "warmth(0.7255)", "verif concept answer": "warmth(0.5930)", "verif image answer": "warmth(0.5603)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036439.jpg"}, {"question": "where are double decker buses used", "gt answer": "city(1.00)<br/>london(0.60)<br/>tour(0.60)<br/>england(0.60)", "pred answer": "school", "question_id": 3616725, "best approach": "image", "verif answer": "london", "anno approach": "wiki, concept, image", "verif wiki answer": "england(0.5360)", "verif concept answer": "tour(0.7022)", "verif image answer": "city(0.6982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361672.jpg"}, {"question": "what type of suit is the lady wearing", "gt answer": "bikini(1.00)<br/>swim(0.60)", "pred answer": "wet suit", "question_id": 4173505, "best approach": "", "verif answer": "wetsuit", "anno approach": "wiki, concept, image", "verif wiki answer": "sunscreen(0.6815)", "verif concept answer": "sunscreen(0.5773)", "verif image answer": "boogie board(0.5496)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417350.jpg"}, {"question": "what might be in the drawers of this picture", "gt answer": "utensil(1.00)<br/>food(0.60)", "pred answer": "dish", "question_id": 727155, "best approach": "", "verif answer": "dish", "anno approach": "wiki, concept, image", "verif wiki answer": "dish(0.6765)", "verif concept answer": "dish(0.6387)", "verif image answer": "dish(0.6289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072715.jpg"}, {"question": "the color of the bus is the same color scheme for what fast food restaurant", "gt answer": "mcdonalds(1.00)<br/>mcdonald's(0.60)", "pred answer": "red", "question_id": 4680975, "best approach": "", "verif answer": "wooden", "anno approach": "wiki, concept, image", "verif wiki answer": "wooden(0.6169)", "verif concept answer": "wooden(0.7092)", "verif image answer": "wooden(0.6570)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000468097.jpg"}, {"question": "is the creature in this photo nocturnal or diurnal", "gt answer": "diurnal(1.00)<br/>nocturnal(1.00)<br/>both(0.60)", "pred answer": "herbivorous", "question_id": 2941085, "best approach": "wiki, concept, image", "verif answer": "normal", "anno approach": "wiki, concept, image", "verif wiki answer": "nocturnal(0.5197)", "verif concept answer": "nocturnal(0.7233)", "verif image answer": "nocturnal(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000294108.jpg"}, {"question": "what breed of cow is this", "gt answer": "holstein(1.00)<br/>jersey(0.60)", "pred answer": "angus", "question_id": 927815, "best approach": "concept, image", "verif answer": "angus", "anno approach": "wiki, concept, image", "verif wiki answer": "jersey(0.6844)", "verif concept answer": "holstein(0.6809)", "verif image answer": "holstein(0.6583)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092781.jpg"}, {"question": "what are those stairs outside the window", "gt answer": "fire escape(1.00)", "pred answer": "refrigeration", "question_id": 881925, "best approach": "wiki", "verif answer": "half pipe", "anno approach": "wiki, concept, image", "verif wiki answer": "fire escape(0.5989)", "verif concept answer": "half pipe(0.5440)", "verif image answer": "half pipe(0.5084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088192.jpg"}, {"question": "what fabric is that bedspread made from", "gt answer": "silk(1.00)", "pred answer": "lace", "question_id": 2094095, "best approach": "wiki, concept, image", "verif answer": "silk", "anno approach": "wiki, concept, image", "verif wiki answer": "silk(0.7230)", "verif concept answer": "silk(0.7184)", "verif image answer": "silk(0.6800)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209409.jpg"}, {"question": "what type of squash is used in this dish", "gt answer": "zucchini(1.00)<br/>yellow(0.60)<br/>white(0.60)", "pred answer": "green", "question_id": 4467095, "best approach": "wiki, concept, image", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "zucchini(0.5551)", "verif concept answer": "zucchini(0.6908)", "verif image answer": "zucchini(0.6230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000446709.jpg"}, {"question": "what kind of garnish is on top of this dish", "gt answer": "basil(1.00)<br/>spinach(0.60)", "pred answer": "green", "question_id": 5447055, "best approach": "wiki", "verif answer": "spinach", "anno approach": "wiki, concept, image", "verif wiki answer": "basil(0.6429)", "verif concept answer": "spinach(0.6009)", "verif image answer": "kale(0.6988)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544705.jpg"}, {"question": "how much weight can each chair on this ski lift support", "gt answer": "500 lbs(1.00)<br/>500 pounds(0.60)", "pred answer": "200", "question_id": 4059645, "best approach": "image", "verif answer": "ton", "anno approach": "wiki, concept, image", "verif wiki answer": "ton(0.6366)", "verif concept answer": "ton(0.6882)", "verif image answer": "500 pounds(0.7127)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405964.jpg"}, {"question": "what do people typically call this type of bread", "gt answer": "pita(1.00)<br/>tortilla(1.00)", "pred answer": "deep dish", "question_id": 2637105, "best approach": "wiki", "verif answer": "tortilla", "anno approach": "wiki, concept, image", "verif wiki answer": "tortilla(0.7048)", "verif concept answer": "potato(0.6059)", "verif image answer": "glazed(0.6756)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263710.jpg"}, {"question": "what kind of worker would clean up the paper towels", "gt answer": "janitor(1.00)", "pred answer": "plumber", "question_id": 454685, "best approach": "wiki, concept, image", "verif answer": "plumber", "anno approach": "wiki, concept, image", "verif wiki answer": "janitor(0.6292)", "verif concept answer": "janitor(0.5449)", "verif image answer": "janitor(0.5515)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045468.jpg"}, {"question": "what kind of weather is this", "gt answer": "snowy(1.00)<br/>rainy(1.00)<br/>winter(0.60)", "pred answer": "cold", "question_id": 3100535, "best approach": "image", "verif answer": "cold", "anno approach": "wiki, concept, image", "verif wiki answer": "fall(0.6126)", "verif concept answer": "fall(0.6063)", "verif image answer": "snowy(0.6528)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310053.jpg"}, {"question": "what position is the man in green playing", "gt answer": "referee(1.00)", "pred answer": "goalie", "question_id": 542955, "best approach": "wiki, concept", "verif answer": "catcher", "anno approach": "wiki, concept, image", "verif wiki answer": "referee(0.5381)", "verif concept answer": "referee(0.5413)", "verif image answer": "judge(0.5426)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054295.jpg"}, {"question": "what is the average life expectancy of the animal seen here", "gt answer": "60 years(1.00)<br/>25 years(0.60)<br/>50 years(0.60)", "pred answer": "25", "question_id": 1572215, "best approach": "wiki", "verif answer": "60 years", "anno approach": "wiki, concept, image", "verif wiki answer": "60 years(0.6933)", "verif concept answer": "100 years(0.6754)", "verif image answer": "50 years(0.5397)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157221.jpg"}, {"question": "where is the animal from", "gt answer": "north pole(1.00)<br/>alaska(0.60)<br/>artic(0.60)", "pred answer": "arctic", "question_id": 5419115, "best approach": "wiki, concept", "verif answer": "north pole", "anno approach": "wiki, concept, image", "verif wiki answer": "north pole(0.7184)", "verif concept answer": "north pole(0.7241)", "verif image answer": "artic(0.7157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541911.jpg"}, {"question": "what sport is being simulated", "gt answer": "box(1.00)<br/>bowl(0.60)<br/>dance(0.60)", "pred answer": "wii", "question_id": 4212415, "best approach": "image", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "wii(0.7092)", "verif concept answer": "wii(0.6295)", "verif image answer": "dance(0.6267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421241.jpg"}, {"question": "what airline is advertised on the van", "gt answer": "southwest(1.00)<br/>american(0.60)", "pred answer": "boeing", "question_id": 4192975, "best approach": "concept, image", "verif answer": "boeing", "anno approach": "wiki, concept, image", "verif wiki answer": "american airline(0.7228)", "verif concept answer": "southwest(0.5909)", "verif image answer": "southwest(0.5851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419297.jpg"}, {"question": "where would the camera need to be to get this shot", "gt answer": "above(1.00)<br/>in air(0.60)<br/>overhead(0.60)", "pred answer": "mountain", "question_id": 1663765, "best approach": "wiki, concept", "verif answer": "above", "anno approach": "wiki, concept, image", "verif wiki answer": "overhead(0.6627)", "verif concept answer": "overhead(0.6352)", "verif image answer": "below(0.5310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166376.jpg"}, {"question": "you should never drive while using what electronic", "gt answer": "phone(1.00)<br/>cellphone(0.60)", "pred answer": "car", "question_id": 2383455, "best approach": "", "verif answer": "phone", "anno approach": "wiki, concept, image", "verif wiki answer": "smartphone(0.7008)", "verif concept answer": "electrical(0.6784)", "verif image answer": "smartphone(0.5805)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238345.jpg"}, {"question": "in what kind of structure are the people sitting in", "gt answer": "tent(1.00)", "pred answer": "house", "question_id": 4281265, "best approach": "concept", "verif answer": "tent", "anno approach": "wiki, concept, image", "verif wiki answer": "under tent(0.7070)", "verif concept answer": "tent(0.6267)", "verif image answer": "train(0.5076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428126.jpg"}, {"question": "what type of brightly colored bird is this", "gt answer": "peacock(1.00)", "pred answer": "parakeet", "question_id": 918585, "best approach": "", "verif answer": "dove", "anno approach": "wiki, concept, image", "verif wiki answer": "dove(0.7237)", "verif concept answer": "dove(0.7013)", "verif image answer": "dove(0.6929)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000091858.jpg"}, {"question": "are these saltwater or freshwater fish", "gt answer": "saltwater(1.00)", "pred answer": "fish", "question_id": 2315425, "best approach": "concept", "verif answer": "saltwater", "anno approach": "wiki, concept, image", "verif wiki answer": "ocean(0.6392)", "verif concept answer": "saltwater(0.7277)", "verif image answer": "salt water(0.5481)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231542.jpg"}, {"question": "what chemical sorrounds these people", "gt answer": "air(1.00)<br/>oxygen(1.00)<br/>bag(0.60)", "pred answer": "oil", "question_id": 2478265, "best approach": "wiki, concept", "verif answer": "air", "anno approach": "wiki, concept, image", "verif wiki answer": "oxygen(0.7233)", "verif concept answer": "oxygen(0.7098)", "verif image answer": "helium(0.6230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247826.jpg"}, {"question": "what type of scissors are these", "gt answer": "safety(0.60)<br/>craft(1.00)", "pred answer": "pair", "question_id": 4451035, "best approach": "image", "verif answer": "stab", "anno approach": "wiki, concept, image", "verif wiki answer": "stab(0.7068)", "verif concept answer": "decor(0.6437)", "verif image answer": "craft(0.7024)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445103.jpg"}, {"question": "what is the machine in the front of the train cars called", "gt answer": "locomotive(1.00)<br/>engine(0.60)<br/>tractor(0.60)", "pred answer": "steam", "question_id": 1639335, "best approach": "concept, image", "verif answer": "tractor", "anno approach": "wiki, concept, image", "verif wiki answer": "cart(0.7199)", "verif concept answer": "tractor(0.7061)", "verif image answer": "engine(0.5634)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163933.jpg"}, {"question": "what type of picture might she be taking", "gt answer": "selfie(1.00)", "pred answer": "canon", "question_id": 4842775, "best approach": "wiki, concept", "verif answer": "selfie", "anno approach": "wiki, concept, image", "verif wiki answer": "selfie(0.6130)", "verif concept answer": "selfie(0.6677)", "verif image answer": "rest(0.5430)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484277.jpg"}, {"question": "what kind of chips are these", "gt answer": "potato(1.00)<br/>ruffle(0.60)", "pred answer": "salmon", "question_id": 2636235, "best approach": "wiki, concept", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "potato(0.6653)", "verif concept answer": "potato(0.6820)", "verif image answer": "cracker(0.6940)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263623.jpg"}, {"question": "what is attached to the truck", "gt answer": "trailer(1.00)", "pred answer": "ladder", "question_id": 784685, "best approach": "", "verif answer": "carriage", "anno approach": "wiki, concept, image", "verif wiki answer": "carriage(0.7127)", "verif concept answer": "carriage(0.7103)", "verif image answer": "camper(0.6359)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078468.jpg"}, {"question": "", "gt answer": "sponsor(0.60)<br/>advertising(0.60)<br/>advertiser(0.60)", "pred answer": "bat", "question_id": 3436915, "best approach": "", "verif answer": "hit ball", "anno approach": "wiki, concept, image", "verif wiki answer": "hit ball(0.6145)", "verif concept answer": "hit ball(0.6552)", "verif image answer": "hit ball(0.6701)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343691.jpg"}, {"question": "what type of cow is that", "gt answer": "angus(1.00)<br/>jersey(0.60)<br/>dairy(0.60)<br/>holstein(0.60)", "pred answer": "dairy cow", "question_id": 5560575, "best approach": "wiki, image", "verif answer": "dairy", "anno approach": "wiki, concept, image", "verif wiki answer": "dairy(0.7083)", "verif concept answer": "milk(0.6421)", "verif image answer": "dairy(0.6771)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556057.jpg"}, {"question": "are these pumpkins or manderines", "gt answer": "manderines(1.00)<br/>pumpkin(0.60)<br/>mandarin(0.60)", "pred answer": "carrot", "question_id": 2235995, "best approach": "wiki, concept, image", "verif answer": "pumpkin", "anno approach": "wiki, concept, image", "verif wiki answer": "pumpkin(0.5677)", "verif concept answer": "pumpkin(0.7171)", "verif image answer": "pumpkin(0.6192)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223599.jpg"}, {"question": "what is the name of this snowboard stunt", "gt answer": "360(1.00)<br/>olly(0.60)<br/>half pipe(0.60)", "pred answer": "jump", "question_id": 5250855, "best approach": "image", "verif answer": "jump", "anno approach": "wiki, concept, image", "verif wiki answer": "flip(0.6700)", "verif concept answer": "flip(0.6870)", "verif image answer": "half pipe(0.6544)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525085.jpg"}, {"question": "what did the boy on the mound do", "gt answer": "pitch(1.00)<br/>throw(0.60)", "pred answer": "hit ball", "question_id": 1559955, "best approach": "", "verif answer": "pitch", "anno approach": "wiki, concept, image", "verif wiki answer": "baseball(0.7277)", "verif concept answer": "baseball(0.7172)", "verif image answer": "baseball(0.5242)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155995.jpg"}, {"question": "what possible events is the aircraft in the picture engaged in", "gt answer": "taxi(1.00)<br/>land(0.60)<br/>takeoff(0.60)", "pred answer": "fly", "question_id": 5297805, "best approach": "", "verif answer": "take off", "anno approach": "wiki, concept, image", "verif wiki answer": "take off(0.7168)", "verif concept answer": "take off(0.6623)", "verif image answer": "take off(0.5974)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529780.jpg"}, {"question": "what baseball teams are playing", "gt answer": "little league(1.00)<br/>kid(0.60)", "pred answer": "dodger", "question_id": 5159285, "best approach": "wiki", "verif answer": "dodger", "anno approach": "wiki, concept, image", "verif wiki answer": "little league(0.7115)", "verif concept answer": "baseball(0.7076)", "verif image answer": "dodger(0.6703)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515928.jpg"}, {"question": "what brand jeans is the woman wearing", "gt answer": "lee(1.00)<br/>denim(0.60)<br/>levi(0.60)", "pred answer": "levis", "question_id": 261325, "best approach": "", "verif answer": "levis", "anno approach": "wiki, concept, image", "verif wiki answer": "levis(0.5921)", "verif concept answer": "levis(0.7048)", "verif image answer": "levis(0.5332)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000026132.jpg"}, {"question": "why are there so many scissors", "gt answer": "artwork(1.00)<br/>art(0.60)", "pred answer": "sew", "question_id": 3911025, "best approach": "wiki", "verif answer": "safety", "anno approach": "wiki, concept, image", "verif wiki answer": "artwork(0.7124)", "verif concept answer": "stopped(0.6705)", "verif image answer": "stopped(0.7003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391102.jpg"}, {"question": "what are displayed on the tv screens", "gt answer": "screensaver(1.00)<br/>screen saver(0.60)", "pred answer": "game", "question_id": 5576785, "best approach": "wiki, concept", "verif answer": "stuffed animal", "anno approach": "wiki, concept, image", "verif wiki answer": "screensaver(0.7030)", "verif concept answer": "screensaver(0.6240)", "verif image answer": "dell(0.5041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557678.jpg"}, {"question": "what type of features does the background animal have", "gt answer": "long neck(1.00)<br/>spot(1.00)", "pred answer": "cracked", "question_id": 3588745, "best approach": "", "verif answer": "cracked", "anno approach": "wiki, concept, image", "verif wiki answer": "be tall(0.7295)", "verif concept answer": "be tall(0.7148)", "verif image answer": "be tall(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358874.jpg"}, {"question": "what kind of plant is sitting closest to the street", "gt answer": "banana(1.00)<br/>aloe(0.60)", "pred answer": "fern", "question_id": 2308645, "best approach": "wiki, concept, image", "verif answer": "bush", "anno approach": "wiki, concept, image", "verif wiki answer": "banana(0.6584)", "verif concept answer": "banana(0.6465)", "verif image answer": "banana(0.7067)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000230864.jpg"}, {"question": "how was this picture made", "gt answer": "puzzle(1.00)", "pred answer": "camera", "question_id": 897535, "best approach": "image", "verif answer": "photoshop", "anno approach": "wiki, concept, image", "verif wiki answer": "photoshop(0.6710)", "verif concept answer": "nicotine(0.6664)", "verif image answer": "puzzle(0.5913)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089753.jpg"}, {"question": "which movie featured a man in this position telling his life story to strangers", "gt answer": "forrest gump(1.00)<br/>forest gump(0.60)", "pred answer": "wizard of oz", "question_id": 5105, "best approach": "wiki, concept", "verif answer": "forrest gump", "anno approach": "wiki, concept, image", "verif wiki answer": "forrest gump(0.6860)", "verif concept answer": "forrest gump(0.7155)", "verif image answer": "1950s(0.7221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000510.jpg"}, {"question": "who is credited with inventing this item", "gt answer": "steve job(1.00)<br/>thomas edison(0.60)<br/>martin cooper(0.60)", "pred answer": "man", "question_id": 54305, "best approach": "wiki, concept", "verif answer": "steve job", "anno approach": "wiki, concept, image", "verif wiki answer": "steve job(0.7304)", "verif concept answer": "steve job(0.7213)", "verif image answer": "martin cooper(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005430.jpg"}, {"question": "what kind of bird is this", "gt answer": "finch(1.00)<br/>pigeon(0.60)<br/>sparrow(0.60)<br/>robin(0.60)", "pred answer": "pelican", "question_id": 2330395, "best approach": "wiki, concept, image", "verif answer": "robin", "anno approach": "wiki, concept, image", "verif wiki answer": "robin(0.6457)", "verif concept answer": "robin(0.7001)", "verif image answer": "robin(0.7042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233039.jpg"}, {"question": "what type of pot is the bread being cooked on", "gt answer": "skillet(1.00)<br/>iron(0.60)<br/>metal(0.60)", "pred answer": "pan", "question_id": 515255, "best approach": "", "verif answer": "steel", "anno approach": "wiki, concept, image", "verif wiki answer": "silver(0.6439)", "verif concept answer": "silver(0.5682)", "verif image answer": "steel(0.5956)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000051525.jpg"}, {"question": "how is the side item cooked", "gt answer": "toasted(1.00)<br/>fast(0.60)", "pred answer": "grilled", "question_id": 5770875, "best approach": "", "verif answer": "fried", "anno approach": "wiki, concept, image", "verif wiki answer": "fried(0.7185)", "verif concept answer": "fried(0.6882)", "verif image answer": "fried(0.6708)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000577087.jpg"}, {"question": "what kind of coat is the skier wearing", "gt answer": "ski jacket(1.00)<br/>ski(0.60)", "pred answer": "peacoat", "question_id": 691695, "best approach": "concept", "verif answer": "ski jacket", "anno approach": "wiki, concept, image", "verif wiki answer": "ski(0.6956)", "verif concept answer": "ski jacket(0.6577)", "verif image answer": "aluminum(0.6586)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069169.jpg"}, {"question": "what does he hope the umpire says after he does this", "gt answer": "strike(1.00)", "pred answer": "home run", "question_id": 200905, "best approach": "", "verif answer": "safe", "anno approach": "wiki, concept, image", "verif wiki answer": "play(0.5102)", "verif concept answer": "landed(0.5523)", "verif image answer": "play(0.5147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020090.jpg"}, {"question": "how does this machine move", "gt answer": "electricity(1.00)<br/>engine(0.60)<br/>track(0.60)", "pred answer": "motor", "question_id": 3697625, "best approach": "wiki", "verif answer": "motor", "anno approach": "wiki, concept, image", "verif wiki answer": "track(0.6805)", "verif concept answer": "cable(0.6444)", "verif image answer": "motor(0.6491)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369762.jpg"}, {"question": "is there a traffic accident causing all this traffic or is it just rush hour", "gt answer": "rush hour(1.00)", "pred answer": "parade", "question_id": 4247055, "best approach": "", "verif answer": "rush hour", "anno approach": "wiki, concept, image", "verif wiki answer": "traffic jam(0.7000)", "verif concept answer": "stop light(0.6539)", "verif image answer": "stop light(0.6771)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424705.jpg"}, {"question": "what kind of people ride in this", "gt answer": "commuter(1.00)<br/>train(0.60)", "pred answer": "passenger", "question_id": 3930865, "best approach": "wiki", "verif answer": "commuter", "anno approach": "wiki, concept, image", "verif wiki answer": "commuter(0.6969)", "verif concept answer": "transportation(0.6313)", "verif image answer": "first(0.6304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393086.jpg"}, {"question": "what profession does this for a living", "gt answer": "computer repair(1.00)", "pred answer": "chef", "question_id": 2828285, "best approach": "", "verif answer": "chef", "anno approach": "wiki, concept, image", "verif wiki answer": "chef(0.6985)", "verif concept answer": "chef(0.6655)", "verif image answer": "chef(0.6837)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282828.jpg"}, {"question": "what is the name of the small purple flowers in this arrangement", "gt answer": "violet(1.00)<br/>lavender(0.60)<br/>rose(0.60)", "pred answer": "tulip", "question_id": 5579875, "best approach": "", "verif answer": "tulip", "anno approach": "wiki, concept, image", "verif wiki answer": "tulip(0.7295)", "verif concept answer": "tulip(0.7281)", "verif image answer": "tulip(0.6112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557987.jpg"}, {"question": "what is the largest one of this type of waterway", "gt answer": "panama canal(1.00)<br/>sea(0.60)<br/>river(0.60)", "pred answer": "canal", "question_id": 2953105, "best approach": "wiki", "verif answer": "canal", "anno approach": "wiki, concept, image", "verif wiki answer": "river(0.6569)", "verif concept answer": "canal(0.6927)", "verif image answer": "canal(0.7007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295310.jpg"}, {"question": "what is the materal these horses are baked with called", "gt answer": "fondant(1.00)<br/>dough(1.00)<br/>clay(0.60)", "pred answer": "frost", "question_id": 4309255, "best approach": "wiki, concept, image", "verif answer": "fondant", "anno approach": "wiki, concept, image", "verif wiki answer": "dough(0.7203)", "verif concept answer": "dough(0.6706)", "verif image answer": "dough(0.7094)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430925.jpg"}, {"question": "what year was this competition held", "gt answer": "2012(1.00)<br/>2004(0.60)", "pred answer": "1965", "question_id": 4107555, "best approach": "", "verif answer": "1965", "anno approach": "wiki, concept, image", "verif wiki answer": "1965(0.6707)", "verif concept answer": "1965(0.6341)", "verif image answer": "2008(0.7084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000410755.jpg"}, {"question": "what event is this person attending", "gt answer": "game convention(1.00)", "pred answer": "game", "question_id": 1570065, "best approach": "", "verif answer": "sport", "anno approach": "wiki, concept, image", "verif wiki answer": "fair(0.6818)", "verif concept answer": "fair(0.6742)", "verif image answer": "fair(0.6108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157006.jpg"}, {"question": "what is the proper equipment for this vehicle", "gt answer": "helmet(1.00)<br/>mirror(0.60)", "pred answer": "motor", "question_id": 3208385, "best approach": "", "verif answer": "helmet", "anno approach": "wiki, concept, image", "verif wiki answer": "hat(0.7237)", "verif concept answer": "reflector(0.7197)", "verif image answer": "ski(0.6455)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320838.jpg"}, {"question": "why are the lens orange on the goggles", "gt answer": "glare(1.00)", "pred answer": "safety", "question_id": 4056055, "best approach": "concept", "verif answer": "sun", "anno approach": "wiki, concept, image", "verif wiki answer": "reflection(0.7005)", "verif concept answer": "glare(0.6614)", "verif image answer": "down(0.6222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405605.jpg"}, {"question": "what type of truck is this", "gt answer": "fedex(1.00)<br/>delivery(0.60)<br/>mail(0.60)", "pred answer": "semi", "question_id": 3392505, "best approach": "image", "verif answer": "trailer", "anno approach": "wiki, concept, image", "verif wiki answer": "trailer(0.7019)", "verif concept answer": "delivery(0.7150)", "verif image answer": "fedex(0.7123)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000339250.jpg"}, {"question": "what style of bicycle is this", "gt answer": "10 speed(1.00)<br/>road(0.60)<br/>mountain(0.60)", "pred answer": "mountain bike", "question_id": 2981825, "best approach": "wiki, concept", "verif answer": "dirt", "anno approach": "wiki, concept, image", "verif wiki answer": "10 speed(0.6806)", "verif concept answer": "10 speed(0.5698)", "verif image answer": "mountain(0.6084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000298182.jpg"}, {"question": "how can this woman keep herself safe while crossing the road", "gt answer": "look both way(1.00)", "pred answer": "hose", "question_id": 2603735, "best approach": "concept", "verif answer": "sidewalk", "anno approach": "wiki, concept, image", "verif wiki answer": "look(0.6977)", "verif concept answer": "look both way(0.6838)", "verif image answer": "look(0.5990)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260373.jpg"}, {"question": "which category of cows are shown in the photo", "gt answer": "dairy(1.00)<br/>bull(0.60)", "pred answer": "dairy cow", "question_id": 1926425, "best approach": "concept", "verif answer": "holstein", "anno approach": "wiki, concept, image", "verif wiki answer": "holstein(0.6199)", "verif concept answer": "bull(0.6774)", "verif image answer": "cow(0.6159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000192642.jpg"}, {"question": "in the office building behind the clock are they more likely to make cell phones or soccer balls", "gt answer": "cell phone(1.00)", "pred answer": "cellphone", "question_id": 4513535, "best approach": "", "verif answer": "cellphone", "anno approach": "wiki, concept, image", "verif wiki answer": "smartphone(0.7222)", "verif concept answer": "iphones(0.6835)", "verif image answer": "smartphone(0.6441)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451353.jpg"}, {"question": "", "gt answer": "light(0.60)<br/>decoration(0.60)<br/>decor(0.60)", "pred answer": "shade", "question_id": 2217396, "best approach": "wiki, concept", "verif answer": "sunlight", "anno approach": "wiki, concept, image", "verif wiki answer": "light(0.5864)", "verif concept answer": "light(0.6255)", "verif image answer": "sunlight(0.5663)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221739.jpg"}, {"question": "what material is the pillow made from", "gt answer": "feather(1.00)<br/>cotton(0.60)<br/>foam(0.60)", "pred answer": "fabric", "question_id": 2222605, "best approach": "wiki, concept", "verif answer": "polyester", "anno approach": "wiki, concept, image", "verif wiki answer": "feather(0.7270)", "verif concept answer": "feather(0.5896)", "verif image answer": "polyester(0.5976)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222260.jpg"}, {"question": "how can we tell no one has used this vehicle in a long time", "gt answer": "rust(1.00)", "pred answer": "clean", "question_id": 3611455, "best approach": "wiki", "verif answer": "oxidation", "anno approach": "wiki, concept, image", "verif wiki answer": "rust(0.5969)", "verif concept answer": "dye(0.6373)", "verif image answer": "oxidation(0.5698)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361145.jpg"}, {"question": "what company created the shoes the person is wearing", "gt answer": "converse(1.00)<br/>van(1.00)", "pred answer": "nike", "question_id": 3132135, "best approach": "wiki, concept, image", "verif answer": "nike", "anno approach": "wiki, concept, image", "verif wiki answer": "converse(0.7212)", "verif concept answer": "converse(0.6336)", "verif image answer": "van(0.5057)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313213.jpg"}, {"question": "what type of charger would this phone require", "gt answer": "usb(1.00)<br/>samsung(0.60)", "pred answer": "text", "question_id": 186835, "best approach": "", "verif answer": "electric", "anno approach": "wiki, concept, image", "verif wiki answer": "iphone(0.6964)", "verif concept answer": "electric(0.5969)", "verif image answer": "iphone(0.7237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000018683.jpg"}, {"question": "what happened to doris", "gt answer": "died(1.00)", "pred answer": "fell", "question_id": 5596575, "best approach": "wiki, concept", "verif answer": "died", "anno approach": "wiki, concept, image", "verif wiki answer": "died(0.7249)", "verif concept answer": "died(0.6941)", "verif image answer": "fire(0.5109)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559657.jpg"}, {"question": "is this a river creek stream or lake", "gt answer": "river(1.00)<br/>stream(0.60)", "pred answer": "lake", "question_id": 796065, "best approach": "image", "verif answer": "lake", "anno approach": "wiki, concept, image", "verif wiki answer": "lake(0.7223)", "verif concept answer": "lake(0.6950)", "verif image answer": "river(0.7267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079606.jpg"}, {"question": "what breed is this bird", "gt answer": "seagull(1.00)", "pred answer": "pelican", "question_id": 3080735, "best approach": "wiki, concept", "verif answer": "pelican", "anno approach": "wiki, concept, image", "verif wiki answer": "seagull(0.6836)", "verif concept answer": "seagull(0.7002)", "verif image answer": "pelican(0.6786)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308073.jpg"}, {"question": "what breed of cats are these", "gt answer": "siamese(1.00)<br/>domestic shorthair(0.60)", "pred answer": "domestic", "question_id": 944445, "best approach": "image", "verif answer": "domestic", "anno approach": "wiki, concept, image", "verif wiki answer": "domestic(0.6556)", "verif concept answer": "domestic(0.6924)", "verif image answer": "siamese(0.5651)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094444.jpg"}, {"question": "who is this tennis player", "gt answer": "rafael nadal(1.00)<br/>man(0.60)<br/>federer(0.60)", "pred answer": "roger federer", "question_id": 2331115, "best approach": "wiki, concept", "verif answer": "roger federer", "anno approach": "wiki, concept, image", "verif wiki answer": "rafael nadal(0.7244)", "verif concept answer": "rafael nadal(0.5335)", "verif image answer": "roger federer(0.5012)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233111.jpg"}, {"question": "what happens when a car reaches this sign", "gt answer": "turn(1.00)<br/>it turn(1.00)<br/>drive(0.60)", "pred answer": "stopped", "question_id": 4354355, "best approach": "", "verif answer": "turn", "anno approach": "wiki, concept, image", "verif wiki answer": "direction(0.7017)", "verif concept answer": "direction(0.6544)", "verif image answer": "direction(0.6773)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435435.jpg"}, {"question": "was this bed made by the owner or by a factory", "gt answer": "factory(1.00)<br/>owner(1.00)", "pred answer": "store", "question_id": 4365085, "best approach": "wiki, concept, image", "verif answer": "home", "anno approach": "wiki, concept, image", "verif wiki answer": "owner(0.6444)", "verif concept answer": "owner(0.6132)", "verif image answer": "owner(0.7156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436508.jpg"}, {"question": "how is the umbrella in the photo unusual", "gt answer": "clear(1.00)<br/>black and white(0.60)", "pred answer": "wind", "question_id": 819035, "best approach": "image", "verif answer": "black and white", "anno approach": "wiki, concept, image", "verif wiki answer": "wide angle(0.7239)", "verif concept answer": "wide angle(0.6348)", "verif image answer": "clear(0.6869)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081903.jpg"}, {"question": "why is the water in this photo not blue", "gt answer": "algae(1.00)", "pred answer": "ocean", "question_id": 4341935, "best approach": "concept, image", "verif answer": "algae", "anno approach": "wiki, concept, image", "verif wiki answer": "reflection of sky(0.7207)", "verif concept answer": "algae(0.7163)", "verif image answer": "algae(0.7257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434193.jpg"}, {"question": "what is the art form made by this", "gt answer": "collage(1.00)", "pred answer": "paint", "question_id": 4475885, "best approach": "", "verif answer": "art", "anno approach": "wiki, concept, image", "verif wiki answer": "art(0.7099)", "verif concept answer": "van gogh(0.6714)", "verif image answer": "van gogh(0.5736)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447588.jpg"}, {"question": "what kind off vitamins do you get from this vegetable", "gt answer": "b(1.00)<br/>c(0.60)", "pred answer": "vitamin", "question_id": 723705, "best approach": "image", "verif answer": "", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin c(0.6989)", "verif concept answer": "vitamin c(0.7143)", "verif image answer": "c(0.5197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072370.jpg"}, {"question": "what habitat is this animal most commonly found in", "gt answer": "savannah(1.00)<br/>zoo(0.60)<br/>tropical(0.60)", "pred answer": "plain", "question_id": 36685, "best approach": "image", "verif answer": "plain", "anno approach": "wiki, concept, image", "verif wiki answer": "tropical(0.7114)", "verif concept answer": "grassland(0.7125)", "verif image answer": "savannah(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003668.jpg"}, {"question": "are these flowers annuals or perannuals", "gt answer": "annual(1.00)", "pred answer": "", "question_id": 4548985, "best approach": "image", "verif answer": "annual", "anno approach": "wiki, concept, image", "verif wiki answer": "same(0.6110)", "verif concept answer": "same(0.5876)", "verif image answer": "annual(0.5183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000454898.jpg"}, {"question": "what are the meters used for", "gt answer": "park(1.00)", "pred answer": "park meter", "question_id": 2148705, "best approach": "wiki", "verif answer": "park meter", "anno approach": "wiki, concept, image", "verif wiki answer": "park(0.6475)", "verif concept answer": "skatepark(0.7167)", "verif image answer": "park meter(0.5263)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214870.jpg"}, {"question": "what newspaper is this woman looking at", "gt answer": "new york time(1.00)<br/>new york(0.60)", "pred answer": "magazine", "question_id": 2603815, "best approach": "", "verif answer": "better home", "anno approach": "wiki, concept, image", "verif wiki answer": "amazon(0.7010)", "verif concept answer": "better home(0.6090)", "verif image answer": "amazon(0.5637)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260381.jpg"}, {"question": "what breed of horse is shown", "gt answer": "clydesdale(1.00)", "pred answer": "stallion", "question_id": 1349585, "best approach": "", "verif answer": "stallion", "anno approach": "wiki, concept, image", "verif wiki answer": "pony(0.7250)", "verif concept answer": "stallion(0.7027)", "verif image answer": "stallion(0.6798)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134958.jpg"}, {"question": "what is the man reading", "gt answer": "newspaper(1.00)<br/>magazine(0.60)", "pred answer": "bowl", "question_id": 1385215, "best approach": "wiki", "verif answer": "magazine", "anno approach": "wiki, concept, image", "verif wiki answer": "magazine(0.6736)", "verif concept answer": "sit(0.6816)", "verif image answer": "sit(0.7218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138521.jpg"}, {"question": "how many teeth do these animals have in their mouth", "gt answer": "32(1.00)<br/>30(0.60)", "pred answer": "7", "question_id": 1038655, "best approach": "image", "verif answer": "30", "anno approach": "wiki, concept, image", "verif wiki answer": "50(0.6989)", "verif concept answer": "20(0.5844)", "verif image answer": "32(0.6623)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103865.jpg"}, {"question": "where would you find snapshots like these posted", "gt answer": "facebook(1.00)<br/>hotel(0.60)", "pred answer": "store", "question_id": 5298865, "best approach": "wiki, image", "verif answer": "facebook", "anno approach": "wiki, concept, image", "verif wiki answer": "facebook(0.6721)", "verif concept answer": "home(0.6748)", "verif image answer": "facebook(0.6642)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529886.jpg"}, {"question": "where are these animals", "gt answer": "farm(1.00)", "pred answer": "stable", "question_id": 5024855, "best approach": "wiki", "verif answer": "farm", "anno approach": "wiki, concept, image", "verif wiki answer": "farm(0.7089)", "verif concept answer": "horse(0.6523)", "verif image answer": "horse(0.6005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502485.jpg"}, {"question": "the what chemical makes the vegetable orange", "gt answer": "beta carotene(1.00)<br/>c(0.60)<br/>chlorophyll(0.60)", "pred answer": "yeast", "question_id": 4394455, "best approach": "wiki", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "chlorophyll(0.7223)", "verif concept answer": "orange(0.6910)", "verif image answer": "(0.6194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439445.jpg"}, {"question": "what shape is quesadilla", "gt answer": "triangle(1.00)", "pred answer": "round", "question_id": 991395, "best approach": "", "verif answer": "diamond", "anno approach": "wiki, concept, image", "verif wiki answer": "in half(0.5998)", "verif concept answer": "in half(0.6611)", "verif image answer": "diamond(0.6921)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099139.jpg"}, {"question": "what is the name of this person onscreen", "gt answer": "dexter(1.00)", "pred answer": "actor", "question_id": 3470555, "best approach": "", "verif answer": "barack obama", "anno approach": "wiki, concept, image", "verif wiki answer": "right(0.6043)", "verif concept answer": "barack obama(0.5869)", "verif image answer": "fowler(0.5041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347055.jpg"}, {"question": "what could someone drink in the left object besides coffee", "gt answer": "tea(1.00)", "pred answer": "coffee", "question_id": 2306505, "best approach": "image", "verif answer": "coffee", "anno approach": "wiki, concept, image", "verif wiki answer": "coffee(0.7030)", "verif concept answer": "beer(0.6506)", "verif image answer": "tea(0.7036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000230650.jpg"}, {"question": "is this veggies or fruit", "gt answer": "veggies(1.00)", "pred answer": "fruit", "question_id": 797925, "best approach": "concept", "verif answer": "vegetable", "anno approach": "wiki, concept, image", "verif wiki answer": "vegetable(0.7087)", "verif concept answer": "veggies(0.7113)", "verif image answer": "leaf(0.6843)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079792.jpg"}, {"question": "what part is missing on this bus", "gt answer": "front(1.00)<br/>grill(0.60)", "pred answer": "back", "question_id": 1106585, "best approach": "wiki", "verif answer": "back", "anno approach": "wiki, concept, image", "verif wiki answer": "front(0.7111)", "verif concept answer": "grill(0.6435)", "verif image answer": "left(0.6577)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000110658.jpg"}, {"question": "which item of sci fi fame is purported to look like this object", "gt answer": "ufo(1.00)", "pred answer": "frisbee", "question_id": 482575, "best approach": "", "verif answer": "frisbee", "anno approach": "wiki, concept, image", "verif wiki answer": "catch(0.7219)", "verif concept answer": "frisbee(0.6777)", "verif image answer": "catch(0.5768)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048257.jpg"}, {"question": "what year did this man win the election", "gt answer": "2008(1.00)<br/>2004(1.00)", "pred answer": "1965", "question_id": 296395, "best approach": "wiki, concept", "verif answer": "2000", "anno approach": "wiki, concept, image", "verif wiki answer": "2004(0.7106)", "verif concept answer": "2004(0.6519)", "verif image answer": "2010(0.6500)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029639.jpg"}, {"question": "what type of board are they people on", "gt answer": "surf(1.00)<br/>surf board(1.00)", "pred answer": "surfboard", "question_id": 1682945, "best approach": "wiki, concept, image", "verif answer": "surfboard", "anno approach": "wiki, concept, image", "verif wiki answer": "surf(0.7302)", "verif concept answer": "surf(0.7200)", "verif image answer": "surf(0.7183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168294.jpg"}, {"question": "what made those stains", "gt answer": "grease(1.00)", "pred answer": "heat", "question_id": 2878725, "best approach": "", "verif answer": "ketchup", "anno approach": "wiki, concept, image", "verif wiki answer": "linseed(0.6373)", "verif concept answer": "linseed(0.7021)", "verif image answer": "ketchup(0.5555)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287872.jpg"}, {"question": "where is this", "gt answer": "high school(1.00)<br/>arizona(0.60)<br/>grand canyon(0.60)", "pred answer": "colorado", "question_id": 4887645, "best approach": "wiki, concept, image", "verif answer": "america", "anno approach": "wiki, concept, image", "verif wiki answer": "grand canyon(0.7019)", "verif concept answer": "grand canyon(0.7234)", "verif image answer": "arizona(0.6698)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488764.jpg"}, {"question": "why would one suspect that this is not chicago", "gt answer": "sign(1.00)", "pred answer": "light", "question_id": 3365805, "best approach": "", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "street sign(0.6451)", "verif concept answer": "street sign(0.6929)", "verif image answer": "street sign(0.6819)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000336580.jpg"}, {"question": "about what time of the day is this", "gt answer": "noon(1.00)<br/>afternoon(1.00)", "pred answer": "morn", "question_id": 241075, "best approach": "wiki", "verif answer": "morn", "anno approach": "wiki, concept, image", "verif wiki answer": "afternoon(0.7055)", "verif concept answer": "lunch(0.6797)", "verif image answer": "lunch(0.6214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024107.jpg"}, {"question": "what kind of event is happening", "gt answer": "speech(1.00)<br/>award(0.60)", "pred answer": "press conference", "question_id": 1936545, "best approach": "", "verif answer": "press conference", "anno approach": "wiki, concept, image", "verif wiki answer": "press conference(0.7282)", "verif concept answer": "press conference(0.7279)", "verif image answer": "press conference(0.7079)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193654.jpg"}, {"question": "who is taking the picture of this bathroom", "gt answer": "owner(1.00)", "pred answer": "maid", "question_id": 1871575, "best approach": "concept", "verif answer": "factory", "anno approach": "wiki, concept, image", "verif wiki answer": "factory(0.6491)", "verif concept answer": "owner(0.6378)", "verif image answer": "master(0.6878)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187157.jpg"}, {"question": "what type of animal do the two large kites look like", "gt answer": "stingray(1.00)<br/>dragon(0.60)<br/>bird(0.60)", "pred answer": "octopus", "question_id": 17855, "best approach": "wiki, image", "verif answer": "octopus", "anno approach": "wiki, concept, image", "verif wiki answer": "bird(0.7122)", "verif concept answer": "octopus(0.7080)", "verif image answer": "bird(0.6318)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001785.jpg"}, {"question": "what is the processor used in this laptop", "gt answer": "intel(1.00)", "pred answer": "camera", "question_id": 3412055, "best approach": "image", "verif answer": "intel", "anno approach": "wiki, concept, image", "verif wiki answer": "hp(0.7255)", "verif concept answer": "hp(0.6770)", "verif image answer": "intel(0.6558)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341205.jpg"}, {"question": "what is this vehicle used for", "gt answer": "fly(1.00)<br/>fight(0.60)<br/>cargo(0.60)", "pred answer": "fuel", "question_id": 2508805, "best approach": "image", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "fight(0.7016)", "verif concept answer": "fight(0.7108)", "verif image answer": "fly(0.6444)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250880.jpg"}, {"question": "how would you describe these animals eating style", "gt answer": "graze(1.00)<br/>slow(0.60)", "pred answer": "grilled", "question_id": 1492535, "best approach": "wiki, image", "verif answer": "herd", "anno approach": "wiki, concept, image", "verif wiki answer": "graze(0.6723)", "verif concept answer": "herd(0.6200)", "verif image answer": "graze(0.6981)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149253.jpg"}, {"question": "what country is this building located in", "gt answer": "belgium(1.00)<br/>england(0.60)", "pred answer": "london", "question_id": 2486015, "best approach": "concept", "verif answer": "england", "anno approach": "wiki, concept, image", "verif wiki answer": "england(0.6939)", "verif concept answer": "belgium(0.6821)", "verif image answer": "united state(0.5616)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248601.jpg"}, {"question": "who do these beautiful bottles do", "gt answer": "hold flower(1.00)<br/>hold thing(0.60)", "pred answer": "chinese", "question_id": 3486165, "best approach": "concept", "verif answer": "decoration", "anno approach": "wiki, concept, image", "verif wiki answer": "decoration(0.5677)", "verif concept answer": "hold flower(0.7013)", "verif image answer": "tell time(0.5587)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348616.jpg"}, {"question": "what general material is the statue made of", "gt answer": "bronze(1.00)<br/>metal(0.60)<br/>stone(0.60)<br/>copper(0.60)", "pred answer": "steel", "question_id": 652205, "best approach": "wiki", "verif answer": "copper", "anno approach": "wiki, concept, image", "verif wiki answer": "bronze(0.7041)", "verif concept answer": "metal(0.6738)", "verif image answer": "metal(0.6213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065220.jpg"}, {"question": "what time of day does it appear to be in this photo", "gt answer": "even(1.00)<br/>dusk(1.00)<br/>dawn(0.60)", "pred answer": "morn", "question_id": 635405, "best approach": "", "verif answer": "sunrise", "anno approach": "wiki, concept, image", "verif wiki answer": "sunrise(0.6421)", "verif concept answer": "sunset(0.6647)", "verif image answer": "sunset(0.5593)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063540.jpg"}, {"question": "are they eating inside or outside", "gt answer": "outside(1.00)", "pred answer": "outdoor", "question_id": 2510495, "best approach": "wiki, concept", "verif answer": "outside", "anno approach": "wiki, concept, image", "verif wiki answer": "outside(0.6571)", "verif concept answer": "outside(0.6203)", "verif image answer": "cafe(0.5341)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251049.jpg"}, {"question": "what is the lady inserting coins into", "gt answer": "park meter(1.00)<br/>meter(0.60)", "pred answer": "case", "question_id": 4666155, "best approach": "concept, image", "verif answer": "coin", "anno approach": "wiki, concept, image", "verif wiki answer": "coin(0.6960)", "verif concept answer": "meter(0.6574)", "verif image answer": "meter(0.7219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466615.jpg"}, {"question": "what is the top speed of this train", "gt answer": "300 mph(1.00)<br/>150(0.60)<br/>120 mph(0.60)<br/>100(0.60)", "pred answer": "100 mph", "question_id": 5034075, "best approach": "concept", "verif answer": "300 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "120 mph(0.6260)", "verif concept answer": "300 mph(0.6702)", "verif image answer": "150(0.7049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503407.jpg"}, {"question": "what kind of jet is that", "gt answer": "fighter(1.00)", "pred answer": "fighter jet", "question_id": 5465945, "best approach": "concept", "verif answer": "fighter", "anno approach": "wiki, concept, image", "verif wiki answer": "jet(0.6936)", "verif concept answer": "fighter(0.6405)", "verif image answer": "jet(0.6031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546594.jpg"}, {"question": "note the most dominant color in the photo what continent is known for being this color", "gt answer": "antarctica(1.00)<br/>red(0.60)<br/>grey(0.60)", "pred answer": "white", "question_id": 423085, "best approach": "wiki, concept, image", "verif answer": "white", "anno approach": "wiki, concept, image", "verif wiki answer": "antarctica(0.7031)", "verif concept answer": "antarctica(0.7109)", "verif image answer": "antarctica(0.7246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042308.jpg"}, {"question": "where style skateboard is this skateboard", "gt answer": "longboard(1.00)<br/>long board(1.00)<br/>kid(0.60)", "pred answer": "street", "question_id": 394955, "best approach": "concept, image", "verif answer": "standard", "anno approach": "wiki, concept, image", "verif wiki answer": "kid(0.6716)", "verif concept answer": "longboard(0.6775)", "verif image answer": "longboard(0.7000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039495.jpg"}, {"question": "what decade is depicted in the image", "gt answer": "1950's(1.00)<br/>tour bus(0.60)<br/>1950s(0.60)", "pred answer": "1800's", "question_id": 2362675, "best approach": "wiki, image", "verif answer": "70's", "anno approach": "wiki, concept, image", "verif wiki answer": "1950s(0.5807)", "verif concept answer": "70's(0.6286)", "verif image answer": "tour bus(0.6328)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236267.jpg"}, {"question": "what racing series do these motorcycles particiapte in", "gt answer": "hertz(1.00)<br/>motocross(0.60)<br/>motorcycle(0.60)", "pred answer": "hell angel", "question_id": 4310125, "best approach": "wiki, concept, image", "verif answer": "motorcycle", "anno approach": "wiki, concept, image", "verif wiki answer": "motorcycle(0.6015)", "verif concept answer": "motorcycle(0.6190)", "verif image answer": "motocross(0.5565)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431012.jpg"}, {"question": "what show is named after this animal", "gt answer": "my little pony(1.00)<br/>horse race(0.60)<br/>mule(0.60)", "pred answer": "horse", "question_id": 5129185, "best approach": "wiki, concept, image", "verif answer": "horse", "anno approach": "wiki, concept, image", "verif wiki answer": "mule(0.6423)", "verif concept answer": "mule(0.6288)", "verif image answer": "mule(0.5210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512918.jpg"}, {"question": "what crime are those people committing", "gt answer": "jaywalk(1.00)<br/>speed(0.60)<br/>0(0.60)", "pred answer": "traffic", "question_id": 2624775, "best approach": "wiki", "verif answer": "speed", "anno approach": "wiki, concept, image", "verif wiki answer": "jaywalk(0.7045)", "verif concept answer": "speed(0.6369)", "verif image answer": "speed(0.6694)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262477.jpg"}, {"question": "what items can be replaced on this dish to make it more healthy", "gt answer": "bacon(1.00)<br/>potato(0.60)<br/>meat(0.60)", "pred answer": "egg", "question_id": 1114555, "best approach": "wiki, concept, image", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "meat(0.7045)", "verif concept answer": "meat(0.7188)", "verif image answer": "meat(0.6396)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111455.jpg"}, {"question": "what type of drinks do hikers need while in colder climates", "gt answer": "warm(1.00)<br/>hot(1.00)", "pred answer": "beer", "question_id": 728095, "best approach": "", "verif answer": "warm", "anno approach": "wiki, concept, image", "verif wiki answer": "sunny(0.6297)", "verif concept answer": "sunny(0.6431)", "verif image answer": "sunny(0.6573)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072809.jpg"}, {"question": "what is the object in front of the chair used for", "gt answer": "foot rest(1.00)<br/>leg(0.60)<br/>rest(0.60)", "pred answer": "sew", "question_id": 2411485, "best approach": "wiki", "verif answer": "relax", "anno approach": "wiki, concept, image", "verif wiki answer": "leg(0.6890)", "verif concept answer": "relax(0.6900)", "verif image answer": "brush(0.6930)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241148.jpg"}, {"question": "what device is that", "gt answer": "pager(1.00)<br/>calculator(0.60)<br/>remote(0.60)", "pred answer": "cell phone", "question_id": 2089675, "best approach": "wiki, concept, image", "verif answer": "take picture", "anno approach": "wiki, concept, image", "verif wiki answer": "calculator(0.6815)", "verif concept answer": "calculator(0.5522)", "verif image answer": "calculator(0.6078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208967.jpg"}, {"question": "what kind of bird is pictured", "gt answer": "dove(1.00)<br/>pigeon(0.60)<br/>sparrow(0.60)", "pred answer": "hawk", "question_id": 3337385, "best approach": "concept", "verif answer": "sparrow", "anno approach": "wiki, concept, image", "verif wiki answer": "finch(0.7007)", "verif concept answer": "dove(0.7188)", "verif image answer": "pigeon(0.7218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333738.jpg"}, {"question": "", "gt answer": "seed(0.60)<br/>fertalization(0.60)<br/>oxygen(0.60)", "pred answer": "tusk", "question_id": 4701965, "best approach": "wiki, concept, image", "verif answer": "oxygen", "anno approach": "wiki, concept, image", "verif wiki answer": "fertalization(0.5156)", "verif concept answer": "oxygen(0.5185)", "verif image answer": "seed(0.5010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470196.jpg"}, {"question": "what kind of boat is in this photo", "gt answer": "sail(1.00)<br/>surf(0.60)<br/>surfboard(0.60)", "pred answer": "sailboat", "question_id": 1289725, "best approach": "", "verif answer": "sailboat", "anno approach": "wiki, concept, image", "verif wiki answer": "surf board(0.7153)", "verif concept answer": "sailboat(0.6975)", "verif image answer": "sailboat(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128972.jpg"}, {"question": "which item is associated with a place famous for a presumed laid back frame of mind", "gt answer": "weed(1.00)<br/>luggage(0.60)<br/>suitcase(0.60)", "pred answer": "tattoo", "question_id": 5198675, "best approach": "wiki, concept, image", "verif answer": "suitcase", "anno approach": "wiki, concept, image", "verif wiki answer": "weed(0.7182)", "verif concept answer": "weed(0.6343)", "verif image answer": "weed(0.5766)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000519867.jpg"}, {"question": "what is the purpose of the long thin object that the man in the black shirt is holding", "gt answer": "hit(1.00)<br/>hit baseball(0.60)<br/>hit ball(0.60)", "pred answer": "bat", "question_id": 964145, "best approach": "wiki, concept, image", "verif answer": "hit ball", "anno approach": "wiki, concept, image", "verif wiki answer": "hit ball(0.7280)", "verif concept answer": "hit ball(0.7255)", "verif image answer": "hit ball(0.6789)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096414.jpg"}, {"question": "what does it look like this toy dog is doing", "gt answer": "use laptop(1.00)<br/>view(0.60)", "pred answer": "play", "question_id": 1636835, "best approach": "concept", "verif answer": "herd", "anno approach": "wiki, concept, image", "verif wiki answer": "nest(0.7189)", "verif concept answer": "use laptop(0.6672)", "verif image answer": "wash it(0.5690)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163683.jpg"}, {"question": "what item will change soon in this picture", "gt answer": "picture(1.00)<br/>screen(0.60)<br/>cat(0.60)<br/>tv(0.60)", "pred answer": "light", "question_id": 2401555, "best approach": "wiki, concept, image", "verif answer": "tv", "anno approach": "wiki, concept, image", "verif wiki answer": "tv(0.6184)", "verif concept answer": "tv(0.6852)", "verif image answer": "screen(0.6491)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240155.jpg"}, {"question": "what type of industry do those trucks work in", "gt answer": "log(1.00)<br/>lumber(0.60)", "pred answer": "construction", "question_id": 3002075, "best approach": "wiki", "verif answer": "lumber", "anno approach": "wiki, concept, image", "verif wiki answer": "log(0.7123)", "verif concept answer": "bamboo(0.7192)", "verif image answer": "lumber(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300207.jpg"}, {"question": "what type of hat is the teddy bear wearing", "gt answer": "bonnet(1.00)", "pred answer": "beanie", "question_id": 1297715, "best approach": "image", "verif answer": "hat", "anno approach": "wiki, concept, image", "verif wiki answer": "bow tie(0.7259)", "verif concept answer": "bow tie(0.7142)", "verif image answer": "bonnet(0.6486)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129771.jpg"}, {"question": "what company runs the bus", "gt answer": "greenwave(1.00)", "pred answer": "greyhound", "question_id": 5731915, "best approach": "wiki, image", "verif answer": "schwinn", "anno approach": "wiki, concept, image", "verif wiki answer": "greenwave(0.6933)", "verif concept answer": "schwinn(0.7206)", "verif image answer": "greenwave(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000573191.jpg"}, {"question": "how do you clean this type of fabric", "gt answer": "soap and water(1.00)<br/>brush(0.60)", "pred answer": "vacuum", "question_id": 1235825, "best approach": "image", "verif answer": "brush", "anno approach": "wiki, concept, image", "verif wiki answer": "hand(0.7268)", "verif concept answer": "hand(0.7083)", "verif image answer": "brush(0.5386)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123582.jpg"}, {"question": "what kind of architecture is this", "gt answer": "victorian(1.00)<br/>roman(0.60)<br/>stone(0.60)", "pred answer": "gothic", "question_id": 2106865, "best approach": "", "verif answer": "gothic", "anno approach": "wiki, concept, image", "verif wiki answer": "gothic(0.7195)", "verif concept answer": "gothic(0.7128)", "verif image answer": "floral(0.5753)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210686.jpg"}, {"question": "what type of gun does this police man carry", "gt answer": "9mm(1.00)", "pred answer": "diesel", "question_id": 4053165, "best approach": "", "verif answer": "harley", "anno approach": "wiki, concept, image", "verif wiki answer": "free(0.6932)", "verif concept answer": "free(0.6975)", "verif image answer": "harley(0.7018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405316.jpg"}, {"question": "what musical instrument is on the left", "gt answer": "guitar(1.00)", "pred answer": "piano", "question_id": 5432765, "best approach": "concept", "verif answer": "guitar", "anno approach": "wiki, concept, image", "verif wiki answer": "pipe(0.5730)", "verif concept answer": "guitar(0.6607)", "verif image answer": "bicycle(0.6387)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543276.jpg"}, {"question": "how much do these objects weigh", "gt answer": "20 pounds(1.00)<br/>50(0.60)<br/>100 lbs(0.60)", "pred answer": "ton", "question_id": 2499685, "best approach": "image", "verif answer": "10 pounds", "anno approach": "wiki, concept, image", "verif wiki answer": "10 pounds(0.6862)", "verif concept answer": "10 pounds(0.5812)", "verif image answer": "20 pounds(0.5581)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249968.jpg"}, {"question": "which breed of apple is this", "gt answer": "gala(1.00)<br/>fuji(0.60)", "pred answer": "granny smith", "question_id": 4811655, "best approach": "image", "verif answer": "granny smith", "anno approach": "wiki, concept, image", "verif wiki answer": "granny smith(0.7297)", "verif concept answer": "granny smith(0.7290)", "verif image answer": "fuji(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481165.jpg"}, {"question": "what kind of skiing is this", "gt answer": "downhill(1.00)<br/>slalom(0.60)<br/>race(0.60)", "pred answer": "cross country", "question_id": 3764905, "best approach": "image", "verif answer": "cross country", "anno approach": "wiki, concept, image", "verif wiki answer": "cross country(0.7306)", "verif concept answer": "cross country(0.7288)", "verif image answer": "downhill(0.6224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376490.jpg"}, {"question": "what is usually displayed on the large white object in the foreground of the picture", "gt answer": "name(1.00)<br/>project(0.60)<br/>flag(0.60)", "pred answer": "map", "question_id": 3862675, "best approach": "concept", "verif answer": "sun", "anno approach": "wiki, concept, image", "verif wiki answer": "project(0.6732)", "verif concept answer": "name(0.6515)", "verif image answer": "project(0.6720)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000386267.jpg"}, {"question": "who holds the record for this activity of this sport", "gt answer": "barry bond(1.00)", "pred answer": "babe ruth", "question_id": 2524705, "best approach": "", "verif answer": "babe ruth", "anno approach": "wiki, concept, image", "verif wiki answer": "babe ruth(0.7277)", "verif concept answer": "babe ruth(0.7197)", "verif image answer": "babe ruth(0.6809)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252470.jpg"}, {"question": "what is special about this player' 's arm", "gt answer": "broken(1.00)", "pred answer": "run with scissor", "question_id": 880875, "best approach": "concept", "verif answer": "swing", "anno approach": "wiki, concept, image", "verif wiki answer": "art(0.5844)", "verif concept answer": "broken(0.5573)", "verif image answer": "art(0.6752)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088087.jpg"}, {"question": "how much does this animal weigh when it is born", "gt answer": "100 lbs(1.00)", "pred answer": "500 pounds", "question_id": 1905515, "best approach": "wiki, concept, image", "verif answer": "ton", "anno approach": "wiki, concept, image", "verif wiki answer": "100 lbs(0.7113)", "verif concept answer": "100 lbs(0.6980)", "verif image answer": "100 lbs(0.6888)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190551.jpg"}, {"question": "what is the type of building in this picture", "gt answer": "cabin(1.00)<br/>garage(0.60)<br/>shed(0.60)", "pred answer": "lighthouse", "question_id": 590935, "best approach": "wiki, concept, image", "verif answer": "grand canyon", "anno approach": "wiki, concept, image", "verif wiki answer": "shed(0.6484)", "verif concept answer": "garage(0.6205)", "verif image answer": "shed(0.6798)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059093.jpg"}, {"question": "what are you suppose to never do with the image in this picture", "gt answer": "run(1.00)<br/>run with scissor(0.60)", "pred answer": "cut", "question_id": 4355435, "best approach": "", "verif answer": "hit", "anno approach": "wiki, concept, image", "verif wiki answer": "play dead(0.7035)", "verif concept answer": "fun(0.7209)", "verif image answer": "play dead(0.6680)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435543.jpg"}, {"question": "how much longer will these flowers live", "gt answer": "2 days(1.00)<br/>5 days(0.60)<br/>week(0.60)", "pred answer": "3 days", "question_id": 4456895, "best approach": "image", "verif answer": "2 weeks", "anno approach": "wiki, concept, image", "verif wiki answer": "2 weeks(0.6257)", "verif concept answer": "1 month(0.6000)", "verif image answer": "week(0.5657)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445689.jpg"}, {"question": "which kind of rope is used around the neck of dog shown in this photo", "gt answer": "leash(1.00)<br/>nylon(0.60)<br/>leather(0.60)", "pred answer": "collar", "question_id": 584375, "best approach": "wiki, image", "verif answer": "leash", "anno approach": "wiki, concept, image", "verif wiki answer": "leash(0.7062)", "verif concept answer": "plastic(0.6551)", "verif image answer": "leash(0.6841)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058437.jpg"}, {"question": "what is the age of the girl sitting on the ground in the teal green dress", "gt answer": "17(1.00)<br/>16(0.60)<br/>18(0.60)<br/>12(0.60)", "pred answer": "21", "question_id": 4049906, "best approach": "wiki, concept, image", "verif answer": "12", "anno approach": "wiki, concept, image", "verif wiki answer": "18(0.7062)", "verif concept answer": "12(0.6046)", "verif image answer": "18(0.6005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404990.jpg"}, {"question": "what photo technique is being used", "gt answer": "sephia(1.00)<br/>filter(0.60)", "pred answer": "black and white", "question_id": 5520925, "best approach": "wiki", "verif answer": "black and white", "anno approach": "wiki, concept, image", "verif wiki answer": "sephia(0.6908)", "verif concept answer": "black and white(0.6767)", "verif image answer": "filter(0.6889)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552092.jpg"}, {"question": "what is this girl 's favorite disney movie", "gt answer": "cinderella(1.00)", "pred answer": "dumbo", "question_id": 3249525, "best approach": "", "verif answer": "mickey mouse", "anno approach": "wiki, concept, image", "verif wiki answer": "mickey mouse(0.7272)", "verif concept answer": "mickey mouse(0.6532)", "verif image answer": "disney(0.7190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324952.jpg"}, {"question": "what movie character is represented", "gt answer": "gandalf(1.00)", "pred answer": "mickey mouse", "question_id": 1744065, "best approach": "wiki, concept", "verif answer": "despicable me", "anno approach": "wiki, concept, image", "verif wiki answer": "gandalf(0.7247)", "verif concept answer": "gandalf(0.7288)", "verif image answer": "despicable me(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174406.jpg"}, {"question": "what does the toilet lid say", "gt answer": "dirty(1.00)", "pred answer": "toilet", "question_id": 4793575, "best approach": "image", "verif answer": "down", "anno approach": "wiki, concept, image", "verif wiki answer": "down(0.7163)", "verif concept answer": "down(0.7234)", "verif image answer": "dirty(0.7198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479357.jpg"}, {"question": "what does this walking sign mean", "gt answer": "safe to cross(1.00)<br/>stop(0.60)", "pred answer": "street name", "question_id": 162095, "best approach": "concept, image", "verif answer": "direct", "anno approach": "wiki, concept, image", "verif wiki answer": "direct(0.6126)", "verif concept answer": "safe to cross(0.6028)", "verif image answer": "safe to cross(0.6476)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016209.jpg"}, {"question": "where could you borrow the object on the bed from", "gt answer": "library(1.00)<br/>play(0.60)", "pred answer": "china", "question_id": 5298275, "best approach": "wiki", "verif answer": "library", "anno approach": "wiki, concept, image", "verif wiki answer": "library(0.6866)", "verif concept answer": "hospital(0.6432)", "verif image answer": "student(0.5435)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529827.jpg"}, {"question": "what type of console is the game for", "gt answer": "xbox(1.00)", "pred answer": "wii", "question_id": 540525, "best approach": "", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "wii(0.7301)", "verif concept answer": "wii(0.7198)", "verif image answer": "wii(0.5782)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054052.jpg"}, {"question": "when was the object the person is wearing on their feet first produced in the united states", "gt answer": "1700(1.00)<br/>1950s(0.60)<br/>2002(0.60)<br/>1892(0.60)", "pred answer": "1965", "question_id": 450865, "best approach": "wiki, concept, image", "verif answer": "1940", "anno approach": "wiki, concept, image", "verif wiki answer": "1892(0.7206)", "verif concept answer": "1892(0.6669)", "verif image answer": "1892(0.7074)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045086.jpg"}, {"question": "what are these vehicles driving on", "gt answer": "road(1.00)<br/>asphalt(0.60)", "pred answer": "track", "question_id": 3986155, "best approach": "concept", "verif answer": "asphalt", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.7006)", "verif concept answer": "road(0.6834)", "verif image answer": "street(0.7150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398615.jpg"}, {"question": "if these players stay outside and don't drink enough they could fall prey to what dangerous condition", "gt answer": "dehydration(1.00)", "pred answer": "drown", "question_id": 455245, "best approach": "image", "verif answer": "hurricane", "anno approach": "wiki, concept, image", "verif wiki answer": "lion king(0.5908)", "verif concept answer": "lion king(0.7235)", "verif image answer": "dehydration(0.5029)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045524.jpg"}, {"question": "what type of bird is this", "gt answer": "owl(1.00)", "pred answer": "hawk", "question_id": 1690355, "best approach": "", "verif answer": "pelican", "anno approach": "wiki, concept, image", "verif wiki answer": "falcon(0.7004)", "verif concept answer": "falcon(0.6928)", "verif image answer": "eagle(0.6838)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169035.jpg"}, {"question": "who normally rides this type of transportation", "gt answer": "kid(1.00)<br/>passenger(0.60)<br/>student(0.60)", "pred answer": "human", "question_id": 3159975, "best approach": "concept", "verif answer": "student", "anno approach": "wiki, concept, image", "verif wiki answer": "children(0.6971)", "verif concept answer": "student(0.6976)", "verif image answer": "children(0.7156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315997.jpg"}, {"question": "what is the name of the trick the motor cyclist is doing", "gt answer": "wheelie(1.00)<br/>barn(0.60)", "pred answer": "jump", "question_id": 4204755, "best approach": "", "verif answer": "grind", "anno approach": "wiki, concept, image", "verif wiki answer": "grind(0.5921)", "verif concept answer": "grind(0.6765)", "verif image answer": "grind(0.5638)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420475.jpg"}, {"question": "what kind of bull is this", "gt answer": "longhorn(1.00)<br/>brown(0.60)", "pred answer": "bull", "question_id": 1802535, "best approach": "wiki", "verif answer": "brown", "anno approach": "wiki, concept, image", "verif wiki answer": "brown(0.6868)", "verif concept answer": "long(0.7003)", "verif image answer": "long(0.7138)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180253.jpg"}, {"question": "what companies sell the device in this photo", "gt answer": "motorola(1.00)", "pred answer": "nokia", "question_id": 4903565, "best approach": "", "verif answer": "samsung", "anno approach": "wiki, concept, image", "verif wiki answer": "flip phone(0.5929)", "verif concept answer": "samsung(0.6375)", "verif image answer": "gucci(0.5579)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490356.jpg"}, {"question": "what is being sold on that truck", "gt answer": "soda(1.00)<br/>coke(0.60)<br/>coca cola(0.60)<br/>hotdog(0.60)", "pred answer": "ice cream", "question_id": 1846695, "best approach": "wiki, concept, image", "verif answer": "coca cola", "anno approach": "wiki, concept, image", "verif wiki answer": "soda(0.7210)", "verif concept answer": "soda(0.7223)", "verif image answer": "soda(0.6534)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184669.jpg"}, {"question": "what is being pulled by the truck", "gt answer": "camper(1.00)<br/>trailer(1.00)<br/>rv(0.60)", "pred answer": "food", "question_id": 5281985, "best approach": "image", "verif answer": "camper", "anno approach": "wiki, concept, image", "verif wiki answer": "carriage(0.7244)", "verif concept answer": "carriage(0.7213)", "verif image answer": "trailer(0.7273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528198.jpg"}, {"question": "where is this happening", "gt answer": "circus(1.00)<br/>rodeo(0.60)", "pred answer": "stable", "question_id": 3635765, "best approach": "wiki", "verif answer": "rodeo", "anno approach": "wiki, concept, image", "verif wiki answer": "circus(0.5854)", "verif concept answer": "rodeo(0.5826)", "verif image answer": "rodeo(0.6943)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363576.jpg"}, {"question": "what toping is on the frankfurter on the left of the two shown", "gt answer": "sauerkraut(1.00)", "pred answer": "ketchup", "question_id": 2730535, "best approach": "image", "verif answer": "cheese", "anno approach": "wiki, concept, image", "verif wiki answer": "bread(0.6459)", "verif concept answer": "bread(0.6905)", "verif image answer": "sauerkraut(0.5810)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273053.jpg"}, {"question": "is it day or night here", "gt answer": "day(1.00)<br/>night(1.00)", "pred answer": "daytime", "question_id": 3701215, "best approach": "wiki", "verif answer": "daytime", "anno approach": "wiki, concept, image", "verif wiki answer": "day(0.7007)", "verif concept answer": "daytime(0.6709)", "verif image answer": "even(0.6971)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370121.jpg"}, {"question": "what popular food are these animals slaughtered to create", "gt answer": "hamburger(1.00)<br/>steak(0.60)<br/>meat(0.60)<br/>beef(0.60)", "pred answer": "milk", "question_id": 1845045, "best approach": "wiki, concept, image", "verif answer": "steak", "anno approach": "wiki, concept, image", "verif wiki answer": "beef(0.7156)", "verif concept answer": "beef(0.6998)", "verif image answer": "steak(0.6941)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184504.jpg"}, {"question": "why the person is on the bed", "gt answer": "sick(1.00)<br/>nighttime(0.60)<br/>sleepy(0.60)<br/>rest(0.60)", "pred answer": "sleep", "question_id": 3981245, "best approach": "wiki", "verif answer": "tired", "anno approach": "wiki, concept, image", "verif wiki answer": "sick(0.7254)", "verif concept answer": "tired(0.6112)", "verif image answer": "tired(0.5406)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398124.jpg"}, {"question": "how long do the teeth on this animal get", "gt answer": "8 inches(1.00)<br/>10 feet(0.60)", "pred answer": "2 inches", "question_id": 4957535, "best approach": "wiki", "verif answer": "1 foot", "anno approach": "wiki, concept, image", "verif wiki answer": "8 inches(0.7115)", "verif concept answer": "10 feet(0.6819)", "verif image answer": "10 inches(0.6931)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495753.jpg"}, {"question": "the fork is stuck into what kind of vegetable", "gt answer": "cucumber(1.00)", "pred answer": "potato", "question_id": 5183925, "best approach": "concept", "verif answer": "cucumber", "anno approach": "wiki, concept, image", "verif wiki answer": "omega 3(0.5420)", "verif concept answer": "cucumber(0.6450)", "verif image answer": "pickle(0.6035)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518392.jpg"}, {"question": "what item seen here is often depicted as winding up on the head of the intoxicated", "gt answer": "lampshade(1.00)<br/>pizza(0.60)<br/>snake(0.60)", "pred answer": "cap", "question_id": 1299125, "best approach": "image", "verif answer": "lampshade", "anno approach": "wiki, concept, image", "verif wiki answer": "calzone(0.6860)", "verif concept answer": "picnic(0.6684)", "verif image answer": "pizza(0.5418)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129912.jpg"}, {"question": "what is the top speed of the white motorcycle", "gt answer": "120 mph(1.00)", "pred answer": "100 mph", "question_id": 5625105, "best approach": "concept", "verif answer": "100 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "100 mph(0.6648)", "verif concept answer": "120 mph(0.6602)", "verif image answer": "500 mph(0.6105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000562510.jpg"}, {"question": "the way the fruit is laid on this pie is called what", "gt answer": "slice(1.00)<br/>swirl(0.60)<br/>dress(0.60)", "pred answer": "fry", "question_id": 488485, "best approach": "concept", "verif answer": "fry", "anno approach": "wiki, concept, image", "verif wiki answer": "fry(0.6429)", "verif concept answer": "slice(0.6431)", "verif image answer": "dress(0.6645)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048848.jpg"}, {"question": "why can't one park here", "gt answer": "fire lane(1.00)<br/>illegal(0.60)<br/>hydrant(0.60)", "pred answer": "empty", "question_id": 4512195, "best approach": "wiki", "verif answer": "illegal", "anno approach": "wiki, concept, image", "verif wiki answer": "fire lane(0.6942)", "verif concept answer": "fire hydrant(0.6610)", "verif image answer": "illegal(0.5185)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451219.jpg"}, {"question": "what would these people be doing with this bus", "gt answer": "tour(1.00)<br/>travel(1.00)<br/>transport(0.60)", "pred answer": "wait", "question_id": 5703855, "best approach": "wiki", "verif answer": "transport", "anno approach": "wiki, concept, image", "verif wiki answer": "tour(0.7115)", "verif concept answer": "transport(0.6628)", "verif image answer": "transport(0.6453)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570385.jpg"}, {"question": "what type of nutrition value does the dish the lady is making have", "gt answer": "carbohydrate(1.00)<br/>fiber(0.60)", "pred answer": "500", "question_id": 830005, "best approach": "concept, image", "verif answer": "protein", "anno approach": "wiki, concept, image", "verif wiki answer": "sugar(0.7249)", "verif concept answer": "fiber(0.6727)", "verif image answer": "fiber(0.6997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083000.jpg"}, {"question": "what food is this", "gt answer": "bbq(0.60)<br/>burger(1.00)<br/>hamburger(0.60)", "pred answer": "pastry", "question_id": 2198805, "best approach": "", "verif answer": "bbq", "anno approach": "wiki, concept, image", "verif wiki answer": "sandwich(0.7265)", "verif concept answer": "sandwich(0.7024)", "verif image answer": "sandwich(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219880.jpg"}, {"question": "what country is associated with the religion shown on the sign", "gt answer": "israel(1.00)<br/>saudi arabia(0.60)<br/>england(0.60)", "pred answer": "italy", "question_id": 4873995, "best approach": "wiki, concept", "verif answer": "germany", "anno approach": "wiki, concept, image", "verif wiki answer": "england(0.7145)", "verif concept answer": "england(0.7112)", "verif image answer": "germany(0.6717)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487399.jpg"}, {"question": "what kind have bathroom is this", "gt answer": "men(1.00)", "pred answer": "toilet", "question_id": 4710855, "best approach": "", "verif answer": "bathroom", "anno approach": "wiki, concept, image", "verif wiki answer": "bathroom(0.7026)", "verif concept answer": "man(0.6567)", "verif image answer": "biker(0.5624)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471085.jpg"}, {"question": "name the dish the man is eating", "gt answer": "chip(1.00)<br/>popcorn(1.00)", "pred answer": "taco", "question_id": 5491845, "best approach": "wiki, concept, image", "verif answer": "taco", "anno approach": "wiki, concept, image", "verif wiki answer": "chip(0.7243)", "verif concept answer": "chip(0.7103)", "verif image answer": "popcorn(0.6610)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000549184.jpg"}, {"question": "what material are the vases made of", "gt answer": "glass(1.00)<br/>sand(0.60)", "pred answer": "ceramic", "question_id": 3038045, "best approach": "", "verif answer": "ceramic", "anno approach": "wiki, concept, image", "verif wiki answer": "wine glass(0.7205)", "verif concept answer": "wine glass(0.7125)", "verif image answer": "ceramic(0.7132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303804.jpg"}, {"question": "what part of the boats are not showing and use the wind", "gt answer": "sail(1.00)", "pred answer": "anchor", "question_id": 906765, "best approach": "image", "verif answer": "wind", "anno approach": "wiki, concept, image", "verif wiki answer": "boat(0.7255)", "verif concept answer": "boat(0.7161)", "verif image answer": "sail(0.6779)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090676.jpg"}, {"question": "what is the name of the chair in which the man is seated", "gt answer": "recliner(1.00)<br/>couch(0.60)<br/>lounge(0.60)", "pred answer": "sofa", "question_id": 4178345, "best approach": "wiki, image", "verif answer": "sofa", "anno approach": "wiki, concept, image", "verif wiki answer": "lounge(0.7215)", "verif concept answer": "sofa(0.6620)", "verif image answer": "lounge(0.6869)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417834.jpg"}, {"question": "where is this food likely displayed", "gt answer": "supermarket(1.00)<br/>produce(1.00)<br/>grocery store(0.60)", "pred answer": "grocery", "question_id": 792245, "best approach": "wiki", "verif answer": "produce", "anno approach": "wiki, concept, image", "verif wiki answer": "supermarket(0.6960)", "verif concept answer": "store(0.7038)", "verif image answer": "store(0.7194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079224.jpg"}, {"question": "how tall are the orange markers in the roadway", "gt answer": "3 feet(1.00)<br/>yard(0.60)", "pred answer": "4 feet", "question_id": 2788235, "best approach": "wiki", "verif answer": "4 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "3 feet(0.6658)", "verif concept answer": "2 feet(0.5881)", "verif image answer": "4 feet(0.6486)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278823.jpg"}, {"question": "which movie starring gene kelley contained a famous muscial number with this item in", "gt answer": "sing in rain(1.00)", "pred answer": "star war", "question_id": 306435, "best approach": "image", "verif answer": "star war", "anno approach": "wiki, concept, image", "verif wiki answer": "star war(0.7296)", "verif concept answer": "wizard of oz(0.7300)", "verif image answer": "sing in rain(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030643.jpg"}, {"question": "how deep is this water", "gt answer": "15 feet(1.00)", "pred answer": "1 mile", "question_id": 4366265, "best approach": "wiki", "verif answer": "2 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "15 feet(0.6319)", "verif concept answer": "10 feet(0.5290)", "verif image answer": "2 feet(0.5474)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436626.jpg"}, {"question": "is it the mother 's or daughter 's birthday", "gt answer": "daughter(1.00)", "pred answer": "girl", "question_id": 2635165, "best approach": "wiki, concept, image", "verif answer": "valentine", "anno approach": "wiki, concept, image", "verif wiki answer": "daughter(0.7179)", "verif concept answer": "daughter(0.7083)", "verif image answer": "daughter(0.7245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263516.jpg"}, {"question": "is the cat indoors or outdoors", "gt answer": "indoor(1.00)", "pred answer": "outdoor", "question_id": 4736345, "best approach": "", "verif answer": "outdoor", "anno approach": "wiki, concept, image", "verif wiki answer": "outdoor(0.7252)", "verif concept answer": "outdoor(0.7170)", "verif image answer": "outdoor(0.6531)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473634.jpg"}, {"question": "where in the world are there big mountains", "gt answer": "switzerland(1.00)", "pred answer": "alaska", "question_id": 2838845, "best approach": "", "verif answer": "norway", "anno approach": "wiki, concept, image", "verif wiki answer": "norway(0.6830)", "verif concept answer": "germany(0.6821)", "verif image answer": "sweden(0.6735)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283884.jpg"}, {"question": "what is the stuff in the middle of the platter", "gt answer": "nut(1.00)<br/>mint(0.60)", "pred answer": "dessert", "question_id": 735835, "best approach": "image", "verif answer": "peanut", "anno approach": "wiki, concept, image", "verif wiki answer": "peanut(0.6726)", "verif concept answer": "mint(0.7087)", "verif image answer": "nut(0.5708)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073583.jpg"}, {"question": "what breed is this dog", "gt answer": "rottweiler(1.00)<br/>beagle(0.60)<br/>retriever(0.60)", "pred answer": "mix", "question_id": 1148695, "best approach": "wiki, concept", "verif answer": "retriever", "anno approach": "wiki, concept, image", "verif wiki answer": "retriever(0.6794)", "verif concept answer": "retriever(0.7066)", "verif image answer": "dog(0.6487)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114869.jpg"}, {"question": "what kind of liquid soap is used in the sink in the image", "gt answer": "dawn(1.00)<br/>foam(0.60)", "pred answer": "dish soap", "question_id": 5141835, "best approach": "wiki, image", "verif answer": "dish soap", "anno approach": "wiki, concept, image", "verif wiki answer": "foam(0.7175)", "verif concept answer": "salt(0.6300)", "verif image answer": "foam(0.6048)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514183.jpg"}, {"question": "how is this type of food made", "gt answer": "fried(1.00)<br/>bread(0.60)<br/>toasted(0.60)", "pred answer": "bake", "question_id": 3930805, "best approach": "wiki", "verif answer": "fried", "anno approach": "wiki, concept, image", "verif wiki answer": "fried(0.7178)", "verif concept answer": "bread(0.6964)", "verif image answer": "fast(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393080.jpg"}, {"question": "is this the living room or dining room", "gt answer": "dine room(1.00)<br/>both(1.00)<br/>dine(0.60)", "pred answer": "live room", "question_id": 588345, "best approach": "wiki, concept", "verif answer": "dine", "anno approach": "wiki, concept, image", "verif wiki answer": "both(0.7131)", "verif concept answer": "both(0.7156)", "verif image answer": "hangout(0.7222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058834.jpg"}, {"question": "what was the name of the chicken in moana", "gt answer": "heihei(1.00)", "pred answer": "rhode island red", "question_id": 5587655, "best approach": "", "verif answer": "sheep", "anno approach": "wiki, concept, image", "verif wiki answer": "duck(0.6976)", "verif concept answer": "duck(0.6903)", "verif image answer": "duck(0.7126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558765.jpg"}, {"question": "what kind of monks are these", "gt answer": "buddhist(1.00)<br/>hindu(0.60)<br/>chinese(0.60)", "pred answer": "indian", "question_id": 410945, "best approach": "wiki, concept", "verif answer": "chinese", "anno approach": "wiki, concept, image", "verif wiki answer": "buddhist(0.6996)", "verif concept answer": "buddhist(0.6941)", "verif image answer": "japanese(0.5917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041094.jpg"}, {"question": "this animal is grazing in the area known as what", "gt answer": "grassland(1.00)<br/>serengeti(0.60)<br/>savannah(0.60)", "pred answer": "cow", "question_id": 4874895, "best approach": "wiki, concept, image", "verif answer": "savannah", "anno approach": "wiki, concept, image", "verif wiki answer": "savannah(0.7151)", "verif concept answer": "savannah(0.7049)", "verif image answer": "savannah(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487489.jpg"}, {"question": "in what country did this sport originate", "gt answer": "united state(1.00)<br/>america(1.00)", "pred answer": "australia", "question_id": 1994875, "best approach": "image", "verif answer": "america", "anno approach": "wiki, concept, image", "verif wiki answer": "germany(0.6706)", "verif concept answer": "germany(0.7056)", "verif image answer": "america(0.6590)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199487.jpg"}, {"question": "why might one assume this is a private school", "gt answer": "uniform(1.00)", "pred answer": "school", "question_id": 5801205, "best approach": "", "verif answer": "young", "anno approach": "wiki, concept, image", "verif wiki answer": "young(0.5325)", "verif concept answer": "young(0.5740)", "verif image answer": "young(0.5193)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580120.jpg"}, {"question": "what time is it in this photo", "gt answer": "5:37(1.00)", "pred answer": "12:24", "question_id": 77535, "best approach": "concept", "verif answer": "3:40", "anno approach": "wiki, concept, image", "verif wiki answer": "3:40(0.7294)", "verif concept answer": "5:37(0.7290)", "verif image answer": "3:40(0.7243)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007753.jpg"}, {"question": "what is the new name for this famous road", "gt answer": "route 66(1.00)", "pred answer": "roundabout", "question_id": 1897355, "best approach": "concept, image", "verif answer": "intersection", "anno approach": "wiki, concept, image", "verif wiki answer": "highway(0.6408)", "verif concept answer": "route 66(0.6363)", "verif image answer": "route 66(0.5902)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000189735.jpg"}, {"question": "what hunts these animals", "gt answer": "poacher(1.00)<br/>lion(0.60)<br/>human(0.60)", "pred answer": "trunk", "question_id": 5506995, "best approach": "concept, image", "verif answer": "lion", "anno approach": "wiki, concept, image", "verif wiki answer": "benjamin franklin(0.5942)", "verif concept answer": "lion(0.6940)", "verif image answer": "lion(0.5215)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550699.jpg"}, {"question": "what 's the best octane of gasoline to put in the tank", "gt answer": "premium(1.00)", "pred answer": "gas", "question_id": 3835255, "best approach": "wiki, image", "verif answer": "diesel", "anno approach": "wiki, concept, image", "verif wiki answer": "premium(0.6983)", "verif concept answer": "coal(0.6700)", "verif image answer": "premium(0.6291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383525.jpg"}, {"question": "why do people use this kind of transportation", "gt answer": "fun(1.00)<br/>for fun(0.60)<br/>race(0.60)", "pred answer": "ride", "question_id": 792585, "best approach": "concept, image", "verif answer": "transportation", "anno approach": "wiki, concept, image", "verif wiki answer": "transportation(0.6629)", "verif concept answer": "race(0.6308)", "verif image answer": "race(0.6647)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079258.jpg"}, {"question": "what device is the baby on", "gt answer": "sled(1.00)<br/>surfboard(0.60)", "pred answer": "suitcase", "question_id": 259965, "best approach": "wiki", "verif answer": "sled", "anno approach": "wiki, concept, image", "verif wiki answer": "sled(0.6330)", "verif concept answer": "ski(0.7139)", "verif image answer": "ski(0.6418)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025996.jpg"}, {"question": "what type of seasoning", "gt answer": "parsley(1.00)<br/>pepper(0.60)", "pred answer": "fry", "question_id": 3511465, "best approach": "wiki", "verif answer": "pepper", "anno approach": "wiki, concept, image", "verif wiki answer": "parsley(0.6646)", "verif concept answer": "spinach(0.6683)", "verif image answer": "spinach(0.7116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351146.jpg"}, {"question": "from which healthy oil the shown dish is prepared", "gt answer": "olive oil(1.00)<br/>canola(0.60)<br/>peanut(0.60)<br/>sunflower(0.60)", "pred answer": "olive", "question_id": 2742715, "best approach": "concept", "verif answer": "sunflower", "anno approach": "wiki, concept, image", "verif wiki answer": "peanut(0.6699)", "verif concept answer": "olive oil(0.6849)", "verif image answer": "peanut(0.7108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274271.jpg"}, {"question": "what kind of event is this", "gt answer": "kite fly(1.00)", "pred answer": "kite", "question_id": 483395, "best approach": "", "verif answer": "kite", "anno approach": "wiki, concept, image", "verif wiki answer": "fly kite(0.7099)", "verif concept answer": "fly kite(0.6918)", "verif image answer": "kite(0.6954)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048339.jpg"}, {"question": "name the material used to make this board in this picture", "gt answer": "cardboard(1.00)<br/>wood(1.00)", "pred answer": "metal", "question_id": 5183555, "best approach": "wiki, concept, image", "verif answer": "wood", "anno approach": "wiki, concept, image", "verif wiki answer": "cardboard(0.7215)", "verif concept answer": "wood(0.6952)", "verif image answer": "wood(0.6010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518355.jpg"}, {"question": "what is this person 's necklace made of", "gt answer": "gold(1.00)<br/>nylon(0.60)", "pred answer": "metal", "question_id": 803055, "best approach": "wiki", "verif answer": "metal", "anno approach": "wiki, concept, image", "verif wiki answer": "gold(0.7118)", "verif concept answer": "rubber(0.7264)", "verif image answer": "plastic(0.5591)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080305.jpg"}, {"question": "how many of these animals remain in the wild", "gt answer": "many(1.00)<br/>1000(0.60)<br/>thousand(0.60)<br/>endangered(0.60)", "pred answer": "0", "question_id": 4585745, "best approach": "wiki, concept, image", "verif answer": "thousand", "anno approach": "wiki, concept, image", "verif wiki answer": "endangered(0.7268)", "verif concept answer": "endangered(0.7170)", "verif image answer": "1000(0.6604)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458574.jpg"}, {"question": "what causes high and low tides", "gt answer": "moon(1.00)<br/>rain(0.60)", "pred answer": "flood", "question_id": 3550925, "best approach": "wiki, concept", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "moon(0.7056)", "verif concept answer": "moon(0.6886)", "verif image answer": "fog(0.6507)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355092.jpg"}, {"question": "a young boy that is designated to run after this ball during this match would be called a what", "gt answer": "ball boy(1.00)", "pred answer": "roger federer", "question_id": 1576565, "best approach": "image", "verif answer": "double", "anno approach": "wiki, concept, image", "verif wiki answer": "double(0.6174)", "verif concept answer": "tennis(0.5106)", "verif image answer": "ball boy(0.5063)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157656.jpg"}, {"question": "this fire hydrant is painted to resemble what", "gt answer": "face(1.00)<br/>fireman(0.60)", "pred answer": "santa", "question_id": 251155, "best approach": "concept", "verif answer": "letter", "anno approach": "wiki, concept, image", "verif wiki answer": "letter(0.6567)", "verif concept answer": "face(0.6512)", "verif image answer": "letter(0.5025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025115.jpg"}, {"question": "what geometric shape is the top", "gt answer": "triangle(1.00)", "pred answer": "rectangle", "question_id": 1343205, "best approach": "", "verif answer": "square", "anno approach": "wiki, concept, image", "verif wiki answer": "in half(0.7144)", "verif concept answer": "diamond(0.6459)", "verif image answer": "in half(0.6059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134320.jpg"}, {"question": "how thick is the orage surfboard", "gt answer": "2 inches(1.00)<br/>4(0.60)", "pred answer": "thin", "question_id": 3735695, "best approach": "", "verif answer": "very", "anno approach": "wiki, concept, image", "verif wiki answer": "very(0.6881)", "verif concept answer": "very(0.5857)", "verif image answer": "very(0.6596)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373569.jpg"}, {"question": "clothes for this sport are typically called tennis what", "gt answer": "shoe(1.00)<br/>gear(1.00)<br/>short(0.60)", "pred answer": "tennis", "question_id": 3293945, "best approach": "", "verif answer": "tennis skirt", "anno approach": "wiki, concept, image", "verif wiki answer": "tennis skirt(0.7290)", "verif concept answer": "nike(0.6982)", "verif image answer": "nike(0.5455)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329394.jpg"}, {"question": "what product does the remote next to the cat operate", "gt answer": "television(1.00)<br/>tv(1.00)", "pred answer": "ipod", "question_id": 4290405, "best approach": "", "verif answer": "television", "anno approach": "wiki, concept, image", "verif wiki answer": "wii(0.7066)", "verif concept answer": "fireplace(0.7243)", "verif image answer": "wii(0.7082)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429040.jpg"}, {"question": "who makes that baseball bat", "gt answer": "wilson(1.00)<br/>louisville slugger(0.60)", "pred answer": "rawling", "question_id": 5526305, "best approach": "wiki, concept", "verif answer": "rawling", "anno approach": "wiki, concept, image", "verif wiki answer": "louisville slugger(0.7148)", "verif concept answer": "louisville slugger(0.7023)", "verif image answer": "schwinn(0.6958)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552630.jpg"}, {"question": "are the people in this picture enthusiastic or bored", "gt answer": "enthusiastic(1.00)", "pred answer": "mad", "question_id": 5339575, "best approach": "", "verif answer": "happy", "anno approach": "wiki, concept, image", "verif wiki answer": "happy(0.7263)", "verif concept answer": "happy(0.7294)", "verif image answer": "happy(0.5020)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000533957.jpg"}, {"question": "where are these buses parked", "gt answer": "bus stop(1.00)<br/>station(0.60)", "pred answer": "train station", "question_id": 3930645, "best approach": "concept", "verif answer": "train station", "anno approach": "wiki, concept, image", "verif wiki answer": "train station(0.7286)", "verif concept answer": "bus stop(0.7268)", "verif image answer": "downtown(0.7015)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393064.jpg"}, {"question": "what city is this", "gt answer": "new york(1.00)<br/>new york city(0.60)", "pred answer": "columbus", "question_id": 1028995, "best approach": "", "verif answer": "new york city", "anno approach": "wiki, concept, image", "verif wiki answer": "new york new york(0.7156)", "verif concept answer": "los angeles(0.6805)", "verif image answer": "boston(0.5735)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000102899.jpg"}, {"question": "what is the primary function of the trucks in this photo", "gt answer": "haul(1.00)<br/>transportation(0.60)", "pred answer": "tow", "question_id": 2535155, "best approach": "image", "verif answer": "tow", "anno approach": "wiki, concept, image", "verif wiki answer": "tow(0.7205)", "verif concept answer": "tow(0.7147)", "verif image answer": "transportation(0.5641)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253515.jpg"}, {"question": "what is the dish named", "gt answer": "soup(1.00)<br/>cashew chicken(1.00)", "pred answer": "pasta", "question_id": 4154995, "best approach": "concept, image", "verif answer": "pasta", "anno approach": "wiki, concept, image", "verif wiki answer": "pasta(0.7222)", "verif concept answer": "cashew chicken(0.6858)", "verif image answer": "soup(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415499.jpg"}, {"question": "what language is on the sign", "gt answer": "italian(1.00)<br/>spanish(0.60)", "pred answer": "english", "question_id": 3460615, "best approach": "wiki, concept", "verif answer": "spanish", "anno approach": "wiki, concept, image", "verif wiki answer": "spanish(0.7227)", "verif concept answer": "spanish(0.7183)", "verif image answer": "french(0.6006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346061.jpg"}, {"question": "what is the purpose of the fixtures on the wall", "gt answer": "hold thing(1.00)<br/>bookshelf(0.60)", "pred answer": "cook", "question_id": 1746235, "best approach": "wiki", "verif answer": "bookshelf", "anno approach": "wiki, concept, image", "verif wiki answer": "bookshelf(0.7132)", "verif concept answer": "hold flower(0.6853)", "verif image answer": "hold flower(0.5078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174623.jpg"}, {"question": "is this food gulten free or vegan", "gt answer": "vegan(1.00)", "pred answer": "healthy", "question_id": 1878725, "best approach": "wiki, concept", "verif answer": "healthy", "anno approach": "wiki, concept, image", "verif wiki answer": "vegan(0.5852)", "verif concept answer": "vegan(0.6066)", "verif image answer": "healthy(0.6953)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187872.jpg"}, {"question": "if the man behind the hitter catches the ball before the hitter gets to first base then the hitter is what", "gt answer": "out(1.00)<br/>safe(0.60)", "pred answer": "homerun", "question_id": 466305, "best approach": "", "verif answer": "out", "anno approach": "wiki, concept, image", "verif wiki answer": "umpire(0.7282)", "verif concept answer": "umpire(0.6955)", "verif image answer": "umpire(0.6935)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046630.jpg"}, {"question": "what type of clouds are in the sky", "gt answer": "cirrus(1.00)<br/>cumulus(1.00)", "pred answer": "stratus", "question_id": 65395, "best approach": "image", "verif answer": "stratus", "anno approach": "wiki, concept, image", "verif wiki answer": "stratus(0.6661)", "verif concept answer": "stratus(0.6067)", "verif image answer": "cirrus(0.6959)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006539.jpg"}, {"question": "what model of camera is being used", "gt answer": "kodak(1.00)<br/>digital(1.00)", "pred answer": "canon", "question_id": 5802575, "best approach": "concept", "verif answer": "canon", "anno approach": "wiki, concept, image", "verif wiki answer": "canon(0.7259)", "verif concept answer": "kodak(0.7065)", "verif image answer": "cannon(0.7136)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580257.jpg"}, {"question": "how do we know this is not a professional game", "gt answer": "cloth(0.60)<br/>outfit(1.00)", "pred answer": "same side", "question_id": 2481505, "best approach": "", "verif answer": "nothing", "anno approach": "wiki, concept, image", "verif wiki answer": "door(0.6620)", "verif concept answer": "nothing(0.5900)", "verif image answer": "shirt(0.6818)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248150.jpg"}, {"question": "what position is the person taking off his helmet", "gt answer": "batter(1.00)<br/>home(1.00)", "pred answer": "catcher", "question_id": 5002245, "best approach": "", "verif answer": "pitcher", "anno approach": "wiki, concept, image", "verif wiki answer": "pitcher(0.7223)", "verif concept answer": "pitcher(0.6925)", "verif image answer": "hitter(0.6377)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500224.jpg"}, {"question": "is this an exercise class or surboard training", "gt answer": "train(1.00)<br/>surfboard train(1.00)<br/>both(0.60)", "pred answer": "surf", "question_id": 4959295, "best approach": "wiki", "verif answer": "both", "anno approach": "wiki, concept, image", "verif wiki answer": "surfboard train(0.5810)", "verif concept answer": "public(0.5407)", "verif image answer": "both(0.6915)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495929.jpg"}, {"question": "what is missing from this wall", "gt answer": "tile(1.00)<br/>wall(0.60)<br/>window(0.60)", "pred answer": "toilet", "question_id": 2581085, "best approach": "wiki, concept, image", "verif answer": "window", "anno approach": "wiki, concept, image", "verif wiki answer": "wall(0.7258)", "verif concept answer": "wall(0.7122)", "verif image answer": "wall(0.5233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258108.jpg"}, {"question": "what food is in the foreground", "gt answer": "orange(1.00)", "pred answer": "fruit", "question_id": 2987115, "best approach": "", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "lemon(0.6633)", "verif concept answer": "grapefruit(0.6592)", "verif image answer": "tangerine(0.6710)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000298711.jpg"}, {"question": "what 's the white cord around the guy on the left", "gt answer": "earbud(1.00)<br/>headphone(0.60)", "pred answer": "rope", "question_id": 4484395, "best approach": "concept", "verif answer": "music", "anno approach": "wiki, concept, image", "verif wiki answer": "music(0.5955)", "verif concept answer": "earbud(0.6398)", "verif image answer": "headphone(0.7068)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448439.jpg"}, {"question": "name the flight name shown in this picture", "gt answer": "j 4138(1.00)", "pred answer": "propeller", "question_id": 723915, "best approach": "wiki", "verif answer": "klm", "anno approach": "wiki, concept, image", "verif wiki answer": "j 4138(0.6941)", "verif concept answer": "klm(0.7257)", "verif image answer": "klm(0.7126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072391.jpg"}, {"question": "what form is the man using to throw the frisbee", "gt answer": "underhand(1.00)<br/>discus(0.60)<br/>kneel(0.60)<br/>first(0.60)", "pred answer": "forehand", "question_id": 1987215, "best approach": "image", "verif answer": "backhand", "anno approach": "wiki, concept, image", "verif wiki answer": "backhand(0.7240)", "verif concept answer": "backhand(0.6589)", "verif image answer": "underhand(0.5420)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198721.jpg"}, {"question": "can you guess the celebration where the people are enjoying", "gt answer": "fourth of july(1.00)<br/>new year(0.60)<br/>4th of july(0.60)", "pred answer": "christmas", "question_id": 3783315, "best approach": "concept, image", "verif answer": "4th of july", "anno approach": "wiki, concept, image", "verif wiki answer": "july 4th(0.7282)", "verif concept answer": "fourth of july(0.7152)", "verif image answer": "fourth of july(0.7067)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378331.jpg"}, {"question": "what mineral causes earth to turn white in warmer climates", "gt answer": "salt(1.00)<br/>stone(0.60)", "pred answer": "snow", "question_id": 703565, "best approach": "", "verif answer": "rock", "anno approach": "wiki, concept, image", "verif wiki answer": "rock(0.6782)", "verif concept answer": "rock(0.6004)", "verif image answer": "ocean(0.7112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070356.jpg"}, {"question": "why do giraffes have long neck and tall body", "gt answer": "to eat(1.00)<br/>evolution(0.60)", "pred answer": "neck", "question_id": 5682375, "best approach": "wiki", "verif answer": "evolution", "anno approach": "wiki, concept, image", "verif wiki answer": "to eat(0.7125)", "verif concept answer": "hot(0.6707)", "verif image answer": "hot(0.5384)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568237.jpg"}, {"question": "the red kite shown in the photo is of which country", "gt answer": "us(1.00)<br/>china(1.00)<br/>usa(0.60)", "pred answer": "canada", "question_id": 1874355, "best approach": "", "verif answer": "france", "anno approach": "wiki, concept, image", "verif wiki answer": "france(0.6840)", "verif concept answer": "asia(0.6871)", "verif image answer": "france(0.6825)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187435.jpg"}, {"question": "what instrument is the boy using", "gt answer": "trombone(1.00)", "pred answer": "cello", "question_id": 2527025, "best approach": "", "verif answer": "cello", "anno approach": "wiki, concept, image", "verif wiki answer": "donut(0.5255)", "verif concept answer": "donut(0.5133)", "verif image answer": "donut(0.5005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252702.jpg"}, {"question": "what type of lighting was usued", "gt answer": "natural(1.00)<br/>outdoor(0.60)", "pred answer": "led", "question_id": 3910655, "best approach": "wiki, image", "verif answer": "natural", "anno approach": "wiki, concept, image", "verif wiki answer": "natural(0.6801)", "verif concept answer": "sun(0.6814)", "verif image answer": "natural(0.6420)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391065.jpg"}, {"question": "what is the function of the man in black", "gt answer": "referee(1.00)<br/>catcher(0.60)<br/>judge(0.60)", "pred answer": "umpire", "question_id": 1696535, "best approach": "", "verif answer": "umpire", "anno approach": "wiki, concept, image", "verif wiki answer": "umpire(0.7280)", "verif concept answer": "umpire(0.7237)", "verif image answer": "catch(0.6200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169653.jpg"}, {"question": "who owns the booth", "gt answer": "adobe(1.00)", "pred answer": "artist", "question_id": 4246695, "best approach": "image", "verif answer": "nokia", "anno approach": "wiki, concept, image", "verif wiki answer": "nokia(0.6862)", "verif concept answer": "krispy kreme(0.6177)", "verif image answer": "adobe(0.6025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424669.jpg"}, {"question": "what day s might i most commonly go to this building", "gt answer": "sunday(1.00)", "pred answer": "vacation", "question_id": 2933425, "best approach": "wiki, image", "verif answer": "christmas", "anno approach": "wiki, concept, image", "verif wiki answer": "sunday(0.7283)", "verif concept answer": "downtown(0.7175)", "verif image answer": "sunday(0.5848)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293342.jpg"}, {"question": "what is the style of paint that the police force seen in the photo use to demarcate their vehicles", "gt answer": "neon(1.00)<br/>checkered(0.60)<br/>spray paint(0.60)", "pred answer": "flame", "question_id": 5137295, "best approach": "wiki, concept", "verif answer": "spray", "anno approach": "wiki, concept, image", "verif wiki answer": "spray paint(0.7158)", "verif concept answer": "spray paint(0.7087)", "verif image answer": "spray(0.5770)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513729.jpg"}, {"question": "what is on the court floor", "gt answer": "water(1.00)<br/>asphalt(0.60)<br/>chalk(0.60)", "pred answer": "net", "question_id": 4948605, "best approach": "concept", "verif answer": "water", "anno approach": "wiki, concept, image", "verif wiki answer": "paint(0.6850)", "verif concept answer": "water(0.6677)", "verif image answer": "rock(0.7118)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494860.jpg"}, {"question": "what material is the sofa", "gt answer": "cloth(1.00)", "pred answer": "microfiber", "question_id": 897925, "best approach": "image", "verif answer": "cloth", "anno approach": "wiki, concept, image", "verif wiki answer": "tablecloth(0.7293)", "verif concept answer": "tablecloth(0.7262)", "verif image answer": "cloth(0.7002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089792.jpg"}, {"question": "what is the mat on the floor made of", "gt answer": "bamboo(1.00)<br/>grass(0.60)", "pred answer": "leather", "question_id": 5483185, "best approach": "wiki, concept", "verif answer": "wood", "anno approach": "wiki, concept, image", "verif wiki answer": "bamboo(0.6884)", "verif concept answer": "bamboo(0.6569)", "verif image answer": "plant(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548318.jpg"}, {"question": "what is in this picture to sit on", "gt answer": "chair(1.00)", "pred answer": "sofa", "question_id": 654475, "best approach": "image", "verif answer": "sofa", "anno approach": "wiki, concept, image", "verif wiki answer": "sofa(0.7228)", "verif concept answer": "luggage(0.6900)", "verif image answer": "chair(0.6996)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065447.jpg"}, {"question": "what is the brown brick building being used for", "gt answer": "church(1.00)<br/>school(0.60)", "pred answer": "storage", "question_id": 1003125, "best approach": "wiki", "verif answer": "church", "anno approach": "wiki, concept, image", "verif wiki answer": "school(0.7256)", "verif concept answer": "apartment(0.7238)", "verif image answer": "house(0.5124)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100312.jpg"}, {"question": "what is the man wearing", "gt answer": "bowtie(1.00)<br/>bow tie(1.00)", "pred answer": "tie", "question_id": 328725, "best approach": "wiki", "verif answer": "tie", "anno approach": "wiki, concept, image", "verif wiki answer": "bow tie(0.7233)", "verif concept answer": "tie(0.6508)", "verif image answer": "tie(0.5762)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032872.jpg"}, {"question": "if there is a high chair what type of person would use it", "gt answer": "baby(1.00)", "pred answer": "kid", "question_id": 949845, "best approach": "", "verif answer": "child", "anno approach": "wiki, concept, image", "verif wiki answer": "child(0.7242)", "verif concept answer": "teddy bear(0.6164)", "verif image answer": "2(0.5479)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094984.jpg"}, {"question": "what is the elephant avoiding stepping on", "gt answer": "human(1.00)<br/>person(1.00)<br/>man(0.60)", "pred answer": "nothing", "question_id": 5474985, "best approach": "wiki, concept, image", "verif answer": "person", "anno approach": "wiki, concept, image", "verif wiki answer": "man(0.7059)", "verif concept answer": "man(0.6663)", "verif image answer": "man(0.6982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000547498.jpg"}, {"question": "what utensils are in the picture", "gt answer": "spoon(1.00)", "pred answer": "fork", "question_id": 4890285, "best approach": "", "verif answer": "fork", "anno approach": "wiki, concept, image", "verif wiki answer": "fork(0.7237)", "verif concept answer": "fork(0.7027)", "verif image answer": "fork(0.6929)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489028.jpg"}, {"question": "why are these people in the water", "gt answer": "bath elephant(1.00)<br/>herd(0.60)<br/>play(0.60)<br/>fish(0.60)", "pred answer": "swim", "question_id": 3443855, "best approach": "wiki, concept, image", "verif answer": "play", "anno approach": "wiki, concept, image", "verif wiki answer": "herd(0.6362)", "verif concept answer": "herd(0.5979)", "verif image answer": "play(0.5323)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344385.jpg"}, {"question": "this portion of an animal is known as its what", "gt answer": "hindquarter(1.00)<br/>butt(0.60)", "pred answer": "zebra", "question_id": 2252305, "best approach": "", "verif answer": "neck", "anno approach": "wiki, concept, image", "verif wiki answer": "neck(0.7109)", "verif concept answer": "neck(0.6659)", "verif image answer": "neck(0.5593)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225230.jpg"}, {"question": "what does this bathroom say about its owner", "gt answer": "clean(1.00)<br/>male(0.60)<br/>man(0.60)", "pred answer": "pee", "question_id": 3490595, "best approach": "concept", "verif answer": "clean", "anno approach": "wiki, concept, image", "verif wiki answer": "female(0.6235)", "verif concept answer": "clean(0.6943)", "verif image answer": "male(0.6414)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000349059.jpg"}, {"question": "what famous one was bombed by the japanese in december 1941", "gt answer": "pearl harbor(1.00)<br/>harbor(0.60)", "pred answer": "john henry", "question_id": 5783175, "best approach": "wiki, concept", "verif answer": "harbor", "anno approach": "wiki, concept, image", "verif wiki answer": "pearl harbor(0.6566)", "verif concept answer": "pearl harbor(0.7292)", "verif image answer": "harbor(0.7168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578317.jpg"}, {"question": "what are the shapes around this cake", "gt answer": "star(1.00)", "pred answer": "heart", "question_id": 3871025, "best approach": "wiki, concept, image", "verif answer": "star", "anno approach": "wiki, concept, image", "verif wiki answer": "star(0.6945)", "verif concept answer": "star(0.6493)", "verif image answer": "star(0.6454)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387102.jpg"}, {"question": "what is the yellow item located inside of the glass", "gt answer": "candle(1.00)<br/>bird(0.60)", "pred answer": "ketchup and mustard", "question_id": 2641835, "best approach": "image", "verif answer": "candle", "anno approach": "wiki, concept, image", "verif wiki answer": "cupcake(0.6912)", "verif concept answer": "cupcake(0.6670)", "verif image answer": "candle(0.6658)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000264183.jpg"}, {"question": "based off the toppings where is this from", "gt answer": "germany(1.00)<br/>chicago(1.00)", "pred answer": "italy", "question_id": 1549125, "best approach": "concept, image", "verif answer": "italy", "anno approach": "wiki, concept, image", "verif wiki answer": "usa(0.7212)", "verif concept answer": "chicago(0.6786)", "verif image answer": "chicago(0.6917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154912.jpg"}, {"question": "this famous sport was desegregated who was the first african american to play with white people", "gt answer": "jackie robinson(1.00)<br/>baseball(0.60)", "pred answer": "babe ruth", "question_id": 710435, "best approach": "concept", "verif answer": "babe ruth", "anno approach": "wiki, concept, image", "verif wiki answer": "babe ruth(0.7223)", "verif concept answer": "jackie robinson(0.7296)", "verif image answer": "babe ruth(0.7087)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071043.jpg"}, {"question": "what day of the week are you least likely to have to use this machine", "gt answer": "sunday(1.00)<br/>winter(0.60)", "pred answer": "vacation", "question_id": 2756425, "best approach": "wiki", "verif answer": "rainy", "anno approach": "wiki, concept, image", "verif wiki answer": "sunday(0.7097)", "verif concept answer": "rainy(0.6116)", "verif image answer": "snowy(0.5976)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000275642.jpg"}, {"question": "in what country is this dish most famous", "gt answer": "vietnam(1.00)<br/>japan(0.60)<br/>chinese(0.60)<br/>china(0.60)", "pred answer": "italy", "question_id": 997455, "best approach": "wiki, concept", "verif answer": "china", "anno approach": "wiki, concept, image", "verif wiki answer": "vietnam(0.6986)", "verif concept answer": "vietnam(0.6855)", "verif image answer": "chinese(0.6176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099745.jpg"}, {"question": "what is this dish a good source of", "gt answer": "vitamin(1.00)<br/>calcium(0.60)", "pred answer": "protein", "question_id": 1917405, "best approach": "wiki, concept", "verif answer": "vitamin", "anno approach": "wiki, concept, image", "verif wiki answer": "calcium(0.6642)", "verif concept answer": "calcium(0.6600)", "verif image answer": "(0.5179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191740.jpg"}, {"question": "what breed is this", "gt answer": "labrador(1.00)<br/>black labrador(0.60)<br/>retriever(0.60)<br/>lab(0.60)", "pred answer": "bulldog", "question_id": 2758855, "best approach": "wiki, concept", "verif answer": "lab", "anno approach": "wiki, concept, image", "verif wiki answer": "labrador(0.7045)", "verif concept answer": "labrador(0.6800)", "verif image answer": "black lab(0.6123)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000275885.jpg"}, {"question": "what sort of wires are above the vehicle", "gt answer": "electrical(1.00)<br/>power(0.60)<br/>phone(0.60)<br/>telephone(0.60)", "pred answer": "electric", "question_id": 784105, "best approach": "wiki", "verif answer": "electrical", "anno approach": "wiki, concept, image", "verif wiki answer": "electrical(0.7093)", "verif concept answer": "telephone(0.6787)", "verif image answer": "power(0.6944)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078410.jpg"}, {"question": "what is this person doing", "gt answer": "play baseball(1.00)<br/>bat(0.60)", "pred answer": "baseball", "question_id": 1407875, "best approach": "wiki, concept, image", "verif answer": "bat", "anno approach": "wiki, concept, image", "verif wiki answer": "play baseball(0.7119)", "verif concept answer": "play baseball(0.7167)", "verif image answer": "play baseball(0.6819)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140787.jpg"}, {"question": "what is this sign for", "gt answer": "stop(1.00)<br/>traffic(0.60)", "pred answer": "crosswalk", "question_id": 834075, "best approach": "", "verif answer": "traffic control", "anno approach": "wiki, concept, image", "verif wiki answer": "traffic control(0.7154)", "verif concept answer": "traffic control(0.6959)", "verif image answer": "traffic control(0.6897)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083407.jpg"}, {"question": "what direction would you drive in this situation", "gt answer": "left(1.00)", "pred answer": "north", "question_id": 3975995, "best approach": "concept", "verif answer": "right", "anno approach": "wiki, concept, image", "verif wiki answer": "right(0.6576)", "verif concept answer": "left(0.6476)", "verif image answer": "blue(0.5134)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397599.jpg"}, {"question": "what nationality is the man holding the plate", "gt answer": "asian(1.00)<br/>white(0.60)<br/>italian(0.60)<br/>french(0.60)", "pred answer": "spanish", "question_id": 2737825, "best approach": "concept", "verif answer": "chinese", "anno approach": "wiki, concept, image", "verif wiki answer": "white(0.6649)", "verif concept answer": "asian(0.6420)", "verif image answer": "chinese(0.6090)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273782.jpg"}, {"question": "what is the name of a famous contest in kentucky these animals participate in", "gt answer": "kentucky derby(1.00)", "pred answer": "race", "question_id": 4159095, "best approach": "", "verif answer": "stallion", "anno approach": "wiki, concept, image", "verif wiki answer": "stallion(0.6463)", "verif concept answer": "saddle(0.5458)", "verif image answer": "thoroughbred(0.5629)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415909.jpg"}, {"question": "what years was this bus in public service", "gt answer": "1950(1.00)<br/>1965(0.60)<br/>1930(0.60)<br/>1945(0.60)", "pred answer": "1970", "question_id": 1921145, "best approach": "wiki, concept, image", "verif answer": "1965", "anno approach": "wiki, concept, image", "verif wiki answer": "1930(0.6832)", "verif concept answer": "1930(0.6754)", "verif image answer": "1965(0.7015)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000192114.jpg"}, {"question": "what ocean sea is this", "gt answer": "caribbean(1.00)<br/>atlantic(0.60)<br/>pacific(0.60)<br/>atlantic ocean(0.60)", "pred answer": "pacific ocean", "question_id": 496115, "best approach": "wiki", "verif answer": "pacific ocean", "anno approach": "wiki, concept, image", "verif wiki answer": "atlantic(0.7101)", "verif concept answer": "pacific ocean(0.7050)", "verif image answer": "pacific ocean(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049611.jpg"}, {"question": "what profession would most likely use these intruments", "gt answer": "doctor(1.00)", "pred answer": "barber", "question_id": 3835815, "best approach": "concept", "verif answer": "doctor", "anno approach": "wiki, concept, image", "verif wiki answer": "nurse(0.7241)", "verif concept answer": "doctor(0.6528)", "verif image answer": "nurse(0.5303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383581.jpg"}, {"question": "", "gt answer": "1960's(0.60)<br/>1970(0.60)<br/>1970's(0.60)", "pred answer": "1940s", "question_id": 4098345, "best approach": "concept, image", "verif answer": "1970", "anno approach": "wiki, concept, image", "verif wiki answer": "70s(0.6004)", "verif concept answer": "1970's(0.5784)", "verif image answer": "1970(0.5690)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409834.jpg"}, {"question": "what sort of scottish garment is often associated with a pattern similar to that upon this pink and yellow couch", "gt answer": "kilt(1.00)<br/>plaid(1.00)", "pred answer": "sweater", "question_id": 4685305, "best approach": "", "verif answer": "skirt", "anno approach": "wiki, concept, image", "verif wiki answer": "checkered(0.7186)", "verif concept answer": "checkered(0.7016)", "verif image answer": "checkered(0.5377)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000468530.jpg"}, {"question": "what type of food is this", "gt answer": "sushi(1.00)<br/>soup(0.60)<br/>vegetable(0.60)", "pred answer": "stew", "question_id": 5056255, "best approach": "concept", "verif answer": "carrot", "anno approach": "wiki, concept, image", "verif wiki answer": "carrot(0.6930)", "verif concept answer": "soup(0.7157)", "verif image answer": "meat(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505625.jpg"}, {"question": "how can we be sure which men are not playing this game", "gt answer": "sit(1.00)", "pred answer": "television", "question_id": 5385185, "best approach": "wiki, concept", "verif answer": "reflection", "anno approach": "wiki, concept, image", "verif wiki answer": "sit(0.7015)", "verif concept answer": "sit(0.7090)", "verif image answer": "balance(0.6179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538518.jpg"}, {"question": "what does the street sign mean to drivers", "gt answer": "do not enter(1.00)<br/>yield(0.60)", "pred answer": "no park", "question_id": 3836395, "best approach": "wiki", "verif answer": "do not enter", "anno approach": "wiki, concept, image", "verif wiki answer": "do not enter(0.6629)", "verif concept answer": "stall(0.6472)", "verif image answer": "stall(0.6610)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383639.jpg"}, {"question": "what meat was used", "gt answer": "salami(1.00)<br/>ham(0.60)<br/>fish(0.60)<br/>pork(0.60)", "pred answer": "beef", "question_id": 5100275, "best approach": "wiki, image", "verif answer": "beef", "anno approach": "wiki, concept, image", "verif wiki answer": "ham(0.7192)", "verif concept answer": "beef(0.7114)", "verif image answer": "pork(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510027.jpg"}, {"question": "what is the offspring of this animal and a horse called", "gt answer": "zorse(1.00)<br/>kid(0.60)<br/>foal(0.60)", "pred answer": "mother", "question_id": 2448475, "best approach": "", "verif answer": "foal", "anno approach": "wiki, concept, image", "verif wiki answer": "woman(0.5645)", "verif concept answer": "woman(0.5559)", "verif image answer": "single(0.5886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244847.jpg"}, {"question": "what type of bike is this", "gt answer": "dirt bike(1.00)<br/>motor(0.60)<br/>motorbike(0.60)", "pred answer": "motorcycle", "question_id": 236315, "best approach": "wiki, concept", "verif answer": "dirt bike", "anno approach": "wiki, concept, image", "verif wiki answer": "dirt bike(0.7030)", "verif concept answer": "dirt bike(0.7047)", "verif image answer": "motor(0.6587)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023631.jpg"}, {"question": "what language is this sign in", "gt answer": "arabic(1.00)<br/>japanese(0.60)", "pred answer": "english", "question_id": 5596195, "best approach": "wiki, concept, image", "verif answer": "arabic", "anno approach": "wiki, concept, image", "verif wiki answer": "arabic(0.7267)", "verif concept answer": "arabic(0.7288)", "verif image answer": "arabic(0.7087)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559619.jpg"}, {"question": "what form of animal is this", "gt answer": "polar bear(1.00)<br/>bear(1.00)", "pred answer": "sheep", "question_id": 4721815, "best approach": "image", "verif answer": "sheep", "anno approach": "wiki, concept, image", "verif wiki answer": "sheep(0.6937)", "verif concept answer": "mammal(0.6167)", "verif image answer": "bear(0.5205)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000472181.jpg"}, {"question": "when would he wear these types of clothes", "gt answer": "interview(1.00)<br/>business(0.60)<br/>work(0.60)<br/>meet(0.60)", "pred answer": "wed", "question_id": 348165, "best approach": "wiki", "verif answer": "wed", "anno approach": "wiki, concept, image", "verif wiki answer": "interview(0.7271)", "verif concept answer": "wed(0.6578)", "verif image answer": "business(0.6869)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000034816.jpg"}, {"question": "what is the white item on the left for", "gt answer": "keep food cold(1.00)<br/>fridge(0.60)<br/>storage(0.60)", "pred answer": "refrigeration", "question_id": 966905, "best approach": "concept", "verif answer": "keep food cold", "anno approach": "wiki, concept, image", "verif wiki answer": "refridgerator(0.7171)", "verif concept answer": "fridge(0.6862)", "verif image answer": "refridgerator(0.6501)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096690.jpg"}, {"question": "what is the texture of that white stuffed animal", "gt answer": "fluffy(1.00)<br/>silk(0.60)<br/>soft(0.60)", "pred answer": "fur", "question_id": 2212895, "best approach": "", "verif answer": "soft", "anno approach": "wiki, concept, image", "verif wiki answer": "checkered(0.6407)", "verif concept answer": "stuffed(0.6002)", "verif image answer": "checkered(0.5853)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221289.jpg"}, {"question": "is the second floor of the building residential or commercial property", "gt answer": "residential(1.00)", "pred answer": "commercial", "question_id": 3696895, "best approach": "", "verif answer": "hotel", "anno approach": "wiki, concept, image", "verif wiki answer": "hotel(0.7211)", "verif concept answer": "urban(0.6895)", "verif image answer": "hotel(0.7145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369689.jpg"}, {"question": "what topping is on this donut", "gt answer": "coconut(1.00)", "pred answer": "sprinkle", "question_id": 680855, "best approach": "", "verif answer": "sprinkle", "anno approach": "wiki, concept, image", "verif wiki answer": "sprinkle(0.6964)", "verif concept answer": "sprinkle(0.7243)", "verif image answer": "pine(0.7174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068085.jpg"}, {"question": "how many times a day does the average person enter one of these types of rooms", "gt answer": "5(1.00)<br/>7(0.60)<br/>3(0.60)<br/>8(0.60)", "pred answer": "10", "question_id": 848335, "best approach": "wiki, concept, image", "verif answer": "8", "anno approach": "wiki, concept, image", "verif wiki answer": "8(0.6453)", "verif concept answer": "8(0.5898)", "verif image answer": "7(0.6261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084833.jpg"}, {"question": "what company operates this airplane", "gt answer": "korean air(1.00)<br/>united(0.60)", "pred answer": "boeing", "question_id": 2834265, "best approach": "", "verif answer": "united", "anno approach": "wiki, concept, image", "verif wiki answer": "lufthansa(0.7257)", "verif concept answer": "lufthansa(0.7259)", "verif image answer": "lufthansa(0.5419)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283426.jpg"}, {"question": "people sit here and put on their makeup what is this type of desk called", "gt answer": "vanity(1.00)", "pred answer": "bathroom", "question_id": 4652135, "best approach": "wiki, concept, image", "verif answer": "bathroom", "anno approach": "wiki, concept, image", "verif wiki answer": "vanity(0.5753)", "verif concept answer": "vanity(0.5430)", "verif image answer": "vanity(0.6079)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465213.jpg"}, {"question": "a game played with a stick is called what", "gt answer": "hockey(1.00)", "pred answer": "disc golf", "question_id": 5162495, "best approach": "wiki", "verif answer": "hockey", "anno approach": "wiki, concept, image", "verif wiki answer": "hockey(0.6620)", "verif concept answer": "baseball(0.5868)", "verif image answer": "soccer(0.5051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516249.jpg"}, {"question": "what might they be buying", "gt answer": "produce(1.00)<br/>vegetable(1.00)<br/>cabbage(0.60)", "pred answer": "food", "question_id": 1896455, "best approach": "wiki, concept", "verif answer": "vegetable", "anno approach": "wiki, concept, image", "verif wiki answer": "vegetable(0.6951)", "verif concept answer": "vegetable(0.6644)", "verif image answer": "fruit(0.7023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000189645.jpg"}, {"question": "is this elephant real or man made", "gt answer": "manmade(1.00)<br/>man made(1.00)", "pred answer": "real", "question_id": 3234895, "best approach": "wiki, concept, image", "verif answer": "man made", "anno approach": "wiki, concept, image", "verif wiki answer": "manmade(0.6246)", "verif concept answer": "manmade(0.7056)", "verif image answer": "manmade(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323489.jpg"}, {"question": "what is the cat sitting in", "gt answer": "bed(1.00)", "pred answer": "couch", "question_id": 1675775, "best approach": "wiki", "verif answer": "bed", "anno approach": "wiki, concept, image", "verif wiki answer": "bed(0.7273)", "verif concept answer": "pillow(0.7104)", "verif image answer": "pillow(0.7021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167577.jpg"}, {"question": "what breed of dog is in the photo", "gt answer": "beagle(1.00)", "pred answer": "mix", "question_id": 4283105, "best approach": "image", "verif answer": "beagle", "anno approach": "wiki, concept, image", "verif wiki answer": "shepherd(0.6239)", "verif concept answer": "shepherd(0.6746)", "verif image answer": "beagle(0.6718)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428310.jpg"}, {"question": "what traffic sign is the street man holding", "gt answer": "stop sign(1.00)<br/>stop(1.00)", "pred answer": "yield", "question_id": 4117055, "best approach": "wiki", "verif answer": "yield", "anno approach": "wiki, concept, image", "verif wiki answer": "stop(0.7244)", "verif concept answer": "bus stop(0.7279)", "verif image answer": "4 way stop(0.5060)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000411705.jpg"}, {"question": "what is the thing on the wall used for", "gt answer": "reflection(1.00)<br/>mirror(0.60)<br/>light(0.60)", "pred answer": "sleep", "question_id": 5057135, "best approach": "wiki, concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "mirror(0.6269)", "verif concept answer": "light(0.6754)", "verif image answer": "remote(0.5414)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505713.jpg"}, {"question": "who painted the painting hanging on the back wall of this restaurant", "gt answer": "van gogh(1.00)", "pred answer": "artist", "question_id": 2836825, "best approach": "", "verif answer": "van gogh", "anno approach": "wiki, concept, image", "verif wiki answer": "man(0.5791)", "verif concept answer": "monet(0.5692)", "verif image answer": "man(0.5288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283682.jpg"}, {"question": "are roses annuals or perennials", "gt answer": "annual(1.00)", "pred answer": "purity", "question_id": 1151565, "best approach": "", "verif answer": "teddy roosevelt", "anno approach": "wiki, concept, image", "verif wiki answer": "teddy roosevelt(0.5111)", "verif concept answer": "teddy roosevelt(0.6987)", "verif image answer": "teddy roosevelt(0.7071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115156.jpg"}, {"question": "where is the mast famous outside market for this type of goods", "gt answer": "mexico(1.00)<br/>europe(0.60)<br/>flea market(0.60)", "pred answer": "china", "question_id": 1784115, "best approach": "wiki, concept", "verif answer": "south america", "anno approach": "wiki, concept, image", "verif wiki answer": "mexico(0.7240)", "verif concept answer": "mexico(0.7215)", "verif image answer": "flea market(0.7056)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178411.jpg"}, {"question": "why would we suspect that this individual has the ability to filter our distractions", "gt answer": "headphone(1.00)", "pred answer": "text", "question_id": 1810095, "best approach": "wiki", "verif answer": "television", "anno approach": "wiki, concept, image", "verif wiki answer": "headphone(0.7270)", "verif concept answer": "earbud(0.7142)", "verif image answer": "hear(0.5859)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181009.jpg"}, {"question": "what style of furniture is this table and example of", "gt answer": "antique(1.00)<br/>formal(0.60)", "pred answer": "gothic", "question_id": 4946225, "best approach": "wiki", "verif answer": "old", "anno approach": "wiki, concept, image", "verif wiki answer": "antique(0.6983)", "verif concept answer": "roman(0.6250)", "verif image answer": "roman(0.7096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494622.jpg"}, {"question": "what is driver 's jacket made out of", "gt answer": "leather(1.00)", "pred answer": "neoprene", "question_id": 1712725, "best approach": "", "verif answer": "rubber", "anno approach": "wiki, concept, image", "verif wiki answer": "rubber(0.6878)", "verif concept answer": "rubber(0.6886)", "verif image answer": "rubber(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171272.jpg"}, {"question": "what is the person 's shape on the wall called", "gt answer": "shadow(1.00)", "pred answer": "rectangle", "question_id": 3429495, "best approach": "concept", "verif answer": "reflection", "anno approach": "wiki, concept, image", "verif wiki answer": "reflection(0.6688)", "verif concept answer": "shadow(0.6234)", "verif image answer": "sunset(0.7089)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342949.jpg"}, {"question": "how capable is the cat at using the device", "gt answer": "not(1.00)<br/>not at all(0.60)", "pred answer": "not very", "question_id": 1096295, "best approach": "wiki", "verif answer": "not very", "anno approach": "wiki, concept, image", "verif wiki answer": "not at all(0.7193)", "verif concept answer": "very healthy(0.6250)", "verif image answer": "very healthy(0.6473)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000109629.jpg"}, {"question": "is this toast or french toast", "gt answer": "french toast(1.00)<br/>toast(0.60)<br/>french(0.60)", "pred answer": "deep dish", "question_id": 4332215, "best approach": "concept", "verif answer": "breakfast", "anno approach": "wiki, concept, image", "verif wiki answer": "breakfast(0.6032)", "verif concept answer": "french(0.6221)", "verif image answer": "breakfast(0.5154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433221.jpg"}, {"question": "where can this boat go", "gt answer": "to sea(1.00)", "pred answer": "dock", "question_id": 895825, "best approach": "", "verif answer": "airport", "anno approach": "wiki, concept, image", "verif wiki answer": "airport(0.6901)", "verif concept answer": "airport(0.6673)", "verif image answer": "us(0.6624)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089582.jpg"}, {"question": "why is this banana brown", "gt answer": "over ripe(1.00)<br/>ripe(0.60)<br/>bad(0.60)", "pred answer": "not ripe", "question_id": 2930125, "best approach": "image", "verif answer": "bad", "anno approach": "wiki, concept, image", "verif wiki answer": "drink(0.7146)", "verif concept answer": "drink(0.6493)", "verif image answer": "over ripe(0.6968)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293012.jpg"}, {"question": "what type of scenery is this", "gt answer": "patio(1.00)<br/>cafe(0.60)<br/>indoor(0.60)", "pred answer": "city", "question_id": 2794775, "best approach": "concept, image", "verif answer": "indoor", "anno approach": "wiki, concept, image", "verif wiki answer": "garden(0.7216)", "verif concept answer": "indoor(0.6742)", "verif image answer": "indoor(0.7085)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000279477.jpg"}, {"question": "what is the cost of pineapples", "gt answer": "1.5(1.00)<br/>50(0.60)", "pred answer": "$500", "question_id": 2364845, "best approach": "wiki", "verif answer": "20 pounds", "anno approach": "wiki, concept, image", "verif wiki answer": "50(0.5733)", "verif concept answer": "20 pounds(0.5884)", "verif image answer": "15(0.5282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236484.jpg"}, {"question": "what is the sink layout in this picture commonly called", "gt answer": "vanity(1.00)<br/>double(0.60)<br/>jack and jill(0.60)<br/>bathroom(0.60)", "pred answer": "modern", "question_id": 1995985, "best approach": "image", "verif answer": "bathroom", "anno approach": "wiki, concept, image", "verif wiki answer": "cleanliness(0.6382)", "verif concept answer": "cleanliness(0.6066)", "verif image answer": "vanity(0.7155)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199598.jpg"}, {"question": "what diet plan would this meal fall under", "gt answer": "healthy(1.00)", "pred answer": "vegetarian", "question_id": 439175, "best approach": "image", "verif answer": "vegetarian", "anno approach": "wiki, concept, image", "verif wiki answer": "vegetarian(0.7164)", "verif concept answer": "extremely(0.6637)", "verif image answer": "healthy(0.6785)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043917.jpg"}, {"question": "what culture considers these to be good luck", "gt answer": "indian(1.00)<br/>hindi(0.60)", "pred answer": "hindu", "question_id": 4566525, "best approach": "", "verif answer": "indian", "anno approach": "wiki, concept, image", "verif wiki answer": "arabic(0.6628)", "verif concept answer": "arabic(0.7087)", "verif image answer": "arabic(0.5331)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456652.jpg"}, {"question": "is the baby laughing or crying", "gt answer": "cry(1.00)", "pred answer": "bond", "question_id": 2636855, "best approach": "", "verif answer": "happy", "anno approach": "wiki, concept, image", "verif wiki answer": "smile(0.7280)", "verif concept answer": "smile(0.6395)", "verif image answer": "brush(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263685.jpg"}, {"question": "what type of natural disaster can happen in a place like this", "gt answer": "avalanche(1.00)", "pred answer": "fall", "question_id": 5378755, "best approach": "wiki, concept", "verif answer": "fall", "anno approach": "wiki, concept, image", "verif wiki answer": "avalanche(0.7259)", "verif concept answer": "avalanche(0.6705)", "verif image answer": "fall(0.6771)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537875.jpg"}, {"question": "what is the purpose railings and stairs in the picture", "gt answer": "fire escape(1.00)", "pred answer": "safety", "question_id": 2594395, "best approach": "", "verif answer": "stair", "anno approach": "wiki, concept, image", "verif wiki answer": "stair(0.6188)", "verif concept answer": "stair(0.5887)", "verif image answer": "bag(0.6884)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259439.jpg"}, {"question": "what company made this train", "gt answer": "amtrack(1.00)<br/>virgin(0.60)", "pred answer": "richard trevithick", "question_id": 367765, "best approach": "image", "verif answer": "virgin", "anno approach": "wiki, concept, image", "verif wiki answer": "american airline(0.6729)", "verif concept answer": "bullet train(0.6885)", "verif image answer": "virgin(0.7134)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036776.jpg"}, {"question": "what type of object is inserted in this system to play games", "gt answer": "cd(1.00)<br/>disc(1.00)", "pred answer": "wii", "question_id": 2600975, "best approach": "wiki", "verif answer": "camera", "anno approach": "wiki, concept, image", "verif wiki answer": "cd(0.7078)", "verif concept answer": "camera(0.5867)", "verif image answer": "camera(0.6117)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260097.jpg"}, {"question": "what are the line of people holding", "gt answer": "flag(1.00)", "pred answer": "fan", "question_id": 2551865, "best approach": "", "verif answer": "kite", "anno approach": "wiki, concept, image", "verif wiki answer": "shield(0.6883)", "verif concept answer": "kite(0.7095)", "verif image answer": "kite(0.6494)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255186.jpg"}, {"question": "", "gt answer": "light(0.60)<br/>decoration(0.60)<br/>decor(0.60)", "pred answer": "fly", "question_id": 3937055, "best approach": "", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "paint(0.5448)", "verif concept answer": "paint(0.5385)", "verif image answer": "paint(0.5202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393705.jpg"}, {"question": "are these different animals in this picture or all they all the same animal", "gt answer": "different(1.00)<br/>same(1.00)", "pred answer": "cow", "question_id": 4614455, "best approach": "wiki, concept, image", "verif answer": "ram", "anno approach": "wiki, concept, image", "verif wiki answer": "different(0.7231)", "verif concept answer": "different(0.7185)", "verif image answer": "same(0.6449)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461445.jpg"}, {"question": "the orange fruit is associated with preventing which disease that was once the scourge of sailors", "gt answer": "scurvy(1.00)<br/>grapefruit(0.60)", "pred answer": "cancer", "question_id": 5452575, "best approach": "concept", "verif answer": "cancer", "anno approach": "wiki, concept, image", "verif wiki answer": "cancer(0.6546)", "verif concept answer": "scurvy(0.7293)", "verif image answer": "orange(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545257.jpg"}, {"question": "how many teeth do these animals have", "gt answer": "42(1.00)<br/>36(0.60)<br/>28(0.60)", "pred answer": "400", "question_id": 5526575, "best approach": "wiki, image", "verif answer": "42", "anno approach": "wiki, concept, image", "verif wiki answer": "36(0.7142)", "verif concept answer": "lot(0.6861)", "verif image answer": "28(0.6387)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552657.jpg"}, {"question": "what kind of finish was applied to the floors of this house", "gt answer": "gloss(1.00)<br/>wax(0.60)", "pred answer": "tile", "question_id": 283495, "best approach": "", "verif answer": "laminate", "anno approach": "wiki, concept, image", "verif wiki answer": "laminate(0.6136)", "verif concept answer": "laminate(0.6907)", "verif image answer": "vacuum(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028349.jpg"}, {"question": "this red item is often used when traveling on what sort of vehicle", "gt answer": "airplane(1.00)<br/>plane(0.60)<br/>luggage(0.60)", "pred answer": "bus", "question_id": 3210705, "best approach": "wiki, image", "verif answer": "plane", "anno approach": "wiki, concept, image", "verif wiki answer": "airplane(0.6664)", "verif concept answer": "plane(0.6843)", "verif image answer": "airplane(0.5111)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321070.jpg"}, {"question": "can you tell the type of wall shown in the photo", "gt answer": "wooden(1.00)<br/>cabin(0.60)<br/>wood(0.60)", "pred answer": "bathroom", "question_id": 206525, "best approach": "image", "verif answer": "wood", "anno approach": "wiki, concept, image", "verif wiki answer": "wall(0.6242)", "verif concept answer": "wall(0.6491)", "verif image answer": "cabin(0.5196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020652.jpg"}, {"question": "who invented the heater in this image", "gt answer": "franz san galli(1.00)<br/>benjamin franklin(0.60)<br/>plumber(0.60)", "pred answer": "sprague", "question_id": 3174585, "best approach": "wiki", "verif answer": "ben franklin", "anno approach": "wiki, concept, image", "verif wiki answer": "franz san galli(0.7227)", "verif concept answer": "ben franklin(0.5995)", "verif image answer": "plumber(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317458.jpg"}, {"question": "based on the photo how busy is it in the street tonight", "gt answer": "not busy(1.00)<br/>quiet(0.60)<br/>not at all(0.60)", "pred answer": "very", "question_id": 2622605, "best approach": "image", "verif answer": "not very", "anno approach": "wiki, concept, image", "verif wiki answer": "not very(0.7262)", "verif concept answer": "not very(0.7071)", "verif image answer": "quiet(0.7005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262260.jpg"}, {"question": "which children 's character does this resemble", "gt answer": "thomas train(1.00)<br/>thomas tank engine(0.60)", "pred answer": "mickey mouse", "question_id": 198635, "best approach": "", "verif answer": "thomas", "anno approach": "wiki, concept, image", "verif wiki answer": "thomas(0.7031)", "verif concept answer": "thomas(0.5101)", "verif image answer": "thomas(0.7185)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019863.jpg"}, {"question": "where should you not drive your car according to the sign", "gt answer": "driveway(1.00)", "pred answer": "no park", "question_id": 1858485, "best approach": "wiki", "verif answer": "school", "anno approach": "wiki, concept, image", "verif wiki answer": "driveway(0.6020)", "verif concept answer": "rv(0.6908)", "verif image answer": "student(0.5999)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185848.jpg"}, {"question": "do the fridges appear to be in a home or a place of business", "gt answer": "business(1.00)", "pred answer": "store", "question_id": 5669925, "best approach": "", "verif answer": "professional", "anno approach": "wiki, concept, image", "verif wiki answer": "professional(0.5708)", "verif concept answer": "professional(0.7059)", "verif image answer": "professional(0.5061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566992.jpg"}, {"question": "what paste is applied before doing this activity", "gt answer": "toothpaste(1.00)", "pred answer": "lipstick", "question_id": 2595955, "best approach": "concept", "verif answer": "soap", "anno approach": "wiki, concept, image", "verif wiki answer": "soap(0.7109)", "verif concept answer": "toothpaste(0.6977)", "verif image answer": "mirror(0.5713)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259595.jpg"}, {"question": "what is that for", "gt answer": "call(1.00)<br/>talk(0.60)<br/>take picture(0.60)", "pred answer": "cut", "question_id": 1224535, "best approach": "wiki, concept, image", "verif answer": "talk", "anno approach": "wiki, concept, image", "verif wiki answer": "take picture(0.6983)", "verif concept answer": "talk(0.6151)", "verif image answer": "talk(0.6944)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122453.jpg"}, {"question": "what can you use to cross this body of water", "gt answer": "boat(1.00)<br/>raft(0.60)", "pred answer": "helicopter", "question_id": 5141935, "best approach": "wiki, concept, image", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "boat(0.7058)", "verif concept answer": "boat(0.7158)", "verif image answer": "boat(0.7168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514193.jpg"}, {"question": "how old is this child", "gt answer": "6 months(1.00)<br/>2 months(0.60)<br/>8 months(0.60)", "pred answer": "1 year", "question_id": 1915255, "best approach": "concept, image", "verif answer": "8 months", "anno approach": "wiki, concept, image", "verif wiki answer": "3 months(0.6352)", "verif concept answer": "8 months(0.6387)", "verif image answer": "2 months(0.7217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191525.jpg"}, {"question": "what airline is this", "gt answer": "southwest(1.00)", "pred answer": "american airline", "question_id": 2025835, "best approach": "", "verif answer": "american airline", "anno approach": "wiki, concept, image", "verif wiki answer": "american airline(0.7280)", "verif concept answer": "american airline(0.6680)", "verif image answer": "boeing(0.5476)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202583.jpg"}, {"question": "how many people will this food serve", "gt answer": "8(1.00)<br/>4(0.60)<br/>3(0.60)<br/>2(0.60)", "pred answer": "12", "question_id": 4881505, "best approach": "wiki, concept", "verif answer": "8", "anno approach": "wiki, concept, image", "verif wiki answer": "4(0.6769)", "verif concept answer": "2(0.6514)", "verif image answer": "1(0.6139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488150.jpg"}, {"question": "how long does this animal usually live", "gt answer": "30 years(1.00)<br/>30(0.60)<br/>10 years(0.60)", "pred answer": "20 years", "question_id": 4206085, "best approach": "wiki, concept", "verif answer": "30 years", "anno approach": "wiki, concept, image", "verif wiki answer": "30 years(0.6667)", "verif concept answer": "30 years(0.6512)", "verif image answer": "30(0.6415)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420608.jpg"}, {"question": "what is hanging from this pole", "gt answer": "street sign(1.00)<br/>sign(1.00)", "pred answer": "wire", "question_id": 1271045, "best approach": "wiki, concept", "verif answer": "street name", "anno approach": "wiki, concept, image", "verif wiki answer": "street sign(0.6023)", "verif concept answer": "street sign(0.6685)", "verif image answer": "street name(0.7110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127104.jpg"}, {"question": "where is this couple walking around at", "gt answer": "carnival(1.00)<br/>amusement park(0.60)<br/>india(0.60)", "pred answer": "circus", "question_id": 2496195, "best approach": "wiki, concept", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "carnival(0.6227)", "verif concept answer": "carnival(0.6558)", "verif image answer": "banana(0.7023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249619.jpg"}, {"question": "what brand of motocycle is this", "gt answer": "bmw(1.00)", "pred answer": "harley", "question_id": 2871735, "best approach": "wiki, concept", "verif answer": "harley", "anno approach": "wiki, concept, image", "verif wiki answer": "bmw(0.6937)", "verif concept answer": "bmw(0.6771)", "verif image answer": "harley(0.6684)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287173.jpg"}, {"question": "what type of sandwich is this", "gt answer": "grilled cheese(1.00)<br/>toasted(0.60)", "pred answer": "chicken", "question_id": 2955715, "best approach": "concept, image", "verif answer": "grilled cheese", "anno approach": "wiki, concept, image", "verif wiki answer": "fried(0.7086)", "verif concept answer": "grilled cheese(0.7120)", "verif image answer": "grilled cheese(0.6981)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295571.jpg"}, {"question": "what is this plant doing in water", "gt answer": "grow(1.00)", "pred answer": "drink", "question_id": 3586205, "best approach": "concept", "verif answer": "drink", "anno approach": "wiki, concept, image", "verif wiki answer": "drink(0.6173)", "verif concept answer": "grow(0.6383)", "verif image answer": "drink(0.5798)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358620.jpg"}, {"question": "who would be most likely to sit here", "gt answer": "person(1.00)<br/>people(0.60)", "pred answer": "human", "question_id": 2430005, "best approach": "wiki", "verif answer": "human", "anno approach": "wiki, concept, image", "verif wiki answer": "person(0.6913)", "verif concept answer": "human(0.6277)", "verif image answer": "human(0.5073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243000.jpg"}, {"question": "what are the doors in the background called", "gt answer": "french(1.00)<br/>french door(0.60)", "pred answer": "slide", "question_id": 2905845, "best approach": "concept, image", "verif answer": "arch", "anno approach": "wiki, concept, image", "verif wiki answer": "arch(0.6785)", "verif concept answer": "french door(0.5586)", "verif image answer": "french door(0.5499)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000290584.jpg"}, {"question": "where does this vehicle travel", "gt answer": "air(1.00)", "pred answer": "runway", "question_id": 74895, "best approach": "image", "verif answer": "air", "anno approach": "wiki, concept, image", "verif wiki answer": "sky(0.5975)", "verif concept answer": "sky(0.6092)", "verif image answer": "air(0.6344)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007489.jpg"}, {"question": "what team hat is he wearing", "gt answer": "yankees(1.00)<br/>met(0.60)", "pred answer": "red sox", "question_id": 558725, "best approach": "image", "verif answer": "red sox", "anno approach": "wiki, concept, image", "verif wiki answer": "dodger(0.7108)", "verif concept answer": "red sox(0.6664)", "verif image answer": "yankees(0.6708)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000055872.jpg"}, {"question": "what brand of peanuts is this", "gt answer": "fisher(1.00)<br/>walmart(0.60)", "pred answer": "pepsi", "question_id": 5240565, "best approach": "concept, image", "verif answer": "krispy kreme", "anno approach": "wiki, concept, image", "verif wiki answer": "target(0.6200)", "verif concept answer": "fisher(0.5560)", "verif image answer": "fisher(0.5737)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000524056.jpg"}, {"question": "what is the name for a device you put money in to park your car", "gt answer": "meter(1.00)", "pred answer": "park meter", "question_id": 1520565, "best approach": "concept", "verif answer": "park meter", "anno approach": "wiki, concept, image", "verif wiki answer": "park meter(0.7060)", "verif concept answer": "meter(0.6482)", "verif image answer": "wrench(0.7075)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000152056.jpg"}, {"question": "who owns this airplane", "gt answer": "skyteam(1.00)<br/>american airline(0.60)", "pred answer": "click", "question_id": 1262825, "best approach": "image", "verif answer": "airbus", "anno approach": "wiki, concept, image", "verif wiki answer": "american airline(0.7091)", "verif concept answer": "american airline(0.7263)", "verif image answer": "skyteam(0.5063)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126282.jpg"}, {"question": "what it company does he work for", "gt answer": "microsoft(1.00)<br/>best buy(0.60)<br/>geek squad(0.60)<br/>ibm(0.60)", "pred answer": "hp", "question_id": 3006205, "best approach": "wiki, image", "verif answer": "ibm", "anno approach": "wiki, concept, image", "verif wiki answer": "ibm(0.7083)", "verif concept answer": "excel(0.6698)", "verif image answer": "ibm(0.5806)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300620.jpg"}, {"question": "what is the metal structure holding up", "gt answer": "power line(1.00)", "pred answer": "clock", "question_id": 5340265, "best approach": "", "verif answer": "wire", "anno approach": "wiki, concept, image", "verif wiki answer": "overhead(0.7149)", "verif concept answer": "overhead(0.7088)", "verif image answer": "wire(0.5514)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534026.jpg"}, {"question": "what event was captured by is this photograph", "gt answer": "protest(1.00)", "pred answer": "birthday", "question_id": 3521805, "best approach": "wiki", "verif answer": "parade", "anno approach": "wiki, concept, image", "verif wiki answer": "protest(0.6961)", "verif concept answer": "selfie(0.6618)", "verif image answer": "selfie(0.6982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000352180.jpg"}, {"question": "is this a popular or unpopular sport", "gt answer": "popular(1.00)<br/>tennis(0.60)", "pred answer": "double", "question_id": 1148805, "best approach": "", "verif answer": "tournament", "anno approach": "wiki, concept, image", "verif wiki answer": "tournament(0.7105)", "verif concept answer": "high 5(0.6862)", "verif image answer": "tournament(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114880.jpg"}, {"question": "what other animals have the same diet as this one", "gt answer": "herbivore(1.00)<br/>elephant(0.60)<br/>monkey(0.60)<br/>zebra(0.60)", "pred answer": "skunk", "question_id": 2395815, "best approach": "concept", "verif answer": "mammal", "anno approach": "wiki, concept, image", "verif wiki answer": "elephant(0.6925)", "verif concept answer": "herbivore(0.6768)", "verif image answer": "elephant(0.6648)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000239581.jpg"}, {"question": "what kind of plant is this", "gt answer": "flower(1.00)<br/>lily(0.60)", "pred answer": "rose bush", "question_id": 1195505, "best approach": "wiki, image", "verif answer": "flower", "anno approach": "wiki, concept, image", "verif wiki answer": "flower(0.7061)", "verif concept answer": "floral(0.6374)", "verif image answer": "flower(0.6898)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119550.jpg"}, {"question": "why kind of ship is depicted", "gt answer": "pirate(1.00)<br/>sailboat(0.60)<br/>0(0.60)", "pred answer": "kite", "question_id": 3783055, "best approach": "wiki, concept, image", "verif answer": "0", "anno approach": "wiki, concept, image", "verif wiki answer": "pirate(0.7200)", "verif concept answer": "pirate(0.6963)", "verif image answer": "pirate(0.6877)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378305.jpg"}, {"question": "what harbor is this", "gt answer": "boat(1.00)", "pred answer": "san francisco", "question_id": 4843865, "best approach": "", "verif answer": "harbor", "anno approach": "wiki, concept, image", "verif wiki answer": "harbor(0.6091)", "verif concept answer": "harbor(0.6301)", "verif image answer": "sail(0.6126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484386.jpg"}, {"question": "what railroad are they traveling", "gt answer": "subway(1.00)<br/>bristol(1.00)<br/>train(0.60)", "pred answer": "commuter", "question_id": 2981545, "best approach": "wiki, concept, image", "verif answer": "train", "anno approach": "wiki, concept, image", "verif wiki answer": "train(0.5565)", "verif concept answer": "train(0.5827)", "verif image answer": "train(0.6415)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000298154.jpg"}, {"question": "what topping is on the food", "gt answer": "rhubarb(1.00)<br/>fruit(0.60)<br/>strawberry(0.60)<br/>pepper(0.60)", "pred answer": "ketchup", "question_id": 5162055, "best approach": "wiki, concept, image", "verif answer": "strawberry", "anno approach": "wiki, concept, image", "verif wiki answer": "pepper(0.6694)", "verif concept answer": "pepper(0.6144)", "verif image answer": "fruit(0.5357)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516205.jpg"}, {"question": "what kind of birds are this", "gt answer": "sparrow(1.00)<br/>pigeon(0.60)<br/>brown(0.60)", "pred answer": "hawk", "question_id": 55645, "best approach": "wiki, concept, image", "verif answer": "pigeon", "anno approach": "wiki, concept, image", "verif wiki answer": "brown(0.6736)", "verif concept answer": "pigeon(0.7101)", "verif image answer": "pigeon(0.6855)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005564.jpg"}, {"question": "what is the name of the mascot pictured", "gt answer": "phillie phanatic(1.00)", "pred answer": "oriole", "question_id": 3651315, "best approach": "wiki, concept", "verif answer": "ty cobb", "anno approach": "wiki, concept, image", "verif wiki answer": "phillie phanatic(0.7263)", "verif concept answer": "phillie phanatic(0.6373)", "verif image answer": "ty cobb(0.6549)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365131.jpg"}, {"question": "is this singles or doubles tennis", "gt answer": "single(1.00)", "pred answer": "double", "question_id": 3006845, "best approach": "", "verif answer": "single", "anno approach": "wiki, concept, image", "verif wiki answer": "kid(0.6666)", "verif concept answer": "woman(0.6318)", "verif image answer": "kid(0.6754)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300684.jpg"}, {"question": "these umbrellas are associated with what sort of eating venue", "gt answer": "cafe(1.00)<br/>hotdog(0.60)<br/>outside(0.60)", "pred answer": "cafeteria", "question_id": 5204865, "best approach": "image", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "restaurant(0.7257)", "verif concept answer": "restaurant(0.6896)", "verif image answer": "outside(0.6410)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520486.jpg"}, {"question": "what year was the sport in this picture invented", "gt answer": "1950(1.00)<br/>skateboard(0.60)", "pred answer": "1965", "question_id": 1840035, "best approach": "", "verif answer": "1950", "anno approach": "wiki, concept, image", "verif wiki answer": "1800(0.6838)", "verif concept answer": "1800(0.6392)", "verif image answer": "1800(0.6652)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184003.jpg"}, {"question": "how do we know this fruit belongs to someone", "gt answer": "in bowl(1.00)", "pred answer": "tree", "question_id": 9025, "best approach": "wiki, image", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "in bowl(0.7222)", "verif concept answer": "orange(0.6357)", "verif image answer": "in bowl(0.6660)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000902.jpg"}, {"question": "who sells the red pillow cases seen behind these two men", "gt answer": "target(1.00)<br/>internet(0.60)", "pred answer": "ikea", "question_id": 2798835, "best approach": "image", "verif answer": "online", "anno approach": "wiki, concept, image", "verif wiki answer": "7 eleven(0.5391)", "verif concept answer": "7 eleven(0.5256)", "verif image answer": "target(0.5096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000279883.jpg"}, {"question": "what are the three colors on a stop light", "gt answer": "red yellow green(1.00)<br/>red green yellow(0.60)", "pred answer": "green", "question_id": 3515215, "best approach": "image", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "green(0.6813)", "verif concept answer": "green(0.6594)", "verif image answer": "red yellow green(0.6786)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351521.jpg"}, {"question": "what are they cooking", "gt answer": "lemon(1.00)", "pred answer": "cake", "question_id": 2599515, "best approach": "concept", "verif answer": "tea", "anno approach": "wiki, concept, image", "verif wiki answer": "tea(0.6655)", "verif concept answer": "lemon(0.6671)", "verif image answer": "broccoli(0.6710)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259951.jpg"}, {"question": "what explanation could you have for the planes", "gt answer": "air show(1.00)<br/>airshow(0.60)", "pred answer": "air", "question_id": 4339685, "best approach": "concept", "verif answer": "air", "anno approach": "wiki, concept, image", "verif wiki answer": "air(0.6512)", "verif concept answer": "airshow(0.5955)", "verif image answer": "aerodynamic(0.6919)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433968.jpg"}, {"question": "was the technology this person is using invented in the past decade or earlier", "gt answer": "earlier(1.00)", "pred answer": "blender", "question_id": 3578375, "best approach": "", "verif answer": "older", "anno approach": "wiki, concept, image", "verif wiki answer": "industrial(0.7157)", "verif concept answer": "industrial(0.6334)", "verif image answer": "classic(0.6289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357837.jpg"}, {"question": "where is this", "gt answer": "ocean(1.00)<br/>beach(1.00)", "pred answer": "california", "question_id": 505115, "best approach": "wiki", "verif answer": "beach", "anno approach": "wiki, concept, image", "verif wiki answer": "ocean(0.6686)", "verif concept answer": "sand(0.7101)", "verif image answer": "sand(0.5944)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050511.jpg"}, {"question": "what teams do these players play for", "gt answer": "dodger(1.00)<br/>baseball(0.60)", "pred answer": "yankees", "question_id": 1635535, "best approach": "image", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "baseball(0.7270)", "verif concept answer": "baseball(0.7240)", "verif image answer": "dodger(0.6538)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163553.jpg"}, {"question": "what type of diet does this animal have", "gt answer": "vegetarian(1.00)<br/>herbivorous(0.60)", "pred answer": "african and grass", "question_id": 3720225, "best approach": "wiki, concept, image", "verif answer": "herbivorous", "anno approach": "wiki, concept, image", "verif wiki answer": "herbivorous(0.7202)", "verif concept answer": "herbivorous(0.7276)", "verif image answer": "herbivorous(0.6818)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372022.jpg"}, {"question": "what disney movie set in this landscape features a musical number with these animals", "gt answer": "lion king(1.00)", "pred answer": "dumbo", "question_id": 697055, "best approach": "concept, image", "verif answer": "dumbo", "anno approach": "wiki, concept, image", "verif wiki answer": "dumbo(0.7301)", "verif concept answer": "lion king(0.7293)", "verif image answer": "lion king(0.6529)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069705.jpg"}, {"question": "what would be strapped to this animal to transport humans", "gt answer": "saddle(1.00)<br/>carriage(0.60)", "pred answer": "cart", "question_id": 5334245, "best approach": "wiki", "verif answer": "cart", "anno approach": "wiki, concept, image", "verif wiki answer": "saddle(0.7260)", "verif concept answer": "carriage(0.6901)", "verif image answer": "cart(0.5844)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000533424.jpg"}, {"question": "what sorts of bulls is this advertisement referring to", "gt answer": "sport team(1.00)<br/>chicago(0.60)", "pred answer": "cow", "question_id": 2978725, "best approach": "", "verif answer": "italian", "anno approach": "wiki, concept, image", "verif wiki answer": "germany(0.6213)", "verif concept answer": "germany(0.6851)", "verif image answer": "italian(0.6409)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297872.jpg"}, {"question": "the fabric on that couch was very popular in the eighties what was it called", "gt answer": "floral(1.00)<br/>polyester(0.60)", "pred answer": "quilt", "question_id": 3182455, "best approach": "", "verif answer": "cotton", "anno approach": "wiki, concept, image", "verif wiki answer": "retro(0.6240)", "verif concept answer": "retro(0.6180)", "verif image answer": "cotton(0.6253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318245.jpg"}, {"question": "what brand is the truck", "gt answer": "gmc(1.00)", "pred answer": "chevy", "question_id": 3846805, "best approach": "", "verif answer": "chevrolet", "anno approach": "wiki, concept, image", "verif wiki answer": "chevrolet(0.7001)", "verif concept answer": "jeep(0.6803)", "verif image answer": "chevrolet(0.6939)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384680.jpg"}, {"question": "what is the time displayed", "gt answer": "3:00(1.00)<br/>noon(0.60)", "pred answer": "1:15", "question_id": 1113185, "best approach": "wiki", "verif answer": "roman", "anno approach": "wiki, concept, image", "verif wiki answer": "3:00(0.7052)", "verif concept answer": "lunch(0.6363)", "verif image answer": "noon(0.6289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111318.jpg"}, {"question": "why does this animal have spots", "gt answer": "camouflage(1.00)", "pred answer": "tusk", "question_id": 1482515, "best approach": "wiki", "verif answer": "long neck", "anno approach": "wiki, concept, image", "verif wiki answer": "camouflage(0.7231)", "verif concept answer": "long neck(0.6991)", "verif image answer": "evolution(0.6481)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148251.jpg"}, {"question": "what is the battery life on this nokia phone", "gt answer": "10 hours(1.00)<br/>2 days(0.60)<br/>1 month(0.60)", "pred answer": "10:1", "question_id": 2972795, "best approach": "wiki", "verif answer": "5 days", "anno approach": "wiki, concept, image", "verif wiki answer": "10 hours(0.6107)", "verif concept answer": "5 days(0.5645)", "verif image answer": "5 days(0.5784)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297279.jpg"}, {"question": "when was this animal breed made", "gt answer": "1930(1.00)<br/>1500(0.60)", "pred answer": "1970", "question_id": 4709705, "best approach": "", "verif answer": "1950s", "anno approach": "wiki, concept, image", "verif wiki answer": "1945(0.6644)", "verif concept answer": "1945(0.6323)", "verif image answer": "1940s(0.6386)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470970.jpg"}, {"question": "what show is this", "gt answer": "auction(1.00)<br/>fair(0.60)", "pred answer": "circus", "question_id": 4527826, "best approach": "wiki", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "auction(0.6432)", "verif concept answer": "birthday(0.6931)", "verif image answer": "fair(0.6889)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000452782.jpg"}, {"question": "what would be the minimum temperature that people would need in order to do this activity", "gt answer": "0 celcius(1.00)", "pred answer": "freeze", "question_id": 3211815, "best approach": "", "verif answer": "freeze", "anno approach": "wiki, concept, image", "verif wiki answer": "350(0.6807)", "verif concept answer": "500(0.5303)", "verif image answer": "freeze(0.5240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321181.jpg"}, {"question": "what is the name of the famous horse racing track", "gt answer": "kentucky derby(1.00)", "pred answer": "stable", "question_id": 1879765, "best approach": "", "verif answer": "race", "anno approach": "wiki, concept, image", "verif wiki answer": "race(0.7052)", "verif concept answer": "horse race(0.6209)", "verif image answer": "hell angel(0.5530)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187976.jpg"}, {"question": "what team does he play for", "gt answer": "0(1.00)<br/>usa(0.60)<br/>united state(0.60)", "pred answer": "red sox", "question_id": 2038915, "best approach": "wiki, concept, image", "verif answer": "met", "anno approach": "wiki, concept, image", "verif wiki answer": "united state(0.6134)", "verif concept answer": "usa(0.6148)", "verif image answer": "usa(0.6105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203891.jpg"}, {"question": "what is the purpose for this", "gt answer": "transport(1.00)<br/>transport good(0.60)<br/>farm(0.60)", "pred answer": "ride", "question_id": 4200855, "best approach": "wiki", "verif answer": "transport", "anno approach": "wiki, concept, image", "verif wiki answer": "transport(0.5862)", "verif concept answer": "haul(0.6912)", "verif image answer": "lumber(0.6858)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420085.jpg"}, {"question": "why isn't this likely to be a married couple", "gt answer": "young(1.00)<br/>children(0.60)", "pred answer": "clean", "question_id": 3150125, "best approach": "", "verif answer": "clean", "anno approach": "wiki, concept, image", "verif wiki answer": "y(0.7258)", "verif concept answer": "clean(0.7156)", "verif image answer": "clean(0.5377)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315012.jpg"}, {"question": "by what mode of transportation are the figures going to descend the mountain", "gt answer": "snowboard(1.00)<br/>lift(0.60)", "pred answer": "ski lift", "question_id": 4694315, "best approach": "concept", "verif answer": "ski lift", "anno approach": "wiki, concept, image", "verif wiki answer": "ski lift(0.6826)", "verif concept answer": "snowboard(0.7207)", "verif image answer": "jump(0.6565)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469431.jpg"}, {"question": "what is the addictive ingredient in this cigarette", "gt answer": "nicotine(1.00)", "pred answer": "air", "question_id": 5407905, "best approach": "image", "verif answer": "john", "anno approach": "wiki, concept, image", "verif wiki answer": "landed(0.7192)", "verif concept answer": "clown(0.7106)", "verif image answer": "nicotine(0.5169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540790.jpg"}, {"question": "what team is this", "gt answer": "cub(1.00)<br/>yankees(0.60)", "pred answer": "baseball", "question_id": 1387415, "best approach": "", "verif answer": "red sox", "anno approach": "wiki, concept, image", "verif wiki answer": "dodger(0.7199)", "verif concept answer": "red sox(0.7093)", "verif image answer": "red sox(0.7156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138741.jpg"}, {"question": "how would you cook this meat", "gt answer": "in oven(1.00)<br/>roast(0.60)", "pred answer": "grill", "question_id": 4707225, "best approach": "concept", "verif answer": "grill", "anno approach": "wiki, concept, image", "verif wiki answer": "grill(0.7288)", "verif concept answer": "roast(0.6026)", "verif image answer": "grill(0.7149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470722.jpg"}, {"question": "what appliance can be find in the room pictured", "gt answer": "sink(1.00)<br/>shower(0.60)<br/>toilet(0.60)", "pred answer": "bathroom", "question_id": 331825, "best approach": "wiki, image", "verif answer": "bathroom", "anno approach": "wiki, concept, image", "verif wiki answer": "toilet(0.7276)", "verif concept answer": "bathroom(0.5974)", "verif image answer": "toilet(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033182.jpg"}, {"question": "what is the type of this called when it 's hired privately to take a group from place to place", "gt answer": "charter(1.00)", "pred answer": "bus", "question_id": 4841585, "best approach": "image", "verif answer": "close", "anno approach": "wiki, concept, image", "verif wiki answer": "hang out(0.7020)", "verif concept answer": "close(0.6078)", "verif image answer": "charter(0.6728)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484158.jpg"}, {"question": "what is on the cup the man is holding", "gt answer": "strawberry(1.00)<br/>flower(0.60)", "pred answer": "coffee", "question_id": 3857055, "best approach": "image", "verif answer": "flower", "anno approach": "wiki, concept, image", "verif wiki answer": "flower(0.6939)", "verif concept answer": "flower(0.6379)", "verif image answer": "strawberry(0.7273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385705.jpg"}, {"question": "how do you tie a tie like this", "gt answer": "bow(1.00)", "pred answer": "clip", "question_id": 4993695, "best approach": "image", "verif answer": "clip", "anno approach": "wiki, concept, image", "verif wiki answer": "clip(0.7125)", "verif concept answer": "clip(0.6900)", "verif image answer": "bow(0.5795)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499369.jpg"}, {"question": "can you guess the place name shown in this picture where these people are standing", "gt answer": "intersection(1.00)<br/>new york city(0.60)<br/>crosswalk(0.60)<br/>new york(0.60)", "pred answer": "street", "question_id": 4340695, "best approach": "wiki, concept, image", "verif answer": "intersection", "anno approach": "wiki, concept, image", "verif wiki answer": "new york(0.7083)", "verif concept answer": "new york(0.7142)", "verif image answer": "new york(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434069.jpg"}, {"question": "what is the building in the background for", "gt answer": "church(1.00)<br/>house(0.60)", "pred answer": "farm", "question_id": 4693305, "best approach": "image", "verif answer": "school", "anno approach": "wiki, concept, image", "verif wiki answer": "school(0.7129)", "verif concept answer": "school(0.6824)", "verif image answer": "church(0.5608)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469330.jpg"}, {"question": "what part of the body is this used on", "gt answer": "teeth(1.00)", "pred answer": "neck", "question_id": 1210015, "best approach": "wiki, concept", "verif answer": "teeth", "anno approach": "wiki, concept, image", "verif wiki answer": "teeth(0.7083)", "verif concept answer": "teeth(0.6845)", "verif image answer": "brush teeth(0.7175)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000121001.jpg"}, {"question": "what kind of food is this", "gt answer": "lamb(1.00)<br/>pork(0.60)<br/>meat(0.60)", "pred answer": "turkey", "question_id": 5787655, "best approach": "image", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "steak(0.6929)", "verif concept answer": "beef(0.6481)", "verif image answer": "meat(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578765.jpg"}, {"question": "why does this man have a number on his shirt", "gt answer": "uniform(1.00)<br/>jersey(0.60)<br/>baseball player(0.60)", "pred answer": "identification", "question_id": 2932335, "best approach": "wiki, concept, image", "verif answer": "jersey", "anno approach": "wiki, concept, image", "verif wiki answer": "jersey(0.7139)", "verif concept answer": "jersey(0.7292)", "verif image answer": "jersey(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293233.jpg"}, {"question": "what kind of animal is being shown", "gt answer": "monkey(1.00)", "pred answer": "dog", "question_id": 1839905, "best approach": "", "verif answer": "monkey", "anno approach": "wiki, concept, image", "verif wiki answer": "dove(0.7194)", "verif concept answer": "dove(0.7195)", "verif image answer": "bird(0.6908)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183990.jpg"}, {"question": "what does the graffiti on the sign say", "gt answer": "listen(1.00)", "pred answer": "end destruction", "question_id": 2009465, "best approach": "", "verif answer": "grandview dr", "anno approach": "wiki, concept, image", "verif wiki answer": "william phelps eno(0.7297)", "verif concept answer": "william phelps eno(0.7263)", "verif image answer": "hear(0.5578)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200946.jpg"}, {"question": "what famous american photographer is best known for taking photos in this color scheme", "gt answer": "ansel adams(1.00)<br/>black and white(0.60)", "pred answer": "van gogh", "question_id": 3696035, "best approach": "wiki, concept, image", "verif answer": "black and white", "anno approach": "wiki, concept, image", "verif wiki answer": "ansel adams(0.6906)", "verif concept answer": "ansel adams(0.7275)", "verif image answer": "ansel adams(0.7012)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369603.jpg"}, {"question": "how many people are on board if it 's full", "gt answer": "600(1.00)<br/>150(0.60)<br/>50(0.60)<br/>200(0.60)", "pred answer": "300", "question_id": 365335, "best approach": "wiki", "verif answer": "200", "anno approach": "wiki, concept, image", "verif wiki answer": "150(0.6835)", "verif concept answer": "100(0.5874)", "verif image answer": "100(0.6473)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036533.jpg"}, {"question": "what type of monitor is that", "gt answer": "computer(1.00)<br/>lcd(0.60)", "pred answer": "desktop", "question_id": 2311645, "best approach": "image", "verif answer": "lcd", "anno approach": "wiki, concept, image", "verif wiki answer": "lcd(0.7269)", "verif concept answer": "laptop(0.7028)", "verif image answer": "computer(0.5785)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231164.jpg"}, {"question": "the fastest specimen of this animal set the world record at the belmont stakes what was his name", "gt answer": "secretariat(1.00)", "pred answer": "horse", "question_id": 418955, "best approach": "", "verif answer": "bareback", "anno approach": "wiki, concept, image", "verif wiki answer": "bareback(0.7083)", "verif concept answer": "bareback(0.6940)", "verif image answer": "bareback(0.6051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041895.jpg"}, {"question": "which digit shown here also sounds like a pastel color", "gt answer": "pinkie(1.00)", "pred answer": "thumb", "question_id": 4050135, "best approach": "", "verif answer": "c", "anno approach": "wiki, concept, image", "verif wiki answer": "c(0.7282)", "verif concept answer": "c(0.7078)", "verif image answer": "tongue(0.6090)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405013.jpg"}, {"question": "which is usually taller a human or the object in the center of the photo", "gt answer": "object(1.00)<br/>pole(0.60)", "pred answer": "man", "question_id": 3120546, "best approach": "wiki, concept", "verif answer": "pole", "anno approach": "wiki, concept, image", "verif wiki answer": "object(0.6815)", "verif concept answer": "object(0.6328)", "verif image answer": "anchor(0.7067)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312054.jpg"}, {"question": "what are the ingredients for this type of sausage", "gt answer": "beef(1.00)<br/>pork(0.60)<br/>meat(1.00)", "pred answer": "hot dog", "question_id": 436975, "best approach": "wiki", "verif answer": "beef", "anno approach": "wiki, concept, image", "verif wiki answer": "meat(0.7201)", "verif concept answer": "steak(0.6941)", "verif image answer": "pork(0.7168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043697.jpg"}, {"question": "what time of day is it", "gt answer": "afternoon(1.00)<br/>noon(1.00)", "pred answer": "morn", "question_id": 2928335, "best approach": "image", "verif answer": "morn", "anno approach": "wiki, concept, image", "verif wiki answer": "morn(0.7106)", "verif concept answer": "morn(0.7125)", "verif image answer": "noon(0.7131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292833.jpg"}, {"question": "what is the object at the very top of this building called", "gt answer": "spire(1.00)<br/>bell(0.60)<br/>point(0.60)", "pred answer": "clock", "question_id": 3646985, "best approach": "concept", "verif answer": "clock tower", "anno approach": "wiki, concept, image", "verif wiki answer": "bell(0.7161)", "verif concept answer": "spire(0.6755)", "verif image answer": "court(0.5915)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364698.jpg"}, {"question": "which genders bathroom are the toilets most likely to be found in", "gt answer": "men(1.00)<br/>women(0.60)", "pred answer": "male", "question_id": 5342915, "best approach": "", "verif answer": "female", "anno approach": "wiki, concept, image", "verif wiki answer": "female(0.6819)", "verif concept answer": "female(0.6656)", "verif image answer": "biker(0.6118)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534291.jpg"}, {"question": "how old are these people", "gt answer": "70(1.00)<br/>60s(0.60)", "pred answer": "18", "question_id": 1446205, "best approach": "image", "verif answer": "50", "anno approach": "wiki, concept, image", "verif wiki answer": "50(0.7077)", "verif concept answer": "60s(0.7112)", "verif image answer": "70(0.7084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144620.jpg"}, {"question": "is that a church or a court", "gt answer": "court(1.00)<br/>church(1.00)", "pred answer": "catholic", "question_id": 2437455, "best approach": "", "verif answer": "court", "anno approach": "wiki, concept, image", "verif wiki answer": "courthouse(0.5171)", "verif concept answer": "courthouse(0.6343)", "verif image answer": "castle(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243745.jpg"}, {"question": "in what era was this photo likely taken", "gt answer": "60s(1.00)", "pred answer": "1940s", "question_id": 4197675, "best approach": "", "verif answer": "1930s", "anno approach": "wiki, concept, image", "verif wiki answer": "1970(0.6340)", "verif concept answer": "1930s(0.6982)", "verif image answer": "50(0.6457)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419767.jpg"}, {"question": "what is the picture of in this photograph", "gt answer": "art(1.00)<br/>supply(0.60)", "pred answer": "map", "question_id": 1837885, "best approach": "concept", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "supply(0.6821)", "verif concept answer": "art(0.5752)", "verif image answer": "supply(0.5370)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183788.jpg"}, {"question": "what kind of event can be celebrated with these cakes", "gt answer": "easter(1.00)", "pred answer": "birthday", "question_id": 1509485, "best approach": "", "verif answer": "christmas", "anno approach": "wiki, concept, image", "verif wiki answer": "christmas(0.7196)", "verif concept answer": "christmas(0.6870)", "verif image answer": "baptism(0.7091)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000150948.jpg"}, {"question": "why is there red sauce in noodles", "gt answer": "tomato(1.00)", "pred answer": "fry", "question_id": 4019445, "best approach": "wiki", "verif answer": "tomato", "anno approach": "wiki, concept, image", "verif wiki answer": "tomato(0.6846)", "verif concept answer": "apple(0.6932)", "verif image answer": "marinara(0.6732)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401944.jpg"}, {"question": "what year did the olympics of the season featured in this picture begin", "gt answer": "1924(1.00)<br/>2010(0.60)<br/>1984(0.60)", "pred answer": "1965", "question_id": 5188195, "best approach": "wiki, image", "verif answer": "2010", "anno approach": "wiki, concept, image", "verif wiki answer": "1984(0.7117)", "verif concept answer": "1903(0.5930)", "verif image answer": "1984(0.6925)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518819.jpg"}, {"question": "what do you call these desserts", "gt answer": "pastry(1.00)<br/>doughnut(0.60)", "pred answer": "donuts", "question_id": 774445, "best approach": "wiki", "verif answer": "doughnut", "anno approach": "wiki, concept, image", "verif wiki answer": "doughnut(0.7217)", "verif concept answer": "donuts(0.7050)", "verif image answer": "donuts(0.6956)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077444.jpg"}, {"question": "where does the flying object take off from", "gt answer": "airport(1.00)", "pred answer": "runway", "question_id": 1747125, "best approach": "concept", "verif answer": "runway", "anno approach": "wiki, concept, image", "verif wiki answer": "runway(0.7035)", "verif concept answer": "airport(0.6790)", "verif image answer": "runway(0.6108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174712.jpg"}, {"question": "what kind of truck is it", "gt answer": "pickup(1.00)", "pred answer": "chevy", "question_id": 2953985, "best approach": "concept, image", "verif answer": "chevy", "anno approach": "wiki, concept, image", "verif wiki answer": "jeep(0.7169)", "verif concept answer": "pickup(0.7119)", "verif image answer": "pickup(0.7015)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295398.jpg"}, {"question": "what was that cutlery made of", "gt answer": "stainless steel(1.00)<br/>steel(0.60)<br/>silver(0.60)<br/>chicken(0.60)", "pred answer": "metal", "question_id": 3890615, "best approach": "wiki, concept, image", "verif answer": "metal", "anno approach": "wiki, concept, image", "verif wiki answer": "silver(0.7168)", "verif concept answer": "silver(0.7079)", "verif image answer": "silver(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389061.jpg"}, {"question": "what 's protecting this floor", "gt answer": "carpet(1.00)<br/>rug(1.00)", "pred answer": "vacuum", "question_id": 2367255, "best approach": "wiki", "verif answer": "tile", "anno approach": "wiki, concept, image", "verif wiki answer": "rug(0.7262)", "verif concept answer": "tile(0.6907)", "verif image answer": "leather(0.5301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236725.jpg"}, {"question": "what are they studying", "gt answer": "math(1.00)<br/>school(0.60)", "pred answer": "book", "question_id": 1198845, "best approach": "", "verif answer": "math", "anno approach": "wiki, concept, image", "verif wiki answer": "number(0.7042)", "verif concept answer": "sew(0.5697)", "verif image answer": "number(0.5304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119884.jpg"}, {"question": "in what city could this bus be", "gt answer": "london(1.00)<br/>england(0.60)<br/>berlin(0.60)", "pred answer": "new york", "question_id": 5010285, "best approach": "image", "verif answer": "london", "anno approach": "wiki, concept, image", "verif wiki answer": "paris(0.7177)", "verif concept answer": "united kingdom(0.6932)", "verif image answer": "england(0.6282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501028.jpg"}, {"question": "how high does this plane fly", "gt answer": "30000 feet(1.00)<br/>very(0.60)", "pred answer": "40000 feet", "question_id": 5501045, "best approach": "wiki, concept", "verif answer": "30000 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "30000 feet(0.7044)", "verif concept answer": "30000 feet(0.6815)", "verif image answer": "very healthy(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550104.jpg"}, {"question": "is this vehicle used primarily for transporting humans or cargo", "gt answer": "cargo(1.00)", "pred answer": "people", "question_id": 857995, "best approach": "wiki, image", "verif answer": "cargo", "anno approach": "wiki, concept, image", "verif wiki answer": "cargo(0.7202)", "verif concept answer": "fly(0.7021)", "verif image answer": "cargo(0.7107)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085799.jpg"}, {"question": "these animals are said to gorge in the fall as preparation for what", "gt answer": "hibernation(1.00)<br/>bear(1.00)<br/>winter(0.60)", "pred answer": "hot", "question_id": 3711835, "best approach": "wiki, concept", "verif answer": "hibernation", "anno approach": "wiki, concept, image", "verif wiki answer": "bear(0.6834)", "verif concept answer": "hibernation(0.6674)", "verif image answer": "teddy bear(0.5372)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371183.jpg"}, {"question": "what move is the man on the skateboard performing", "gt answer": "slide(1.00)<br/>trick(0.60)<br/>jump(0.60)", "pred answer": "kickflip", "question_id": 111595, "best approach": "", "verif answer": "kickflip", "anno approach": "wiki, concept, image", "verif wiki answer": "kickflip(0.7094)", "verif concept answer": "kickflip(0.7140)", "verif image answer": "kickflip(0.6910)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011159.jpg"}, {"question": "name the variety of aeroplane which is shown in this picture", "gt answer": "boeing 747(1.00)<br/>commercial(0.60)", "pred answer": "boeing", "question_id": 1013105, "best approach": "", "verif answer": "boeing", "anno approach": "wiki, concept, image", "verif wiki answer": "boeing(0.6621)", "verif concept answer": "boeing(0.6872)", "verif image answer": "boeing(0.6316)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000101310.jpg"}, {"question": "", "gt answer": "army(0.60)<br/>military(0.60)<br/>levis(0.60)", "pred answer": "levi", "question_id": 1287295, "best approach": "wiki, concept, image", "verif answer": "army", "anno approach": "wiki, concept, image", "verif wiki answer": "army(0.5908)", "verif concept answer": "army(0.6041)", "verif image answer": "army(0.6450)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128729.jpg"}, {"question": "what country is this", "gt answer": "united state(1.00)<br/>usa(0.60)<br/>america(0.60)", "pred answer": "france", "question_id": 98095, "best approach": "wiki, concept, image", "verif answer": "usa", "anno approach": "wiki, concept, image", "verif wiki answer": "usa(0.6862)", "verif concept answer": "usa(0.6913)", "verif image answer": "usa(0.6733)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009809.jpg"}, {"question": "what food is this", "gt answer": "stir fry(1.00)", "pred answer": "salad", "question_id": 5270565, "best approach": "concept", "verif answer": "stir fry", "anno approach": "wiki, concept, image", "verif wiki answer": "ramen(0.6878)", "verif concept answer": "stir fry(0.7166)", "verif image answer": "stew(0.6867)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527056.jpg"}, {"question": "what are the birds drinking from", "gt answer": "pool(1.00)", "pred answer": "air", "question_id": 2282275, "best approach": "", "verif answer": "trash", "anno approach": "wiki, concept, image", "verif wiki answer": "trash(0.5427)", "verif concept answer": "trash(0.5751)", "verif image answer": "amazon(0.5805)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000228227.jpg"}, {"question": "what toppings are on this hotdog", "gt answer": "mustard(1.00)", "pred answer": "hot dog", "question_id": 4688295, "best approach": "", "verif answer": "cheese", "anno approach": "wiki, concept, image", "verif wiki answer": "tomato(0.7156)", "verif concept answer": "tomato(0.6811)", "verif image answer": "tomato(0.6379)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000468829.jpg"}, {"question": "what year is this truck", "gt answer": "1969(1.00)<br/>1965(0.60)<br/>1950(0.60)", "pred answer": "1940", "question_id": 5161675, "best approach": "wiki, image", "verif answer": "1950", "anno approach": "wiki, concept, image", "verif wiki answer": "1969(0.6589)", "verif concept answer": "1980(0.6561)", "verif image answer": "1969(0.6743)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516167.jpg"}, {"question": "what is the woman sitting on", "gt answer": "bean bag(1.00)", "pred answer": "bed", "question_id": 3052245, "best approach": "wiki, concept, image", "verif answer": "flat screen", "anno approach": "wiki, concept, image", "verif wiki answer": "bean bag(0.6346)", "verif concept answer": "bean bag(0.6351)", "verif image answer": "bean bag(0.6458)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305224.jpg"}, {"question": "how many oz 's of liquid will this cup hold", "gt answer": "8(1.00)", "pred answer": "300", "question_id": 4295595, "best approach": "", "verif answer": "12", "anno approach": "wiki, concept, image", "verif wiki answer": "2(0.7210)", "verif concept answer": "75(0.6354)", "verif image answer": "12(0.6812)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429559.jpg"}, {"question": "what would he find in what he is reading", "gt answer": "news(1.00)", "pred answer": "magazine", "question_id": 5582865, "best approach": "wiki", "verif answer": "old", "anno approach": "wiki, concept, image", "verif wiki answer": "news(0.7215)", "verif concept answer": "sony(0.6321)", "verif image answer": "play(0.5123)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558286.jpg"}, {"question": "where would the sun be located relative to the photographer", "gt answer": "behind(1.00)<br/>front(0.60)", "pred answer": "north", "question_id": 3355655, "best approach": "", "verif answer": "north", "anno approach": "wiki, concept, image", "verif wiki answer": "north(0.6916)", "verif concept answer": "back(0.6812)", "verif image answer": "back(0.5547)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335565.jpg"}, {"question": "what year is that laptop from", "gt answer": "2010(1.00)", "pred answer": "1990", "question_id": 4727375, "best approach": "image", "verif answer": "1990", "anno approach": "wiki, concept, image", "verif wiki answer": "1990(0.6714)", "verif concept answer": "2002(0.6167)", "verif image answer": "2010(0.6845)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000472737.jpg"}, {"question": "what time of day is this meal eaten", "gt answer": "even(1.00)<br/>dinner(0.60)", "pred answer": "morn", "question_id": 5634445, "best approach": "", "verif answer": "lunch", "anno approach": "wiki, concept, image", "verif wiki answer": "lunch(0.7188)", "verif concept answer": "lunch(0.7153)", "verif image answer": "breakfast(0.5395)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000563444.jpg"}, {"question": "what first responder would use this device", "gt answer": "fireman(1.00)<br/>firefighter(1.00)<br/>fire fighter(0.60)", "pred answer": "fire", "question_id": 4454465, "best approach": "wiki, concept", "verif answer": "fireman", "anno approach": "wiki, concept, image", "verif wiki answer": "fireman(0.7289)", "verif concept answer": "fireman(0.7270)", "verif image answer": "frederick graff sr(0.6711)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445446.jpg"}, {"question": "what is the proper reaction to seeing a stop sign", "gt answer": "stop(1.00)<br/>brake(0.60)", "pred answer": "sad", "question_id": 3444225, "best approach": "concept, image", "verif answer": "stop", "anno approach": "wiki, concept, image", "verif wiki answer": "stopped(0.5593)", "verif concept answer": "stop(0.6526)", "verif image answer": "stop(0.5948)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344422.jpg"}, {"question": "who kept the kitchen so clean", "gt answer": "wife(1.00)<br/>owner(0.60)<br/>grandma(0.60)<br/>maid(0.60)", "pred answer": "cook", "question_id": 4361855, "best approach": "concept", "verif answer": "maid", "anno approach": "wiki, concept, image", "verif wiki answer": "ge(0.6806)", "verif concept answer": "wife(0.6326)", "verif image answer": "ge(0.6520)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436185.jpg"}, {"question": "what holiday is being celebrated", "gt answer": "july 4th(1.00)<br/>vacation(0.60)<br/>fourth of july(0.60)", "pred answer": "christmas", "question_id": 1349865, "best approach": "image", "verif answer": "4th of july", "anno approach": "wiki, concept, image", "verif wiki answer": "vacation(0.7083)", "verif concept answer": "4th of july(0.7032)", "verif image answer": "july 4th(0.6195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134986.jpg"}, {"question": "what model of train is the red train sitting on the tracks", "gt answer": "bullet(1.00)<br/>bullet train(1.00)", "pred answer": "commuter", "question_id": 3956145, "best approach": "", "verif answer": "amtrak", "anno approach": "wiki, concept, image", "verif wiki answer": "amtrak(0.7225)", "verif concept answer": "amtrak(0.7217)", "verif image answer": "amtrak(0.6983)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395614.jpg"}, {"question": "what type of nut is pictured", "gt answer": "walnut(1.00)", "pred answer": "pistachio", "question_id": 2610645, "best approach": "image", "verif answer": "pistachio", "anno approach": "wiki, concept, image", "verif wiki answer": "sesame(0.7240)", "verif concept answer": "parsley(0.6597)", "verif image answer": "walnut(0.5865)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261064.jpg"}, {"question": "what is a building of this height called", "gt answer": "skyscraper(1.00)", "pred answer": "clock", "question_id": 2527495, "best approach": "concept", "verif answer": "clock tower", "anno approach": "wiki, concept, image", "verif wiki answer": "clock tower(0.7213)", "verif concept answer": "skyscraper(0.7248)", "verif image answer": "big ben(0.7048)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252749.jpg"}, {"question": "what is on the tv", "gt answer": "earth(1.00)<br/>dog(0.60)", "pred answer": "video game", "question_id": 328165, "best approach": "", "verif answer": "music", "anno approach": "wiki, concept, image", "verif wiki answer": "music(0.7084)", "verif concept answer": "teddy bear(0.6296)", "verif image answer": "music(0.6900)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032816.jpg"}, {"question": "what is this act of playing with a dog called", "gt answer": "fetch(1.00)", "pred answer": "catch", "question_id": 1515815, "best approach": "image", "verif answer": "catch", "anno approach": "wiki, concept, image", "verif wiki answer": "catch(0.7019)", "verif concept answer": "catch(0.6392)", "verif image answer": "fetch(0.6492)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151581.jpg"}, {"question": "what material is used to color this court", "gt answer": "paint(1.00)<br/>asphalt(0.60)<br/>green(0.60)", "pred answer": "concrete", "question_id": 4166055, "best approach": "", "verif answer": "asphalt", "anno approach": "wiki, concept, image", "verif wiki answer": "spray paint(0.7256)", "verif concept answer": "spray paint(0.7153)", "verif image answer": "spray paint(0.6816)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416605.jpg"}, {"question": "how many animals like this currently exist", "gt answer": "20000(1.00)", "pred answer": "6", "question_id": 3579295, "best approach": "concept, image", "verif answer": "7", "anno approach": "wiki, concept, image", "verif wiki answer": "million(0.6476)", "verif concept answer": "20000(0.6107)", "verif image answer": "20000(0.6394)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357929.jpg"}, {"question": "how many stripes does this animal typically have", "gt answer": "lot(1.00)<br/>300(0.60)<br/>200(0.60)<br/>80(0.60)", "pred answer": "45", "question_id": 1023335, "best approach": "concept, image", "verif answer": "300", "anno approach": "wiki, concept, image", "verif wiki answer": "80(0.7043)", "verif concept answer": "lot(0.6176)", "verif image answer": "lot(0.5233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000102333.jpg"}, {"question": "what 's the name of this river", "gt answer": "mississippi(1.00)<br/>dirty(0.60)<br/>fox(0.60)<br/>thames(0.60)", "pred answer": "canal", "question_id": 977475, "best approach": "concept", "verif answer": "canal", "anno approach": "wiki, concept, image", "verif wiki answer": "thames(0.5845)", "verif concept answer": "mississippi(0.6181)", "verif image answer": "dirty(0.6442)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097747.jpg"}, {"question": "what popular brand of these items features a laughing man of enormous stature", "gt answer": "green giant(1.00)<br/>broccoli(0.60)", "pred answer": "dram", "question_id": 1593325, "best approach": "wiki", "verif answer": "broccoli", "anno approach": "wiki, concept, image", "verif wiki answer": "green giant(0.7148)", "verif concept answer": "broccoli(0.7033)", "verif image answer": "broccoli(0.7115)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159332.jpg"}, {"question": "what animal is pictured", "gt answer": "cat(1.00)", "pred answer": "dog", "question_id": 77815, "best approach": "wiki, concept", "verif answer": "dog", "anno approach": "wiki, concept, image", "verif wiki answer": "cat(0.7275)", "verif concept answer": "cat(0.7112)", "verif image answer": "fox(0.5405)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007781.jpg"}, {"question": "what type of clock is this", "gt answer": "coocoo(1.00)", "pred answer": "analog", "question_id": 4485335, "best approach": "", "verif answer": "analog", "anno approach": "wiki, concept, image", "verif wiki answer": "analog(0.7286)", "verif concept answer": "analog(0.7078)", "verif image answer": "grandfather clock(0.5499)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448533.jpg"}, {"question": "who is the famous person that used one of these to win seven races only to have his titles stripped for using performance enhancing drugs", "gt answer": "lance armstrong(1.00)", "pred answer": "friend", "question_id": 4697285, "best approach": "wiki, concept, image", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "lance armstrong(0.7049)", "verif concept answer": "lance armstrong(0.6140)", "verif image answer": "lance armstrong(0.5499)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469728.jpg"}, {"question": "which material is used to make this hand bag shown here", "gt answer": "yarn(1.00)<br/>cotton(0.60)<br/>mesh(0.60)", "pred answer": "canvas", "question_id": 2404635, "best approach": "wiki, concept", "verif answer": "mesh", "anno approach": "wiki, concept, image", "verif wiki answer": "yarn(0.7218)", "verif concept answer": "yarn(0.6766)", "verif image answer": "mesh(0.5656)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240463.jpg"}, {"question": "why would these people be at the table", "gt answer": "family dinner(1.00)<br/>food(0.60)<br/>supper(0.60)<br/>eat(0.60)", "pred answer": "to eat", "question_id": 1763925, "best approach": "wiki, concept, image", "verif answer": "eat", "anno approach": "wiki, concept, image", "verif wiki answer": "eat(0.7293)", "verif concept answer": "eat(0.6773)", "verif image answer": "eat(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176392.jpg"}, {"question": "what team is this", "gt answer": "cub(1.00)<br/>met(0.60)<br/>red sox(0.60)", "pred answer": "baseball", "question_id": 541635, "best approach": "wiki, concept, image", "verif answer": "red sox", "anno approach": "wiki, concept, image", "verif wiki answer": "red sox(0.7255)", "verif concept answer": "red sox(0.7152)", "verif image answer": "red sox(0.6593)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054163.jpg"}, {"question": "who is famous for their temper in this sport", "gt answer": "john mcenroe(1.00)", "pred answer": "serena williams", "question_id": 2720075, "best approach": "", "verif answer": "serena williams", "anno approach": "wiki, concept, image", "verif wiki answer": "roger federer(0.7291)", "verif concept answer": "serena williams(0.6972)", "verif image answer": "sharapova(0.6256)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000272007.jpg"}, {"question": "what brand of toothbrush is this", "gt answer": "oral b(1.00)<br/>colgate(1.00)", "pred answer": "crest", "question_id": 5607505, "best approach": "", "verif answer": "crest", "anno approach": "wiki, concept, image", "verif wiki answer": "crest(0.6745)", "verif concept answer": "electric(0.6781)", "verif image answer": "teeth(0.5203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560750.jpg"}, {"question": "what sort of device was likely used to make the shaped edibles", "gt answer": "cookie cutter(1.00)", "pred answer": "grill", "question_id": 3104505, "best approach": "", "verif answer": "baked", "anno approach": "wiki, concept, image", "verif wiki answer": "pot(0.7292)", "verif concept answer": "baked(0.7033)", "verif image answer": "see(0.5851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310450.jpg"}, {"question": "what type of bird is that", "gt answer": "owl(1.00)<br/>falcon(0.60)<br/>pigeon(0.60)", "pred answer": "pelican", "question_id": 1422395, "best approach": "concept", "verif answer": "falcon", "anno approach": "wiki, concept, image", "verif wiki answer": "hawk(0.7116)", "verif concept answer": "falcon(0.7244)", "verif image answer": "hawk(0.7177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142239.jpg"}, {"question": "how many people does this vehicle hold", "gt answer": "300(1.00)<br/>lot(0.60)<br/>thousand(0.60)<br/>100(0.60)", "pred answer": "many", "question_id": 5392145, "best approach": "image", "verif answer": "300", "anno approach": "wiki, concept, image", "verif wiki answer": "lot(0.7026)", "verif concept answer": "lot(0.6272)", "verif image answer": "300(0.6902)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539214.jpg"}, {"question": "how many different species of animals call this body of water home", "gt answer": "thousand(1.00)<br/>100(0.60)", "pred answer": "1", "question_id": 3185645, "best approach": "concept", "verif answer": "thousand", "anno approach": "wiki, concept, image", "verif wiki answer": "1000(0.6704)", "verif concept answer": "100(0.5800)", "verif image answer": "300(0.6682)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318564.jpg"}, {"question": "what fabrics are made these ties", "gt answer": "silk(1.00)", "pred answer": "canvas", "question_id": 413115, "best approach": "image", "verif answer": "silk", "anno approach": "wiki, concept, image", "verif wiki answer": "cotton(0.6786)", "verif concept answer": "tie(0.7101)", "verif image answer": "silk(0.6682)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041311.jpg"}, {"question": "is this an example of humans hanging out togehter or are they working", "gt answer": "hang out(1.00)", "pred answer": "play game", "question_id": 3532705, "best approach": "", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "work(0.7081)", "verif concept answer": "hunt(0.6107)", "verif image answer": "hunt(0.7011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353270.jpg"}, {"question": "what kind of berries are shown", "gt answer": "rasberries(1.00)<br/>raspberry(1.00)", "pred answer": "red", "question_id": 4589845, "best approach": "", "verif answer": "red", "anno approach": "wiki, concept, image", "verif wiki answer": "orange(0.7137)", "verif concept answer": "red(0.6948)", "verif image answer": "jam(0.6392)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458984.jpg"}, {"question": "what type of mattress is this", "gt answer": "single(1.00)<br/>futon(0.60)<br/>air(0.60)<br/>baby(0.60)", "pred answer": "twin", "question_id": 442155, "best approach": "", "verif answer": "single", "anno approach": "wiki, concept, image", "verif wiki answer": "kid(0.7184)", "verif concept answer": "kid(0.6827)", "verif image answer": "kid(0.5575)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000044215.jpg"}, {"question": "what breed of cat is in this picture", "gt answer": "siamese(1.00)<br/>persian(0.60)", "pred answer": "calico", "question_id": 3332915, "best approach": "", "verif answer": "persian", "anno approach": "wiki, concept, image", "verif wiki answer": "ragdoll(0.7141)", "verif concept answer": "sleep(0.6576)", "verif image answer": "ragdoll(0.6174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333291.jpg"}, {"question": "how much taller is the man in the hat than the animal in front of him", "gt answer": "2 feet(1.00)<br/>1 foot(0.60)<br/>3 feet(0.60)", "pred answer": "4 feet", "question_id": 3414575, "best approach": "concept", "verif answer": "1 foot", "anno approach": "wiki, concept, image", "verif wiki answer": "1 foot(0.6750)", "verif concept answer": "2 feet(0.5865)", "verif image answer": "15 feet(0.5697)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341457.jpg"}, {"question": "what sound does this animal make", "gt answer": "woof(1.00)<br/>bark(0.60)", "pred answer": "moo", "question_id": 5226605, "best approach": "wiki", "verif answer": "moo", "anno approach": "wiki, concept, image", "verif wiki answer": "woof(0.7258)", "verif concept answer": "moo(0.7172)", "verif image answer": "moo(0.6805)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522660.jpg"}, {"question": "what 's the name of the tallest building in this photo", "gt answer": "big ben(1.00)", "pred answer": "clock tower", "question_id": 1363125, "best approach": "", "verif answer": "clock tower", "anno approach": "wiki, concept, image", "verif wiki answer": "clock tower(0.7304)", "verif concept answer": "clock tower(0.7262)", "verif image answer": "roman numeral(0.5154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136312.jpg"}, {"question": "what cocktail is this lady drinking", "gt answer": "vodka cranberry(1.00)<br/>alcoholic(0.60)", "pred answer": "beer", "question_id": 2090125, "best approach": "", "verif answer": "lemonade", "anno approach": "wiki, concept, image", "verif wiki answer": "lemonade(0.6511)", "verif concept answer": "ollie(0.7145)", "verif image answer": "ollie(0.6718)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209012.jpg"}, {"question": "this woman wears glasses for what purpose", "gt answer": "see(1.00)<br/>read(0.60)", "pred answer": "sun protection", "question_id": 2255395, "best approach": "wiki, concept, image", "verif answer": "tell time", "anno approach": "wiki, concept, image", "verif wiki answer": "read(0.7206)", "verif concept answer": "read(0.6396)", "verif image answer": "read(0.6991)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225539.jpg"}, {"question": "what is the life span of this animal", "gt answer": "2 16 years(1.00)<br/>15 years(0.60)<br/>year(0.60)<br/>9 years(0.60)", "pred answer": "10 years", "question_id": 4390855, "best approach": "wiki, concept", "verif answer": "10 years", "anno approach": "wiki, concept, image", "verif wiki answer": "15 years(0.6792)", "verif concept answer": "15 years(0.6809)", "verif image answer": "10 years(0.6935)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439085.jpg"}, {"question": "what is the large silver item on the top left", "gt answer": "phone(1.00)<br/>keyboard(0.60)", "pred answer": "clock", "question_id": 2838095, "best approach": "wiki, concept, image", "verif answer": "telephone", "anno approach": "wiki, concept, image", "verif wiki answer": "phone(0.7033)", "verif concept answer": "phone(0.6555)", "verif image answer": "phone(0.5467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283809.jpg"}, {"question": "is this a hangout or a form of a gang", "gt answer": "hangout(1.00)<br/>both(0.60)", "pred answer": "biker", "question_id": 2698295, "best approach": "", "verif answer": "competition", "anno approach": "wiki, concept, image", "verif wiki answer": "public(0.7218)", "verif concept answer": "competition(0.6853)", "verif image answer": "competition(0.7039)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269829.jpg"}, {"question": "what is the name for the body of a plane", "gt answer": "fuselage(1.00)<br/>jet(0.60)", "pred answer": "jet fuel", "question_id": 2503035, "best approach": "wiki", "verif answer": "jet", "anno approach": "wiki, concept, image", "verif wiki answer": "jet(0.6910)", "verif concept answer": "contrail(0.6493)", "verif image answer": "fly(0.6071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250303.jpg"}, {"question": "what is the maximum weight the red suitcase can carry", "gt answer": "50 kg(1.00)<br/>2(0.60)", "pred answer": "500", "question_id": 250605, "best approach": "wiki, concept", "verif answer": "400", "anno approach": "wiki, concept, image", "verif wiki answer": "2(0.6152)", "verif concept answer": "2(0.5992)", "verif image answer": "3(0.5778)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025060.jpg"}, {"question": "what do the white lines indicate", "gt answer": "crosswalk(1.00)<br/>pedestrian cross(0.60)<br/>pedestrian(0.60)", "pred answer": "stop", "question_id": 4128555, "best approach": "wiki, image", "verif answer": "crosswalk", "anno approach": "wiki, concept, image", "verif wiki answer": "pedestrian cross(0.6981)", "verif concept answer": "line(0.6838)", "verif image answer": "pedestrian(0.5881)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412855.jpg"}, {"question": "what kind of food appears the most on the monitors at the top of the photo", "gt answer": "sandwich(1.00)<br/>hamburger(1.00)", "pred answer": "hotdogs", "question_id": 3343645, "best approach": "", "verif answer": "sandwich", "anno approach": "wiki, concept, image", "verif wiki answer": "steak(0.7270)", "verif concept answer": "burger(0.6929)", "verif image answer": "meat(0.6726)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334364.jpg"}, {"question": "what is the boat doing on the sand", "gt answer": "beached(1.00)<br/>rest(0.60)<br/>parked(0.60)", "pred answer": "float", "question_id": 5788465, "best approach": "wiki", "verif answer": "stopped", "anno approach": "wiki, concept, image", "verif wiki answer": "beached(0.7067)", "verif concept answer": "stopped(0.6737)", "verif image answer": "relax(0.6655)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578846.jpg"}, {"question": "what are these animals standing inside of", "gt answer": "trailer(1.00)<br/>carriage(0.60)<br/>shelter(0.60)", "pred answer": "barn", "question_id": 1541195, "best approach": "wiki, concept, image", "verif answer": "cart", "anno approach": "wiki, concept, image", "verif wiki answer": "shelter(0.7230)", "verif concept answer": "shelter(0.6257)", "verif image answer": "carriage(0.6227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154119.jpg"}, {"question": "where can i find this road", "gt answer": "peru(1.00)<br/>mountain(1.00)<br/>china(0.60)", "pred answer": "country", "question_id": 369145, "best approach": "wiki", "verif answer": "peru", "anno approach": "wiki, concept, image", "verif wiki answer": "mountain(0.6189)", "verif concept answer": "city(0.6438)", "verif image answer": "china(0.6661)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036914.jpg"}, {"question": "what activity is taking place here", "gt answer": "selfie(1.00)<br/>rest(1.00)", "pred answer": "sleep", "question_id": 2180995, "best approach": "", "verif answer": "rest", "anno approach": "wiki, concept, image", "verif wiki answer": "pillow(0.7120)", "verif concept answer": "flip(0.6747)", "verif image answer": "take picture(0.6643)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218099.jpg"}, {"question": "why is the horse pulling something", "gt answer": "farm(1.00)<br/>plow(1.00)", "pred answer": "protection", "question_id": 3841575, "best approach": "concept, image", "verif answer": "plow", "anno approach": "wiki, concept, image", "verif wiki answer": "ride(0.7070)", "verif concept answer": "plow(0.5597)", "verif image answer": "plow(0.7273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384157.jpg"}, {"question": "in which state is there a mountain named for these animals", "gt answer": "new york(1.00)<br/>bear(0.60)<br/>california(0.60)<br/>alaska(0.60)", "pred answer": "colorado", "question_id": 1156815, "best approach": "concept", "verif answer": "california", "anno approach": "wiki, concept, image", "verif wiki answer": "alaska(0.7111)", "verif concept answer": "new york(0.6685)", "verif image answer": "alaska(0.5710)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115681.jpg"}, {"question": "what is the average cost for this service", "gt answer": "2 dollars(1.00)", "pred answer": "$2", "question_id": 3109265, "best approach": "concept", "verif answer": "2 dollars", "anno approach": "wiki, concept, image", "verif wiki answer": "200(0.6227)", "verif concept answer": "2 dollars(0.6490)", "verif image answer": "200(0.6302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310926.jpg"}, {"question": "what type of plane is this", "gt answer": "glider(1.00)<br/>airplane(0.60)<br/>private(0.60)", "pred answer": "jet", "question_id": 677265, "best approach": "wiki, concept, image", "verif answer": "jet", "anno approach": "wiki, concept, image", "verif wiki answer": "airplane(0.6276)", "verif concept answer": "private(0.5993)", "verif image answer": "private(0.6521)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067726.jpg"}, {"question": "what style of window has an arch on top", "gt answer": "arch(1.00)<br/>french(0.60)", "pred answer": "gothic", "question_id": 4361455, "best approach": "", "verif answer": "dome", "anno approach": "wiki, concept, image", "verif wiki answer": "dome(0.7163)", "verif concept answer": "french door(0.6661)", "verif image answer": "french door(0.6484)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436145.jpg"}, {"question": "what model of motorcycle is this", "gt answer": "honda(1.00)<br/>mercedes benz(0.60)<br/>motorbike(0.60)", "pred answer": "harley davidson", "question_id": 4778605, "best approach": "wiki", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "honda(0.6909)", "verif concept answer": "mercedes(0.7065)", "verif image answer": "mercedes(0.6391)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477860.jpg"}, {"question": "", "gt answer": "32 degree(0.60)", "pred answer": "rain", "question_id": 3066815, "best approach": "", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "inside(0.5679)", "verif concept answer": "inside(0.6366)", "verif image answer": "inside(0.5126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306681.jpg"}, {"question": "what company designed the e reader shown in the picture", "gt answer": "amazon(1.00)", "pred answer": "irma s rombauer", "question_id": 1053885, "best approach": "wiki, concept, image", "verif answer": "target", "anno approach": "wiki, concept, image", "verif wiki answer": "amazon(0.7184)", "verif concept answer": "amazon(0.6347)", "verif image answer": "amazon(0.5009)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105388.jpg"}, {"question": "is this a luxury or economy suite", "gt answer": "luxury(1.00)", "pred answer": "queen", "question_id": 5385475, "best approach": "", "verif answer": "hotel", "anno approach": "wiki, concept, image", "verif wiki answer": "hotel(0.5681)", "verif concept answer": "hotel(0.5431)", "verif image answer": "content(0.5042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538547.jpg"}, {"question": "if this player proceeds to hit a ball close to the ground for a short distance that is called a what", "gt answer": "bunt(1.00)<br/>foul(0.60)", "pred answer": "hit", "question_id": 2471465, "best approach": "", "verif answer": "homerun", "anno approach": "wiki, concept, image", "verif wiki answer": "homerun(0.7235)", "verif concept answer": "homerun(0.5949)", "verif image answer": "homerun(0.5066)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247146.jpg"}, {"question": "what does 30 indicate on the sign", "gt answer": "speed limit(1.00)", "pred answer": "advertising", "question_id": 5007125, "best approach": "concept", "verif answer": "speed limit", "anno approach": "wiki, concept, image", "verif wiki answer": "arrow(0.6176)", "verif concept answer": "speed limit(0.6136)", "verif image answer": "arrow(0.6326)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500712.jpg"}, {"question": "what kind of soap would be used on these", "gt answer": "dish soap(1.00)<br/>dawn(0.60)<br/>dish(0.60)", "pred answer": "coconut", "question_id": 4462665, "best approach": "wiki, concept, image", "verif answer": "dawn", "anno approach": "wiki, concept, image", "verif wiki answer": "dawn(0.6155)", "verif concept answer": "dawn(0.7282)", "verif image answer": "dawn(0.5959)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000446266.jpg"}, {"question": "what is the green vegetable on this plate called", "gt answer": "pickle(1.00)", "pred answer": "pea", "question_id": 3148225, "best approach": "", "verif answer": "cucumber", "anno approach": "wiki, concept, image", "verif wiki answer": "pepper(0.6189)", "verif concept answer": "cucumber(0.6016)", "verif image answer": "pepper(0.5734)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314822.jpg"}, {"question": "what kind of a horse is this", "gt answer": "shetland(1.00)<br/>ride(0.60)<br/>arabian(0.60)", "pred answer": "pony", "question_id": 1003375, "best approach": "wiki, image", "verif answer": "mustang", "anno approach": "wiki, concept, image", "verif wiki answer": "arabian(0.6994)", "verif concept answer": "foal(0.6764)", "verif image answer": "ride(0.6769)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100337.jpg"}, {"question": "how are these shrimp prepared", "gt answer": "boiled(1.00)", "pred answer": "grilled", "question_id": 139495, "best approach": "concept", "verif answer": "grilled", "anno approach": "wiki, concept, image", "verif wiki answer": "steamed(0.7187)", "verif concept answer": "boiled(0.7099)", "verif image answer": "hard boiled(0.7018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013949.jpg"}, {"question": "what festival is this", "gt answer": "annual(0.60)<br/>elephant(1.00)<br/>chinese new year(0.60)", "pred answer": "circus", "question_id": 4220635, "best approach": "wiki", "verif answer": "annual", "anno approach": "wiki, concept, image", "verif wiki answer": "elephant(0.6035)", "verif concept answer": "brain(0.5586)", "verif image answer": "brain(0.5545)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422063.jpg"}, {"question": "what character is this umbrella designed after", "gt answer": "sock monkey(1.00)<br/>monkey(0.60)<br/>bear(0.60)", "pred answer": "mickey mouse", "question_id": 575155, "best approach": "wiki, concept", "verif answer": "dog", "anno approach": "wiki, concept, image", "verif wiki answer": "sock monkey(0.6046)", "verif concept answer": "sock monkey(0.5413)", "verif image answer": "monkey(0.5178)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000057515.jpg"}, {"question": "why wouldn't this animal be seen in a zoo", "gt answer": "pet(1.00)<br/>domesticated(0.60)<br/>domestic(0.60)", "pred answer": "rest", "question_id": 5412295, "best approach": "image", "verif answer": "wild", "anno approach": "wiki, concept, image", "verif wiki answer": "wild(0.7083)", "verif concept answer": "wild(0.5856)", "verif image answer": "domesticated(0.5684)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541229.jpg"}, {"question": "what is the purpose of the object that the man is sitting on", "gt answer": "transportation(1.00)<br/>ride(0.60)<br/>transport(0.60)", "pred answer": "bicycle", "question_id": 4715295, "best approach": "wiki, concept, image", "verif answer": "ride", "anno approach": "wiki, concept, image", "verif wiki answer": "transport(0.6026)", "verif concept answer": "transport(0.6505)", "verif image answer": "ride(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471529.jpg"}, {"question": "which type of glass is used for making this flower vase shown in this picture", "gt answer": "green(1.00)<br/>crystal(0.60)", "pred answer": "tempered", "question_id": 927295, "best approach": "wiki, image", "verif answer": "rose", "anno approach": "wiki, concept, image", "verif wiki answer": "crystal(0.7215)", "verif concept answer": "rose(0.7011)", "verif image answer": "crystal(0.5566)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092729.jpg"}, {"question": "what type of desert is on the tray in front", "gt answer": "cupcake(1.00)<br/>dessert(0.60)", "pred answer": "chocolate", "question_id": 2139995, "best approach": "concept", "verif answer": "pastry", "anno approach": "wiki, concept, image", "verif wiki answer": "cake(0.7189)", "verif concept answer": "cupcake(0.7105)", "verif image answer": "cake(0.5406)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000213999.jpg"}, {"question": "what kind of dog is in the photo", "gt answer": "golden retriever(1.00)<br/>german shepard(0.60)", "pred answer": "poodle", "question_id": 103695, "best approach": "concept", "verif answer": "collie", "anno approach": "wiki, concept, image", "verif wiki answer": "collie(0.7170)", "verif concept answer": "german shepard(0.6824)", "verif image answer": "retriever(0.5270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000010369.jpg"}, {"question": "what meat is in between the bread", "gt answer": "hot dog(1.00)<br/>sausage(0.60)<br/>hotdog(0.60)<br/>beef(0.60)", "pred answer": "pork", "question_id": 3512425, "best approach": "wiki, concept, image", "verif answer": "hot dog", "anno approach": "wiki, concept, image", "verif wiki answer": "sausage(0.7284)", "verif concept answer": "sausage(0.7288)", "verif image answer": "sausage(0.7095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351242.jpg"}, {"question": "what does it seem like these riders are doing", "gt answer": "hunt(1.00)<br/>horseback ride(0.60)", "pred answer": "run", "question_id": 5267136, "best approach": "wiki", "verif answer": "gallop", "anno approach": "wiki, concept, image", "verif wiki answer": "hunt(0.6296)", "verif concept answer": "gallop(0.7111)", "verif image answer": "gallop(0.7156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526713.jpg"}, {"question": "how old is this baby", "gt answer": "3 months(1.00)<br/>6 months(0.60)", "pred answer": "4", "question_id": 2534305, "best approach": "wiki, image", "verif answer": "2 weeks", "anno approach": "wiki, concept, image", "verif wiki answer": "3 months(0.6793)", "verif concept answer": "2 weeks(0.6129)", "verif image answer": "3 months(0.6881)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253430.jpg"}, {"question": "what is this train 's cargo", "gt answer": "car(1.00)<br/>good(0.60)<br/>vehicle(0.60)", "pred answer": "people", "question_id": 3670115, "best approach": "", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "tug(0.7166)", "verif concept answer": "tug(0.7138)", "verif image answer": "tug(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367011.jpg"}, {"question": "where is this", "gt answer": "small town(1.00)<br/>california(0.60)<br/>street(0.60)<br/>usa(0.60)", "pred answer": "racetrack", "question_id": 4007025, "best approach": "image", "verif answer": "usa", "anno approach": "wiki, concept, image", "verif wiki answer": "california(0.6334)", "verif concept answer": "usa(0.6475)", "verif image answer": "small town(0.6638)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400702.jpg"}, {"question": "how busy is the street near the hydrant", "gt answer": "not busy(1.00)<br/>not very(0.60)<br/>empty(0.60)", "pred answer": "very", "question_id": 1150035, "best approach": "image", "verif answer": "empty", "anno approach": "wiki, concept, image", "verif wiki answer": "not at all(0.6746)", "verif concept answer": "quiet(0.6527)", "verif image answer": "empty(0.5213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115003.jpg"}, {"question": "what brand is the mouse", "gt answer": "compaq(1.00)<br/>dell(0.60)", "pred answer": "logitech", "question_id": 4560095, "best approach": "concept, image", "verif answer": "logitech", "anno approach": "wiki, concept, image", "verif wiki answer": "logitech(0.6901)", "verif concept answer": "dell(0.6735)", "verif image answer": "dell(0.6846)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456009.jpg"}, {"question": "", "gt answer": "chocolate chip cookie and ice cream(0.60)", "pred answer": "wheat", "question_id": 4666275, "best approach": "wiki, concept, image", "verif answer": "cheese", "anno approach": "wiki, concept, image", "verif wiki answer": "chocolate chip cookie and ice cream(0.6102)", "verif concept answer": "chocolate chip cookie and ice cream(0.6442)", "verif image answer": "chocolate chip cookie and ice cream(0.7249)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466627.jpg"}, {"question": "is the lead cycle meeting safety requirements or is he unsafe", "gt answer": "safe(1.00)<br/>meet(0.60)", "pred answer": "fine", "question_id": 5057385, "best approach": "wiki, concept", "verif answer": "danger", "anno approach": "wiki, concept, image", "verif wiki answer": "meet(0.6440)", "verif concept answer": "meet(0.5240)", "verif image answer": "thrill seeker(0.5420)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505738.jpg"}, {"question": "what are the risks with being outdoors in cold weather during the winter", "gt answer": "frostbite(1.00)<br/>freeze(0.60)<br/>cold(0.60)", "pred answer": "fall", "question_id": 5368555, "best approach": "concept", "verif answer": "cold", "anno approach": "wiki, concept, image", "verif wiki answer": "frost bite(0.7156)", "verif concept answer": "freeze(0.6648)", "verif image answer": "ski(0.5999)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536855.jpg"}, {"question": "which city is this street corner at", "gt answer": "berlin(1.00)<br/>amsterdam(0.60)", "pred answer": "london", "question_id": 2240425, "best approach": "wiki", "verif answer": "london", "anno approach": "wiki, concept, image", "verif wiki answer": "berlin(0.7153)", "verif concept answer": "new york(0.7007)", "verif image answer": "new york(0.6785)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224042.jpg"}, {"question": "", "gt answer": "small(0.60)<br/>19 inch(0.60)", "pred answer": "medium", "question_id": 1602595, "best approach": "wiki, image", "verif answer": "15 pounds", "anno approach": "wiki, concept, image", "verif wiki answer": "small(0.6800)", "verif concept answer": "crow(0.6189)", "verif image answer": "small(0.6294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160259.jpg"}, {"question": "", "gt answer": "1900's(0.60)<br/>1914(0.60)<br/>1930(0.60)", "pred answer": "1800s", "question_id": 2084185, "best approach": "", "verif answer": "1912", "anno approach": "wiki, concept, image", "verif wiki answer": "1912(0.6280)", "verif concept answer": "1912(0.6014)", "verif image answer": "1912(0.6483)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208418.jpg"}, {"question": "what is main purpose of items in the picture", "gt answer": "provide water(1.00)<br/>water(0.60)", "pred answer": "safety", "question_id": 792985, "best approach": "concept", "verif answer": "art", "anno approach": "wiki, concept, image", "verif wiki answer": "art(0.7165)", "verif concept answer": "water(0.6409)", "verif image answer": "fun(0.6831)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079298.jpg"}, {"question": "what activity is this person doing", "gt answer": "game(1.00)<br/>play(0.60)", "pred answer": "play wii", "question_id": 352165, "best approach": "image", "verif answer": "video game", "anno approach": "wiki, concept, image", "verif wiki answer": "wii(0.6858)", "verif concept answer": "football(0.6513)", "verif image answer": "play(0.6073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000035216.jpg"}, {"question": "would you have travel far or nearto get here", "gt answer": "far(1.00)", "pred answer": "mile", "question_id": 3228695, "best approach": "image", "verif answer": "far", "anno approach": "wiki, concept, image", "verif wiki answer": "105 feet(0.6965)", "verif concept answer": "105 feet(0.6149)", "verif image answer": "far(0.5381)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322869.jpg"}, {"question": "where are the centerpieces found", "gt answer": "on table(1.00)<br/>table(1.00)<br/>garden(0.60)", "pred answer": "kitchen", "question_id": 3105015, "best approach": "concept", "verif answer": "table", "anno approach": "wiki, concept, image", "verif wiki answer": "dine room(0.7199)", "verif concept answer": "table(0.6570)", "verif image answer": "bench(0.6801)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310501.jpg"}, {"question": "what is the sun setting behind", "gt answer": "wall(1.00)<br/>bridge(0.60)<br/>tree(0.60)", "pred answer": "island", "question_id": 4954575, "best approach": "image", "verif answer": "bridge", "anno approach": "wiki, concept, image", "verif wiki answer": "fence(0.6929)", "verif concept answer": "fence(0.7123)", "verif image answer": "tree(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495457.jpg"}, {"question": "what type of camera was this taken from", "gt answer": "security camera(1.00)<br/>canon(0.60)", "pred answer": "wide angle", "question_id": 1439655, "best approach": "wiki", "verif answer": "canon", "anno approach": "wiki, concept, image", "verif wiki answer": "canon(0.6783)", "verif concept answer": "3(0.6020)", "verif image answer": "girl(0.5361)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143965.jpg"}, {"question": "how long did it take to climb this mountain", "gt answer": "6 hours(1.00)<br/>1 hour(0.60)", "pred answer": "hour", "question_id": 3820325, "best approach": "", "verif answer": "hour", "anno approach": "wiki, concept, image", "verif wiki answer": "2 hours(0.6638)", "verif concept answer": "8 hours(0.6815)", "verif image answer": "8 hours(0.5931)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382032.jpg"}, {"question": "what is the mouse attached to", "gt answer": "cord(1.00)<br/>computer(0.60)<br/>keyboard(0.60)<br/>wire(0.60)", "pred answer": "bluetooth", "question_id": 854835, "best approach": "wiki, concept, image", "verif answer": "bluetooth", "anno approach": "wiki, concept, image", "verif wiki answer": "computer(0.6939)", "verif concept answer": "wire(0.7028)", "verif image answer": "wire(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085483.jpg"}, {"question": "where in the supermarket would you find this food", "gt answer": "deli(1.00)", "pred answer": "grocery", "question_id": 3278765, "best approach": "", "verif answer": "taco", "anno approach": "wiki, concept, image", "verif wiki answer": "taco(0.7112)", "verif concept answer": "taco(0.6667)", "verif image answer": "diner(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327876.jpg"}, {"question": "these types of bears typically belong on what continent", "gt answer": "antarctica(1.00)<br/>north america(0.60)", "pred answer": "arctic", "question_id": 1131505, "best approach": "", "verif answer": "alaska", "anno approach": "wiki, concept, image", "verif wiki answer": "north pole(0.7249)", "verif concept answer": "north pole(0.7264)", "verif image answer": "north pole(0.7263)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113150.jpg"}, {"question": "the ads are for which company", "gt answer": "gucci(1.00)", "pred answer": "pepsi", "question_id": 1484805, "best approach": "", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "apple(0.7247)", "verif concept answer": "motorola(0.6285)", "verif image answer": "motorola(0.5177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148480.jpg"}, {"question": "what is the name of this flower", "gt answer": "morn glory(1.00)<br/>lily(0.60)<br/>orchid(0.60)", "pred answer": "dandelion", "question_id": 1563265, "best approach": "wiki, concept, image", "verif answer": "lily", "anno approach": "wiki, concept, image", "verif wiki answer": "orchid(0.6616)", "verif concept answer": "orchid(0.5520)", "verif image answer": "lily(0.6154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000156326.jpg"}, {"question": "what material is the bathtub made out of", "gt answer": "ceramic(1.00)<br/>steel(0.60)<br/>metal(0.60)", "pred answer": "tile", "question_id": 4948175, "best approach": "wiki", "verif answer": "ceramic", "anno approach": "wiki, concept, image", "verif wiki answer": "ceramic(0.6829)", "verif concept answer": "paper(0.6863)", "verif image answer": "steel(0.7124)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494817.jpg"}, {"question": "what kind of dog is that", "gt answer": "corgi(1.00)<br/>pomeranian(0.60)", "pred answer": "chihuahua", "question_id": 950505, "best approach": "", "verif answer": "pomeranian", "anno approach": "wiki, concept, image", "verif wiki answer": "beagle(0.7272)", "verif concept answer": "beagle(0.7084)", "verif image answer": "collie(0.6446)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000095050.jpg"}, {"question": "how many points do you play to in a tennis match", "gt answer": "48(1.00)<br/>45(0.60)<br/>wind(0.60)<br/>100(0.60)", "pred answer": "21", "question_id": 4326835, "best approach": "concept, image", "verif answer": "45", "anno approach": "wiki, concept, image", "verif wiki answer": "45(0.7247)", "verif concept answer": "48(0.6804)", "verif image answer": "48(0.6517)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432683.jpg"}, {"question": "why is the player touching the other player", "gt answer": "tag(1.00)<br/>out(0.60)<br/>accident(0.60)", "pred answer": "catch", "question_id": 3811165, "best approach": "wiki", "verif answer": "accident", "anno approach": "wiki, concept, image", "verif wiki answer": "tag(0.5901)", "verif concept answer": "accident(0.5056)", "verif image answer": "safe(0.5171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381116.jpg"}, {"question": "what kinds of phones are they using", "gt answer": "smartphone(1.00)<br/>blackberry(0.60)", "pred answer": "cell", "question_id": 600415, "best approach": "", "verif answer": "cell", "anno approach": "wiki, concept, image", "verif wiki answer": "iphone(0.6928)", "verif concept answer": "iphone(0.6937)", "verif image answer": "flip(0.5367)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060041.jpg"}, {"question": "what breed of horse is this", "gt answer": "thoroughbred(1.00)<br/>stallion(0.60)", "pred answer": "clydesdale", "question_id": 1267095, "best approach": "", "verif answer": "clydesdale", "anno approach": "wiki, concept, image", "verif wiki answer": "clydesdale(0.7182)", "verif concept answer": "clydesdale(0.6950)", "verif image answer": "arabian(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126709.jpg"}, {"question": "what type of food is this", "gt answer": "stir fry(1.00)<br/>ramen(0.60)<br/>italian(0.60)", "pred answer": "salad", "question_id": 2837155, "best approach": "wiki, concept, image", "verif answer": "italian", "anno approach": "wiki, concept, image", "verif wiki answer": "italian(0.7213)", "verif concept answer": "italian(0.6607)", "verif image answer": "italian(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283715.jpg"}, {"question": "who manufactures these vehicles", "gt answer": "ford(1.00)<br/>chevy(0.60)<br/>dodge(0.60)", "pred answer": "harley davidson", "question_id": 2177695, "best approach": "wiki, concept, image", "verif answer": "ford", "anno approach": "wiki, concept, image", "verif wiki answer": "ford(0.7256)", "verif concept answer": "ford(0.7077)", "verif image answer": "ford(0.6825)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217769.jpg"}, {"question": "can you tell me the place where this building is seen", "gt answer": "mexico(1.00)<br/>london(0.60)<br/>street(0.60)<br/>city(0.60)", "pred answer": "bus stop", "question_id": 1251685, "best approach": "concept", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "city(0.6998)", "verif concept answer": "mexico(0.6817)", "verif image answer": "street(0.7106)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125168.jpg"}, {"question": "what is the man doing", "gt answer": "tai chi(1.00)<br/>catch(0.60)<br/>fly kite(0.60)<br/>throw frisbee(0.60)", "pred answer": "frisbee", "question_id": 3721995, "best approach": "image", "verif answer": "throw", "anno approach": "wiki, concept, image", "verif wiki answer": "fly kite(0.7259)", "verif concept answer": "fly kite(0.6917)", "verif image answer": "tai chi(0.6072)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372199.jpg"}, {"question": "is this a snack or meal", "gt answer": "snack(1.00)", "pred answer": "meal", "question_id": 2851305, "best approach": "", "verif answer": "meal", "anno approach": "wiki, concept, image", "verif wiki answer": "meal(0.6662)", "verif concept answer": "meal(0.5656)", "verif image answer": "dessert(0.7065)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285130.jpg"}, {"question": "what is the vegetable being cut on", "gt answer": "board(1.00)<br/>cucumber(0.60)", "pred answer": "pan", "question_id": 1913385, "best approach": "", "verif answer": "water", "anno approach": "wiki, concept, image", "verif wiki answer": "water(0.7253)", "verif concept answer": "log(0.5972)", "verif image answer": "water(0.6912)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191338.jpg"}, {"question": "how old is this child", "gt answer": "5(1.00)<br/>6(1.00)<br/>2(0.60)", "pred answer": "4", "question_id": 5232205, "best approach": "concept", "verif answer": "4", "anno approach": "wiki, concept, image", "verif wiki answer": "3(0.6767)", "verif concept answer": "6(0.6252)", "verif image answer": "3(0.6486)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523220.jpg"}, {"question": "who lives at this relgious facility", "gt answer": "priest(1.00)", "pred answer": "biker", "question_id": 2573505, "best approach": "wiki", "verif answer": "woman", "anno approach": "wiki, concept, image", "verif wiki answer": "priest(0.5961)", "verif concept answer": "woman(0.6819)", "verif image answer": "both(0.5121)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257350.jpg"}, {"question": "in what city are these people getting their picture taken", "gt answer": "boston(1.00)<br/>new york city(0.60)<br/>seattle(0.60)", "pred answer": "new york", "question_id": 3451045, "best approach": "", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "new york(0.7243)", "verif concept answer": "new york(0.7134)", "verif image answer": "new york(0.6949)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345104.jpg"}, {"question": "what vehicle is this", "gt answer": "car(1.00)<br/>audi(0.60)", "pred answer": "motorcycle", "question_id": 3629445, "best approach": "", "verif answer": "sedan", "anno approach": "wiki, concept, image", "verif wiki answer": "sedan(0.7267)", "verif concept answer": "bike(0.6306)", "verif image answer": "bike(0.6491)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362944.jpg"}, {"question": "what kind of dog is this", "gt answer": "poodle(1.00)<br/>faux(0.60)", "pred answer": "terrier", "question_id": 2860095, "best approach": "wiki", "verif answer": "poodle", "anno approach": "wiki, concept, image", "verif wiki answer": "poodle(0.7146)", "verif concept answer": "husky(0.7005)", "verif image answer": "faux(0.6291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000286009.jpg"}, {"question": "what are they standing in", "gt answer": "truck(1.00)<br/>vehicle(0.60)", "pred answer": "carriage", "question_id": 2680365, "best approach": "concept", "verif answer": "truck", "anno approach": "wiki, concept, image", "verif wiki answer": "van(0.7208)", "verif concept answer": "truck(0.6825)", "verif image answer": "van(0.5799)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268036.jpg"}, {"question": "what types of fruit are these", "gt answer": "orange and lime(1.00)<br/>citrus(0.60)<br/>orange(0.60)", "pred answer": "apple and orange", "question_id": 4570505, "best approach": "wiki", "verif answer": "citrus", "anno approach": "wiki, concept, image", "verif wiki answer": "orange and lime(0.6956)", "verif concept answer": "orange(0.6347)", "verif image answer": "orange(0.6898)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457050.jpg"}, {"question": "how are the napkins folded", "gt answer": "in half(1.00)<br/>triangle(1.00)", "pred answer": "knife", "question_id": 2685485, "best approach": "wiki, image", "verif answer": "heart", "anno approach": "wiki, concept, image", "verif wiki answer": "triangle(0.7025)", "verif concept answer": "square(0.5643)", "verif image answer": "in half(0.5174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268548.jpg"}, {"question": "what is the girl in the middle wearing on her head", "gt answer": "headband(1.00)<br/>hat(0.60)", "pred answer": "hijab", "question_id": 3543275, "best approach": "concept", "verif answer": "hat", "anno approach": "wiki, concept, image", "verif wiki answer": "wizard hat(0.7223)", "verif concept answer": "hat(0.6938)", "verif image answer": "helmet(0.6545)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354327.jpg"}, {"question": "the baked good shown on the image was invented in which country", "gt answer": "america(1.00)<br/>germany(0.60)<br/>great britain(0.60)", "pred answer": "italy", "question_id": 3241655, "best approach": "wiki, concept, image", "verif answer": "germany", "anno approach": "wiki, concept, image", "verif wiki answer": "germany(0.6835)", "verif concept answer": "germany(0.6790)", "verif image answer": "great britain(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324165.jpg"}, {"question": "what does this land on", "gt answer": "runway(1.00)", "pred answer": "pavement", "question_id": 367835, "best approach": "wiki", "verif answer": "runway", "anno approach": "wiki, concept, image", "verif wiki answer": "runway(0.7280)", "verif concept answer": "air(0.6740)", "verif image answer": "air(0.5028)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036783.jpg"}, {"question": "what nationality eats this type of food", "gt answer": "mexican(1.00)<br/>mexico(0.60)<br/>asian(0.60)", "pred answer": "italian", "question_id": 2126105, "best approach": "image", "verif answer": "china", "anno approach": "wiki, concept, image", "verif wiki answer": "china(0.6234)", "verif concept answer": "china(0.6364)", "verif image answer": "mexico(0.6378)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212610.jpg"}, {"question": "what type of show is this", "gt answer": "news(1.00)", "pred answer": "video game", "question_id": 2212235, "best approach": "", "verif answer": "sport", "anno approach": "wiki, concept, image", "verif wiki answer": "sport(0.6444)", "verif concept answer": "crt(0.6762)", "verif image answer": "old(0.6841)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221223.jpg"}, {"question": "what could these children be watching", "gt answer": "cartoon(1.00)<br/>television(0.60)", "pred answer": "travel", "question_id": 3721985, "best approach": "", "verif answer": "television", "anno approach": "wiki, concept, image", "verif wiki answer": "movie(0.7214)", "verif concept answer": "tv(0.6323)", "verif image answer": "mickey mouse(0.5432)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372198.jpg"}, {"question": "why have these people gathered", "gt answer": "protest(1.00)", "pred answer": "parade", "question_id": 2855635, "best approach": "", "verif answer": "parade", "anno approach": "wiki, concept, image", "verif wiki answer": "obama(0.7248)", "verif concept answer": "obama(0.7285)", "verif image answer": "obama(0.7202)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285563.jpg"}, {"question": "what language is that written in yellow", "gt answer": "chinese(1.00)<br/>japanese(0.60)", "pred answer": "arabic", "question_id": 4254805, "best approach": "", "verif answer": "chinese", "anno approach": "wiki, concept, image", "verif wiki answer": "korean(0.7218)", "verif concept answer": "korean(0.7250)", "verif image answer": "asian(0.5493)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425480.jpg"}, {"question": "what is the man wearing on his head", "gt answer": "beanie(1.00)<br/>cap(0.60)", "pred answer": "hat", "question_id": 1382175, "best approach": "wiki, concept, image", "verif answer": "hat", "anno approach": "wiki, concept, image", "verif wiki answer": "beanie(0.7266)", "verif concept answer": "beanie(0.7286)", "verif image answer": "beanie(0.7019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138217.jpg"}, {"question": "what kind of jewelry does she have on", "gt answer": "earring(1.00)", "pred answer": "tie", "question_id": 5201555, "best approach": "concept", "verif answer": "music", "anno approach": "wiki, concept, image", "verif wiki answer": "music(0.6582)", "verif concept answer": "earring(0.7170)", "verif image answer": "music(0.7192)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520155.jpg"}, {"question": "what is someone called who can't see this color", "gt answer": "colorblind(1.00)", "pred answer": "light", "question_id": 3410655, "best approach": "concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "reflection(0.6943)", "verif concept answer": "colorblind(0.6791)", "verif image answer": "light(0.6702)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341065.jpg"}, {"question": "what is the man 's belt a reference to", "gt answer": "rasta(1.00)<br/>gay(0.60)", "pred answer": "skateboard", "question_id": 2842465, "best approach": "wiki, concept", "verif answer": "skateboard", "anno approach": "wiki, concept, image", "verif wiki answer": "rasta(0.7196)", "verif concept answer": "rasta(0.5794)", "verif image answer": "gay(0.6870)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284246.jpg"}, {"question": "what type of train is pictured here", "gt answer": "passenger train(1.00)<br/>cargo(0.60)<br/>amtrack(0.60)<br/>green(0.60)", "pred answer": "steam", "question_id": 5374125, "best approach": "wiki", "verif answer": "freight", "anno approach": "wiki, concept, image", "verif wiki answer": "passenger train(0.6685)", "verif concept answer": "freight(0.6678)", "verif image answer": "freight(0.6591)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537412.jpg"}, {"question": "which part of the body should this equipment be worn on", "gt answer": "feet(1.00)", "pred answer": "foot", "question_id": 3610305, "best approach": "wiki, image", "verif answer": "foot", "anno approach": "wiki, concept, image", "verif wiki answer": "feet(0.7259)", "verif concept answer": "foot(0.6654)", "verif image answer": "feet(0.7242)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361030.jpg"}, {"question": "what effect does this beverage have", "gt answer": "drunk(1.00)<br/>calm(0.60)<br/>intoxication(0.60)", "pred answer": "bark", "question_id": 4724325, "best approach": "concept, image", "verif answer": "wine", "anno approach": "wiki, concept, image", "verif wiki answer": "wine(0.7128)", "verif concept answer": "drunk(0.5875)", "verif image answer": "drunk(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000472432.jpg"}, {"question": "what type of chicken is this", "gt answer": "rooster(1.00)", "pred answer": "rhode island red", "question_id": 4130885, "best approach": "", "verif answer": "rhode island red", "anno approach": "wiki, concept, image", "verif wiki answer": "rhode island red(0.7207)", "verif concept answer": "rhode island red(0.7044)", "verif image answer": "rhode island red(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000413088.jpg"}, {"question": "what device is normally used to lead these animals", "gt answer": "rein(1.00)<br/>rain(0.60)", "pred answer": "saddle", "question_id": 1517315, "best approach": "image", "verif answer": "saddle", "anno approach": "wiki, concept, image", "verif wiki answer": "saddle(0.7000)", "verif concept answer": "saddle(0.6652)", "verif image answer": "rain(0.6321)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151731.jpg"}, {"question": "what effect would be experienced from too much of the beverage", "gt answer": "drunk(1.00)<br/>intoxication(0.60)", "pred answer": "on rock", "question_id": 4492385, "best approach": "", "verif answer": "fermentation", "anno approach": "wiki, concept, image", "verif wiki answer": "fermentation(0.7135)", "verif concept answer": "fermentation(0.7175)", "verif image answer": "calm(0.5824)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449238.jpg"}, {"question": "what movie has the same color scheme as the picture", "gt answer": "schindler's list(1.00)<br/>black and white(0.60)<br/>color(0.60)", "pred answer": "wizard of oz", "question_id": 3216015, "best approach": "wiki", "verif answer": "long exposure", "anno approach": "wiki, concept, image", "verif wiki answer": "black and white(0.5178)", "verif concept answer": "long exposure(0.5972)", "verif image answer": "long exposure(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321601.jpg"}, {"question": "what is the lifespan of this animal", "gt answer": "15 years(1.00)<br/>20(0.60)", "pred answer": "10 years", "question_id": 5673465, "best approach": "wiki, concept", "verif answer": "10 years", "anno approach": "wiki, concept, image", "verif wiki answer": "15 years(0.6783)", "verif concept answer": "15 years(0.6956)", "verif image answer": "10 years(0.6187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567346.jpg"}, {"question": "who is advertising in this park", "gt answer": "coca cola(1.00)", "pred answer": "shaun white", "question_id": 261645, "best approach": "wiki, concept, image", "verif answer": "coca cola", "anno approach": "wiki, concept, image", "verif wiki answer": "coca cola(0.5722)", "verif concept answer": "coca cola(0.6272)", "verif image answer": "coca cola(0.5420)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000026164.jpg"}, {"question": "is this bed larger smaller or the same size as a twin bed", "gt answer": "larger(1.00)", "pred answer": "queen", "question_id": 787605, "best approach": "", "verif answer": "queen", "anno approach": "wiki, concept, image", "verif wiki answer": "huge(0.6983)", "verif concept answer": "huge(0.6869)", "verif image answer": "huge(0.6523)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078760.jpg"}, {"question": "what geometric shape is the patch on the elephant", "gt answer": "diamond(1.00)", "pred answer": "star", "question_id": 2855705, "best approach": "image", "verif answer": "square", "anno approach": "wiki, concept, image", "verif wiki answer": "square(0.6367)", "verif concept answer": "square(0.6317)", "verif image answer": "diamond(0.5211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285570.jpg"}, {"question": "how many wheels does this vehicle have normally", "gt answer": "18(1.00)", "pred answer": "2", "question_id": 4358395, "best approach": "image", "verif answer": "8", "anno approach": "wiki, concept, image", "verif wiki answer": "21(0.6951)", "verif concept answer": "21(0.6599)", "verif image answer": "18(0.6835)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435839.jpg"}, {"question": "how long of a runway is required for a small plane to take off", "gt answer": "6000 feet(1.00)", "pred answer": "20 feet", "question_id": 4798995, "best approach": "wiki, concept", "verif answer": "1 mile", "anno approach": "wiki, concept, image", "verif wiki answer": "6000 feet(0.6922)", "verif concept answer": "6000 feet(0.6399)", "verif image answer": "2000 feet(0.6188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479899.jpg"}, {"question": "what kind of motorcycle is this mirror on", "gt answer": "scooter(1.00)<br/>black(0.60)<br/>harley davidson(0.60)", "pred answer": "honda", "question_id": 3545455, "best approach": "wiki, concept", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "scooter(0.7142)", "verif concept answer": "scooter(0.6918)", "verif image answer": "black(0.6922)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354545.jpg"}, {"question": "what is the name of the song belonging to the lyrics", "gt answer": "bohemian rhapsody(1.00)", "pred answer": "national anthem", "question_id": 4412635, "best approach": "wiki", "verif answer": "catholic", "anno approach": "wiki, concept, image", "verif wiki answer": "bohemian rhapsody(0.7043)", "verif concept answer": "catholic(0.5584)", "verif image answer": "catholic(0.5176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441263.jpg"}, {"question": "where would you find an umbrella like the one shown", "gt answer": "patio(1.00)<br/>beach(0.60)", "pred answer": "poolside", "question_id": 2564745, "best approach": "image", "verif answer": "beach", "anno approach": "wiki, concept, image", "verif wiki answer": "beach(0.7154)", "verif concept answer": "indoor(0.6954)", "verif image answer": "patio(0.7026)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256474.jpg"}, {"question": "what tv show is the character on the tv from", "gt answer": "friend(1.00)", "pred answer": "cartoon", "question_id": 399485, "best approach": "concept", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "best friend(0.7156)", "verif concept answer": "friend(0.6885)", "verif image answer": "father and son(0.6149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039948.jpg"}, {"question": "the viewers are seated in an area known as the what", "gt answer": "stand(1.00)<br/>bleacher(0.60)", "pred answer": "stadium", "question_id": 3406225, "best approach": "image", "verif answer": "bleacher", "anno approach": "wiki, concept, image", "verif wiki answer": "bench(0.6014)", "verif concept answer": "bench(0.5623)", "verif image answer": "stand(0.6629)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340622.jpg"}, {"question": "why are the bananas sitting under the sun", "gt answer": "ripen(1.00)", "pred answer": "not ripe", "question_id": 5343235, "best approach": "concept, image", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "rain(0.5764)", "verif concept answer": "ripen(0.6455)", "verif image answer": "ripen(0.6563)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534323.jpg"}, {"question": "what is the breed of each dog", "gt answer": "golden retriever(1.00)", "pred answer": "boxer", "question_id": 2793775, "best approach": "", "verif answer": "labrador", "anno approach": "wiki, concept, image", "verif wiki answer": "labrador(0.7149)", "verif concept answer": "german shepherd(0.6872)", "verif image answer": "collie(0.5731)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000279377.jpg"}, {"question": "when was the first stadium of this type built", "gt answer": "1909(1.00)<br/>1970(0.60)", "pred answer": "1839", "question_id": 32205, "best approach": "concept, image", "verif answer": "1970", "anno approach": "wiki, concept, image", "verif wiki answer": "1990(0.6245)", "verif concept answer": "1909(0.5529)", "verif image answer": "1909(0.7282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003220.jpg"}, {"question": "what is this brand famous for", "gt answer": "iphones(1.00)<br/>fun(0.60)<br/>apple(0.60)", "pred answer": "laptop", "question_id": 3769885, "best approach": "wiki", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "iphones(0.6733)", "verif concept answer": "cell phone(0.6620)", "verif image answer": "fun(0.6362)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376988.jpg"}, {"question": "what model of computer is this", "gt answer": "laptop(1.00)<br/>desktop(0.60)", "pred answer": "ibm", "question_id": 851715, "best approach": "image", "verif answer": "ibm", "anno approach": "wiki, concept, image", "verif wiki answer": "macbook(0.7065)", "verif concept answer": "desktop(0.6717)", "verif image answer": "laptop(0.7086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085171.jpg"}, {"question": "what is the specific action which gives this truck its name", "gt answer": "dump(1.00)<br/>pickup(0.60)", "pred answer": "tow", "question_id": 5460745, "best approach": "wiki", "verif answer": "construction", "anno approach": "wiki, concept, image", "verif wiki answer": "pickup(0.6769)", "verif concept answer": "flatbed(0.7109)", "verif image answer": "construction(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546074.jpg"}, {"question": "does this person likely have good or bad natural eyesight", "gt answer": "bad(1.00)", "pred answer": "good", "question_id": 2007825, "best approach": "concept", "verif answer": "good", "anno approach": "wiki, concept, image", "verif wiki answer": "over ripe(0.7286)", "verif concept answer": "bad(0.7273)", "verif image answer": "over ripe(0.5912)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200782.jpg"}, {"question": "what is the name of the vehicle the jet is taking off from", "gt answer": "aircraft carrier(1.00)<br/>pad(0.60)", "pred answer": "helicopter", "question_id": 4493695, "best approach": "wiki, concept, image", "verif answer": "navy", "anno approach": "wiki, concept, image", "verif wiki answer": "pad(0.6425)", "verif concept answer": "pad(0.6905)", "verif image answer": "pad(0.5186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449369.jpg"}, {"question": "what are sausages stuffed into", "gt answer": "case(1.00)", "pred answer": "grill", "question_id": 1485165, "best approach": "wiki", "verif answer": "sauce", "anno approach": "wiki, concept, image", "verif wiki answer": "case(0.7297)", "verif concept answer": "sauce(0.6951)", "verif image answer": "backpack(0.6941)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148516.jpg"}, {"question": "what is the girl in the picture doing", "gt answer": "take selfie(1.00)<br/>film(0.60)", "pred answer": "take picture", "question_id": 3477945, "best approach": "wiki, image", "verif answer": "take picture", "anno approach": "wiki, concept, image", "verif wiki answer": "take selfie(0.6957)", "verif concept answer": "take photo(0.6436)", "verif image answer": "take selfie(0.5872)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347794.jpg"}, {"question": "what bird species is shown in this image", "gt answer": "robin(1.00)<br/>finch(0.60)", "pred answer": "sparrow", "question_id": 4608795, "best approach": "concept, image", "verif answer": "sparrow", "anno approach": "wiki, concept, image", "verif wiki answer": "sparrow(0.6925)", "verif concept answer": "finch(0.6738)", "verif image answer": "finch(0.7017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460879.jpg"}, {"question": "what type of wood is that", "gt answer": "lumber(0.60)<br/>bamboo(0.60)<br/>log(1.00)<br/>pine(0.60)", "pred answer": "oak", "question_id": 48345, "best approach": "wiki, concept", "verif answer": "lumber", "anno approach": "wiki, concept, image", "verif wiki answer": "bamboo(0.7095)", "verif concept answer": "bamboo(0.7106)", "verif image answer": "wood(0.7237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004834.jpg"}, {"question": "what is the purpose of the green fabric around the horses ankles", "gt answer": "to be seen(1.00)<br/>visibility(1.00)", "pred answer": "safety", "question_id": 2686445, "best approach": "", "verif answer": "to be seen", "anno approach": "wiki, concept, image", "verif wiki answer": "fun(0.7229)", "verif concept answer": "fun(0.5180)", "verif image answer": "identification(0.5081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268644.jpg"}, {"question": "what is kept in the tube that the baby is holding", "gt answer": "toothpaste(1.00)<br/>juice(0.60)<br/>straw(0.60)", "pred answer": "citrus juice", "question_id": 415975, "best approach": "wiki, concept, image", "verif answer": "straw", "anno approach": "wiki, concept, image", "verif wiki answer": "juice(0.7090)", "verif concept answer": "juice(0.6955)", "verif image answer": "juice(0.7042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041597.jpg"}, {"question": "what is the purpose of the item in the box", "gt answer": "protection(0.60)<br/>compute(1.00)", "pred answer": "work", "question_id": 795915, "best approach": "wiki, concept", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "protection(0.7280)", "verif concept answer": "protection(0.6452)", "verif image answer": "internet(0.6748)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079591.jpg"}, {"question": "what is the name of the animated version of this animal found in disney 's the jungle book", "gt answer": "baloo(1.00)", "pred answer": "bear", "question_id": 1375835, "best approach": "concept", "verif answer": "bear", "anno approach": "wiki, concept, image", "verif wiki answer": "play(0.5517)", "verif concept answer": "baloo(0.6909)", "verif image answer": "apple(0.5038)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000137583.jpg"}, {"question": "do these mountains more resemble a kanye west promotional art for his music or mackned promotional art for his music", "gt answer": "kanye west(1.00)", "pred answer": "country", "question_id": 3739605, "best approach": "", "verif answer": "cross country", "anno approach": "wiki, concept, image", "verif wiki answer": "2000(0.5138)", "verif concept answer": "cross country(0.7122)", "verif image answer": "2000(0.5098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373960.jpg"}, {"question": "what is the name of the pattern on the plates", "gt answer": "zigzag(1.00)", "pred answer": "checkered", "question_id": 1150185, "best approach": "", "verif answer": "checkered", "anno approach": "wiki, concept, image", "verif wiki answer": "stripe(0.6905)", "verif concept answer": "checkered(0.6887)", "verif image answer": "stripe(0.5786)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115018.jpg"}, {"question": "what type of food is this", "gt answer": "donut(1.00)<br/>doughnut(0.60)", "pred answer": "hot dog", "question_id": 5091145, "best approach": "wiki", "verif answer": "donut", "anno approach": "wiki, concept, image", "verif wiki answer": "donut(0.6938)", "verif concept answer": "sprinkle(0.6615)", "verif image answer": "donuts(0.6780)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509114.jpg"}, {"question": "what helps this vehicle to remain suspended in the air", "gt answer": "propel(1.00)<br/>propeller(0.60)<br/>air(0.60)", "pred answer": "engine", "question_id": 99875, "best approach": "wiki", "verif answer": "wind", "anno approach": "wiki, concept, image", "verif wiki answer": "air(0.7244)", "verif concept answer": "gravity(0.7163)", "verif image answer": "gravity(0.6629)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009987.jpg"}, {"question": "what kind of weather do these cyclists appear dressed for", "gt answer": "cool(1.00)<br/>rain(0.60)<br/>autumn(0.60)<br/>fall(0.60)", "pred answer": "cold", "question_id": 729875, "best approach": "image", "verif answer": "autumn", "anno approach": "wiki, concept, image", "verif wiki answer": "spring(0.6968)", "verif concept answer": "spring(0.6377)", "verif image answer": "rain(0.5513)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072987.jpg"}, {"question": "what treat can be baked in an oven", "gt answer": "cookies(1.00)<br/>cake(0.60)<br/>bread(0.60)", "pred answer": "pancake", "question_id": 948845, "best approach": "wiki, concept, image", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "cookies(0.7225)", "verif concept answer": "cookies(0.7167)", "verif image answer": "cookies(0.6039)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094884.jpg"}, {"question": "how often might a dad get a cake like the one in the photo", "gt answer": "once year(1.00)<br/>once(0.60)<br/>yearly(0.60)", "pred answer": "1 hour", "question_id": 4097675, "best approach": "image", "verif answer": "once", "anno approach": "wiki, concept, image", "verif wiki answer": "yearly(0.6420)", "verif concept answer": "once(0.5879)", "verif image answer": "once year(0.6624)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409767.jpg"}, {"question": "what does someone want to happen", "gt answer": "stop harper(1.00)", "pred answer": "stop", "question_id": 3734925, "best approach": "wiki, concept", "verif answer": "vandalism", "anno approach": "wiki, concept, image", "verif wiki answer": "stop harper(0.6855)", "verif concept answer": "stop harper(0.7146)", "verif image answer": "light(0.6665)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373492.jpg"}, {"question": "what is the boy on the left peeling", "gt answer": "potato(1.00)", "pred answer": "apple", "question_id": 5694925, "best approach": "concept", "verif answer": "salad", "anno approach": "wiki, concept, image", "verif wiki answer": "bread(0.7111)", "verif concept answer": "potato(0.7145)", "verif image answer": "carrot(0.7148)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569492.jpg"}, {"question": "what brand is this vehicle", "gt answer": "mercedes(1.00)<br/>daf(1.00)<br/>lexus(0.60)", "pred answer": "ford", "question_id": 5327685, "best approach": "", "verif answer": "mercedes benz", "anno approach": "wiki, concept, image", "verif wiki answer": "mercedes benz(0.7285)", "verif concept answer": "mercedes benz(0.7140)", "verif image answer": "mercedes benz(0.7132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532768.jpg"}, {"question": "how much water do they drink", "gt answer": "lot(1.00)<br/>10 gallons(0.60)<br/>5 gallons(0.60)", "pred answer": "gallon", "question_id": 2246745, "best approach": "wiki", "verif answer": "gallon", "anno approach": "wiki, concept, image", "verif wiki answer": "10 gallons(0.7253)", "verif concept answer": "milk(0.5882)", "verif image answer": "gallon(0.6578)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224674.jpg"}, {"question": "what is on the elephant 's leg", "gt answer": "blood(1.00)<br/>boot(0.60)", "pred answer": "fur", "question_id": 5275975, "best approach": "wiki, concept, image", "verif answer": "boot", "anno approach": "wiki, concept, image", "verif wiki answer": "boot(0.7168)", "verif concept answer": "boot(0.6959)", "verif image answer": "boot(0.7102)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527597.jpg"}, {"question": "what type of energy does the white device utilize", "gt answer": "solar(1.00)", "pred answer": "electricity", "question_id": 4400155, "best approach": "", "verif answer": "diesel", "anno approach": "wiki, concept, image", "verif wiki answer": "diesel(0.7143)", "verif concept answer": "diesel(0.6918)", "verif image answer": "diesel(0.6530)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440015.jpg"}, {"question": "how long will the ride be", "gt answer": "2 hours(1.00)<br/>mile(0.60)", "pred answer": "1 hour", "question_id": 4488395, "best approach": "", "verif answer": "1 hour", "anno approach": "wiki, concept, image", "verif wiki answer": "1 hour(0.6285)", "verif concept answer": "15 minutes(0.6148)", "verif image answer": "15 minutes(0.6816)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448839.jpg"}, {"question": "what 's the primary photographic style used here", "gt answer": "shadow(1.00)<br/>candid(0.60)", "pred answer": "black and white", "question_id": 5160435, "best approach": "wiki, concept", "verif answer": "candid", "anno approach": "wiki, concept, image", "verif wiki answer": "candid(0.7020)", "verif concept answer": "candid(0.6112)", "verif image answer": "sunset(0.6130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516043.jpg"}, {"question": "what are the people sitting on", "gt answer": "bench(1.00)<br/>sidewalk(0.60)<br/>chair(0.60)", "pred answer": "stair", "question_id": 1587945, "best approach": "wiki, concept, image", "verif answer": "bench", "anno approach": "wiki, concept, image", "verif wiki answer": "bench(0.7227)", "verif concept answer": "bench(0.6709)", "verif image answer": "bench(0.6183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000158794.jpg"}, {"question": "what type of energy is moving the board", "gt answer": "kinetic(1.00)<br/>water(0.60)", "pred answer": "wind", "question_id": 851545, "best approach": "wiki", "verif answer": "gasoline", "anno approach": "wiki, concept, image", "verif wiki answer": "kinetic(0.7056)", "verif concept answer": "gas(0.5948)", "verif image answer": "gasoline(0.6659)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085154.jpg"}, {"question": "what types of vegetables do you see", "gt answer": "broccoli(1.00)<br/>tomato(0.60)", "pred answer": "pepper", "question_id": 3227495, "best approach": "", "verif answer": "pepper", "anno approach": "wiki, concept, image", "verif wiki answer": "pepper(0.7224)", "verif concept answer": "pepper(0.7251)", "verif image answer": "pepper(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322749.jpg"}, {"question": "what are they doing", "gt answer": "cut cake(1.00)<br/>eat(0.60)", "pred answer": "birthday", "question_id": 1543455, "best approach": "concept", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "cake(0.6683)", "verif concept answer": "cut cake(0.6823)", "verif image answer": "eat(0.5292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154345.jpg"}, {"question": "what is the name of the garment worn by the men in this photo", "gt answer": "robe(1.00)<br/>coat(0.60)", "pred answer": "sweater", "question_id": 5039615, "best approach": "concept", "verif answer": "hat", "anno approach": "wiki, concept, image", "verif wiki answer": "hat(0.7258)", "verif concept answer": "robe(0.6688)", "verif image answer": "coat(0.6450)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503961.jpg"}, {"question": "how might a vehicle like this be powered other than electrically", "gt answer": "steam(1.00)<br/>diesel(0.60)<br/>fuel(0.60)", "pred answer": "gas", "question_id": 2574145, "best approach": "wiki", "verif answer": "gas", "anno approach": "wiki, concept, image", "verif wiki answer": "steam(0.7172)", "verif concept answer": "fuel(0.7013)", "verif image answer": "fuel(0.5686)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257414.jpg"}, {"question": "who is the parent company of the sponsor", "gt answer": "ge(1.00)<br/>general electric(0.60)", "pred answer": "mercedes", "question_id": 1681875, "best approach": "wiki, concept", "verif answer": "general electric", "anno approach": "wiki, concept, image", "verif wiki answer": "general electric(0.7240)", "verif concept answer": "general electric(0.7153)", "verif image answer": "frigidaire(0.6208)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168187.jpg"}, {"question": "what team won the title for this sport last year", "gt answer": "astros(1.00)<br/>met(0.60)<br/>houston astros(0.60)", "pred answer": "dodger", "question_id": 1346225, "best approach": "", "verif answer": "dodger", "anno approach": "wiki, concept, image", "verif wiki answer": "dodger(0.7276)", "verif concept answer": "dodger(0.7198)", "verif image answer": "dodger(0.6755)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134622.jpg"}, {"question": "which item depicted is usually made with baking powder", "gt answer": "roll(0.60)<br/>bun(1.00)<br/>biscuit(0.60)<br/>bread(0.60)", "pred answer": "pancake", "question_id": 5264335, "best approach": "wiki, concept, image", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "bread(0.7256)", "verif concept answer": "roll(0.6945)", "verif image answer": "roll(0.6642)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526433.jpg"}, {"question": "how long has this brand of soda been around", "gt answer": "1886(1.00)<br/>1892(0.60)<br/>100 years(0.60)", "pred answer": "3 years", "question_id": 1572375, "best approach": "concept, image", "verif answer": "50 years", "anno approach": "wiki, concept, image", "verif wiki answer": "1940(0.6673)", "verif concept answer": "1892(0.6594)", "verif image answer": "1892(0.6698)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157237.jpg"}, {"question": "what utensils are not pictured", "gt answer": "fork and knife(1.00)<br/>fork(1.00)", "pred answer": "spoon", "question_id": 2898525, "best approach": "concept, image", "verif answer": "fork", "anno approach": "wiki, concept, image", "verif wiki answer": "right fork(0.6705)", "verif concept answer": "fork(0.6538)", "verif image answer": "fork(0.5309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000289852.jpg"}, {"question": "what is the name of the item worn around the neck and tied at the waist", "gt answer": "apron(1.00)", "pred answer": "tie", "question_id": 4491975, "best approach": "", "verif answer": "tie", "anno approach": "wiki, concept, image", "verif wiki answer": "tie(0.7229)", "verif concept answer": "tie(0.7301)", "verif image answer": "tie(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449197.jpg"}, {"question": "what kind of bike is this", "gt answer": "schwinn(1.00)<br/>motorcycle(0.60)<br/>pedal(0.60)", "pred answer": "bicycle", "question_id": 2157825, "best approach": "wiki", "verif answer": "pedal", "anno approach": "wiki, concept, image", "verif wiki answer": "pedal(0.7093)", "verif concept answer": "huffy(0.6700)", "verif image answer": "huffy(0.6928)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215782.jpg"}, {"question": "which item depicted here is also a kind of shoe", "gt answer": "platform(1.00)<br/>train(0.60)<br/>track(0.60)", "pred answer": "boot", "question_id": 242575, "best approach": "wiki", "verif answer": "train", "anno approach": "wiki, concept, image", "verif wiki answer": "platform(0.6102)", "verif concept answer": "scooter(0.6026)", "verif image answer": "scooter(0.6104)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024257.jpg"}, {"question": "guess what type of ice doll they are going to do", "gt answer": "snow man(1.00)<br/>snowboard(0.60)", "pred answer": "cross country", "question_id": 123135, "best approach": "wiki, image", "verif answer": "snowboard", "anno approach": "wiki, concept, image", "verif wiki answer": "snow man(0.6056)", "verif concept answer": "snowboard(0.5973)", "verif image answer": "snow man(0.5177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012313.jpg"}, {"question": "at what time of day is the food depicted eaten", "gt answer": "noon(1.00)<br/>afternoon(0.60)<br/>dinner(0.60)<br/>lunch(0.60)", "pred answer": "morn", "question_id": 3039355, "best approach": "wiki, image", "verif answer": "morn", "anno approach": "wiki, concept, image", "verif wiki answer": "afternoon(0.7177)", "verif concept answer": "morn(0.7258)", "verif image answer": "afternoon(0.5701)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303935.jpg"}, {"question": "how many master card logos are there", "gt answer": "2(1.00)", "pred answer": "5", "question_id": 1970695, "best approach": "", "verif answer": "5", "anno approach": "wiki, concept, image", "verif wiki answer": "0(0.7195)", "verif concept answer": "0(0.6761)", "verif image answer": "5(0.7230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197069.jpg"}, {"question": "would this be a traditionally made or custom made", "gt answer": "custom(1.00)", "pred answer": "friendly", "question_id": 3123385, "best approach": "", "verif answer": "real", "anno approach": "wiki, concept, image", "verif wiki answer": "real(0.5385)", "verif concept answer": "real(0.6194)", "verif image answer": "real(0.5435)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312338.jpg"}, {"question": "what is a group of bananas called", "gt answer": "bunch(1.00)", "pred answer": "sun", "question_id": 761305, "best approach": "", "verif answer": "bunch", "anno approach": "wiki, concept, image", "verif wiki answer": "orange(0.5404)", "verif concept answer": "orange(0.5450)", "verif image answer": "orange(0.5813)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076130.jpg"}, {"question": "who had the highest batting rate in history", "gt answer": "ty cobb(1.00)<br/>pete rose(0.60)", "pred answer": "babe ruth", "question_id": 2464125, "best approach": "", "verif answer": "babe ruth", "anno approach": "wiki, concept, image", "verif wiki answer": "babe ruth(0.7267)", "verif concept answer": "babe ruth(0.7173)", "verif image answer": "babe ruth(0.7079)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246412.jpg"}, {"question": "who makes this phone", "gt answer": "motorola(1.00)<br/>samsung(0.60)", "pred answer": "nokia", "question_id": 228545, "best approach": "image", "verif answer": "nokia", "anno approach": "wiki, concept, image", "verif wiki answer": "nokia(0.6547)", "verif concept answer": "nokia(0.6777)", "verif image answer": "samsung(0.7055)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000022854.jpg"}, {"question": "what is the process called that denudes these animals of their covering", "gt answer": "shear(1.00)", "pred answer": "wool", "question_id": 5467235, "best approach": "", "verif answer": "shear", "anno approach": "wiki, concept, image", "verif wiki answer": "sheer(0.6587)", "verif concept answer": "sheer(0.6740)", "verif image answer": "sheer(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546723.jpg"}, {"question": "what is written on the green sign", "gt answer": "hilltop hotel(1.00)<br/>letter(0.60)<br/>walk(0.60)", "pred answer": "street", "question_id": 2032695, "best approach": "wiki", "verif answer": "western ave", "anno approach": "wiki, concept, image", "verif wiki answer": "hilltop hotel(0.6378)", "verif concept answer": "newspaper(0.5201)", "verif image answer": "western ave(0.6808)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203269.jpg"}, {"question": "what is the general mood in this room", "gt answer": "happy(1.00)", "pred answer": "tired", "question_id": 2572975, "best approach": "wiki, concept", "verif answer": "happiness", "anno approach": "wiki, concept, image", "verif wiki answer": "happy(0.7278)", "verif concept answer": "happy(0.7237)", "verif image answer": "excited(0.7034)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257297.jpg"}, {"question": "what movie features this vehicle and it can not stop", "gt answer": "speed(1.00)<br/>car(0.60)", "pred answer": "star war", "question_id": 864525, "best approach": "image", "verif answer": "0", "anno approach": "wiki, concept, image", "verif wiki answer": "jaywalk(0.5392)", "verif concept answer": "jaywalk(0.6151)", "verif image answer": "car(0.5942)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086452.jpg"}, {"question": "where in africa is this photo taken", "gt answer": "savannah(1.00)<br/>outside(0.60)", "pred answer": "africa", "question_id": 1095865, "best approach": "wiki, concept", "verif answer": "plain", "anno approach": "wiki, concept, image", "verif wiki answer": "savannah(0.7004)", "verif concept answer": "savannah(0.7026)", "verif image answer": "plain(0.6839)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000109586.jpg"}, {"question": "what is this person performing", "gt answer": "trick(1.00)<br/>flip(0.60)", "pred answer": "ski", "question_id": 2547745, "best approach": "", "verif answer": "backflip", "anno approach": "wiki, concept, image", "verif wiki answer": "jump(0.6456)", "verif concept answer": "jump(0.7031)", "verif image answer": "kickflip(0.5029)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000254774.jpg"}, {"question": "what are these books about", "gt answer": "embroidery(1.00)", "pred answer": "mystery", "question_id": 4514825, "best approach": "", "verif answer": "student", "anno approach": "wiki, concept, image", "verif wiki answer": "art(0.7135)", "verif concept answer": "art(0.6082)", "verif image answer": "student(0.5998)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451482.jpg"}, {"question": "what is the model of this car", "gt answer": "model t(1.00)", "pred answer": "jeep", "question_id": 1990115, "best approach": "", "verif answer": "truck", "anno approach": "wiki, concept, image", "verif wiki answer": "honda(0.7085)", "verif concept answer": "vintage(0.5615)", "verif image answer": "honda(0.6287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199011.jpg"}, {"question": "how is this side item cooked", "gt answer": "fried(1.00)<br/>fresh(0.60)", "pred answer": "grilled", "question_id": 182765, "best approach": "wiki", "verif answer": "fried", "anno approach": "wiki, concept, image", "verif wiki answer": "fried(0.7119)", "verif concept answer": "toasted(0.7120)", "verif image answer": "fry(0.6414)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000018276.jpg"}, {"question": "what is the fire hydrate doing", "gt answer": "leak(1.00)<br/>run(0.60)", "pred answer": "move", "question_id": 5412035, "best approach": "concept, image", "verif answer": "fire", "anno approach": "wiki, concept, image", "verif wiki answer": "smell(0.7260)", "verif concept answer": "run(0.6560)", "verif image answer": "run(0.7049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541203.jpg"}, {"question": "how many base are in this sport", "gt answer": "4(1.00)<br/>3(0.60)", "pred answer": "6", "question_id": 397775, "best approach": "image", "verif answer": "6", "anno approach": "wiki, concept, image", "verif wiki answer": "6(0.7165)", "verif concept answer": "6(0.6901)", "verif image answer": "4(0.7187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039777.jpg"}, {"question": "what league are the players on this team members of", "gt answer": "major league(1.00)<br/>major(1.00)", "pred answer": "baseball", "question_id": 3957685, "best approach": "wiki, concept", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "major(0.7232)", "verif concept answer": "major(0.7023)", "verif image answer": "minor(0.7011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395768.jpg"}, {"question": "what kind of couch is this", "gt answer": "loveseat(1.00)<br/>brown(1.00)<br/>long(0.60)", "pred answer": "couch", "question_id": 1871675, "best approach": "wiki", "verif answer": "brown", "anno approach": "wiki, concept, image", "verif wiki answer": "brown(0.7210)", "verif concept answer": "grizzly(0.7011)", "verif image answer": "long(0.7025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187167.jpg"}, {"question": "what breed of dogs are these", "gt answer": "mixed(1.00)<br/>dog(0.60)", "pred answer": "mutt", "question_id": 790215, "best approach": "", "verif answer": "collie", "anno approach": "wiki, concept, image", "verif wiki answer": "collie(0.6839)", "verif concept answer": "doberman(0.6921)", "verif image answer": "doberman(0.6176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079021.jpg"}, {"question": "what relationship do these men have", "gt answer": "father and son(0.60)<br/>friend(1.00)", "pred answer": "family", "question_id": 5597605, "best approach": "", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "co worker(0.7089)", "verif concept answer": "co worker(0.7146)", "verif image answer": "lost(0.5216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559760.jpg"}, {"question": "what is this kind of table named after", "gt answer": "picnic(1.00)<br/>picnic table(0.60)", "pred answer": "cafeteria", "question_id": 3336945, "best approach": "concept", "verif answer": "picnic", "anno approach": "wiki, concept, image", "verif wiki answer": "picnic table(0.7185)", "verif concept answer": "picnic(0.6810)", "verif image answer": "lunch(0.6876)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333694.jpg"}, {"question": "are these travelers going home or going on an adventure", "gt answer": "adventure(1.00)<br/>home(0.60)", "pred answer": "vacation", "question_id": 3018555, "best approach": "", "verif answer": "dorm", "anno approach": "wiki, concept, image", "verif wiki answer": "dorm(0.7110)", "verif concept answer": "nike(0.5138)", "verif image answer": "dorm(0.5063)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301855.jpg"}, {"question": "what is underneath this bag", "gt answer": "park meter(1.00)<br/>meter(0.60)", "pred answer": "sidewalk", "question_id": 811025, "best approach": "wiki", "verif answer": "park meter", "anno approach": "wiki, concept, image", "verif wiki answer": "park meter(0.7226)", "verif concept answer": "meter(0.6221)", "verif image answer": "park(0.5113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081102.jpg"}, {"question": "which superhero is the cake supposed to be", "gt answer": "wonder woman(1.00)", "pred answer": "batman", "question_id": 4379445, "best approach": "wiki", "verif answer": "batman", "anno approach": "wiki, concept, image", "verif wiki answer": "wonder woman(0.6616)", "verif concept answer": "fondant(0.5986)", "verif image answer": "captain(0.6592)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437944.jpg"}, {"question": "is this a portrait shot or was the photo taken while this subject was doing something", "gt answer": "candid(1.00)<br/>active(0.60)<br/>eat(0.60)", "pred answer": "snapshot", "question_id": 4306915, "best approach": "image", "verif answer": "active", "anno approach": "wiki, concept, image", "verif wiki answer": "relax(0.7155)", "verif concept answer": "relax(0.6701)", "verif image answer": "candid(0.6343)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430691.jpg"}, {"question": "what is this animal being transported inside of", "gt answer": "trailer(1.00)", "pred answer": "stable", "question_id": 3820445, "best approach": "image", "verif answer": "house", "anno approach": "wiki, concept, image", "verif wiki answer": "rv(0.7268)", "verif concept answer": "shelter(0.7085)", "verif image answer": "trailer(0.5925)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382044.jpg"}, {"question": "what are these on his face used for", "gt answer": "see(1.00)<br/>vision(0.60)", "pred answer": "beard", "question_id": 923405, "best approach": "", "verif answer": "read", "anno approach": "wiki, concept, image", "verif wiki answer": "read(0.6318)", "verif concept answer": "read(0.6139)", "verif image answer": "communication(0.5284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092340.jpg"}, {"question": "how does one go about making one of these", "gt answer": "oven(1.00)<br/>dough(0.60)", "pred answer": "bake", "question_id": 4213465, "best approach": "wiki", "verif answer": "oven", "anno approach": "wiki, concept, image", "verif wiki answer": "oven(0.7144)", "verif concept answer": "dough(0.6762)", "verif image answer": "dough(0.6984)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421346.jpg"}, {"question": "which manchester united player wears the same number as the person jumping", "gt answer": "paul pogba(1.00)<br/>goalie(0.60)", "pred answer": "left", "question_id": 2487455, "best approach": "wiki, concept, image", "verif answer": "frisbee", "anno approach": "wiki, concept, image", "verif wiki answer": "goalie(0.7308)", "verif concept answer": "goalie(0.7298)", "verif image answer": "goalie(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248745.jpg"}, {"question": "which old fashioned song speaks of one of these built for two", "gt answer": "bicycle built for 2(1.00)<br/>classic(0.60)<br/>country(0.60)", "pred answer": "rock", "question_id": 1719665, "best approach": "concept", "verif answer": "classic", "anno approach": "wiki, concept, image", "verif wiki answer": "deep dish(0.6323)", "verif concept answer": "country(0.6678)", "verif image answer": "deep dish(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171966.jpg"}, {"question": "why is there two key boards", "gt answer": "1 for letters 1 for numbers(1.00)", "pred answer": "music", "question_id": 3900735, "best approach": "wiki, concept", "verif answer": "1 for letters 1 for numbers", "anno approach": "wiki, concept, image", "verif wiki answer": "1 for letters 1 for numbers(0.6300)", "verif concept answer": "1 for letters 1 for numbers(0.6133)", "verif image answer": "slow(0.5116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390073.jpg"}, {"question": "what is the meaning of the symbols seen on the back of this truck", "gt answer": "caution(1.00)<br/>slow(0.60)<br/>brake(0.60)", "pred answer": "direct", "question_id": 4005935, "best approach": "concept", "verif answer": "brake", "anno approach": "wiki, concept, image", "verif wiki answer": "pedestrian cross(0.5219)", "verif concept answer": "brake(0.6062)", "verif image answer": "slow down(0.5229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400593.jpg"}, {"question": "what is the purpose of the wooden sticks in the photo", "gt answer": "hold sandwich together(1.00)", "pred answer": "eat", "question_id": 4347535, "best approach": "wiki, concept", "verif answer": "eat", "anno approach": "wiki, concept, image", "verif wiki answer": "hold sandwich together(0.7218)", "verif concept answer": "hold sandwich together(0.7230)", "verif image answer": "never(0.7005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434753.jpg"}, {"question": "why would we suspect these two are posing rather than going about their normal routines", "gt answer": "camera(1.00)<br/>mirror(0.60)", "pred answer": "take picture", "question_id": 1680835, "best approach": "wiki, concept, image", "verif answer": "mirror", "anno approach": "wiki, concept, image", "verif wiki answer": "mirror(0.7211)", "verif concept answer": "mirror(0.6098)", "verif image answer": "mirror(0.5132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168083.jpg"}, {"question": "who is credited for inventing these electronic devices", "gt answer": "steve job(1.00)", "pred answer": "bill gate", "question_id": 1263895, "best approach": "", "verif answer": "bill gate", "anno approach": "wiki, concept, image", "verif wiki answer": "martin cooper(0.6959)", "verif concept answer": "martin cooper(0.6922)", "verif image answer": "martin cooper(0.6552)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126389.jpg"}, {"question": "what stage of life is this boy in", "gt answer": "toddler(1.00)<br/>early(0.60)", "pred answer": "1 year", "question_id": 2371375, "best approach": "", "verif answer": "early", "anno approach": "wiki, concept, image", "verif wiki answer": "baby(0.7029)", "verif concept answer": "kid(0.7080)", "verif image answer": "baby(0.6908)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237137.jpg"}, {"question": "what were those ceiling fan blades made to resemble", "gt answer": "propeller(1.00)<br/>chopper(0.60)", "pred answer": "star", "question_id": 4904005, "best approach": "wiki", "verif answer": "engine", "anno approach": "wiki, concept, image", "verif wiki answer": "propeller(0.6138)", "verif concept answer": "air(0.6296)", "verif image answer": "air(0.5337)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490400.jpg"}, {"question": "what breed of dog is this", "gt answer": "beagle(1.00)<br/>shepherd(0.60)", "pred answer": "collie", "question_id": 606785, "best approach": "", "verif answer": "collie", "anno approach": "wiki, concept, image", "verif wiki answer": "collie(0.7205)", "verif concept answer": "corgi(0.7079)", "verif image answer": "corgi(0.6939)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060678.jpg"}, {"question": "", "gt answer": "stopped(0.60)<br/>stop(0.60)<br/>flash(0.60)", "pred answer": "night", "question_id": 4253815, "best approach": "wiki, concept, image", "verif answer": "stopped", "anno approach": "wiki, concept, image", "verif wiki answer": "flash(0.5484)", "verif concept answer": "flash(0.5394)", "verif image answer": "flash(0.5247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425381.jpg"}, {"question": "what type of planes are those", "gt answer": "biplane(1.00)<br/>military(0.60)<br/>prop(0.60)", "pred answer": "jet", "question_id": 4657015, "best approach": "wiki, concept, image", "verif answer": "biplane", "anno approach": "wiki, concept, image", "verif wiki answer": "biplane(0.7196)", "verif concept answer": "biplane(0.6703)", "verif image answer": "biplane(0.6826)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465701.jpg"}, {"question": "what emotions is this man displaying", "gt answer": "hunger(1.00)<br/>sad(0.60)", "pred answer": "happiness", "question_id": 5103855, "best approach": "concept", "verif answer": "happiness", "anno approach": "wiki, concept, image", "verif wiki answer": "happiness(0.7250)", "verif concept answer": "sad(0.7075)", "verif image answer": "sleepy(0.6907)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510385.jpg"}, {"question": "from what outdoor area of a house would you gather these", "gt answer": "garden(1.00)", "pred answer": "live", "question_id": 4505845, "best approach": "", "verif answer": "garden", "anno approach": "wiki, concept, image", "verif wiki answer": "outside(0.6981)", "verif concept answer": "table(0.6432)", "verif image answer": "ground(0.6645)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450584.jpg"}, {"question": "what are these sometimes filled with", "gt answer": "jelly(1.00)", "pred answer": "sugar", "question_id": 5428095, "best approach": "concept", "verif answer": "chocolate", "anno approach": "wiki, concept, image", "verif wiki answer": "cream(0.7164)", "verif concept answer": "jelly(0.6783)", "verif image answer": "cream(0.5735)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542809.jpg"}, {"question": "what substance are these items sitting on", "gt answer": "pavement(1.00)<br/>concrete(0.60)<br/>tarmac(0.60)", "pred answer": "runway", "question_id": 4860025, "best approach": "image", "verif answer": "runway", "anno approach": "wiki, concept, image", "verif wiki answer": "sidewalk(0.7205)", "verif concept answer": "sidewalk(0.7248)", "verif image answer": "tarmac(0.7161)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000486002.jpg"}, {"question": "who invented the first one of these", "gt answer": "mesopotamia(1.00)<br/>columbus(0.60)<br/>egypt(0.60)", "pred answer": "samuel fox", "question_id": 2953215, "best approach": "wiki", "verif answer": "ben franklin", "anno approach": "wiki, concept, image", "verif wiki answer": "egypt(0.6358)", "verif concept answer": "ben franklin(0.7256)", "verif image answer": "ben franklin(0.6901)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295321.jpg"}, {"question": "is this a snack or meal", "gt answer": "meal(1.00)", "pred answer": "snack", "question_id": 3480105, "best approach": "wiki, concept", "verif answer": "snack", "anno approach": "wiki, concept, image", "verif wiki answer": "meal(0.6493)", "verif concept answer": "meal(0.7178)", "verif image answer": "snack(0.7059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348010.jpg"}, {"question": "which breed of cat is this", "gt answer": "calico(1.00)<br/>striped(0.60)", "pred answer": "domestic", "question_id": 5215695, "best approach": "wiki, concept", "verif answer": "calico", "anno approach": "wiki, concept, image", "verif wiki answer": "calico(0.6998)", "verif concept answer": "calico(0.6935)", "verif image answer": "stripe(0.6900)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521569.jpg"}, {"question": "can you guess the type of glass used for the vehicle mirror shown in this picture", "gt answer": "reflective(1.00)<br/>mirrored(0.60)<br/>tempered(0.60)", "pred answer": "red", "question_id": 1720595, "best approach": "wiki, concept, image", "verif answer": "mirrored", "anno approach": "wiki, concept, image", "verif wiki answer": "mirrored(0.7177)", "verif concept answer": "mirrored(0.7174)", "verif image answer": "mirrored(0.6829)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000172059.jpg"}, {"question": "what do the protesters intend to gain from the boycott", "gt answer": "equal right(1.00)<br/>peace(1.00)", "pred answer": "0", "question_id": 3557375, "best approach": "wiki, concept", "verif answer": "hat over heart", "anno approach": "wiki, concept, image", "verif wiki answer": "peace(0.5360)", "verif concept answer": "peace(0.5967)", "verif image answer": "san francisco(0.6759)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355737.jpg"}, {"question": "where could this be found", "gt answer": "grocery store(1.00)<br/>supermarket(0.60)<br/>store(0.60)<br/>farmer market(0.60)", "pred answer": "produce", "question_id": 2551815, "best approach": "wiki, concept", "verif answer": "supermarket", "anno approach": "wiki, concept, image", "verif wiki answer": "grocery store(0.6894)", "verif concept answer": "grocery store(0.6816)", "verif image answer": "walmart(0.7123)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255181.jpg"}, {"question": "what type of trees grow on those hills", "gt answer": "pine tree(1.00)<br/>oak(1.00)", "pred answer": "pine", "question_id": 5683915, "best approach": "wiki, concept", "verif answer": "pine", "anno approach": "wiki, concept, image", "verif wiki answer": "pine tree(0.7208)", "verif concept answer": "pine tree(0.6797)", "verif image answer": "pine(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568391.jpg"}, {"question": "who is the celebrity in the wall art pictured here", "gt answer": "bob marley(1.00)", "pred answer": "barack obama", "question_id": 1163265, "best approach": "wiki, concept, image", "verif answer": "van gogh", "anno approach": "wiki, concept, image", "verif wiki answer": "bob marley(0.7246)", "verif concept answer": "bob marley(0.7295)", "verif image answer": "bob marley(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116326.jpg"}, {"question": "what material is the hat made of", "gt answer": "fur(1.00)<br/>wool(0.60)", "pred answer": "yarn", "question_id": 2372735, "best approach": "wiki, concept, image", "verif answer": "wool", "anno approach": "wiki, concept, image", "verif wiki answer": "fur(0.6091)", "verif concept answer": "fur(0.6905)", "verif image answer": "fur(0.7167)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237273.jpg"}, {"question": "what message is being portrayed here", "gt answer": "end destruction(1.00)<br/>construction(0.60)", "pred answer": "1 way", "question_id": 947925, "best approach": "", "verif answer": "graffiti", "anno approach": "wiki, concept, image", "verif wiki answer": "chicago(0.5589)", "verif concept answer": "chicago(0.5701)", "verif image answer": "graffiti(0.7091)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094792.jpg"}, {"question": "what item is showcased in this photo", "gt answer": "stuffed animal(1.00)<br/>bear(0.60)", "pred answer": "teddy bear", "question_id": 1683165, "best approach": "wiki", "verif answer": "doll", "anno approach": "wiki, concept, image", "verif wiki answer": "stuffed animal(0.6167)", "verif concept answer": "teddy bear(0.6675)", "verif image answer": "doll(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168316.jpg"}, {"question": "other than rain what else might people use these for", "gt answer": "sun protection(1.00)<br/>sun(0.60)", "pred answer": "rain", "question_id": 1665255, "best approach": "wiki, concept, image", "verif answer": "shade", "anno approach": "wiki, concept, image", "verif wiki answer": "sun protection(0.7238)", "verif concept answer": "sun protection(0.6210)", "verif image answer": "sun protection(0.7173)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166525.jpg"}, {"question": "what is the fastest one of these have ever been thrown", "gt answer": "105(1.00)<br/>60 mph(0.60)", "pred answer": "1880", "question_id": 863785, "best approach": "wiki", "verif answer": "ty cobb", "anno approach": "wiki, concept, image", "verif wiki answer": "105(0.5683)", "verif concept answer": "ty cobb(0.6544)", "verif image answer": "60 mph(0.6828)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086378.jpg"}, {"question": "what does the text on the mirror say", "gt answer": "object in mirror are closer than they appear(1.00)<br/>object are closer than they appear(0.60)", "pred answer": "speed limit", "question_id": 1081565, "best approach": "wiki, concept, image", "verif answer": "object are closer than they appear", "anno approach": "wiki, concept, image", "verif wiki answer": "object in mirror are closer than they appear(0.7280)", "verif concept answer": "object in mirror are closer than they appear(0.7246)", "verif image answer": "object in mirror are closer than they appear(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108156.jpg"}, {"question": "why is this person leaning", "gt answer": "turn(1.00)<br/>to turn(0.60)<br/>ride(0.60)", "pred answer": "accident", "question_id": 3022365, "best approach": "wiki, concept, image", "verif answer": "to turn", "anno approach": "wiki, concept, image", "verif wiki answer": "ride(0.7250)", "verif concept answer": "to turn(0.6551)", "verif image answer": "ride(0.6881)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302236.jpg"}, {"question": "what type of refrigerator is this", "gt answer": "play(1.00)<br/>toy(1.00)", "pred answer": "convection", "question_id": 713475, "best approach": "image", "verif answer": "thrown", "anno approach": "wiki, concept, image", "verif wiki answer": "children(0.6280)", "verif concept answer": "children(0.6172)", "verif image answer": "toy(0.6994)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071347.jpg"}, {"question": "what button is used to delete text", "gt answer": "delete(1.00)<br/>backspace(0.60)", "pred answer": "right", "question_id": 2246705, "best approach": "concept", "verif answer": "window", "anno approach": "wiki, concept, image", "verif wiki answer": "backspace(0.6304)", "verif concept answer": "delete(0.6302)", "verif image answer": "american idol(0.6681)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224670.jpg"}, {"question": "what type of skis is this man using", "gt answer": "downhill(1.00)<br/>snow(0.60)<br/>short(0.60)", "pred answer": "ski", "question_id": 1909925, "best approach": "concept", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "ski(0.7080)", "verif concept answer": "downhill(0.7022)", "verif image answer": "ski(0.6975)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190992.jpg"}, {"question": "where is this located", "gt answer": "spain(1.00)<br/>rome(0.60)<br/>italy(0.60)<br/>europe(0.60)", "pred answer": "washington dc", "question_id": 4402915, "best approach": "wiki", "verif answer": "italy", "anno approach": "wiki, concept, image", "verif wiki answer": "spain(0.7073)", "verif concept answer": "mexico(0.7198)", "verif image answer": "mexico(0.6690)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440291.jpg"}, {"question": "what expression is on the lady in the blue tank top 's face", "gt answer": "smile(1.00)<br/>happy(0.60)", "pred answer": "joy", "question_id": 4774425, "best approach": "wiki, concept", "verif answer": "joy", "anno approach": "wiki, concept, image", "verif wiki answer": "smile(0.6270)", "verif concept answer": "smile(0.6938)", "verif image answer": "happy(0.6838)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477442.jpg"}, {"question": "what monument is that", "gt answer": "washington(1.00)", "pred answer": "big ben", "question_id": 3341035, "best approach": "concept", "verif answer": "washington dc", "anno approach": "wiki, concept, image", "verif wiki answer": "george washington(0.7088)", "verif concept answer": "washington(0.6942)", "verif image answer": "washington dc(0.6973)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334103.jpg"}, {"question": "why do they keep animals within the mesh boundary", "gt answer": "safety(1.00)<br/>zoo(1.00)<br/>protection(0.60)", "pred answer": "pet", "question_id": 5041875, "best approach": "wiki, concept", "verif answer": "safety", "anno approach": "wiki, concept, image", "verif wiki answer": "zoo(0.6483)", "verif concept answer": "zoo(0.6141)", "verif image answer": "protection(0.7245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000504187.jpg"}, {"question": "what is this receptacle generally called", "gt answer": "mug(1.00)<br/>cup(0.60)", "pred answer": "coffee", "question_id": 5458495, "best approach": "", "verif answer": "cup", "anno approach": "wiki, concept, image", "verif wiki answer": "upper right(0.5302)", "verif concept answer": "spoon(0.7074)", "verif image answer": "spoon(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545849.jpg"}, {"question": "what 's the size of the tv", "gt answer": "50 inch(1.00)<br/>52(0.60)", "pred answer": "large", "question_id": 5192345, "best approach": "wiki, concept, image", "verif answer": "500", "anno approach": "wiki, concept, image", "verif wiki answer": "50 inch(0.7210)", "verif concept answer": "50 inch(0.7288)", "verif image answer": "50 inch(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000519234.jpg"}, {"question": "how do you attach this kind of tie", "gt answer": "clip(1.00)", "pred answer": "bow", "question_id": 5309015, "best approach": "wiki", "verif answer": "string", "anno approach": "wiki, concept, image", "verif wiki answer": "clip(0.6270)", "verif concept answer": "string(0.6325)", "verif image answer": "string(0.5973)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000530901.jpg"}, {"question": "what happens next", "gt answer": "he land(1.00)<br/>land(1.00)", "pred answer": "jump", "question_id": 534745, "best approach": "wiki, concept, image", "verif answer": "jump", "anno approach": "wiki, concept, image", "verif wiki answer": "land(0.6868)", "verif concept answer": "land(0.6847)", "verif image answer": "land(0.7211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053474.jpg"}, {"question": "which bicycle seeking nerd of the movie with his name has the same name as the term often associated with this level of a sport", "gt answer": "little league(1.00)<br/>bear(0.60)", "pred answer": "giant", "question_id": 3289785, "best approach": "wiki, concept, image", "verif answer": "little league", "anno approach": "wiki, concept, image", "verif wiki answer": "little league(0.7267)", "verif concept answer": "little league(0.7132)", "verif image answer": "little league(0.6982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328978.jpg"}, {"question": "what causes the sking pigment of the girl in the blue shirt to be so dark", "gt answer": "melanin(1.00)<br/>sun(0.60)", "pred answer": "light", "question_id": 5320625, "best approach": "wiki, concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "melanin(0.7209)", "verif concept answer": "melanin(0.6641)", "verif image answer": "yellow(0.7199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532062.jpg"}, {"question": "this sport is called who 's passtime", "gt answer": "americas(1.00)", "pred answer": "homerun", "question_id": 3039925, "best approach": "", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "home run(0.5799)", "verif concept answer": "baseball(0.6887)", "verif image answer": "baseball(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303992.jpg"}, {"question": "how much protein is in the food the man is holding in his left hand", "gt answer": "20 grams(1.00)", "pred answer": "200", "question_id": 4601645, "best approach": "concept", "verif answer": "lot", "anno approach": "wiki, concept, image", "verif wiki answer": "grilled(0.6474)", "verif concept answer": "20 grams(0.6680)", "verif image answer": "40(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460164.jpg"}, {"question": "what is the most unhealthy food on the plate", "gt answer": "bread(1.00)", "pred answer": "vegetable", "question_id": 4318085, "best approach": "wiki, concept", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "bread(0.6041)", "verif concept answer": "bread(0.7011)", "verif image answer": "cake(0.7169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431808.jpg"}, {"question": "what does the animal eat", "gt answer": "dog food(1.00)<br/>food(0.60)", "pred answer": "meat", "question_id": 1415575, "best approach": "wiki, concept, image", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "dog food(0.7263)", "verif concept answer": "dog food(0.7170)", "verif image answer": "dog food(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000141557.jpg"}, {"question": "how is this meal made", "gt answer": "grilled(1.00)<br/>bake(0.60)", "pred answer": "fried", "question_id": 1055945, "best approach": "wiki, concept, image", "verif answer": "grilled", "anno approach": "wiki, concept, image", "verif wiki answer": "grilled(0.7210)", "verif concept answer": "grilled(0.7187)", "verif image answer": "grilled(0.7001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105594.jpg"}, {"question": "is this plane sitting still or flying", "gt answer": "sit still(1.00)<br/>fly(0.60)", "pred answer": "land", "question_id": 4213145, "best approach": "wiki, concept, image", "verif answer": "sit", "anno approach": "wiki, concept, image", "verif wiki answer": "sit still(0.7179)", "verif concept answer": "sit still(0.7285)", "verif image answer": "sit still(0.6831)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421314.jpg"}, {"question": "what month did the beautiful snowfall ocurr", "gt answer": "december(1.00)", "pred answer": "winter", "question_id": 4997885, "best approach": "wiki, image", "verif answer": "december", "anno approach": "wiki, concept, image", "verif wiki answer": "december(0.7303)", "verif concept answer": "summer(0.7170)", "verif image answer": "december(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499788.jpg"}, {"question": "where did they get this pizza", "gt answer": "domino(1.00)", "pred answer": "restaurant", "question_id": 3271685, "best approach": "", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "restaurant(0.7297)", "verif concept answer": "oven(0.7177)", "verif image answer": "oven(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327168.jpg"}, {"question": "what is the roof of that house made of", "gt answer": "shingle(1.00)<br/>spray(0.60)", "pred answer": "wood", "question_id": 443415, "best approach": "wiki, concept, image", "verif answer": "white", "anno approach": "wiki, concept, image", "verif wiki answer": "shingle(0.7265)", "verif concept answer": "shingle(0.7152)", "verif image answer": "shingle(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000044341.jpg"}, {"question": "what do most of the objects in the tray most closely resemble", "gt answer": "doughnut(1.00)<br/>donuts(1.00)", "pred answer": "brain", "question_id": 4246655, "best approach": "concept", "verif answer": "doughnut", "anno approach": "wiki, concept, image", "verif wiki answer": "donut(0.6148)", "verif concept answer": "doughnut(0.6927)", "verif image answer": "coffee and donuts(0.6689)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424665.jpg"}, {"question": "what sport activity is the man in the image doing", "gt answer": "ice fish(1.00)<br/>sled(0.60)<br/>snowboarder(0.60)<br/>snowboard(0.60)", "pred answer": "ski", "question_id": 4235025, "best approach": "concept, image", "verif answer": "sled", "anno approach": "wiki, concept, image", "verif wiki answer": "surf(0.6234)", "verif concept answer": "snowboard(0.6317)", "verif image answer": "snowboard(0.7036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000423502.jpg"}, {"question": "what is this type of airplane called", "gt answer": "seaplane(1.00)<br/>pontoon(0.60)<br/>water(0.60)", "pred answer": "biplane", "question_id": 5545565, "best approach": "wiki", "verif answer": "prop", "anno approach": "wiki, concept, image", "verif wiki answer": "seaplane(0.7132)", "verif concept answer": "water(0.6140)", "verif image answer": "water(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554556.jpg"}, {"question": "how many people are seriously injured from this activity a year", "gt answer": "1000(1.00)<br/>thousand(0.60)<br/>200(0.60)", "pred answer": "0", "question_id": 242425, "best approach": "wiki", "verif answer": "100", "anno approach": "wiki, concept, image", "verif wiki answer": "1000(0.7186)", "verif concept answer": "200(0.6611)", "verif image answer": "10000(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024242.jpg"}, {"question": "mcdonald who", "gt answer": "ronald(1.00)", "pred answer": "girl", "question_id": 2861715, "best approach": "wiki, concept, image", "verif answer": "child", "anno approach": "wiki, concept, image", "verif wiki answer": "ronald(0.6299)", "verif concept answer": "ronald(0.6958)", "verif image answer": "ronald(0.6907)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000286171.jpg"}, {"question": "what is the model name of this vehicle", "gt answer": "bus(1.00)<br/>volkswagon(0.60)<br/>ford(0.60)", "pred answer": "jeep", "question_id": 5106175, "best approach": "wiki, image", "verif answer": "volkswagon", "anno approach": "wiki, concept, image", "verif wiki answer": "volkswagon(0.7255)", "verif concept answer": "cdl(0.7123)", "verif image answer": "ford(0.6885)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510617.jpg"}, {"question": "what type of building is this likely to be situated in", "gt answer": "apartment(1.00)", "pred answer": "house", "question_id": 2044075, "best approach": "wiki, concept, image", "verif answer": "apartment", "anno approach": "wiki, concept, image", "verif wiki answer": "apartment(0.7071)", "verif concept answer": "apartment(0.6519)", "verif image answer": "apartment(0.6997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000204407.jpg"}, {"question": "what does this foodstuff have a high level of", "gt answer": "calories(1.00)<br/>sugar(0.60)", "pred answer": "saturated", "question_id": 1455265, "best approach": "wiki, concept", "verif answer": "sugar", "anno approach": "wiki, concept, image", "verif wiki answer": "calories(0.7145)", "verif concept answer": "calories(0.6086)", "verif image answer": "sugar(0.6888)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145526.jpg"}, {"question": "who created the first digital one of these", "gt answer": "protzmann(1.00)<br/>factory(0.60)", "pred answer": "steve job", "question_id": 5230355, "best approach": "wiki, concept, image", "verif answer": "yamaha", "anno approach": "wiki, concept, image", "verif wiki answer": "protzmann(0.6442)", "verif concept answer": "protzmann(0.6995)", "verif image answer": "protzmann(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523035.jpg"}, {"question": "how many chromosomes do these creatures have", "gt answer": "23(1.00)<br/>46(1.00)", "pred answer": "3", "question_id": 4546365, "best approach": "wiki", "verif answer": "12", "anno approach": "wiki, concept, image", "verif wiki answer": "46(0.7015)", "verif concept answer": "million(0.6790)", "verif image answer": "million(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000454636.jpg"}, {"question": "what type of plane is this", "gt answer": "fighter(1.00)<br/>jet(0.60)<br/>military(0.60)", "pred answer": "fighter jet", "question_id": 1933905, "best approach": "wiki, concept, image", "verif answer": "fighter jet", "anno approach": "wiki, concept, image", "verif wiki answer": "fighter(0.7279)", "verif concept answer": "fighter(0.7134)", "verif image answer": "fighter(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193390.jpg"}, {"question": "name the lighting model used in this picture", "gt answer": "spot light(1.00)<br/>lamp(0.60)", "pred answer": "fluorescent", "question_id": 1899435, "best approach": "wiki, concept", "verif answer": "flash", "anno approach": "wiki, concept, image", "verif wiki answer": "spot light(0.5635)", "verif concept answer": "spot light(0.6093)", "verif image answer": "flash(0.6682)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000189943.jpg"}, {"question": "what type of bar is located on this desk behind the computer", "gt answer": "sound(1.00)<br/>snack(0.60)", "pred answer": "office", "question_id": 1636925, "best approach": "wiki", "verif answer": "lunch", "anno approach": "wiki, concept, image", "verif wiki answer": "snack(0.6055)", "verif concept answer": "meal(0.6400)", "verif image answer": "lunch(0.7194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163692.jpg"}, {"question": "what are the young of this animal called", "gt answer": "duckling(1.00)<br/>duck(0.60)", "pred answer": "female", "question_id": 8135, "best approach": "wiki, concept", "verif answer": "duck", "anno approach": "wiki, concept, image", "verif wiki answer": "duck(0.6505)", "verif concept answer": "duck(0.6374)", "verif image answer": "goose(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000813.jpg"}, {"question": "which type of leather is used for making the overcoat weared by the lady in the photo", "gt answer": "faux(1.00)", "pred answer": "leather", "question_id": 1182785, "best approach": "", "verif answer": "leather", "anno approach": "wiki, concept, image", "verif wiki answer": "leather(0.6943)", "verif concept answer": "poodle(0.7201)", "verif image answer": "poodle(0.7230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118278.jpg"}, {"question": "what is this older woman holding that has wheels", "gt answer": "walker(1.00)", "pred answer": "carriage", "question_id": 1142885, "best approach": "image", "verif answer": "carriage", "anno approach": "wiki, concept, image", "verif wiki answer": "luggage(0.7076)", "verif concept answer": "luggage(0.5394)", "verif image answer": "walker(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114288.jpg"}, {"question": "what example of good exercise is displayed in this image", "gt answer": "walk(1.00)", "pred answer": "arm", "question_id": 5351645, "best approach": "wiki, concept", "verif answer": "walk", "anno approach": "wiki, concept, image", "verif wiki answer": "walk(0.6836)", "verif concept answer": "walk(0.6352)", "verif image answer": "sell(0.6145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535164.jpg"}, {"question": "why would it be pointless to offer these animals red meat", "gt answer": "plant eater(1.00)<br/>herbivore(0.60)", "pred answer": "wild", "question_id": 4311945, "best approach": "wiki, concept, image", "verif answer": "herbivore", "anno approach": "wiki, concept, image", "verif wiki answer": "herbivore(0.7176)", "verif concept answer": "herbivore(0.6971)", "verif image answer": "herbivore(0.5869)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431194.jpg"}, {"question": "when might someone do this to another person", "gt answer": "smuggle(1.00)", "pred answer": "night", "question_id": 876425, "best approach": "wiki, concept", "verif answer": "valentine's day", "anno approach": "wiki, concept, image", "verif wiki answer": "smuggle(0.7039)", "verif concept answer": "smuggle(0.5861)", "verif image answer": "valentine's day(0.5314)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087642.jpg"}, {"question": "what movie would this image relate to", "gt answer": "ted(1.00)<br/>teddy bear(0.60)<br/>halloween(0.60)", "pred answer": "forrest gump", "question_id": 2169635, "best approach": "wiki, concept, image", "verif answer": "halloween", "anno approach": "wiki, concept, image", "verif wiki answer": "teddy bear(0.5179)", "verif concept answer": "halloween(0.5991)", "verif image answer": "halloween(0.7194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216963.jpg"}, {"question": "how many people attend this sporting event anually", "gt answer": "million(1.00)<br/>thousand(0.60)<br/>6(0.60)", "pred answer": "9", "question_id": 4306175, "best approach": "wiki, concept", "verif answer": "9", "anno approach": "wiki, concept, image", "verif wiki answer": "million(0.6970)", "verif concept answer": "million(0.6553)", "verif image answer": "6(0.7218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430617.jpg"}, {"question": "who is riding this vehicle", "gt answer": "policeman(1.00)<br/>police officer(1.00)", "pred answer": "man", "question_id": 4556145, "best approach": "concept, image", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "man(0.7191)", "verif concept answer": "police officer(0.6560)", "verif image answer": "police officer(0.7172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455614.jpg"}, {"question": "who is the designer of the jacket worn by the man sitting in the middle of the bench", "gt answer": "armani(1.00)<br/>brook brother(0.60)", "pred answer": "columbia", "question_id": 3751295, "best approach": "wiki", "verif answer": "levi", "anno approach": "wiki, concept, image", "verif wiki answer": "armani(0.7283)", "verif concept answer": "hell angel(0.6871)", "verif image answer": "brook brother(0.7180)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375129.jpg"}, {"question": "can you tell me in which area this variety of cows are seen", "gt answer": "midwest(1.00)", "pred answer": "pasture", "question_id": 3419635, "best approach": "image", "verif answer": "midwest", "anno approach": "wiki, concept, image", "verif wiki answer": "farmer(0.6893)", "verif concept answer": "south(0.6235)", "verif image answer": "midwest(0.7041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341963.jpg"}, {"question": "what type of jewelry did the woman in the photo likely acquire very recently", "gt answer": "ring(1.00)", "pred answer": "earring", "question_id": 5081305, "best approach": "", "verif answer": "0", "anno approach": "wiki, concept, image", "verif wiki answer": "wrench(0.6227)", "verif concept answer": "rodeo(0.6717)", "verif image answer": "0(0.6561)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000508130.jpg"}, {"question": "what department store in chicago has a clock on the outside like the one in the photo", "gt answer": "marshall field(1.00)", "pred answer": "home depot", "question_id": 5288005, "best approach": "", "verif answer": "illegal", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.5550)", "verif concept answer": "london(0.5841)", "verif image answer": "london(0.6243)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528800.jpg"}, {"question": "is this an official or unofficial sporting event", "gt answer": "official(1.00)", "pred answer": "professional", "question_id": 1648425, "best approach": "wiki, concept, image", "verif answer": "manmade", "anno approach": "wiki, concept, image", "verif wiki answer": "official(0.7260)", "verif concept answer": "official(0.6861)", "verif image answer": "official(0.6549)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000164842.jpg"}, {"question": "how do we know this is not an owl", "gt answer": "too small(1.00)", "pred answer": "sign", "question_id": 2483605, "best approach": "wiki, concept, image", "verif answer": "too small", "anno approach": "wiki, concept, image", "verif wiki answer": "too small(0.7302)", "verif concept answer": "too small(0.7303)", "verif image answer": "too small(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248360.jpg"}, {"question": "what city of this", "gt answer": "charlottesville(1.00)", "pred answer": "tarana", "question_id": 3032875, "best approach": "", "verif answer": "tarana", "anno approach": "wiki, concept, image", "verif wiki answer": "london(0.7047)", "verif concept answer": "london(0.6774)", "verif image answer": "texas(0.7075)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303287.jpg"}, {"question": "what is the most likely relationship of these people", "gt answer": "sister(1.00)<br/>sibling(0.60)", "pred answer": "mother and child", "question_id": 1140345, "best approach": "", "verif answer": "mother and son", "anno approach": "wiki, concept, image", "verif wiki answer": "mother and son(0.7172)", "verif concept answer": "mother and son(0.7232)", "verif image answer": "mother and son(0.6606)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114034.jpg"}, {"question": "what department maintains and uses this", "gt answer": "fire department(1.00)<br/>fire(1.00)", "pred answer": "firefighter", "question_id": 5466205, "best approach": "wiki, concept, image", "verif answer": "firefight", "anno approach": "wiki, concept, image", "verif wiki answer": "fire department(0.7272)", "verif concept answer": "fire department(0.7289)", "verif image answer": "fire department(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546620.jpg"}, {"question": "what kind of book is she looking at", "gt answer": "yearbook(1.00)<br/>tv(0.60)", "pred answer": "fairytale", "question_id": 3438605, "best approach": "concept", "verif answer": "picture", "anno approach": "wiki, concept, image", "verif wiki answer": "picture(0.6828)", "verif concept answer": "yearbook(0.6620)", "verif image answer": "picture(0.5030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343860.jpg"}, {"question": "what appliance is this a picture of", "gt answer": "toaster(1.00)", "pred answer": "toilet", "question_id": 2913215, "best approach": "", "verif answer": "fridge", "anno approach": "wiki, concept, image", "verif wiki answer": "grill(0.5932)", "verif concept answer": "grill(0.7073)", "verif image answer": "grill(0.6575)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291321.jpg"}, {"question": "what is the gestation period of this animal", "gt answer": "152 days(1.00)<br/>2 months(0.60)<br/>sheep(0.60)<br/>3 months(0.60)", "pred answer": "15 years", "question_id": 4021915, "best approach": "image", "verif answer": "152 days", "anno approach": "wiki, concept, image", "verif wiki answer": "8 months(0.6746)", "verif concept answer": "sheep(0.6436)", "verif image answer": "152 days(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402191.jpg"}, {"question": "what is the name of the utensil", "gt answer": "pizza cutter(1.00)", "pred answer": "fork", "question_id": 935805, "best approach": "", "verif answer": "tong", "anno approach": "wiki, concept, image", "verif wiki answer": "spoon(0.7203)", "verif concept answer": "spoon(0.7245)", "verif image answer": "tong(0.6949)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093580.jpg"}, {"question": "where is the book in the picture sold", "gt answer": "amazon(1.00)<br/>target(0.60)", "pred answer": "store", "question_id": 753225, "best approach": "wiki, concept", "verif answer": "store", "anno approach": "wiki, concept, image", "verif wiki answer": "amazon(0.7005)", "verif concept answer": "amazon(0.6602)", "verif image answer": "store(0.7122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075322.jpg"}, {"question": "what kind of boat is the big boat", "gt answer": "cruise ship(1.00)", "pred answer": "freight", "question_id": 4807975, "best approach": "concept, image", "verif answer": "cruise ship", "anno approach": "wiki, concept, image", "verif wiki answer": "ship(0.7166)", "verif concept answer": "cruise ship(0.6583)", "verif image answer": "cruise ship(0.7176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480797.jpg"}, {"question": "why does that sign say 'takeovr'", "gt answer": "protest(1.00)", "pred answer": "no u turn", "question_id": 4999155, "best approach": "concept", "verif answer": "direct", "anno approach": "wiki, concept, image", "verif wiki answer": "parade(0.6922)", "verif concept answer": "protest(0.6179)", "verif image answer": "direct(0.6213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499915.jpg"}, {"question": "what brand of shoes do these resemble", "gt answer": "converse(1.00)<br/>nike(0.60)<br/>van(0.60)", "pred answer": "dc", "question_id": 1053865, "best approach": "image", "verif answer": "adidas", "anno approach": "wiki, concept, image", "verif wiki answer": "adidas(0.7302)", "verif concept answer": "adidas(0.7275)", "verif image answer": "nike(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105386.jpg"}, {"question": "how can i find out where the closest public transportation stop is located to me", "gt answer": "internet(1.00)<br/>outside(0.60)", "pred answer": "intersection", "question_id": 3581895, "best approach": "", "verif answer": "outside", "anno approach": "wiki, concept, image", "verif wiki answer": "work(0.6809)", "verif concept answer": "work(0.5699)", "verif image answer": "work(0.7088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358189.jpg"}, {"question": "what will happen next", "gt answer": "land(1.00)<br/>fall(0.60)", "pred answer": "jump", "question_id": 2989495, "best approach": "", "verif answer": "fall", "anno approach": "wiki, concept, image", "verif wiki answer": "landed(0.7171)", "verif concept answer": "landed(0.6792)", "verif image answer": "he land(0.6854)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000298949.jpg"}, {"question": "what company made this truck", "gt answer": "chrysler(1.00)<br/>nissan(0.60)<br/>honda(0.60)", "pred answer": "ford", "question_id": 4988905, "best approach": "", "verif answer": "audi", "anno approach": "wiki, concept, image", "verif wiki answer": "van(0.7058)", "verif concept answer": "audi(0.7166)", "verif image answer": "audi(0.7218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000498890.jpg"}, {"question": "what type of flower is next to the bird", "gt answer": "dandelion(1.00)", "pred answer": "daisy", "question_id": 3708085, "best approach": "", "verif answer": "daffodil", "anno approach": "wiki, concept, image", "verif wiki answer": "daffodil(0.6996)", "verif concept answer": "sun(0.7148)", "verif image answer": "sun(0.7075)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370808.jpg"}, {"question": "what kind of cookies are these", "gt answer": "chocolate chip(1.00)<br/>banana(0.60)", "pred answer": "powdered", "question_id": 1162235, "best approach": "wiki", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "banana(0.6909)", "verif concept answer": "banana split(0.6595)", "verif image answer": "quarter(0.6800)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116223.jpg"}, {"question": "what is the breed of dog shown", "gt answer": "collie(1.00)<br/>shepherd(0.60)<br/>poodle(0.60)<br/>husky(0.60)", "pred answer": "beagle", "question_id": 2413885, "best approach": "wiki, image", "verif answer": "shepherd", "anno approach": "wiki, concept, image", "verif wiki answer": "poodle(0.6701)", "verif concept answer": "terrier(0.6877)", "verif image answer": "husky(0.6531)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241388.jpg"}, {"question": "who invented this electronic device", "gt answer": "alexander graham bell(1.00)<br/>bell(0.60)<br/>martin cooper(0.60)<br/>apple(0.60)", "pred answer": "steve job", "question_id": 3710905, "best approach": "wiki, concept, image", "verif answer": "bill gate", "anno approach": "wiki, concept, image", "verif wiki answer": "apple(0.6128)", "verif concept answer": "martin cooper(0.7257)", "verif image answer": "apple(0.6995)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371090.jpg"}, {"question": "what is the name of the vehicle", "gt answer": "jet ski(1.00)", "pred answer": "raft", "question_id": 642415, "best approach": "", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "boat(0.7198)", "verif concept answer": "water ski(0.6886)", "verif image answer": "yacht(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064241.jpg"}, {"question": "why the girl is dressed with a shirtless dress", "gt answer": "hot(1.00)<br/>summer(0.60)", "pred answer": "bikini", "question_id": 3142925, "best approach": "wiki, concept, image", "verif answer": "hot", "anno approach": "wiki, concept, image", "verif wiki answer": "hot(0.7289)", "verif concept answer": "hot(0.7266)", "verif image answer": "hot(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314292.jpg"}, {"question": "what industry would this be associated with", "gt answer": "farm(1.00)<br/>golf(0.60)<br/>ranch(0.60)", "pred answer": "transportation", "question_id": 2025005, "best approach": "wiki, concept", "verif answer": "farm", "anno approach": "wiki, concept, image", "verif wiki answer": "farm(0.6321)", "verif concept answer": "farm(0.6413)", "verif image answer": "golf(0.5474)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202500.jpg"}, {"question": "is this snow real or manmade", "gt answer": "manmade(1.00)<br/>both(0.60)<br/>real(0.60)", "pred answer": "man made", "question_id": 1437115, "best approach": "wiki, image", "verif answer": "manmade", "anno approach": "wiki, concept, image", "verif wiki answer": "manmade(0.7201)", "verif concept answer": "real(0.6745)", "verif image answer": "manmade(0.6850)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143711.jpg"}, {"question": "what would be the name of the object in the image if the president of the united states owned it", "gt answer": "air force 1(1.00)", "pred answer": "airplane", "question_id": 2359595, "best approach": "image", "verif answer": "private jet", "anno approach": "wiki, concept, image", "verif wiki answer": "private jet(0.7141)", "verif concept answer": "private jet(0.7047)", "verif image answer": "air force 1(0.7143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000235959.jpg"}, {"question": "are these major or minor league players", "gt answer": "minor(1.00)<br/>major(0.60)", "pred answer": "professional", "question_id": 4714705, "best approach": "", "verif answer": "professional", "anno approach": "wiki, concept, image", "verif wiki answer": "professional(0.6730)", "verif concept answer": "professional(0.6750)", "verif image answer": "professional(0.5887)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471470.jpg"}, {"question": "", "gt answer": "brownie(0.60)<br/>sweet(0.60)<br/>chocolate(0.60)", "pred answer": "cupcake", "question_id": 4759995, "best approach": "wiki, concept, image", "verif answer": "brownie", "anno approach": "wiki, concept, image", "verif wiki answer": "brownie(0.5900)", "verif concept answer": "brownie(0.6338)", "verif image answer": "brownie(0.7079)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475999.jpg"}, {"question": "how fast does this goes", "gt answer": "500 mph(1.00)<br/>120 mph(0.60)", "pred answer": "100 mph", "question_id": 1079625, "best approach": "wiki", "verif answer": "100 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "120 mph(0.6268)", "verif concept answer": "564 mph(0.5586)", "verif image answer": "564 mph(0.5864)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000107962.jpg"}, {"question": "what is the top of the fireplace in this image called", "gt answer": "mantle(1.00)", "pred answer": "fan", "question_id": 3385415, "best approach": "wiki, image", "verif answer": "chandelier", "anno approach": "wiki, concept, image", "verif wiki answer": "mantle(0.7036)", "verif concept answer": "chandelier(0.7109)", "verif image answer": "mantle(0.6932)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338541.jpg"}, {"question": "what type of phone does this man have", "gt answer": "i phone(1.00)<br/>iphone(1.00)", "pred answer": "cell", "question_id": 2366265, "best approach": "wiki, concept, image", "verif answer": "i phone", "anno approach": "wiki, concept, image", "verif wiki answer": "i phone(0.7088)", "verif concept answer": "i phone(0.6308)", "verif image answer": "i phone(0.6612)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236626.jpg"}, {"question": "", "gt answer": "smoothies(0.60)<br/>lime(0.60)<br/>limade(0.60)", "pred answer": "lemonade", "question_id": 3134655, "best approach": "wiki, concept, image", "verif answer": "juice", "anno approach": "wiki, concept, image", "verif wiki answer": "lime(0.5497)", "verif concept answer": "lime(0.6074)", "verif image answer": "lime(0.6919)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313465.jpg"}, {"question": "what is this fixture used for", "gt answer": "bath(1.00)<br/>water(0.60)", "pred answer": "wash hand", "question_id": 682065, "best approach": "wiki", "verif answer": "bath", "anno approach": "wiki, concept, image", "verif wiki answer": "bath(0.6955)", "verif concept answer": "drink water(0.6672)", "verif image answer": "bathroom(0.7215)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068206.jpg"}, {"question": "what animals with claws do these animals like to eat", "gt answer": "crab(1.00)<br/>mice(0.60)", "pred answer": "bird", "question_id": 3889005, "best approach": "wiki, concept", "verif answer": "fish", "anno approach": "wiki, concept, image", "verif wiki answer": "crab(0.7258)", "verif concept answer": "crab(0.7260)", "verif image answer": "fish(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388900.jpg"}, {"question": "what type of cows are these", "gt answer": "dairy cow(1.00)<br/>jersey(0.60)", "pred answer": "dairy", "question_id": 2845365, "best approach": "", "verif answer": "dairy", "anno approach": "wiki, concept, image", "verif wiki answer": "dairy(0.7228)", "verif concept answer": "dairy(0.7083)", "verif image answer": "dairy(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284536.jpg"}, {"question": "what century was this furniture item popular", "gt answer": "20th(1.00)<br/>1950s(0.60)<br/>nineteenth(0.60)", "pred answer": "1970's", "question_id": 704415, "best approach": "image", "verif answer": "1950s", "anno approach": "wiki, concept, image", "verif wiki answer": "19th(0.6964)", "verif concept answer": "19th(0.5991)", "verif image answer": "1950s(0.6668)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070441.jpg"}, {"question": "which type of food is on the plate most forward", "gt answer": "pie(1.00)", "pred answer": "sandwich", "question_id": 3114085, "best approach": "", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "dessert(0.7152)", "verif concept answer": "apple pie(0.7201)", "verif image answer": "dessert(0.7211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311408.jpg"}, {"question": "what kind of couch are these people sitting on", "gt answer": "futon(1.00)", "pred answer": "sectional", "question_id": 865605, "best approach": "image", "verif answer": "loveseat", "anno approach": "wiki, concept, image", "verif wiki answer": "loveseat(0.7292)", "verif concept answer": "loveseat(0.7209)", "verif image answer": "futon(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086560.jpg"}, {"question": "what winged items might be up in the trees", "gt answer": "bird(1.00)<br/>kite(0.60)<br/>pigeon(0.60)", "pred answer": "eagle", "question_id": 270125, "best approach": "wiki, concept, image", "verif answer": "pigeon", "anno approach": "wiki, concept, image", "verif wiki answer": "pigeon(0.7268)", "verif concept answer": "kite(0.7120)", "verif image answer": "pigeon(0.6292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027012.jpg"}, {"question": "what is this style of architecture known as", "gt answer": "industrial(1.00)<br/>dilapidated(0.60)", "pred answer": "greek", "question_id": 2976075, "best approach": "", "verif answer": "1800's", "anno approach": "wiki, concept, image", "verif wiki answer": "convection(0.7160)", "verif concept answer": "mechanical(0.6912)", "verif image answer": "1800's(0.7086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297607.jpg"}, {"question": "what type of bird is being depicted on the bed", "gt answer": "swan(1.00)", "pred answer": "robin", "question_id": 3455575, "best approach": "concept", "verif answer": "peacock", "anno approach": "wiki, concept, image", "verif wiki answer": "stork(0.7209)", "verif concept answer": "swan(0.7086)", "verif image answer": "duck(0.6835)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345557.jpg"}, {"question": "what does this lot hold", "gt answer": "bus(1.00)<br/>people(0.60)", "pred answer": "car", "question_id": 4564165, "best approach": "wiki, image", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "people(0.7067)", "verif concept answer": "public transportation(0.6563)", "verif image answer": "people(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456416.jpg"}, {"question": "where is this restaurant located", "gt answer": "asia(1.00)<br/>china(1.00)", "pred answer": "city", "question_id": 5108595, "best approach": "", "verif answer": "chinese", "anno approach": "wiki, concept, image", "verif wiki answer": "us(0.5839)", "verif concept answer": "us(0.5752)", "verif image answer": "us(0.7131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510859.jpg"}, {"question": "what is the average life span of this living creature", "gt answer": "80(1.00)", "pred answer": "15 years", "question_id": 497195, "best approach": "", "verif answer": "30 years", "anno approach": "wiki, concept, image", "verif wiki answer": "200(0.7105)", "verif concept answer": "$50(0.6959)", "verif image answer": "30 years(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049719.jpg"}, {"question": "what are they drinking", "gt answer": "tea(1.00)<br/>coffee(0.60)", "pred answer": "wine", "question_id": 3554875, "best approach": "", "verif answer": "coffee", "anno approach": "wiki, concept, image", "verif wiki answer": "juice(0.7176)", "verif concept answer": "tea room(0.6896)", "verif image answer": "tea room(0.7071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355487.jpg"}, {"question": "what kind of bus is this", "gt answer": "city bus(1.00)<br/>urban(0.60)<br/>city(0.60)", "pred answer": "tour", "question_id": 3840275, "best approach": "wiki, concept, image", "verif answer": "greyhound", "anno approach": "wiki, concept, image", "verif wiki answer": "urban(0.6837)", "verif concept answer": "city(0.6732)", "verif image answer": "city(0.5354)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384027.jpg"}, {"question": "what could these elephants be involved in", "gt answer": "circus(1.00)<br/>parade(1.00)", "pred answer": "pet", "question_id": 3090815, "best approach": "wiki, concept", "verif answer": "race", "anno approach": "wiki, concept, image", "verif wiki answer": "circus(0.7158)", "verif concept answer": "circus(0.6791)", "verif image answer": "elephant(0.7109)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000309081.jpg"}, {"question": "what kind of plane is pictured", "gt answer": "cessna(1.00)<br/>boat(0.60)<br/>propeller(0.60)", "pred answer": "biplane", "question_id": 12325, "best approach": "", "verif answer": "biplane", "anno approach": "wiki, concept, image", "verif wiki answer": "biplane(0.7248)", "verif concept answer": "biplane(0.6456)", "verif image answer": "commercial(0.6742)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001232.jpg"}, {"question": "what war did the plane in this picture fly in", "gt answer": "world war 2(1.00)<br/>ww2(0.60)", "pred answer": "wwii", "question_id": 3721975, "best approach": "", "verif answer": "wwii", "anno approach": "wiki, concept, image", "verif wiki answer": "airforce(0.6989)", "verif concept answer": "wwii(0.6934)", "verif image answer": "airshow(0.6414)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372197.jpg"}, {"question": "are we united or divided", "gt answer": "united(1.00)", "pred answer": "disorganized", "question_id": 4511605, "best approach": "", "verif answer": "american", "anno approach": "wiki, concept, image", "verif wiki answer": "american(0.7142)", "verif concept answer": "american(0.6242)", "verif image answer": "take off(0.5650)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451160.jpg"}, {"question": "who is the all time hits leader in this sport", "gt answer": "pete rose(1.00)<br/>babe ruth(0.60)", "pred answer": "jackie robinson", "question_id": 3471335, "best approach": "wiki, concept, image", "verif answer": "babe ruth", "anno approach": "wiki, concept, image", "verif wiki answer": "babe ruth(0.6988)", "verif concept answer": "babe ruth(0.5449)", "verif image answer": "babe ruth(0.6001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347133.jpg"}, {"question": "what country was this piucture taken in", "gt answer": "cuba(1.00)", "pred answer": "england", "question_id": 453435, "best approach": "image", "verif answer": "england", "anno approach": "wiki, concept, image", "verif wiki answer": "england(0.7058)", "verif concept answer": "puerto rico(0.6871)", "verif image answer": "cuba(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045343.jpg"}, {"question": "why are these animals kept on farms", "gt answer": "wool(1.00)", "pred answer": "farm", "question_id": 4033515, "best approach": "", "verif answer": "wool", "anno approach": "wiki, concept, image", "verif wiki answer": "baa(0.6214)", "verif concept answer": "baa(0.7193)", "verif image answer": "cotton(0.6699)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403351.jpg"}, {"question": "what are these students learning", "gt answer": "computer(1.00)<br/>math(1.00)", "pred answer": "work", "question_id": 4515135, "best approach": "image", "verif answer": "math", "anno approach": "wiki, concept, image", "verif wiki answer": "electron(0.6948)", "verif concept answer": "light(0.6803)", "verif image answer": "math(0.6401)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451513.jpg"}, {"question": "what style of architechure is the building", "gt answer": "spanish(1.00)<br/>modern(0.60)<br/>old(0.60)", "pred answer": "victorian", "question_id": 4276925, "best approach": "wiki, concept", "verif answer": "old", "anno approach": "wiki, concept, image", "verif wiki answer": "old(0.6741)", "verif concept answer": "old(0.7212)", "verif image answer": "direct(0.6885)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427692.jpg"}, {"question": "what are the green metal rungs in the background called", "gt answer": "gate(1.00)", "pred answer": "fence", "question_id": 1301475, "best approach": "image", "verif answer": "fence", "anno approach": "wiki, concept, image", "verif wiki answer": "fence(0.7078)", "verif concept answer": "fence(0.6844)", "verif image answer": "gate(0.6999)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130147.jpg"}, {"question": "in what type of structure is this lady with her cat and dog", "gt answer": "bed(1.00)<br/>bunk bed(0.60)", "pred answer": "house", "question_id": 2181145, "best approach": "wiki", "verif answer": "bed", "anno approach": "wiki, concept, image", "verif wiki answer": "bed(0.7305)", "verif concept answer": "bunk bed(0.7293)", "verif image answer": "bunk bed(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218114.jpg"}, {"question": "where was this picture taken from", "gt answer": "boat(1.00)", "pred answer": "airport", "question_id": 2020705, "best approach": "concept, image", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "raft(0.6130)", "verif concept answer": "boat(0.6542)", "verif image answer": "boat(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202070.jpg"}, {"question": "what is the gestation period of a pachyderm", "gt answer": "22 months(1.00)<br/>2 months(0.60)", "pred answer": "60 years", "question_id": 3952685, "best approach": "wiki", "verif answer": "baby", "anno approach": "wiki, concept, image", "verif wiki answer": "22 months(0.6611)", "verif concept answer": "2 months(0.6063)", "verif image answer": "3 months(0.6635)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395268.jpg"}, {"question": "how do you groom this animal", "gt answer": "shear(1.00)<br/>sheer(0.60)<br/>clip(0.60)", "pred answer": "brush", "question_id": 2169805, "best approach": "wiki", "verif answer": "shear", "anno approach": "wiki, concept, image", "verif wiki answer": "shear(0.7222)", "verif concept answer": "sheer(0.7017)", "verif image answer": "sheer(0.7106)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216980.jpg"}, {"question": "what color handle is unique", "gt answer": "blue(1.00)<br/>white(0.60)<br/>orange(0.60)", "pred answer": "yellow", "question_id": 3997465, "best approach": "image", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "red(0.6778)", "verif concept answer": "red(0.6486)", "verif image answer": "blue(0.7189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399746.jpg"}, {"question": "what are those flying object made of", "gt answer": "silk(1.00)<br/>fabric(0.60)<br/>thread(0.60)", "pred answer": "plastic", "question_id": 537255, "best approach": "wiki, concept", "verif answer": "thread", "anno approach": "wiki, concept, image", "verif wiki answer": "fabric(0.6315)", "verif concept answer": "fabric(0.7124)", "verif image answer": "cotton(0.6971)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053725.jpg"}, {"question": "what city is this in", "gt answer": "san francisco(1.00)", "pred answer": "new york", "question_id": 1245255, "best approach": "image", "verif answer": "chicago", "anno approach": "wiki, concept, image", "verif wiki answer": "new york city(0.6247)", "verif concept answer": "chicago(0.6767)", "verif image answer": "san francisco(0.5838)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000124525.jpg"}, {"question": "what industry do the uniformed men work for", "gt answer": "law enforcement(1.00)<br/>police(1.00)", "pred answer": "military", "question_id": 4695875, "best approach": "concept", "verif answer": "police", "anno approach": "wiki, concept, image", "verif wiki answer": "captain(0.7252)", "verif concept answer": "law enforcement(0.7041)", "verif image answer": "captain(0.7183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469587.jpg"}, {"question": "what is the meaning of the number 20 inside the green circle", "gt answer": "speed limit(1.00)", "pred answer": "1 way", "question_id": 1302865, "best approach": "image", "verif answer": "speed limit", "anno approach": "wiki, concept, image", "verif wiki answer": "direct(0.5448)", "verif concept answer": "turn(0.5827)", "verif image answer": "speed limit(0.5159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130286.jpg"}, {"question": "which type of wrapper is used for cover this gift shown in this picture", "gt answer": "wrap paper(1.00)", "pred answer": "canvas", "question_id": 697005, "best approach": "concept", "verif answer": "paper", "anno approach": "wiki, concept, image", "verif wiki answer": "mesh(0.6704)", "verif concept answer": "wrap paper(0.6106)", "verif image answer": "large(0.6477)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069700.jpg"}, {"question": "what type of place would you find these items", "gt answer": "grocery(1.00)<br/>farmer market(0.60)<br/>market(0.60)<br/>grocery store(0.60)", "pred answer": "produce", "question_id": 4152755, "best approach": "", "verif answer": "farmer market", "anno approach": "wiki, concept, image", "verif wiki answer": "supermarket(0.6497)", "verif concept answer": "supermarket(0.6206)", "verif image answer": "supermarket(0.6776)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415275.jpg"}, {"question": "what type of bike is this", "gt answer": "bicycle(1.00)<br/>(0.60)<br/>low(0.60)<br/>regular(0.60)", "pred answer": "schwinn", "question_id": 1643575, "best approach": "image", "verif answer": "bicycle", "anno approach": "wiki, concept, image", "verif wiki answer": "bike(0.7260)", "verif concept answer": "bike(0.7003)", "verif image answer": "bicycle(0.6353)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000164357.jpg"}, {"question": "pigeons are also be known as what", "gt answer": "bird(1.00)", "pred answer": "pigeon", "question_id": 5816865, "best approach": "", "verif answer": "pigeon", "anno approach": "wiki, concept, image", "verif wiki answer": "bee(0.7145)", "verif concept answer": "hummingbird(0.6947)", "verif image answer": "bee(0.6899)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000581686.jpg"}, {"question": "what is the life span of this animal", "gt answer": "15 18 years(1.00)<br/>15 years(0.60)<br/>5 years(0.60)<br/>10 years(0.60)", "pred answer": "60 years", "question_id": 1262105, "best approach": "wiki, concept, image", "verif answer": "15 years", "anno approach": "wiki, concept, image", "verif wiki answer": "10 years(0.7215)", "verif concept answer": "5 years(0.6480)", "verif image answer": "15 years(0.7257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126210.jpg"}, {"question": "what may have caused this accident", "gt answer": "speed(1.00)", "pred answer": "flood", "question_id": 1477465, "best approach": "wiki, concept", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "speed(0.6139)", "verif concept answer": "speed(0.6227)", "verif image answer": "0(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147746.jpg"}, {"question": "what company manufactured this truck", "gt answer": "volvo(1.00)<br/>mercedes(0.60)<br/>mercedes benz(0.60)<br/>germany(0.60)", "pred answer": "kenworth", "question_id": 1690405, "best approach": "wiki, concept", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "mercedes benz(0.7289)", "verif concept answer": "mercedes benz(0.7204)", "verif image answer": "honda(0.7205)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169040.jpg"}, {"question": "what is the use of that light", "gt answer": "traffic(1.00)<br/>traffic control(0.60)", "pred answer": "go", "question_id": 5454475, "best approach": "concept", "verif answer": "control traffic", "anno approach": "wiki, concept, image", "verif wiki answer": "control traffic(0.7026)", "verif concept answer": "traffic control(0.7092)", "verif image answer": "stop light(0.6987)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545447.jpg"}, {"question": "where is this photo taken from", "gt answer": "vehicle(1.00)<br/>zebra(0.60)", "pred answer": "city", "question_id": 4294915, "best approach": "wiki", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "vehicle(0.6264)", "verif concept answer": "truck(0.6612)", "verif image answer": "car(0.6789)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429491.jpg"}, {"question": "the purple item is for what", "gt answer": "read(1.00)", "pred answer": "tv", "question_id": 5601525, "best approach": "", "verif answer": "book", "anno approach": "wiki, concept, image", "verif wiki answer": "shop(0.6824)", "verif concept answer": "shop(0.7269)", "verif image answer": "book(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560152.jpg"}, {"question": "what type of sauce is used for this dish", "gt answer": "hollandaise(1.00)<br/>butter(0.60)<br/>italian(0.60)", "pred answer": "ranch dress", "question_id": 1448475, "best approach": "concept", "verif answer": "ranch dress", "anno approach": "wiki, concept, image", "verif wiki answer": "ranch dress(0.6873)", "verif concept answer": "hollandaise(0.6916)", "verif image answer": "egg(0.6822)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144847.jpg"}, {"question": "what cartoon show are the character on this kid 's chair from", "gt answer": "looney tune(1.00)", "pred answer": "yogi", "question_id": 5398445, "best approach": "", "verif answer": "bug bunny", "anno approach": "wiki, concept, image", "verif wiki answer": "bug bunny(0.7275)", "verif concept answer": "bug bunny(0.6979)", "verif image answer": "crosswalk(0.7203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539844.jpg"}, {"question": "what could i use in this room to cool things", "gt answer": "refrigerator(1.00)<br/>c(0.60)<br/>fan(0.60)", "pred answer": "microwave", "question_id": 2512195, "best approach": "wiki", "verif answer": "refrigerator", "anno approach": "wiki, concept, image", "verif wiki answer": "refrigerator(0.7291)", "verif concept answer": "fridge(0.7222)", "verif image answer": "fridge(0.6831)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251219.jpg"}, {"question": "how many world series has this team won", "gt answer": "27(1.00)<br/>7(0.60)<br/>5(0.60)", "pred answer": "30", "question_id": 2130095, "best approach": "wiki, concept, image", "verif answer": "5", "anno approach": "wiki, concept, image", "verif wiki answer": "7(0.6211)", "verif concept answer": "7(0.7119)", "verif image answer": "7(0.7069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000213009.jpg"}, {"question": "what is inside those motorcycle tires", "gt answer": "air(1.00)", "pred answer": "cloth", "question_id": 3281065, "best approach": "image", "verif answer": "water", "anno approach": "wiki, concept, image", "verif wiki answer": "water(0.5441)", "verif concept answer": "water(0.6339)", "verif image answer": "air(0.6619)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328106.jpg"}, {"question": "what is in the glass cabinets", "gt answer": "dish(1.00)<br/>cup(0.60)", "pred answer": "utensil", "question_id": 2625195, "best approach": "image", "verif answer": "dish", "anno approach": "wiki, concept, image", "verif wiki answer": "dishwasher(0.7128)", "verif concept answer": "dishwasher(0.7112)", "verif image answer": "dish(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262519.jpg"}, {"question": "are these people in a classroom or a store", "gt answer": "store(1.00)", "pred answer": "library", "question_id": 1546775, "best approach": "", "verif answer": "store", "anno approach": "wiki, concept, image", "verif wiki answer": "online(0.6945)", "verif concept answer": "online(0.6919)", "verif image answer": "online(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154677.jpg"}, {"question": "what ingredients are used to make that bread", "gt answer": "yeast(1.00)<br/>vegetable(0.60)", "pred answer": "wheat", "question_id": 4854815, "best approach": "wiki", "verif answer": "flour", "anno approach": "wiki, concept, image", "verif wiki answer": "vegetable(0.7112)", "verif concept answer": "meat(0.6532)", "verif image answer": "meat(0.6657)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485481.jpg"}, {"question": "what kind of tree is shown on the left side of the image", "gt answer": "elm(1.00)<br/>oak(1.00)<br/>deciduous(0.60)", "pred answer": "maple", "question_id": 1034985, "best approach": "", "verif answer": "maple", "anno approach": "wiki, concept, image", "verif wiki answer": "maple(0.7266)", "verif concept answer": "maple(0.7205)", "verif image answer": "maple(0.7045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103498.jpg"}, {"question": "what kind of bus is it", "gt answer": "tour bus(1.00)<br/>double decker(1.00)<br/>amtrak(0.60)", "pred answer": "tour", "question_id": 3333565, "best approach": "wiki, concept, image", "verif answer": "tour", "anno approach": "wiki, concept, image", "verif wiki answer": "tour bus(0.7154)", "verif concept answer": "tour bus(0.6387)", "verif image answer": "double decker(0.6274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333356.jpg"}, {"question": "who is more likely to use these tools a leather crafter or a paper crafter", "gt answer": "paper crafter(1.00)<br/>paper(0.60)<br/>electrician(0.60)", "pred answer": "craft", "question_id": 4897715, "best approach": "wiki", "verif answer": "electrician", "anno approach": "wiki, concept, image", "verif wiki answer": "paper crafter(0.5077)", "verif concept answer": "5(0.5328)", "verif image answer": "paper(0.5011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489771.jpg"}, {"question": "how does the thing falling help the plants", "gt answer": "water them(1.00)<br/>water(0.60)", "pred answer": "rain", "question_id": 5432015, "best approach": "image", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "water(0.7119)", "verif concept answer": "rock(0.5283)", "verif image answer": "water them(0.7217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543201.jpg"}, {"question": "what bank does this atm come from", "gt answer": "servihanca(1.00)", "pred answer": "7 11", "question_id": 4672625, "best approach": "", "verif answer": "dryer", "anno approach": "wiki, concept, image", "verif wiki answer": "john henry(0.6121)", "verif concept answer": "john henry(0.7216)", "verif image answer": "million(0.6979)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467262.jpg"}, {"question": "what kind of license is required for these vehicles", "gt answer": "boat(1.00)<br/>commercial(0.60)", "pred answer": "100", "question_id": 3269485, "best approach": "concept, image", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "raft(0.6548)", "verif concept answer": "boat(0.6570)", "verif image answer": "boat(0.6773)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000326948.jpg"}, {"question": "what is the flavor of the pink topping on this dessert", "gt answer": "strawberry(1.00)<br/>cherry(0.60)", "pred answer": "vanilla", "question_id": 4365965, "best approach": "", "verif answer": "chocolate", "anno approach": "wiki, concept, image", "verif wiki answer": "chocolate(0.7086)", "verif concept answer": "chocolate(0.6873)", "verif image answer": "chocolate(0.6923)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436596.jpg"}, {"question": "what was that sign meant for", "gt answer": "direct(1.00)", "pred answer": "street name", "question_id": 5519005, "best approach": "", "verif answer": "street name", "anno approach": "wiki, concept, image", "verif wiki answer": "street name(0.6010)", "verif concept answer": "direction(0.6658)", "verif image answer": "arrow(0.7165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000551900.jpg"}, {"question": "who is this person addressing", "gt answer": "student(1.00)", "pred answer": "adobe", "question_id": 3808895, "best approach": "concept", "verif answer": "student", "anno approach": "wiki, concept, image", "verif wiki answer": "school kid(0.6584)", "verif concept answer": "student(0.5649)", "verif image answer": "school kid(0.5945)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000380889.jpg"}, {"question": "in what year was this food item first created", "gt answer": "1889(1.00)<br/>1800s(0.60)", "pred answer": "1900", "question_id": 3075525, "best approach": "image", "verif answer": "1950s", "anno approach": "wiki, concept, image", "verif wiki answer": "1800's(0.6585)", "verif concept answer": "1800's(0.6444)", "verif image answer": "1889(0.6350)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307552.jpg"}, {"question": "are the animals' bones hollow or dense", "gt answer": "dense(1.00)", "pred answer": "hot", "question_id": 5338075, "best approach": "", "verif answer": "fresh", "anno approach": "wiki, concept, image", "verif wiki answer": "arrive(0.5995)", "verif concept answer": "arrive(0.6657)", "verif image answer": "arrive(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000533807.jpg"}, {"question": "who wrote this poem", "gt answer": "eric berne(1.00)", "pred answer": "irma s rombauer", "question_id": 3738215, "best approach": "wiki, concept, image", "verif answer": "graffiti artist", "anno approach": "wiki, concept, image", "verif wiki answer": "eric berne(0.7299)", "verif concept answer": "eric berne(0.6921)", "verif image answer": "eric berne(0.6622)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373821.jpg"}, {"question": "what is this vehicle used for", "gt answer": "fire(1.00)<br/>firefight(1.00)", "pred answer": "tow", "question_id": 2872455, "best approach": "wiki, concept, image", "verif answer": "fire", "anno approach": "wiki, concept, image", "verif wiki answer": "fire(0.7006)", "verif concept answer": "fire(0.6665)", "verif image answer": "fire(0.5854)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287245.jpg"}, {"question": "what type of shoes is the person using", "gt answer": "tennis shoe(1.00)<br/>tennis(1.00)", "pred answer": "sneaker", "question_id": 1539655, "best approach": "concept, image", "verif answer": "tennis shoe", "anno approach": "wiki, concept, image", "verif wiki answer": "tennis ball(0.5915)", "verif concept answer": "tennis(0.6860)", "verif image answer": "tennis shoe(0.6636)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153965.jpg"}, {"question": "name that game", "gt answer": "rugby(1.00)", "pred answer": "frisbee", "question_id": 946605, "best approach": "", "verif answer": "soccer", "anno approach": "wiki, concept, image", "verif wiki answer": "soccer(0.7188)", "verif concept answer": "equestrian(0.6363)", "verif image answer": "polo(0.5314)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094660.jpg"}, {"question": "what was that device used for", "gt answer": "phone call(1.00)<br/>communication(1.00)", "pred answer": "cellphone", "question_id": 4648565, "best approach": "wiki, concept", "verif answer": "cell phone", "anno approach": "wiki, concept, image", "verif wiki answer": "communication(0.7112)", "verif concept answer": "phone call(0.7094)", "verif image answer": "cell phone(0.6749)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464856.jpg"}, {"question": "who is the highest paid person in this sport", "gt answer": "tony hawk(1.00)", "pred answer": "shaun white", "question_id": 3653445, "best approach": "concept", "verif answer": "tony hawk", "anno approach": "wiki, concept, image", "verif wiki answer": "kelly slater(0.7222)", "verif concept answer": "tony hawk(0.6996)", "verif image answer": "kelly slater(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365344.jpg"}, {"question": "is this an example of a toy collector or normal kid", "gt answer": "normal kid(1.00)<br/>normal(0.60)", "pred answer": "adult", "question_id": 4479135, "best approach": "wiki, image", "verif answer": "normal", "anno approach": "wiki, concept, image", "verif wiki answer": "normal kid(0.6927)", "verif concept answer": "normal(0.7274)", "verif image answer": "normal kid(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447913.jpg"}, {"question": "what bird is the bench modeled after", "gt answer": "peacock(1.00)<br/>swan(0.60)", "pred answer": "pigeon", "question_id": 4824725, "best approach": "", "verif answer": "bird", "anno approach": "wiki, concept, image", "verif wiki answer": "bird(0.7070)", "verif concept answer": "bird(0.6999)", "verif image answer": "bird(0.5330)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482472.jpg"}, {"question": "what kind of suit are these men wearing", "gt answer": "tuxedo(1.00)", "pred answer": "suit", "question_id": 1345205, "best approach": "concept", "verif answer": "suit", "anno approach": "wiki, concept, image", "verif wiki answer": "suit(0.7246)", "verif concept answer": "tuxedo(0.7166)", "verif image answer": "suit(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134520.jpg"}, {"question": "what type of plants is the pink color one in the photo", "gt answer": "fern(1.00)", "pred answer": "daffodil", "question_id": 3497345, "best approach": "concept", "verif answer": "lavender", "anno approach": "wiki, concept, image", "verif wiki answer": "cactus(0.7100)", "verif concept answer": "fern(0.7111)", "verif image answer": "lavender(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000349734.jpg"}, {"question": "what was the name of the character with this profession in a famous ken kesey novel", "gt answer": "nurse(1.00)", "pred answer": "mulan", "question_id": 1400925, "best approach": "", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "scissor(0.7298)", "verif concept answer": "scissor(0.5898)", "verif image answer": "apple(0.6950)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140092.jpg"}, {"question": "a name for a room of this kind found on campus", "gt answer": "dorm(1.00)", "pred answer": "bedroom", "question_id": 5642885, "best approach": "wiki, concept, image", "verif answer": "college", "anno approach": "wiki, concept, image", "verif wiki answer": "dorm(0.7254)", "verif concept answer": "dorm(0.5610)", "verif image answer": "dorm(0.7037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564288.jpg"}, {"question": "describe what this structure appears to be", "gt answer": "outhouse(1.00)", "pred answer": "apartment", "question_id": 1915405, "best approach": "wiki, concept, image", "verif answer": "toilet paper", "anno approach": "wiki, concept, image", "verif wiki answer": "outhouse(0.7212)", "verif concept answer": "outhouse(0.6821)", "verif image answer": "outhouse(0.6905)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191540.jpg"}, {"question": "what type of vehicle is the yellow item", "gt answer": "box truck(1.00)<br/>truck(1.00)<br/>skateboard(0.60)", "pred answer": "train", "question_id": 2165245, "best approach": "wiki, image", "verif answer": "skateboard", "anno approach": "wiki, concept, image", "verif wiki answer": "truck(0.5893)", "verif concept answer": "skateboard(0.7159)", "verif image answer": "box truck(0.6534)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216524.jpg"}, {"question": "this bear is famous for loving what food", "gt answer": "honey(1.00)", "pred answer": "vanilla", "question_id": 2103685, "best approach": "wiki, concept", "verif answer": "theodore roosevelt", "anno approach": "wiki, concept, image", "verif wiki answer": "honey(0.5410)", "verif concept answer": "honey(0.6124)", "verif image answer": "italian(0.6241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210368.jpg"}, {"question": "what type of toilet is this", "gt answer": "bidet(1.00)<br/>japanese(0.60)", "pred answer": "modern", "question_id": 547555, "best approach": "concept", "verif answer": "bathroom", "anno approach": "wiki, concept, image", "verif wiki answer": "fountain(0.6389)", "verif concept answer": "bidet(0.6383)", "verif image answer": "bathroom(0.6585)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054755.jpg"}, {"question": "what is the employment status of these men", "gt answer": "retired(1.00)", "pred answer": "poor", "question_id": 4796876, "best approach": "", "verif answer": "poor", "anno approach": "wiki, concept, image", "verif wiki answer": "unsafe(0.7307)", "verif concept answer": "unsafe(0.6976)", "verif image answer": "unsafe(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479687.jpg"}, {"question": "what is the substance growing on this", "gt answer": "algae(1.00)<br/>moss(0.60)", "pred answer": "water", "question_id": 274065, "best approach": "wiki, concept, image", "verif answer": "leaf", "anno approach": "wiki, concept, image", "verif wiki answer": "algae(0.7204)", "verif concept answer": "algae(0.7082)", "verif image answer": "algae(0.6999)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027406.jpg"}, {"question": "what species of bear is this", "gt answer": "grizzly(1.00)<br/>mammal(0.60)", "pred answer": "brown", "question_id": 26195, "best approach": "", "verif answer": "brown", "anno approach": "wiki, concept, image", "verif wiki answer": "brown(0.7141)", "verif concept answer": "brown(0.6881)", "verif image answer": "brown(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002619.jpg"}, {"question": "what are these animals used for", "gt answer": "meat(1.00)<br/>eat(1.00)<br/>farm(0.60)", "pred answer": "food", "question_id": 5415105, "best approach": "concept", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "milk(0.7264)", "verif concept answer": "eat(0.7104)", "verif image answer": "food(0.7105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541510.jpg"}, {"question": "what kind of lettuce is on this plate", "gt answer": "iceberg(1.00)<br/>leaf(0.60)<br/>kale(0.60)", "pred answer": "romaine", "question_id": 160895, "best approach": "wiki", "verif answer": "iceberg", "anno approach": "wiki, concept, image", "verif wiki answer": "iceberg(0.7231)", "verif concept answer": "leaf(0.7150)", "verif image answer": "leaf(0.6818)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016089.jpg"}, {"question": "what kind of damage can this animal do to furniture", "gt answer": "scratch(1.00)", "pred answer": "broken", "question_id": 4395315, "best approach": "wiki, concept", "verif answer": "stripe", "anno approach": "wiki, concept, image", "verif wiki answer": "scratch(0.7226)", "verif concept answer": "scratch(0.6637)", "verif image answer": "stripe(0.5607)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439531.jpg"}, {"question": "what genus does this species of animal come from", "gt answer": "elephas(1.00)<br/>cow(0.60)<br/>pachyderm(0.60)", "pred answer": "elephant", "question_id": 3255705, "best approach": "", "verif answer": "elephant", "anno approach": "wiki, concept, image", "verif wiki answer": "elephant(0.7301)", "verif concept answer": "elephant(0.7260)", "verif image answer": "elephant(0.6186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325570.jpg"}, {"question": "what is a luxury vessel called", "gt answer": "yacht(1.00)<br/>boat(0.60)<br/>italian(0.60)", "pred answer": "cruise ship", "question_id": 5284525, "best approach": "wiki, image", "verif answer": "italian", "anno approach": "wiki, concept, image", "verif wiki answer": "italian(0.7264)", "verif concept answer": "water ski(0.7056)", "verif image answer": "italian(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528452.jpg"}, {"question": "where does this bird originate from", "gt answer": "alaska(1.00)<br/>canada(0.60)<br/>north america(0.60)<br/>asia(0.60)", "pred answer": "europe", "question_id": 2946085, "best approach": "image", "verif answer": "america", "anno approach": "wiki, concept, image", "verif wiki answer": "america(0.7263)", "verif concept answer": "canada(0.7059)", "verif image answer": "alaska(0.7194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000294608.jpg"}, {"question": "if wearing proper glasses what might this picture do", "gt answer": "pop out(1.00)<br/>move(0.60)", "pred answer": "reflection", "question_id": 2026295, "best approach": "", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "fly(0.7228)", "verif concept answer": "fly(0.6315)", "verif image answer": "no saddle(0.7238)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202629.jpg"}, {"question": "what is the tv playing", "gt answer": "movie(1.00)<br/>show(1.00)<br/>video(0.60)", "pred answer": "cartoon", "question_id": 213535, "best approach": "concept", "verif answer": "video game", "anno approach": "wiki, concept, image", "verif wiki answer": "video game(0.7219)", "verif concept answer": "movie(0.6431)", "verif image answer": "wii(0.6731)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000021353.jpg"}, {"question": "what airline does the plane belong to", "gt answer": "portland timber(1.00)<br/>alaska(0.60)", "pred answer": "american", "question_id": 4550155, "best approach": "", "verif answer": "american", "anno approach": "wiki, concept, image", "verif wiki answer": "eva air(0.7253)", "verif concept answer": "eva air(0.5871)", "verif image answer": "canada(0.5768)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455015.jpg"}, {"question": "why might we suspect that this scene is nowhere in north america", "gt answer": "elephant(1.00)<br/>tree(0.60)", "pred answer": "wild", "question_id": 1123955, "best approach": "wiki, image", "verif answer": "elephant", "anno approach": "wiki, concept, image", "verif wiki answer": "elephant(0.6274)", "verif concept answer": "brain(0.5540)", "verif image answer": "elephant(0.6709)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000112395.jpg"}, {"question": "where would you find a stand such as the one in the picture", "gt answer": "market(1.00)<br/>farmer market(0.60)", "pred answer": "kitchen", "question_id": 5672745, "best approach": "", "verif answer": "grocery store", "anno approach": "wiki, concept, image", "verif wiki answer": "grocery store(0.6328)", "verif concept answer": "supermarket(0.6561)", "verif image answer": "grocery store(0.6956)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567274.jpg"}, {"question": "what kind of bread is this", "gt answer": "pita(1.00)", "pred answer": "whole grain", "question_id": 1976895, "best approach": "", "verif answer": "whole grain", "anno approach": "wiki, concept, image", "verif wiki answer": "tortilla(0.7273)", "verif concept answer": "tortilla(0.7156)", "verif image answer": "whole grain(0.7083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197689.jpg"}, {"question": "why is this officer using this mode of transportation", "gt answer": "patrol(1.00)<br/>fast(0.60)", "pred answer": "race", "question_id": 20565, "best approach": "concept", "verif answer": "fun", "anno approach": "wiki, concept, image", "verif wiki answer": "very fast(0.6737)", "verif concept answer": "fast(0.6301)", "verif image answer": "very fast(0.6875)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002056.jpg"}, {"question": "what does one traditionally do when blowing out these candles", "gt answer": "make wish(1.00)<br/>birthday(0.60)", "pred answer": "candle", "question_id": 962225, "best approach": "", "verif answer": "share", "anno approach": "wiki, concept, image", "verif wiki answer": "cut cake(0.7071)", "verif concept answer": "hug(0.7306)", "verif image answer": "share(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096222.jpg"}, {"question": "what is associated with this place", "gt answer": "cook(1.00)<br/>eat(0.60)", "pred answer": "computer", "question_id": 3077595, "best approach": "", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "chef(0.6402)", "verif concept answer": "restaurant(0.6985)", "verif image answer": "dinner(0.6490)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307759.jpg"}, {"question": "what is the white line for", "gt answer": "safety(1.00)<br/>stop(0.60)<br/>transport(0.60)", "pred answer": "crosswalk", "question_id": 1030895, "best approach": "concept", "verif answer": "train", "anno approach": "wiki, concept, image", "verif wiki answer": "transport(0.6404)", "verif concept answer": "safety(0.6273)", "verif image answer": "train(0.7164)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103089.jpg"}, {"question": "who invented the first pair of these", "gt answer": "leonardo da vinci(1.00)<br/>romans(0.60)<br/>man(0.60)", "pred answer": "wright", "question_id": 3800725, "best approach": "wiki, concept", "verif answer": "croatian mercenary", "anno approach": "wiki, concept, image", "verif wiki answer": "leonardo da vinci(0.7289)", "verif concept answer": "leonardo da vinci(0.7041)", "verif image answer": "croatian mercenary(0.7176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000380072.jpg"}, {"question": "according to their attire what decade is represented", "gt answer": "1940s(1.00)<br/>1930(1.00)<br/>1930s(0.60)", "pred answer": "20th", "question_id": 1126195, "best approach": "", "verif answer": "1940's", "anno approach": "wiki, concept, image", "verif wiki answer": "1940's(0.6514)", "verif concept answer": "1940's(0.7073)", "verif image answer": "1940's(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000112619.jpg"}, {"question": "what sound does this animal make", "gt answer": "quack(1.00)<br/>honk(0.60)", "pred answer": "neigh", "question_id": 46475, "best approach": "concept, image", "verif answer": "moo", "anno approach": "wiki, concept, image", "verif wiki answer": "woof(0.7299)", "verif concept answer": "quack(0.7266)", "verif image answer": "quack(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004647.jpg"}, {"question": "what is the vegetable in this sandwich", "gt answer": "lettuce(1.00)", "pred answer": "roast beef", "question_id": 87765, "best approach": "concept", "verif answer": "spinach", "anno approach": "wiki, concept, image", "verif wiki answer": "kale(0.6882)", "verif concept answer": "lettuce(0.7275)", "verif image answer": "spinach(0.7225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008776.jpg"}, {"question": "if you combined the two colors of the toilets it would create which color", "gt answer": "purple(1.00)<br/>violet(0.60)", "pred answer": "vanilla", "question_id": 2803245, "best approach": "", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "green(0.7249)", "verif concept answer": "green(0.5922)", "verif image answer": "green(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280324.jpg"}, {"question": "what is reflected in this image", "gt answer": "bike(1.00)<br/>monitor(0.60)", "pred answer": "car", "question_id": 3859715, "best approach": "", "verif answer": "bike", "anno approach": "wiki, concept, image", "verif wiki answer": "scooter(0.6573)", "verif concept answer": "scooter(0.7003)", "verif image answer": "bicycle(0.6448)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385971.jpg"}, {"question": "what species of hourse is in this photo", "gt answer": "thoroughbred(1.00)<br/>stallion(0.60)<br/>arabian(0.60)", "pred answer": "horse", "question_id": 346455, "best approach": "wiki", "verif answer": "clydesdale", "anno approach": "wiki, concept, image", "verif wiki answer": "thoroughbred(0.6686)", "verif concept answer": "arabian(0.6638)", "verif image answer": "stallion(0.6735)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000034645.jpg"}, {"question": "in order for the microwave to start what needs to be done", "gt answer": "close door(1.00)", "pred answer": "stove", "question_id": 3325745, "best approach": "wiki, concept", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "close door(0.5442)", "verif concept answer": "close door(0.5015)", "verif image answer": "restaurant(0.6427)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332574.jpg"}, {"question": "what kind of machine is this", "gt answer": "truck(1.00)<br/>car(0.60)", "pred answer": "jeep", "question_id": 4196455, "best approach": "wiki, concept, image", "verif answer": "truck", "anno approach": "wiki, concept, image", "verif wiki answer": "truck(0.7150)", "verif concept answer": "truck(0.6732)", "verif image answer": "truck(0.6718)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419645.jpg"}, {"question": "what holiday is being celebrated here", "gt answer": "halloween(1.00)", "pred answer": "valentine's day", "question_id": 1719405, "best approach": "concept", "verif answer": "christmas", "anno approach": "wiki, concept, image", "verif wiki answer": "birthday(0.7195)", "verif concept answer": "halloween(0.6744)", "verif image answer": "birthday(0.7120)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171940.jpg"}, {"question": "what type of bird is this", "gt answer": "crow(1.00)<br/>seagull(0.60)<br/>pigeon(0.60)<br/>black(0.60)", "pred answer": "hummingbird", "question_id": 4951345, "best approach": "wiki, concept, image", "verif answer": "crow", "anno approach": "wiki, concept, image", "verif wiki answer": "black(0.7247)", "verif concept answer": "black(0.7236)", "verif image answer": "black(0.7213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495134.jpg"}, {"question": "what type of political event is this", "gt answer": "rally(1.00)<br/>parade(1.00)", "pred answer": "police", "question_id": 819665, "best approach": "concept, image", "verif answer": "parade", "anno approach": "wiki, concept, image", "verif wiki answer": "motorcycle(0.7145)", "verif concept answer": "parade(0.6796)", "verif image answer": "parade(0.6756)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081966.jpg"}, {"question": "what kind of notes are on the cake", "gt answer": "music(1.00)", "pred answer": "paint", "question_id": 4275605, "best approach": "", "verif answer": "plastic", "anno approach": "wiki, concept, image", "verif wiki answer": "compos music(0.6097)", "verif concept answer": "compos music(0.6673)", "verif image answer": "headphone(0.6740)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427560.jpg"}, {"question": "what kind of coat might you bring in this room", "gt answer": "bathrobe(1.00)<br/>overcoat(0.60)", "pred answer": "scarf", "question_id": 4029085, "best approach": "image", "verif answer": "overcoat", "anno approach": "wiki, concept, image", "verif wiki answer": "overcoat(0.6704)", "verif concept answer": "overcoat(0.6112)", "verif image answer": "bathrobe(0.6176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402908.jpg"}, {"question": "which circus act famously makes use of a device reminiscent of the bar the man is holding", "gt answer": "fly trapeze(1.00)", "pred answer": "parachute", "question_id": 1136985, "best approach": "wiki, concept", "verif answer": "ben franklin", "anno approach": "wiki, concept, image", "verif wiki answer": "fly trapeze(0.7195)", "verif concept answer": "fly trapeze(0.6401)", "verif image answer": "new year(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113698.jpg"}, {"question": "what kind of filling is in this donut", "gt answer": "jelly(1.00)<br/>jam(0.60)", "pred answer": "beef", "question_id": 231275, "best approach": "image", "verif answer": "chocolate", "anno approach": "wiki, concept, image", "verif wiki answer": "chocolate(0.6903)", "verif concept answer": "donut(0.7228)", "verif image answer": "jam(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023127.jpg"}, {"question": "what is the officer expecting the dog to do to the suitcase", "gt answer": "sniff(1.00)<br/>smell(0.60)", "pred answer": "fly", "question_id": 249355, "best approach": "", "verif answer": "eat", "anno approach": "wiki, concept, image", "verif wiki answer": "stop(0.6675)", "verif concept answer": "stop(0.7091)", "verif image answer": "stop(0.6810)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024935.jpg"}, {"question": "what is there to show this woman needs help walking", "gt answer": "cane(1.00)", "pred answer": "leash", "question_id": 4137075, "best approach": "", "verif answer": "desk", "anno approach": "wiki, concept, image", "verif wiki answer": "crutch(0.7247)", "verif concept answer": "crutch(0.7224)", "verif image answer": "glass(0.7157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000413707.jpg"}, {"question": "what are these foods being served in", "gt answer": "contain(1.00)<br/>dish(0.60)", "pred answer": "vegetable", "question_id": 380465, "best approach": "wiki, concept", "verif answer": "dinner", "anno approach": "wiki, concept, image", "verif wiki answer": "dish(0.7291)", "verif concept answer": "dish(0.7109)", "verif image answer": "toilet(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038046.jpg"}, {"question": "a castle like the one in the background can be viewed at the start of movies from what studio", "gt answer": "disney(1.00)", "pred answer": "church", "question_id": 2964395, "best approach": "wiki", "verif answer": "disney", "anno approach": "wiki, concept, image", "verif wiki answer": "disney(0.6853)", "verif concept answer": "thomas tank engine(0.7057)", "verif image answer": "build bear(0.6041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296439.jpg"}, {"question": "why would we suspect that a cat lives here", "gt answer": "scratch post(1.00)", "pred answer": "sleep", "question_id": 3813845, "best approach": "image", "verif answer": "to eat", "anno approach": "wiki, concept, image", "verif wiki answer": "run(0.6563)", "verif concept answer": "to eat(0.7249)", "verif image answer": "scratch post(0.6349)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381384.jpg"}, {"question": "where did the animal learn that trick", "gt answer": "owner(1.00)<br/>master(0.60)", "pred answer": "chicago", "question_id": 1587575, "best approach": "image", "verif answer": "house", "anno approach": "wiki, concept, image", "verif wiki answer": "house(0.6187)", "verif concept answer": "factory(0.6714)", "verif image answer": "master(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000158757.jpg"}, {"question": "what type or breed of dog is that", "gt answer": "golden retriever(1.00)<br/>german shepherd(0.60)<br/>retriever(0.60)<br/>collie(0.60)", "pred answer": "lab", "question_id": 5392965, "best approach": "wiki, image", "verif answer": "border collie", "anno approach": "wiki, concept, image", "verif wiki answer": "retriever(0.7170)", "verif concept answer": "border collie(0.7197)", "verif image answer": "german shepherd(0.6786)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539296.jpg"}, {"question": "what is the person making", "gt answer": "snow angel(1.00)", "pred answer": "snowboard", "question_id": 5677275, "best approach": "image", "verif answer": "snowboard", "anno approach": "wiki, concept, image", "verif wiki answer": "half pipe(0.7096)", "verif concept answer": "shaun white(0.7167)", "verif image answer": "snow angel(0.6220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567727.jpg"}, {"question": "what makes these items similar", "gt answer": "button(1.00)<br/>battery(0.60)<br/>electron(0.60)", "pred answer": "computer", "question_id": 1520705, "best approach": "wiki, concept, image", "verif answer": "computer", "anno approach": "wiki, concept, image", "verif wiki answer": "battery(0.6886)", "verif concept answer": "battery(0.7191)", "verif image answer": "battery(0.7116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000152070.jpg"}, {"question": "what type of sofa is this", "gt answer": "loveseat(1.00)<br/>futon(0.60)<br/>cat(0.60)<br/>miniature(0.60)", "pred answer": "large", "question_id": 4799015, "best approach": "wiki, concept", "verif answer": "loveseat", "anno approach": "wiki, concept, image", "verif wiki answer": "loveseat(0.7298)", "verif concept answer": "loveseat(0.6941)", "verif image answer": "brown(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479901.jpg"}, {"question": "what is the age of the woman standing behind the children", "gt answer": "40(1.00)<br/>34(0.60)<br/>25(0.60)", "pred answer": "50", "question_id": 874655, "best approach": "wiki, image", "verif answer": "40", "anno approach": "wiki, concept, image", "verif wiki answer": "40(0.7152)", "verif concept answer": "many(0.6525)", "verif image answer": "40(0.7148)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087465.jpg"}, {"question": "what type of truck do they call the large boxed truck in the photo", "gt answer": "semi(1.00)<br/>trailer(0.60)", "pred answer": "garbage", "question_id": 4780325, "best approach": "", "verif answer": "semi", "anno approach": "wiki, concept, image", "verif wiki answer": "bus(0.6588)", "verif concept answer": "industrial(0.6970)", "verif image answer": "industrial(0.7094)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478032.jpg"}, {"question": "is this a active or inactive game", "gt answer": "active(1.00)", "pred answer": "business", "question_id": 458295, "best approach": "wiki, concept", "verif answer": "candid", "anno approach": "wiki, concept, image", "verif wiki answer": "active(0.7154)", "verif concept answer": "active(0.7286)", "verif image answer": "candid(0.7227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045829.jpg"}, {"question": "what is the name of the blue beverage in the bottle in front of the child", "gt answer": "gatorade(1.00)", "pred answer": "juice", "question_id": 1601815, "best approach": "wiki, concept", "verif answer": "juice", "anno approach": "wiki, concept, image", "verif wiki answer": "gatorade(0.7210)", "verif concept answer": "gatorade(0.5516)", "verif image answer": "tea(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160181.jpg"}, {"question": "what is the mascot doing", "gt answer": "thumb up(1.00)<br/>cheer(0.60)", "pred answer": "pitch", "question_id": 4402445, "best approach": "concept", "verif answer": "play", "anno approach": "wiki, concept, image", "verif wiki answer": "catcher(0.7136)", "verif concept answer": "thumb up(0.6321)", "verif image answer": "catch(0.6987)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440244.jpg"}, {"question": "what brand is deodorant", "gt answer": "speed stick(1.00)", "pred answer": "nintendo", "question_id": 2534835, "best approach": "wiki, concept, image", "verif answer": "pepsi", "anno approach": "wiki, concept, image", "verif wiki answer": "speed stick(0.6750)", "verif concept answer": "speed stick(0.5332)", "verif image answer": "speed stick(0.7122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253483.jpg"}, {"question": "what image does the food make", "gt answer": "smiley face(1.00)<br/>face(0.60)<br/>smile(0.60)", "pred answer": "birthday", "question_id": 2504985, "best approach": "wiki, concept, image", "verif answer": "face", "anno approach": "wiki, concept, image", "verif wiki answer": "smiley face(0.6450)", "verif concept answer": "smiley face(0.6460)", "verif image answer": "smiley face(0.7180)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250498.jpg"}, {"question": "what area of the world are these trees found in", "gt answer": "tropic(1.00)<br/>south(0.60)<br/>tropical(0.60)", "pred answer": "south america", "question_id": 4864495, "best approach": "image", "verif answer": "south", "anno approach": "wiki, concept, image", "verif wiki answer": "florida(0.7140)", "verif concept answer": "florida(0.6415)", "verif image answer": "south(0.6756)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000486449.jpg"}, {"question": "what is causing the snow to scatter upwards", "gt answer": "snowboarder(1.00)<br/>man(0.60)<br/>fall(0.60)", "pred answer": "gravity", "question_id": 5605305, "best approach": "wiki, concept, image", "verif answer": "fall", "anno approach": "wiki, concept, image", "verif wiki answer": "fall(0.7275)", "verif concept answer": "fall(0.6952)", "verif image answer": "man(0.6436)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560530.jpg"}, {"question": "what do you call the wall covering abve this bed", "gt answer": "quilt(1.00)", "pred answer": "blanket", "question_id": 4552575, "best approach": "", "verif answer": "blanket", "anno approach": "wiki, concept, image", "verif wiki answer": "sew(0.7292)", "verif concept answer": "sew(0.7259)", "verif image answer": "blanket(0.6632)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455257.jpg"}, {"question": "what team is the batter from", "gt answer": "white sox(1.00)<br/>tiger(0.60)<br/>home(0.60)", "pred answer": "yankees", "question_id": 334885, "best approach": "wiki, concept", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "white sox(0.6657)", "verif concept answer": "white sox(0.6994)", "verif image answer": "garden(0.7171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033488.jpg"}, {"question": "what kind of vehicles are this photo", "gt answer": "bus(1.00)<br/>semi(0.60)", "pred answer": "train", "question_id": 3936005, "best approach": "wiki", "verif answer": "truck", "anno approach": "wiki, concept, image", "verif wiki answer": "bus(0.6861)", "verif concept answer": "submarine(0.7125)", "verif image answer": "semi(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393600.jpg"}, {"question": "where is this store", "gt answer": "grocery(1.00)<br/>starbucks(0.60)<br/>chicago(0.60)", "pred answer": "walmart", "question_id": 792695, "best approach": "wiki, concept, image", "verif answer": "starbucks", "anno approach": "wiki, concept, image", "verif wiki answer": "starbucks(0.7036)", "verif concept answer": "starbucks(0.6904)", "verif image answer": "chicago(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079269.jpg"}, {"question": "what does the weather seem like", "gt answer": "stormy(1.00)<br/>rainy(0.60)<br/>cloudy(0.60)", "pred answer": "sunny", "question_id": 4189355, "best approach": "wiki", "verif answer": "cloudy", "anno approach": "wiki, concept, image", "verif wiki answer": "rainy(0.7197)", "verif concept answer": "overcast(0.6654)", "verif image answer": "daytime(0.6507)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000418935.jpg"}, {"question": "what are these type of seating apparatus generally called", "gt answer": "swing(1.00)", "pred answer": "toy", "question_id": 2276215, "best approach": "", "verif answer": "bird feeder", "anno approach": "wiki, concept, image", "verif wiki answer": "hit ball(0.7153)", "verif concept answer": "hit ball(0.7298)", "verif image answer": "hit ball(0.7102)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000227621.jpg"}, {"question": "at what age would a child engage in this behavior", "gt answer": "1 year(1.00)<br/>2(0.60)<br/>1(0.60)<br/>12 months(0.60)", "pred answer": "toddler", "question_id": 4618705, "best approach": "image", "verif answer": "3", "anno approach": "wiki, concept, image", "verif wiki answer": "2(0.7005)", "verif concept answer": "1(0.6846)", "verif image answer": "1 year(0.6866)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461870.jpg"}, {"question": "what store in competition with the one featured on the notepad is named after a metal fastener", "gt answer": "staple(1.00)", "pred answer": "nokia", "question_id": 4291115, "best approach": "", "verif answer": "purse", "anno approach": "wiki, concept, image", "verif wiki answer": "carmen miranda(0.6297)", "verif concept answer": "smuggle(0.5537)", "verif image answer": "short(0.7063)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429111.jpg"}, {"question": "what kind of airplane is this", "gt answer": "fighter jet(1.00)<br/>military(0.60)", "pred answer": "jet", "question_id": 1076305, "best approach": "", "verif answer": "jet", "anno approach": "wiki, concept, image", "verif wiki answer": "bomber(0.7272)", "verif concept answer": "bomber(0.7171)", "verif image answer": "jet(0.7126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000107630.jpg"}, {"question": "what is a benefit of visiting this location", "gt answer": "relaxation(1.00)<br/>vacation(0.60)<br/>tan(0.60)", "pred answer": "fun", "question_id": 2588545, "best approach": "wiki", "verif answer": "relax", "anno approach": "wiki, concept, image", "verif wiki answer": "vacation(0.6981)", "verif concept answer": "walk(0.6825)", "verif image answer": "walk(0.6974)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258854.jpg"}, {"question": "what is the purpose of the yellow object", "gt answer": "float(1.00)<br/>pillow(0.60)<br/>safety(0.60)", "pred answer": "storage", "question_id": 3717945, "best approach": "", "verif answer": "travel", "anno approach": "wiki, concept, image", "verif wiki answer": "travel(0.5720)", "verif concept answer": "travel(0.6197)", "verif image answer": "art(0.6845)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371794.jpg"}, {"question": "what type of food is in the large dish", "gt answer": "lasagna(1.00)<br/>macaroni and cheese(0.60)", "pred answer": "chicken", "question_id": 1362005, "best approach": "concept", "verif answer": "burger", "anno approach": "wiki, concept, image", "verif wiki answer": "popcorn(0.7199)", "verif concept answer": "macaroni and cheese(0.7255)", "verif image answer": "popcorn(0.7267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136200.jpg"}, {"question": "what tv channel is the photo taken from", "gt answer": "cnn(1.00)", "pred answer": "espn", "question_id": 5126625, "best approach": "", "verif answer": "instagram", "anno approach": "wiki, concept, image", "verif wiki answer": "instagram(0.6466)", "verif concept answer": "instagram(0.6297)", "verif image answer": "instagram(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512662.jpg"}, {"question": "what does the sign say right above the stop sign", "gt answer": "grandview dr(1.00)<br/>street(0.60)<br/>street name(0.60)", "pred answer": "brake", "question_id": 4025985, "best approach": "", "verif answer": "street sign", "anno approach": "wiki, concept, image", "verif wiki answer": "street sign(0.5572)", "verif concept answer": "street sign(0.5995)", "verif image answer": "street sign(0.5006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402598.jpg"}, {"question": "what is the elephant doing with it 's foot", "gt answer": "lift it(1.00)<br/>kick(0.60)<br/>walk(0.60)", "pred answer": "sit", "question_id": 4667975, "best approach": "concept", "verif answer": "kick", "anno approach": "wiki, concept, image", "verif wiki answer": "jump(0.6408)", "verif concept answer": "walk(0.6746)", "verif image answer": "jump(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466797.jpg"}, {"question": "what types of birds are those", "gt answer": "pigeon(1.00)<br/>finch(0.60)<br/>sparrow(0.60)", "pred answer": "pelican", "question_id": 3672605, "best approach": "concept, image", "verif answer": "pigeon", "anno approach": "wiki, concept, image", "verif wiki answer": "owl(0.7149)", "verif concept answer": "sparrow(0.7154)", "verif image answer": "finch(0.6497)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367260.jpg"}, {"question": "the activity these horses is doing is what", "gt answer": "graze(1.00)<br/>walk(0.60)", "pred answer": "herd", "question_id": 2968765, "best approach": "concept", "verif answer": "herd", "anno approach": "wiki, concept, image", "verif wiki answer": "herd(0.7300)", "verif concept answer": "walk(0.7076)", "verif image answer": "herd(0.7262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296876.jpg"}, {"question": "name the yellow signal that is shown in this picture", "gt answer": "firetruck(1.00)<br/>yield(0.60)", "pred answer": "caution", "question_id": 3126035, "best approach": "concept", "verif answer": "caution", "anno approach": "wiki, concept, image", "verif wiki answer": "yield(0.7267)", "verif concept answer": "firetruck(0.7076)", "verif image answer": "fire truck(0.6942)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312603.jpg"}, {"question": "what would i do here", "gt answer": "read(1.00)<br/>sleep(0.60)", "pred answer": "vacation", "question_id": 4204505, "best approach": "wiki, concept, image", "verif answer": "read", "anno approach": "wiki, concept, image", "verif wiki answer": "read(0.7197)", "verif concept answer": "read(0.7090)", "verif image answer": "read(0.6985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420450.jpg"}, {"question": "what is written on the van", "gt answer": "mike willy(1.00)", "pred answer": "ice cream", "question_id": 734425, "best approach": "", "verif answer": "speed limit", "anno approach": "wiki, concept, image", "verif wiki answer": "speed limit(0.6305)", "verif concept answer": "speed limit(0.7209)", "verif image answer": "speed limit(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073442.jpg"}, {"question": "what healthy oil is this dish a source of", "gt answer": "canola(1.00)<br/>0(0.60)", "pred answer": "omega 3", "question_id": 3350035, "best approach": "concept", "verif answer": "olive oil", "anno approach": "wiki, concept, image", "verif wiki answer": "vegetable(0.7271)", "verif concept answer": "canola(0.7241)", "verif image answer": "olive oil(0.7217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335003.jpg"}, {"question": "what gender would use this bathroom", "gt answer": "male(1.00)", "pred answer": "men", "question_id": 479055, "best approach": "concept", "verif answer": "men", "anno approach": "wiki, concept, image", "verif wiki answer": "female(0.7176)", "verif concept answer": "male(0.7152)", "verif image answer": "female(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047905.jpg"}, {"question": "the holiday pictured celebrates which religion", "gt answer": "christianity(1.00)<br/>christian(1.00)", "pred answer": "christmas", "question_id": 5776695, "best approach": "", "verif answer": "catholic", "anno approach": "wiki, concept, image", "verif wiki answer": "catholic(0.7231)", "verif concept answer": "catholic(0.7278)", "verif image answer": "catholic(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000577669.jpg"}, {"question": "what is the life span of this animal", "gt answer": "10 years(1.00)<br/>14(0.60)<br/>12 years(0.60)", "pred answer": "20", "question_id": 4958505, "best approach": "wiki, image", "verif answer": "10 years", "anno approach": "wiki, concept, image", "verif wiki answer": "10 years(0.6729)", "verif concept answer": "20 years(0.6294)", "verif image answer": "10 years(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495850.jpg"}, {"question": "what is the person doing in this photo", "gt answer": "serve(1.00)<br/>play tennis(0.60)", "pred answer": "tennis", "question_id": 528135, "best approach": "", "verif answer": "tennis", "anno approach": "wiki, concept, image", "verif wiki answer": "hit ball(0.7237)", "verif concept answer": "hit ball(0.7278)", "verif image answer": "hit ball(0.7158)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052813.jpg"}, {"question": "where was this refrigerator manufactured", "gt answer": "united state(1.00)<br/>hp(0.60)<br/>america(0.60)", "pred answer": "ge", "question_id": 3286545, "best approach": "wiki, concept, image", "verif answer": "america", "anno approach": "wiki, concept, image", "verif wiki answer": "america(0.6985)", "verif concept answer": "hp(0.7196)", "verif image answer": "hp(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328654.jpg"}, {"question": "what type of flowers are on this bus", "gt answer": "sunflower(1.00)", "pred answer": "daffodil", "question_id": 4016885, "best approach": "", "verif answer": "daisy", "anno approach": "wiki, concept, image", "verif wiki answer": "daisy(0.6871)", "verif concept answer": "daisy(0.6666)", "verif image answer": "daisy(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401688.jpg"}, {"question": "what is the divider of the court called", "gt answer": "net(1.00)", "pred answer": "chain link", "question_id": 5684205, "best approach": "", "verif answer": "court", "anno approach": "wiki, concept, image", "verif wiki answer": "court(0.6032)", "verif concept answer": "shake hand(0.6112)", "verif image answer": "shake hand(0.6120)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568420.jpg"}, {"question": "what are the two items on the window called", "gt answer": "wiper(1.00)", "pred answer": "blind", "question_id": 3288985, "best approach": "wiki, concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "wiper(0.7258)", "verif concept answer": "wiper(0.6279)", "verif image answer": "train(0.7155)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328898.jpg"}, {"question": "what kind of stuffed animal is this", "gt answer": "panda(1.00)", "pred answer": "bear", "question_id": 4542105, "best approach": "", "verif answer": "bear", "anno approach": "wiki, concept, image", "verif wiki answer": "penguin(0.7299)", "verif concept answer": "penguin(0.7256)", "verif image answer": "polar(0.7084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000454210.jpg"}, {"question": "what kind of wallpaper was used", "gt answer": "floral(1.00)<br/>retro(0.60)<br/>orange(0.60)", "pred answer": "checkered", "question_id": 1016325, "best approach": "concept", "verif answer": "floral", "anno approach": "wiki, concept, image", "verif wiki answer": "retro(0.6939)", "verif concept answer": "floral(0.6841)", "verif image answer": "retro(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000101632.jpg"}, {"question": "what is the presidential plane called", "gt answer": "air force 1(1.00)", "pred answer": "private jet", "question_id": 5117745, "best approach": "image", "verif answer": "private jet", "anno approach": "wiki, concept, image", "verif wiki answer": "air force(0.5859)", "verif concept answer": "private(0.6381)", "verif image answer": "air force 1(0.6372)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511774.jpg"}, {"question": "how does this fly", "gt answer": "engine(1.00)<br/>lift(0.60)", "pred answer": "fuel", "question_id": 3928415, "best approach": "wiki, concept, image", "verif answer": "fuel", "anno approach": "wiki, concept, image", "verif wiki answer": "engine(0.6874)", "verif concept answer": "engine(0.7128)", "verif image answer": "engine(0.7158)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392841.jpg"}, {"question": "what kind of orange is this", "gt answer": "navel(1.00)", "pred answer": "orange", "question_id": 3731375, "best approach": "", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "orange(0.5921)", "verif concept answer": "skin(0.6200)", "verif image answer": "pumpkin(0.6891)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373137.jpg"}, {"question": "what is the wing span of the plane", "gt answer": "20 feet(1.00)", "pred answer": "6000 feet", "question_id": 1321395, "best approach": "", "verif answer": "3 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "100 feet(0.7256)", "verif concept answer": "100 feet(0.6323)", "verif image answer": "100 feet(0.6339)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000132139.jpg"}, {"question": "which of the foods on this table has the lowest sodium", "gt answer": "salad(1.00)<br/>butter(1.00)", "pred answer": "potato", "question_id": 4103455, "best approach": "wiki, concept, image", "verif answer": "butter", "anno approach": "wiki, concept, image", "verif wiki answer": "salad(0.7185)", "verif concept answer": "salad(0.7200)", "verif image answer": "salad(0.7187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000410345.jpg"}, {"question": "what type of motorcycle is this", "gt answer": "kawasaki(1.00)<br/>crotch rocket(0.60)<br/>race(0.60)<br/>racer(0.60)", "pred answer": "honda", "question_id": 1989745, "best approach": "concept", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "honda(0.7084)", "verif concept answer": "race(0.6767)", "verif image answer": "honda(0.7036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198974.jpg"}, {"question": "what is the compression ratio of the motor in this motorcycle", "gt answer": "10:1(1.00)<br/>2(0.60)", "pred answer": "100", "question_id": 1618365, "best approach": "image", "verif answer": "120 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "120 mph(0.7117)", "verif concept answer": "120 mph(0.6709)", "verif image answer": "10:1(0.5484)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161836.jpg"}, {"question": "what breed of dog is in the photo", "gt answer": "dachsund(0.60)<br/>corgi(1.00)<br/>beagle(0.60)<br/>collie(0.60)", "pred answer": "mutt", "question_id": 2906785, "best approach": "wiki, concept", "verif answer": "collie", "anno approach": "wiki, concept, image", "verif wiki answer": "collie(0.7243)", "verif concept answer": "collie(0.7223)", "verif image answer": "hound(0.7042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000290678.jpg"}, {"question": "what temperature is the maximum in this picture", "gt answer": "32(1.00)<br/>0(0.60)", "pred answer": "freeze", "question_id": 2313105, "best approach": "wiki, concept, image", "verif answer": "0", "anno approach": "wiki, concept, image", "verif wiki answer": "0(0.5513)", "verif concept answer": "0(0.5402)", "verif image answer": "0(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231310.jpg"}, {"question": "what style of cooking was used for this dish", "gt answer": "grill(1.00)<br/>fry(0.60)", "pred answer": "deep dish", "question_id": 4776175, "best approach": "image", "verif answer": "fried", "anno approach": "wiki, concept, image", "verif wiki answer": "fried(0.7095)", "verif concept answer": "over easy(0.7208)", "verif image answer": "grill(0.6773)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477617.jpg"}, {"question": "what is this used for", "gt answer": "cook(1.00)<br/>bake(0.60)<br/>roast(0.60)", "pred answer": "heat food", "question_id": 4602265, "best approach": "wiki, image", "verif answer": "cook", "anno approach": "wiki, concept, image", "verif wiki answer": "cook(0.6724)", "verif concept answer": "grill(0.6691)", "verif image answer": "cook(0.7143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460226.jpg"}, {"question": "", "gt answer": "apron(0.60)<br/>grill(0.60)", "pred answer": "back", "question_id": 1902725, "best approach": "", "verif answer": "front", "anno approach": "wiki, concept, image", "verif wiki answer": "counter(0.5729)", "verif concept answer": "counter(0.6585)", "verif image answer": "stir fry(0.5309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190272.jpg"}, {"question": "what is the box in the image known as", "gt answer": "bird house(1.00)", "pred answer": "money", "question_id": 4478795, "best approach": "concept", "verif answer": "room", "anno approach": "wiki, concept, image", "verif wiki answer": "room(0.5827)", "verif concept answer": "bird house(0.6109)", "verif image answer": "room(0.6789)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447879.jpg"}, {"question": "how tall is the mast on this boat", "gt answer": "10feet(1.00)<br/>10 feet(0.60)", "pred answer": "20 feet", "question_id": 3605665, "best approach": "", "verif answer": "15 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "15 feet(0.7254)", "verif concept answer": "15 feet(0.6705)", "verif image answer": "15 feet(0.6600)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000360566.jpg"}, {"question": "what makeup product is smudged on the woman 's face", "gt answer": "mascara(1.00)", "pred answer": "lipstick", "question_id": 5540035, "best approach": "", "verif answer": "lipstick", "anno approach": "wiki, concept, image", "verif wiki answer": "lipstick(0.7241)", "verif concept answer": "lipstick(0.5390)", "verif image answer": "lipstick(0.6966)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554003.jpg"}, {"question": "what type of cable is this", "gt answer": "usb(1.00)<br/>long(0.60)", "pred answer": "samsung", "question_id": 5533045, "best approach": "image", "verif answer": "electric", "anno approach": "wiki, concept, image", "verif wiki answer": "smartphone(0.6996)", "verif concept answer": "electric(0.6894)", "verif image answer": "usb(0.6696)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553304.jpg"}, {"question": "to which company do you think the van shown belongs", "gt answer": "up(1.00)", "pred answer": "toyota", "question_id": 242595, "best approach": "concept, image", "verif answer": "bank", "anno approach": "wiki, concept, image", "verif wiki answer": "amazon(0.6661)", "verif concept answer": "up(0.5686)", "verif image answer": "up(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024259.jpg"}, {"question": "who makes the luggage in this room", "gt answer": "samsonite(1.00)<br/>children(0.60)<br/>china(0.60)", "pred answer": "columbia", "question_id": 2263635, "best approach": "wiki, image", "verif answer": "columbia", "anno approach": "wiki, concept, image", "verif wiki answer": "samsonite(0.7294)", "verif concept answer": "china(0.6574)", "verif image answer": "samsonite(0.7195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226363.jpg"}, {"question": "how are those fries seasoned", "gt answer": "salt(1.00)", "pred answer": "fried", "question_id": 3279215, "best approach": "wiki", "verif answer": "fresh", "anno approach": "wiki, concept, image", "verif wiki answer": "salt(0.6934)", "verif concept answer": "salt and pepper(0.6501)", "verif image answer": "salt and pepper(0.6877)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327921.jpg"}, {"question": "who invented this sport", "gt answer": "abner doubleday(1.00)<br/>english(0.60)", "pred answer": "jackie robinson", "question_id": 1090785, "best approach": "wiki", "verif answer": "abner doubleday", "anno approach": "wiki, concept, image", "verif wiki answer": "abner doubleday(0.7111)", "verif concept answer": "ty cobb(0.7160)", "verif image answer": "ty cobb(0.6375)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000109078.jpg"}, {"question": "what companys van is being pictured", "gt answer": "ice cream(1.00)<br/>ge(0.60)<br/>school(0.60)<br/>ford(0.60)", "pred answer": "greyhound", "question_id": 4015095, "best approach": "wiki, concept, image", "verif answer": "ford", "anno approach": "wiki, concept, image", "verif wiki answer": "ge(0.5988)", "verif concept answer": "ge(0.5501)", "verif image answer": "ford(0.7148)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401509.jpg"}, {"question": "why is this form of transportation stopped", "gt answer": "pick up people(1.00)<br/>broken(0.60)<br/>turn(0.60)<br/>passenger(0.60)", "pred answer": "bus", "question_id": 1283515, "best approach": "wiki, concept, image", "verif answer": "broken", "anno approach": "wiki, concept, image", "verif wiki answer": "broken(0.7128)", "verif concept answer": "broken(0.6438)", "verif image answer": "broken(0.6682)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128351.jpg"}, {"question": "what is this person inside of", "gt answer": "bus(1.00)<br/>train(1.00)", "pred answer": "car", "question_id": 4659405, "best approach": "wiki", "verif answer": "bus", "anno approach": "wiki, concept, image", "verif wiki answer": "bus(0.6818)", "verif concept answer": "rush hour(0.6775)", "verif image answer": "submarine(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465940.jpg"}, {"question": "what division are these players in", "gt answer": "mlb(1.00)<br/>central(0.60)", "pred answer": "first", "question_id": 3411335, "best approach": "", "verif answer": "major league", "anno approach": "wiki, concept, image", "verif wiki answer": "major league(0.7084)", "verif concept answer": "major league baseball(0.6570)", "verif image answer": "central park(0.7051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341133.jpg"}, {"question": "what era is this plane from", "gt answer": "1940s(1.00)<br/>old(0.60)", "pred answer": "1940's", "question_id": 216785, "best approach": "", "verif answer": "wwii", "anno approach": "wiki, concept, image", "verif wiki answer": "1930(0.6598)", "verif concept answer": "wwii(0.6842)", "verif image answer": "1930(0.7093)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000021678.jpg"}, {"question": "how many watts does this appliance consume", "gt answer": "300(1.00)<br/>100(0.60)", "pred answer": "8", "question_id": 926915, "best approach": "wiki, image", "verif answer": "100", "anno approach": "wiki, concept, image", "verif wiki answer": "100(0.7003)", "verif concept answer": "60(0.6233)", "verif image answer": "100(0.6876)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092691.jpg"}, {"question": "what kind of bike is this", "gt answer": "dirt bike(1.00)<br/>dirt(0.60)<br/>motorcycle(0.60)<br/>motorbike(0.60)", "pred answer": "honda", "question_id": 1188705, "best approach": "concept", "verif answer": "motorbike", "anno approach": "wiki, concept, image", "verif wiki answer": "motorcycle(0.7153)", "verif concept answer": "dirt bike(0.7166)", "verif image answer": "motorcycle(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118870.jpg"}, {"question": "what are the ingredients used in preparing the dish shown", "gt answer": "cheese(1.00)", "pred answer": "tomato", "question_id": 470015, "best approach": "wiki, image", "verif answer": "tomato", "anno approach": "wiki, concept, image", "verif wiki answer": "cheese(0.6495)", "verif concept answer": "tomato(0.6780)", "verif image answer": "cheese(0.6866)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047001.jpg"}, {"question": "which famous character is represented on the sheets", "gt answer": "mickey mouse(1.00)", "pred answer": "theodore roosevelt", "question_id": 1535855, "best approach": "wiki, concept, image", "verif answer": "mickey mouse", "anno approach": "wiki, concept, image", "verif wiki answer": "mickey mouse(0.7305)", "verif concept answer": "mickey mouse(0.7300)", "verif image answer": "mickey mouse(0.7016)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153585.jpg"}, {"question": "what is this device called this woman is on", "gt answer": "lift(1.00)<br/>ski lift(1.00)", "pred answer": "ski", "question_id": 413405, "best approach": "wiki, image", "verif answer": "lift", "anno approach": "wiki, concept, image", "verif wiki answer": "lift(0.7190)", "verif concept answer": "snowboard(0.7218)", "verif image answer": "lift(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041340.jpg"}, {"question": "why are the elephants milling around the waterhole", "gt answer": "thirsty(1.00)<br/>bath(0.60)", "pred answer": "drink", "question_id": 2911175, "best approach": "concept", "verif answer": "drink", "anno approach": "wiki, concept, image", "verif wiki answer": "drink water(0.6674)", "verif concept answer": "thirsty(0.6807)", "verif image answer": "drink(0.6094)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291117.jpg"}, {"question": "smooth water such as this is said to be what", "gt answer": "calm(1.00)<br/>harbor(0.60)", "pred answer": "salt", "question_id": 2010035, "best approach": "concept", "verif answer": "harbor", "anno approach": "wiki, concept, image", "verif wiki answer": "drunk(0.5621)", "verif concept answer": "calm(0.6243)", "verif image answer": "drunk(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201003.jpg"}, {"question": "what purpose does the white and red striped bar in the picture serve", "gt answer": "stop traffic(1.00)<br/>stop(0.60)", "pred answer": "traffic control", "question_id": 1631755, "best approach": "wiki", "verif answer": "traffic control", "anno approach": "wiki, concept, image", "verif wiki answer": "stop traffic(0.7027)", "verif concept answer": "traffic control(0.6939)", "verif image answer": "traffic control(0.6993)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163175.jpg"}, {"question": "what breed of dog is this", "gt answer": "pomeranian(1.00)", "pred answer": "pug", "question_id": 2834515, "best approach": "concept", "verif answer": "chihuahua", "anno approach": "wiki, concept, image", "verif wiki answer": "chihuahua(0.7258)", "verif concept answer": "pomeranian(0.7258)", "verif image answer": "teddy bear(0.5807)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283451.jpg"}, {"question": "what is the name of the material used to make this kind of fence", "gt answer": "barbed wire(1.00)<br/>wood(0.60)<br/>wire(0.60)", "pred answer": "metal", "question_id": 1819325, "best approach": "wiki", "verif answer": "nylon", "anno approach": "wiki, concept, image", "verif wiki answer": "barbed wire(0.6916)", "verif concept answer": "nylon(0.7265)", "verif image answer": "wire(0.7262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181932.jpg"}, {"question": "what are these pieces made of and where can we find them", "gt answer": "clay museum(1.00)", "pred answer": "wood", "question_id": 3260015, "best approach": "image", "verif answer": "paper", "anno approach": "wiki, concept, image", "verif wiki answer": "clay(0.6821)", "verif concept answer": "clay(0.6721)", "verif image answer": "clay museum(0.7037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000326001.jpg"}, {"question": "what kind of dog might belong to this worker", "gt answer": "dalmatian(1.00)<br/>dalmation(1.00)", "pred answer": "labrador", "question_id": 3070325, "best approach": "wiki, concept, image", "verif answer": "dalmatian", "anno approach": "wiki, concept, image", "verif wiki answer": "dalmatian(0.7110)", "verif concept answer": "dalmatian(0.6457)", "verif image answer": "dalmatian(0.6967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307032.jpg"}, {"question": "what is the slang term for this gesture", "gt answer": "middle finger(1.00)", "pred answer": "peace", "question_id": 1616115, "best approach": "", "verif answer": "vandalism", "anno approach": "wiki, concept, image", "verif wiki answer": "move(0.5823)", "verif concept answer": "move(0.5993)", "verif image answer": "vandalism(0.5559)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161611.jpg"}, {"question": "who came up with this creative idea", "gt answer": "artist(1.00)", "pred answer": "frederick graff", "question_id": 2128465, "best approach": "", "verif answer": "frederick graff sr", "anno approach": "wiki, concept, image", "verif wiki answer": "banksy(0.7233)", "verif concept answer": "banksy(0.7037)", "verif image answer": "banksy(0.7036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212846.jpg"}, {"question": "what kind of pizza is this", "gt answer": "pepperoni(1.00)<br/>cheese(1.00)", "pred answer": "supreme", "question_id": 1041775, "best approach": "concept, image", "verif answer": "supreme", "anno approach": "wiki, concept, image", "verif wiki answer": "deep dish(0.7079)", "verif concept answer": "cheese(0.7153)", "verif image answer": "cheese(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000104177.jpg"}, {"question": "what is the name of this olympic sport", "gt answer": "horse jump(1.00)<br/>jump(0.60)<br/>horse ride(0.60)", "pred answer": "horse race", "question_id": 5172615, "best approach": "wiki, concept, image", "verif answer": "ride", "anno approach": "wiki, concept, image", "verif wiki answer": "horse ride(0.7261)", "verif concept answer": "horse ride(0.6871)", "verif image answer": "jump(0.6422)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517261.jpg"}, {"question": "what kind of car is in the reflection of this window", "gt answer": "suv(1.00)<br/>station wagon(0.60)<br/>jeep(0.60)", "pred answer": "sedan", "question_id": 144885, "best approach": "wiki, image", "verif answer": "jeep", "anno approach": "wiki, concept, image", "verif wiki answer": "suv(0.7223)", "verif concept answer": "jeep(0.7000)", "verif image answer": "suv(0.7030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000014488.jpg"}, {"question": "which large sea going vehicle like this one famously sank after hitting an ice burg", "gt answer": "titanic(1.00)<br/>shark(0.60)", "pred answer": "tanker", "question_id": 5685165, "best approach": "concept, image", "verif answer": "0", "anno approach": "wiki, concept, image", "verif wiki answer": "0(0.7121)", "verif concept answer": "titanic(0.6522)", "verif image answer": "titanic(0.6467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568516.jpg"}, {"question": "how old is this child", "gt answer": "3(1.00)<br/>2(0.60)", "pred answer": "1", "question_id": 5752735, "best approach": "image", "verif answer": "1", "anno approach": "wiki, concept, image", "verif wiki answer": "1(0.7099)", "verif concept answer": "1(0.6835)", "verif image answer": "2(0.6609)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575273.jpg"}, {"question": "what do you call this type of bed", "gt answer": "king(1.00)<br/>queen(0.60)", "pred answer": "double", "question_id": 5050865, "best approach": "wiki", "verif answer": "double", "anno approach": "wiki, concept, image", "verif wiki answer": "queen(0.7156)", "verif concept answer": "full(0.7159)", "verif image answer": "full(0.6932)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505086.jpg"}, {"question": "what emotion does the color of his shirt illicit from bears", "gt answer": "fear(1.00)<br/>anger(0.60)<br/>danger(0.60)", "pred answer": "love", "question_id": 3333245, "best approach": "concept", "verif answer": "sad", "anno approach": "wiki, concept, image", "verif wiki answer": "sad(0.7271)", "verif concept answer": "fear(0.6481)", "verif image answer": "anger(0.5953)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333324.jpg"}, {"question": "what does one call the sheer netting the woman is wearing over her head", "gt answer": "veil(1.00)", "pred answer": "cap", "question_id": 4480465, "best approach": "", "verif answer": "hat", "anno approach": "wiki, concept, image", "verif wiki answer": "hat(0.7103)", "verif concept answer": "chandelier(0.7162)", "verif image answer": "chandelier(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448046.jpg"}, {"question": "name the type of fruit in the bottom right corner", "gt answer": "apple(1.00)<br/>peach(1.00)", "pred answer": "orange", "question_id": 4724055, "best approach": "", "verif answer": "peach", "anno approach": "wiki, concept, image", "verif wiki answer": "lime(0.7242)", "verif concept answer": "lime(0.7295)", "verif image answer": "watermelon(0.6614)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000472405.jpg"}, {"question": "where do these buses usually take people", "gt answer": "school(1.00)", "pred answer": "tour", "question_id": 1495985, "best approach": "wiki, concept, image", "verif answer": "school", "anno approach": "wiki, concept, image", "verif wiki answer": "school(0.7184)", "verif concept answer": "school(0.6413)", "verif image answer": "school(0.6640)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149598.jpg"}, {"question": "which part of this vehicle bears the same name as the part a dog wags with", "gt answer": "tail(1.00)", "pred answer": "engine", "question_id": 3653195, "best approach": "wiki", "verif answer": "tail", "anno approach": "wiki, concept, image", "verif wiki answer": "tail(0.7056)", "verif concept answer": "box(0.5835)", "verif image answer": "leather(0.6858)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365319.jpg"}, {"question": "how fast can people ski", "gt answer": "80 mph(1.00)<br/>fast(0.60)", "pred answer": "100 mph", "question_id": 1862545, "best approach": "concept", "verif answer": "100 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "very fast(0.7159)", "verif concept answer": "80 mph(0.6017)", "verif image answer": "120 mph(0.7098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186254.jpg"}, {"question": "for whom are they created", "gt answer": "fan(1.00)<br/>san francisco(0.60)<br/>baseball player(0.60)", "pred answer": "team", "question_id": 1919575, "best approach": "image", "verif answer": "team", "anno approach": "wiki, concept, image", "verif wiki answer": "baseball player(0.5283)", "verif concept answer": "san francisco(0.5257)", "verif image answer": "fan(0.6699)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191957.jpg"}, {"question": "the current top female competitor in this sport is who", "gt answer": "lindsey vonn(1.00)", "pred answer": "shaun white", "question_id": 738575, "best approach": "", "verif answer": "shaun white", "anno approach": "wiki, concept, image", "verif wiki answer": "ge(0.7286)", "verif concept answer": "ge(0.6999)", "verif image answer": "ge(0.7000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073857.jpg"}, {"question": "what transportation is this", "gt answer": "airplane(1.00)<br/>plane(0.60)", "pred answer": "bus", "question_id": 4704715, "best approach": "", "verif answer": "airplane", "anno approach": "wiki, concept, image", "verif wiki answer": "luggage(0.6153)", "verif concept answer": "luggage(0.6528)", "verif image answer": "luggage(0.5654)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470471.jpg"}, {"question": "what restaurant does the cup in this image come from", "gt answer": "subway(1.00)", "pred answer": "fast food", "question_id": 3312665, "best approach": "", "verif answer": "mcdonalds", "anno approach": "wiki, concept, image", "verif wiki answer": "dunkin donuts(0.6830)", "verif concept answer": "dunkin donuts(0.7191)", "verif image answer": "mcdonalds(0.7204)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331266.jpg"}, {"question": "what year was this mode of transportation first invented", "gt answer": "1903(1.00)<br/>1984(0.60)", "pred answer": "1800s", "question_id": 5037825, "best approach": "wiki, concept", "verif answer": "1924", "anno approach": "wiki, concept, image", "verif wiki answer": "1903(0.7272)", "verif concept answer": "1903(0.6907)", "verif image answer": "1984(0.7195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503782.jpg"}, {"question": "what type of container is the soup held in", "gt answer": "bowl(1.00)", "pred answer": "metal", "question_id": 3292455, "best approach": "wiki, image", "verif answer": "bowl", "anno approach": "wiki, concept, image", "verif wiki answer": "bowl(0.7250)", "verif concept answer": "soup(0.6951)", "verif image answer": "bowl(0.6525)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329245.jpg"}, {"question": "what type of bath tub is this", "gt answer": "freestanding(1.00)<br/>porcelain(0.60)", "pred answer": "modern", "question_id": 4079115, "best approach": "", "verif answer": "ceramic", "anno approach": "wiki, concept, image", "verif wiki answer": "ceramic(0.5361)", "verif concept answer": "ceramic(0.6806)", "verif image answer": "ceramic(0.6307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407911.jpg"}, {"question": "sleeping or watching tv", "gt answer": "watch tv(1.00)<br/>watch(0.60)", "pred answer": "relax", "question_id": 4886415, "best approach": "concept, image", "verif answer": "play", "anno approach": "wiki, concept, image", "verif wiki answer": "talk(0.7253)", "verif concept answer": "watch(0.7080)", "verif image answer": "watch(0.7131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488641.jpg"}, {"question": "is that food cooked in an oven or fryer", "gt answer": "fryer(1.00)<br/>oven(1.00)", "pred answer": "grill", "question_id": 2248215, "best approach": "wiki, concept, image", "verif answer": "fryer", "anno approach": "wiki, concept, image", "verif wiki answer": "fryer(0.6919)", "verif concept answer": "fryer(0.6879)", "verif image answer": "oven(0.7114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224821.jpg"}, {"question": "what type of place is that green symbol often associated with", "gt answer": "gas station(1.00)<br/>beach(0.60)<br/>gas(0.60)", "pred answer": "city", "question_id": 2942445, "best approach": "wiki, concept", "verif answer": "florida", "anno approach": "wiki, concept, image", "verif wiki answer": "gas station(0.6304)", "verif concept answer": "gas station(0.7042)", "verif image answer": "gas(0.6920)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000294244.jpg"}, {"question": "how will he pitch", "gt answer": "fast(1.00)", "pred answer": "throw", "question_id": 5434805, "best approach": "concept, image", "verif answer": "fast", "anno approach": "wiki, concept, image", "verif wiki answer": "slow(0.6242)", "verif concept answer": "fast(0.6390)", "verif image answer": "fast(0.5273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543480.jpg"}, {"question": "what are the buildings behind the buses", "gt answer": "apart(1.00)<br/>business(0.60)<br/>house(0.60)", "pred answer": "bar", "question_id": 3174605, "best approach": "concept", "verif answer": "apart", "anno approach": "wiki, concept, image", "verif wiki answer": "house(0.6498)", "verif concept answer": "apart(0.6756)", "verif image answer": "house(0.6530)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317460.jpg"}, {"question": "what time of day is it", "gt answer": "morn(1.00)<br/>noon(0.60)", "pred answer": "even", "question_id": 3210075, "best approach": "wiki, concept", "verif answer": "morn", "anno approach": "wiki, concept, image", "verif wiki answer": "morn(0.7149)", "verif concept answer": "morn(0.7009)", "verif image answer": "afternoon(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321007.jpg"}, {"question": "what children 's fairy tale features a little blonde girl who wanders into the house occupied by three of these animals", "gt answer": "goldilocks(1.00)", "pred answer": "goldilocks and 3 bears", "question_id": 1930115, "best approach": "wiki, concept", "verif answer": "little bow peep", "anno approach": "wiki, concept, image", "verif wiki answer": "goldilocks(0.7308)", "verif concept answer": "goldilocks(0.7117)", "verif image answer": "little bow peep(0.7172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193011.jpg"}, {"question": "what are these people making", "gt answer": "cookies(1.00)<br/>food(0.60)", "pred answer": "straw", "question_id": 5134515, "best approach": "concept, image", "verif answer": "cake", "anno approach": "wiki, concept, image", "verif wiki answer": "food(0.6776)", "verif concept answer": "cookies(0.6903)", "verif image answer": "cookies(0.5865)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513451.jpg"}, {"question": "what year was this photo taken", "gt answer": "1945(1.00)<br/>1920s(0.60)<br/>1950(0.60)", "pred answer": "1930", "question_id": 3142465, "best approach": "wiki", "verif answer": "1930", "anno approach": "wiki, concept, image", "verif wiki answer": "1945(0.7185)", "verif concept answer": "1950(0.6867)", "verif image answer": "1930(0.6893)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314246.jpg"}, {"question": "what is the skateboard trick the boy is trying to pull", "gt answer": "kickflip(1.00)<br/>grind(1.00)<br/>ollie(0.60)", "pred answer": "jump", "question_id": 2874345, "best approach": "wiki, concept, image", "verif answer": "jump", "anno approach": "wiki, concept, image", "verif wiki answer": "kickflip(0.7117)", "verif concept answer": "kickflip(0.6990)", "verif image answer": "kickflip(0.6081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287434.jpg"}, {"question": "how did the plate with the pizza on it obtain its deep blue coloring", "gt answer": "paint(1.00)<br/>glaze(1.00)", "pred answer": "grease", "question_id": 857985, "best approach": "image", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "ice(0.6807)", "verif concept answer": "ice(0.6529)", "verif image answer": "glaze(0.6056)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085798.jpg"}, {"question": "what kind if hotdog is this", "gt answer": "chicago(1.00)<br/>beef(0.60)", "pred answer": "pork", "question_id": 2377265, "best approach": "", "verif answer": "beef", "anno approach": "wiki, concept, image", "verif wiki answer": "hotdog(0.7231)", "verif concept answer": "hotdog(0.7271)", "verif image answer": "hotdog(0.6609)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237726.jpg"}, {"question": "what is on the wall behind the couch", "gt answer": "map(1.00)", "pred answer": "paint", "question_id": 4031625, "best approach": "", "verif answer": "map", "anno approach": "wiki, concept, image", "verif wiki answer": "art(0.7260)", "verif concept answer": "camera(0.6662)", "verif image answer": "abstract(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403162.jpg"}, {"question": "what is the difference between each picture", "gt answer": "daylight(1.00)<br/>day(0.60)<br/>light(0.60)<br/>time(0.60)", "pred answer": "color", "question_id": 868755, "best approach": "image", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "light(0.5986)", "verif concept answer": "light(0.7045)", "verif image answer": "daylight(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086875.jpg"}, {"question": "where is this", "gt answer": "market(1.00)<br/>south america(0.60)<br/>city(0.60)", "pred answer": "kitchen", "question_id": 1013905, "best approach": "wiki, concept", "verif answer": "city", "anno approach": "wiki, concept, image", "verif wiki answer": "market(0.7118)", "verif concept answer": "market(0.7033)", "verif image answer": "city(0.7102)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000101390.jpg"}, {"question": "what year did this phone come out", "gt answer": "2004(1.00)<br/>2010(0.60)<br/>2005(0.60)<br/>2000(0.60)", "pred answer": "1930", "question_id": 4587485, "best approach": "concept, image", "verif answer": "2010", "anno approach": "wiki, concept, image", "verif wiki answer": "2008(0.7116)", "verif concept answer": "2000(0.6957)", "verif image answer": "2010(0.7069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458748.jpg"}, {"question": "who invented this sport", "gt answer": "legaignoux brother(1.00)", "pred answer": "tom sim", "question_id": 5397345, "best approach": "wiki, concept", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "legaignoux brother(0.7279)", "verif concept answer": "legaignoux brother(0.7238)", "verif image answer": "ben franklin(0.7035)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539734.jpg"}, {"question": "where would you post this", "gt answer": "instagram(1.00)<br/>facebook(0.60)", "pred answer": "park", "question_id": 2918255, "best approach": "", "verif answer": "bank", "anno approach": "wiki, concept, image", "verif wiki answer": "bank(0.6852)", "verif concept answer": "blurry(0.6646)", "verif image answer": "bank(0.6721)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291825.jpg"}, {"question": "the artifacts in this image is cause by a lack of what", "gt answer": "light(1.00)<br/>caution(0.60)<br/>filter(0.60)", "pred answer": "50", "question_id": 3548195, "best approach": "wiki, concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "light(0.5935)", "verif concept answer": "light(0.6242)", "verif image answer": "filter(0.5393)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354819.jpg"}, {"question": "is this a good example of public or private transportation", "gt answer": "public(1.00)", "pred answer": "private", "question_id": 224405, "best approach": "wiki, concept, image", "verif answer": "private", "anno approach": "wiki, concept, image", "verif wiki answer": "public(0.7128)", "verif concept answer": "public(0.6848)", "verif image answer": "public(0.7180)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000022440.jpg"}, {"question": "who is the namesake of this popular theme park", "gt answer": "disney(1.00)", "pred answer": "0", "question_id": 2883835, "best approach": "", "verif answer": "disney", "anno approach": "wiki, concept, image", "verif wiki answer": "mickey mouse(0.7295)", "verif concept answer": "mickey mouse(0.7236)", "verif image answer": "mickey mouse(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288383.jpg"}, {"question": "why is there a flower on plate", "gt answer": "decoration(1.00)<br/>garnish(0.60)", "pred answer": "not ripe", "question_id": 208575, "best approach": "", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "display(0.5631)", "verif concept answer": "display(0.5572)", "verif image answer": "display(0.7248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020857.jpg"}, {"question": "what all is needed to wash all these kitchen tools", "gt answer": "dishwasher(1.00)<br/>dish soap(0.60)", "pred answer": "soap", "question_id": 999885, "best approach": "wiki", "verif answer": "dish soap", "anno approach": "wiki, concept, image", "verif wiki answer": "dish soap(0.6731)", "verif concept answer": "dish(0.6460)", "verif image answer": "dish(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099988.jpg"}, {"question": "what type of attire is this", "gt answer": "business(1.00)<br/>formal(0.60)<br/>suit(0.60)", "pred answer": "casual", "question_id": 126145, "best approach": "", "verif answer": "casual", "anno approach": "wiki, concept, image", "verif wiki answer": "casual(0.7270)", "verif concept answer": "casual(0.7130)", "verif image answer": "casual(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012614.jpg"}, {"question": "what kind of birds are these", "gt answer": "sparrow(1.00)<br/>hummingbird(0.60)<br/>finch(0.60)", "pred answer": "parakeet", "question_id": 1439295, "best approach": "concept", "verif answer": "pigeon", "anno approach": "wiki, concept, image", "verif wiki answer": "robin(0.6549)", "verif concept answer": "sparrow(0.6977)", "verif image answer": "pigeon(0.6766)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143929.jpg"}, {"question": "which place in the home the tv is placed", "gt answer": "live room(1.00)", "pred answer": "kitchen", "question_id": 5205935, "best approach": "", "verif answer": "live room", "anno approach": "wiki, concept, image", "verif wiki answer": "table(0.6980)", "verif concept answer": "couch(0.6925)", "verif image answer": "table(0.6846)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520593.jpg"}, {"question": "how fast can these animals go", "gt answer": "40 mph(1.00)<br/>65 mph(0.60)", "pred answer": "35 miles per hour", "question_id": 880805, "best approach": "concept", "verif answer": "35 miles per hour", "anno approach": "wiki, concept, image", "verif wiki answer": "35 miles per hour(0.7185)", "verif concept answer": "65 mph(0.6406)", "verif image answer": "35 miles per hour(0.6896)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088080.jpg"}, {"question": "what team is the catcher on", "gt answer": "met(1.00)<br/>cub(0.60)<br/>dodger(0.60)", "pred answer": "yankees", "question_id": 5344485, "best approach": "image", "verif answer": "dodger", "anno approach": "wiki, concept, image", "verif wiki answer": "astros(0.7224)", "verif concept answer": "houston astros(0.5866)", "verif image answer": "dodger(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534448.jpg"}, {"question": "what type of motorcycles are these", "gt answer": "harleys(1.00)<br/>harley(0.60)<br/>harley davidson(0.60)", "pred answer": "chopper", "question_id": 4513645, "best approach": "wiki, concept", "verif answer": "harley", "anno approach": "wiki, concept, image", "verif wiki answer": "harley davidson(0.7120)", "verif concept answer": "harley(0.6455)", "verif image answer": "bmw(0.6191)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451364.jpg"}, {"question": "which popular fairy tale does this image remind you of", "gt answer": "sleep beauty(1.00)<br/>red(0.60)", "pred answer": "goldilocks and 3 bears", "question_id": 5656635, "best approach": "wiki, concept, image", "verif answer": "sleep beauty", "anno approach": "wiki, concept, image", "verif wiki answer": "sleep beauty(0.5299)", "verif concept answer": "sleep beauty(0.6577)", "verif image answer": "sleep beauty(0.5058)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000565663.jpg"}, {"question": "which finger is the child holding up", "gt answer": "index(1.00)", "pred answer": "thumb", "question_id": 5069795, "best approach": "", "verif answer": "pinkie", "anno approach": "wiki, concept, image", "verif wiki answer": "tongue(0.5971)", "verif concept answer": "pinkie(0.5951)", "verif image answer": "tongue(0.5951)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506979.jpg"}, {"question": "what type of dogs are these", "gt answer": "german shepard(1.00)", "pred answer": "chihuahua", "question_id": 4371735, "best approach": "", "verif answer": "chihuahua", "anno approach": "wiki, concept, image", "verif wiki answer": "chihuahua(0.7139)", "verif concept answer": "german shepherd(0.7178)", "verif image answer": "cat(0.6955)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437173.jpg"}, {"question": "how long must the food in this photo be baked", "gt answer": "15 minutes(1.00)<br/>30 minutes(0.60)<br/>1 hour(0.60)", "pred answer": "10 minutes", "question_id": 3630785, "best approach": "wiki, image", "verif answer": "10 minutes", "anno approach": "wiki, concept, image", "verif wiki answer": "15 minutes(0.6558)", "verif concept answer": "10 minutes(0.6008)", "verif image answer": "15 minutes(0.6132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363078.jpg"}, {"question": "what does the temperature look like it would be in this photo", "gt answer": "75(1.00)<br/>warm(0.60)", "pred answer": "cool", "question_id": 2932525, "best approach": "wiki, concept, image", "verif answer": "warm", "anno approach": "wiki, concept, image", "verif wiki answer": "warm(0.6941)", "verif concept answer": "warm(0.6502)", "verif image answer": "warm(0.6437)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293252.jpg"}, {"question": "where is the biggest comic book version of this picture held annually", "gt answer": "san diego(1.00)<br/>california(0.60)", "pred answer": "library", "question_id": 2609065, "best approach": "concept, image", "verif answer": "california", "anno approach": "wiki, concept, image", "verif wiki answer": "california(0.6768)", "verif concept answer": "san diego(0.5928)", "verif image answer": "san diego(0.7064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260906.jpg"}, {"question": "which type of vehicle is the silver", "gt answer": "van(1.00)<br/>taxi(0.60)<br/>mini cooper(0.60)<br/>honda(0.60)", "pred answer": "car", "question_id": 618225, "best approach": "", "verif answer": "van", "anno approach": "wiki, concept, image", "verif wiki answer": "cargo van(0.7259)", "verif concept answer": "cargo van(0.6917)", "verif image answer": "cargo van(0.7195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061822.jpg"}, {"question": "what are these part of", "gt answer": "collection(1.00)<br/>bedroom(0.60)<br/>room(0.60)", "pred answer": "table", "question_id": 3399665, "best approach": "wiki, concept, image", "verif answer": "room", "anno approach": "wiki, concept, image", "verif wiki answer": "bedroom(0.6969)", "verif concept answer": "bedroom(0.7176)", "verif image answer": "bedroom(0.6451)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000339966.jpg"}, {"question": "name the type of boat the person in the picture is riding", "gt answer": "paddleboard(1.00)<br/>paddle(0.60)<br/>surf board(0.60)<br/>row(0.60)", "pred answer": "kayak", "question_id": 4958725, "best approach": "", "verif answer": "surfboard", "anno approach": "wiki, concept, image", "verif wiki answer": "surfboard(0.6526)", "verif concept answer": "surfboard(0.6949)", "verif image answer": "surfboard(0.7156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495872.jpg"}, {"question": "is this a wild or tamed horse", "gt answer": "wild(1.00)", "pred answer": "domesticated", "question_id": 615065, "best approach": "wiki, image", "verif answer": "wild", "anno approach": "wiki, concept, image", "verif wiki answer": "wild(0.7286)", "verif concept answer": "predator(0.7063)", "verif image answer": "wild(0.6524)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061506.jpg"}, {"question": "from what school is this prom photo from", "gt answer": "high school(1.00)<br/>high(0.60)", "pred answer": "college", "question_id": 4049905, "best approach": "image", "verif answer": "college", "anno approach": "wiki, concept, image", "verif wiki answer": "college(0.7164)", "verif concept answer": "college(0.6500)", "verif image answer": "high school(0.7125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404990.jpg"}, {"question": "why people stand on the platform", "gt answer": "wait(1.00)", "pred answer": "train", "question_id": 3569725, "best approach": "", "verif answer": "wait", "anno approach": "wiki, concept, image", "verif wiki answer": "rest(0.5747)", "verif concept answer": "rest(0.5680)", "verif image answer": "dry(0.6220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356972.jpg"}, {"question": "in this country what numbers do you dial for emergencies", "gt answer": "911(1.00)", "pred answer": "english", "question_id": 36025, "best approach": "concept, image", "verif answer": "england", "anno approach": "wiki, concept, image", "verif wiki answer": "20th(0.7257)", "verif concept answer": "911(0.6884)", "verif image answer": "911(0.5660)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003602.jpg"}, {"question": "", "gt answer": "baseball stadium(0.60)<br/>yankees(0.60)", "pred answer": "baseball field", "question_id": 5549435, "best approach": "", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "red sox(0.5903)", "verif concept answer": "red sox(0.5800)", "verif image answer": "red sox(0.6590)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554943.jpg"}, {"question": "the name of the bus contains the name of a character from which acclaimed book series", "gt answer": "lord of ring(1.00)", "pred answer": "rosa park", "question_id": 1003315, "best approach": "concept", "verif answer": "double decker", "anno approach": "wiki, concept, image", "verif wiki answer": "double decker(0.7296)", "verif concept answer": "lord of ring(0.7261)", "verif image answer": "double decker(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100331.jpg"}, {"question": "what is the model of the water craft being used", "gt answer": "chevy(1.00)<br/>boat(0.60)", "pred answer": "row", "question_id": 5221005, "best approach": "wiki, concept, image", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "boat(0.7254)", "verif concept answer": "boat(0.5879)", "verif image answer": "boat(0.6742)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522100.jpg"}, {"question": "where is this", "gt answer": "colorado(1.00)", "pred answer": "new york city", "question_id": 167205, "best approach": "", "verif answer": "new york city", "anno approach": "wiki, concept, image", "verif wiki answer": "alaska(0.6963)", "verif concept answer": "new york city(0.6581)", "verif image answer": "alaska(0.6841)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016720.jpg"}, {"question": "what are these people sitting on", "gt answer": "step(1.00)<br/>stair(1.00)", "pred answer": "bench", "question_id": 3246265, "best approach": "wiki", "verif answer": "step", "anno approach": "wiki, concept, image", "verif wiki answer": "step(0.7148)", "verif concept answer": "fence(0.7195)", "verif image answer": "ladder(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324626.jpg"}, {"question": "is this hairstyle easy to do or does it take a long time", "gt answer": "easy(1.00)", "pred answer": "difficult", "question_id": 2781745, "best approach": "", "verif answer": "very", "anno approach": "wiki, concept, image", "verif wiki answer": "not at all(0.7289)", "verif concept answer": "not at all(0.6821)", "verif image answer": "not at all(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278174.jpg"}, {"question": "how are these riders being unsafe while riding the horses", "gt answer": "no helmet(1.00)", "pred answer": "bridle", "question_id": 2654535, "best approach": "", "verif answer": "saddle", "anno approach": "wiki, concept, image", "verif wiki answer": "saddle(0.7099)", "verif concept answer": "saddle(0.5921)", "verif image answer": "saddle(0.5317)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265453.jpg"}, {"question": "what are the hazards involved in this activity", "gt answer": "fall(1.00)", "pred answer": "wind", "question_id": 2406895, "best approach": "", "verif answer": "hurricane", "anno approach": "wiki, concept, image", "verif wiki answer": "drown(0.6894)", "verif concept answer": "drown(0.6768)", "verif image answer": "dive(0.6576)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240689.jpg"}, {"question": "which city are the two people posed in", "gt answer": "san francisco(1.00)<br/>new york city(0.60)", "pred answer": "seattle", "question_id": 2090895, "best approach": "concept", "verif answer": "new york city", "anno approach": "wiki, concept, image", "verif wiki answer": "new york city(0.6992)", "verif concept answer": "san francisco(0.6119)", "verif image answer": "new york city(0.6747)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209089.jpg"}, {"question": "what is the best type of potato to use for these", "gt answer": "russet(1.00)<br/>red(0.60)<br/>idaho(0.60)", "pred answer": "fry", "question_id": 4691425, "best approach": "", "verif answer": "white", "anno approach": "wiki, concept, image", "verif wiki answer": "white(0.6842)", "verif concept answer": "white(0.7257)", "verif image answer": "white(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469142.jpg"}, {"question": "why do kids stare", "gt answer": "curious(1.00)", "pred answer": "play", "question_id": 5426515, "best approach": "image", "verif answer": "sad", "anno approach": "wiki, concept, image", "verif wiki answer": "sad(0.7233)", "verif concept answer": "hot(0.6509)", "verif image answer": "curious(0.7030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542651.jpg"}, {"question": "what shapes are in the rug", "gt answer": "square(1.00)", "pred answer": "checkered", "question_id": 3233875, "best approach": "image", "verif answer": "square", "anno approach": "wiki, concept, image", "verif wiki answer": "diamond(0.6852)", "verif concept answer": "rectangle(0.6357)", "verif image answer": "square(0.6977)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323387.jpg"}, {"question": "what is the name of the technique the surfer is carrying out", "gt answer": "paddle(1.00)<br/>swim(0.60)", "pred answer": "drown", "question_id": 179355, "best approach": "concept", "verif answer": "swim", "anno approach": "wiki, concept, image", "verif wiki answer": "row(0.7284)", "verif concept answer": "paddle(0.6171)", "verif image answer": "row(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000017935.jpg"}, {"question": "", "gt answer": "he jumped(0.60)<br/>jump(0.60)<br/>jumped(0.60)", "pred answer": "play tennis", "question_id": 1396795, "best approach": "", "verif answer": "jumped", "anno approach": "wiki, concept, image", "verif wiki answer": "fall(0.5757)", "verif concept answer": "fall(0.5828)", "verif image answer": "by skateboard(0.5497)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139679.jpg"}, {"question": "what type of athletes are these", "gt answer": "jockey(1.00)<br/>polo(0.60)", "pred answer": "police", "question_id": 139795, "best approach": "", "verif answer": "jockey", "anno approach": "wiki, concept, image", "verif wiki answer": "cowboy(0.7016)", "verif concept answer": "horseback rider(0.6417)", "verif image answer": "cowboy(0.7021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013979.jpg"}, {"question": "what is the underground version of this transportation called", "gt answer": "subway(1.00)", "pred answer": "commuter", "question_id": 3148775, "best approach": "", "verif answer": "subway", "anno approach": "wiki, concept, image", "verif wiki answer": "train(0.7014)", "verif concept answer": "train(0.6178)", "verif image answer": "american(0.7154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314877.jpg"}, {"question": "what habitat are these animals most commonly found in", "gt answer": "desert(1.00)<br/>plain(0.60)<br/>zoo(0.60)<br/>grassland(0.60)", "pred answer": "savannah", "question_id": 2330225, "best approach": "image", "verif answer": "grassland", "anno approach": "wiki, concept, image", "verif wiki answer": "plain(0.7113)", "verif concept answer": "plain(0.7167)", "verif image answer": "desert(0.6452)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233022.jpg"}, {"question": "what is material is the surface that the man is standing on made of", "gt answer": "asphalt(1.00)<br/>wood(1.00)", "pred answer": "concrete", "question_id": 5428205, "best approach": "image", "verif answer": "concrete", "anno approach": "wiki, concept, image", "verif wiki answer": "concrete(0.7273)", "verif concept answer": "concrete(0.7163)", "verif image answer": "asphalt(0.7147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542820.jpg"}, {"question": "what language is this street sign in", "gt answer": "german(1.00)", "pred answer": "english", "question_id": 516525, "best approach": "wiki", "verif answer": "english", "anno approach": "wiki, concept, image", "verif wiki answer": "german(0.6223)", "verif concept answer": "english(0.6831)", "verif image answer": "english(0.6640)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000051652.jpg"}, {"question": "the writing on this shirt indicate this man is a member of what club", "gt answer": "newspaper(1.00)<br/>harley(0.60)", "pred answer": "business", "question_id": 2255845, "best approach": "wiki", "verif answer": "harley davidson", "anno approach": "wiki, concept, image", "verif wiki answer": "newspaper(0.7145)", "verif concept answer": "harley davidson(0.7182)", "verif image answer": "harley davidson(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225584.jpg"}, {"question": "is this boy almost done with his meal or is he still hungry", "gt answer": "hungry(1.00)", "pred answer": "healthy", "question_id": 357075, "best approach": "wiki", "verif answer": "hungry", "anno approach": "wiki, concept, image", "verif wiki answer": "hungry(0.7287)", "verif concept answer": "eat(0.7065)", "verif image answer": "vegetarian(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000035707.jpg"}, {"question": "is this more likely a snapshot or a poised picture", "gt answer": "snapshot(1.00)", "pred answer": "candid", "question_id": 4148875, "best approach": "wiki", "verif answer": "selfie", "anno approach": "wiki, concept, image", "verif wiki answer": "snapshot(0.6800)", "verif concept answer": "move(0.6670)", "verif image answer": "facebook(0.6664)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000414887.jpg"}, {"question": "what is the name of the store", "gt answer": "7 eleven(1.00)", "pred answer": "super fish", "question_id": 5186495, "best approach": "", "verif answer": "coca cola", "anno approach": "wiki, concept, image", "verif wiki answer": "coca cola(0.5136)", "verif concept answer": "coca cola(0.5472)", "verif image answer": "coca cola(0.7246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518649.jpg"}, {"question": "what is a common term used for when this happens", "gt answer": "wipeout(1.00)", "pred answer": "surf", "question_id": 1227985, "best approach": "", "verif answer": "drown", "anno approach": "wiki, concept, image", "verif wiki answer": "drown(0.7304)", "verif concept answer": "drown(0.7031)", "verif image answer": "death(0.7098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122798.jpg"}, {"question": "what famous actress is this", "gt answer": "reese witherspoon(1.00)", "pred answer": "justin bieber", "question_id": 3107515, "best approach": "wiki", "verif answer": "ponytail", "anno approach": "wiki, concept, image", "verif wiki answer": "reese witherspoon(0.6575)", "verif concept answer": "van(0.5117)", "verif image answer": "ponytail(0.7197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310751.jpg"}, {"question": "what is the average passenger capacity of this vehicle", "gt answer": "fifty(1.00)<br/>50(0.60)<br/>200(0.60)", "pred answer": "20", "question_id": 1985065, "best approach": "image", "verif answer": "100", "anno approach": "wiki, concept, image", "verif wiki answer": "100(0.6760)", "verif concept answer": "100(0.6322)", "verif image answer": "200(0.6822)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198506.jpg"}, {"question": "", "gt answer": "collie(0.60)", "pred answer": "mutt", "question_id": 295795, "best approach": "", "verif answer": "mutt", "anno approach": "wiki, concept, image", "verif wiki answer": "beagle(0.5834)", "verif concept answer": "beagle(0.6313)", "verif image answer": "beagle(0.6560)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029579.jpg"}, {"question": "how ripe are the bananas", "gt answer": "very ripe(1.00)<br/>unripe(0.60)<br/>medium(0.60)", "pred answer": "very", "question_id": 4969185, "best approach": "image", "verif answer": "boiled", "anno approach": "wiki, concept, image", "verif wiki answer": "boiled(0.5154)", "verif concept answer": "large(0.5667)", "verif image answer": "unripe(0.6667)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496918.jpg"}, {"question": "what tools are needed for this operation", "gt answer": "screwdriver(1.00)", "pred answer": "scissor", "question_id": 2677155, "best approach": "concept", "verif answer": "tow", "anno approach": "wiki, concept, image", "verif wiki answer": "tow(0.7176)", "verif concept answer": "screwdriver(0.7098)", "verif image answer": "play(0.6398)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000267715.jpg"}, {"question": "what was used to make those furnitures", "gt answer": "wood(1.00)", "pred answer": "straw", "question_id": 3209875, "best approach": "", "verif answer": "wicker", "anno approach": "wiki, concept, image", "verif wiki answer": "cardboard(0.7056)", "verif concept answer": "paper(0.7165)", "verif image answer": "plastic(0.6830)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320987.jpg"}, {"question": "which team is playing", "gt answer": "minnesota twin(1.00)<br/>cub(0.60)<br/>baseball(0.60)<br/>chicago(0.60)", "pred answer": "yankees", "question_id": 2413455, "best approach": "image", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "yankees(0.6896)", "verif concept answer": "yankees(0.6514)", "verif image answer": "minnesota twin(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241345.jpg"}, {"question": "how are these figures standing on the water", "gt answer": "surfboard(1.00)", "pred answer": "paddle board", "question_id": 263105, "best approach": "concept", "verif answer": "surfboard", "anno approach": "wiki, concept, image", "verif wiki answer": "float(0.7269)", "verif concept answer": "surfboard(0.7035)", "verif image answer": "wood(0.5399)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000026310.jpg"}, {"question": "what types of hairs are pictured here in sets of 3", "gt answer": "whisker(1.00)", "pred answer": "pony tail", "question_id": 1838445, "best approach": "wiki, concept", "verif answer": "beard", "anno approach": "wiki, concept, image", "verif wiki answer": "whisker(0.6845)", "verif concept answer": "whisker(0.7202)", "verif image answer": "mustache(0.7162)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183844.jpg"}, {"question": "when would i eat this", "gt answer": "dinner(1.00)<br/>lunch(0.60)", "pred answer": "salad", "question_id": 693025, "best approach": "concept, image", "verif answer": "lunch", "anno approach": "wiki, concept, image", "verif wiki answer": "lunch(0.7252)", "verif concept answer": "dinner(0.6958)", "verif image answer": "dinner(0.7127)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069302.jpg"}, {"question": "what kind of dog is on the surfboard", "gt answer": "lab(1.00)<br/>labrador(0.60)<br/>brown(0.60)<br/>greyhound(0.60)", "pred answer": "pitbull", "question_id": 2692285, "best approach": "", "verif answer": "greyhound", "anno approach": "wiki, concept, image", "verif wiki answer": "golden retriever(0.7200)", "verif concept answer": "golden retriever(0.7244)", "verif image answer": "golden retriever(0.6974)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269228.jpg"}, {"question": "where do the steps lead", "gt answer": "up(1.00)", "pred answer": "house", "question_id": 4320195, "best approach": "", "verif answer": "ship", "anno approach": "wiki, concept, image", "verif wiki answer": "united parcel service(0.6325)", "verif concept answer": "ship(0.6307)", "verif image answer": "ship(0.6410)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432019.jpg"}, {"question": "describe what kind of team sport or individual sport the person in the photo is playing", "gt answer": "polo(1.00)<br/>equestrian(1.00)<br/>rugby(0.60)", "pred answer": "cowboy", "question_id": 2453515, "best approach": "wiki, concept", "verif answer": "polo", "anno approach": "wiki, concept, image", "verif wiki answer": "equestrian(0.6920)", "verif concept answer": "polo(0.6622)", "verif image answer": "horse race(0.5199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245351.jpg"}, {"question": "is the weather sunny or rainy today", "gt answer": "rainy(1.00)", "pred answer": "rain", "question_id": 275395, "best approach": "image", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "no wind(0.7302)", "verif concept answer": "winter(0.6965)", "verif image answer": "rainy(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027539.jpg"}, {"question": "what does the state of texas have in common with the design seen on this plane", "gt answer": "star(1.00)", "pred answer": "color", "question_id": 4484615, "best approach": "concept", "verif answer": "star", "anno approach": "wiki, concept, image", "verif wiki answer": "clock(0.6953)", "verif concept answer": "star(0.6869)", "verif image answer": "clock(0.6626)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448461.jpg"}, {"question": "what model of bike is in the picture", "gt answer": "dirt bike(1.00)<br/>dirt(0.60)<br/>bmx(0.60)<br/>motocross(0.60)", "pred answer": "honda", "question_id": 1747055, "best approach": "wiki, concept, image", "verif answer": "motorbike", "anno approach": "wiki, concept, image", "verif wiki answer": "dirt bike(0.7247)", "verif concept answer": "dirt bike(0.6950)", "verif image answer": "dirt bike(0.7211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174705.jpg"}, {"question": "what 's the name of the character on the gentleman 's shirt", "gt answer": "stewie(1.00)", "pred answer": "friend", "question_id": 3630285, "best approach": "", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "looney tune(0.7301)", "verif concept answer": "looney tune(0.7287)", "verif image answer": "looney tune(0.7271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363028.jpg"}, {"question": "what breed of dog is that", "gt answer": "terrier(1.00)<br/>cat(0.60)<br/>collie(0.60)<br/>chihuahua(0.60)", "pred answer": "pug", "question_id": 1344905, "best approach": "concept", "verif answer": "terrier", "anno approach": "wiki, concept, image", "verif wiki answer": "collie(0.7109)", "verif concept answer": "terrier(0.7108)", "verif image answer": "cat(0.6070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134490.jpg"}, {"question": "what kind of organic matter is shown in this picture", "gt answer": "plant(1.00)<br/>flower(0.60)<br/>leaf(0.60)", "pred answer": "tree", "question_id": 4079585, "best approach": "", "verif answer": "grass", "anno approach": "wiki, concept, image", "verif wiki answer": "grass(0.7286)", "verif concept answer": "grass(0.7163)", "verif image answer": "grass(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407958.jpg"}, {"question": "why is this an atypical look for someone wearing this makeup", "gt answer": "clown(1.00)", "pred answer": "posed", "question_id": 1795265, "best approach": "", "verif answer": "run", "anno approach": "wiki, concept, image", "verif wiki answer": "run(0.6735)", "verif concept answer": "run(0.7270)", "verif image answer": "circus(0.7108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000179526.jpg"}, {"question": "what is this type of food set up called", "gt answer": "buffet(1.00)", "pred answer": "vegetarian", "question_id": 4644985, "best approach": "", "verif answer": "taco", "anno approach": "wiki, concept, image", "verif wiki answer": "taco(0.7143)", "verif concept answer": "hotdog(0.7144)", "verif image answer": "taco(0.7087)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464498.jpg"}, {"question": "in what part of the playing field is this glove lying", "gt answer": "outfield(1.00)", "pred answer": "second", "question_id": 5578555, "best approach": "", "verif answer": "field", "anno approach": "wiki, concept, image", "verif wiki answer": "field(0.6546)", "verif concept answer": "shortstop(0.6392)", "verif image answer": "shortstop(0.7190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557855.jpg"}, {"question": "what kind of truck is that", "gt answer": "dump(1.00)<br/>garbage(0.60)<br/>trash(0.60)<br/>flatbed(0.60)", "pred answer": "semi", "question_id": 577705, "best approach": "", "verif answer": "garbage truck", "anno approach": "wiki, concept, image", "verif wiki answer": "garbage truck(0.6995)", "verif concept answer": "garbage truck(0.7255)", "verif image answer": "garbage truck(0.7155)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000057770.jpg"}, {"question": "how is this water vehicle powered", "gt answer": "motor(1.00)<br/>oar(0.60)", "pred answer": "diesel", "question_id": 4038305, "best approach": "wiki, concept", "verif answer": "engine", "anno approach": "wiki, concept, image", "verif wiki answer": "oar(0.7057)", "verif concept answer": "oar(0.6944)", "verif image answer": "paddle(0.5746)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403830.jpg"}, {"question": "was this pizza baked in a stone or conventional oven", "gt answer": "conventional(1.00)<br/>bake(0.60)<br/>stone(0.60)", "pred answer": "french", "question_id": 1399585, "best approach": "wiki, concept, image", "verif answer": "conventional", "anno approach": "wiki, concept, image", "verif wiki answer": "conventional(0.7218)", "verif concept answer": "conventional(0.7236)", "verif image answer": "conventional(0.5468)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139958.jpg"}, {"question": "what flying device could be used to take a photo at this angle", "gt answer": "drone(1.00)<br/>camera(0.60)<br/>helicopter(0.60)", "pred answer": "phone", "question_id": 4762765, "best approach": "wiki, concept", "verif answer": "helicopter", "anno approach": "wiki, concept, image", "verif wiki answer": "helicopter(0.6911)", "verif concept answer": "helicopter(0.6425)", "verif image answer": "bee(0.7058)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476276.jpg"}, {"question": "what do these animals eat", "gt answer": "mice(1.00)<br/>worm(0.60)<br/>rodent(0.60)<br/>bug(0.60)", "pred answer": "plant", "question_id": 4318165, "best approach": "concept, image", "verif answer": "seed", "anno approach": "wiki, concept, image", "verif wiki answer": "seed(0.7281)", "verif concept answer": "rodent(0.7037)", "verif image answer": "rodent(0.6719)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431816.jpg"}, {"question": "the mountain is made from what material", "gt answer": "rock(1.00)<br/>granite(0.60)", "pred answer": "stone", "question_id": 2260535, "best approach": "wiki", "verif answer": "rock", "anno approach": "wiki, concept, image", "verif wiki answer": "rock(0.6978)", "verif concept answer": "limestone(0.6906)", "verif image answer": "stone(0.6360)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226053.jpg"}, {"question": "what are these large boats here for", "gt answer": "cargo(1.00)<br/>ship(0.60)", "pred answer": "sail", "question_id": 3190705, "best approach": "concept", "verif answer": "cargo", "anno approach": "wiki, concept, image", "verif wiki answer": "freight(0.7133)", "verif concept answer": "cargo(0.6290)", "verif image answer": "tanker(0.6617)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319070.jpg"}, {"question": "what is this surfing move called", "gt answer": "ride wave(1.00)<br/>surf(0.60)", "pred answer": "flip", "question_id": 2829525, "best approach": "wiki", "verif answer": "surf", "anno approach": "wiki, concept, image", "verif wiki answer": "surf(0.7293)", "verif concept answer": "crouch(0.6961)", "verif image answer": "crouch(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282952.jpg"}, {"question": "this type of animal is famous for seeing under what sort of conditions", "gt answer": "dark(1.00)<br/>night(0.60)", "pred answer": "domestic", "question_id": 884995, "best approach": "wiki, concept, image", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "night(0.6923)", "verif concept answer": "night(0.6355)", "verif image answer": "night(0.6479)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088499.jpg"}, {"question": "what breed are these dogs", "gt answer": "bulldog(0.60)<br/>boxer(1.00)", "pred answer": "mutt", "question_id": 5346905, "best approach": "", "verif answer": "terrier", "anno approach": "wiki, concept, image", "verif wiki answer": "terrier(0.7074)", "verif concept answer": "terrier(0.7209)", "verif image answer": "terrier(0.6413)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534690.jpg"}, {"question": "what does a hostess do that sounds exactly like what this man is doing", "gt answer": "serve(1.00)", "pred answer": "surf up", "question_id": 660035, "best approach": "", "verif answer": "serve", "anno approach": "wiki, concept, image", "verif wiki answer": "hit ball(0.7250)", "verif concept answer": "backhand(0.7274)", "verif image answer": "backhand(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000066003.jpg"}, {"question": "what war was this plane used in", "gt answer": "ww2(1.00)", "pred answer": "wwii", "question_id": 5685076, "best approach": "", "verif answer": "wwii", "anno approach": "wiki, concept, image", "verif wiki answer": "world war 2(0.7059)", "verif concept answer": "wwii(0.6776)", "verif image answer": "airshow(0.6786)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568507.jpg"}, {"question": "what show is being watched", "gt answer": "law and order(1.00)", "pred answer": "american idol", "question_id": 3973155, "best approach": "", "verif answer": "game", "anno approach": "wiki, concept, image", "verif wiki answer": "score(0.6688)", "verif concept answer": "dumbo(0.7033)", "verif image answer": "dumbo(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397315.jpg"}, {"question": "where do you find the pattern around the images", "gt answer": "film(1.00)", "pred answer": "square", "question_id": 720025, "best approach": "wiki, concept", "verif answer": "square", "anno approach": "wiki, concept, image", "verif wiki answer": "film(0.6757)", "verif concept answer": "film(0.6908)", "verif image answer": "square(0.6992)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072002.jpg"}, {"question": "what ingredients were used to make this food", "gt answer": "broccoli and cheese(1.00)<br/>cheese(0.60)", "pred answer": "spinach", "question_id": 1561335, "best approach": "image", "verif answer": "dough spinach cheese", "anno approach": "wiki, concept, image", "verif wiki answer": "onion(0.7151)", "verif concept answer": "onion(0.7141)", "verif image answer": "broccoli and cheese(0.7177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000156133.jpg"}, {"question": "is this an example of human bonding or ignoring", "gt answer": "bond(1.00)", "pred answer": "mad", "question_id": 2043865, "best approach": "image", "verif answer": "hug", "anno approach": "wiki, concept, image", "verif wiki answer": "hug(0.7266)", "verif concept answer": "hug(0.5257)", "verif image answer": "bond(0.6027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000204386.jpg"}, {"question": "what type of food are they serving", "gt answer": "cafeteria(1.00)<br/>breakfast(0.60)<br/>chinese(0.60)<br/>fast food(0.60)", "pred answer": "hibachi", "question_id": 500615, "best approach": "wiki, concept, image", "verif answer": "fast food", "anno approach": "wiki, concept, image", "verif wiki answer": "fast food(0.5416)", "verif concept answer": "fast food(0.5486)", "verif image answer": "fast food(0.6636)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050061.jpg"}, {"question": "what city is this in", "gt answer": "big city(1.00)<br/>san francisco(0.60)", "pred answer": "new york", "question_id": 3125405, "best approach": "image", "verif answer": "seattle", "anno approach": "wiki, concept, image", "verif wiki answer": "seattle(0.7233)", "verif concept answer": "seattle(0.7016)", "verif image answer": "big city(0.6795)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312540.jpg"}, {"question": "what type of knot is tied here", "gt answer": "windsor(1.00)<br/>knot(0.60)", "pred answer": "tie", "question_id": 2395865, "best approach": "wiki, concept, image", "verif answer": "windsor", "anno approach": "wiki, concept, image", "verif wiki answer": "windsor(0.7281)", "verif concept answer": "windsor(0.7239)", "verif image answer": "windsor(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000239586.jpg"}, {"question": "what is being pulled on the water", "gt answer": "skier(1.00)<br/>person(1.00)", "pred answer": "boat", "question_id": 1643105, "best approach": "image", "verif answer": "people", "anno approach": "wiki, concept, image", "verif wiki answer": "ski(0.7013)", "verif concept answer": "ski(0.7201)", "verif image answer": "person(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000164310.jpg"}, {"question": "what plants were grown to create this hay mixture", "gt answer": "wheat(1.00)<br/>corn(0.60)<br/>grass(0.60)", "pred answer": "lavender", "question_id": 895635, "best approach": "concept", "verif answer": "grass", "anno approach": "wiki, concept, image", "verif wiki answer": "grass(0.7128)", "verif concept answer": "wheat(0.7025)", "verif image answer": "grain(0.5820)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089563.jpg"}, {"question": "in which cradle of civilization were animals of this type considered to be sacred", "gt answer": "egypt(1.00)<br/>tennis(0.60)", "pred answer": "africa", "question_id": 2226595, "best approach": "image", "verif answer": "america", "anno approach": "wiki, concept, image", "verif wiki answer": "america(0.6770)", "verif concept answer": "america(0.6841)", "verif image answer": "egypt(0.6668)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222659.jpg"}, {"question": "what do you use this item for", "gt answer": "dry hair(1.00)<br/>dry(0.60)<br/>sing(0.60)", "pred answer": "brush hair", "question_id": 824805, "best approach": "wiki, concept, image", "verif answer": "marriage", "anno approach": "wiki, concept, image", "verif wiki answer": "dry hair(0.6738)", "verif concept answer": "dry hair(0.7019)", "verif image answer": "dry hair(0.6909)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082480.jpg"}, {"question": "what material are those drapes made out of", "gt answer": "lace(1.00)<br/>cloth(0.60)", "pred answer": "nylon", "question_id": 2362435, "best approach": "concept", "verif answer": "silk", "anno approach": "wiki, concept, image", "verif wiki answer": "paper(0.6884)", "verif concept answer": "lace(0.7121)", "verif image answer": "paper(0.7106)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236243.jpg"}, {"question": "because it does not come from an electrical source the light in this room is said to be what kind of light", "gt answer": "natural(1.00)<br/>sunlight(1.00)", "pred answer": "lamp", "question_id": 1168315, "best approach": "", "verif answer": "ceiling", "anno approach": "wiki, concept, image", "verif wiki answer": "ceiling(0.7242)", "verif concept answer": "ceiling(0.6454)", "verif image answer": "sun(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116831.jpg"}, {"question": "which famous characters might you see in this place", "gt answer": "mickey mouse(1.00)<br/>disney(0.60)<br/>cinderella(0.60)", "pred answer": "0", "question_id": 1603255, "best approach": "wiki, concept, image", "verif answer": "garfield", "anno approach": "wiki, concept, image", "verif wiki answer": "mickey mouse(0.7295)", "verif concept answer": "mickey mouse(0.7289)", "verif image answer": "mickey mouse(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160325.jpg"}, {"question": "what kind of minty herb might this animal enjoy eating", "gt answer": "catnip(1.00)", "pred answer": "aloe", "question_id": 3381345, "best approach": "", "verif answer": "fiber", "anno approach": "wiki, concept, image", "verif wiki answer": "vegan(0.6483)", "verif concept answer": "latte(0.6629)", "verif image answer": "vegan(0.7052)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338134.jpg"}, {"question": "name a vegetable on this pizza", "gt answer": "olive(1.00)<br/>olives(0.60)<br/>onion(0.60)", "pred answer": "tomato", "question_id": 2614965, "best approach": "wiki", "verif answer": "pepper", "anno approach": "wiki, concept, image", "verif wiki answer": "olive(0.5359)", "verif concept answer": "olives(0.6132)", "verif image answer": "onion(0.6997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261496.jpg"}, {"question": "what is the man carrying", "gt answer": "suitcase(1.00)<br/>case(0.60)", "pred answer": "luggage", "question_id": 2910095, "best approach": "", "verif answer": "luggage", "anno approach": "wiki, concept, image", "verif wiki answer": "luggage(0.7261)", "verif concept answer": "luggage(0.7227)", "verif image answer": "luggage(0.7035)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291009.jpg"}, {"question": "what is the subject of the books", "gt answer": "tattoo(1.00)", "pred answer": "movie", "question_id": 1536385, "best approach": "wiki, concept", "verif answer": "beard", "anno approach": "wiki, concept, image", "verif wiki answer": "tattoo(0.5101)", "verif concept answer": "tattoo(0.5560)", "verif image answer": "beard(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153638.jpg"}, {"question": "what mainstream food chain is known for that drink", "gt answer": "starbucks(1.00)", "pred answer": "french", "question_id": 3730765, "best approach": "wiki, concept", "verif answer": "dunkin donuts", "anno approach": "wiki, concept, image", "verif wiki answer": "starbucks(0.7296)", "verif concept answer": "starbucks(0.7210)", "verif image answer": "coffee cake(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373076.jpg"}, {"question": "what kind of style is this food prepared", "gt answer": "grilled(1.00)<br/>fry(0.60)<br/>comfort(0.60)", "pred answer": "deep dish", "question_id": 425195, "best approach": "image", "verif answer": "deep dish", "anno approach": "wiki, concept, image", "verif wiki answer": "fry(0.6947)", "verif concept answer": "deep dish(0.6774)", "verif image answer": "grilled(0.6999)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042519.jpg"}, {"question": "what is a common stowaway in this product", "gt answer": "spider(1.00)<br/>bug(0.60)", "pred answer": "banana", "question_id": 5013075, "best approach": "concept", "verif answer": "potassium", "anno approach": "wiki, concept, image", "verif wiki answer": "potassium(0.5853)", "verif concept answer": "spider(0.7021)", "verif image answer": "bug(0.7155)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501307.jpg"}, {"question": "what are this flower a symbol of", "gt answer": "love(1.00)", "pred answer": "rose", "question_id": 2263005, "best approach": "wiki, image", "verif answer": "sad", "anno approach": "wiki, concept, image", "verif wiki answer": "love(0.6767)", "verif concept answer": "anger(0.7084)", "verif image answer": "love(0.6880)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226300.jpg"}, {"question": "what is the object leaning agains the pole", "gt answer": "pot(1.00)", "pred answer": "luggage", "question_id": 3730155, "best approach": "", "verif answer": "vase", "anno approach": "wiki, concept, image", "verif wiki answer": "vase(0.6788)", "verif concept answer": "vase(0.7223)", "verif image answer": "overhead(0.6856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373015.jpg"}, {"question": "what sport does the man on stage play", "gt answer": "basketball(1.00)", "pred answer": "volleyball", "question_id": 87465, "best approach": "wiki, concept", "verif answer": "tennis", "anno approach": "wiki, concept, image", "verif wiki answer": "basketball(0.7302)", "verif concept answer": "basketball(0.7303)", "verif image answer": "football(0.6451)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008746.jpg"}, {"question": "which of these fruits contains the least sugar", "gt answer": "lime(1.00)<br/>blueberry(0.60)<br/>apple(0.60)<br/>kiwi(0.60)", "pred answer": "orange", "question_id": 5698515, "best approach": "wiki", "verif answer": "blueberry", "anno approach": "wiki, concept, image", "verif wiki answer": "lime(0.7134)", "verif concept answer": "apple(0.7196)", "verif image answer": "apple(0.6805)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569851.jpg"}, {"question": "what kind of battery does this device use", "gt answer": "lithium(1.00)", "pred answer": "samsung", "question_id": 795525, "best approach": "wiki", "verif answer": "cd", "anno approach": "wiki, concept, image", "verif wiki answer": "lithium(0.6861)", "verif concept answer": "cd(0.6716)", "verif image answer": "candle(0.7121)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079552.jpg"}, {"question": "what breed is this", "gt answer": "pinto(1.00)<br/>horse(0.60)<br/>paint(0.60)", "pred answer": "mustang", "question_id": 2671265, "best approach": "concept", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "paint(0.6826)", "verif concept answer": "pinto(0.6655)", "verif image answer": "horse(0.7078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000267126.jpg"}, {"question": "what would this table be used for", "gt answer": "eat(1.00)<br/>dinner(0.60)<br/>dine(0.60)", "pred answer": "sit", "question_id": 3692175, "best approach": "wiki, concept, image", "verif answer": "eat", "anno approach": "wiki, concept, image", "verif wiki answer": "eat(0.7300)", "verif concept answer": "eat(0.6252)", "verif image answer": "eat(0.6665)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369217.jpg"}, {"question": "what kind of boat in in the picture", "gt answer": "tugboat(1.00)<br/>barge(0.60)<br/>houseboat(0.60)", "pred answer": "freight", "question_id": 3141305, "best approach": "wiki, concept", "verif answer": "houseboat", "anno approach": "wiki, concept, image", "verif wiki answer": "tugboat(0.7259)", "verif concept answer": "tugboat(0.6903)", "verif image answer": "houseboat(0.7166)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314130.jpg"}, {"question": "what light is this", "gt answer": "stop light(1.00)<br/>traffic(1.00)<br/>sunlight(0.60)", "pred answer": "go", "question_id": 3740015, "best approach": "image", "verif answer": "traffic", "anno approach": "wiki, concept, image", "verif wiki answer": "traffic control(0.6462)", "verif concept answer": "traffic control(0.7006)", "verif image answer": "traffic(0.5644)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374001.jpg"}, {"question": "what kind of car", "gt answer": "lexus(1.00)<br/>toyota(0.60)<br/>van(0.60)", "pred answer": "sedan", "question_id": 5226675, "best approach": "wiki", "verif answer": "chevy", "anno approach": "wiki, concept, image", "verif wiki answer": "lexus(0.7017)", "verif concept answer": "nike(0.6932)", "verif image answer": "chevy(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522667.jpg"}, {"question": "why is this man standing behind the player", "gt answer": "look(0.60)<br/>referee(1.00)<br/>coach(0.60)", "pred answer": "score", "question_id": 1464205, "best approach": "wiki, concept", "verif answer": "look", "anno approach": "wiki, concept, image", "verif wiki answer": "look(0.6859)", "verif concept answer": "look(0.6271)", "verif image answer": "batter(0.6684)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146420.jpg"}, {"question": "what is this truck used for", "gt answer": "fuel(1.00)", "pred answer": "transport", "question_id": 3940655, "best approach": "", "verif answer": "oil", "anno approach": "wiki, concept, image", "verif wiki answer": "gas(0.6534)", "verif concept answer": "gas(0.6523)", "verif image answer": "oil(0.6906)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000394065.jpg"}, {"question": "what is the dish in the photo made from", "gt answer": "ceramic(1.00)<br/>plastic(0.60)<br/>glass(0.60)<br/>fish(0.60)", "pred answer": "paper", "question_id": 1298205, "best approach": "wiki, concept, image", "verif answer": "ceramic", "anno approach": "wiki, concept, image", "verif wiki answer": "fish(0.7185)", "verif concept answer": "plastic(0.7271)", "verif image answer": "fish(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000129820.jpg"}, {"question": "what game are they playing", "gt answer": "ping pong(1.00)", "pred answer": "frisbee", "question_id": 1610285, "best approach": "", "verif answer": "us open", "anno approach": "wiki, concept, image", "verif wiki answer": "basketball(0.7270)", "verif concept answer": "basketball(0.6955)", "verif image answer": "salad(0.6788)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161028.jpg"}, {"question": "what does the sign under the stop sign mean", "gt answer": "no park(1.00)", "pred answer": "do not enter", "question_id": 5646825, "best approach": "wiki, concept", "verif answer": "turn", "anno approach": "wiki, concept, image", "verif wiki answer": "no park(0.6683)", "verif concept answer": "no park(0.7053)", "verif image answer": "no turn(0.6928)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564682.jpg"}, {"question": "why is this woman smiling", "gt answer": "giraffe(1.00)<br/>happy(0.60)", "pred answer": "shade", "question_id": 3008815, "best approach": "wiki, image", "verif answer": "shade", "anno approach": "wiki, concept, image", "verif wiki answer": "giraffe(0.7150)", "verif concept answer": "happy(0.7271)", "verif image answer": "giraffe(0.7227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300881.jpg"}, {"question": "what phylum does this animal belong to", "gt answer": "chordate(1.00)<br/>cat(0.60)", "pred answer": "feline", "question_id": 1309985, "best approach": "wiki, concept, image", "verif answer": "cat", "anno approach": "wiki, concept, image", "verif wiki answer": "chordate(0.7227)", "verif concept answer": "chordate(0.7282)", "verif image answer": "chordate(0.7052)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130998.jpg"}, {"question": "what resort is this snowboarder at", "gt answer": "vail(1.00)<br/>aspen(0.60)", "pred answer": "colorado", "question_id": 1572785, "best approach": "concept", "verif answer": "colorado", "anno approach": "wiki, concept, image", "verif wiki answer": "colorado(0.7243)", "verif concept answer": "aspen(0.6904)", "verif image answer": "colorado(0.7032)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157278.jpg"}, {"question": "what sound do i make", "gt answer": "moo(1.00)", "pred answer": "bark", "question_id": 331575, "best approach": "", "verif answer": "bark", "anno approach": "wiki, concept, image", "verif wiki answer": "bark(0.7258)", "verif concept answer": "neigh(0.7302)", "verif image answer": "purr(0.7271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033157.jpg"}, {"question": "what is the job title of the person who uses that tool", "gt answer": "stylist(1.00)", "pred answer": "writer", "question_id": 5424025, "best approach": "concept, image", "verif answer": "account", "anno approach": "wiki, concept, image", "verif wiki answer": "teddy roosevelt(0.5592)", "verif concept answer": "stylist(0.5780)", "verif image answer": "stylist(0.5743)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542402.jpg"}, {"question": "where would you find someone eating this", "gt answer": "party(1.00)<br/>table(0.60)<br/>home(0.60)<br/>restaurant(0.60)", "pred answer": "kitchen", "question_id": 863995, "best approach": "wiki, concept, image", "verif answer": "table", "anno approach": "wiki, concept, image", "verif wiki answer": "table(0.7072)", "verif concept answer": "table(0.6544)", "verif image answer": "home(0.6957)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086399.jpg"}, {"question": "where is this", "gt answer": "alp(1.00)<br/>mountain(0.60)<br/>maine(0.60)", "pred answer": "colorado", "question_id": 1602265, "best approach": "concept", "verif answer": "colorado", "anno approach": "wiki, concept, image", "verif wiki answer": "maine(0.7117)", "verif concept answer": "alp(0.6965)", "verif image answer": "maine(0.7149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160226.jpg"}, {"question": "what do you call a bunch of sheep", "gt answer": "flock(1.00)<br/>herd(0.60)<br/>pack(0.60)", "pred answer": "ram", "question_id": 3703695, "best approach": "wiki, concept, image", "verif answer": "ram", "anno approach": "wiki, concept, image", "verif wiki answer": "flock(0.7289)", "verif concept answer": "flock(0.7218)", "verif image answer": "flock(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370369.jpg"}, {"question": "what product does the company in the back make", "gt answer": "car(1.00)", "pred answer": "motorcycle", "question_id": 1228675, "best approach": "", "verif answer": "motorcycle", "anno approach": "wiki, concept, image", "verif wiki answer": "motorcycle(0.6511)", "verif concept answer": "motorcycle(0.6970)", "verif image answer": "car show(0.6550)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122867.jpg"}, {"question": "what happened to the sheep", "gt answer": "died(1.00)", "pred answer": "fall", "question_id": 4259445, "best approach": "", "verif answer": "eaten", "anno approach": "wiki, concept, image", "verif wiki answer": "eaten(0.7099)", "verif concept answer": "fell(0.7111)", "verif image answer": "bitten(0.7097)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425944.jpg"}, {"question": "where are the kids playing ball", "gt answer": "alley(1.00)<br/>street(1.00)<br/>baseball(0.60)", "pred answer": "park", "question_id": 3019165, "best approach": "concept, image", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "park lot(0.7187)", "verif concept answer": "street(0.6818)", "verif image answer": "alley(0.7103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301916.jpg"}, {"question": "what is the name of this yellow bird", "gt answer": "finch(1.00)<br/>parrot(0.60)", "pred answer": "woodpecker", "question_id": 865765, "best approach": "wiki, concept, image", "verif answer": "toucan", "anno approach": "wiki, concept, image", "verif wiki answer": "finch(0.7293)", "verif concept answer": "finch(0.7123)", "verif image answer": "finch(0.7127)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086576.jpg"}, {"question": "what manufacturing additive causes the lampshade to be this color", "gt answer": "dye(1.00)<br/>plastic(0.60)", "pred answer": "battery", "question_id": 4737255, "best approach": "wiki", "verif answer": "dye", "anno approach": "wiki, concept, image", "verif wiki answer": "dye(0.7254)", "verif concept answer": "paint(0.6993)", "verif image answer": "paper(0.7120)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473725.jpg"}, {"question": "what other sport is closely related to the one shown", "gt answer": "snowboard(1.00)", "pred answer": "ski", "question_id": 1359845, "best approach": "", "verif answer": "slalom", "anno approach": "wiki, concept, image", "verif wiki answer": "lift(0.7252)", "verif concept answer": "slalom(0.7168)", "verif image answer": "slalom(0.6973)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000135984.jpg"}, {"question": "what is the dish named", "gt answer": "pasta(1.00)<br/>noodle(0.60)", "pred answer": "stir fry", "question_id": 2012915, "best approach": "", "verif answer": "ramen", "anno approach": "wiki, concept, image", "verif wiki answer": "rotini(0.7207)", "verif concept answer": "rotini(0.7231)", "verif image answer": "rotini(0.7189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201291.jpg"}, {"question": "how do you make that", "gt answer": "steam(1.00)<br/>boil(0.60)<br/>cook(0.60)", "pred answer": "bake", "question_id": 3907575, "best approach": "wiki, concept, image", "verif answer": "fry", "anno approach": "wiki, concept, image", "verif wiki answer": "boil(0.7042)", "verif concept answer": "cook(0.6198)", "verif image answer": "boil(0.7106)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390757.jpg"}, {"question": "where is this man eating lunch", "gt answer": "dock(1.00)<br/>outside(0.60)<br/>maine(0.60)", "pred answer": "bus stop", "question_id": 505185, "best approach": "wiki, concept, image", "verif answer": "maine", "anno approach": "wiki, concept, image", "verif wiki answer": "dock(0.7303)", "verif concept answer": "dock(0.7158)", "verif image answer": "dock(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050518.jpg"}, {"question": "what is shouted by the umpire when the runner does not reach the base", "gt answer": "out(1.00)", "pred answer": "ball", "question_id": 5339445, "best approach": "", "verif answer": "catch", "anno approach": "wiki, concept, image", "verif wiki answer": "catch(0.7113)", "verif concept answer": "catch(0.6048)", "verif image answer": "catch(0.6949)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000533944.jpg"}, {"question": "what country could these people be in", "gt answer": "kenya(1.00)<br/>africa(1.00)", "pred answer": "america", "question_id": 5581635, "best approach": "wiki", "verif answer": "south africa", "anno approach": "wiki, concept, image", "verif wiki answer": "africa(0.7288)", "verif concept answer": "australia(0.7223)", "verif image answer": "jungle(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558163.jpg"}, {"question": "who is this man hitting the ball to", "gt answer": "opponent(1.00)", "pred answer": "rafael nadal", "question_id": 1263755, "best approach": "", "verif answer": "alexis ohanian", "anno approach": "wiki, concept, image", "verif wiki answer": "tennis(0.6501)", "verif concept answer": "alexis ohanian(0.6688)", "verif image answer": "alexis ohanian(0.7141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126375.jpg"}, {"question": "according to new safety codes what is wrong with this picture", "gt answer": "toaster near sink(1.00)<br/>toaster(0.60)", "pred answer": "clean", "question_id": 4840905, "best approach": "image", "verif answer": "too small", "anno approach": "wiki, concept, image", "verif wiki answer": "too small(0.6558)", "verif concept answer": "toaster(0.7049)", "verif image answer": "toaster near sink(0.5295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484090.jpg"}, {"question": "is it raining or are umbrellas just decorations", "gt answer": "decor(1.00)<br/>umbrella(0.60)", "pred answer": "shade", "question_id": 4827335, "best approach": "wiki, concept, image", "verif answer": "umbrella", "anno approach": "wiki, concept, image", "verif wiki answer": "umbrella(0.7290)", "verif concept answer": "umbrella(0.6594)", "verif image answer": "umbrella(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482733.jpg"}, {"question": "what is attached to the side of the vehicle shown", "gt answer": "sidecar(1.00)<br/>side car(1.00)", "pred answer": "helmet", "question_id": 4909795, "best approach": "wiki, concept", "verif answer": "motorcycle", "anno approach": "wiki, concept, image", "verif wiki answer": "sidecar(0.7254)", "verif concept answer": "sidecar(0.7136)", "verif image answer": "motorcycle(0.7141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490979.jpg"}, {"question": "what is the book about", "gt answer": "mystery(1.00)<br/>wind(0.60)", "pred answer": "embroidery", "question_id": 5471005, "best approach": "", "verif answer": "embroidery", "anno approach": "wiki, concept, image", "verif wiki answer": "embroidery(0.5487)", "verif concept answer": "cry(0.6206)", "verif image answer": "relaxation(0.5022)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000547100.jpg"}, {"question": "before women started to join the work force men like this were thought to be part of what fictitious club that excluded women", "gt answer": "men club(1.00)<br/>boy(0.60)", "pred answer": "friend", "question_id": 4205015, "best approach": "wiki", "verif answer": "boy", "anno approach": "wiki, concept, image", "verif wiki answer": "men club(0.5990)", "verif concept answer": "pixie(0.6210)", "verif image answer": "ponytail(0.5255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420501.jpg"}, {"question": "who is considered one of the best players of this sport ever", "gt answer": "roger federer(1.00)<br/>federer(1.00)", "pred answer": "serena williams", "question_id": 194875, "best approach": "", "verif answer": "rafael nadal", "anno approach": "wiki, concept, image", "verif wiki answer": "rafael nadal(0.7251)", "verif concept answer": "rafael nadal(0.5968)", "verif image answer": "rafael nadal(0.6516)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019487.jpg"}, {"question": "where could you store your china here", "gt answer": "cabinet(1.00)", "pred answer": "library", "question_id": 445835, "best approach": "image", "verif answer": "refrigerator", "anno approach": "wiki, concept, image", "verif wiki answer": "refrigerator(0.7154)", "verif concept answer": "refrigerator(0.6982)", "verif image answer": "cabinet(0.7262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000044583.jpg"}, {"question": "what breed of horse is this", "gt answer": "arabian(1.00)<br/>stallion(0.60)", "pred answer": "mustang", "question_id": 5351415, "best approach": "concept, image", "verif answer": "mustang", "anno approach": "wiki, concept, image", "verif wiki answer": "mustang(0.6882)", "verif concept answer": "stallion(0.6856)", "verif image answer": "stallion(0.7177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535141.jpg"}, {"question": "where were these fruits grown", "gt answer": "tropical climate(1.00)<br/>ground(0.60)<br/>root(0.60)", "pred answer": "tropic", "question_id": 4205235, "best approach": "", "verif answer": "tropic", "anno approach": "wiki, concept, image", "verif wiki answer": "florida(0.6891)", "verif concept answer": "tropic(0.6653)", "verif image answer": "tropic(0.6847)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420523.jpg"}, {"question": "what can be used to shine the wood", "gt answer": "polish(1.00)<br/>oil(0.60)", "pred answer": "light", "question_id": 3801265, "best approach": "", "verif answer": "polish", "anno approach": "wiki, concept, image", "verif wiki answer": "metal(0.7271)", "verif concept answer": "dish(0.7121)", "verif image answer": "dish(0.5226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000380126.jpg"}, {"question": "what kind of food is in the bowl", "gt answer": "cereal(1.00)<br/>tea(1.00)<br/>unhealthy(0.60)", "pred answer": "stir fry", "question_id": 735115, "best approach": "", "verif answer": "popcorn", "anno approach": "wiki, concept, image", "verif wiki answer": "popcorn(0.7097)", "verif concept answer": "popcorn(0.7102)", "verif image answer": "popcorn(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073511.jpg"}, {"question": "what instrument is this person carrying", "gt answer": "guitar(1.00)<br/>amplifier(0.60)", "pred answer": "cellphone", "question_id": 17325, "best approach": "", "verif answer": "microphone", "anno approach": "wiki, concept, image", "verif wiki answer": "horn(0.6310)", "verif concept answer": "pipe(0.7283)", "verif image answer": "microphone(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001732.jpg"}, {"question": "hundreds of years ago people that cleaned brick roof towers or the sort visible here arising from the home 's fireplace were called what", "gt answer": "chimney sweep(1.00)<br/>chicago(0.60)<br/>chimney(0.60)", "pred answer": "200 years", "question_id": 5573355, "best approach": "", "verif answer": "chicago", "anno approach": "wiki, concept, image", "verif wiki answer": "mary poppins(0.6511)", "verif concept answer": "mary poppins(0.5853)", "verif image answer": "residential(0.7177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557335.jpg"}, {"question": "why is someone jumping", "gt answer": "happy(1.00)<br/>excited(0.60)", "pred answer": "accident", "question_id": 19435, "best approach": "wiki, concept", "verif answer": "play", "anno approach": "wiki, concept, image", "verif wiki answer": "happy(0.6950)", "verif concept answer": "happy(0.6299)", "verif image answer": "play(0.7002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001943.jpg"}, {"question": "what spicy condiment goes with this", "gt answer": "wasabi(1.00)<br/>chili(0.60)", "pred answer": "ketchup", "question_id": 5103995, "best approach": "", "verif answer": "ketchup", "anno approach": "wiki, concept, image", "verif wiki answer": "ketchup(0.6934)", "verif concept answer": "ketchup(0.6823)", "verif image answer": "ketchup(0.6861)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510399.jpg"}, {"question": "the shape of this vase is reminiscent of what sort of cup usually silver and often used at weddings", "gt answer": "chalice(1.00)<br/>copper(0.60)", "pred answer": "octagon", "question_id": 5682565, "best approach": "wiki, concept", "verif answer": "metal", "anno approach": "wiki, concept, image", "verif wiki answer": "chalice(0.5453)", "verif concept answer": "chalice(0.6730)", "verif image answer": "aluminium(0.7050)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568256.jpg"}, {"question": "what part of the city could you find these in", "gt answer": "downtown(1.00)<br/>bus stop(1.00)", "pred answer": "city", "question_id": 1426745, "best approach": "wiki, concept", "verif answer": "city", "anno approach": "wiki, concept, image", "verif wiki answer": "bus stop(0.7162)", "verif concept answer": "downtown(0.6901)", "verif image answer": "urban(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142674.jpg"}, {"question": "what can people do with that object on top of the stove", "gt answer": "boil water(1.00)", "pred answer": "bake", "question_id": 5721105, "best approach": "", "verif answer": "clean", "anno approach": "wiki, concept, image", "verif wiki answer": "hold thing(0.6693)", "verif concept answer": "hold thing(0.7113)", "verif image answer": "hold thing(0.7238)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572110.jpg"}, {"question": "what is the green area the animals are in called", "gt answer": "meadow(1.00)<br/>pasture(0.60)<br/>hill(0.60)<br/>grass(0.60)", "pred answer": "farm", "question_id": 525635, "best approach": "image", "verif answer": "grassland", "anno approach": "wiki, concept, image", "verif wiki answer": "grassland(0.6998)", "verif concept answer": "grassland(0.7135)", "verif image answer": "pasture(0.6908)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052563.jpg"}, {"question": "", "gt answer": "juice(0.60)<br/>smoothie(0.60)<br/>smoothies(0.60)", "pred answer": "cupcake", "question_id": 2428475, "best approach": "", "verif answer": "smoothie", "anno approach": "wiki, concept, image", "verif wiki answer": "alcohol(0.6595)", "verif concept answer": "alcohol(0.6662)", "verif image answer": "alcohol(0.7241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000242847.jpg"}, {"question": "what is the name of the course where this is being done", "gt answer": "skatepark(1.00)<br/>skate park(0.60)", "pred answer": "skateboard", "question_id": 149605, "best approach": "concept", "verif answer": "skateboard", "anno approach": "wiki, concept, image", "verif wiki answer": "skate park(0.6942)", "verif concept answer": "skatepark(0.7009)", "verif image answer": "skateboard(0.6916)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000014960.jpg"}, {"question": "what is the average temp of this water in august", "gt answer": "80(1.00)<br/>70(0.60)", "pred answer": "low", "question_id": 830585, "best approach": "image", "verif answer": "60", "anno approach": "wiki, concept, image", "verif wiki answer": "60(0.7173)", "verif concept answer": "60(0.6714)", "verif image answer": "70(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083058.jpg"}, {"question": "what side dish is this meal typically served with", "gt answer": "potato(1.00)<br/>cake(0.60)<br/>salad(0.60)<br/>bread(0.60)", "pred answer": "popcorn", "question_id": 1693225, "best approach": "wiki, concept, image", "verif answer": "potato", "anno approach": "wiki, concept, image", "verif wiki answer": "potato(0.7184)", "verif concept answer": "potato(0.7167)", "verif image answer": "potato(0.7112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169322.jpg"}, {"question": "how old is the kid riding the skateboard", "gt answer": "17(1.00)<br/>19(0.60)", "pred answer": "16", "question_id": 4456215, "best approach": "image", "verif answer": "16", "anno approach": "wiki, concept, image", "verif wiki answer": "12(0.6675)", "verif concept answer": "12(0.6661)", "verif image answer": "19(0.7038)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445621.jpg"}, {"question": "what is used to separate the court", "gt answer": "net(1.00)<br/>line(0.60)", "pred answer": "fence", "question_id": 4298095, "best approach": "image", "verif answer": "fence", "anno approach": "wiki, concept, image", "verif wiki answer": "crosswalk(0.7257)", "verif concept answer": "crosswalk(0.7283)", "verif image answer": "net(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429809.jpg"}, {"question": "what is the breed of cattle shown", "gt answer": "jersey(1.00)<br/>cow(0.60)<br/>dairy(0.60)", "pred answer": "holstein", "question_id": 1737605, "best approach": "", "verif answer": "holstein", "anno approach": "wiki, concept, image", "verif wiki answer": "holstein(0.6699)", "verif concept answer": "holstein(0.6976)", "verif image answer": "holstein(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000173760.jpg"}, {"question": "what is the boy in red attempting to do", "gt answer": "steal(1.00)", "pred answer": "slide", "question_id": 5391675, "best approach": "", "verif answer": "catch", "anno approach": "wiki, concept, image", "verif wiki answer": "catch(0.7286)", "verif concept answer": "kick(0.5199)", "verif image answer": "block(0.5872)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539167.jpg"}, {"question": "what bible chapter describes the return of jesus", "gt answer": "revel(1.00)<br/>john(0.60)", "pred answer": "classified", "question_id": 211835, "best approach": "wiki", "verif answer": "upper", "anno approach": "wiki, concept, image", "verif wiki answer": "revel(0.7283)", "verif concept answer": "upper(0.6198)", "verif image answer": "first(0.5041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000021183.jpg"}, {"question": "what is a well know brand of these type of containers she is filling", "gt answer": "mason(1.00)<br/>tupperware(0.60)<br/>pyrex(0.60)<br/>ball(0.60)", "pred answer": "kenmore", "question_id": 3106655, "best approach": "", "verif answer": "ball", "anno approach": "wiki, concept, image", "verif wiki answer": "active(0.6678)", "verif concept answer": "active(0.7230)", "verif image answer": "active(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310665.jpg"}, {"question": "", "gt answer": "harley(0.60)<br/>harleys(0.60)<br/>honda(0.60)", "pred answer": "harley davidson", "question_id": 1228345, "best approach": "concept", "verif answer": "harley davidson", "anno approach": "wiki, concept, image", "verif wiki answer": "harley davidson(0.6238)", "verif concept answer": "harleys(0.6599)", "verif image answer": "harley davidson(0.6868)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122834.jpg"}, {"question": "what is this food called", "gt answer": "stew(1.00)", "pred answer": "salad", "question_id": 3493385, "best approach": "", "verif answer": "vegetable", "anno approach": "wiki, concept, image", "verif wiki answer": "carrot(0.6957)", "verif concept answer": "smoothie(0.7269)", "verif image answer": "vegetable(0.6749)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000349338.jpg"}, {"question": "where can you buy these sheets", "gt answer": "online(1.00)", "pred answer": "store", "question_id": 1862075, "best approach": "", "verif answer": "walmart", "anno approach": "wiki, concept, image", "verif wiki answer": "walmart(0.6691)", "verif concept answer": "sew(0.6794)", "verif image answer": "sew(0.6799)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186207.jpg"}, {"question": "what type of building does this kitchen belong in", "gt answer": "office(1.00)<br/>storage(0.60)", "pred answer": "apartment", "question_id": 1384355, "best approach": "wiki, image", "verif answer": "school", "anno approach": "wiki, concept, image", "verif wiki answer": "office(0.6970)", "verif concept answer": "school(0.6895)", "verif image answer": "office(0.7121)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138435.jpg"}, {"question": "what is this equipment used for", "gt answer": "boat(1.00)<br/>sail(1.00)", "pred answer": "fish", "question_id": 2063945, "best approach": "wiki, image", "verif answer": "sail", "anno approach": "wiki, concept, image", "verif wiki answer": "boat(0.7248)", "verif concept answer": "harbor(0.6490)", "verif image answer": "sail(0.7160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206394.jpg"}, {"question": "what kind of pressed sandwich is this", "gt answer": "panini(1.00)<br/>grilled(0.60)", "pred answer": "sub", "question_id": 2114845, "best approach": "image", "verif answer": "grilled", "anno approach": "wiki, concept, image", "verif wiki answer": "bake(0.5421)", "verif concept answer": "grilled(0.6515)", "verif image answer": "panini(0.6578)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000211484.jpg"}, {"question": "what animal is hiding", "gt answer": "cat(1.00)", "pred answer": "feline", "question_id": 3868845, "best approach": "", "verif answer": "feline", "anno approach": "wiki, concept, image", "verif wiki answer": "feline(0.7302)", "verif concept answer": "feline(0.7279)", "verif image answer": "black cat(0.7151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000386884.jpg"}, {"question": "what are two fruits found on the plate beside the waffle", "gt answer": "banana orange(1.00)<br/>banana(0.60)", "pred answer": "blueberry", "question_id": 2004835, "best approach": "", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "veggies(0.6760)", "verif concept answer": "veggies(0.5583)", "verif image answer": "lime(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200483.jpg"}, {"question": "what kinds of flowers are those", "gt answer": "lavendar(1.00)<br/>purple(0.60)", "pred answer": "daisy", "question_id": 2473205, "best approach": "", "verif answer": "daisy", "anno approach": "wiki, concept, image", "verif wiki answer": "daisy(0.7094)", "verif concept answer": "daisy(0.6830)", "verif image answer": "daisy(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247320.jpg"}, {"question": "what is a famous chain that sells these", "gt answer": "starbucks(1.00)", "pred answer": "dunkin donuts", "question_id": 4264295, "best approach": "concept", "verif answer": "dunkin donuts", "anno approach": "wiki, concept, image", "verif wiki answer": "coffee cake(0.7131)", "verif concept answer": "starbucks(0.5468)", "verif image answer": "coffee cake(0.5229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426429.jpg"}, {"question": "tell me the name of the skating used by the boy", "gt answer": "skateboard(1.00)", "pred answer": "jump", "question_id": 4435925, "best approach": "concept, image", "verif answer": "skateboard", "anno approach": "wiki, concept, image", "verif wiki answer": "box truck(0.5695)", "verif concept answer": "skateboard(0.6774)", "verif image answer": "skateboard(0.6905)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443592.jpg"}, {"question": "horses typically eat what types of fruits", "gt answer": "apple(1.00)<br/>carrot(0.60)", "pred answer": "hay", "question_id": 5298235, "best approach": "", "verif answer": "hay", "anno approach": "wiki, concept, image", "verif wiki answer": "hay(0.6958)", "verif concept answer": "watermelon(0.7132)", "verif image answer": "hay(0.6906)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529823.jpg"}, {"question": "what is the term for this kind of office arrangement", "gt answer": "cubicle(1.00)", "pred answer": "study", "question_id": 748945, "best approach": "wiki, concept", "verif answer": "office", "anno approach": "wiki, concept, image", "verif wiki answer": "cubicle(0.7274)", "verif concept answer": "cubicle(0.6496)", "verif image answer": "ibm(0.7039)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074894.jpg"}, {"question": "which of the foods here have the highest saturated fats", "gt answer": "donuts(1.00)<br/>donut(0.60)<br/>fried(0.60)", "pred answer": "doughnut", "question_id": 760425, "best approach": "wiki, image", "verif answer": "doughnut", "anno approach": "wiki, concept, image", "verif wiki answer": "donuts(0.6613)", "verif concept answer": "espresso(0.6483)", "verif image answer": "donuts(0.6206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076042.jpg"}, {"question": "how do we know this guy is not likely to have packed a razor", "gt answer": "has beard(1.00)<br/>beard(0.60)", "pred answer": "sunscreen", "question_id": 5223385, "best approach": "wiki, concept, image", "verif answer": "cell phone", "anno approach": "wiki, concept, image", "verif wiki answer": "has beard(0.6936)", "verif concept answer": "has beard(0.7234)", "verif image answer": "has beard(0.7095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522338.jpg"}, {"question": "what is the termperature like", "gt answer": "warm(1.00)<br/>hot(1.00)", "pred answer": "casual", "question_id": 4714735, "best approach": "wiki, concept, image", "verif answer": "hot", "anno approach": "wiki, concept, image", "verif wiki answer": "warm(0.7267)", "verif concept answer": "warm(0.7184)", "verif image answer": "warm(0.6101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471473.jpg"}, {"question": "why are there so many beds", "gt answer": "sleepover(1.00)<br/>hotel(0.60)", "pred answer": "travel", "question_id": 1339055, "best approach": "image", "verif answer": "hotel", "anno approach": "wiki, concept, image", "verif wiki answer": "watch tv(0.7182)", "verif concept answer": "watch tv(0.6151)", "verif image answer": "hotel(0.7241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000133905.jpg"}, {"question": "why is the lady sitting behind a table filled with fruit", "gt answer": "sell fruit(1.00)<br/>sell(0.60)<br/>work(0.60)", "pred answer": "shade", "question_id": 3317245, "best approach": "wiki, concept, image", "verif answer": "sell", "anno approach": "wiki, concept, image", "verif wiki answer": "sell(0.6106)", "verif concept answer": "sell(0.5852)", "verif image answer": "sell(0.7241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331724.jpg"}, {"question": "a screen lies on the floor is it a crt or lcd", "gt answer": "lcd(1.00)<br/>crt(1.00)", "pred answer": "led", "question_id": 4651535, "best approach": "wiki, concept, image", "verif answer": "lcd", "anno approach": "wiki, concept, image", "verif wiki answer": "crt(0.7277)", "verif concept answer": "crt(0.6905)", "verif image answer": "crt(0.7168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465153.jpg"}, {"question": "what is the cost of the items in this store", "gt answer": "1 dollar(1.00)<br/>1(0.60)", "pred answer": "2 dollars", "question_id": 2994885, "best approach": "concept, image", "verif answer": "50", "anno approach": "wiki, concept, image", "verif wiki answer": "20 pounds(0.6237)", "verif concept answer": "1 dollar(0.6017)", "verif image answer": "1 dollar(0.6584)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000299488.jpg"}, {"question": "what child cartoon is known for his love of honey", "gt answer": "winnie pooh(1.00)", "pred answer": "disney", "question_id": 4439165, "best approach": "", "verif answer": "disney", "anno approach": "wiki, concept, image", "verif wiki answer": "mickey mouse(0.7308)", "verif concept answer": "mickey mouse(0.7298)", "verif image answer": "mickey mouse(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443916.jpg"}, {"question": "what year was this model of motorcycle introduced", "gt answer": "1970(1.00)<br/>1998(0.60)<br/>1970's(0.60)", "pred answer": "1950", "question_id": 826765, "best approach": "wiki, concept", "verif answer": "1950", "anno approach": "wiki, concept, image", "verif wiki answer": "1998(0.7022)", "verif concept answer": "1998(0.6337)", "verif image answer": "1950(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082676.jpg"}, {"question": "approximately what time of day is this", "gt answer": "10pm(1.00)<br/>night(0.60)", "pred answer": "even", "question_id": 2373905, "best approach": "image", "verif answer": "even", "anno approach": "wiki, concept, image", "verif wiki answer": "even(0.7112)", "verif concept answer": "even(0.6597)", "verif image answer": "night(0.6624)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237390.jpg"}, {"question": "what style is the couch made in", "gt answer": "floral(1.00)<br/>victorian(0.60)<br/>retro(0.60)", "pred answer": "oriental", "question_id": 5543245, "best approach": "wiki", "verif answer": "retro", "anno approach": "wiki, concept, image", "verif wiki answer": "retro(0.7255)", "verif concept answer": "polyester(0.6671)", "verif image answer": "polyester(0.7213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554324.jpg"}, {"question": "why would one suspect this is an older photograph", "gt answer": "cloth(1.00)<br/>black and white(0.60)", "pred answer": "color", "question_id": 4641665, "best approach": "wiki, concept", "verif answer": "black and white", "anno approach": "wiki, concept, image", "verif wiki answer": "black and white(0.6314)", "verif concept answer": "black and white(0.6915)", "verif image answer": "paper(0.6825)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464166.jpg"}, {"question": "what city does the batter play for", "gt answer": "baltimore(1.00)", "pred answer": "cleveland", "question_id": 3826955, "best approach": "", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "chicago(0.7202)", "verif concept answer": "chicago(0.7197)", "verif image answer": "oakland(0.6752)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382695.jpg"}, {"question": "what is on the sandwhich", "gt answer": "egg salad(1.00)<br/>tuna(0.60)", "pred answer": "ham", "question_id": 3921675, "best approach": "wiki, concept, image", "verif answer": "ham", "anno approach": "wiki, concept, image", "verif wiki answer": "egg salad(0.6404)", "verif concept answer": "egg salad(0.7275)", "verif image answer": "egg salad(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392167.jpg"}, {"question": "what does this appear to be", "gt answer": "mall(1.00)", "pred answer": "city", "question_id": 1570375, "best approach": "", "verif answer": "airport", "anno approach": "wiki, concept, image", "verif wiki answer": "airport(0.6865)", "verif concept answer": "san diego(0.6520)", "verif image answer": "airport(0.6609)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157037.jpg"}, {"question": "what type of meal are they eating", "gt answer": "dinner(1.00)<br/>0(0.60)<br/>vegan(0.60)", "pred answer": "sandwich", "question_id": 1427675, "best approach": "image", "verif answer": "lunch", "anno approach": "wiki, concept, image", "verif wiki answer": "lunch(0.6962)", "verif concept answer": "lunch(0.6910)", "verif image answer": "dinner(0.6965)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142767.jpg"}, {"question": "how high do you think this is", "gt answer": "40000 feet(1.00)<br/>2000 feet(0.60)", "pred answer": "30000 feet", "question_id": 4805025, "best approach": "concept", "verif answer": "30000 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "30000 feet(0.5156)", "verif concept answer": "2000 feet(0.5733)", "verif image answer": "6 inches(0.6613)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480502.jpg"}, {"question": "what is this batter doing", "gt answer": "swing(1.00)<br/>hit ball(0.60)", "pred answer": "pitch", "question_id": 5500285, "best approach": "image", "verif answer": "pitch", "anno approach": "wiki, concept, image", "verif wiki answer": "hit(0.7213)", "verif concept answer": "hit(0.7287)", "verif image answer": "hit ball(0.5870)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550028.jpg"}, {"question": "what is the occupation of these uniformed men", "gt answer": "firemen(1.00)<br/>delivery(0.60)<br/>police(0.60)", "pred answer": "military", "question_id": 5105945, "best approach": "wiki, image", "verif answer": "police", "anno approach": "wiki, concept, image", "verif wiki answer": "firemen(0.7306)", "verif concept answer": "police(0.6714)", "verif image answer": "firemen(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510594.jpg"}, {"question": "which item would be most practical to use for opening a box", "gt answer": "box cutter(1.00)", "pred answer": "scissor", "question_id": 3893265, "best approach": "", "verif answer": "scissor", "anno approach": "wiki, concept, image", "verif wiki answer": "scissor(0.7300)", "verif concept answer": "scissor(0.7260)", "verif image answer": "scissor(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389326.jpg"}, {"question": "what are the people in this photo saying with their hand gesture", "gt answer": "hello(1.00)", "pred answer": "peace", "question_id": 1712705, "best approach": "wiki, concept, image", "verif answer": "hello", "anno approach": "wiki, concept, image", "verif wiki answer": "hello(0.5737)", "verif concept answer": "hello(0.7215)", "verif image answer": "hello(0.7092)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171270.jpg"}, {"question": "name the place shown in this picture where the train is crossing", "gt answer": "forest(1.00)<br/>bridge(0.60)<br/>thailand(0.60)<br/>jungle(0.60)", "pred answer": "station", "question_id": 5435495, "best approach": "wiki, concept, image", "verif answer": "jungle", "anno approach": "wiki, concept, image", "verif wiki answer": "thailand(0.5969)", "verif concept answer": "thailand(0.7016)", "verif image answer": "jungle(0.7214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543549.jpg"}, {"question": "what is the brand of keyboard in this picture", "gt answer": "logitech(1.00)<br/>dell(0.60)", "pred answer": "samsung", "question_id": 4271525, "best approach": "wiki", "verif answer": "samsung", "anno approach": "wiki, concept, image", "verif wiki answer": "logitech(0.6811)", "verif concept answer": "samsung(0.6515)", "verif image answer": "samsung(0.7098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427152.jpg"}, {"question": "how old is the man with the receding hairline", "gt answer": "35(1.00)<br/>21(0.60)<br/>51(0.60)", "pred answer": "45", "question_id": 3920675, "best approach": "wiki, concept", "verif answer": "51", "anno approach": "wiki, concept, image", "verif wiki answer": "51(0.7186)", "verif concept answer": "51(0.6680)", "verif image answer": "26(0.6397)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392067.jpg"}, {"question": "why is she wearing that", "gt answer": "safety(1.00)<br/>helmet(0.60)", "pred answer": "cold", "question_id": 3575495, "best approach": "wiki, concept", "verif answer": "protection", "anno approach": "wiki, concept, image", "verif wiki answer": "safety(0.6865)", "verif concept answer": "safety(0.6992)", "verif image answer": "protection(0.7230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357549.jpg"}, {"question": "what is the life span of this animal", "gt answer": "16 years(1.00)<br/>10 years(0.60)", "pred answer": "15 years", "question_id": 2962445, "best approach": "wiki", "verif answer": "15 years", "anno approach": "wiki, concept, image", "verif wiki answer": "16 years(0.7032)", "verif concept answer": "year(0.6538)", "verif image answer": "2 years(0.6997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296244.jpg"}, {"question": "what can you do to protect yourself from this environment", "gt answer": "leave(1.00)<br/>wash hand(0.60)", "pred answer": "flush", "question_id": 3905595, "best approach": "wiki, concept, image", "verif answer": "wash hand", "anno approach": "wiki, concept, image", "verif wiki answer": "wash hand(0.6958)", "verif concept answer": "wash hand(0.5770)", "verif image answer": "wash hand(0.5799)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390559.jpg"}, {"question": "why is the red object on the sink important to use", "gt answer": "cleanliness(1.00)", "pred answer": "toothpaste", "question_id": 2322185, "best approach": "", "verif answer": "dish soap", "anno approach": "wiki, concept, image", "verif wiki answer": "vanity(0.7121)", "verif concept answer": "vanity(0.7166)", "verif image answer": "dish(0.7118)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232218.jpg"}, {"question": "what is for rent", "gt answer": "apartment(1.00)<br/>build(0.60)", "pred answer": "car", "question_id": 4917435, "best approach": "", "verif answer": "apartment", "anno approach": "wiki, concept, image", "verif wiki answer": "school(0.6231)", "verif concept answer": "school(0.6941)", "verif image answer": "school(0.7276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491743.jpg"}, {"question": "what type of vehicle is this", "gt answer": "plane(1.00)<br/>airplane(1.00)", "pred answer": "fighter", "question_id": 873485, "best approach": "wiki, concept, image", "verif answer": "plane", "anno approach": "wiki, concept, image", "verif wiki answer": "airplane(0.7139)", "verif concept answer": "airplane(0.7138)", "verif image answer": "airplane(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087348.jpg"}, {"question": "where could this trash be placed", "gt answer": "garbage can(1.00)<br/>field(0.60)", "pred answer": "trash", "question_id": 808015, "best approach": "wiki, concept", "verif answer": "park", "anno approach": "wiki, concept, image", "verif wiki answer": "garbage can(0.6925)", "verif concept answer": "garbage can(0.6339)", "verif image answer": "park(0.7137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080801.jpg"}, {"question": "what type of establishment is this", "gt answer": "bar(1.00)", "pred answer": "apartment", "question_id": 1506465, "best approach": "", "verif answer": "bar", "anno approach": "wiki, concept, image", "verif wiki answer": "deli(0.5863)", "verif concept answer": "cafe(0.6580)", "verif image answer": "deli(0.6851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000150646.jpg"}, {"question": "if you have a dirty spot you might say you are what word that is also the name of this type of glass window", "gt answer": "stained(1.00)", "pred answer": "eagle", "question_id": 5424845, "best approach": "image", "verif answer": "black and white", "anno approach": "wiki, concept, image", "verif wiki answer": "1950(0.6786)", "verif concept answer": "1950(0.6203)", "verif image answer": "stained(0.7198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542484.jpg"}, {"question": "what is usually in the big blue metal box", "gt answer": "newspaper(1.00)<br/>wire(0.60)", "pred answer": "cloth", "question_id": 2029905, "best approach": "", "verif answer": "cloth", "anno approach": "wiki, concept, image", "verif wiki answer": "cloth(0.7036)", "verif concept answer": "cloth(0.7136)", "verif image answer": "cloth(0.7151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202990.jpg"}, {"question": "who manufactures this type of bus", "gt answer": "mercedes benz(1.00)<br/>mercedes(0.60)", "pred answer": "greyhound", "question_id": 4918045, "best approach": "wiki", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "mercedes(0.7170)", "verif concept answer": "rawling(0.7051)", "verif image answer": "rawling(0.5690)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491804.jpg"}, {"question": "what part of the dogs body is covered by the blanket", "gt answer": "torso(1.00)<br/>leg(0.60)", "pred answer": "head", "question_id": 4002165, "best approach": "wiki, concept, image", "verif answer": "arm", "anno approach": "wiki, concept, image", "verif wiki answer": "torso(0.7297)", "verif concept answer": "torso(0.7260)", "verif image answer": "torso(0.7258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400216.jpg"}, {"question": "what kind of profession is the man in the apron in", "gt answer": "chef(1.00)<br/>culinary(0.60)<br/>mechanic(0.60)", "pred answer": "hair stylist", "question_id": 2877375, "best approach": "wiki, image", "verif answer": "culinary", "anno approach": "wiki, concept, image", "verif wiki answer": "culinary(0.6906)", "verif concept answer": "italians(0.5160)", "verif image answer": "culinary(0.5737)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287737.jpg"}, {"question": "how do i make this", "gt answer": "grill(1.00)<br/>cook(0.60)", "pred answer": "bake", "question_id": 4123505, "best approach": "", "verif answer": "grill", "anno approach": "wiki, concept, image", "verif wiki answer": "stir fry(0.6910)", "verif concept answer": "eat(0.7237)", "verif image answer": "stir fry(0.7159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412350.jpg"}, {"question": "would you describe the room as minimalist or cluttered", "gt answer": "cluttered(1.00)", "pred answer": "automatic", "question_id": 5541525, "best approach": "", "verif answer": "casual", "anno approach": "wiki, concept, image", "verif wiki answer": "casual(0.5577)", "verif concept answer": "casual(0.5566)", "verif image answer": "casual(0.5745)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554152.jpg"}, {"question": "what is this panel discussing", "gt answer": "politic(1.00)<br/>sport(0.60)", "pred answer": "meet", "question_id": 1245805, "best approach": "", "verif answer": "politic", "anno approach": "wiki, concept, image", "verif wiki answer": "danger(0.7032)", "verif concept answer": "school(0.5354)", "verif image answer": "danger(0.5896)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000124580.jpg"}, {"question": "what are the poles down the road from the cars called", "gt answer": "telephone(1.00)<br/>electric(0.60)", "pred answer": "track", "question_id": 4030645, "best approach": "image", "verif answer": "electric", "anno approach": "wiki, concept, image", "verif wiki answer": "electrical(0.5912)", "verif concept answer": "phone(0.6365)", "verif image answer": "electric(0.6664)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403064.jpg"}, {"question": "meek people are sometimes called what that sounds like a variation of this animal 's name", "gt answer": "sheep(1.00)", "pred answer": "indian", "question_id": 5081005, "best approach": "", "verif answer": "goat", "anno approach": "wiki, concept, image", "verif wiki answer": "ewe(0.6851)", "verif concept answer": "ewe(0.6885)", "verif image answer": "food(0.7076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000508100.jpg"}, {"question": "what is this water doing", "gt answer": "wave(1.00)<br/>crash(0.60)<br/>move(0.60)", "pred answer": "tide", "question_id": 1032605, "best approach": "concept", "verif answer": "wave", "anno approach": "wiki, concept, image", "verif wiki answer": "move(0.6736)", "verif concept answer": "wave(0.6858)", "verif image answer": "surf(0.7191)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103260.jpg"}, {"question": "what does the sign indicate", "gt answer": "roundabout(1.00)<br/>direction(0.60)", "pred answer": "watch for pedestrian", "question_id": 1584855, "best approach": "wiki", "verif answer": "direct", "anno approach": "wiki, concept, image", "verif wiki answer": "roundabout(0.6316)", "verif concept answer": "direction(0.5184)", "verif image answer": "circle(0.5494)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000158485.jpg"}, {"question": "what kind of craft are drifting along this waterway", "gt answer": "ship(0.60)<br/>boat(0.60)<br/>raft(0.60)<br/>bird(1.00)", "pred answer": "canoe", "question_id": 2933665, "best approach": "wiki, concept", "verif answer": "ship", "anno approach": "wiki, concept, image", "verif wiki answer": "raft(0.7173)", "verif concept answer": "ship(0.7161)", "verif image answer": "duck(0.7109)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293366.jpg"}, {"question": "what is this area of the train usually called", "gt answer": "hall(1.00)<br/>hallway(0.60)", "pred answer": "train station", "question_id": 1982145, "best approach": "image", "verif answer": "door", "anno approach": "wiki, concept, image", "verif wiki answer": "lobby(0.6205)", "verif concept answer": "lobby(0.5434)", "verif image answer": "hallway(0.7243)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198214.jpg"}, {"question": "what is the man wearing", "gt answer": "leather jacket(1.00)<br/>glass(0.60)<br/>sunglasses(0.60)<br/>leather(0.60)", "pred answer": "hat", "question_id": 1764035, "best approach": "wiki, concept, image", "verif answer": "sunglasses", "anno approach": "wiki, concept, image", "verif wiki answer": "sunglasses(0.7221)", "verif concept answer": "sunglasses(0.7191)", "verif image answer": "sunglasses(0.6900)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176403.jpg"}, {"question": "what is it called when a wave is shaped like that", "gt answer": "crest(1.00)<br/>roll(0.60)<br/>surf(0.60)", "pred answer": "wave", "question_id": 954865, "best approach": "wiki", "verif answer": "surf", "anno approach": "wiki, concept, image", "verif wiki answer": "surf(0.7198)", "verif concept answer": "crash(0.6873)", "verif image answer": "sail(0.7241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000095486.jpg"}, {"question": "", "gt answer": "dry(0.60)<br/>hay(0.60)", "pred answer": "green grass", "question_id": 1402785, "best approach": "wiki, concept, image", "verif answer": "hay", "anno approach": "wiki, concept, image", "verif wiki answer": "dry(0.6196)", "verif concept answer": "hay(0.6119)", "verif image answer": "dry(0.6146)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140278.jpg"}, {"question": "why is that dog tired", "gt answer": "run(1.00)<br/>old(0.60)", "pred answer": "tired", "question_id": 1826045, "best approach": "wiki, concept, image", "verif answer": "fun", "anno approach": "wiki, concept, image", "verif wiki answer": "run(0.6872)", "verif concept answer": "run(0.6981)", "verif image answer": "run(0.6425)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182604.jpg"}, {"question": "what kind of birds are these", "gt answer": "hawk(0.60)<br/>crow(1.00)", "pred answer": "geese", "question_id": 4433605, "best approach": "concept", "verif answer": "hawk", "anno approach": "wiki, concept, image", "verif wiki answer": "falcon(0.6858)", "verif concept answer": "hawk(0.6794)", "verif image answer": "pigeon(0.6843)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443360.jpg"}, {"question": "would you consider this room contemporary or retro", "gt answer": "retro(1.00)<br/>contemporary(0.60)", "pred answer": "modern", "question_id": 2149465, "best approach": "concept", "verif answer": "victorian", "anno approach": "wiki, concept, image", "verif wiki answer": "victorian(0.6895)", "verif concept answer": "retro(0.6665)", "verif image answer": "victorian(0.6126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214946.jpg"}, {"question": "what is the child riding on as he is being pulled", "gt answer": "suitcase(1.00)<br/>luggage(1.00)", "pred answer": "skateboard", "question_id": 890125, "best approach": "wiki, concept, image", "verif answer": "luggage", "anno approach": "wiki, concept, image", "verif wiki answer": "luggage(0.6841)", "verif concept answer": "luggage(0.6582)", "verif image answer": "luggage(0.7005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089012.jpg"}, {"question": "what make the hands on the clock move", "gt answer": "gear(1.00)<br/>motor(0.60)", "pred answer": "tell time", "question_id": 3266635, "best approach": "wiki, image", "verif answer": "motor", "anno approach": "wiki, concept, image", "verif wiki answer": "gear(0.7304)", "verif concept answer": "engine(0.7291)", "verif image answer": "gear(0.7262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000326663.jpg"}, {"question": "why is it illegal to do this while driving", "gt answer": "danger(1.00)<br/>distraction(0.60)", "pred answer": "red light", "question_id": 5704105, "best approach": "concept", "verif answer": "distraction", "anno approach": "wiki, concept, image", "verif wiki answer": "empty(0.7175)", "verif concept answer": "distraction(0.5814)", "verif image answer": "empty(0.5837)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570410.jpg"}, {"question": "what cafe is his shirt from", "gt answer": "road kill(1.00)", "pred answer": "dunkin donuts", "question_id": 1274415, "best approach": "", "verif answer": "fast food", "anno approach": "wiki, concept, image", "verif wiki answer": "fast food(0.7144)", "verif concept answer": "fast food(0.6397)", "verif image answer": "amazon(0.5022)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127441.jpg"}, {"question": "what is wrong with this sign", "gt answer": "upside down(1.00)", "pred answer": "dog drive", "question_id": 494955, "best approach": "", "verif answer": "vandalism", "anno approach": "wiki, concept, image", "verif wiki answer": "bent sign(0.7289)", "verif concept answer": "graffiti(0.5134)", "verif image answer": "graffiti(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049495.jpg"}, {"question": "the fruit before you is good for which parts of the body", "gt answer": "skin(1.00)", "pred answer": "brain", "question_id": 2183345, "best approach": "", "verif answer": "brain", "anno approach": "wiki, concept, image", "verif wiki answer": "heart(0.7024)", "verif concept answer": "brain(0.7085)", "verif image answer": "heart(0.5913)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218334.jpg"}, {"question": "what is the name of this position in baseball", "gt answer": "pitcher(1.00)", "pred answer": "batter", "question_id": 2174865, "best approach": "", "verif answer": "pitcher", "anno approach": "wiki, concept, image", "verif wiki answer": "home(0.6739)", "verif concept answer": "catcher(0.6631)", "verif image answer": "home(0.5093)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217486.jpg"}, {"question": "what is the purpose of the glasses that the man in the white shirt and girl in the black shirt are wearing", "gt answer": "sunglasses(1.00)", "pred answer": "sun protection", "question_id": 3297995, "best approach": "image", "verif answer": "sunglasses", "anno approach": "wiki, concept, image", "verif wiki answer": "goggle(0.7265)", "verif concept answer": "goggle(0.7092)", "verif image answer": "sunglasses(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329799.jpg"}, {"question": "how many visitors does this location receive annually", "gt answer": "5 million(1.00)<br/>lot(0.60)<br/>million(0.60)", "pred answer": "10000", "question_id": 5386405, "best approach": "wiki", "verif answer": "lot", "anno approach": "wiki, concept, image", "verif wiki answer": "lot(0.7011)", "verif concept answer": "52(0.6709)", "verif image answer": "52(0.6649)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538640.jpg"}, {"question": "is the glazed donut on the top or bottom", "gt answer": "top(1.00)", "pred answer": "full", "question_id": 3098505, "best approach": "", "verif answer": "front", "anno approach": "wiki, concept, image", "verif wiki answer": "scissor(0.6985)", "verif concept answer": "scissor(0.7275)", "verif image answer": "front(0.5236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000309850.jpg"}, {"question": "what is the purpose of the net in the picture", "gt answer": "goal(1.00)<br/>to catch ball(0.60)", "pred answer": "protection", "question_id": 5302935, "best approach": "wiki, concept, image", "verif answer": "score", "anno approach": "wiki, concept, image", "verif wiki answer": "to catch ball(0.7026)", "verif concept answer": "to catch ball(0.7180)", "verif image answer": "to catch ball(0.6221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000530293.jpg"}, {"question": "how long did it take to make this", "gt answer": "10 minutes(1.00)<br/>5 minutes(0.60)", "pred answer": "4 years", "question_id": 3015915, "best approach": "concept", "verif answer": "hour", "anno approach": "wiki, concept, image", "verif wiki answer": "5 minutes(0.7105)", "verif concept answer": "10 minutes(0.6016)", "verif image answer": "hour(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301591.jpg"}, {"question": "what type of yellow flower is that", "gt answer": "sunflower(1.00)<br/>dandelion(0.60)", "pred answer": "daffodil", "question_id": 3035975, "best approach": "", "verif answer": "lily", "anno approach": "wiki, concept, image", "verif wiki answer": "floral(0.6663)", "verif concept answer": "floral(0.7155)", "verif image answer": "mix(0.7116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303597.jpg"}, {"question": "which animal doesn't belong", "gt answer": "panda(1.00)", "pred answer": "bear", "question_id": 4420625, "best approach": "wiki, image", "verif answer": "bear", "anno approach": "wiki, concept, image", "verif wiki answer": "panda(0.7293)", "verif concept answer": "bear(0.7254)", "verif image answer": "panda(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442062.jpg"}, {"question": "what form of snowboarding is seen here", "gt answer": "downhill(1.00)<br/>cross country(1.00)<br/>slope(0.60)", "pred answer": "snowboard", "question_id": 3218245, "best approach": "concept", "verif answer": "cross country", "anno approach": "wiki, concept, image", "verif wiki answer": "slalom(0.7154)", "verif concept answer": "downhill(0.7185)", "verif image answer": "down(0.6475)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321824.jpg"}, {"question": "what model car is this", "gt answer": "audi(1.00)<br/>mercedes(1.00)", "pred answer": "sedan", "question_id": 1557395, "best approach": "", "verif answer": "mercedes", "anno approach": "wiki, concept, image", "verif wiki answer": "fiat(0.7235)", "verif concept answer": "fiat(0.6374)", "verif image answer": "fiat(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155739.jpg"}, {"question": "what jacket brand is he wearing", "gt answer": "columbia(1.00)<br/>polo(0.60)<br/>adidas(0.60)", "pred answer": "north face", "question_id": 120965, "best approach": "image", "verif answer": "north face", "anno approach": "wiki, concept, image", "verif wiki answer": "north face(0.7286)", "verif concept answer": "north face(0.6534)", "verif image answer": "columbia(0.6006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012096.jpg"}, {"question": "what is the common name for this kind of chair", "gt answer": "director(1.00)<br/>wooden(0.60)", "pred answer": "toilet", "question_id": 1947585, "best approach": "", "verif answer": "wicker", "anno approach": "wiki, concept, image", "verif wiki answer": "antique(0.7156)", "verif concept answer": "antique(0.7042)", "verif image answer": "blue(0.5959)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194758.jpg"}, {"question": "what is the make of the truck", "gt answer": "dodge(1.00)<br/>chevy(0.60)", "pred answer": "chevrolet", "question_id": 3791435, "best approach": "wiki", "verif answer": "chevrolet", "anno approach": "wiki, concept, image", "verif wiki answer": "chevy(0.7075)", "verif concept answer": "1960(0.6984)", "verif image answer": "chevrolet(0.7161)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379143.jpg"}, {"question": "what is the name of the winter sport that looks a lot like this one", "gt answer": "snowboard(1.00)", "pred answer": "skateboard", "question_id": 4949595, "best approach": "wiki, concept", "verif answer": "snowboard", "anno approach": "wiki, concept, image", "verif wiki answer": "snowboard(0.7262)", "verif concept answer": "snowboard(0.7220)", "verif image answer": "espn(0.7077)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494959.jpg"}, {"question": "what is required for this to fly", "gt answer": "wind(1.00)", "pred answer": "string", "question_id": 3281795, "best approach": "wiki", "verif answer": "string", "anno approach": "wiki, concept, image", "verif wiki answer": "wind(0.7154)", "verif concept answer": "string(0.7109)", "verif image answer": "string(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328179.jpg"}, {"question": "how is the egg on this dish prepared", "gt answer": "fried(1.00)<br/>sunny side up(0.60)<br/>over easy(0.60)", "pred answer": "hard boiled", "question_id": 589795, "best approach": "", "verif answer": "hard boiled", "anno approach": "wiki, concept, image", "verif wiki answer": "hard boiled(0.7030)", "verif concept answer": "fry(0.7217)", "verif image answer": "fry(0.7042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058979.jpg"}, {"question": "what is a common ailment tennis players get", "gt answer": "tennis elbow(1.00)", "pred answer": "serve", "question_id": 2317485, "best approach": "", "verif answer": "serve", "anno approach": "wiki, concept, image", "verif wiki answer": "serve(0.7194)", "verif concept answer": "serve(0.7269)", "verif image answer": "serve(0.6689)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231748.jpg"}, {"question": "what kind of peas are these", "gt answer": "snap pea(1.00)", "pred answer": "green", "question_id": 2049695, "best approach": "", "verif answer": "granny smith", "anno approach": "wiki, concept, image", "verif wiki answer": "granny smith(0.7259)", "verif concept answer": "granny smith(0.7307)", "verif image answer": "granny smith(0.6942)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000204969.jpg"}, {"question": "what is the accent color around the front windows", "gt answer": "teal(1.00)<br/>green(0.60)", "pred answer": "red", "question_id": 867055, "best approach": "", "verif answer": "blue", "anno approach": "wiki, concept, image", "verif wiki answer": "grey(0.7039)", "verif concept answer": "grey(0.6849)", "verif image answer": "grey(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086705.jpg"}, {"question": "what type of body of water is shown", "gt answer": "lake(1.00)", "pred answer": "river", "question_id": 5530675, "best approach": "image", "verif answer": "lake", "anno approach": "wiki, concept, image", "verif wiki answer": "snow(0.7151)", "verif concept answer": "alaska(0.6912)", "verif image answer": "lake(0.7166)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553067.jpg"}, {"question": "what style of restaurant is this", "gt answer": "buffet(1.00)<br/>cater(0.60)", "pred answer": "italian", "question_id": 45875, "best approach": "image", "verif answer": "italian", "anno approach": "wiki, concept, image", "verif wiki answer": "cater(0.7112)", "verif concept answer": "deli(0.7172)", "verif image answer": "buffet(0.7183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004587.jpg"}, {"question": "can you guess the model of mouse shown in this picture", "gt answer": "apple(1.00)<br/>dell(0.60)", "pred answer": "ibm", "question_id": 4999585, "best approach": "wiki, concept", "verif answer": "dell", "anno approach": "wiki, concept, image", "verif wiki answer": "dell(0.6823)", "verif concept answer": "dell(0.5209)", "verif image answer": "peach(0.6224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499958.jpg"}, {"question": "what are these horses jumping over", "gt answer": "fence(0.60)<br/>gate(0.60)<br/>hurdle(1.00)<br/>jump(0.60)", "pred answer": "ball", "question_id": 3285745, "best approach": "wiki, concept, image", "verif answer": "hurdle", "anno approach": "wiki, concept, image", "verif wiki answer": "jump(0.6270)", "verif concept answer": "jump(0.6513)", "verif image answer": "fence(0.7267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328574.jpg"}, {"question": "who is guiding the horseback chariot", "gt answer": "coachman(1.00)<br/>man(1.00)<br/>driver(0.60)", "pred answer": "conductor", "question_id": 5170955, "best approach": "wiki, image", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "coachman(0.5399)", "verif concept answer": "newscaster(0.6288)", "verif image answer": "man(0.5585)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517095.jpg"}, {"question": "what is this person known for", "gt answer": "writer(1.00)<br/>road(0.60)", "pred answer": "street name", "question_id": 3621545, "best approach": "wiki, concept", "verif answer": "street name", "anno approach": "wiki, concept, image", "verif wiki answer": "writer(0.5727)", "verif concept answer": "writer(0.6311)", "verif image answer": "street name(0.6982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362154.jpg"}, {"question": "what breed of horse is this", "gt answer": "pinto(1.00)<br/>palomino(0.60)<br/>wild(0.60)<br/>quarter(0.60)", "pred answer": "mustang", "question_id": 467255, "best approach": "concept", "verif answer": "mustang", "anno approach": "wiki, concept, image", "verif wiki answer": "mustang(0.7209)", "verif concept answer": "wild(0.7132)", "verif image answer": "mustang(0.7144)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046725.jpg"}, {"question": "id these birds", "gt answer": "sparrow(1.00)<br/>finch(0.60)<br/>pigeon(0.60)", "pred answer": "seagull", "question_id": 300545, "best approach": "", "verif answer": "robin", "anno approach": "wiki, concept, image", "verif wiki answer": "owl(0.7169)", "verif concept answer": "owl(0.6447)", "verif image answer": "owl(0.5977)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030054.jpg"}, {"question": "what is the name for this type of truck", "gt answer": "flatbed(1.00)", "pred answer": "semi", "question_id": 4947945, "best approach": "image", "verif answer": "semi", "anno approach": "wiki, concept, image", "verif wiki answer": "dump(0.6501)", "verif concept answer": "monster truck(0.6874)", "verif image answer": "flatbed(0.6054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494794.jpg"}, {"question": "what show features this and a rec dept", "gt answer": "park and rec(1.00)", "pred answer": "kite fly", "question_id": 2319415, "best approach": "", "verif answer": "kite", "anno approach": "wiki, concept, image", "verif wiki answer": "rodeo(0.6876)", "verif concept answer": "kite(0.6192)", "verif image answer": "kite(0.6937)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231941.jpg"}, {"question": "what brand is the television", "gt answer": "lg(1.00)<br/>sony(0.60)", "pred answer": "sharp", "question_id": 5753195, "best approach": "wiki, concept", "verif answer": "sony", "anno approach": "wiki, concept, image", "verif wiki answer": "lg(0.7172)", "verif concept answer": "lg(0.6789)", "verif image answer": "kenmore(0.6995)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575319.jpg"}, {"question": "what recipe is this", "gt answer": "stir fry(0.60)<br/>potato(1.00)", "pred answer": "salad", "question_id": 5845, "best approach": "concept", "verif answer": "potato", "anno approach": "wiki, concept, image", "verif wiki answer": "kale(0.6585)", "verif concept answer": "potato(0.7244)", "verif image answer": "kale(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000584.jpg"}, {"question": "has this guy shaved his beard today how do you know", "gt answer": "no scruffy(1.00)", "pred answer": "crew cut", "question_id": 4600955, "best approach": "wiki, concept", "verif answer": "protest", "anno approach": "wiki, concept, image", "verif wiki answer": "no scruffy(0.7232)", "verif concept answer": "no scruffy(0.7241)", "verif image answer": "protest(0.6804)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460095.jpg"}, {"question": "what is the green food on this sandwich", "gt answer": "spinach(1.00)<br/>kale(0.60)", "pred answer": "pickle", "question_id": 5412555, "best approach": "", "verif answer": "broccoli", "anno approach": "wiki, concept, image", "verif wiki answer": "broccoli(0.7255)", "verif concept answer": "broccoli(0.7298)", "verif image answer": "lettuce(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541255.jpg"}, {"question": "what is the plane going to do", "gt answer": "land(1.00)<br/>vacation(0.60)<br/>takeoff(0.60)", "pred answer": "fly", "question_id": 133975, "best approach": "", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "fly(0.7305)", "verif concept answer": "fly(0.7092)", "verif image answer": "fly(0.6367)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013397.jpg"}, {"question": "where does the bridge go", "gt answer": "island(1.00)", "pred answer": "bridge", "question_id": 216935, "best approach": "", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "mountain(0.7023)", "verif concept answer": "hill(0.6001)", "verif image answer": "mountain(0.7187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000021693.jpg"}, {"question": "what happens when a pebble hits your windshield on the freeway", "gt answer": "crack(1.00)", "pred answer": "turn", "question_id": 3423235, "best approach": "", "verif answer": "turn", "anno approach": "wiki, concept, image", "verif wiki answer": "turn(0.7230)", "verif concept answer": "turn(0.5417)", "verif image answer": "turn(0.7082)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342323.jpg"}, {"question": "why is the car being towed", "gt answer": "broken(1.00)", "pred answer": "accident", "question_id": 666625, "best approach": "image", "verif answer": "accident", "anno approach": "wiki, concept, image", "verif wiki answer": "accident(0.7190)", "verif concept answer": "bent(0.6492)", "verif image answer": "broken(0.6766)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000066662.jpg"}, {"question": "what is the meat cooked on", "gt answer": "grill(1.00)", "pred answer": "plate", "question_id": 3140685, "best approach": "wiki", "verif answer": "grilled", "anno approach": "wiki, concept, image", "verif wiki answer": "grill(0.6604)", "verif concept answer": "cook(0.6451)", "verif image answer": "fry(0.6968)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314068.jpg"}, {"question": "what food is this", "gt answer": "turkey(1.00)<br/>chicken(0.60)<br/>meat(0.60)", "pred answer": "pizza", "question_id": 4108055, "best approach": "wiki, concept, image", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "meat(0.7119)", "verif concept answer": "meat(0.7216)", "verif image answer": "chicken(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000410805.jpg"}, {"question": "is this a tournament match or a practice match", "gt answer": "tournament(1.00)", "pred answer": "strike", "question_id": 701615, "best approach": "wiki", "verif answer": "popular", "anno approach": "wiki, concept, image", "verif wiki answer": "tournament(0.7293)", "verif concept answer": "open(0.6959)", "verif image answer": "tennis(0.7184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070161.jpg"}, {"question": "which of the following items pictured is the best source of fiber", "gt answer": "kale(1.00)<br/>lettuce(0.60)<br/>beet(0.60)", "pred answer": "carrot", "question_id": 1015595, "best approach": "wiki, concept, image", "verif answer": "beet", "anno approach": "wiki, concept, image", "verif wiki answer": "beet(0.6844)", "verif concept answer": "beet(0.7257)", "verif image answer": "lettuce(0.6917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000101559.jpg"}, {"question": "is this a typical or atypical workplace", "gt answer": "atypical(1.00)", "pred answer": "casual", "question_id": 3808275, "best approach": "wiki", "verif answer": "professional", "anno approach": "wiki, concept, image", "verif wiki answer": "atypical(0.6123)", "verif concept answer": "professional(0.5928)", "verif image answer": "professional(0.5363)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000380827.jpg"}, {"question": "what happened to the rider", "gt answer": "fell(1.00)", "pred answer": "fall", "question_id": 4511965, "best approach": "", "verif answer": "fall", "anno approach": "wiki, concept, image", "verif wiki answer": "fall(0.7216)", "verif concept answer": "fly(0.6054)", "verif image answer": "fall(0.6486)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451196.jpg"}, {"question": "how tall is the girl", "gt answer": "4 feet(1.00)<br/>3 feet(0.60)", "pred answer": "6", "question_id": 2825585, "best approach": "wiki", "verif answer": "20 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "3 feet(0.7038)", "verif concept answer": "42 inches(0.5430)", "verif image answer": "5 feet(0.5977)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282558.jpg"}, {"question": "what is the instrument used for", "gt answer": "music(1.00)", "pred answer": "piano", "question_id": 1995335, "best approach": "wiki, image", "verif answer": "music", "anno approach": "wiki, concept, image", "verif wiki answer": "music(0.7224)", "verif concept answer": "decoration(0.6415)", "verif image answer": "music(0.6950)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199533.jpg"}, {"question": "what is the temperature of the water", "gt answer": "cold(1.00)", "pred answer": "cool", "question_id": 2352135, "best approach": "", "verif answer": "cold", "anno approach": "wiki, concept, image", "verif wiki answer": "very cold(0.6544)", "verif concept answer": "very cold(0.6937)", "verif image answer": "freeze(0.7271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000235213.jpg"}, {"question": "is this fire hydrant functional or is it just for show", "gt answer": "functional(1.00)<br/>show(1.00)", "pred answer": "real", "question_id": 5396755, "best approach": "wiki", "verif answer": "sale", "anno approach": "wiki, concept, image", "verif wiki answer": "show(0.5743)", "verif concept answer": "sale(0.5559)", "verif image answer": "fly(0.5188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539675.jpg"}, {"question": "what are these ground tracks used for", "gt answer": "train(1.00)<br/>transport(1.00)<br/>transportation(0.60)", "pred answer": "coal", "question_id": 5253985, "best approach": "wiki, image", "verif answer": "transport", "anno approach": "wiki, concept, image", "verif wiki answer": "transport(0.7253)", "verif concept answer": "transport good(0.6880)", "verif image answer": "transport(0.6774)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525398.jpg"}, {"question": "what is the name of the rumbling sound these animals typically make", "gt answer": "purr(1.00)<br/>pure(1.00)", "pred answer": "meow", "question_id": 2172995, "best approach": "", "verif answer": "meow", "anno approach": "wiki, concept, image", "verif wiki answer": "meow(0.7308)", "verif concept answer": "meow(0.7273)", "verif image answer": "meow(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217299.jpg"}, {"question": "what type of pasta is represented", "gt answer": "shell(1.00)", "pred answer": "penne", "question_id": 5601865, "best approach": "", "verif answer": "ram", "anno approach": "wiki, concept, image", "verif wiki answer": "ram(0.5199)", "verif concept answer": "ram(0.6501)", "verif image answer": "rock(0.5582)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560186.jpg"}, {"question": "what 's this guy in between", "gt answer": "pier(1.00)", "pred answer": "wave", "question_id": 2279185, "best approach": "", "verif answer": "dock", "anno approach": "wiki, concept, image", "verif wiki answer": "perch(0.6188)", "verif concept answer": "dock(0.6727)", "verif image answer": "dock(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000227918.jpg"}, {"question": "why is this person cooking", "gt answer": "hungry(1.00)<br/>to eat(0.60)<br/>holiday(0.60)", "pred answer": "warmth", "question_id": 3057095, "best approach": "wiki", "verif answer": "hungry", "anno approach": "wiki, concept, image", "verif wiki answer": "hungry(0.7280)", "verif concept answer": "to eat(0.7281)", "verif image answer": "to eat(0.7109)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305709.jpg"}, {"question": "how is this food made", "gt answer": "baked(1.00)<br/>oven(0.60)", "pred answer": "steamed", "question_id": 4905705, "best approach": "image", "verif answer": "baked in oven", "anno approach": "wiki, concept, image", "verif wiki answer": "boiled(0.7283)", "verif concept answer": "boiled(0.7237)", "verif image answer": "baked(0.7138)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490570.jpg"}, {"question": "what is wrong with that zebra", "gt answer": "it ear(1.00)<br/>nothing(0.60)", "pred answer": "dead", "question_id": 115545, "best approach": "wiki", "verif answer": "dead", "anno approach": "wiki, concept, image", "verif wiki answer": "it ear(0.7287)", "verif concept answer": "sing(0.6713)", "verif image answer": "sing(0.7249)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011554.jpg"}, {"question": "how long would this side dish take to cook", "gt answer": "5 minutes(0.60)<br/>hour(1.00)<br/>10 minutes(0.60)<br/>1 hour(0.60)", "pred answer": "4 months", "question_id": 764065, "best approach": "image", "verif answer": "hour", "anno approach": "wiki, concept, image", "verif wiki answer": "30 minutes(0.7022)", "verif concept answer": "1 hour(0.6853)", "verif image answer": "hour(0.7190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076406.jpg"}, {"question": "what type of market do most people call this", "gt answer": "farmer market(1.00)<br/>grocery(0.60)<br/>farmer(0.60)", "pred answer": "produce", "question_id": 4576785, "best approach": "wiki, image", "verif answer": "farmer", "anno approach": "wiki, concept, image", "verif wiki answer": "farmer(0.7287)", "verif concept answer": "market(0.6478)", "verif image answer": "farmer(0.5579)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457678.jpg"}, {"question": "how old do you have to be in canada to do this", "gt answer": "18(1.00)", "pred answer": "21", "question_id": 817215, "best approach": "image", "verif answer": "21", "anno approach": "wiki, concept, image", "verif wiki answer": "21(0.7220)", "verif concept answer": "18 years(0.6166)", "verif image answer": "18(0.7122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081721.jpg"}, {"question": "what 's another word for coffee", "gt answer": "java(1.00)", "pred answer": "espresso", "question_id": 2024235, "best approach": "image", "verif answer": "espresso", "anno approach": "wiki, concept, image", "verif wiki answer": "espresso(0.7290)", "verif concept answer": "espresso(0.7285)", "verif image answer": "java(0.5273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202423.jpg"}, {"question": "what would the giraffes do if threatened", "gt answer": "run(1.00)", "pred answer": "forget", "question_id": 5738855, "best approach": "", "verif answer": "run", "anno approach": "wiki, concept, image", "verif wiki answer": "run with scissor(0.7103)", "verif concept answer": "run with scissor(0.7205)", "verif image answer": "run with scissor(0.6316)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000573885.jpg"}, {"question": "what watersport is the person doing", "gt answer": "parasailing(1.00)<br/>windsurf(0.60)<br/>surf(0.60)", "pred answer": "ocean", "question_id": 997285, "best approach": "wiki", "verif answer": "swim", "anno approach": "wiki, concept, image", "verif wiki answer": "parasailing(0.7196)", "verif concept answer": "swim(0.6886)", "verif image answer": "windsurf(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099728.jpg"}, {"question": "why is the woman wearing a mask", "gt answer": "pollution(1.00)<br/>religion(0.60)", "pred answer": "rain", "question_id": 3451725, "best approach": "", "verif answer": "fog", "anno approach": "wiki, concept, image", "verif wiki answer": "snow(0.5686)", "verif concept answer": "clear(0.6100)", "verif image answer": "fog(0.7168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345172.jpg"}, {"question": "what are these women doing", "gt answer": "play video game(0.60)<br/>play(0.60)<br/>play game(1.00)<br/>play wii(0.60)", "pred answer": "video game", "question_id": 2496185, "best approach": "wiki", "verif answer": "video game", "anno approach": "wiki, concept, image", "verif wiki answer": "play game(0.6752)", "verif concept answer": "play video game(0.7250)", "verif image answer": "play(0.7258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249618.jpg"}, {"question": "what type of shopping experience is going on here", "gt answer": "farmer market(1.00)<br/>market(0.60)", "pred answer": "produce", "question_id": 3314575, "best approach": "concept, image", "verif answer": "market", "anno approach": "wiki, concept, image", "verif wiki answer": "supermarket(0.6987)", "verif concept answer": "market(0.6886)", "verif image answer": "market(0.6941)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331457.jpg"}, {"question": "what brand of ripped jeans is being worn", "gt answer": "levis(1.00)", "pred answer": "denim", "question_id": 4909315, "best approach": "concept, image", "verif answer": "levi", "anno approach": "wiki, concept, image", "verif wiki answer": "skinny(0.7186)", "verif concept answer": "levis(0.7245)", "verif image answer": "levis(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490931.jpg"}, {"question": "is this a pet or stray cat", "gt answer": "stray(1.00)", "pred answer": "pet", "question_id": 391965, "best approach": "wiki, concept, image", "verif answer": "family", "anno approach": "wiki, concept, image", "verif wiki answer": "stray(0.5738)", "verif concept answer": "stray(0.7282)", "verif image answer": "stray(0.7071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039196.jpg"}, {"question": "why is this man not worried about audience reactions", "gt answer": "no 1 is there(1.00)", "pred answer": "fun", "question_id": 1323855, "best approach": "", "verif answer": "legal", "anno approach": "wiki, concept, image", "verif wiki answer": "legal(0.7090)", "verif concept answer": "legal(0.7034)", "verif image answer": "cancer(0.6791)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000132385.jpg"}, {"question": "how fast will they fall", "gt answer": "fast(1.00)<br/>very fast(0.60)<br/>extremely(0.60)", "pred answer": "100 mph", "question_id": 832685, "best approach": "wiki, concept", "verif answer": "fast", "anno approach": "wiki, concept, image", "verif wiki answer": "fast(0.6398)", "verif concept answer": "fast(0.6153)", "verif image answer": "very fast(0.6313)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083268.jpg"}, {"question": "when did the stuffed animal shown here first originate", "gt answer": "1902(1.00)<br/>rugby(0.60)<br/>1903(0.60)", "pred answer": "1950s", "question_id": 3083125, "best approach": "wiki, concept", "verif answer": "1924", "anno approach": "wiki, concept, image", "verif wiki answer": "1902(0.6428)", "verif concept answer": "1902(0.6887)", "verif image answer": "1903(0.7090)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308312.jpg"}, {"question": "in what condition is the train station", "gt answer": "good(1.00)<br/>empty(0.60)", "pred answer": "poor", "question_id": 5815825, "best approach": "", "verif answer": "poor", "anno approach": "wiki, concept, image", "verif wiki answer": "distraction(0.7246)", "verif concept answer": "danger(0.6605)", "verif image answer": "distraction(0.7134)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000581582.jpg"}, {"question": "where was this photo taken", "gt answer": "street(1.00)<br/>india(0.60)<br/>park lot(0.60)<br/>city(0.60)", "pred answer": "highway", "question_id": 3744905, "best approach": "wiki", "verif answer": "park lot", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.6747)", "verif concept answer": "city(0.6920)", "verif image answer": "mexico(0.6546)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374490.jpg"}, {"question": "what is unusual about the surface the boats are resting on", "gt answer": "no water(1.00)<br/>solid(0.60)<br/>land(0.60)", "pred answer": "marina", "question_id": 5589245, "best approach": "wiki, concept", "verif answer": "mud", "anno approach": "wiki, concept, image", "verif wiki answer": "no water(0.7037)", "verif concept answer": "no water(0.6899)", "verif image answer": "dirt(0.6713)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558924.jpg"}, {"question": "what vegetable does it take to make what she holding", "gt answer": "potato(1.00)<br/>carrot(0.60)", "pred answer": "cucumber", "question_id": 5762255, "best approach": "concept, image", "verif answer": "potato", "anno approach": "wiki, concept, image", "verif wiki answer": "pepper(0.7236)", "verif concept answer": "potato(0.6766)", "verif image answer": "potato(0.6853)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000576225.jpg"}, {"question": "a person in what sort profession might own this library", "gt answer": "chef(1.00)<br/>cook(1.00)", "pred answer": "computer repair", "question_id": 5056615, "best approach": "", "verif answer": "italians", "anno approach": "wiki, concept, image", "verif wiki answer": "italians(0.6495)", "verif concept answer": "italians(0.6225)", "verif image answer": "italians(0.5897)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505661.jpg"}, {"question": "what sport is this", "gt answer": "football(1.00)", "pred answer": "motocross", "question_id": 2112835, "best approach": "", "verif answer": "soccer", "anno approach": "wiki, concept, image", "verif wiki answer": "soccer(0.6004)", "verif concept answer": "soccer(0.6472)", "verif image answer": "soccer(0.5157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000211283.jpg"}, {"question": "which animal is taller the one with stripes or the one with spots", "gt answer": "spot(1.00)", "pred answer": "giraffe", "question_id": 4426805, "best approach": "", "verif answer": "long neck", "anno approach": "wiki, concept, image", "verif wiki answer": "shark(0.7181)", "verif concept answer": "shark(0.6128)", "verif image answer": "long neck(0.6909)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442680.jpg"}, {"question": "why can you see two of the man and pet", "gt answer": "mirror(1.00)<br/>reflection(0.60)", "pred answer": "family", "question_id": 736105, "best approach": "concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "light(0.6652)", "verif concept answer": "mirror(0.5169)", "verif image answer": "light(0.5245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073610.jpg"}, {"question": "what type of item is connected to this person 's pants", "gt answer": "suspend(1.00)", "pred answer": "belt", "question_id": 1001595, "best approach": "", "verif answer": "belt", "anno approach": "wiki, concept, image", "verif wiki answer": "bluetooth(0.5370)", "verif concept answer": "earring(0.6524)", "verif image answer": "belt(0.6072)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100159.jpg"}, {"question": "which city is this", "gt answer": "brooklyn(1.00)<br/>new york city(0.60)", "pred answer": "copenhagen", "question_id": 3473595, "best approach": "", "verif answer": "beijing", "anno approach": "wiki, concept, image", "verif wiki answer": "washington(0.7077)", "verif concept answer": "beijing(0.7017)", "verif image answer": "washington(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347359.jpg"}, {"question": "what sport video game are they playing", "gt answer": "box(1.00)", "pred answer": "wii", "question_id": 4822515, "best approach": "", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "wii(0.7291)", "verif concept answer": "wii(0.7122)", "verif image answer": "wii(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482251.jpg"}, {"question": "what breed of animal is this", "gt answer": "dog(1.00)<br/>doberman(0.60)<br/>chihuahua(0.60)", "pred answer": "bear", "question_id": 876335, "best approach": "wiki", "verif answer": "dog", "anno approach": "wiki, concept, image", "verif wiki answer": "dog(0.7220)", "verif concept answer": "chihuahua(0.7221)", "verif image answer": "doberman(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087633.jpg"}, {"question": "who is this man", "gt answer": "actor(1.00)<br/>model(0.60)", "pred answer": "man", "question_id": 2101895, "best approach": "", "verif answer": "sailor", "anno approach": "wiki, concept, image", "verif wiki answer": "sailor(0.6964)", "verif concept answer": "san francisco(0.6287)", "verif image answer": "sailor(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210189.jpg"}, {"question": "what letter of the alphabet could this sail be compared to", "gt answer": "d(1.00)<br/>c(0.60)", "pred answer": "", "question_id": 434795, "best approach": "", "verif answer": "", "anno approach": "wiki, concept, image", "verif wiki answer": "(0.7224)", "verif concept answer": "(0.7110)", "verif image answer": "(0.7021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043479.jpg"}, {"question": "can you guess the place name where these game is being played", "gt answer": "baseball stadium(1.00)", "pred answer": "baseball field", "question_id": 4341615, "best approach": "wiki, concept, image", "verif answer": "stadium", "anno approach": "wiki, concept, image", "verif wiki answer": "baseball stadium(0.7016)", "verif concept answer": "baseball stadium(0.7078)", "verif image answer": "baseball stadium(0.6922)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434161.jpg"}, {"question": "what unusual kind of object is attached to this plane 's top", "gt answer": "radar(1.00)<br/>wing(0.60)<br/>camera(0.60)", "pred answer": "propeller", "question_id": 5068435, "best approach": "wiki", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "camera(0.7048)", "verif concept answer": "fly(0.7100)", "verif image answer": "helicopter(0.7159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506843.jpg"}, {"question": "what youtube video are they watching", "gt answer": "dance(1.00)", "pred answer": "television", "question_id": 2917645, "best approach": "wiki", "verif answer": "dance", "anno approach": "wiki, concept, image", "verif wiki answer": "dance(0.7129)", "verif concept answer": "karaoke(0.6711)", "verif image answer": "karaoke(0.7203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291764.jpg"}, {"question": "what is strange about these bananas", "gt answer": "face(1.00)<br/>orange(0.60)", "pred answer": "good", "question_id": 3358605, "best approach": "", "verif answer": "letter", "anno approach": "wiki, concept, image", "verif wiki answer": "smiley face(0.6331)", "verif concept answer": "smiley face(0.7151)", "verif image answer": "letter(0.7159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335860.jpg"}, {"question": "what are recent security issues related to this area of an airport", "gt answer": "bomb(1.00)", "pred answer": "light", "question_id": 5547525, "best approach": "", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "military(0.7262)", "verif concept answer": "military(0.6586)", "verif image answer": "fly(0.6914)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554752.jpg"}, {"question": "what word that starts with n are these animals doing", "gt answer": "nuzzle(1.00)<br/>nest(0.60)<br/>nursing(0.60)", "pred answer": "stripe", "question_id": 948255, "best approach": "wiki, concept", "verif answer": "nursing", "anno approach": "wiki, concept, image", "verif wiki answer": "nuzzle(0.7098)", "verif concept answer": "nuzzle(0.7214)", "verif image answer": "feed(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094825.jpg"}, {"question": "how much does the surfboard this person is standing on weigh", "gt answer": "20 pounds(1.00)<br/>10 pounds(0.60)", "pred answer": "20", "question_id": 3018855, "best approach": "", "verif answer": "20", "anno approach": "wiki, concept, image", "verif wiki answer": "100 lbs(0.6782)", "verif concept answer": "100 lbs(0.6622)", "verif image answer": "100 lbs(0.6676)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301885.jpg"}, {"question": "what united state is famous for the vegetable listed on the front of this truck", "gt answer": "idaho(1.00)<br/>china(0.60)", "pred answer": "washington", "question_id": 2775305, "best approach": "image", "verif answer": "nevada", "anno approach": "wiki, concept, image", "verif wiki answer": "mississippi(0.5634)", "verif concept answer": "mississippi(0.5911)", "verif image answer": "china(0.6900)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277530.jpg"}, {"question": "what flower is this", "gt answer": "sunflower(1.00)<br/>dandelion(0.60)", "pred answer": "daffodil", "question_id": 253775, "best approach": "", "verif answer": "daffodil", "anno approach": "wiki, concept, image", "verif wiki answer": "daffodil(0.6957)", "verif concept answer": "daffodil(0.7279)", "verif image answer": "daffodil(0.7043)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025377.jpg"}, {"question": "in which furnicture piece is the cat lying in", "gt answer": "shelf(1.00)<br/>closet(0.60)", "pred answer": "torso", "question_id": 353185, "best approach": "wiki", "verif answer": "bookshelf", "anno approach": "wiki, concept, image", "verif wiki answer": "closet(0.5970)", "verif concept answer": "shelve(0.6394)", "verif image answer": "bookshelf(0.5439)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000035318.jpg"}, {"question": "", "gt answer": "disgust(0.60)", "pred answer": "warm", "question_id": 4188185, "best approach": "concept", "verif answer": "sink", "anno approach": "wiki, concept, image", "verif wiki answer": "sink(0.6446)", "verif concept answer": "disgust(0.5688)", "verif image answer": "sink(0.5177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000418818.jpg"}, {"question": "who was the pilot who landed one of these on the hudson river", "gt answer": "sully(1.00)", "pred answer": "wright brother", "question_id": 2375385, "best approach": "", "verif answer": "air force 1", "anno approach": "wiki, concept, image", "verif wiki answer": "air force 1(0.7284)", "verif concept answer": "air force 1(0.7246)", "verif image answer": "air force 1(0.7271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237538.jpg"}, {"question": "how many people can fit on that bus", "gt answer": "many(1.00)<br/>60(0.60)<br/>50(0.60)<br/>34(0.60)", "pred answer": "20", "question_id": 3734145, "best approach": "wiki, concept", "verif answer": "50", "anno approach": "wiki, concept, image", "verif wiki answer": "34(0.7182)", "verif concept answer": "34(0.6973)", "verif image answer": "200(0.7103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373414.jpg"}, {"question": "which kelly slater 's pro surfer character does this person most look like", "gt answer": "kelly slater(1.00)<br/>iron(0.60)", "pred answer": "tony hawk", "question_id": 3400815, "best approach": "wiki", "verif answer": "tony hawk", "anno approach": "wiki, concept, image", "verif wiki answer": "kelly slater(0.7308)", "verif concept answer": "tony hawk(0.7258)", "verif image answer": "tony hawk(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340081.jpg"}, {"question": "where is the rest of the stuff", "gt answer": "in suitcase(1.00)<br/>inside(1.00)", "pred answer": "van", "question_id": 3712585, "best approach": "wiki, concept", "verif answer": "in suitcase", "anno approach": "wiki, concept, image", "verif wiki answer": "inside(0.7238)", "verif concept answer": "inside(0.7098)", "verif image answer": "outside(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371258.jpg"}, {"question": "what name is given to this auto in a road race", "gt answer": "pace car(1.00)<br/>honda(0.60)", "pred answer": "mercedes", "question_id": 1127265, "best approach": "wiki", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "honda(0.6920)", "verif concept answer": "scooter(0.5872)", "verif image answer": "motorcycle(0.7205)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000112726.jpg"}, {"question": "who is this player", "gt answer": "baseball player(1.00)", "pred answer": "babe ruth", "question_id": 1420985, "best approach": "", "verif answer": "baseball player", "anno approach": "wiki, concept, image", "verif wiki answer": "hitter(0.6994)", "verif concept answer": "hitter(0.7200)", "verif image answer": "hitter(0.6172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142098.jpg"}, {"question": "why do cats sleep so much", "gt answer": "lazy(1.00)<br/>habit(0.60)", "pred answer": "tired", "question_id": 3767125, "best approach": "", "verif answer": "lazy", "anno approach": "wiki, concept, image", "verif wiki answer": "amatuer(0.6246)", "verif concept answer": "amatuer(0.6335)", "verif image answer": "amatuer(0.6421)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376712.jpg"}, {"question": "what were these made for", "gt answer": "halloween(1.00)", "pred answer": "kid", "question_id": 5546985, "best approach": "image", "verif answer": "halloween", "anno approach": "wiki, concept, image", "verif wiki answer": "party(0.6091)", "verif concept answer": "party(0.6447)", "verif image answer": "halloween(0.6670)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554698.jpg"}, {"question": "which us president made this toy famous", "gt answer": "teddy roosevelt(1.00)<br/>roosevelt(1.00)<br/>obama(0.60)", "pred answer": "theodore roosevelt", "question_id": 3357125, "best approach": "", "verif answer": "theodore roosevelt", "anno approach": "wiki, concept, image", "verif wiki answer": "theodore roosevelt(0.7269)", "verif concept answer": "theodore roosevelt(0.7232)", "verif image answer": "barack obama(0.7176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335712.jpg"}, {"question": "how much will these animals weigh when fully grown", "gt answer": "2000 pounds(1.00)<br/>500 pounds(0.60)<br/>1500(0.60)", "pred answer": "100 lbs", "question_id": 2760155, "best approach": "concept", "verif answer": "1500", "anno approach": "wiki, concept, image", "verif wiki answer": "400 lbs(0.7099)", "verif concept answer": "500 pounds(0.6814)", "verif image answer": "300 pounds(0.7217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276015.jpg"}, {"question": "which item that she is wearing is often named after the sport that she is playing", "gt answer": "tennis skirt(1.00)<br/>tennis shoe(0.60)<br/>shoe(0.60)", "pred answer": "tennis", "question_id": 1996095, "best approach": "wiki, concept, image", "verif answer": "tennis", "anno approach": "wiki, concept, image", "verif wiki answer": "tennis shoe(0.6492)", "verif concept answer": "tennis shoe(0.6716)", "verif image answer": "shoe(0.6065)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199609.jpg"}, {"question": "what is the dark brown food in the forground of this photo called", "gt answer": "cake(1.00)<br/>sit(0.60)", "pred answer": "cupcake", "question_id": 2446355, "best approach": "concept", "verif answer": "cake", "anno approach": "wiki, concept, image", "verif wiki answer": "cookies(0.7239)", "verif concept answer": "sit(0.7149)", "verif image answer": "cookies(0.6776)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244635.jpg"}, {"question": "what item here is associated with intestinal gas", "gt answer": "bean(1.00)", "pred answer": "potato", "question_id": 2519885, "best approach": "wiki, concept, image", "verif answer": "wing", "anno approach": "wiki, concept, image", "verif wiki answer": "bean(0.5746)", "verif concept answer": "bean(0.7084)", "verif image answer": "bean(0.6274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251988.jpg"}, {"question": "what type of meat is obtained from these animals", "gt answer": "beef(1.00)<br/>steak(0.60)", "pred answer": "pork", "question_id": 3214185, "best approach": "", "verif answer": "pork", "anno approach": "wiki, concept, image", "verif wiki answer": "pork(0.6844)", "verif concept answer": "pork(0.6990)", "verif image answer": "hamburger(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321418.jpg"}, {"question": "what 's leaning in picture", "gt answer": "lamp(1.00)<br/>lampshade(1.00)", "pred answer": "light", "question_id": 783055, "best approach": "wiki, concept", "verif answer": "bed", "anno approach": "wiki, concept, image", "verif wiki answer": "lamp(0.7193)", "verif concept answer": "lamp(0.7221)", "verif image answer": "bed(0.7221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078305.jpg"}, {"question": "why would we suspect this office belongs to a vintage car enthusiast", "gt answer": "picture(1.00)", "pred answer": "headphone", "question_id": 3854175, "best approach": "concept", "verif answer": "tv", "anno approach": "wiki, concept, image", "verif wiki answer": "tv(0.6137)", "verif concept answer": "picture(0.5820)", "verif image answer": "light(0.6820)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385417.jpg"}, {"question": "what type of knife is being used to cut this apple", "gt answer": "pair(1.00)<br/>kitchen(0.60)", "pred answer": "butter", "question_id": 5261965, "best approach": "image", "verif answer": "flip", "anno approach": "wiki, concept, image", "verif wiki answer": "short(0.5593)", "verif concept answer": "short(0.6714)", "verif image answer": "kitchen(0.5956)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526196.jpg"}, {"question": "what substance is this animal trying to remove from her teeth", "gt answer": "plaque(1.00)", "pred answer": "toothpaste", "question_id": 3145375, "best approach": "", "verif answer": "scissor", "anno approach": "wiki, concept, image", "verif wiki answer": "sign(0.5287)", "verif concept answer": "scissor(0.6661)", "verif image answer": "brush(0.5492)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314537.jpg"}, {"question": "what activities could you do in this room", "gt answer": "watch tv(1.00)<br/>television(0.60)<br/>read(0.60)", "pred answer": "relax", "question_id": 2528505, "best approach": "image", "verif answer": "watch tv", "anno approach": "wiki, concept, image", "verif wiki answer": "read(0.7199)", "verif concept answer": "read(0.7219)", "verif image answer": "watch tv(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252850.jpg"}, {"question": "what are sinks used for", "gt answer": "wash(1.00)", "pred answer": "wash hand", "question_id": 5518775, "best approach": "", "verif answer": "wash", "anno approach": "wiki, concept, image", "verif wiki answer": "bath(0.6549)", "verif concept answer": "bath(0.6685)", "verif image answer": "de ice(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000551877.jpg"}, {"question": "what 's this guy doing", "gt answer": "work(1.00)", "pred answer": "play video game", "question_id": 535395, "best approach": "", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "meet(0.7216)", "verif concept answer": "meet(0.7110)", "verif image answer": "meet(0.7158)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053539.jpg"}, {"question": "what type of vegetable is she holding", "gt answer": "broccoli(1.00)", "pred answer": "banana", "question_id": 970575, "best approach": "concept", "verif answer": "broccoli", "anno approach": "wiki, concept, image", "verif wiki answer": "meat(0.6886)", "verif concept answer": "broccoli(0.7206)", "verif image answer": "meat(0.5358)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097057.jpg"}, {"question": "the patties are made of which meat", "gt answer": "hamburger(1.00)<br/>beef(1.00)", "pred answer": "pork", "question_id": 1831125, "best approach": "", "verif answer": "beef", "anno approach": "wiki, concept, image", "verif wiki answer": "roast beef(0.6584)", "verif concept answer": "meat(0.6778)", "verif image answer": "meat(0.7174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183112.jpg"}, {"question": "how long will it take to finish this meal", "gt answer": "10 minutes(1.00)<br/>5 minutes(0.60)", "pred answer": "4 months", "question_id": 4476275, "best approach": "wiki", "verif answer": "5 minutes", "anno approach": "wiki, concept, image", "verif wiki answer": "10 minutes(0.6930)", "verif concept answer": "grilled(0.6174)", "verif image answer": "5 minutes(0.6671)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447627.jpg"}, {"question": "what breed of dog is this", "gt answer": "mix(1.00)<br/>pit bull(0.60)<br/>lab(0.60)", "pred answer": "retriever", "question_id": 5462285, "best approach": "wiki, concept, image", "verif answer": "retriever", "anno approach": "wiki, concept, image", "verif wiki answer": "pit bull(0.7220)", "verif concept answer": "pit bull(0.6811)", "verif image answer": "lab(0.7166)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546228.jpg"}, {"question": "what type of boat is this", "gt answer": "barge(1.00)<br/>raft(0.60)<br/>canal(0.60)", "pred answer": "canoe", "question_id": 230355, "best approach": "wiki, concept, image", "verif answer": "canal", "anno approach": "wiki, concept, image", "verif wiki answer": "canal(0.7033)", "verif concept answer": "canal(0.6624)", "verif image answer": "canal(0.7060)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023035.jpg"}, {"question": "which two primary colors are featured in this picture", "gt answer": "red and green(1.00)", "pred answer": "talk and eat", "question_id": 3613925, "best approach": "", "verif answer": "red yellow green", "anno approach": "wiki, concept, image", "verif wiki answer": "red yellow green(0.7192)", "verif concept answer": "male(0.7184)", "verif image answer": "green(0.7219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361392.jpg"}, {"question": "what common breakfast food is often enjoyed with sliced up pieces of fruit such as is seen here", "gt answer": "cereal(1.00)<br/>fruit salad(0.60)<br/>pancake(1.00)", "pred answer": "dessert", "question_id": 3923305, "best approach": "", "verif answer": "dessert", "anno approach": "wiki, concept, image", "verif wiki answer": "boiled(0.6696)", "verif concept answer": "boiled(0.6868)", "verif image answer": "boiled(0.6199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392330.jpg"}, {"question": "what kind of store is this", "gt answer": "furniture(1.00)<br/>furniture store(0.60)<br/>antique(0.60)", "pred answer": "gift shop", "question_id": 1315095, "best approach": "wiki", "verif answer": "furniture store", "anno approach": "wiki, concept, image", "verif wiki answer": "furniture store(0.6427)", "verif concept answer": "convenience store(0.7075)", "verif image answer": "purse(0.6562)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000131509.jpg"}, {"question": "what can this person be using a mirror and scissors for", "gt answer": "cut hair(1.00)<br/>haircut(0.60)<br/>shave(0.60)", "pred answer": "toothpaste", "question_id": 2086445, "best approach": "wiki, concept", "verif answer": "haircut", "anno approach": "wiki, concept, image", "verif wiki answer": "cut hair(0.7167)", "verif concept answer": "cut hair(0.7132)", "verif image answer": "haircut(0.7180)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208644.jpg"}, {"question": "what type of boats are these", "gt answer": "paddle(0.60)<br/>row boat(1.00)<br/>row(0.60)", "pred answer": "canoes", "question_id": 678025, "best approach": "concept", "verif answer": "paddle", "anno approach": "wiki, concept, image", "verif wiki answer": "row(0.7263)", "verif concept answer": "row boat(0.7081)", "verif image answer": "paddleboard(0.7057)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067802.jpg"}, {"question": "why is the woman in the orange helmet up there", "gt answer": "zipline(1.00)", "pred answer": "protection", "question_id": 577965, "best approach": "image", "verif answer": "vacation", "anno approach": "wiki, concept, image", "verif wiki answer": "vacation(0.7073)", "verif concept answer": "flip(0.7123)", "verif image answer": "zipline(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000057796.jpg"}, {"question": "what kind of wakeboard is the man using", "gt answer": "continuous(1.00)<br/>ski(0.60)", "pred answer": "longboard", "question_id": 5314595, "best approach": "", "verif answer": "water ski", "anno approach": "wiki, concept, image", "verif wiki answer": "water ski(0.7053)", "verif concept answer": "water ski(0.7151)", "verif image answer": "water ski(0.6348)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531459.jpg"}, {"question": "who is on the cup", "gt answer": "queen elizabeth(1.00)<br/>shakespeare(0.60)<br/>king(0.60)<br/>woman(0.60)", "pred answer": "bill clinton", "question_id": 3929475, "best approach": "wiki, concept, image", "verif answer": "queen elizabeth", "anno approach": "wiki, concept, image", "verif wiki answer": "queen elizabeth(0.6540)", "verif concept answer": "queen elizabeth(0.7303)", "verif image answer": "queen elizabeth(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392947.jpg"}, {"question": "what is the formal name of this type of drapery", "gt answer": "curtain(1.00)", "pred answer": "skirt", "question_id": 373265, "best approach": "", "verif answer": "quilt", "anno approach": "wiki, concept, image", "verif wiki answer": "blind(0.6777)", "verif concept answer": "blind(0.6701)", "verif image answer": "blind(0.7238)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000037326.jpg"}, {"question": "what can you do in this room", "gt answer": "sit(1.00)<br/>watch tv(0.60)<br/>read(0.60)", "pred answer": "eat", "question_id": 3342515, "best approach": "wiki, concept, image", "verif answer": "read", "anno approach": "wiki, concept, image", "verif wiki answer": "read(0.7219)", "verif concept answer": "read(0.7280)", "verif image answer": "read(0.7158)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334251.jpg"}, {"question": "what job would use these products on a daily basis", "gt answer": "janitor(1.00)", "pred answer": "plumber", "question_id": 1728895, "best approach": "", "verif answer": "plumber", "anno approach": "wiki, concept, image", "verif wiki answer": "fireman(0.7308)", "verif concept answer": "fireman(0.7306)", "verif image answer": "plumber(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000172889.jpg"}, {"question": "name a movie that included this type of animal", "gt answer": "dumbo(1.00)", "pred answer": "lion king", "question_id": 2504345, "best approach": "wiki", "verif answer": "lion king", "anno approach": "wiki, concept, image", "verif wiki answer": "dumbo(0.7268)", "verif concept answer": "lion king(0.7264)", "verif image answer": "pacaderm(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250434.jpg"}, {"question": "what year where these models made", "gt answer": "1920(1.00)<br/>1930s(0.60)", "pred answer": "1940", "question_id": 325625, "best approach": "image", "verif answer": "1945", "anno approach": "wiki, concept, image", "verif wiki answer": "1945(0.7220)", "verif concept answer": "1945(0.6849)", "verif image answer": "1930s(0.6859)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032562.jpg"}, {"question": "", "gt answer": "1940s(0.60)<br/>1940's(0.60)<br/>1960(0.60)", "pred answer": "1930", "question_id": 3361075, "best approach": "wiki, concept, image", "verif answer": "1940", "anno approach": "wiki, concept, image", "verif wiki answer": "1940s(0.6125)", "verif concept answer": "1960(0.5857)", "verif image answer": "1940s(0.6416)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000336107.jpg"}, {"question": "what plane is that", "gt answer": "passenger(1.00)<br/>private(1.00)", "pred answer": "private jet", "question_id": 4271665, "best approach": "concept", "verif answer": "private jet", "anno approach": "wiki, concept, image", "verif wiki answer": "private jet(0.7151)", "verif concept answer": "private(0.6808)", "verif image answer": "private jet(0.7217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427166.jpg"}, {"question": "what vitamins do you get from these vegetables", "gt answer": "vitamin(1.00)<br/>d(1.00)", "pred answer": "", "question_id": 2188465, "best approach": "", "verif answer": "d", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin c(0.6893)", "verif concept answer": "vitamin c(0.6870)", "verif image answer": "protein(0.6576)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218846.jpg"}, {"question": "what is the exchange being offered here", "gt answer": "cash for gold(1.00)", "pred answer": "money", "question_id": 4846665, "best approach": "wiki, concept", "verif answer": "mcdonalds", "anno approach": "wiki, concept, image", "verif wiki answer": "cash for gold(0.5688)", "verif concept answer": "cash for gold(0.6248)", "verif image answer": "high(0.5452)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484666.jpg"}, {"question": "what is in the cereal dish", "gt answer": "cheerio(1.00)", "pred answer": "egg", "question_id": 5296305, "best approach": "image", "verif answer": "whole grain", "anno approach": "wiki, concept, image", "verif wiki answer": "whole grain(0.5816)", "verif concept answer": "tell time(0.5421)", "verif image answer": "cheerio(0.7129)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529630.jpg"}, {"question": "what historical figure are these type of birds associated with", "gt answer": "pirate(1.00)<br/>captain morgan(0.60)<br/>human(0.60)", "pred answer": "fish", "question_id": 3046915, "best approach": "wiki", "verif answer": "pirate", "anno approach": "wiki, concept, image", "verif wiki answer": "human(0.6755)", "verif concept answer": "ben franklin(0.7085)", "verif image answer": "ben franklin(0.6867)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304691.jpg"}, {"question": "how can you distinguish the male cow from the female cow", "gt answer": "udder(1.00)<br/>horn(0.60)", "pred answer": "bad luck", "question_id": 1174945, "best approach": "image", "verif answer": "kitten", "anno approach": "wiki, concept, image", "verif wiki answer": "0(0.6228)", "verif concept answer": "0(0.6400)", "verif image answer": "udder(0.5548)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117494.jpg"}, {"question": "where is this famous street", "gt answer": "dublin(1.00)<br/>london(0.60)", "pred answer": "europe", "question_id": 2939465, "best approach": "concept", "verif answer": "europe", "anno approach": "wiki, concept, image", "verif wiki answer": "druid hill(0.6786)", "verif concept answer": "dublin(0.7002)", "verif image answer": "druid hill(0.7181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293946.jpg"}, {"question": "what is the man doing", "gt answer": "work(1.00)<br/>compute(0.60)<br/>use laptop(0.60)", "pred answer": "play video game", "question_id": 2832945, "best approach": "wiki, concept, image", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "use laptop(0.7108)", "verif concept answer": "compute(0.7093)", "verif image answer": "compute(0.7144)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283294.jpg"}, {"question": "when was the last time this team won a national title", "gt answer": "1984(1.00)", "pred answer": "1839", "question_id": 40425, "best approach": "", "verif answer": "1924", "anno approach": "wiki, concept, image", "verif wiki answer": "1924(0.7158)", "verif concept answer": "2010(0.7156)", "verif image answer": "2010(0.6832)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004042.jpg"}, {"question": "who sponsors this vehicle", "gt answer": "citilink(1.00)", "pred answer": "ford", "question_id": 5616415, "best approach": "concept", "verif answer": "overnite", "anno approach": "wiki, concept, image", "verif wiki answer": "speed stick(0.6498)", "verif concept answer": "citilink(0.6890)", "verif image answer": "overnite(0.6006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561641.jpg"}, {"question": "which is the cleaning agent used for cleaning of this cooking range", "gt answer": "degreaser(1.00)", "pred answer": "scissor", "question_id": 2858005, "best approach": "wiki", "verif answer": "clean", "anno approach": "wiki, concept, image", "verif wiki answer": "degreaser(0.5280)", "verif concept answer": "ocean(0.5128)", "verif image answer": "clean(0.5042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285800.jpg"}, {"question": "what is the name of a famous chain that sells this product", "gt answer": "dunkin donuts(1.00)<br/>nintendo(0.60)", "pred answer": "walmart", "question_id": 5213865, "best approach": "wiki, image", "verif answer": "dunkin donuts", "anno approach": "wiki, concept, image", "verif wiki answer": "nintendo(0.6444)", "verif concept answer": "ford(0.6615)", "verif image answer": "nintendo(0.5498)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521386.jpg"}, {"question": "what kind of doughnut is in this picture", "gt answer": "powdered(1.00)<br/>jelly filled(1.00)", "pred answer": "glazed", "question_id": 4437525, "best approach": "wiki, concept, image", "verif answer": "cherry", "anno approach": "wiki, concept, image", "verif wiki answer": "powdered(0.6283)", "verif concept answer": "powdered(0.6210)", "verif image answer": "jelly filled(0.5335)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443752.jpg"}, {"question": "what kind of building is this", "gt answer": "apartment(1.00)", "pred answer": "house", "question_id": 2525445, "best approach": "wiki, concept, image", "verif answer": "apartment", "anno approach": "wiki, concept, image", "verif wiki answer": "apartment(0.7167)", "verif concept answer": "apartment(0.6670)", "verif image answer": "apartment(0.7018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252544.jpg"}, {"question": "what kind of jacket is the man wearing", "gt answer": "peacoat(1.00)<br/>wool(1.00)<br/>fleece(0.60)", "pred answer": "suit", "question_id": 2518685, "best approach": "wiki, concept", "verif answer": "overcoat", "anno approach": "wiki, concept, image", "verif wiki answer": "peacoat(0.6903)", "verif concept answer": "peacoat(0.6760)", "verif image answer": "overcoat(0.7146)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251868.jpg"}, {"question": "which muscle was engaged when the man on the right stood that way", "gt answer": "calf(1.00)", "pred answer": "leg", "question_id": 5228275, "best approach": "concept, image", "verif answer": "calf", "anno approach": "wiki, concept, image", "verif wiki answer": "bovine(0.5741)", "verif concept answer": "calf(0.6555)", "verif image answer": "calf(0.7126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522827.jpg"}, {"question": "what is the make of this vehicle", "gt answer": "volkswagon(1.00)<br/>vw(0.60)<br/>volkswagen(0.60)<br/>steel(0.60)", "pred answer": "ford", "question_id": 366395, "best approach": "wiki, concept", "verif answer": "volkswagon", "anno approach": "wiki, concept, image", "verif wiki answer": "volkswagon(0.7118)", "verif concept answer": "volkswagon(0.7164)", "verif image answer": "chevy(0.6856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036639.jpg"}, {"question": "what would be a good side for this food", "gt answer": "salad(1.00)", "pred answer": "bread", "question_id": 1255855, "best approach": "wiki", "verif answer": "salad", "anno approach": "wiki, concept, image", "verif wiki answer": "salad(0.7091)", "verif concept answer": "soup(0.6830)", "verif image answer": "soup(0.7132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125585.jpg"}, {"question": "is his fur soft or wire like", "gt answer": "soft(1.00)<br/>wire(0.60)", "pred answer": "long", "question_id": 3444605, "best approach": "wiki, concept", "verif answer": "soft", "anno approach": "wiki, concept, image", "verif wiki answer": "soft(0.5953)", "verif concept answer": "soft(0.6039)", "verif image answer": "fluffy(0.6428)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344460.jpg"}, {"question": "what type of donut can been seen in this image", "gt answer": "cruller(1.00)<br/>sugar(0.60)", "pred answer": "glazed", "question_id": 4097065, "best approach": "wiki, concept", "verif answer": "cream", "anno approach": "wiki, concept, image", "verif wiki answer": "cruller(0.7195)", "verif concept answer": "cruller(0.5324)", "verif image answer": "cream(0.5066)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409706.jpg"}, {"question": "which sport is the little girl practising for", "gt answer": "baseball(1.00)<br/>softball(0.60)", "pred answer": "soccer", "question_id": 4203985, "best approach": "concept", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "wiffleball(0.6777)", "verif concept answer": "baseball(0.6202)", "verif image answer": "wiffleball(0.7211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420398.jpg"}, {"question": "what kind of sidedish served with a a sandwich is crunchy", "gt answer": "chip(1.00)<br/>pasta(0.60)", "pred answer": "ketchup", "question_id": 3104595, "best approach": "image", "verif answer": "ramen", "anno approach": "wiki, concept, image", "verif wiki answer": "ramen(0.6749)", "verif concept answer": "ramen(0.5809)", "verif image answer": "pasta(0.6447)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310459.jpg"}, {"question": "what spice is shown on the table", "gt answer": "pepper(1.00)", "pred answer": "cheese", "question_id": 3700595, "best approach": "wiki", "verif answer": "tomato", "anno approach": "wiki, concept, image", "verif wiki answer": "pepper(0.7048)", "verif concept answer": "tomato(0.6633)", "verif image answer": "parsley(0.5393)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370059.jpg"}, {"question": "why would we assume this man just hit the ball", "gt answer": "run(1.00)", "pred answer": "hit", "question_id": 2742325, "best approach": "", "verif answer": "run", "anno approach": "wiki, concept, image", "verif wiki answer": "run with scissor(0.6036)", "verif concept answer": "play dead(0.6110)", "verif image answer": "run with scissor(0.5841)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274232.jpg"}, {"question": "what kind of plane is this", "gt answer": "prop(1.00)<br/>seaplane(0.60)<br/>small(0.60)", "pred answer": "fighter", "question_id": 3662045, "best approach": "wiki", "verif answer": "biplane", "anno approach": "wiki, concept, image", "verif wiki answer": "prop(0.7239)", "verif concept answer": "small(0.6421)", "verif image answer": "biplane(0.7054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366204.jpg"}, {"question": "what does the sign on the top imply", "gt answer": "no truck(1.00)", "pred answer": "no park", "question_id": 159155, "best approach": "concept", "verif answer": "driveway", "anno approach": "wiki, concept, image", "verif wiki answer": "protzmann(0.5745)", "verif concept answer": "no truck(0.6310)", "verif image answer": "player(0.6305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015915.jpg"}, {"question": "what is the wire behind her head", "gt answer": "ski lift(1.00)<br/>cable(0.60)<br/>skilift(0.60)<br/>electric(0.60)", "pred answer": "power line", "question_id": 1990395, "best approach": "wiki, concept", "verif answer": "cable", "anno approach": "wiki, concept, image", "verif wiki answer": "ski lift(0.7227)", "verif concept answer": "ski lift(0.7009)", "verif image answer": "electric(0.7190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199039.jpg"}, {"question": "is this animal in a zoo or its natural habitat", "gt answer": "natural habitat(1.00)", "pred answer": "wild", "question_id": 3644025, "best approach": "wiki", "verif answer": "wild", "anno approach": "wiki, concept, image", "verif wiki answer": "natural habitat(0.7173)", "verif concept answer": "wild(0.6693)", "verif image answer": "zoo(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364402.jpg"}, {"question": "what grade is he in", "gt answer": "2nd(1.00)<br/>kindergarten(0.60)", "pred answer": "first", "question_id": 3579045, "best approach": "concept", "verif answer": "first", "anno approach": "wiki, concept, image", "verif wiki answer": "kindergarten(0.6792)", "verif concept answer": "2nd(0.6199)", "verif image answer": "1st(0.6771)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357904.jpg"}, {"question": "what popular fast food restaurant is in this photo", "gt answer": "mcdonalds(1.00)<br/>mcdonald's(1.00)<br/>wooden(0.60)", "pred answer": "hotdog", "question_id": 2849015, "best approach": "concept", "verif answer": "mcdonalds", "anno approach": "wiki, concept, image", "verif wiki answer": "food(0.5352)", "verif concept answer": "mcdonalds(0.6160)", "verif image answer": "wooden(0.5855)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284901.jpg"}, {"question": "", "gt answer": "$50(0.60)<br/>50(0.60)<br/>200(0.60)<br/>$18(0.60)", "pred answer": "15", "question_id": 102305, "best approach": "wiki, concept, image", "verif answer": "200", "anno approach": "wiki, concept, image", "verif wiki answer": "$18(0.5635)", "verif concept answer": "$18(0.5483)", "verif image answer": "$18(0.5886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000010230.jpg"}, {"question": "why is the person in the white shirt wearing a large leather glove on his left hand", "gt answer": "play baseball(1.00)<br/>catch(0.60)<br/>catcher(0.60)", "pred answer": "glove", "question_id": 5443255, "best approach": "wiki, concept, image", "verif answer": "catch", "anno approach": "wiki, concept, image", "verif wiki answer": "catcher(0.5350)", "verif concept answer": "catcher(0.5757)", "verif image answer": "catcher(0.6875)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544325.jpg"}, {"question": "what do you call a specialist who repairs these devices", "gt answer": "mechanic(1.00)", "pred answer": "plumber", "question_id": 3215925, "best approach": "", "verif answer": "engineer", "anno approach": "wiki, concept, image", "verif wiki answer": "engineer(0.7183)", "verif concept answer": "engineer(0.6651)", "verif image answer": "man(0.7056)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321592.jpg"}, {"question": "what 's the main ingredient in this dish", "gt answer": "pasta(1.00)<br/>noodle(0.60)", "pred answer": "vegetable", "question_id": 3977355, "best approach": "wiki, concept", "verif answer": "pasta", "anno approach": "wiki, concept, image", "verif wiki answer": "pasta(0.6563)", "verif concept answer": "pasta(0.6908)", "verif image answer": "ramen(0.6859)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397735.jpg"}, {"question": "what breed of dog is this", "gt answer": "rottweiler(1.00)<br/>beagle(0.60)<br/>dog(0.60)", "pred answer": "lab", "question_id": 4692815, "best approach": "", "verif answer": "doberman", "anno approach": "wiki, concept, image", "verif wiki answer": "doberman(0.7145)", "verif concept answer": "doberman(0.6798)", "verif image answer": "doberman(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469281.jpg"}, {"question": "who is the woman on the wall", "gt answer": "model(1.00)<br/>advertising(0.60)", "pred answer": "paint", "question_id": 4554275, "best approach": "wiki, image", "verif answer": "model", "anno approach": "wiki, concept, image", "verif wiki answer": "model(0.5943)", "verif concept answer": "fun(0.5379)", "verif image answer": "model(0.7023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455427.jpg"}, {"question": "name the type of aircraft shown in this picture", "gt answer": "fighter jet(1.00)", "pred answer": "jet", "question_id": 436065, "best approach": "wiki, concept", "verif answer": "fighter jet", "anno approach": "wiki, concept, image", "verif wiki answer": "fighter jet(0.7046)", "verif concept answer": "fighter jet(0.5651)", "verif image answer": "bomber(0.5271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043606.jpg"}, {"question": "what brand of backpack is this", "gt answer": "jansport(1.00)<br/>north face(0.60)", "pred answer": "columbia", "question_id": 4925455, "best approach": "wiki, concept", "verif answer": "columbia", "anno approach": "wiki, concept, image", "verif wiki answer": "jansport(0.6934)", "verif concept answer": "jansport(0.6612)", "verif image answer": "north face(0.6508)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492545.jpg"}, {"question": "what style map is on the wall", "gt answer": "world(1.00)", "pred answer": "caricature", "question_id": 5616305, "best approach": "concept", "verif answer": "abstract", "anno approach": "wiki, concept, image", "verif wiki answer": "abstract(0.6846)", "verif concept answer": "world(0.5614)", "verif image answer": "roman(0.5936)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561630.jpg"}, {"question": "what sets this apart from a city traffic jam", "gt answer": "cow(1.00)<br/>sheep(0.60)<br/>animal(0.60)", "pred answer": "light", "question_id": 4848405, "best approach": "image", "verif answer": "cow", "anno approach": "wiki, concept, image", "verif wiki answer": "animal(0.6310)", "verif concept answer": "animal(0.6557)", "verif image answer": "cow(0.6409)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484840.jpg"}, {"question": "cellphones can do what", "gt answer": "make call(1.00)<br/>call(0.60)", "pred answer": "text", "question_id": 4192495, "best approach": "wiki", "verif answer": "nokia", "anno approach": "wiki, concept, image", "verif wiki answer": "make call(0.5832)", "verif concept answer": "nokia(0.6149)", "verif image answer": "nokia(0.7045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419249.jpg"}, {"question": "color is usually associated with this disease", "gt answer": "breast cancer(1.00)<br/>cancer(0.60)<br/>red(0.60)", "pred answer": "green", "question_id": 2272505, "best approach": "concept", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "cancer(0.5825)", "verif concept answer": "breast cancer(0.6222)", "verif image answer": "cancer(0.6587)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000227250.jpg"}, {"question": "who is the owner of this building", "gt answer": "pope(1.00)", "pred answer": "priest", "question_id": 606005, "best approach": "wiki, concept, image", "verif answer": "priest", "anno approach": "wiki, concept, image", "verif wiki answer": "pope(0.7176)", "verif concept answer": "pope(0.6310)", "verif image answer": "pope(0.7078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060600.jpg"}, {"question": "what species of animal is in the picture", "gt answer": "bird(1.00)", "pred answer": "finch", "question_id": 925225, "best approach": "wiki, image", "verif answer": "bird", "anno approach": "wiki, concept, image", "verif wiki answer": "bird(0.6639)", "verif concept answer": "pigeon(0.6104)", "verif image answer": "bird(0.5985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092522.jpg"}, {"question": "what brand is this", "gt answer": "whirlpool(1.00)<br/>kenmore(0.60)<br/>maytag(0.60)", "pred answer": "ge", "question_id": 1182995, "best approach": "wiki, concept, image", "verif answer": "kenmore", "anno approach": "wiki, concept, image", "verif wiki answer": "whirlpool(0.6538)", "verif concept answer": "whirlpool(0.6817)", "verif image answer": "whirlpool(0.7047)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118299.jpg"}, {"question": "what kind of company is advertised on the bus", "gt answer": "yahoo(1.00)<br/>internet(0.60)", "pred answer": "greenwave", "question_id": 3030225, "best approach": "wiki, concept, image", "verif answer": "internet", "anno approach": "wiki, concept, image", "verif wiki answer": "yahoo(0.7076)", "verif concept answer": "yahoo(0.7162)", "verif image answer": "yahoo(0.6177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303022.jpg"}, {"question": "how can this item be made neat", "gt answer": "make bed(1.00)", "pred answer": "sew", "question_id": 848535, "best approach": "wiki, concept", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "make bed(0.7195)", "verif concept answer": "make bed(0.6975)", "verif image answer": "plastic(0.7157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084853.jpg"}, {"question": "what type of seat is this", "gt answer": "toilet(1.00)<br/>plastic(0.60)", "pred answer": "bidet", "question_id": 1237625, "best approach": "concept", "verif answer": "toilet", "anno approach": "wiki, concept, image", "verif wiki answer": "toilet seat(0.6468)", "verif concept answer": "toilet(0.6956)", "verif image answer": "toilet seat(0.6926)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123762.jpg"}, {"question": "what kind of product was once stored here", "gt answer": "grain(1.00)<br/>corn(0.60)<br/>oil(0.60)", "pred answer": "newspaper", "question_id": 3057625, "best approach": "wiki, concept", "verif answer": "paper", "anno approach": "wiki, concept, image", "verif wiki answer": "grain(0.6218)", "verif concept answer": "grain(0.6385)", "verif image answer": "dairy(0.6872)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305762.jpg"}, {"question": "what could have caused this to happen", "gt answer": "storm(1.00)<br/>flood(1.00)", "pred answer": "rain", "question_id": 4052095, "best approach": "wiki, concept", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "storm(0.6161)", "verif concept answer": "storm(0.6882)", "verif image answer": "fire(0.6439)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405209.jpg"}, {"question": "what kind of device are they using", "gt answer": "tablet(1.00)", "pred answer": "laptop", "question_id": 1142265, "best approach": "wiki, concept", "verif answer": "laptop", "anno approach": "wiki, concept, image", "verif wiki answer": "tablet(0.6671)", "verif concept answer": "tablet(0.6731)", "verif image answer": "laptop(0.6308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114226.jpg"}, {"question": "what is the complimentary color of the shirt of the man on the right", "gt answer": "blue(1.00)<br/>purple(0.60)<br/>red(0.60)<br/>green(0.60)", "pred answer": "white", "question_id": 1105305, "best approach": "wiki, concept", "verif answer": "purple", "anno approach": "wiki, concept, image", "verif wiki answer": "blue(0.6698)", "verif concept answer": "blue(0.6638)", "verif image answer": "purple(0.6726)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000110530.jpg"}, {"question": "at what time of day would she be doing this", "gt answer": "noon(1.00)<br/>morn(1.00)<br/>afternoon(0.60)", "pred answer": "even", "question_id": 4679055, "best approach": "concept, image", "verif answer": "noon", "anno approach": "wiki, concept, image", "verif wiki answer": "afternoon(0.5404)", "verif concept answer": "morn(0.5920)", "verif image answer": "noon(0.7117)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467905.jpg"}, {"question": "what size are these tools normally", "gt answer": "6 inches(1.00)<br/>small(0.60)<br/>8 inches(0.60)", "pred answer": "large", "question_id": 1702075, "best approach": "wiki", "verif answer": "8 inches", "anno approach": "wiki, concept, image", "verif wiki answer": "8 inches(0.7087)", "verif concept answer": "1 foot(0.6615)", "verif image answer": "12 inches(0.6074)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000170207.jpg"}, {"question": "what are these used for", "gt answer": "electron(1.00)<br/>travel(0.60)<br/>computer(0.60)", "pred answer": "work", "question_id": 1519005, "best approach": "concept, image", "verif answer": "computer", "anno approach": "wiki, concept, image", "verif wiki answer": "compute(0.6233)", "verif concept answer": "computer(0.6777)", "verif image answer": "computer(0.7060)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151900.jpg"}, {"question": "what power moves the boats with the long mast", "gt answer": "wind(1.00)", "pred answer": "sail", "question_id": 4217755, "best approach": "wiki", "verif answer": "sail", "anno approach": "wiki, concept, image", "verif wiki answer": "wind(0.6774)", "verif concept answer": "string(0.6689)", "verif image answer": "sail(0.6126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421775.jpg"}, {"question": "what kind of birds are these", "gt answer": "geese(1.00)<br/>seagull(0.60)<br/>pelican(0.60)", "pred answer": "crow", "question_id": 5143565, "best approach": "wiki", "verif answer": "geese", "anno approach": "wiki, concept, image", "verif wiki answer": "geese(0.6423)", "verif concept answer": "crane(0.6113)", "verif image answer": "crane(0.6966)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514356.jpg"}, {"question": "can you guess the brand of bus shown in this photo", "gt answer": "greyhound(1.00)<br/>city bus(0.60)<br/>coach(0.60)", "pred answer": "ford", "question_id": 4798645, "best approach": "concept", "verif answer": "tour", "anno approach": "wiki, concept, image", "verif wiki answer": "tour(0.6042)", "verif concept answer": "greyhound(0.6935)", "verif image answer": "city bus(0.7205)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479864.jpg"}, {"question": "how long do you thing you should cook this", "gt answer": "10 minutes(1.00)", "pred answer": "hour", "question_id": 2958035, "best approach": "wiki, concept", "verif answer": "hour", "anno approach": "wiki, concept, image", "verif wiki answer": "10 minutes(0.6417)", "verif concept answer": "10 minutes(0.6444)", "verif image answer": "hour(0.6357)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295803.jpg"}, {"question": "what is double parked in this picture", "gt answer": "motorcycle(1.00)<br/>bike(0.60)", "pred answer": "car", "question_id": 1605245, "best approach": "wiki", "verif answer": "motorcycle", "anno approach": "wiki, concept, image", "verif wiki answer": "motorcycle(0.5895)", "verif concept answer": "bike(0.6119)", "verif image answer": "bike(0.6369)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160524.jpg"}, {"question": "what are these animals used for", "gt answer": "food(1.00)<br/>milk(0.60)<br/>meat(0.60)", "pred answer": "eat", "question_id": 758835, "best approach": "wiki, image", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "food(0.6191)", "verif concept answer": "meat(0.5768)", "verif image answer": "food(0.5887)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075883.jpg"}, {"question": "what are newborns called", "gt answer": "foal(1.00)<br/>colt(0.60)<br/>baby(0.60)", "pred answer": "calf", "question_id": 938665, "best approach": "", "verif answer": "zebra", "anno approach": "wiki, concept, image", "verif wiki answer": "zebra(0.6914)", "verif concept answer": "zebra(0.6135)", "verif image answer": "kid(0.5499)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093866.jpg"}, {"question": "what is the black high seat and platform used for", "gt answer": "shoe shine(1.00)", "pred answer": "sit", "question_id": 3876855, "best approach": "image", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "anniversary(0.5589)", "verif concept answer": "watch(0.6175)", "verif image answer": "shoe shine(0.7073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387685.jpg"}, {"question": "what is this pitchers last name", "gt answer": "sonnanstine(1.00)", "pred answer": "fowler", "question_id": 1903825, "best approach": "wiki, concept", "verif answer": "ty cobb", "anno approach": "wiki, concept, image", "verif wiki answer": "sonnanstine(0.5328)", "verif concept answer": "sonnanstine(0.5271)", "verif image answer": "tennis(0.5717)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190382.jpg"}, {"question": "what kind of weather is it", "gt answer": "cloudy(1.00)<br/>sunny(0.60)", "pred answer": "rainy", "question_id": 4506665, "best approach": "wiki, concept, image", "verif answer": "cloudy", "anno approach": "wiki, concept, image", "verif wiki answer": "cloudy(0.6285)", "verif concept answer": "cloudy(0.6307)", "verif image answer": "cloudy(0.7164)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450666.jpg"}, {"question": "what kind of cheese is that", "gt answer": "cheddar(1.00)", "pred answer": "mozzarella", "question_id": 4168845, "best approach": "wiki, concept", "verif answer": "mozzarella", "anno approach": "wiki, concept, image", "verif wiki answer": "cheddar(0.6788)", "verif concept answer": "cheddar(0.6619)", "verif image answer": "tortilla(0.6246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416884.jpg"}, {"question": "where is this", "gt answer": "ski resort(1.00)<br/>russia(0.60)", "pred answer": "ski", "question_id": 86305, "best approach": "concept", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "mountain(0.5976)", "verif concept answer": "ski resort(0.6523)", "verif image answer": "snow(0.6131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008630.jpg"}, {"question": "how long can this vessel travel", "gt answer": "100 miles(1.00)<br/>3 hours(0.60)", "pred answer": "2 hours", "question_id": 97455, "best approach": "wiki, concept, image", "verif answer": "1 hour", "anno approach": "wiki, concept, image", "verif wiki answer": "3 hours(0.6475)", "verif concept answer": "3 hours(0.6410)", "verif image answer": "3 hours(0.6253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009745.jpg"}, {"question": "what fuels the car", "gt answer": "vegetable oil(1.00)", "pred answer": "gasoline", "question_id": 3036515, "best approach": "wiki", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "vegetable oil(0.5516)", "verif concept answer": "wind(0.5719)", "verif image answer": "car(0.6898)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303651.jpg"}, {"question": "what name is given to the ribbons on the kite 's back", "gt answer": "tail(1.00)", "pred answer": "string", "question_id": 361575, "best approach": "wiki", "verif answer": "wind", "anno approach": "wiki, concept, image", "verif wiki answer": "tail(0.5480)", "verif concept answer": "wind(0.5304)", "verif image answer": "wind(0.5198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036157.jpg"}, {"question": "what activity does the animal depicted here like to do", "gt answer": "eat wood(1.00)<br/>brush teeth(0.60)", "pred answer": "play", "question_id": 3198185, "best approach": "wiki", "verif answer": "cut", "anno approach": "wiki, concept, image", "verif wiki answer": "eat wood(0.5956)", "verif concept answer": "cut(0.5436)", "verif image answer": "cut(0.6758)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319818.jpg"}, {"question": "what are the long hairs on this cat 's face called", "gt answer": "whisker(1.00)", "pred answer": "stripe", "question_id": 3380915, "best approach": "", "verif answer": "whisker", "anno approach": "wiki, concept, image", "verif wiki answer": "beard(0.7173)", "verif concept answer": "beard(0.7209)", "verif image answer": "beard(0.7167)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338091.jpg"}, {"question": "what is the name of the type of bread shown at the front", "gt answer": "roll(1.00)<br/>bun(0.60)", "pred answer": "sourdough", "question_id": 1248355, "best approach": "", "verif answer": "sourdough", "anno approach": "wiki, concept, image", "verif wiki answer": "biscuit(0.6824)", "verif concept answer": "sourdough(0.6738)", "verif image answer": "biscuit(0.5807)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000124835.jpg"}, {"question": "what is the slang term for how the beverage is served", "gt answer": "on rock(1.00)", "pred answer": "beer", "question_id": 1701015, "best approach": "wiki, image", "verif answer": "drunk", "anno approach": "wiki, concept, image", "verif wiki answer": "on rock(0.7122)", "verif concept answer": "drunk(0.6017)", "verif image answer": "on rock(0.6902)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000170101.jpg"}, {"question": "what type of horse is this", "gt answer": "palomino(1.00)", "pred answer": "arabian", "question_id": 1718345, "best approach": "wiki, concept, image", "verif answer": "mustang", "anno approach": "wiki, concept, image", "verif wiki answer": "palomino(0.7217)", "verif concept answer": "palomino(0.7081)", "verif image answer": "palomino(0.6861)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171834.jpg"}, {"question": "what is this man about to do", "gt answer": "throw frisbee(1.00)<br/>throw(0.60)", "pred answer": "catch", "question_id": 2692635, "best approach": "", "verif answer": "catch", "anno approach": "wiki, concept, image", "verif wiki answer": "catch(0.7148)", "verif concept answer": "catch(0.6738)", "verif image answer": "catch(0.6323)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269263.jpg"}, {"question": "what is the profession of the man in this photo", "gt answer": "soldier(1.00)<br/>military(0.60)", "pred answer": "farmer", "question_id": 2514755, "best approach": "wiki, concept", "verif answer": "military", "anno approach": "wiki, concept, image", "verif wiki answer": "soldier(0.6706)", "verif concept answer": "soldier(0.6778)", "verif image answer": "military(0.6760)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251475.jpg"}, {"question": "name the type of duck shown in this picture", "gt answer": "mallard(1.00)", "pred answer": "parakeet", "question_id": 1480105, "best approach": "", "verif answer": "mallard", "anno approach": "wiki, concept, image", "verif wiki answer": "duck(0.7171)", "verif concept answer": "duck(0.6675)", "verif image answer": "duck(0.7174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148010.jpg"}, {"question": "the standing hair on this animal 's neck is called its what", "gt answer": "mane(1.00)", "pred answer": "stripe", "question_id": 3042235, "best approach": "image", "verif answer": "stripe", "anno approach": "wiki, concept, image", "verif wiki answer": "stripe(0.7184)", "verif concept answer": "fur(0.7137)", "verif image answer": "mane(0.7276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304223.jpg"}, {"question": "what would one use to get to the second level", "gt answer": "stair(1.00)<br/>step(0.60)<br/>ladder(0.60)", "pred answer": "ski lift", "question_id": 1498785, "best approach": "concept, image", "verif answer": "ladder", "anno approach": "wiki, concept, image", "verif wiki answer": "fence(0.7106)", "verif concept answer": "ladder(0.6649)", "verif image answer": "step(0.5669)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149878.jpg"}, {"question": "is the broccoli on the plate steamed or baked", "gt answer": "steamed(1.00)", "pred answer": "toasted", "question_id": 2760045, "best approach": "wiki, image", "verif answer": "steamed", "anno approach": "wiki, concept, image", "verif wiki answer": "steamed(0.6211)", "verif concept answer": "boiled(0.6346)", "verif image answer": "steamed(0.5463)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276004.jpg"}, {"question": "name the material used to make this toy shown in this picture", "gt answer": "plush(1.00)<br/>cotton(0.60)<br/>stuffing(0.60)<br/>fur(0.60)", "pred answer": "polyester", "question_id": 4755755, "best approach": "image", "verif answer": "stuffing", "anno approach": "wiki, concept, image", "verif wiki answer": "fur(0.6957)", "verif concept answer": "stuffing(0.6747)", "verif image answer": "plush(0.6899)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475575.jpg"}, {"question": "when was the pictured snowboarding company founded", "gt answer": "1977(1.00)<br/>1990(0.60)", "pred answer": "1998", "question_id": 3505185, "best approach": "concept", "verif answer": "1970", "anno approach": "wiki, concept, image", "verif wiki answer": "1990(0.6638)", "verif concept answer": "1977(0.6226)", "verif image answer": "1990(0.6718)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350518.jpg"}, {"question": "where is this", "gt answer": "minneapolis(1.00)<br/>minnesota(0.60)", "pred answer": "city", "question_id": 3039625, "best approach": "concept", "verif answer": "california", "anno approach": "wiki, concept, image", "verif wiki answer": "california(0.6229)", "verif concept answer": "minneapolis(0.6087)", "verif image answer": "china(0.6411)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303962.jpg"}, {"question": "how do tennis players keep water out of their eyes", "gt answer": "umbrella(1.00)", "pred answer": "sun protection", "question_id": 2672105, "best approach": "wiki, concept, image", "verif answer": "umbrella", "anno approach": "wiki, concept, image", "verif wiki answer": "umbrella(0.7118)", "verif concept answer": "umbrella(0.6074)", "verif image answer": "umbrella(0.6564)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000267210.jpg"}, {"question": "which profession is associated with these items", "gt answer": "barber(1.00)<br/>hair stylist(0.60)", "pred answer": "chef", "question_id": 4537725, "best approach": "image", "verif answer": "hair stylist", "anno approach": "wiki, concept, image", "verif wiki answer": "sew(0.5165)", "verif concept answer": "drawer(0.5364)", "verif image answer": "hair stylist(0.6159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453772.jpg"}, {"question": "which dog breed is associated with this vehicle", "gt answer": "dalmation(1.00)<br/>dalmatian(0.60)", "pred answer": "bulldog", "question_id": 5436225, "best approach": "wiki, concept, image", "verif answer": "dalmatian", "anno approach": "wiki, concept, image", "verif wiki answer": "dalmatian(0.6855)", "verif concept answer": "dalmatian(0.5947)", "verif image answer": "dalmatian(0.6196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543622.jpg"}, {"question": "what kind of car is this", "gt answer": "bmw(1.00)<br/>mercedes(0.60)", "pred answer": "sedan", "question_id": 2037115, "best approach": "image", "verif answer": "mercedes", "anno approach": "wiki, concept, image", "verif wiki answer": "mercedes(0.6689)", "verif concept answer": "mercedes(0.6693)", "verif image answer": "bmw(0.7223)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203711.jpg"}, {"question": "what is another name for cat", "gt answer": "feline(1.00)<br/>kitten(0.60)", "pred answer": "american shorthair", "question_id": 5590735, "best approach": "concept", "verif answer": "domestic shorthair", "anno approach": "wiki, concept, image", "verif wiki answer": "felis catus(0.7072)", "verif concept answer": "feline(0.6949)", "verif image answer": "domestic shorthair(0.6312)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559073.jpg"}, {"question": "which greek god is associated with this type of scene", "gt answer": "poseidon(1.00)", "pred answer": "shark", "question_id": 2109895, "best approach": "wiki, concept, image", "verif answer": "wipeout", "anno approach": "wiki, concept, image", "verif wiki answer": "poseidon(0.6982)", "verif concept answer": "poseidon(0.6409)", "verif image answer": "poseidon(0.5949)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210989.jpg"}, {"question": "what type of aircraft has rotors on top", "gt answer": "helicopter(1.00)", "pred answer": "propeller", "question_id": 4147545, "best approach": "", "verif answer": "cloud", "anno approach": "wiki, concept, image", "verif wiki answer": "kite(0.7019)", "verif concept answer": "kite(0.6728)", "verif image answer": "bird(0.6459)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000414754.jpg"}, {"question": "what types of skills are needed to change tires", "gt answer": "mechanical(1.00)", "pred answer": "drive", "question_id": 4203725, "best approach": "image", "verif answer": "mechanical", "anno approach": "wiki, concept, image", "verif wiki answer": "qwerty(0.6146)", "verif concept answer": "qwerty(0.6248)", "verif image answer": "mechanical(0.5673)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420372.jpg"}, {"question": "", "gt answer": "end of day(0.60)<br/>zombies(0.60)", "pred answer": "christianity", "question_id": 3778685, "best approach": "concept", "verif answer": "catholic", "anno approach": "wiki, concept, image", "verif wiki answer": "catholic(0.6368)", "verif concept answer": "end of day(0.6741)", "verif image answer": "catholic(0.6626)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377868.jpg"}, {"question": "what place is she at", "gt answer": "salon(1.00)", "pred answer": "home", "question_id": 5747605, "best approach": "", "verif answer": "college", "anno approach": "wiki, concept, image", "verif wiki answer": "university(0.5938)", "verif concept answer": "college(0.6549)", "verif image answer": "university(0.5449)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000574760.jpg"}, {"question": "what brand of skateboard is he riding", "gt answer": "element(1.00)<br/>wooden(0.60)", "pred answer": "burton", "question_id": 2168255, "best approach": "image", "verif answer": "van", "anno approach": "wiki, concept, image", "verif wiki answer": "van(0.6295)", "verif concept answer": "ollie(0.6464)", "verif image answer": "wooden(0.6804)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216825.jpg"}, {"question": "how do these animals communicate a sense of contentment to their owners", "gt answer": "purr(1.00)<br/>music(0.60)<br/>pure(0.60)", "pred answer": "fly", "question_id": 436555, "best approach": "image", "verif answer": "music", "anno approach": "wiki, concept, image", "verif wiki answer": "music(0.7259)", "verif concept answer": "music(0.6525)", "verif image answer": "purr(0.5310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043655.jpg"}, {"question": "what vegetable here is mainly flowers", "gt answer": "broccoli(1.00)", "pred answer": "lettuce", "question_id": 581725, "best approach": "wiki, concept", "verif answer": "broccoli", "anno approach": "wiki, concept, image", "verif wiki answer": "broccoli(0.6768)", "verif concept answer": "broccoli(0.7191)", "verif image answer": "green(0.5751)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058172.jpg"}, {"question": "which mythical creature often appears as part of the architecture of sites such as this", "gt answer": "griffin(1.00)<br/>dolphin(0.60)", "pred answer": "fire", "question_id": 5054895, "best approach": "image", "verif answer": "octopus", "anno approach": "wiki, concept, image", "verif wiki answer": "octopus(0.7149)", "verif concept answer": "octopus(0.7103)", "verif image answer": "griffin(0.6721)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505489.jpg"}, {"question": "what is the name of the band that wrote many famous songs about the pictured activity", "gt answer": "beach boy(1.00)", "pred answer": "surf", "question_id": 4120625, "best approach": "wiki, concept, image", "verif answer": "beach boy", "anno approach": "wiki, concept, image", "verif wiki answer": "beach boy(0.7264)", "verif concept answer": "beach boy(0.7183)", "verif image answer": "beach boy(0.5498)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412062.jpg"}, {"question": "tell me the variety of birds which are seen in this picture", "gt answer": "crow(0.60)<br/>pigeon(1.00)", "pred answer": "seagull", "question_id": 4734205, "best approach": "wiki, image", "verif answer": "crow", "anno approach": "wiki, concept, image", "verif wiki answer": "pigeon(0.6918)", "verif concept answer": "crow(0.6630)", "verif image answer": "pigeon(0.6614)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473420.jpg"}, {"question": "what is the largest us restaurant chain that sells this item", "gt answer": "subway(1.00)", "pred answer": "starbucks", "question_id": 1106975, "best approach": "wiki", "verif answer": "ihop", "anno approach": "wiki, concept, image", "verif wiki answer": "subway(0.6513)", "verif concept answer": "bristol(0.5550)", "verif image answer": "bristol(0.6785)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000110697.jpg"}, {"question": "what time of day would someone use this", "gt answer": "night(1.00)<br/>nighttime(0.60)", "pred answer": "even", "question_id": 3885685, "best approach": "concept", "verif answer": "night", "anno approach": "wiki, concept, image", "verif wiki answer": "night time(0.5929)", "verif concept answer": "night(0.6325)", "verif image answer": "night time(0.7060)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388568.jpg"}, {"question": "what is the number on the batter 's jersey", "gt answer": "16(1.00)<br/>19(1.00)", "pred answer": "15", "question_id": 5399675, "best approach": "wiki, concept", "verif answer": "16", "anno approach": "wiki, concept, image", "verif wiki answer": "16(0.6859)", "verif concept answer": "19(0.6849)", "verif image answer": "50(0.5449)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539967.jpg"}, {"question": "what is the nearest relative of this animal", "gt answer": "horse(1.00)<br/>donkey(0.60)", "pred answer": "lion", "question_id": 3543165, "best approach": "", "verif answer": "zebra", "anno approach": "wiki, concept, image", "verif wiki answer": "zebra(0.6887)", "verif concept answer": "sheep(0.6535)", "verif image answer": "pony(0.6191)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354316.jpg"}, {"question": "why do people hold remotes like those", "gt answer": "video game(1.00)<br/>play game(1.00)", "pred answer": "game", "question_id": 675605, "best approach": "concept", "verif answer": "video game", "anno approach": "wiki, concept, image", "verif wiki answer": "play(0.7192)", "verif concept answer": "video game(0.7075)", "verif image answer": "wii(0.7014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067560.jpg"}, {"question": "how much wsa the costume", "gt answer": "$60(1.00)<br/>200(0.60)", "pred answer": "lot", "question_id": 4963395, "best approach": "image", "verif answer": "40", "anno approach": "wiki, concept, image", "verif wiki answer": "20 grams(0.6201)", "verif concept answer": "40(0.6189)", "verif image answer": "$60(0.6840)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496339.jpg"}, {"question": "what type of meat is in this meal", "gt answer": "corned beef(1.00)<br/>roast beef(0.60)", "pred answer": "pork", "question_id": 680285, "best approach": "wiki", "verif answer": "beef", "anno approach": "wiki, concept, image", "verif wiki answer": "corned beef(0.6449)", "verif concept answer": "beef(0.6635)", "verif image answer": "roast beef(0.7076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068028.jpg"}, {"question": "what is the most popular topping for these items", "gt answer": "glaze(1.00)<br/>ice(0.60)", "pred answer": "ketchup", "question_id": 3873935, "best approach": "", "verif answer": "ketchup", "anno approach": "wiki, concept, image", "verif wiki answer": "ketchup(0.7186)", "verif concept answer": "ketchup(0.7085)", "verif image answer": "ketchup(0.5363)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387393.jpg"}, {"question": "what is the horse being prepared for", "gt answer": "race(1.00)", "pred answer": "ride", "question_id": 2102055, "best approach": "wiki", "verif answer": "ride", "anno approach": "wiki, concept, image", "verif wiki answer": "race(0.6858)", "verif concept answer": "ride(0.6755)", "verif image answer": "ride(0.6668)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210205.jpg"}, {"question": "which model of suitcase is this shown in this picture", "gt answer": "samsonite(1.00)<br/>columbia(0.60)", "pred answer": "carry on", "question_id": 2954485, "best approach": "wiki, concept", "verif answer": "suitcase", "anno approach": "wiki, concept, image", "verif wiki answer": "samsonite(0.7242)", "verif concept answer": "samsonite(0.6637)", "verif image answer": "suitcase(0.6939)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295448.jpg"}, {"question": "what is the relationship between these two people", "gt answer": "mother and child(1.00)<br/>close(0.60)", "pred answer": "friend", "question_id": 5325775, "best approach": "concept", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "family(0.7260)", "verif concept answer": "close(0.6209)", "verif image answer": "friend(0.6781)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532577.jpg"}, {"question": "what country is this person in", "gt answer": "uk(1.00)<br/>canada(0.60)<br/>france(0.60)<br/>london(0.60)", "pred answer": "england", "question_id": 1215825, "best approach": "concept", "verif answer": "germany", "anno approach": "wiki, concept, image", "verif wiki answer": "london(0.7014)", "verif concept answer": "uk(0.6596)", "verif image answer": "france(0.6599)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000121582.jpg"}, {"question": "what country is named here", "gt answer": "tahiti(1.00)", "pred answer": "canada", "question_id": 4515745, "best approach": "", "verif answer": "canada", "anno approach": "wiki, concept, image", "verif wiki answer": "canada(0.6947)", "verif concept answer": "france(0.6882)", "verif image answer": "japan(0.5636)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451574.jpg"}, {"question": "what sort of joint distress affecting the middle of the arm borrows its name from the game played with this racket", "gt answer": "tennis elbow(1.00)<br/>tennis(0.60)", "pred answer": "backhand", "question_id": 2599605, "best approach": "image", "verif answer": "tennis elbow", "anno approach": "wiki, concept, image", "verif wiki answer": "high 5(0.6861)", "verif concept answer": "serve(0.6886)", "verif image answer": "tennis elbow(0.5261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259960.jpg"}, {"question": "how many of these kinds of establishments are there in the united states", "gt answer": "thousand(1.00)<br/>10000(1.00)", "pred answer": "5", "question_id": 4223365, "best approach": "", "verif answer": "million", "anno approach": "wiki, concept, image", "verif wiki answer": "1000(0.7071)", "verif concept answer": "million(0.6943)", "verif image answer": "1000(0.7021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422336.jpg"}, {"question": "what is the child wearing over their red shirt", "gt answer": "overall(1.00)", "pred answer": "tie", "question_id": 81765, "best approach": "", "verif answer": "scarf", "anno approach": "wiki, concept, image", "verif wiki answer": "jean(0.6677)", "verif concept answer": "jean(0.6150)", "verif image answer": "scarf(0.7258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008176.jpg"}, {"question": "where is this park", "gt answer": "washington dc(1.00)<br/>united state(0.60)<br/>america(0.60)", "pred answer": "park", "question_id": 1692045, "best approach": "wiki, concept", "verif answer": "washington dc", "anno approach": "wiki, concept, image", "verif wiki answer": "washington dc(0.7217)", "verif concept answer": "washington dc(0.6670)", "verif image answer": "united state(0.6612)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169204.jpg"}, {"question": "how hard is she gonna hit that ball", "gt answer": "very hard(1.00)", "pred answer": "backhand", "question_id": 4990275, "best approach": "concept", "verif answer": "forehand", "anno approach": "wiki, concept, image", "verif wiki answer": "forehand(0.6731)", "verif concept answer": "very hard(0.6315)", "verif image answer": "forehand(0.6142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499027.jpg"}, {"question": "are these animals safe or in danger", "gt answer": "safe(1.00)", "pred answer": "unsafe", "question_id": 170555, "best approach": "wiki, concept", "verif answer": "unsafe", "anno approach": "wiki, concept, image", "verif wiki answer": "safe(0.6876)", "verif concept answer": "safe(0.6571)", "verif image answer": "thrill seeker(0.6756)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000017055.jpg"}, {"question": "what kind of food might be cooked with the white appliance on the shelf", "gt answer": "popcorn(1.00)<br/>tea(0.60)", "pred answer": "soup", "question_id": 3022305, "best approach": "image", "verif answer": "taco", "anno approach": "wiki, concept, image", "verif wiki answer": "taco(0.6792)", "verif concept answer": "taco(0.6742)", "verif image answer": "tea(0.6303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302230.jpg"}, {"question": "", "gt answer": "rockies(0.60)<br/>mount ranier(0.60)", "pred answer": "alp", "question_id": 3070695, "best approach": "wiki, concept, image", "verif answer": "mount ranier", "anno approach": "wiki, concept, image", "verif wiki answer": "mount ranier(0.5330)", "verif concept answer": "mount ranier(0.5649)", "verif image answer": "mount ranier(0.5660)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307069.jpg"}, {"question": "how high can that crane reach", "gt answer": "200 feet(1.00)", "pred answer": "3 feet", "question_id": 2566375, "best approach": "concept, image", "verif answer": "3 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "3 feet(0.6330)", "verif concept answer": "200 feet(0.5771)", "verif image answer": "200 feet(0.6652)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256637.jpg"}, {"question": "which one would a monkey choose", "gt answer": "banana(1.00)", "pred answer": "orange", "question_id": 2767815, "best approach": "wiki, concept, image", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "banana(0.6539)", "verif concept answer": "banana(0.6013)", "verif image answer": "banana(0.6232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276781.jpg"}, {"question": "what kind of car is the horse next to", "gt answer": "porch(1.00)<br/>porsche(1.00)", "pred answer": "suv", "question_id": 337325, "best approach": "concept", "verif answer": "suv", "anno approach": "wiki, concept, image", "verif wiki answer": "van(0.6743)", "verif concept answer": "porsche(0.6270)", "verif image answer": "suv(0.6985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033732.jpg"}, {"question": "what toppings are on this hot dog", "gt answer": "ketchup and relish(1.00)<br/>ketchup(0.60)", "pred answer": "onion", "question_id": 531315, "best approach": "image", "verif answer": "onion", "anno approach": "wiki, concept, image", "verif wiki answer": "mustard and ketchup(0.6977)", "verif concept answer": "onion(0.6960)", "verif image answer": "ketchup(0.6799)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053131.jpg"}, {"question": "how do you make this dish", "gt answer": "bake(1.00)<br/>bake it(0.60)<br/>oven(0.60)", "pred answer": "toasted", "question_id": 3137575, "best approach": "concept", "verif answer": "baked", "anno approach": "wiki, concept, image", "verif wiki answer": "baked(0.6806)", "verif concept answer": "oven(0.6536)", "verif image answer": "baked(0.7147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313757.jpg"}, {"question": "what country was this photograph taken in", "gt answer": "thailand(1.00)<br/>germany(0.60)<br/>england(0.60)<br/>china(0.60)", "pred answer": "america", "question_id": 3730535, "best approach": "wiki, concept, image", "verif answer": "germany", "anno approach": "wiki, concept, image", "verif wiki answer": "england(0.6442)", "verif concept answer": "england(0.6493)", "verif image answer": "china(0.6300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373053.jpg"}, {"question": "what kind of water is in the ocean", "gt answer": "salt water(1.00)<br/>saltwater(1.00)", "pred answer": "river", "question_id": 5021525, "best approach": "concept", "verif answer": "ocean", "anno approach": "wiki, concept, image", "verif wiki answer": "ocean(0.6584)", "verif concept answer": "salt water(0.6901)", "verif image answer": "ocean(0.6979)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502152.jpg"}, {"question": "where does this animal usually live", "gt answer": "house(1.00)", "pred answer": "beach", "question_id": 5588635, "best approach": "concept", "verif answer": "house", "anno approach": "wiki, concept, image", "verif wiki answer": "dollhouse(0.5845)", "verif concept answer": "house(0.6187)", "verif image answer": "home(0.5715)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558863.jpg"}, {"question": "which computer operating system is he using", "gt answer": "window(1.00)", "pred answer": "macbook", "question_id": 3106065, "best approach": "", "verif answer": "mac", "anno approach": "wiki, concept, image", "verif wiki answer": "mac(0.6580)", "verif concept answer": "mac(0.6446)", "verif image answer": "screen(0.6734)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310606.jpg"}, {"question": "how fast can a plane like this fly", "gt answer": "700 mph(1.00)<br/>200 mph(0.60)", "pred answer": "80 mph", "question_id": 2108065, "best approach": "image", "verif answer": "200 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "200 mph(0.7204)", "verif concept answer": "200 mph(0.6448)", "verif image answer": "700 mph(0.5759)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210806.jpg"}, {"question": "what type of boats are these", "gt answer": "row(1.00)<br/>fish boat(0.60)<br/>canoes(0.60)", "pred answer": "row boat", "question_id": 2813305, "best approach": "wiki, concept", "verif answer": "row boat", "anno approach": "wiki, concept, image", "verif wiki answer": "fish boat(0.7277)", "verif concept answer": "canoes(0.7198)", "verif image answer": "row boat(0.7237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281330.jpg"}, {"question": "where is this beer 's brand headquartered", "gt answer": "belgium(1.00)<br/>france(0.60)<br/>united state(0.60)<br/>spain(0.60)", "pred answer": "budweiser", "question_id": 4540725, "best approach": "wiki, concept, image", "verif answer": "spain", "anno approach": "wiki, concept, image", "verif wiki answer": "belgium(0.7247)", "verif concept answer": "belgium(0.6456)", "verif image answer": "belgium(0.7176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000454072.jpg"}, {"question": "what number did someone call", "gt answer": "911(1.00)", "pred answer": "15", "question_id": 5265145, "best approach": "wiki, concept", "verif answer": "50", "anno approach": "wiki, concept, image", "verif wiki answer": "911(0.6772)", "verif concept answer": "911(0.7015)", "verif image answer": "thumb(0.7071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526514.jpg"}, {"question": "how much weight can this breed of horse pull", "gt answer": "2000(1.00)<br/>500(0.60)", "pred answer": "ton", "question_id": 5643145, "best approach": "wiki, concept", "verif answer": "50", "anno approach": "wiki, concept, image", "verif wiki answer": "2000(0.6195)", "verif concept answer": "2000(0.5921)", "verif image answer": "1600 lbs(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564314.jpg"}, {"question": "what other bird is known to stand like this", "gt answer": "flamingo(1.00)<br/>pelican(0.60)<br/>duck(0.60)", "pred answer": "seagull", "question_id": 2853235, "best approach": "concept, image", "verif answer": "duck", "anno approach": "wiki, concept, image", "verif wiki answer": "egret(0.7012)", "verif concept answer": "duck(0.6541)", "verif image answer": "duck(0.6836)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285323.jpg"}, {"question": "a driver at this intersection makes a u turn and is pulled over by a policeman why did the policeman pull him over", "gt answer": "no u turn(1.00)<br/>red light(0.60)", "pred answer": "stop", "question_id": 2746315, "best approach": "", "verif answer": "traffic light", "anno approach": "wiki, concept, image", "verif wiki answer": "traffic light(0.7074)", "verif concept answer": "traffic light(0.7262)", "verif image answer": "yield(0.6025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274631.jpg"}, {"question": "what is the purpose of the blue object on the front of this bike", "gt answer": "shield(1.00)", "pred answer": "helmet", "question_id": 129335, "best approach": "wiki", "verif answer": "flag", "anno approach": "wiki, concept, image", "verif wiki answer": "shield(0.6810)", "verif concept answer": "picture(0.6892)", "verif image answer": "paint(0.5838)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012933.jpg"}, {"question": "what is covering the animals' bodies", "gt answer": "fur(1.00)", "pred answer": "feather", "question_id": 973115, "best approach": "wiki, concept", "verif answer": "fur", "anno approach": "wiki, concept, image", "verif wiki answer": "fur(0.7257)", "verif concept answer": "fur(0.7218)", "verif image answer": "stuffing(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097311.jpg"}, {"question": "what popular type of boot is the girl wearing", "gt answer": "ugg(1.00)", "pred answer": "sneaker", "question_id": 3212155, "best approach": "", "verif answer": "boot", "anno approach": "wiki, concept, image", "verif wiki answer": "boot(0.7204)", "verif concept answer": "boot(0.6367)", "verif image answer": "van(0.7094)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321215.jpg"}, {"question": "what 's about to happen", "gt answer": "fight(1.00)<br/>bark(0.60)", "pred answer": "sleep", "question_id": 2738855, "best approach": "image", "verif answer": "run", "anno approach": "wiki, concept, image", "verif wiki answer": "play(0.5624)", "verif concept answer": "run(0.6535)", "verif image answer": "fight(0.5781)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273885.jpg"}, {"question": "what tool is used to flush this device", "gt answer": "handle(1.00)", "pred answer": "wrench", "question_id": 3237845, "best approach": "image", "verif answer": "knife", "anno approach": "wiki, concept, image", "verif wiki answer": "hard boiled(0.6620)", "verif concept answer": "paddle(0.6677)", "verif image answer": "handle(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323784.jpg"}, {"question": "what does it take for a pet owner to bond with his dog", "gt answer": "love(1.00)", "pred answer": "year", "question_id": 8825, "best approach": "concept", "verif answer": "3 months", "anno approach": "wiki, concept, image", "verif wiki answer": "anger(0.7092)", "verif concept answer": "love(0.6713)", "verif image answer": "foul(0.6470)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000882.jpg"}, {"question": "which item seen is associated with vehicle safety", "gt answer": "seat belt(1.00)", "pred answer": "tie", "question_id": 567335, "best approach": "", "verif answer": "tie", "anno approach": "wiki, concept, image", "verif wiki answer": "camera(0.6685)", "verif concept answer": "luggage(0.5972)", "verif image answer": "helmet(0.7230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000056733.jpg"}, {"question": "what is the store in the picture", "gt answer": "laundromat(1.00)<br/>cloth(0.60)<br/>convenience store(0.60)", "pred answer": "furniture", "question_id": 524425, "best approach": "wiki, image", "verif answer": "7 eleven", "anno approach": "wiki, concept, image", "verif wiki answer": "laundromat(0.6589)", "verif concept answer": "cloth(0.6844)", "verif image answer": "laundromat(0.7172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052442.jpg"}, {"question": "what airline is this", "gt answer": "transat(1.00)", "pred answer": "klm", "question_id": 5461405, "best approach": "", "verif answer": "klm", "anno approach": "wiki, concept, image", "verif wiki answer": "klm(0.7308)", "verif concept answer": "klm(0.7297)", "verif image answer": "klm(0.6941)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546140.jpg"}, {"question": "which british comedic series has a main character who has a best friend like one of the toys in the photo", "gt answer": "ted(1.00)<br/>bean(0.60)", "pred answer": "disney", "question_id": 4772585, "best approach": "", "verif answer": "teddy bear", "anno approach": "wiki, concept, image", "verif wiki answer": "morris michtom(0.7207)", "verif concept answer": "morris michtom(0.5749)", "verif image answer": "teddy bear(0.5294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477258.jpg"}, {"question": "what type of dog has spots all over", "gt answer": "dalmatian(1.00)<br/>dalmation(1.00)", "pred answer": "shepard", "question_id": 3988135, "best approach": "wiki, concept, image", "verif answer": "dalmatian", "anno approach": "wiki, concept, image", "verif wiki answer": "dalmatian(0.6242)", "verif concept answer": "dalmatian(0.6628)", "verif image answer": "dalmatian(0.6859)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398813.jpg"}, {"question": "what is the name of the person who is responsible for caring for these kinds of animals", "gt answer": "sheep herder(1.00)<br/>farmer(0.60)", "pred answer": "shepherd", "question_id": 3934875, "best approach": "concept", "verif answer": "shepherd", "anno approach": "wiki, concept, image", "verif wiki answer": "shepherd(0.7146)", "verif concept answer": "sheep herder(0.6460)", "verif image answer": "farmer market(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393487.jpg"}, {"question": "what kind of train is in this photo", "gt answer": "freight(1.00)<br/>cargo(0.60)", "pred answer": "steam", "question_id": 2241995, "best approach": "concept, image", "verif answer": "freight", "anno approach": "wiki, concept, image", "verif wiki answer": "tanker(0.6977)", "verif concept answer": "freight(0.6867)", "verif image answer": "freight(0.7215)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224199.jpg"}, {"question": "who invented the figures on both sides of the woman", "gt answer": "richard steiff(1.00)<br/>morris michtom(0.60)<br/>2(0.60)", "pred answer": "theodore roosevelt", "question_id": 2405455, "best approach": "wiki, concept", "verif answer": "2", "anno approach": "wiki, concept, image", "verif wiki answer": "2(0.7134)", "verif concept answer": "2(0.6501)", "verif image answer": "5(0.7181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240545.jpg"}, {"question": "what company 's logo can be seen on this tennis player 's clothing", "gt answer": "nike(1.00)", "pred answer": "adidas", "question_id": 2354995, "best approach": "", "verif answer": "adidas", "anno approach": "wiki, concept, image", "verif wiki answer": "adidas(0.6882)", "verif concept answer": "adidas(0.6929)", "verif image answer": "adidas(0.7003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000235499.jpg"}, {"question": "what substance was used to color the man on the left gold", "gt answer": "paint(1.00)<br/>pain(0.60)<br/>spray paint(0.60)", "pred answer": "iron", "question_id": 648165, "best approach": "image", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "plastic(0.6644)", "verif concept answer": "pain(0.5632)", "verif image answer": "paint(0.6135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064816.jpg"}, {"question": "what would you call this event", "gt answer": "meet(1.00)", "pred answer": "work", "question_id": 740805, "best approach": "", "verif answer": "office", "anno approach": "wiki, concept, image", "verif wiki answer": "interview(0.6740)", "verif concept answer": "interview(0.7163)", "verif image answer": "award(0.6917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074080.jpg"}, {"question": "what is this man 's profession", "gt answer": "sommelier(1.00)<br/>wine taster(0.60)", "pred answer": "hair stylist", "question_id": 5395895, "best approach": "image", "verif answer": "sommelier", "anno approach": "wiki, concept, image", "verif wiki answer": "president(0.7249)", "verif concept answer": "president(0.6872)", "verif image answer": "wine taster(0.6488)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539589.jpg"}, {"question": "what is the average distance per hour covered while doing this activity", "gt answer": "2 miles(1.00)<br/>3(0.60)<br/>1(0.60)", "pred answer": "20", "question_id": 1344475, "best approach": "image", "verif answer": "5", "anno approach": "wiki, concept, image", "verif wiki answer": "1 mile(0.6991)", "verif concept answer": "1 mile(0.6493)", "verif image answer": "2 miles(0.6471)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134447.jpg"}, {"question": "what kind of cat is this", "gt answer": "grey(1.00)<br/>gray(0.60)<br/>ragdoll(0.60)", "pred answer": "siamese", "question_id": 4202155, "best approach": "concept", "verif answer": "tabby", "anno approach": "wiki, concept, image", "verif wiki answer": "tabby(0.6858)", "verif concept answer": "grey(0.6972)", "verif image answer": "silver(0.6843)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420215.jpg"}, {"question": "what is normally used to kill the animals mounted on the wall", "gt answer": "gun(1.00)", "pred answer": "wall", "question_id": 2838755, "best approach": "wiki, image", "verif answer": "sew machine", "anno approach": "wiki, concept, image", "verif wiki answer": "gun(0.6521)", "verif concept answer": "mouse(0.5706)", "verif image answer": "gun(0.5911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283875.jpg"}, {"question": "", "gt answer": "bathroom(0.60)", "pred answer": "hotel", "question_id": 800855, "best approach": "", "verif answer": "bathroom", "anno approach": "wiki, concept, image", "verif wiki answer": "shower(0.5610)", "verif concept answer": "bedroom(0.5396)", "verif image answer": "shower(0.5504)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080085.jpg"}, {"question": "the object on the wall with three vertical dials is most likely used to measure what", "gt answer": "barometric pressure(1.00)<br/>temperature(0.60)<br/>time(0.60)", "pred answer": "light", "question_id": 4621105, "best approach": "wiki, concept, image", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "time(0.5988)", "verif concept answer": "temperature(0.6674)", "verif image answer": "time(0.6772)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000462110.jpg"}, {"question": "how would one describe the way the egg in the sandwich is cooked", "gt answer": "hard boiled(1.00)<br/>fried(0.60)<br/>over easy(0.60)", "pred answer": "grilled", "question_id": 2962675, "best approach": "wiki, concept", "verif answer": "over easy", "anno approach": "wiki, concept, image", "verif wiki answer": "over easy(0.6852)", "verif concept answer": "fried(0.6683)", "verif image answer": "sunny side up(0.5582)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296267.jpg"}, {"question": "who is believed to have invented the mode of transportation seen in this image", "gt answer": "john kemp starley(1.00)<br/>russia(0.60)<br/>kid(0.60)", "pred answer": "man", "question_id": 3602115, "best approach": "wiki, concept", "verif answer": "kid", "anno approach": "wiki, concept, image", "verif wiki answer": "john kemp starley(0.7255)", "verif concept answer": "john kemp starley(0.7250)", "verif image answer": "kid(0.6421)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000360211.jpg"}, {"question": "which part of this animal moves to and fro when the animal is excited", "gt answer": "tail(1.00)", "pred answer": "catch", "question_id": 4964155, "best approach": "wiki, concept", "verif answer": "catch", "anno approach": "wiki, concept, image", "verif wiki answer": "tail(0.6857)", "verif concept answer": "tail(0.6780)", "verif image answer": "catch(0.6989)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496415.jpg"}, {"question": "how can i warm my food", "gt answer": "microwave(1.00)", "pred answer": "oven", "question_id": 2612715, "best approach": "wiki", "verif answer": "microwave", "anno approach": "wiki, concept, image", "verif wiki answer": "microwave(0.7021)", "verif concept answer": "toaster oven(0.6255)", "verif image answer": "refrigerator(0.7157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261271.jpg"}, {"question": "what position is the player behind thr plate", "gt answer": "catcher(1.00)<br/>shortstop(0.60)", "pred answer": "batter", "question_id": 3592495, "best approach": "wiki", "verif answer": "catcher", "anno approach": "wiki, concept, image", "verif wiki answer": "catcher(0.7258)", "verif concept answer": "outfield(0.7152)", "verif image answer": "shortstop(0.6087)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359249.jpg"}, {"question": "what type of animal is this", "gt answer": "llama(1.00)<br/>camel(1.00)<br/>giraffe(0.60)", "pred answer": "cow", "question_id": 536155, "best approach": "image", "verif answer": "cow", "anno approach": "wiki, concept, image", "verif wiki answer": "cow(0.6655)", "verif concept answer": "cow(0.5616)", "verif image answer": "llama(0.7087)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053615.jpg"}, {"question": "what does 'xing' mean", "gt answer": "cross(1.00)<br/>stop(0.60)<br/>row(0.60)", "pred answer": "speed limit", "question_id": 85645, "best approach": "wiki, concept, image", "verif answer": "no park", "anno approach": "wiki, concept, image", "verif wiki answer": "row(0.7205)", "verif concept answer": "row(0.6156)", "verif image answer": "stop(0.6147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008564.jpg"}, {"question": "what company makes this farm equipment", "gt answer": "john deere(1.00)", "pred answer": "delta", "question_id": 1229525, "best approach": "wiki", "verif answer": "delta", "anno approach": "wiki, concept, image", "verif wiki answer": "john deere(0.5681)", "verif concept answer": "frigidaire(0.6076)", "verif image answer": "delta(0.5973)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122952.jpg"}, {"question": "what kind of dog is this", "gt answer": "lab(1.00)<br/>labrador(0.60)<br/>retriever(0.60)", "pred answer": "beagle", "question_id": 4500475, "best approach": "", "verif answer": "lab", "anno approach": "wiki, concept, image", "verif wiki answer": "black labrador(0.6981)", "verif concept answer": "black labrador(0.6235)", "verif image answer": "black labrador(0.6169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450047.jpg"}, {"question": "in what year was this plane retired from service", "gt answer": "1979(1.00)<br/>2000(0.60)", "pred answer": "1880", "question_id": 4054415, "best approach": "wiki", "verif answer": "2000", "anno approach": "wiki, concept, image", "verif wiki answer": "2000(0.7239)", "verif concept answer": "in operation(0.5876)", "verif image answer": "1970(0.5557)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405441.jpg"}, {"question": "what do these hanging objects keep out usually", "gt answer": "sun(1.00)<br/>fly(0.60)<br/>light(0.60)<br/>sunlight(0.60)", "pred answer": "heat", "question_id": 5522915, "best approach": "concept", "verif answer": "sunlight", "anno approach": "wiki, concept, image", "verif wiki answer": "fly(0.6670)", "verif concept answer": "sun(0.5387)", "verif image answer": "yellow(0.6849)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552291.jpg"}, {"question": "what type of sport is this person doing", "gt answer": "water ski(1.00)<br/>parasailing(1.00)", "pred answer": "wind surf", "question_id": 71235, "best approach": "wiki, image", "verif answer": "wind surf", "anno approach": "wiki, concept, image", "verif wiki answer": "water ski(0.7123)", "verif concept answer": "windsurf(0.6165)", "verif image answer": "parasailing(0.6471)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007123.jpg"}, {"question": "is this a wedding or birthday", "gt answer": "wed(1.00)", "pred answer": "birthday", "question_id": 2283295, "best approach": "concept", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "birthday(0.6888)", "verif concept answer": "wed(0.6388)", "verif image answer": "birthday(0.6859)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000228329.jpg"}, {"question": "how many people are killed annually in the us while doing this sport", "gt answer": "10(1.00)<br/>5(0.60)<br/>100(0.60)", "pred answer": "0", "question_id": 782905, "best approach": "wiki, image", "verif answer": "0", "anno approach": "wiki, concept, image", "verif wiki answer": "5(0.7101)", "verif concept answer": "0(0.6308)", "verif image answer": "5(0.6840)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078290.jpg"}, {"question": "what is the floor cleaned with", "gt answer": "vacuum(1.00)<br/>mop(1.00)<br/>bleach(0.60)", "pred answer": "tile", "question_id": 940495, "best approach": "wiki, image", "verif answer": "vacuum", "anno approach": "wiki, concept, image", "verif wiki answer": "vacuum(0.6125)", "verif concept answer": "brush(0.6808)", "verif image answer": "mop(0.7152)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094049.jpg"}, {"question": "what food is this", "gt answer": "seafood(1.00)<br/>shrimp(0.60)", "pred answer": "turkey", "question_id": 1875415, "best approach": "image", "verif answer": "shrimp", "anno approach": "wiki, concept, image", "verif wiki answer": "noodle(0.7101)", "verif concept answer": "noodle(0.6509)", "verif image answer": "seafood(0.5707)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187541.jpg"}, {"question": "what was the board made of", "gt answer": "polyurethane(1.00)<br/>plastic(0.60)<br/>wood(0.60)", "pred answer": "fiberglass", "question_id": 3876055, "best approach": "", "verif answer": "fiberglass", "anno approach": "wiki, concept, image", "verif wiki answer": "surfboard(0.6969)", "verif concept answer": "surfboard(0.6962)", "verif image answer": "surfboard(0.6462)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387605.jpg"}, {"question": "are they studying or having fun", "gt answer": "study(1.00)", "pred answer": "work", "question_id": 3748465, "best approach": "", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "work(0.6893)", "verif concept answer": "work(0.6507)", "verif image answer": "fun(0.5959)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374846.jpg"}, {"question": "what is the girl writing in", "gt answer": "notebook(1.00)<br/>cake(0.60)", "pred answer": "book", "question_id": 1666925, "best approach": "wiki, image", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "notebook(0.6307)", "verif concept answer": "bowl(0.6942)", "verif image answer": "notebook(0.6787)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166692.jpg"}, {"question": "is the man working on a kitchen island or a peninsula", "gt answer": "peninsula(1.00)", "pred answer": "kitchen", "question_id": 5117895, "best approach": "", "verif answer": "snack", "anno approach": "wiki, concept, image", "verif wiki answer": "float(0.7063)", "verif concept answer": "snack(0.7210)", "verif image answer": "breakfast(0.7273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511789.jpg"}, {"question": "what shape is within the clear balloon", "gt answer": "heart(1.00)", "pred answer": "round", "question_id": 3249235, "best approach": "", "verif answer": "brain", "anno approach": "wiki, concept, image", "verif wiki answer": "brain(0.6543)", "verif concept answer": "brain(0.7142)", "verif image answer": "brain(0.5045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324923.jpg"}, {"question": "what kind of bear is the person holding", "gt answer": "teddy(1.00)", "pred answer": "stuffed", "question_id": 1309715, "best approach": "wiki, image", "verif answer": "stuffed", "anno approach": "wiki, concept, image", "verif wiki answer": "teddy(0.7257)", "verif concept answer": "grizzly(0.6605)", "verif image answer": "teddy(0.7057)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130971.jpg"}, {"question": "what brand is this truck", "gt answer": "kenworth(1.00)<br/>mac(0.60)", "pred answer": "dodge", "question_id": 528025, "best approach": "wiki", "verif answer": "ford", "anno approach": "wiki, concept, image", "verif wiki answer": "kenworth(0.7134)", "verif concept answer": "ford(0.7192)", "verif image answer": "mac(0.6760)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052802.jpg"}, {"question": "what sport is being scored here", "gt answer": "cricket(1.00)", "pred answer": "bowl", "question_id": 3813055, "best approach": "", "verif answer": "golf", "anno approach": "wiki, concept, image", "verif wiki answer": "wii(0.6414)", "verif concept answer": "baseball(0.7101)", "verif image answer": "golf(0.5964)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381305.jpg"}, {"question": "what could have caused the hole in the fence", "gt answer": "tree(1.00)", "pred answer": "speed", "question_id": 390165, "best approach": "image", "verif answer": "umbrella", "anno approach": "wiki, concept, image", "verif wiki answer": "umbrella(0.6609)", "verif concept answer": "umbrella(0.6283)", "verif image answer": "tree(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039016.jpg"}, {"question": "what is on the hot dog", "gt answer": "cheese(1.00)", "pred answer": "ketchup", "question_id": 5116505, "best approach": "wiki, image", "verif answer": "onion", "anno approach": "wiki, concept, image", "verif wiki answer": "cheese(0.7104)", "verif concept answer": "onion(0.7048)", "verif image answer": "cheese(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511650.jpg"}, {"question": "what time of day is it", "gt answer": "morn(1.00)<br/>sunrise(0.60)<br/>afternoon(0.60)<br/>even(0.60)", "pred answer": "dusk", "question_id": 1777495, "best approach": "image", "verif answer": "dusk", "anno approach": "wiki, concept, image", "verif wiki answer": "dusk(0.6560)", "verif concept answer": "even(0.6798)", "verif image answer": "morn(0.6645)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177749.jpg"}, {"question": "what famous ice cream dish is made with this fruit", "gt answer": "banana split(1.00)", "pred answer": "banana", "question_id": 166805, "best approach": "wiki, image", "verif answer": "banana split", "anno approach": "wiki, concept, image", "verif wiki answer": "banana split(0.7212)", "verif concept answer": "banana bread(0.6946)", "verif image answer": "banana split(0.6939)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016680.jpg"}, {"question": "is this coca cola bus or pepsi", "gt answer": "coca cola(1.00)<br/>coco cola(0.60)", "pred answer": "double decker", "question_id": 3699205, "best approach": "image", "verif answer": "coke", "anno approach": "wiki, concept, image", "verif wiki answer": "coke(0.5180)", "verif concept answer": "coke(0.5076)", "verif image answer": "coco cola(0.5811)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369920.jpg"}, {"question": "what kind of rug is shown", "gt answer": "oriental(1.00)<br/>decorative(0.60)<br/>large(0.60)", "pred answer": "quilt", "question_id": 799015, "best approach": "", "verif answer": "quilt", "anno approach": "wiki, concept, image", "verif wiki answer": "quilt(0.6619)", "verif concept answer": "quilt(0.7173)", "verif image answer": "quilt(0.5806)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079901.jpg"}, {"question": "what 's the name of the walkway to board a plane", "gt answer": "jet bridge(1.00)<br/>walkway(0.60)", "pred answer": "runway", "question_id": 5061495, "best approach": "", "verif answer": "airstair", "anno approach": "wiki, concept, image", "verif wiki answer": "contrail(0.6050)", "verif concept answer": "airstair(0.6733)", "verif image answer": "airstair(0.7099)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506149.jpg"}, {"question": "what is the second letter from the left written on the ground", "gt answer": "o(1.00)", "pred answer": "first", "question_id": 4572075, "best approach": "wiki, concept", "verif answer": "first", "anno approach": "wiki, concept, image", "verif wiki answer": "o(0.7051)", "verif concept answer": "o(0.5906)", "verif image answer": "tie(0.5656)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457207.jpg"}, {"question": "who is the highest paid athlete of the sport played in this picture", "gt answer": "clayton kershaw(1.00)<br/>bond(0.60)", "pred answer": "babe ruth", "question_id": 4045335, "best approach": "image", "verif answer": "babe ruth", "anno approach": "wiki, concept, image", "verif wiki answer": "babe ruth(0.7263)", "verif concept answer": "babe ruth(0.7138)", "verif image answer": "clayton kershaw(0.6908)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404533.jpg"}, {"question": "what kitchen appliances are shown in the picture", "gt answer": "microwave(1.00)<br/>toaster oven(0.60)", "pred answer": "refrigerator", "question_id": 226915, "best approach": "concept, image", "verif answer": "refrigerator", "anno approach": "wiki, concept, image", "verif wiki answer": "refrigerator(0.7123)", "verif concept answer": "microwave(0.7267)", "verif image answer": "microwave(0.6732)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000022691.jpg"}, {"question": "what is the material used in snowboard", "gt answer": "fiberglass(1.00)<br/>plastic(0.60)<br/>skateboard(0.60)<br/>foam(0.60)", "pred answer": "wood", "question_id": 4994695, "best approach": "concept, image", "verif answer": "fiberglass", "anno approach": "wiki, concept, image", "verif wiki answer": "wood(0.7035)", "verif concept answer": "fiberglass(0.6937)", "verif image answer": "fiberglass(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499469.jpg"}, {"question": "who makes this type of motorcycles", "gt answer": "harley davidson(1.00)<br/>harley(0.60)", "pred answer": "honda", "question_id": 3154625, "best approach": "concept", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "honda(0.7012)", "verif concept answer": "harley davidson(0.6928)", "verif image answer": "yamaha(0.6328)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315462.jpg"}, {"question": "how was that device powered", "gt answer": "battery(1.00)<br/>electricity(0.60)", "pred answer": "gas", "question_id": 2812885, "best approach": "wiki, concept, image", "verif answer": "battery", "anno approach": "wiki, concept, image", "verif wiki answer": "battery(0.6258)", "verif concept answer": "battery(0.6298)", "verif image answer": "battery(0.5700)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281288.jpg"}, {"question": "what is the most popular brand of the appliance shown", "gt answer": "kenmore(1.00)<br/>lg(1.00)", "pred answer": "ge", "question_id": 5596525, "best approach": "wiki", "verif answer": "kenmore", "anno approach": "wiki, concept, image", "verif wiki answer": "lg(0.6849)", "verif concept answer": "whirlpool(0.6460)", "verif image answer": "kitchen aid(0.6528)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559652.jpg"}, {"question": "would ajax or tide more likely be used to clean this", "gt answer": "ajax(1.00)", "pred answer": "bleach", "question_id": 4162845, "best approach": "wiki", "verif answer": "eastern", "anno approach": "wiki, concept, image", "verif wiki answer": "ajax(0.5265)", "verif concept answer": "eastern(0.5897)", "verif image answer": "cherry(0.5818)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416284.jpg"}, {"question": "is this a quiet or busy city", "gt answer": "busy(1.00)<br/>quiet(1.00)", "pred answer": "urban", "question_id": 5436895, "best approach": "image", "verif answer": "city", "anno approach": "wiki, concept, image", "verif wiki answer": "city(0.7167)", "verif concept answer": "city(0.6841)", "verif image answer": "quiet(0.6802)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543689.jpg"}, {"question": "what is the man laying inside of", "gt answer": "tent(1.00)", "pred answer": "trailer", "question_id": 4452635, "best approach": "wiki", "verif answer": "tent", "anno approach": "wiki, concept, image", "verif wiki answer": "tent(0.6756)", "verif concept answer": "desk(0.7295)", "verif image answer": "desk(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445263.jpg"}, {"question": "what breed of bird is sitting on the fence", "gt answer": "sparrow(1.00)", "pred answer": "finch", "question_id": 1100235, "best approach": "", "verif answer": "finch", "anno approach": "wiki, concept, image", "verif wiki answer": "finch(0.6535)", "verif concept answer": "hummingbird(0.6907)", "verif image answer": "hummingbird(0.5909)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000110023.jpg"}, {"question": "what position is the person in the middle of the photo", "gt answer": "pitcher(1.00)", "pred answer": "batter", "question_id": 4059065, "best approach": "image", "verif answer": "outfield", "anno approach": "wiki, concept, image", "verif wiki answer": "outfield(0.7141)", "verif concept answer": "outfield(0.7232)", "verif image answer": "pitcher(0.6770)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405906.jpg"}, {"question": "what is the weight in oz 's of the food left over on this plate", "gt answer": "8(1.00)<br/>7(0.60)<br/>75(0.60)", "pred answer": "500", "question_id": 4255505, "best approach": "wiki, concept", "verif answer": "7", "anno approach": "wiki, concept, image", "verif wiki answer": "7(0.5853)", "verif concept answer": "7(0.5556)", "verif image answer": "40(0.5644)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425550.jpg"}, {"question": "what food is that", "gt answer": "pot pie(1.00)<br/>pie(0.60)", "pred answer": "bread", "question_id": 2173785, "best approach": "image", "verif answer": "cake", "anno approach": "wiki, concept, image", "verif wiki answer": "cheesecake(0.7097)", "verif concept answer": "cake(0.7145)", "verif image answer": "pot pie(0.7058)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217378.jpg"}, {"question": "are these cows real or man made", "gt answer": "man made(1.00)", "pred answer": "manmade", "question_id": 3024245, "best approach": "concept", "verif answer": "manmade", "anno approach": "wiki, concept, image", "verif wiki answer": "(0.7305)", "verif concept answer": "man made(0.6850)", "verif image answer": "manmade(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302424.jpg"}, {"question": "what type of lettuce is this", "gt answer": "romaine(1.00)<br/>arugula(0.60)", "pred answer": "iceberg", "question_id": 3854235, "best approach": "wiki, concept", "verif answer": "iceberg", "anno approach": "wiki, concept, image", "verif wiki answer": "arugula(0.6864)", "verif concept answer": "arugula(0.6668)", "verif image answer": "iceberg(0.6628)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385423.jpg"}, {"question": "is this a modern or ancient system", "gt answer": "modern(1.00)", "pred answer": "antique", "question_id": 1511705, "best approach": "wiki", "verif answer": "modern", "anno approach": "wiki, concept, image", "verif wiki answer": "modern(0.7153)", "verif concept answer": "small(0.6500)", "verif image answer": "gothic(0.5402)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151170.jpg"}, {"question": "why is the man swinging at a ball", "gt answer": "play tennis(1.00)<br/>tennis(1.00)<br/>serve(0.60)", "pred answer": "hit ball", "question_id": 5470995, "best approach": "", "verif answer": "hit", "anno approach": "wiki, concept, image", "verif wiki answer": "backhand(0.7120)", "verif concept answer": "backhand(0.7096)", "verif image answer": "hit(0.7161)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000547099.jpg"}, {"question": "what is the filling", "gt answer": "beef(1.00)<br/>corned beef(0.60)<br/>meat(0.60)", "pred answer": "ketchup", "question_id": 3989245, "best approach": "concept", "verif answer": "beef", "anno approach": "wiki, concept, image", "verif wiki answer": "corned beef(0.7013)", "verif concept answer": "beef(0.6893)", "verif image answer": "corned beef(0.7082)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398924.jpg"}, {"question": "what were the variety of vegetables shown in this picture", "gt answer": "green(1.00)", "pred answer": "broccoli", "question_id": 3464335, "best approach": "", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "granny smith(0.6338)", "verif concept answer": "red(0.5808)", "verif image answer": "crystal(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346433.jpg"}, {"question": "what brand is the dark brown cowboy hat", "gt answer": "stetson(1.00)", "pred answer": "budweiser", "question_id": 1245625, "best approach": "concept, image", "verif answer": "budweiser", "anno approach": "wiki, concept, image", "verif wiki answer": "budweiser(0.7120)", "verif concept answer": "stetson(0.6737)", "verif image answer": "stetson(0.7086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000124562.jpg"}, {"question": "in what city would you see this", "gt answer": "london(1.00)", "pred answer": "philadelphia", "question_id": 1035835, "best approach": "concept", "verif answer": "london", "anno approach": "wiki, concept, image", "verif wiki answer": "berlin(0.7060)", "verif concept answer": "london(0.6528)", "verif image answer": "england(0.7027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103583.jpg"}, {"question": "can you guess the name of the sea where this boat is seen", "gt answer": "english channel(1.00)<br/>black(0.60)<br/>canal(0.60)", "pred answer": "pacific", "question_id": 4396145, "best approach": "concept", "verif answer": "pacific", "anno approach": "wiki, concept, image", "verif wiki answer": "pacific(0.6983)", "verif concept answer": "english channel(0.5996)", "verif image answer": "black(0.6802)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439614.jpg"}, {"question": "what position is he playing", "gt answer": "second base(1.00)<br/>second(0.60)", "pred answer": "batter", "question_id": 4602355, "best approach": "", "verif answer": "batter", "anno approach": "wiki, concept, image", "verif wiki answer": "shortstop(0.7175)", "verif concept answer": "outfield(0.7149)", "verif image answer": "shortstop(0.5985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460235.jpg"}, {"question": "what type of protein is in this dish", "gt answer": "tofu(1.00)", "pred answer": "vegetable", "question_id": 2216965, "best approach": "wiki, image", "verif answer": "beef", "anno approach": "wiki, concept, image", "verif wiki answer": "tofu(0.6641)", "verif concept answer": "taco(0.5843)", "verif image answer": "tofu(0.7019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221696.jpg"}, {"question": "what will happen next", "gt answer": "hit ball(1.00)<br/>hit(0.60)", "pred answer": "serve", "question_id": 4116295, "best approach": "wiki, concept", "verif answer": "serve", "anno approach": "wiki, concept, image", "verif wiki answer": "hit ball(0.6410)", "verif concept answer": "hit ball(0.6782)", "verif image answer": "serve(0.6591)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000411629.jpg"}, {"question": "how can one steer this boat", "gt answer": "paddle(1.00)<br/>row(0.60)<br/>oar(0.60)", "pred answer": "float", "question_id": 5379105, "best approach": "", "verif answer": "paddle", "anno approach": "wiki, concept, image", "verif wiki answer": "tow(0.7246)", "verif concept answer": "tow(0.6739)", "verif image answer": "tow(0.7172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537910.jpg"}, {"question": "what is the common name of the orange items seen here", "gt answer": "noodle(1.00)<br/>orange(0.60)", "pred answer": "television", "question_id": 593675, "best approach": "", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "pasta(0.6043)", "verif concept answer": "pasta(0.6888)", "verif image answer": "pasta(0.6288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059367.jpg"}, {"question": "how quickly did one well known chain used to promise to deliver this item", "gt answer": "30 minutes(1.00)<br/>10 minutes(1.00)", "pred answer": "21", "question_id": 3812515, "best approach": "wiki, concept", "verif answer": "10 minutes", "anno approach": "wiki, concept, image", "verif wiki answer": "10 minutes(0.6174)", "verif concept answer": "30 minutes(0.5929)", "verif image answer": "5 minutes(0.5696)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381251.jpg"}, {"question": "what famous monument is this", "gt answer": "fountain(1.00)<br/>duck(0.60)", "pred answer": "george washington", "question_id": 4227745, "best approach": "", "verif answer": "bidet", "anno approach": "wiki, concept, image", "verif wiki answer": "pelican(0.7104)", "verif concept answer": "pelican(0.7000)", "verif image answer": "pelican(0.7130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422774.jpg"}, {"question": "what is the technical name for the size of the vegetable cut", "gt answer": "dice(1.00)", "pred answer": "large", "question_id": 2469245, "best approach": "wiki", "verif answer": "first", "anno approach": "wiki, concept, image", "verif wiki answer": "dice(0.6636)", "verif concept answer": "chop(0.6471)", "verif image answer": "first(0.6090)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246924.jpg"}, {"question": "what style of hat is being worn by the man in the foreground", "gt answer": "beanie(1.00)<br/>knit(0.60)<br/>ski(0.60)", "pred answer": "fedora", "question_id": 388405, "best approach": "wiki, concept, image", "verif answer": "beanie", "anno approach": "wiki, concept, image", "verif wiki answer": "beanie(0.7162)", "verif concept answer": "beanie(0.7246)", "verif image answer": "beanie(0.7204)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038840.jpg"}, {"question": "what material is this toy made of", "gt answer": "balloon(1.00)<br/>rubber(1.00)<br/>plastic(0.60)", "pred answer": "cotton", "question_id": 3085225, "best approach": "wiki, concept, image", "verif answer": "rubber", "anno approach": "wiki, concept, image", "verif wiki answer": "rubber(0.6816)", "verif concept answer": "rubber(0.6920)", "verif image answer": "rubber(0.6941)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308522.jpg"}, {"question": "what is the penalty for not obeying the law on the sign", "gt answer": "fine(1.00)<br/>jail(0.60)", "pred answer": "ticket", "question_id": 1352375, "best approach": "wiki, image", "verif answer": "ticket", "anno approach": "wiki, concept, image", "verif wiki answer": "fine(0.6997)", "verif concept answer": "ticket(0.6446)", "verif image answer": "fine(0.6348)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000135237.jpg"}, {"question": "which zodiac sign is represented by this animal", "gt answer": "aries(1.00)<br/>ox(0.60)", "pred answer": "sheep", "question_id": 5385305, "best approach": "wiki, concept", "verif answer": "sheep", "anno approach": "wiki, concept, image", "verif wiki answer": "aries(0.6794)", "verif concept answer": "aries(0.6540)", "verif image answer": "ox(0.6233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538530.jpg"}, {"question": "what does the food on the right come from", "gt answer": "pig(1.00)<br/>garden(0.60)", "pred answer": "italy", "question_id": 4990615, "best approach": "image", "verif answer": "bakery", "anno approach": "wiki, concept, image", "verif wiki answer": "bakery(0.6558)", "verif concept answer": "krispy kreme(0.6428)", "verif image answer": "pig(0.5738)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499061.jpg"}, {"question": "which cartoon rabbit is associated with this vegetable", "gt answer": "bug bunny(1.00)", "pred answer": "garfield", "question_id": 2014465, "best approach": "wiki, concept", "verif answer": "garfield", "anno approach": "wiki, concept, image", "verif wiki answer": "bug bunny(0.7303)", "verif concept answer": "bug bunny(0.6945)", "verif image answer": "garfield(0.5960)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201446.jpg"}, {"question": "what kind of truck is shown", "gt answer": "food truck(1.00)<br/>food(0.60)", "pred answer": "ice cream", "question_id": 334315, "best approach": "concept", "verif answer": "ice cream", "anno approach": "wiki, concept, image", "verif wiki answer": "restaurant(0.7059)", "verif concept answer": "food truck(0.7100)", "verif image answer": "united state(0.6993)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033431.jpg"}, {"question": "what do you use these for", "gt answer": "tell time(1.00)", "pred answer": "time", "question_id": 334135, "best approach": "wiki, concept", "verif answer": "tell time", "anno approach": "wiki, concept, image", "verif wiki answer": "tell time(0.7182)", "verif concept answer": "tell time(0.6990)", "verif image answer": "time(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033413.jpg"}, {"question": "what is the pattern of the pillow on the left", "gt answer": "checkered(1.00)<br/>square(1.00)<br/>swirl(0.60)", "pred answer": "floral", "question_id": 1834455, "best approach": "image", "verif answer": "square", "anno approach": "wiki, concept, image", "verif wiki answer": "checkerboard(0.5830)", "verif concept answer": "diamond(0.5889)", "verif image answer": "square(0.7204)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183445.jpg"}, {"question": "how much sleep does this aged person need", "gt answer": "8 hours(1.00)<br/>10 hours(0.60)", "pred answer": "lot", "question_id": 1227525, "best approach": "image", "verif answer": "30", "anno approach": "wiki, concept, image", "verif wiki answer": "30(0.6119)", "verif concept answer": "30(0.5353)", "verif image answer": "10 hours(0.6605)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122752.jpg"}, {"question": "what kind of material is the sink", "gt answer": "porcelain(1.00)<br/>copper(0.60)", "pred answer": "marble", "question_id": 3226385, "best approach": "wiki, concept", "verif answer": "ceramic", "anno approach": "wiki, concept, image", "verif wiki answer": "porcelain(0.6736)", "verif concept answer": "porcelain(0.6944)", "verif image answer": "ceramic(0.6252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322638.jpg"}, {"question": "what is missing that is usually underneath the silverware on the placemat", "gt answer": "napkin(1.00)", "pred answer": "spoon", "question_id": 352725, "best approach": "", "verif answer": "spoon", "anno approach": "wiki, concept, image", "verif wiki answer": "spoon(0.7211)", "verif concept answer": "spoon(0.6242)", "verif image answer": "spoon(0.6038)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000035272.jpg"}, {"question": "this vehicle transports medical victims to where", "gt answer": "hospital(1.00)", "pred answer": "airport", "question_id": 5629115, "best approach": "", "verif answer": "airport", "anno approach": "wiki, concept, image", "verif wiki answer": "airport(0.5813)", "verif concept answer": "office(0.6488)", "verif image answer": "military(0.5225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000562911.jpg"}, {"question": "why has the white truck stopped at this building", "gt answer": "deliver mail(1.00)<br/>delivery(0.60)", "pred answer": "bus stop", "question_id": 1455385, "best approach": "", "verif answer": "delivery", "anno approach": "wiki, concept, image", "verif wiki answer": "school(0.7022)", "verif concept answer": "school(0.7112)", "verif image answer": "school(0.6307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145538.jpg"}, {"question": "what is this horse carrying", "gt answer": "cart(1.00)", "pred answer": "carriage", "question_id": 3145725, "best approach": "", "verif answer": "carriage", "anno approach": "wiki, concept, image", "verif wiki answer": "carriage(0.6864)", "verif concept answer": "carriage(0.6705)", "verif image answer": "carriage(0.6945)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314572.jpg"}, {"question": "what is the calorie count of one portion of the cake shown", "gt answer": "250(1.00)<br/>200(0.60)", "pred answer": "500", "question_id": 4785375, "best approach": "image", "verif answer": "500", "anno approach": "wiki, concept, image", "verif wiki answer": "100(0.6879)", "verif concept answer": "200(0.6530)", "verif image answer": "250(0.6643)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478537.jpg"}, {"question": "what is this vehicle used for", "gt answer": "haul(1.00)<br/>transport(1.00)", "pred answer": "cargo", "question_id": 292145, "best approach": "wiki, concept", "verif answer": "transportation", "anno approach": "wiki, concept, image", "verif wiki answer": "transport(0.7152)", "verif concept answer": "transport(0.6998)", "verif image answer": "tow(0.6426)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029214.jpg"}, {"question": "what could you smell if someone would be sitting on the corner object", "gt answer": "poop(1.00)<br/>feces(1.00)", "pred answer": "water", "question_id": 3468905, "best approach": "", "verif answer": "toothpaste", "anno approach": "wiki, concept, image", "verif wiki answer": "mirror(0.5804)", "verif concept answer": "mirror(0.6098)", "verif image answer": "mirror(0.5336)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346890.jpg"}, {"question": "which type of establishment is this", "gt answer": "mall(1.00)<br/>airport(0.60)", "pred answer": "school", "question_id": 1708575, "best approach": "image", "verif answer": "mall", "anno approach": "wiki, concept, image", "verif wiki answer": "commercial(0.7056)", "verif concept answer": "san diego(0.6460)", "verif image answer": "airport(0.5736)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000170857.jpg"}, {"question": "what disease is killing bananas", "gt answer": "fusarium(1.00)<br/>over ripe(0.60)", "pred answer": "rain", "question_id": 1572885, "best approach": "wiki", "verif answer": "ripe", "anno approach": "wiki, concept, image", "verif wiki answer": "fusarium(0.6678)", "verif concept answer": "ripe(0.5550)", "verif image answer": "over ripe(0.5643)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157288.jpg"}, {"question": "which airline does the plane belong to", "gt answer": "united(1.00)<br/>american(0.60)", "pred answer": "klm", "question_id": 2462875, "best approach": "concept, image", "verif answer": "american airline", "anno approach": "wiki, concept, image", "verif wiki answer": "korean air(0.7178)", "verif concept answer": "united(0.6502)", "verif image answer": "united(0.5386)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246287.jpg"}, {"question": "what are these animals standing on", "gt answer": "dirt(1.00)<br/>mud(0.60)<br/>bridge(0.60)", "pred answer": "asphalt", "question_id": 1973185, "best approach": "image", "verif answer": "clay", "anno approach": "wiki, concept, image", "verif wiki answer": "clay(0.6052)", "verif concept answer": "clay(0.6491)", "verif image answer": "dirt(0.5996)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197318.jpg"}, {"question": "what variety of plant you were seeing in this picture", "gt answer": "orange tree(1.00)<br/>orange(1.00)", "pred answer": "cactus", "question_id": 4922915, "best approach": "concept", "verif answer": "orange tree", "anno approach": "wiki, concept, image", "verif wiki answer": "lemon(0.6340)", "verif concept answer": "orange tree(0.6545)", "verif image answer": "seed(0.6807)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492291.jpg"}, {"question": "what does this arrow sign signify", "gt answer": "look(1.00)<br/>look both way(0.60)", "pred answer": "no park", "question_id": 767095, "best approach": "wiki, concept", "verif answer": "look both way", "anno approach": "wiki, concept, image", "verif wiki answer": "look both way(0.7206)", "verif concept answer": "look both way(0.6821)", "verif image answer": "referee(0.5797)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076709.jpg"}, {"question": "what do these types of animals use to eat with", "gt answer": "beak(1.00)<br/>nothing(0.60)", "pred answer": "fish", "question_id": 3596355, "best approach": "wiki, concept, image", "verif answer": "seed", "anno approach": "wiki, concept, image", "verif wiki answer": "beak(0.6857)", "verif concept answer": "beak(0.6152)", "verif image answer": "beak(0.5757)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359635.jpg"}, {"question": "where are these signs usually found", "gt answer": "street(1.00)", "pred answer": "bar", "question_id": 2171185, "best approach": "", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "street sign(0.7008)", "verif concept answer": "street name(0.6486)", "verif image answer": "street name(0.6745)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217118.jpg"}, {"question": "what kind of haircut does this girl have", "gt answer": "pixie(1.00)<br/>short(1.00)<br/>boy(0.60)", "pred answer": "bob", "question_id": 5502775, "best approach": "wiki, concept, image", "verif answer": "short", "anno approach": "wiki, concept, image", "verif wiki answer": "short(0.6684)", "verif concept answer": "pixie(0.6082)", "verif image answer": "short(0.5437)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550277.jpg"}, {"question": "what utensil was used to create the slice of bread depicted", "gt answer": "knife(1.00)", "pred answer": "fork", "question_id": 5254435, "best approach": "wiki, concept", "verif answer": "knife", "anno approach": "wiki, concept, image", "verif wiki answer": "knife(0.6767)", "verif concept answer": "knife(0.6855)", "verif image answer": "scissor(0.7171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525443.jpg"}, {"question": "who makes chairs like this", "gt answer": "ikea(1.00)<br/>store(0.60)", "pred answer": "wilson", "question_id": 1238515, "best approach": "wiki, concept", "verif answer": "ikea", "anno approach": "wiki, concept, image", "verif wiki answer": "ikea(0.6146)", "verif concept answer": "ikea(0.5909)", "verif image answer": "online(0.6517)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123851.jpg"}, {"question": "are bananas typically stored in a fridge or room temperature", "gt answer": "room(1.00)", "pred answer": "high", "question_id": 4663785, "best approach": "", "verif answer": "inside", "anno approach": "wiki, concept, image", "verif wiki answer": "inside(0.5291)", "verif concept answer": "inside(0.6295)", "verif image answer": "bedroom(0.5574)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466378.jpg"}, {"question": "what profession uses this", "gt answer": "fireman(1.00)<br/>firefighter(0.60)", "pred answer": "chef", "question_id": 798935, "best approach": "concept", "verif answer": "firefighter", "anno approach": "wiki, concept, image", "verif wiki answer": "cook(0.6096)", "verif concept answer": "fireman(0.7159)", "verif image answer": "frederick graff sr(0.7143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079893.jpg"}, {"question": "are these animals owned by someone or free", "gt answer": "owned(1.00)<br/>free(0.60)", "pred answer": "captivity", "question_id": 4541555, "best approach": "concept", "verif answer": "free", "anno approach": "wiki, concept, image", "verif wiki answer": "farmer(0.7156)", "verif concept answer": "owned(0.6579)", "verif image answer": "free(0.5594)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000454155.jpg"}, {"question": "what type of train is that", "gt answer": "steam(1.00)<br/>steam locomotive(0.60)<br/>steam engine(0.60)", "pred answer": "passenger train", "question_id": 5451545, "best approach": "wiki", "verif answer": "steam", "anno approach": "wiki, concept, image", "verif wiki answer": "steam engine(0.6801)", "verif concept answer": "locomotive(0.7000)", "verif image answer": "locomotive(0.7083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545154.jpg"}, {"question": "what is material is the surface that the girl is one made of", "gt answer": "carpet(1.00)<br/>leather(0.60)", "pred answer": "cotton", "question_id": 2565335, "best approach": "image", "verif answer": "cotton", "anno approach": "wiki, concept, image", "verif wiki answer": "rubber(0.6776)", "verif concept answer": "rubber(0.6945)", "verif image answer": "leather(0.5966)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256533.jpg"}, {"question": "can you guess the area whether it is rural or urban", "gt answer": "rural(1.00)", "pred answer": "urban", "question_id": 4584305, "best approach": "wiki, concept, image", "verif answer": "urban", "anno approach": "wiki, concept, image", "verif wiki answer": "rural(0.7230)", "verif concept answer": "rural(0.7091)", "verif image answer": "rural(0.7066)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458430.jpg"}, {"question": "how long have they waited", "gt answer": "20 minutes(1.00)<br/>hour(0.60)", "pred answer": "2 hours", "question_id": 4445035, "best approach": "concept", "verif answer": "1 hour", "anno approach": "wiki, concept, image", "verif wiki answer": "30 minutes(0.6547)", "verif concept answer": "20 minutes(0.6093)", "verif image answer": "10 minutes(0.5629)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000444503.jpg"}, {"question": "what genus is this animal", "gt answer": "equus(1.00)<br/>horse(0.60)", "pred answer": "zebra", "question_id": 4772305, "best approach": "", "verif answer": "zebra", "anno approach": "wiki, concept, image", "verif wiki answer": "zebra(0.5943)", "verif concept answer": "zebra(0.6690)", "verif image answer": "donkey(0.6815)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477230.jpg"}, {"question": "what is the person in the middle of this boat doing", "gt answer": "row(1.00)<br/>row boat(0.60)", "pred answer": "swim", "question_id": 5588515, "best approach": "", "verif answer": "paddle", "anno approach": "wiki, concept, image", "verif wiki answer": "canoe(0.6974)", "verif concept answer": "canoe(0.6717)", "verif image answer": "canoe(0.6821)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558851.jpg"}, {"question": "are they business partners or enemies", "gt answer": "partner(1.00)", "pred answer": "amateur", "question_id": 2419055, "best approach": "concept", "verif answer": "teammate", "anno approach": "wiki, concept, image", "verif wiki answer": "tie(0.7036)", "verif concept answer": "partner(0.6550)", "verif image answer": "tie(0.5216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241905.jpg"}, {"question": "what is the meaning of the object on the woman 's finger", "gt answer": "marriage(1.00)<br/>wed(0.60)<br/>brush(0.60)", "pred answer": "shave", "question_id": 2327795, "best approach": "wiki, concept", "verif answer": "marriage", "anno approach": "wiki, concept, image", "verif wiki answer": "wed(0.7050)", "verif concept answer": "wed(0.6911)", "verif image answer": "anniversary(0.7064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232779.jpg"}, {"question": "what device is pictured", "gt answer": "remote(1.00)<br/>remote control(0.60)", "pred answer": "keyboard", "question_id": 854115, "best approach": "", "verif answer": "pager", "anno approach": "wiki, concept, image", "verif wiki answer": "pager(0.7015)", "verif concept answer": "pager(0.5547)", "verif image answer": "pager(0.6298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085411.jpg"}, {"question": "what would the red bottle next to the sink probably contain", "gt answer": "dish soap(1.00)<br/>soap(0.60)<br/>water(0.60)", "pred answer": "juice", "question_id": 1665335, "best approach": "image", "verif answer": "dish", "anno approach": "wiki, concept, image", "verif wiki answer": "dish(0.6915)", "verif concept answer": "dish(0.7077)", "verif image answer": "water(0.7087)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166533.jpg"}, {"question": "how much of the body is made up of what the man is surrounded by", "gt answer": "60%(1.00)<br/>60(0.60)", "pred answer": "foot", "question_id": 2113895, "best approach": "", "verif answer": "10 hours", "anno approach": "wiki, concept, image", "verif wiki answer": "full(0.6245)", "verif concept answer": "full(0.6631)", "verif image answer": "full(0.7122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000211389.jpg"}, {"question": "when was the device pictured invented", "gt answer": "1973(1.00)", "pred answer": "1981", "question_id": 4388675, "best approach": "wiki, concept", "verif answer": "1973", "anno approach": "wiki, concept, image", "verif wiki answer": "1973(0.7212)", "verif concept answer": "1973(0.5872)", "verif image answer": "nokia(0.5885)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000438867.jpg"}, {"question": "are the noodles made from rice or wheat", "gt answer": "wheat(1.00)<br/>rice(0.60)", "pred answer": "egg", "question_id": 851765, "best approach": "wiki", "verif answer": "wheat", "anno approach": "wiki, concept, image", "verif wiki answer": "wheat(0.6913)", "verif concept answer": "corn(0.6145)", "verif image answer": "bread(0.6434)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085176.jpg"}, {"question": "what is the large black item used for in this room", "gt answer": "refrigerate food(1.00)<br/>keep food cold(0.60)<br/>refrigeration(0.60)", "pred answer": "storage", "question_id": 5158785, "best approach": "wiki", "verif answer": "storage", "anno approach": "wiki, concept, image", "verif wiki answer": "refrigerate food(0.6899)", "verif concept answer": "storage(0.6867)", "verif image answer": "refrigeration(0.6913)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515878.jpg"}, {"question": "buildings like those seen here are often identified as what kind of scrapers", "gt answer": "sky(1.00)<br/>windy(0.60)", "pred answer": "skyscraper", "question_id": 3204835, "best approach": "wiki", "verif answer": "storm", "anno approach": "wiki, concept, image", "verif wiki answer": "windy(0.5360)", "verif concept answer": "storm(0.5645)", "verif image answer": "storm(0.5567)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320483.jpg"}, {"question": "what is this little girl doing", "gt answer": "brush hair(1.00)<br/>dance(0.60)", "pred answer": "play video game", "question_id": 869225, "best approach": "concept, image", "verif answer": "shave", "anno approach": "wiki, concept, image", "verif wiki answer": "shave(0.6324)", "verif concept answer": "dance(0.6462)", "verif image answer": "dance(0.6772)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086922.jpg"}, {"question": "what is the man laying on", "gt answer": "pillow(1.00)<br/>mattress(0.60)", "pred answer": "bed", "question_id": 5478275, "best approach": "concept", "verif answer": "bed", "anno approach": "wiki, concept, image", "verif wiki answer": "quilt(0.7305)", "verif concept answer": "pillow(0.7301)", "verif image answer": "mattress(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000547827.jpg"}, {"question": "how much blood circulates in this animal", "gt answer": "5 liters(1.00)<br/>1 liter(0.60)", "pred answer": "50 lbs", "question_id": 4182825, "best approach": "image", "verif answer": "lot", "anno approach": "wiki, concept, image", "verif wiki answer": "1 liter(0.6268)", "verif concept answer": "4300(0.6197)", "verif image answer": "5 liters(0.6172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000418282.jpg"}, {"question": "which bird species has a deep red breast and resembles a finch", "gt answer": "cardinal(1.00)", "pred answer": "finch", "question_id": 3233685, "best approach": "concept, image", "verif answer": "cardinal", "anno approach": "wiki, concept, image", "verif wiki answer": "robin(0.6746)", "verif concept answer": "cardinal(0.6793)", "verif image answer": "cardinal(0.6226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323368.jpg"}, {"question": "where do you think they are heading", "gt answer": "construction(1.00)<br/>construction site(0.60)", "pred answer": "house", "question_id": 3991955, "best approach": "wiki", "verif answer": "construction", "anno approach": "wiki, concept, image", "verif wiki answer": "construction(0.6738)", "verif concept answer": "dig(0.6857)", "verif image answer": "dig(0.5958)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399195.jpg"}, {"question": "who invented this sport", "gt answer": "tom sim(1.00)", "pred answer": "bode miller", "question_id": 37135, "best approach": "wiki, image", "verif answer": "tom sim", "anno approach": "wiki, concept, image", "verif wiki answer": "tom sim(0.7194)", "verif concept answer": "sweden(0.6448)", "verif image answer": "tom sim(0.6596)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003713.jpg"}, {"question": "what comes before vista", "gt answer": "buena(1.00)", "pred answer": "mountain", "question_id": 1081015, "best approach": "", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "ski(0.6302)", "verif concept answer": "ski(0.6997)", "verif image answer": "ski(0.6706)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108101.jpg"}, {"question": "what size bed is shown", "gt answer": "twin(1.00)<br/>single(1.00)", "pred answer": "queen", "question_id": 396435, "best approach": "wiki, concept", "verif answer": "single", "anno approach": "wiki, concept, image", "verif wiki answer": "single(0.6760)", "verif concept answer": "single(0.6439)", "verif image answer": "double(0.6316)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039643.jpg"}, {"question": "what type of numerals are the numbers on this clock", "gt answer": "roman(1.00)", "pred answer": "roman numeral", "question_id": 2816315, "best approach": "wiki, concept", "verif answer": "roman numeral", "anno approach": "wiki, concept, image", "verif wiki answer": "roman(0.7002)", "verif concept answer": "roman(0.6419)", "verif image answer": "gothic(0.6772)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281631.jpg"}, {"question": "where is this person farming and what is he harvesting", "gt answer": "banana(1.00)", "pred answer": "farm", "question_id": 502045, "best approach": "wiki", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "banana(0.6362)", "verif concept answer": "bush(0.6691)", "verif image answer": "bush(0.6694)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050204.jpg"}, {"question": "what brand is the game console", "gt answer": "playstation(1.00)<br/>xbox(0.60)<br/>wii(0.60)", "pred answer": "nintendo", "question_id": 3854455, "best approach": "", "verif answer": "nintendo", "anno approach": "wiki, concept, image", "verif wiki answer": "nintendo(0.7200)", "verif concept answer": "nintendo(0.6401)", "verif image answer": "nintendo(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385445.jpg"}, {"question": "what branch of the military is this", "gt answer": "army(1.00)<br/>marine(1.00)", "pred answer": "navy", "question_id": 3881495, "best approach": "", "verif answer": "navy", "anno approach": "wiki, concept, image", "verif wiki answer": "air force(0.7186)", "verif concept answer": "navy(0.6728)", "verif image answer": "air force(0.7108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388149.jpg"}, {"question": "what kind of bottoms do the women who play this sport usually wear", "gt answer": "skirt(1.00)<br/>short(0.60)<br/>tennis(0.60)", "pred answer": "shoe", "question_id": 3272995, "best approach": "wiki, image", "verif answer": "tennis", "anno approach": "wiki, concept, image", "verif wiki answer": "tennis(0.6235)", "verif concept answer": "play tennis(0.6898)", "verif image answer": "short(0.6603)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327299.jpg"}, {"question": "what fleetwood mac song describes this image", "gt answer": "7 wonders(1.00)<br/>horse(0.60)<br/>0(0.60)", "pred answer": "chirp", "question_id": 2455505, "best approach": "wiki", "verif answer": "horse", "anno approach": "wiki, concept, image", "verif wiki answer": "7 wonders(0.6051)", "verif concept answer": "horse(0.5897)", "verif image answer": "panda(0.5170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245550.jpg"}, {"question": "the tall houses with beacons that are often found in areas like this are called what", "gt answer": "lighthouse(1.00)<br/>light house(0.60)", "pred answer": "beach", "question_id": 1342655, "best approach": "concept", "verif answer": "beach", "anno approach": "wiki, concept, image", "verif wiki answer": "beach(0.6576)", "verif concept answer": "lighthouse(0.6359)", "verif image answer": "beach(0.6451)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134265.jpg"}, {"question": "what type of fish are in this picture", "gt answer": "sardine(1.00)", "pred answer": "parakeet", "question_id": 3195945, "best approach": "", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "dolphin(0.6746)", "verif concept answer": "banana(0.6428)", "verif image answer": "dolphin(0.5335)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319594.jpg"}, {"question": "which continent does the langue shown derive from", "gt answer": "asia(1.00)<br/>asian(0.60)", "pred answer": "europe", "question_id": 4928945, "best approach": "wiki, concept", "verif answer": "asia", "anno approach": "wiki, concept, image", "verif wiki answer": "asia(0.7099)", "verif concept answer": "asia(0.6784)", "verif image answer": "chinese(0.6965)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492894.jpg"}, {"question": "where is the parking lot", "gt answer": "to left(1.00)<br/>park(0.60)<br/>italy(0.60)", "pred answer": "london", "question_id": 2811085, "best approach": "wiki, concept, image", "verif answer": "america", "anno approach": "wiki, concept, image", "verif wiki answer": "to left(0.7007)", "verif concept answer": "to left(0.6540)", "verif image answer": "to left(0.6846)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281108.jpg"}, {"question": "what is the weather in this picture", "gt answer": "cold(1.00)", "pred answer": "rainy", "question_id": 2584395, "best approach": "", "verif answer": "cold", "anno approach": "wiki, concept, image", "verif wiki answer": "hot(0.6915)", "verif concept answer": "hot(0.6922)", "verif image answer": "stay warm(0.7176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258439.jpg"}, {"question": "what fruits are these", "gt answer": "blueberry(1.00)<br/>cherry(0.60)", "pred answer": "apple", "question_id": 5029115, "best approach": "image", "verif answer": "strawberry", "anno approach": "wiki, concept, image", "verif wiki answer": "berry(0.6804)", "verif concept answer": "strawberry(0.6853)", "verif image answer": "cherry(0.6517)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502911.jpg"}, {"question": "what is the largest competition for this sport", "gt answer": "o'neill world cup of surf(1.00)", "pred answer": "surf", "question_id": 5193565, "best approach": "wiki", "verif answer": "surf", "anno approach": "wiki, concept, image", "verif wiki answer": "o'neill world cup of surf(0.7057)", "verif concept answer": "surf(0.6851)", "verif image answer": "surf(0.6360)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000519356.jpg"}, {"question": "who manfactures the helmet", "gt answer": "doc(1.00)<br/>oakley(0.60)", "pred answer": "bode miller", "question_id": 5356855, "best approach": "", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "ski pole(0.6191)", "verif concept answer": "ski pole(0.7126)", "verif image answer": "ski pole(0.7029)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535685.jpg"}, {"question": "what ancient general famously used animals like these when invading rome", "gt answer": "hannibal(1.00)", "pred answer": "elephant", "question_id": 2850935, "best approach": "", "verif answer": "dumbo", "anno approach": "wiki, concept, image", "verif wiki answer": "dumbo(0.6867)", "verif concept answer": "dumbo(0.5694)", "verif image answer": "million(0.5620)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285093.jpg"}, {"question": "what kind of bear in the middle", "gt answer": "koala(1.00)<br/>teddy bear(0.60)", "pred answer": "stuffed", "question_id": 2668805, "best approach": "wiki, concept", "verif answer": "teddy bear", "anno approach": "wiki, concept, image", "verif wiki answer": "koala(0.7226)", "verif concept answer": "koala(0.6913)", "verif image answer": "stuffing(0.6687)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266880.jpg"}, {"question": "what is the punishment of doing this in the usa", "gt answer": "prison(1.00)<br/>death(0.60)<br/>knife(0.60)", "pred answer": "relax", "question_id": 2802285, "best approach": "wiki", "verif answer": "cut", "anno approach": "wiki, concept, image", "verif wiki answer": "knife(0.5770)", "verif concept answer": "cut(0.6554)", "verif image answer": "cut(0.6674)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280228.jpg"}, {"question": "where is the boat at", "gt answer": "alaska(1.00)<br/>norway(0.60)<br/>harbor(0.60)", "pred answer": "marina", "question_id": 4510365, "best approach": "wiki, concept, image", "verif answer": "harbor", "anno approach": "wiki, concept, image", "verif wiki answer": "harbor(0.7135)", "verif concept answer": "harbor(0.6960)", "verif image answer": "harbor(0.7145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451036.jpg"}, {"question": "what are these toys filled with", "gt answer": "stuffing(1.00)<br/>cotton(0.60)<br/>polyester(0.60)", "pred answer": "teddy bear", "question_id": 401815, "best approach": "concept, image", "verif answer": "stuffing", "anno approach": "wiki, concept, image", "verif wiki answer": "plush(0.6597)", "verif concept answer": "stuffing(0.6360)", "verif image answer": "stuffing(0.6554)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040181.jpg"}, {"question": "what kind of person lives here", "gt answer": "single(1.00)<br/>mother(0.60)<br/>woman(0.60)<br/>kid(0.60)", "pred answer": "student", "question_id": 5032745, "best approach": "image", "verif answer": "female", "anno approach": "wiki, concept, image", "verif wiki answer": "mother(0.6834)", "verif concept answer": "female(0.6267)", "verif image answer": "single(0.5416)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503274.jpg"}, {"question": "what are these horses on top of", "gt answer": "hill(1.00)", "pred answer": "mountain", "question_id": 4637385, "best approach": "concept", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "mountain(0.6927)", "verif concept answer": "hill(0.6233)", "verif image answer": "mountain(0.6939)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463738.jpg"}, {"question": "what breed of birds are these", "gt answer": "dove(0.60)<br/>finch(0.60)<br/>monkey(0.60)<br/>robin(1.00)", "pred answer": "sparrow", "question_id": 4872645, "best approach": "concept", "verif answer": "sparrow", "anno approach": "wiki, concept, image", "verif wiki answer": "dove(0.6861)", "verif concept answer": "robin(0.6245)", "verif image answer": "dove(0.6517)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487264.jpg"}, {"question": "how do you cook this dish", "gt answer": "bake(1.00)<br/>fry(0.60)<br/>bake it(0.60)<br/>baked(0.60)", "pred answer": "in oven", "question_id": 4283455, "best approach": "wiki, concept, image", "verif answer": "baked", "anno approach": "wiki, concept, image", "verif wiki answer": "baked(0.6661)", "verif concept answer": "baked(0.6728)", "verif image answer": "baked(0.6491)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428345.jpg"}, {"question": "what kind of sauce is this", "gt answer": "ranch dress(1.00)<br/>ranch(0.60)", "pred answer": "beef", "question_id": 4216565, "best approach": "concept", "verif answer": "mustard", "anno approach": "wiki, concept, image", "verif wiki answer": "mustard(0.6951)", "verif concept answer": "ranch dress(0.6647)", "verif image answer": "tomato(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421656.jpg"}, {"question": "why are the animals here", "gt answer": "drink(1.00)<br/>drink water(0.60)<br/>thirsty(0.60)", "pred answer": "bath", "question_id": 4842875, "best approach": "wiki, concept, image", "verif answer": "bath", "anno approach": "wiki, concept, image", "verif wiki answer": "thirsty(0.7037)", "verif concept answer": "thirsty(0.6610)", "verif image answer": "drink water(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484287.jpg"}, {"question": "what kind of appliance is next to the sink", "gt answer": "dryer(1.00)<br/>wash machine(1.00)", "pred answer": "blender", "question_id": 4082275, "best approach": "", "verif answer": "oven", "anno approach": "wiki, concept, image", "verif wiki answer": "oven(0.7101)", "verif concept answer": "oven(0.7203)", "verif image answer": "oven(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408227.jpg"}, {"question": "what orbiting body is said to influence these waves", "gt answer": "moon(1.00)<br/>gravity(0.60)", "pred answer": "wave", "question_id": 189355, "best approach": "wiki, concept, image", "verif answer": "moon", "anno approach": "wiki, concept, image", "verif wiki answer": "moon(0.6872)", "verif concept answer": "moon(0.6367)", "verif image answer": "moon(0.6571)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000018935.jpg"}, {"question": "what is tied to this animal 's horns", "gt answer": "rope(1.00)", "pred answer": "leash", "question_id": 24155, "best approach": "", "verif answer": "rope", "anno approach": "wiki, concept, image", "verif wiki answer": "strap(0.6824)", "verif concept answer": "strap(0.7150)", "verif image answer": "strap(0.6994)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002415.jpg"}, {"question": "what is the man doing", "gt answer": "play tennis(1.00)<br/>tennis(1.00)<br/>hit(0.60)", "pred answer": "serve", "question_id": 2462805, "best approach": "concept", "verif answer": "serve", "anno approach": "wiki, concept, image", "verif wiki answer": "hit(0.6382)", "verif concept answer": "tennis(0.6585)", "verif image answer": "serve(0.6356)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246280.jpg"}, {"question": "what is he supposed to be doing", "gt answer": "work(1.00)<br/>code(0.60)<br/>study(0.60)", "pred answer": "play video game", "question_id": 5352025, "best approach": "wiki, concept", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "work(0.5422)", "verif concept answer": "work(0.6307)", "verif image answer": "study(0.5656)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535202.jpg"}, {"question": "where would you find this type of transportation", "gt answer": "pennsylvania(1.00)<br/>country(0.60)<br/>countryside(0.60)", "pred answer": "farm", "question_id": 2776885, "best approach": "wiki, concept, image", "verif answer": "pennsylvania", "anno approach": "wiki, concept, image", "verif wiki answer": "country(0.6834)", "verif concept answer": "country(0.5949)", "verif image answer": "countryside(0.6847)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277688.jpg"}, {"question": "what kind of bird is this", "gt answer": "penguin(1.00)", "pred answer": "puffin", "question_id": 4160085, "best approach": "", "verif answer": "pelican", "anno approach": "wiki, concept, image", "verif wiki answer": "oriole(0.7093)", "verif concept answer": "pelican(0.6849)", "verif image answer": "san diego(0.6370)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416008.jpg"}, {"question": "what person was this toy named after", "gt answer": "teddy roosevelt(1.00)", "pred answer": "theodore roosevelt", "question_id": 1627285, "best approach": "", "verif answer": "theodore roosevelt", "anno approach": "wiki, concept, image", "verif wiki answer": "theodore roosevelt(0.7246)", "verif concept answer": "theodore roosevelt(0.6689)", "verif image answer": "obama(0.5930)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162728.jpg"}, {"question": "what position are the people in the picture in", "gt answer": "cross legged(1.00)", "pred answer": "sit", "question_id": 52155, "best approach": "concept, image", "verif answer": "sit", "anno approach": "wiki, concept, image", "verif wiki answer": "sit(0.7045)", "verif concept answer": "cross legged(0.7086)", "verif image answer": "cross legged(0.7051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005215.jpg"}, {"question": "what type of headpiece is this woman wearing", "gt answer": "tiara(1.00)", "pred answer": "hat", "question_id": 4403395, "best approach": "wiki", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "tiara(0.6980)", "verif concept answer": "donut(0.6965)", "verif image answer": "birthday(0.6983)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440339.jpg"}, {"question": "what video character is shown here", "gt answer": "pac man(1.00)", "pred answer": "mary poppins", "question_id": 2349005, "best approach": "wiki, concept, image", "verif answer": "fire", "anno approach": "wiki, concept, image", "verif wiki answer": "pac man(0.7310)", "verif concept answer": "pac man(0.7309)", "verif image answer": "pac man(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000234900.jpg"}, {"question": "what kind of aircraft is this", "gt answer": "bomber(1.00)<br/>fighter jet(0.60)<br/>military(0.60)", "pred answer": "fighter", "question_id": 1768965, "best approach": "concept", "verif answer": "fighter", "anno approach": "wiki, concept, image", "verif wiki answer": "fighter(0.7200)", "verif concept answer": "bomber(0.6963)", "verif image answer": "biplane(0.7263)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176896.jpg"}, {"question": "do these colors indicate high noon or the start end of the day", "gt answer": "end(1.00)<br/>end of day(1.00)<br/>noon(0.60)", "pred answer": "sunset", "question_id": 1767635, "best approach": "wiki, concept", "verif answer": "even", "anno approach": "wiki, concept, image", "verif wiki answer": "end(0.7163)", "verif concept answer": "end(0.7044)", "verif image answer": "morn(0.6807)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176763.jpg"}, {"question": "which type of fruits are seen here", "gt answer": "apple and orange(1.00)<br/>orange(0.60)", "pred answer": "apple", "question_id": 5253425, "best approach": "image", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "apple(0.6756)", "verif concept answer": "apple(0.6913)", "verif image answer": "orange(0.7159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525342.jpg"}, {"question": "do you see two blue birds or two seagulls", "gt answer": "seagull(1.00)<br/>2 seagulls(1.00)", "pred answer": "blue", "question_id": 4274915, "best approach": "wiki, image", "verif answer": "2 seagulls", "anno approach": "wiki, concept, image", "verif wiki answer": "seagull(0.5381)", "verif concept answer": "apple(0.5130)", "verif image answer": "2 seagulls(0.5606)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427491.jpg"}, {"question": "what is the monkey on the child 's backpack doing", "gt answer": "eat banana(1.00)<br/>eat(1.00)", "pred answer": "sit", "question_id": 4485315, "best approach": "wiki", "verif answer": "eat", "anno approach": "wiki, concept, image", "verif wiki answer": "eat banana(0.7218)", "verif concept answer": "eat it(0.7219)", "verif image answer": "eat it(0.6203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448531.jpg"}, {"question": "in which city are the headquarters of the company that manufactures this type of computers located", "gt answer": "cupertino(1.00)<br/>seattle(0.60)", "pred answer": "amsterdam", "question_id": 4788855, "best approach": "wiki, image", "verif answer": "new york city", "anno approach": "wiki, concept, image", "verif wiki answer": "seattle(0.7219)", "verif concept answer": "new york(0.6558)", "verif image answer": "seattle(0.6478)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478885.jpg"}, {"question": "what ingredients were used for this dessert", "gt answer": "chocolate(1.00)", "pred answer": "sugar", "question_id": 2380185, "best approach": "", "verif answer": "chocolate", "anno approach": "wiki, concept, image", "verif wiki answer": "strawberry(0.6841)", "verif concept answer": "strawberry(0.7079)", "verif image answer": "strawberry(0.6148)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238018.jpg"}, {"question": "what adult achievement recognized by three letters is comparable to a high school diploma", "gt answer": "ged(1.00)<br/>5(0.60)", "pred answer": "obama", "question_id": 4598535, "best approach": "wiki, concept", "verif answer": "2", "anno approach": "wiki, concept, image", "verif wiki answer": "ged(0.5569)", "verif concept answer": "ged(0.6356)", "verif image answer": "5(0.6367)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459853.jpg"}, {"question": "what is the use for this vehicle", "gt answer": "dig(1.00)<br/>construction(0.60)", "pred answer": "haul", "question_id": 3682935, "best approach": "image", "verif answer": "construction", "anno approach": "wiki, concept, image", "verif wiki answer": "work(0.6811)", "verif concept answer": "construction site(0.7092)", "verif image answer": "dig(0.6579)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000368293.jpg"}, {"question": "what type of car is the gray car", "gt answer": "jeep(1.00)<br/>corolla(0.60)<br/>suv(0.60)", "pred answer": "sedan", "question_id": 4767615, "best approach": "concept", "verif answer": "sedan", "anno approach": "wiki, concept, image", "verif wiki answer": "sedan(0.7105)", "verif concept answer": "jeep(0.6840)", "verif image answer": "sedan(0.7227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476761.jpg"}, {"question": "what kind of fish is on that plate", "gt answer": "salmon(1.00)", "pred answer": "potato", "question_id": 989445, "best approach": "", "verif answer": "egg", "anno approach": "wiki, concept, image", "verif wiki answer": "carrot(0.6892)", "verif concept answer": "tuna(0.5449)", "verif image answer": "carrot(0.5366)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098944.jpg"}, {"question": "what types of boats are in this picture", "gt answer": "sail(1.00)<br/>sailboat(1.00)<br/>yacht(0.60)", "pred answer": "fish boat", "question_id": 2052435, "best approach": "wiki, concept, image", "verif answer": "sailboat", "anno approach": "wiki, concept, image", "verif wiki answer": "sailboat(0.6817)", "verif concept answer": "sailboat(0.7127)", "verif image answer": "sailboat(0.7208)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205243.jpg"}, {"question": "what position did the man on the shirt hold", "gt answer": "president(1.00)<br/>wine taster(0.60)", "pred answer": "batter", "question_id": 5136835, "best approach": "concept", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "bus driver(0.6448)", "verif concept answer": "president(0.5788)", "verif image answer": "man(0.7079)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513683.jpg"}, {"question": "of what airplane is this a model", "gt answer": "biplane(1.00)<br/>boat(0.60)<br/>glider(0.60)", "pred answer": "cessna", "question_id": 11685, "best approach": "wiki, image", "verif answer": "biplane", "anno approach": "wiki, concept, image", "verif wiki answer": "biplane(0.5508)", "verif concept answer": "prop(0.5577)", "verif image answer": "biplane(0.5731)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001168.jpg"}, {"question": "what two chemical elements make up the substance that is most prevalent in this picture", "gt answer": "hydrogen and oxygen(1.00)", "pred answer": "boat", "question_id": 2020505, "best approach": "wiki, concept, image", "verif answer": "h2o", "anno approach": "wiki, concept, image", "verif wiki answer": "hydrogen and oxygen(0.7153)", "verif concept answer": "hydrogen and oxygen(0.6749)", "verif image answer": "hydrogen and oxygen(0.6154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202050.jpg"}, {"question": "what is the use of that pink object over her head", "gt answer": "keep dry(1.00)", "pred answer": "umbrella", "question_id": 4705325, "best approach": "wiki, image", "verif answer": "stay dry", "anno approach": "wiki, concept, image", "verif wiki answer": "keep dry(0.6506)", "verif concept answer": "stay dry(0.7067)", "verif image answer": "keep dry(0.6582)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470532.jpg"}, {"question": "what physical feature seen here looks the way dirt that has been baked in the sun starts to look", "gt answer": "cracked(1.00)<br/>spot(0.60)", "pred answer": "island", "question_id": 1306815, "best approach": "wiki", "verif answer": "spot", "anno approach": "wiki, concept, image", "verif wiki answer": "cracked(0.6200)", "verif concept answer": "long neck(0.5993)", "verif image answer": "spot(0.6783)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130681.jpg"}, {"question": "where was this motorcycle manufactured", "gt answer": "japan(1.00)<br/>europe(0.60)<br/>kawasaki(0.60)", "pred answer": "germany", "question_id": 5495325, "best approach": "concept", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "honda(0.6769)", "verif concept answer": "kawasaki(0.6830)", "verif image answer": "america(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000549532.jpg"}, {"question": "this statue is used to track what", "gt answer": "time(1.00)<br/>horse race(0.60)", "pred answer": "clock", "question_id": 5339415, "best approach": "wiki, concept, image", "verif answer": "time", "anno approach": "wiki, concept, image", "verif wiki answer": "time(0.7218)", "verif concept answer": "time(0.6756)", "verif image answer": "time(0.6821)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000533941.jpg"}, {"question": "are those cabinets painted or plastic", "gt answer": "painted(1.00)<br/>plastic(0.60)", "pred answer": "paint", "question_id": 1261825, "best approach": "image", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "plastic(0.6193)", "verif concept answer": "paint(0.6629)", "verif image answer": "painted(0.5970)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126182.jpg"}, {"question": "what would someone do with the object in the photo", "gt answer": "sit(1.00)", "pred answer": "hike", "question_id": 2228715, "best approach": "wiki, concept, image", "verif answer": "sit", "anno approach": "wiki, concept, image", "verif wiki answer": "sit(0.7263)", "verif concept answer": "sit(0.6864)", "verif image answer": "sit(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222871.jpg"}, {"question": "what other utensil could be used to eat this dish", "gt answer": "fork(1.00)", "pred answer": "spoon", "question_id": 5202085, "best approach": "wiki", "verif answer": "spoon", "anno approach": "wiki, concept, image", "verif wiki answer": "fork(0.7153)", "verif concept answer": "spoon(0.6677)", "verif image answer": "right fork(0.6863)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520208.jpg"}, {"question": "who made this bed at the hotel", "gt answer": "maid(1.00)<br/>serta(0.60)", "pred answer": "owner", "question_id": 3971815, "best approach": "", "verif answer": "maid", "anno approach": "wiki, concept, image", "verif wiki answer": "queen(0.6596)", "verif concept answer": "wife(0.5854)", "verif image answer": "wife(0.6339)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397181.jpg"}, {"question": "the open location where the animals are is called what", "gt answer": "savannah(1.00)<br/>plain(0.60)", "pred answer": "grassland", "question_id": 4606425, "best approach": "wiki, concept, image", "verif answer": "savannah", "anno approach": "wiki, concept, image", "verif wiki answer": "plain(0.7236)", "verif concept answer": "plain(0.6820)", "verif image answer": "plain(0.7187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460642.jpg"}, {"question": "where are the mountains located", "gt answer": "peru(1.00)<br/>grand canyon(0.60)", "pred answer": "rockies", "question_id": 599535, "best approach": "", "verif answer": "nevada", "anno approach": "wiki, concept, image", "verif wiki answer": "mountain(0.6952)", "verif concept answer": "nevada(0.6227)", "verif image answer": "mountain(0.6695)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059953.jpg"}, {"question": "where is this carriage displayed", "gt answer": "museum(1.00)<br/>horse(0.60)<br/>mall(0.60)<br/>china(0.60)", "pred answer": "circus", "question_id": 3117265, "best approach": "wiki, image", "verif answer": "museum", "anno approach": "wiki, concept, image", "verif wiki answer": "museum(0.7066)", "verif concept answer": "mall(0.6504)", "verif image answer": "museum(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311726.jpg"}, {"question": "for what purpose did this breed of dog originate for", "gt answer": "hunt(1.00)<br/>race(0.60)<br/>work(0.60)", "pred answer": "pet", "question_id": 4314405, "best approach": "wiki, concept", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "hunt(0.6031)", "verif concept answer": "hunt(0.6371)", "verif image answer": "work(0.6198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431440.jpg"}, {"question": "what musical instrument used to be made with parts from these animals", "gt answer": "piano(1.00)<br/>horn(0.60)", "pred answer": "ivory", "question_id": 1381335, "best approach": "concept, image", "verif answer": "horn", "anno approach": "wiki, concept, image", "verif wiki answer": "oar(0.6647)", "verif concept answer": "horn(0.6513)", "verif image answer": "horn(0.6861)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138133.jpg"}, {"question": "what are the two vegetables on the counter", "gt answer": "broccoli and carrot(1.00)", "pred answer": "carrot", "question_id": 2650745, "best approach": "", "verif answer": "vegetable", "anno approach": "wiki, concept, image", "verif wiki answer": "broccoli(0.6181)", "verif concept answer": "veggie(0.6804)", "verif image answer": "broccoli(0.5640)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265074.jpg"}, {"question": "this sort of narrow space is called a what", "gt answer": "alley(1.00)", "pred answer": "street", "question_id": 619515, "best approach": "", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.6178)", "verif concept answer": "store(0.6895)", "verif image answer": "street(0.7058)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061951.jpg"}, {"question": "the horizontal slats connecting the rails seen here are generally called railroad what", "gt answer": "tie(1.00)<br/>track(0.60)", "pred answer": "electric", "question_id": 5115085, "best approach": "", "verif answer": "track", "anno approach": "wiki, concept, image", "verif wiki answer": "attach to surfer(0.7077)", "verif concept answer": "attach to surfer(0.6357)", "verif image answer": "rail(0.6751)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511508.jpg"}, {"question": "what company manufactured the water faucet seen here", "gt answer": "moen(1.00)<br/>kohler(1.00)", "pred answer": "colgate", "question_id": 1259955, "best approach": "wiki, image", "verif answer": "colgate", "anno approach": "wiki, concept, image", "verif wiki answer": "moen(0.6191)", "verif concept answer": "colgate(0.7162)", "verif image answer": "kohler(0.6733)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125995.jpg"}, {"question": "what causes these waves", "gt answer": "tide(1.00)<br/>gravity(0.60)<br/>wind(0.60)", "pred answer": "wave", "question_id": 1228965, "best approach": "concept, image", "verif answer": "moon", "anno approach": "wiki, concept, image", "verif wiki answer": "air(0.6889)", "verif concept answer": "gravity(0.6604)", "verif image answer": "gravity(0.6702)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122896.jpg"}, {"question": "what design is drawn on the plate", "gt answer": "spider web(1.00)", "pred answer": "striped", "question_id": 4177515, "best approach": "", "verif answer": "stripe", "anno approach": "wiki, concept, image", "verif wiki answer": "leopard(0.6867)", "verif concept answer": "leopard(0.6854)", "verif image answer": "floral(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417751.jpg"}, {"question": "how do mirrors distort light", "gt answer": "reflection(0.60)<br/>reflect(1.00)", "pred answer": "lcd", "question_id": 4421545, "best approach": "", "verif answer": "mirror", "anno approach": "wiki, concept, image", "verif wiki answer": "light(0.7220)", "verif concept answer": "mirror(0.5878)", "verif image answer": "mirror(0.6632)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442154.jpg"}, {"question": "which type of glass is used to make this table", "gt answer": "tempered(1.00)<br/>clear(0.60)<br/>pane(0.60)", "pred answer": "reflective", "question_id": 1795195, "best approach": "wiki", "verif answer": "reflective", "anno approach": "wiki, concept, image", "verif wiki answer": "pane(0.6714)", "verif concept answer": "black and white(0.6434)", "verif image answer": "black and white(0.7203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000179519.jpg"}, {"question": "is it day time or night time", "gt answer": "day time(1.00)<br/>day(0.60)<br/>daytime(0.60)", "pred answer": "night", "question_id": 4799355, "best approach": "wiki, concept", "verif answer": "daytime", "anno approach": "wiki, concept, image", "verif wiki answer": "daytime(0.6402)", "verif concept answer": "day(0.7016)", "verif image answer": "yellow(0.7047)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479935.jpg"}, {"question": "are the tomatoes on this salad a fruit or vegetable", "gt answer": "vegetable(1.00)<br/>fruit(0.60)", "pred answer": "veggies", "question_id": 3388645, "best approach": "wiki", "verif answer": "veggies", "anno approach": "wiki, concept, image", "verif wiki answer": "fruit(0.6484)", "verif concept answer": "veggies(0.6052)", "verif image answer": "vegetarian(0.6485)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338864.jpg"}, {"question": "what floor is this room on", "gt answer": "first(1.00)<br/>main(0.60)", "pred answer": "laminate", "question_id": 4150895, "best approach": "image", "verif answer": "1st", "anno approach": "wiki, concept, image", "verif wiki answer": "kindergarten(0.6348)", "verif concept answer": "kindergarten(0.6518)", "verif image answer": "main(0.6374)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415089.jpg"}, {"question": "", "gt answer": "little(0.60)<br/>$10(0.60)<br/>200(0.60)", "pred answer": "15", "question_id": 145365, "best approach": "concept", "verif answer": "200", "anno approach": "wiki, concept, image", "verif wiki answer": "2 dollars(0.6513)", "verif concept answer": "little(0.6161)", "verif image answer": "2 dollars(0.6340)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000014536.jpg"}, {"question": "which form is the wood", "gt answer": "log(1.00)<br/>arm(0.60)<br/>board(0.60)", "pred answer": "pine", "question_id": 3825825, "best approach": "image", "verif answer": "bamboo", "anno approach": "wiki, concept, image", "verif wiki answer": "bamboo(0.6382)", "verif concept answer": "bamboo(0.6652)", "verif image answer": "arm(0.6822)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382582.jpg"}, {"question": "what city is shown in the photo", "gt answer": "tokyo(1.00)<br/>new york(1.00)", "pred answer": "san francisco", "question_id": 903245, "best approach": "wiki, concept", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "tokyo(0.7276)", "verif concept answer": "new york(0.6960)", "verif image answer": "chicago(0.5743)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090324.jpg"}, {"question": "how long will it take them to drink this coffee", "gt answer": "forever(1.00)", "pred answer": "10 minutes", "question_id": 2646995, "best approach": "concept", "verif answer": "year", "anno approach": "wiki, concept, image", "verif wiki answer": "5 days(0.6055)", "verif concept answer": "forever(0.6107)", "verif image answer": "4 days(0.6793)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000264699.jpg"}, {"question": "what is the formal name of pipe exhausting smoke from the woodburning stove", "gt answer": "chimney(1.00)", "pred answer": "gas", "question_id": 1284345, "best approach": "wiki", "verif answer": "bleach", "anno approach": "wiki, concept, image", "verif wiki answer": "chimney(0.5464)", "verif concept answer": "chimney sweep(0.6050)", "verif image answer": "chimney sweep(0.7200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128434.jpg"}, {"question": "what type of owl is this", "gt answer": "snow owl(1.00)<br/>barn(0.60)<br/>night(0.60)", "pred answer": "stuffed", "question_id": 2770505, "best approach": "image", "verif answer": "night", "anno approach": "wiki, concept, image", "verif wiki answer": "milk(0.5409)", "verif concept answer": "milk(0.5854)", "verif image answer": "night(0.5675)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277050.jpg"}, {"question": "what kind of house is here", "gt answer": "apartment(1.00)<br/>apart(1.00)", "pred answer": "house", "question_id": 771545, "best approach": "", "verif answer": "house", "anno approach": "wiki, concept, image", "verif wiki answer": "house(0.6880)", "verif concept answer": "live(0.5970)", "verif image answer": "house(0.6476)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077154.jpg"}, {"question": "what kind of sandwhich is on the plate", "gt answer": "ham and cheese(1.00)<br/>ham(0.60)", "pred answer": "sub", "question_id": 2498565, "best approach": "wiki, image", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "ham and cheese(0.5702)", "verif concept answer": "breakfast(0.5803)", "verif image answer": "ham and cheese(0.6563)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249856.jpg"}, {"question": "what type of food is this", "gt answer": "sandwich(1.00)<br/>burger(0.60)", "pred answer": "cake", "question_id": 2910195, "best approach": "image", "verif answer": "cake", "anno approach": "wiki, concept, image", "verif wiki answer": "cake(0.6924)", "verif concept answer": "cake(0.7085)", "verif image answer": "burger(0.7264)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291019.jpg"}, {"question": "what is the professional name of the group in which these pilots fly", "gt answer": "blue angel(1.00)", "pred answer": "military", "question_id": 901065, "best approach": "image", "verif answer": "blue angel", "anno approach": "wiki, concept, image", "verif wiki answer": "airshow(0.7180)", "verif concept answer": "motorcycle(0.5186)", "verif image answer": "blue angel(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090106.jpg"}, {"question": "what did the animal in the clock jump over in a nursery rhyme", "gt answer": "moon(1.00)", "pred answer": "ball", "question_id": 2569085, "best approach": "wiki", "verif answer": "wave", "anno approach": "wiki, concept, image", "verif wiki answer": "moon(0.6778)", "verif concept answer": "gravity(0.6165)", "verif image answer": "gravity(0.6434)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256908.jpg"}, {"question": "known to be on a very fast car", "gt answer": "mustang(1.00)", "pred answer": "horse", "question_id": 5585815, "best approach": "", "verif answer": "pony", "anno approach": "wiki, concept, image", "verif wiki answer": "stallion(0.5820)", "verif concept answer": "pony(0.5644)", "verif image answer": "pony(0.6993)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558581.jpg"}, {"question": "what voltage is that electrial outlet in the wall rated at", "gt answer": "120v(1.00)<br/>low(0.60)", "pred answer": "50", "question_id": 2432315, "best approach": "wiki, concept, image", "verif answer": "d", "anno approach": "wiki, concept, image", "verif wiki answer": "120v(0.5686)", "verif concept answer": "120v(0.6745)", "verif image answer": "120v(0.5975)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243231.jpg"}, {"question": "how many people can be seated in the furniture", "gt answer": "4(1.00)", "pred answer": "many", "question_id": 2570205, "best approach": "", "verif answer": "1", "anno approach": "wiki, concept, image", "verif wiki answer": "6(0.6928)", "verif concept answer": "6(0.6865)", "verif image answer": "3(0.7068)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257020.jpg"}, {"question": "what type of pizza is this", "gt answer": "vegetarian(1.00)", "pred answer": "pepperoni", "question_id": 5281515, "best approach": "", "verif answer": "supreme", "anno approach": "wiki, concept, image", "verif wiki answer": "vegan(0.6942)", "verif concept answer": "hungry(0.6103)", "verif image answer": "vegetable(0.6466)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528151.jpg"}, {"question": "what is the cause of the orange dust like breakdown shown on these cars", "gt answer": "rust(1.00)<br/>oxidation(1.00)", "pred answer": "fire", "question_id": 1997325, "best approach": "wiki", "verif answer": "rust", "anno approach": "wiki, concept, image", "verif wiki answer": "oxidation(0.7006)", "verif concept answer": "reflection(0.6522)", "verif image answer": "reflection(0.6251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199732.jpg"}, {"question": "how many teeth does this animal have", "gt answer": "42(1.00)<br/>45(0.60)<br/>25(0.60)<br/>lot(0.60)", "pred answer": "32", "question_id": 3961945, "best approach": "image", "verif answer": "42", "anno approach": "wiki, concept, image", "verif wiki answer": "lot(0.7002)", "verif concept answer": "25(0.6785)", "verif image answer": "42(0.6227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396194.jpg"}, {"question": "what distinguishes these trees from many other north american trees during the autumn season", "gt answer": "remain green(1.00)", "pred answer": "fir", "question_id": 1767575, "best approach": "wiki", "verif answer": "winter", "anno approach": "wiki, concept, image", "verif wiki answer": "remain green(0.6533)", "verif concept answer": "bear(0.6020)", "verif image answer": "native(0.6023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176757.jpg"}, {"question": "is this a king or queen bed", "gt answer": "queen(1.00)<br/>king(1.00)", "pred answer": "full", "question_id": 2933065, "best approach": "wiki", "verif answer": "full", "anno approach": "wiki, concept, image", "verif wiki answer": "queen(0.6341)", "verif concept answer": "full(0.6220)", "verif image answer": "canopy(0.7150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293306.jpg"}, {"question": "how many of this animal are in the us", "gt answer": "85.8 million(1.00)<br/>thousand(0.60)", "pred answer": "5", "question_id": 5667655, "best approach": "", "verif answer": "thousand", "anno approach": "wiki, concept, image", "verif wiki answer": "million(0.7070)", "verif concept answer": "million(0.6915)", "verif image answer": "million(0.6908)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566765.jpg"}, {"question": "what kind of hat is this man wearing", "gt answer": "sombrero(1.00)<br/>big(0.60)", "pred answer": "bowl", "question_id": 4994255, "best approach": "", "verif answer": "fedora", "anno approach": "wiki, concept, image", "verif wiki answer": "fedora(0.6839)", "verif concept answer": "fedora(0.7194)", "verif image answer": "fedora(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499425.jpg"}, {"question": "what does this animal eat", "gt answer": "seed(1.00)<br/>grain(0.60)<br/>nut(0.60)", "pred answer": "cat food", "question_id": 5002715, "best approach": "image", "verif answer": "mice", "anno approach": "wiki, concept, image", "verif wiki answer": "mice(0.6605)", "verif concept answer": "mice(0.6463)", "verif image answer": "seed(0.5992)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500271.jpg"}, {"question": "when were stoves invented", "gt answer": "1820s(1.00)<br/>1950s(0.60)<br/>1850(0.60)", "pred answer": "1981", "question_id": 96205, "best approach": "image", "verif answer": "1800s", "anno approach": "wiki, concept, image", "verif wiki answer": "1800s(0.6617)", "verif concept answer": "1950s(0.5802)", "verif image answer": "1820s(0.5641)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009620.jpg"}, {"question": "what is the animals offspring called", "gt answer": "foal(1.00)<br/>colt(1.00)<br/>zebra(0.60)", "pred answer": "calf", "question_id": 5103335, "best approach": "wiki", "verif answer": "foal", "anno approach": "wiki, concept, image", "verif wiki answer": "colt(0.6273)", "verif concept answer": "zebra(0.6106)", "verif image answer": "african(0.7161)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510333.jpg"}, {"question": "do you think he just landed a trick or did he fail", "gt answer": "landed(1.00)", "pred answer": "jump", "question_id": 5012125, "best approach": "", "verif answer": "land", "anno approach": "wiki, concept, image", "verif wiki answer": "strike(0.6973)", "verif concept answer": "strike(0.6983)", "verif image answer": "parked(0.6911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501212.jpg"}, {"question": "is this airplane on the ground or flying in the air", "gt answer": "on ground(1.00)<br/>parked(0.60)", "pred answer": "land", "question_id": 5299055, "best approach": "concept", "verif answer": "land", "anno approach": "wiki, concept, image", "verif wiki answer": "take off(0.7186)", "verif concept answer": "parked(0.5475)", "verif image answer": "land(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529905.jpg"}, {"question": "what is strange about these cars", "gt answer": "stuffed animal(1.00)<br/>bear(0.60)<br/>teddy bear(0.60)", "pred answer": "nothing", "question_id": 4283015, "best approach": "", "verif answer": "teddy bear", "anno approach": "wiki, concept, image", "verif wiki answer": "people(0.5783)", "verif concept answer": "stuffed(0.5691)", "verif image answer": "people(0.7088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428301.jpg"}, {"question": "what is this room called when it is off the owner 's bedroom", "gt answer": "master(1.00)", "pred answer": "bathroom", "question_id": 3336535, "best approach": "wiki", "verif answer": "bedroom", "anno approach": "wiki, concept, image", "verif wiki answer": "master(0.6457)", "verif concept answer": "bedroom(0.6973)", "verif image answer": "bedroom(0.6954)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333653.jpg"}, {"question": "this boat travels using wooden what", "gt answer": "oar(1.00)", "pred answer": "wooden", "question_id": 494025, "best approach": "", "verif answer": "row", "anno approach": "wiki, concept, image", "verif wiki answer": "row(0.6941)", "verif concept answer": "paddle(0.6666)", "verif image answer": "trunk(0.5857)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049402.jpg"}, {"question": "what type of building is in the background", "gt answer": "stable(1.00)<br/>barn(0.60)", "pred answer": "house", "question_id": 2366735, "best approach": "image", "verif answer": "barn", "anno approach": "wiki, concept, image", "verif wiki answer": "barn(0.7195)", "verif concept answer": "barn(0.6724)", "verif image answer": "stable(0.5990)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236673.jpg"}, {"question": "what is this woman about to do", "gt answer": "snowboard(1.00)", "pred answer": "ski", "question_id": 1856815, "best approach": "wiki, concept, image", "verif answer": "snowboard", "anno approach": "wiki, concept, image", "verif wiki answer": "snowboard(0.6905)", "verif concept answer": "snowboard(0.6781)", "verif image answer": "snowboard(0.6260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185681.jpg"}, {"question": "what is the man in the white shirt drinking", "gt answer": "gatorade(1.00)", "pred answer": "coke", "question_id": 1874425, "best approach": "concept", "verif answer": "juice", "anno approach": "wiki, concept, image", "verif wiki answer": "beer(0.6989)", "verif concept answer": "gatorade(0.6282)", "verif image answer": "alcoholic(0.5544)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187442.jpg"}, {"question": "how old is this little leaguer", "gt answer": "6(1.00)<br/>7(0.60)<br/>5(0.60)", "pred answer": "15", "question_id": 4484315, "best approach": "concept, image", "verif answer": "6", "anno approach": "wiki, concept, image", "verif wiki answer": "9(0.5936)", "verif concept answer": "5(0.6389)", "verif image answer": "7(0.6051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448431.jpg"}, {"question": "what fabric objects are normally put at these glass parts of the building", "gt answer": "curtain(1.00)<br/>blind(0.60)", "pred answer": "blanket", "question_id": 1289035, "best approach": "", "verif answer": "curtain", "anno approach": "wiki, concept, image", "verif wiki answer": "chrome(0.7000)", "verif concept answer": "chrome(0.6913)", "verif image answer": "shade(0.6895)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128903.jpg"}, {"question": "what country is seen here", "gt answer": "egypt(1.00)", "pred answer": "switzerland", "question_id": 959405, "best approach": "", "verif answer": "italy", "anno approach": "wiki, concept, image", "verif wiki answer": "italy(0.6978)", "verif concept answer": "mesopotamia(0.6515)", "verif image answer": "italy(0.6064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000095940.jpg"}, {"question": "what kind of meat is in this sandwich", "gt answer": "ham(1.00)<br/>turkey(1.00)", "pred answer": "pork", "question_id": 2230685, "best approach": "concept", "verif answer": "pork", "anno approach": "wiki, concept, image", "verif wiki answer": "pork(0.6023)", "verif concept answer": "ham(0.6081)", "verif image answer": "pork(0.6249)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223068.jpg"}, {"question": "what fruit flavored ice cream can this be", "gt answer": "blueberry(1.00)", "pred answer": "strawberry", "question_id": 39925, "best approach": "", "verif answer": "strawberry", "anno approach": "wiki, concept, image", "verif wiki answer": "strawberry(0.7050)", "verif concept answer": "strawberry(0.5499)", "verif image answer": "cherry(0.7193)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003992.jpg"}, {"question": "what electrical items might you find in this room", "gt answer": "mixer(1.00)<br/>stove(0.60)", "pred answer": "fan", "question_id": 4877965, "best approach": "wiki, concept, image", "verif answer": "stove", "anno approach": "wiki, concept, image", "verif wiki answer": "stove(0.7048)", "verif concept answer": "stove(0.7208)", "verif image answer": "stove(0.7010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487796.jpg"}, {"question": "don't run with these in your hands", "gt answer": "scissor(1.00)", "pred answer": "cut", "question_id": 3050145, "best approach": "", "verif answer": "scissor", "anno approach": "wiki, concept, image", "verif wiki answer": "razor(0.6125)", "verif concept answer": "razor(0.6877)", "verif image answer": "razor(0.5509)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305014.jpg"}, {"question": "what are those for", "gt answer": "knit(1.00)<br/>crochet(1.00)", "pred answer": "read", "question_id": 5702155, "best approach": "image", "verif answer": "sew", "anno approach": "wiki, concept, image", "verif wiki answer": "book(0.5559)", "verif concept answer": "book(0.5912)", "verif image answer": "knit(0.6241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570215.jpg"}, {"question": "which country does this type of parking meter appear", "gt answer": "usa(1.00)<br/>canada(0.60)<br/>united state(0.60)", "pred answer": "america", "question_id": 1501515, "best approach": "concept", "verif answer": "america", "anno approach": "wiki, concept, image", "verif wiki answer": "united state(0.6298)", "verif concept answer": "usa(0.6307)", "verif image answer": "us(0.7053)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000150151.jpg"}, {"question": "what is the horse doing", "gt answer": "stand(1.00)<br/>wait(0.60)", "pred answer": "walk", "question_id": 115195, "best approach": "wiki", "verif answer": "plow", "anno approach": "wiki, concept, image", "verif wiki answer": "stand(0.6875)", "verif concept answer": "plow(0.7173)", "verif image answer": "plow(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011519.jpg"}, {"question": "what 's he jumping", "gt answer": "road block(1.00)", "pred answer": "skateboard", "question_id": 3106745, "best approach": "wiki", "verif answer": "skateboard", "anno approach": "wiki, concept, image", "verif wiki answer": "road block(0.6815)", "verif concept answer": "skate(0.6694)", "verif image answer": "ollie(0.6784)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310674.jpg"}, {"question": "what city is that", "gt answer": "tokyo(1.00)<br/>beijing(0.60)", "pred answer": "san francisco", "question_id": 1713395, "best approach": "image", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "new york(0.7220)", "verif concept answer": "new york(0.7057)", "verif image answer": "beijing(0.6622)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171339.jpg"}, {"question": "how many years in total is most likely represented by the candles", "gt answer": "51(1.00)<br/>80(0.60)", "pred answer": "6", "question_id": 1394945, "best approach": "wiki, concept", "verif answer": "21", "anno approach": "wiki, concept, image", "verif wiki answer": "80(0.6825)", "verif concept answer": "80(0.6071)", "verif image answer": "35(0.5860)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139494.jpg"}, {"question": "who painted the mural on the side of this bus", "gt answer": "artist(1.00)<br/>banksy(0.60)", "pred answer": "graffiti", "question_id": 2359765, "best approach": "wiki, concept, image", "verif answer": "looney tune", "anno approach": "wiki, concept, image", "verif wiki answer": "banksy(0.6936)", "verif concept answer": "banksy(0.6815)", "verif image answer": "banksy(0.6889)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000235976.jpg"}, {"question": "this type of chair is also what type of musician", "gt answer": "rock(1.00)", "pred answer": "grand", "question_id": 3626435, "best approach": "", "verif answer": "concrete", "anno approach": "wiki, concept, image", "verif wiki answer": "wood(0.5437)", "verif concept answer": "concrete(0.6011)", "verif image answer": "concrete(0.6457)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362643.jpg"}, {"question": "what is the name of the law this driver is breaking", "gt answer": "distracted drive(1.00)<br/>phone(0.60)", "pred answer": "text", "question_id": 5295805, "best approach": "wiki", "verif answer": "phone", "anno approach": "wiki, concept, image", "verif wiki answer": "phone(0.7181)", "verif concept answer": "cell phone(0.6166)", "verif image answer": "fire(0.5975)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529580.jpg"}, {"question": "what time is it in this photo", "gt answer": "6:50(1.00)", "pred answer": "3:40", "question_id": 136035, "best approach": "wiki", "verif answer": "5:37", "anno approach": "wiki, concept, image", "verif wiki answer": "6:50(0.5145)", "verif concept answer": "5:37(0.6487)", "verif image answer": "even(0.5356)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013603.jpg"}, {"question": "what does those green cluster behind him inhale", "gt answer": "oxygen(1.00)<br/>tree(0.60)", "pred answer": "park", "question_id": 314435, "best approach": "concept", "verif answer": "tree", "anno approach": "wiki, concept, image", "verif wiki answer": "tree(0.6472)", "verif concept answer": "oxygen(0.6430)", "verif image answer": "aloe(0.6936)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000031443.jpg"}, {"question": "where is this", "gt answer": "florida(1.00)<br/>london(0.60)<br/>pennsylvania(0.60)<br/>new york(0.60)", "pred answer": "field", "question_id": 5050465, "best approach": "concept", "verif answer": "london", "anno approach": "wiki, concept, image", "verif wiki answer": "city(0.6603)", "verif concept answer": "florida(0.6354)", "verif image answer": "city(0.7149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505046.jpg"}, {"question": "why are fire hydrants yellow", "gt answer": "visibility(1.00)", "pred answer": "caution", "question_id": 920985, "best approach": "", "verif answer": "art", "anno approach": "wiki, concept, image", "verif wiki answer": "to be seen(0.6235)", "verif concept answer": "art(0.6254)", "verif image answer": "art(0.6397)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092098.jpg"}, {"question": "what type of seafood do you see in the picture", "gt answer": "shrimp(1.00)", "pred answer": "carrot", "question_id": 5077695, "best approach": "", "verif answer": "noodle", "anno approach": "wiki, concept, image", "verif wiki answer": "pasta(0.6577)", "verif concept answer": "pasta(0.7129)", "verif image answer": "pasta(0.6814)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507769.jpg"}, {"question": "what flag is on the bike", "gt answer": "british(1.00)<br/>britain(0.60)", "pred answer": "germany", "question_id": 1985475, "best approach": "concept", "verif answer": "england", "anno approach": "wiki, concept, image", "verif wiki answer": "england(0.6803)", "verif concept answer": "britain(0.6345)", "verif image answer": "india(0.6255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198547.jpg"}, {"question": "what is missing from this man 's body", "gt answer": "shirt(1.00)<br/>hair(0.60)", "pred answer": "foot", "question_id": 2694905, "best approach": "concept", "verif answer": "leg", "anno approach": "wiki, concept, image", "verif wiki answer": "leg(0.6504)", "verif concept answer": "shirt(0.5900)", "verif image answer": "hair(0.5525)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269490.jpg"}, {"question": "what airline is this", "gt answer": "lufthansa(1.00)", "pred answer": "hawaiian", "question_id": 4507635, "best approach": "wiki", "verif answer": "air canada", "anno approach": "wiki, concept, image", "verif wiki answer": "lufthansa(0.7278)", "verif concept answer": "air canada(0.7256)", "verif image answer": "air canada(0.6491)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450763.jpg"}, {"question": "", "gt answer": "1920's(0.60)<br/>1980(0.60)", "pred answer": "1800's", "question_id": 4905185, "best approach": "wiki, concept", "verif answer": "1970's", "anno approach": "wiki, concept, image", "verif wiki answer": "1980(0.6042)", "verif concept answer": "1980(0.5879)", "verif image answer": "1960's(0.5820)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490518.jpg"}, {"question": "what sort of wares is the merchant selling", "gt answer": "fruit(1.00)<br/>vegetable(1.00)<br/>live(0.60)", "pred answer": "tea", "question_id": 2741305, "best approach": "wiki, concept, image", "verif answer": "fruit", "anno approach": "wiki, concept, image", "verif wiki answer": "vegetable(0.6913)", "verif concept answer": "vegetable(0.6475)", "verif image answer": "vegetable(0.6957)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274130.jpg"}, {"question": "what country is this in", "gt answer": "us(1.00)<br/>usa(0.60)<br/>asia(0.60)<br/>america(0.60)", "pred answer": "china", "question_id": 4653535, "best approach": "image", "verif answer": "china", "anno approach": "wiki, concept, image", "verif wiki answer": "america(0.6819)", "verif concept answer": "china(0.6332)", "verif image answer": "us(0.6070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465353.jpg"}, {"question": "is this a government or private function", "gt answer": "government(1.00)<br/>private(1.00)", "pred answer": "public", "question_id": 355325, "best approach": "wiki", "verif answer": "public", "anno approach": "wiki, concept, image", "verif wiki answer": "private(0.7134)", "verif concept answer": "public(0.6276)", "verif image answer": "public(0.5621)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000035532.jpg"}, {"question": "if you had to guess the color of the skin of the woman would you say pinkish or blue", "gt answer": "pinkish(1.00)", "pred answer": "blue", "question_id": 452765, "best approach": "", "verif answer": "blue", "anno approach": "wiki, concept, image", "verif wiki answer": "blue(0.6469)", "verif concept answer": "cat(0.5905)", "verif image answer": "cat(0.5359)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045276.jpg"}, {"question": "which player of this sport has a bird last name", "gt answer": "tony hawk(1.00)<br/>hawk(1.00)", "pred answer": "skateboard", "question_id": 3229345, "best approach": "", "verif answer": "skateboard", "anno approach": "wiki, concept, image", "verif wiki answer": "shaun white(0.7263)", "verif concept answer": "shaun white(0.7153)", "verif image answer": "shaun white(0.6057)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322934.jpg"}, {"question": "what attire is this", "gt answer": "tuxedo(1.00)<br/>formal(0.60)", "pred answer": "suit", "question_id": 3788465, "best approach": "image", "verif answer": "suit", "anno approach": "wiki, concept, image", "verif wiki answer": "casual(0.5479)", "verif concept answer": "casual(0.6933)", "verif image answer": "tuxedo(0.5234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378846.jpg"}, {"question": "what pattern is on the bench", "gt answer": "heart(1.00)<br/>stone(0.60)", "pred answer": "floral", "question_id": 4503145, "best approach": "image", "verif answer": "victorian", "anno approach": "wiki, concept, image", "verif wiki answer": "brick(0.5942)", "verif concept answer": "brick(0.6271)", "verif image answer": "heart(0.7076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450314.jpg"}, {"question": "where are these mountains located", "gt answer": "colorado(1.00)<br/>alaska(1.00)<br/>west(0.60)", "pred answer": "mountain", "question_id": 3889605, "best approach": "wiki", "verif answer": "alaska", "anno approach": "wiki, concept, image", "verif wiki answer": "colorado(0.6959)", "verif concept answer": "west(0.5759)", "verif image answer": "west(0.7146)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388960.jpg"}, {"question": "what musical instrument is this man playing", "gt answer": "guitar(1.00)", "pred answer": "surf board", "question_id": 3907925, "best approach": "wiki, concept, image", "verif answer": "guitar", "anno approach": "wiki, concept, image", "verif wiki answer": "guitar(0.7234)", "verif concept answer": "guitar(0.7196)", "verif image answer": "guitar(0.7027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390792.jpg"}, {"question": "which item is associated with ireland", "gt answer": "alcohol(1.00)<br/>food(0.60)<br/>potato(1.00)", "pred answer": "onion", "question_id": 4282085, "best approach": "image", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "salad(0.7116)", "verif concept answer": "food(0.6906)", "verif image answer": "potato(0.6875)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428208.jpg"}, {"question": "what type of neckline is the yellow shirt", "gt answer": "scoop(1.00)<br/>low(0.60)", "pred answer": "button up", "question_id": 5200395, "best approach": "", "verif answer": "high", "anno approach": "wiki, concept, image", "verif wiki answer": "120v(0.6820)", "verif concept answer": "get lost(0.6425)", "verif image answer": "high(0.5364)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520039.jpg"}, {"question": "who 's the image on the tie", "gt answer": "bill clinton(1.00)<br/>van gogh(0.60)<br/>clinton(0.60)", "pred answer": "woman", "question_id": 2346375, "best approach": "wiki", "verif answer": "ben franklin", "anno approach": "wiki, concept, image", "verif wiki answer": "clinton(0.6264)", "verif concept answer": "samuel fox(0.6060)", "verif image answer": "ben franklin(0.6785)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000234637.jpg"}, {"question": "what 's in the white bag on the left", "gt answer": "flour(1.00)", "pred answer": "food", "question_id": 395485, "best approach": "", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "chocolate(0.6914)", "verif concept answer": "sugar(0.6370)", "verif image answer": "chocolate(0.6949)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039548.jpg"}, {"question": "what are of the store was this picture taken", "gt answer": "pharmacy(1.00)<br/>convenience store(0.60)<br/>toothbrush(0.60)", "pred answer": "target", "question_id": 885145, "best approach": "image", "verif answer": "grocery store", "anno approach": "wiki, concept, image", "verif wiki answer": "grocery store(0.6722)", "verif concept answer": "wooden(0.5963)", "verif image answer": "toothbrush(0.5181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088514.jpg"}, {"question": "what type of stone was used in the building", "gt answer": "limestone(1.00)<br/>cobblestone(0.60)<br/>concrete(0.60)", "pred answer": "brick", "question_id": 2466395, "best approach": "image", "verif answer": "brick", "anno approach": "wiki, concept, image", "verif wiki answer": "brick(0.6779)", "verif concept answer": "brick(0.6871)", "verif image answer": "concrete(0.6911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246639.jpg"}, {"question": "a typical recipe yields how many of the items shown above", "gt answer": "12(1.00)<br/>10(0.60)", "pred answer": "5", "question_id": 2187175, "best approach": "concept, image", "verif answer": "5", "anno approach": "wiki, concept, image", "verif wiki answer": "10(0.6562)", "verif concept answer": "12(0.6015)", "verif image answer": "12(0.5779)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218717.jpg"}, {"question": "who makes these trucks", "gt answer": "volkswagen(1.00)", "pred answer": "dodge", "question_id": 2325515, "best approach": "wiki, image", "verif answer": "volkswagen", "anno approach": "wiki, concept, image", "verif wiki answer": "volkswagen(0.6379)", "verif concept answer": "kenmore(0.7048)", "verif image answer": "volkswagen(0.7169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232551.jpg"}, {"question": "how many of this type of animal typically live together", "gt answer": "6(1.00)<br/>40(0.60)<br/>8(0.60)", "pred answer": "thousand", "question_id": 4315695, "best approach": "concept, image", "verif answer": "thousand", "anno approach": "wiki, concept, image", "verif wiki answer": "5(0.5899)", "verif concept answer": "6(0.6319)", "verif image answer": "6(0.6848)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431569.jpg"}, {"question": "where are these people", "gt answer": "library(1.00)<br/>student(0.60)", "pred answer": "school", "question_id": 3315445, "best approach": "concept", "verif answer": "library", "anno approach": "wiki, concept, image", "verif wiki answer": "bookstore(0.7200)", "verif concept answer": "student(0.6163)", "verif image answer": "bookstore(0.6270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331544.jpg"}, {"question": "who is going faster", "gt answer": "scooter(1.00)<br/>bike(0.60)", "pred answer": "motorcycle", "question_id": 3728045, "best approach": "wiki, concept", "verif answer": "motorcycle", "anno approach": "wiki, concept, image", "verif wiki answer": "scooter(0.6731)", "verif concept answer": "scooter(0.6520)", "verif image answer": "motorcycle(0.6918)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372804.jpg"}, {"question": "what kind of pampering is this", "gt answer": "haircut(1.00)", "pred answer": "sew", "question_id": 2340885, "best approach": "", "verif answer": "haircut", "anno approach": "wiki, concept, image", "verif wiki answer": "toothbrush(0.7061)", "verif concept answer": "toothbrush(0.7122)", "verif image answer": "toothbrush(0.6801)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000234088.jpg"}, {"question": "what is the vitamin that can be got in the upper fruit", "gt answer": "vitamin c(1.00)<br/>(0.60)<br/>c(0.60)", "pred answer": "potassium", "question_id": 1050665, "best approach": "", "verif answer": "vitamin", "anno approach": "wiki, concept, image", "verif wiki answer": "d(0.6228)", "verif concept answer": "vitamin(0.6324)", "verif image answer": "d(0.6318)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105066.jpg"}, {"question": "what are the bananas hanging on", "gt answer": "hook(1.00)", "pred answer": "banana", "question_id": 3896155, "best approach": "wiki", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "hook(0.6015)", "verif concept answer": "grocery(0.6577)", "verif image answer": "orange(0.6235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389615.jpg"}, {"question": "what do these birds produce", "gt answer": "egg(1.00)", "pred answer": "pigeon", "question_id": 3166995, "best approach": "wiki, concept", "verif answer": "chicken", "anno approach": "wiki, concept, image", "verif wiki answer": "egg(0.7009)", "verif concept answer": "egg(0.6830)", "verif image answer": "chicken(0.6779)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316699.jpg"}, {"question": "which age group of childrens love to play with this toy", "gt answer": "toddler(1.00)<br/>3 years(0.60)", "pred answer": "baby", "question_id": 3228075, "best approach": "", "verif answer": "kid", "anno approach": "wiki, concept, image", "verif wiki answer": "early(0.6824)", "verif concept answer": "kid(0.6595)", "verif image answer": "early(0.6374)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322807.jpg"}, {"question": "what two animals are pictured", "gt answer": "giraffe and ostrich(1.00)", "pred answer": "giraffe", "question_id": 4335685, "best approach": "wiki", "verif answer": "zebra", "anno approach": "wiki, concept, image", "verif wiki answer": "giraffe and ostrich(0.7040)", "verif concept answer": "herbivore(0.7016)", "verif image answer": "herbivore(0.7026)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433568.jpg"}, {"question": "how many compartments are in this picture", "gt answer": "8(1.00)", "pred answer": "5", "question_id": 2366295, "best approach": "", "verif answer": "12", "anno approach": "wiki, concept, image", "verif wiki answer": "12(0.7019)", "verif concept answer": "12(0.6931)", "verif image answer": "12(0.6622)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236629.jpg"}, {"question": "in france what would this food be called", "gt answer": "gateau(1.00)<br/>dessert(0.60)", "pred answer": "cake", "question_id": 1256395, "best approach": "wiki, concept, image", "verif answer": "dessert", "anno approach": "wiki, concept, image", "verif wiki answer": "dessert(0.7038)", "verif concept answer": "dessert(0.6644)", "verif image answer": "dessert(0.6309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125639.jpg"}, {"question": "what is the cage where the other players are sitting behind called", "gt answer": "dugout(1.00)<br/>bat(0.60)", "pred answer": "bat cage", "question_id": 4244045, "best approach": "wiki, concept, image", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "dugout(0.7267)", "verif concept answer": "dugout(0.7282)", "verif image answer": "dugout(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424404.jpg"}, {"question": "what is the name of the aeroline", "gt answer": "airbus(1.00)<br/>4300(0.60)", "pred answer": "jet", "question_id": 2742485, "best approach": "wiki, concept", "verif answer": "jet", "anno approach": "wiki, concept, image", "verif wiki answer": "airbus(0.7245)", "verif concept answer": "airbus(0.6225)", "verif image answer": "4300(0.5985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274248.jpg"}, {"question": "what do couples use the top layer of this for traditionally", "gt answer": "anniversary(1.00)", "pred answer": "birthday", "question_id": 3455785, "best approach": "", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "birthday(0.6376)", "verif concept answer": "birthday(0.6537)", "verif image answer": "party(0.5831)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345578.jpg"}, {"question": "what is the temperature like", "gt answer": "cool(1.00)<br/>cold(0.60)<br/>warm(0.60)", "pred answer": "hot", "question_id": 2130365, "best approach": "wiki, concept, image", "verif answer": "warm", "anno approach": "wiki, concept, image", "verif wiki answer": "warm(0.6383)", "verif concept answer": "warm(0.6257)", "verif image answer": "cold(0.6138)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000213036.jpg"}, {"question": "what religious group uses this mode of transportation", "gt answer": "amish(1.00)", "pred answer": "catholic", "question_id": 2221805, "best approach": "", "verif answer": "catholic", "anno approach": "wiki, concept, image", "verif wiki answer": "catholic(0.7244)", "verif concept answer": "catholic(0.7096)", "verif image answer": "catholic(0.6675)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222180.jpg"}, {"question": "what type of topping is on top of the orange balls", "gt answer": "coconut(1.00)", "pred answer": "ketchup", "question_id": 36715, "best approach": "wiki", "verif answer": "coconut", "anno approach": "wiki, concept, image", "verif wiki answer": "coconut(0.6773)", "verif concept answer": "sugar(0.6846)", "verif image answer": "pine(0.6125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003671.jpg"}, {"question": "what type of gasoline does this vehicle use", "gt answer": "unleaded(1.00)<br/>diesel(0.60)<br/>regular(0.60)", "pred answer": "gasoline", "question_id": 1393895, "best approach": "image", "verif answer": "gasoline", "anno approach": "wiki, concept, image", "verif wiki answer": "regular(0.6995)", "verif concept answer": "regular(0.6718)", "verif image answer": "unleaded(0.5811)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139389.jpg"}, {"question": "what is the name of the flotation device this man is holding", "gt answer": "boogie board(1.00)<br/>board(0.60)", "pred answer": "surf board", "question_id": 1075275, "best approach": "image", "verif answer": "surf", "anno approach": "wiki, concept, image", "verif wiki answer": "surf(0.7152)", "verif concept answer": "surf(0.6589)", "verif image answer": "board(0.6945)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000107527.jpg"}, {"question": "what could you enter through", "gt answer": "door(1.00)", "pred answer": "house", "question_id": 1112805, "best approach": "", "verif answer": "door", "anno approach": "wiki, concept, image", "verif wiki answer": "gate(0.7247)", "verif concept answer": "window(0.7153)", "verif image answer": "stall(0.7045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111280.jpg"}, {"question": "what breed of dog is this", "gt answer": "collie(1.00)<br/>border collie(0.60)<br/>retriever(0.60)<br/>mixed(0.60)", "pred answer": "terrier", "question_id": 5454285, "best approach": "concept", "verif answer": "collie", "anno approach": "wiki, concept, image", "verif wiki answer": "mixed(0.6918)", "verif concept answer": "collie(0.6746)", "verif image answer": "mixed(0.6666)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545428.jpg"}, {"question": "what kind of oil is typically found in the orange food depicted", "gt answer": "fish(1.00)<br/>omega 3(1.00)", "pred answer": "olive", "question_id": 4089465, "best approach": "wiki, image", "verif answer": "fish", "anno approach": "wiki, concept, image", "verif wiki answer": "fish(0.6148)", "verif concept answer": "salmon(0.6648)", "verif image answer": "omega 3(0.6500)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408946.jpg"}, {"question": "what speed should the ceiling fan run in this room", "gt answer": "slow(1.00)<br/>low(0.60)", "pred answer": "120 mph", "question_id": 4365195, "best approach": "image", "verif answer": "25 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "25 mph(0.5686)", "verif concept answer": "25 mph(0.5246)", "verif image answer": "low(0.5938)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436519.jpg"}, {"question": "what country will you find this market", "gt answer": "brazil(1.00)<br/>thailand(0.60)<br/>nigeria(0.60)", "pred answer": "vietnam", "question_id": 452305, "best approach": "wiki, concept, image", "verif answer": "india", "anno approach": "wiki, concept, image", "verif wiki answer": "nigeria(0.6916)", "verif concept answer": "nigeria(0.6841)", "verif image answer": "thailand(0.6695)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045230.jpg"}, {"question": "what type of grass is best for their growth", "gt answer": "green grass(1.00)<br/>bent(0.60)<br/>hay(0.60)<br/>green(0.60)", "pred answer": "turf", "question_id": 2735485, "best approach": "wiki, concept, image", "verif answer": "hay", "anno approach": "wiki, concept, image", "verif wiki answer": "green grass(0.6063)", "verif concept answer": "green grass(0.6530)", "verif image answer": "green grass(0.7083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273548.jpg"}, {"question": "was the white pot hand made or factory made", "gt answer": "handmade(1.00)<br/>hand(0.60)<br/>factory(0.60)", "pred answer": "manmade", "question_id": 2446665, "best approach": "wiki", "verif answer": "manmade", "anno approach": "wiki, concept, image", "verif wiki answer": "hand(0.6097)", "verif concept answer": "manmade(0.6989)", "verif image answer": "home(0.6856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244666.jpg"}, {"question": "what is this event", "gt answer": "lecture(1.00)<br/>snow(0.60)", "pred answer": "work", "question_id": 5059495, "best approach": "image", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "work(0.5331)", "verif concept answer": "work(0.6002)", "verif image answer": "snow(0.6650)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505949.jpg"}, {"question": "can you name a sport this person could be a part of", "gt answer": "race(1.00)<br/>motocross(0.60)<br/>dirt bike(0.60)", "pred answer": "motorcross", "question_id": 1537305, "best approach": "image", "verif answer": "motorcross", "anno approach": "wiki, concept, image", "verif wiki answer": "motorcross(0.7157)", "verif concept answer": "motorcross(0.7070)", "verif image answer": "motocross(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153730.jpg"}, {"question": "which breed of dog is still the most popular", "gt answer": "labrador(1.00)<br/>golden retriever(0.60)", "pred answer": "mutt", "question_id": 3052475, "best approach": "wiki", "verif answer": "boxer", "anno approach": "wiki, concept, image", "verif wiki answer": "labrador(0.5810)", "verif concept answer": "boxer(0.5522)", "verif image answer": "lab(0.5763)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305247.jpg"}, {"question": "who is the manufactuer of the black keyboard in front of the three monitos", "gt answer": "logitech(1.00)<br/>acer(0.60)<br/>hp(0.60)<br/>samsung(0.60)", "pred answer": "steve job", "question_id": 1362305, "best approach": "image", "verif answer": "dell", "anno approach": "wiki, concept, image", "verif wiki answer": "dell(0.6344)", "verif concept answer": "hp(0.6133)", "verif image answer": "logitech(0.5500)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136230.jpg"}, {"question": "is this photo under or over exposed", "gt answer": "under(1.00)", "pred answer": "above", "question_id": 1082015, "best approach": "image", "verif answer": "messy", "anno approach": "wiki, concept, image", "verif wiki answer": "messy(0.7181)", "verif concept answer": "messy(0.7299)", "verif image answer": "under(0.6219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108201.jpg"}, {"question": "where are these signs typically found", "gt answer": "school(1.00)", "pred answer": "park", "question_id": 4283795, "best approach": "concept, image", "verif answer": "school", "anno approach": "wiki, concept, image", "verif wiki answer": "college(0.6771)", "verif concept answer": "school(0.6609)", "verif image answer": "school(0.6893)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428379.jpg"}, {"question": "what was the use of the device beside the food", "gt answer": "tablet(1.00)", "pred answer": "cut", "question_id": 4676745, "best approach": "wiki, image", "verif answer": "tablet", "anno approach": "wiki, concept, image", "verif wiki answer": "tablet(0.7150)", "verif concept answer": "laptop(0.6649)", "verif image answer": "tablet(0.6949)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467674.jpg"}, {"question": "what company makes this type of appliance", "gt answer": "frigidaire(1.00)<br/>samsung(0.60)<br/>ge(0.60)", "pred answer": "refrigerator", "question_id": 3130615, "best approach": "wiki, concept", "verif answer": "ge", "anno approach": "wiki, concept, image", "verif wiki answer": "frigidaire(0.6634)", "verif concept answer": "frigidaire(0.6077)", "verif image answer": "samsung(0.6397)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313061.jpg"}, {"question": "what kind of contest is this", "gt answer": "eat(1.00)<br/>donut(0.60)", "pred answer": "food", "question_id": 3235885, "best approach": "", "verif answer": "dinner", "anno approach": "wiki, concept, image", "verif wiki answer": "dinner(0.6583)", "verif concept answer": "dinner(0.6649)", "verif image answer": "dinner(0.5657)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323588.jpg"}, {"question": "what kind of bug are these", "gt answer": "dragon fly(0.60)<br/>butterfly(1.00)", "pred answer": "bee", "question_id": 993885, "best approach": "wiki, concept", "verif answer": "bee", "anno approach": "wiki, concept, image", "verif wiki answer": "dragon fly(0.6594)", "verif concept answer": "dragon fly(0.6786)", "verif image answer": "bee(0.5605)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099388.jpg"}, {"question": "what are these people doing as they sit on a couch", "gt answer": "watch tv(1.00)<br/>play(0.60)<br/>video game(0.60)<br/>talk(0.60)", "pred answer": "sit", "question_id": 3962665, "best approach": "concept, image", "verif answer": "watch tv", "anno approach": "wiki, concept, image", "verif wiki answer": "play(0.6795)", "verif concept answer": "watch tv(0.6029)", "verif image answer": "watch tv(0.6895)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396266.jpg"}, {"question": "what is the name for her headdress", "gt answer": "hijab(1.00)", "pred answer": "bonnet", "question_id": 3781795, "best approach": "image", "verif answer": "fedora", "anno approach": "wiki, concept, image", "verif wiki answer": "fedora(0.7266)", "verif concept answer": "fedora(0.7232)", "verif image answer": "hijab(0.5724)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378179.jpg"}, {"question": "is this a school bus or a passenger bus", "gt answer": "passenger bus(1.00)<br/>passenger(0.60)", "pred answer": "double decker", "question_id": 1952945, "best approach": "concept", "verif answer": "tour bus", "anno approach": "wiki, concept, image", "verif wiki answer": "tourist(0.7141)", "verif concept answer": "passenger(0.6048)", "verif image answer": "tour bus(0.5910)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195294.jpg"}, {"question": "what type of spelling is being used for the word under candy", "gt answer": "british(1.00)<br/>english(0.60)", "pred answer": "ketchup", "question_id": 5070285, "best approach": "wiki, image", "verif answer": "english", "anno approach": "wiki, concept, image", "verif wiki answer": "english(0.6542)", "verif concept answer": "spanish(0.6410)", "verif image answer": "english(0.7030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507028.jpg"}, {"question": "how long does the big white electronic item shown normally last before needing to be replaced", "gt answer": "5 years(1.00)<br/>4 years(0.60)", "pred answer": "2 hours", "question_id": 5066055, "best approach": "", "verif answer": "4 years", "anno approach": "wiki, concept, image", "verif wiki answer": "2 years(0.6519)", "verif concept answer": "2 years(0.6414)", "verif image answer": "3 years(0.6732)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506605.jpg"}, {"question": "the animal on the bottom of the photo is commonly referred to as man 's best what", "gt answer": "friend(1.00)<br/>cow(0.60)", "pred answer": "beagle", "question_id": 2113405, "best approach": "image", "verif answer": "bull", "anno approach": "wiki, concept, image", "verif wiki answer": "bull(0.7024)", "verif concept answer": "cow(0.6863)", "verif image answer": "friend(0.7200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000211340.jpg"}, {"question": "what kind have cake is that", "gt answer": "cheesecake(1.00)<br/>chocolate(0.60)<br/>icecream(0.60)<br/>pie(0.60)", "pred answer": "red velvet", "question_id": 4045785, "best approach": "wiki, concept, image", "verif answer": "cheesecake", "anno approach": "wiki, concept, image", "verif wiki answer": "cheesecake(0.6901)", "verif concept answer": "cheesecake(0.5912)", "verif image answer": "cheesecake(0.5869)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404578.jpg"}, {"question": "what does this gesture mean", "gt answer": "good game(1.00)", "pred answer": "serve", "question_id": 1159175, "best approach": "image", "verif answer": "serve", "anno approach": "wiki, concept, image", "verif wiki answer": "serve(0.6783)", "verif concept answer": "shake hand(0.6689)", "verif image answer": "good game(0.7064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115917.jpg"}, {"question": "what buttons are the cats paws covering", "gt answer": "number(1.00)<br/>remote(0.60)", "pred answer": "mouse", "question_id": 3829265, "best approach": "", "verif answer": "cd", "anno approach": "wiki, concept, image", "verif wiki answer": "cd(0.7198)", "verif concept answer": "best buy(0.6035)", "verif image answer": "wool(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382926.jpg"}, {"question": "", "gt answer": "drop(0.60)", "pred answer": "tile", "question_id": 3499475, "best approach": "", "verif answer": "arch", "anno approach": "wiki, concept, image", "verif wiki answer": "al fresco(0.5465)", "verif concept answer": "al fresco(0.6074)", "verif image answer": "al fresco(0.5968)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000349947.jpg"}, {"question": "what is the power consumption of that laptop", "gt answer": "battery(1.00)", "pred answer": "intel", "question_id": 5179985, "best approach": "", "verif answer": "battery", "anno approach": "wiki, concept, image", "verif wiki answer": "electricity(0.7010)", "verif concept answer": "electricity(0.6362)", "verif image answer": "dc(0.5829)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517998.jpg"}, {"question": "what is this building called", "gt answer": "courthouse(1.00)<br/>court(0.60)", "pred answer": "church", "question_id": 5433715, "best approach": "image", "verif answer": "church", "anno approach": "wiki, concept, image", "verif wiki answer": "church(0.7091)", "verif concept answer": "church(0.6492)", "verif image answer": "court(0.5720)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543371.jpg"}, {"question": "they make is a lot in italy what do you call it", "gt answer": "pizza(1.00)", "pred answer": "cheese", "question_id": 2558985, "best approach": "", "verif answer": "pizza", "anno approach": "wiki, concept, image", "verif wiki answer": "nacho(0.6890)", "verif concept answer": "nacho(0.6077)", "verif image answer": "italian(0.5544)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255898.jpg"}, {"question": "why is the boat floating above water", "gt answer": "buoyancy(1.00)", "pred answer": "boat", "question_id": 4800055, "best approach": "wiki", "verif answer": "canoe", "anno approach": "wiki, concept, image", "verif wiki answer": "buoyancy(0.6517)", "verif concept answer": "15 feet(0.6558)", "verif image answer": "drink(0.6542)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480005.jpg"}, {"question": "what is this cutting instrument used for", "gt answer": "fabric(1.00)<br/>scissor(0.60)<br/>sew(0.60)", "pred answer": "cut", "question_id": 2007945, "best approach": "concept, image", "verif answer": "cut", "anno approach": "wiki, concept, image", "verif wiki answer": "scissor(0.6631)", "verif concept answer": "fabric(0.6802)", "verif image answer": "fabric(0.6935)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200794.jpg"}, {"question": "does this animal normally live in a hot or cold climate", "gt answer": "hot(1.00)", "pred answer": "cold", "question_id": 5090955, "best approach": "", "verif answer": "cold", "anno approach": "wiki, concept, image", "verif wiki answer": "warm(0.6874)", "verif concept answer": "warm(0.6870)", "verif image answer": "cold(0.6393)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509095.jpg"}, {"question": "what event is this", "gt answer": "race(1.00)<br/>car show(0.60)", "pred answer": "carnival", "question_id": 5669385, "best approach": "wiki", "verif answer": "car show", "anno approach": "wiki, concept, image", "verif wiki answer": "car show(0.6580)", "verif concept answer": "car(0.6422)", "verif image answer": "ride(0.6907)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566938.jpg"}, {"question": "where can you buy a sofa like this", "gt answer": "ikea(1.00)", "pred answer": "walmart", "question_id": 2762085, "best approach": "concept, image", "verif answer": "furniture store", "anno approach": "wiki, concept, image", "verif wiki answer": "furniture store(0.6873)", "verif concept answer": "ikea(0.6626)", "verif image answer": "ikea(0.6926)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276208.jpg"}, {"question": "what happened to the train", "gt answer": "derailed(1.00)<br/>stopped(0.60)", "pred answer": "broken", "question_id": 249805, "best approach": "wiki, concept, image", "verif answer": "crash", "anno approach": "wiki, concept, image", "verif wiki answer": "stopped(0.6028)", "verif concept answer": "stopped(0.6628)", "verif image answer": "stopped(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024980.jpg"}, {"question": "how much water do this animal consume in a day", "gt answer": "5 gallons(1.00)<br/>gallon(0.60)", "pred answer": "lot", "question_id": 4154925, "best approach": "", "verif answer": "lot", "anno approach": "wiki, concept, image", "verif wiki answer": "10 gallons(0.6560)", "verif concept answer": "lot(0.6705)", "verif image answer": "salt(0.6496)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415492.jpg"}, {"question": "which brothers invented this machine", "gt answer": "wright(1.00)<br/>wright brother(1.00)", "pred answer": "legaignoux brother", "question_id": 1457485, "best approach": "wiki, concept", "verif answer": "wright", "anno approach": "wiki, concept, image", "verif wiki answer": "wright(0.7122)", "verif concept answer": "wright brother(0.5570)", "verif image answer": "american airline(0.5277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145748.jpg"}, {"question": "what kinds of boats are these", "gt answer": "yacht(1.00)<br/>passenger(0.60)", "pred answer": "fish boat", "question_id": 1941596, "best approach": "wiki", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "passenger(0.6820)", "verif concept answer": "speedboat(0.6935)", "verif image answer": "speedboat(0.6992)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194159.jpg"}, {"question": "what model of truck is this", "gt answer": "chevy(1.00)<br/>toyota(0.60)<br/>pickup(0.60)", "pred answer": "dodge", "question_id": 3846985, "best approach": "wiki", "verif answer": "dodge", "anno approach": "wiki, concept, image", "verif wiki answer": "pickup(0.7160)", "verif concept answer": "ford(0.6947)", "verif image answer": "dodge(0.7068)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384698.jpg"}, {"question": "when were these planes in service", "gt answer": "ww2(1.00)<br/>2000(0.60)<br/>1940(0.60)<br/>airshow(0.60)", "pred answer": "1903", "question_id": 5296475, "best approach": "concept, image", "verif answer": "1960", "anno approach": "wiki, concept, image", "verif wiki answer": "2000(0.7210)", "verif concept answer": "ww2(0.6015)", "verif image answer": "ww2(0.5367)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529647.jpg"}, {"question": "what powerful objects are used to help this vehicle move", "gt answer": "engine(1.00)", "pred answer": "gasoline", "question_id": 2532855, "best approach": "concept, image", "verif answer": "fuel", "anno approach": "wiki, concept, image", "verif wiki answer": "lift(0.6604)", "verif concept answer": "engine(0.6766)", "verif image answer": "engine(0.6221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253285.jpg"}, {"question": "why would peanuts be relevant to this picture", "gt answer": "elephant(1.00)", "pred answer": "tusk", "question_id": 3048335, "best approach": "wiki, image", "verif answer": "elephant", "anno approach": "wiki, concept, image", "verif wiki answer": "elephant(0.6017)", "verif concept answer": "brain(0.5638)", "verif image answer": "elephant(0.6593)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304833.jpg"}, {"question": "what is the animal 's collar for", "gt answer": "identification(1.00)<br/>name(0.60)<br/>cat(0.60)", "pred answer": "tie", "question_id": 4165595, "best approach": "wiki, concept, image", "verif answer": "identification", "anno approach": "wiki, concept, image", "verif wiki answer": "cat(0.6840)", "verif concept answer": "name(0.6121)", "verif image answer": "cat(0.5829)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416559.jpg"}, {"question": "what does this man have on his lip", "gt answer": "mustache(1.00)", "pred answer": "beard", "question_id": 1802675, "best approach": "", "verif answer": "goatee", "anno approach": "wiki, concept, image", "verif wiki answer": "beard(0.5478)", "verif concept answer": "goatee(0.6671)", "verif image answer": "goatee(0.6824)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180267.jpg"}, {"question": "which famous disney host animal also wears gloves not unlike these shown here", "gt answer": "mickey mouse(1.00)", "pred answer": "mary poppins", "question_id": 1056055, "best approach": "wiki, concept, image", "verif answer": "mickey mouse", "anno approach": "wiki, concept, image", "verif wiki answer": "mickey mouse(0.7293)", "verif concept answer": "mickey mouse(0.6954)", "verif image answer": "mickey mouse(0.6929)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105605.jpg"}, {"question": "what kind of bed is pictured", "gt answer": "4 poster(1.00)<br/>canopy(0.60)", "pred answer": "queen", "question_id": 4765855, "best approach": "concept", "verif answer": "queen", "anno approach": "wiki, concept, image", "verif wiki answer": "queen(0.6792)", "verif concept answer": "canopy(0.6102)", "verif image answer": "king(0.6876)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476585.jpg"}, {"question": "what brand of shoes is he wearing", "gt answer": "van(1.00)", "pred answer": "converse", "question_id": 130825, "best approach": "image", "verif answer": "converse", "anno approach": "wiki, concept, image", "verif wiki answer": "converse(0.7244)", "verif concept answer": "converse(0.6319)", "verif image answer": "van(0.6869)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013082.jpg"}, {"question": "what is the material the couch is made of in the photo", "gt answer": "leather(1.00)", "pred answer": "microfiber", "question_id": 3937195, "best approach": "", "verif answer": "leather", "anno approach": "wiki, concept, image", "verif wiki answer": "cotton(0.7137)", "verif concept answer": "cotton(0.6208)", "verif image answer": "fabric(0.7189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393719.jpg"}, {"question": "what kind of drink can you get here", "gt answer": "alcoholic(1.00)<br/>alcohol(0.60)<br/>coffee(0.60)<br/>cocktail(0.60)", "pred answer": "beer", "question_id": 4025635, "best approach": "wiki, concept, image", "verif answer": "alcohol", "anno approach": "wiki, concept, image", "verif wiki answer": "cocktail(0.7051)", "verif concept answer": "cocktail(0.6727)", "verif image answer": "alcohol(0.6810)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402563.jpg"}, {"question": "what does the item in this photo do", "gt answer": "fly(1.00)", "pred answer": "land", "question_id": 1777555, "best approach": "image", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "airplane(0.7039)", "verif concept answer": "takeoff(0.6783)", "verif image answer": "fly(0.6050)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177755.jpg"}, {"question": "what kind of structure is that", "gt answer": "tent(1.00)", "pred answer": "house", "question_id": 3364895, "best approach": "wiki", "verif answer": "tent", "anno approach": "wiki, concept, image", "verif wiki answer": "tent(0.7112)", "verif concept answer": "chair(0.6900)", "verif image answer": "outside(0.6840)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000336489.jpg"}, {"question": "is this animal full grown or a younger animal", "gt answer": "younger(1.00)<br/>young(0.60)", "pred answer": "baby", "question_id": 5418805, "best approach": "concept, image", "verif answer": "younger", "anno approach": "wiki, concept, image", "verif wiki answer": "old(0.5485)", "verif concept answer": "younger(0.6430)", "verif image answer": "younger(0.5894)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541880.jpg"}, {"question": "who invented the device shown in the right side of the image", "gt answer": "alexander graham bell(1.00)<br/>bill gate(0.60)", "pred answer": "steve job", "question_id": 964975, "best approach": "wiki, image", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "alexander graham bell(0.6733)", "verif concept answer": "bill gate(0.6554)", "verif image answer": "alexander graham bell(0.7021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096497.jpg"}, {"question": "is this a girls or boy room", "gt answer": "boy(1.00)", "pred answer": "girl", "question_id": 1412655, "best approach": "image", "verif answer": "girl", "anno approach": "wiki, concept, image", "verif wiki answer": "girl(0.7244)", "verif concept answer": "girl(0.7215)", "verif image answer": "boy(0.5751)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000141265.jpg"}, {"question": "what kind of flowers are in the background", "gt answer": "tulip(1.00)<br/>daffodil(1.00)", "pred answer": "daisy", "question_id": 5693495, "best approach": "", "verif answer": "daisy", "anno approach": "wiki, concept, image", "verif wiki answer": "daisy(0.6765)", "verif concept answer": "rose(0.6178)", "verif image answer": "daisy(0.6662)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569349.jpg"}, {"question": "what are the round black objects next to the computer used for", "gt answer": "hear(1.00)<br/>headphone(0.60)<br/>listen(0.60)<br/>ear(0.60)", "pred answer": "computer", "question_id": 1888265, "best approach": "wiki, concept, image", "verif answer": "headphone", "anno approach": "wiki, concept, image", "verif wiki answer": "listen(0.7186)", "verif concept answer": "listen(0.6188)", "verif image answer": "headphone(0.7002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188826.jpg"}, {"question": "what part of the body is used in the picture", "gt answer": "butt(1.00)<br/>hand(1.00)<br/>neck(0.60)", "pred answer": "shower", "question_id": 2103225, "best approach": "wiki, image", "verif answer": "toilet", "anno approach": "wiki, concept, image", "verif wiki answer": "neck(0.6779)", "verif concept answer": "toilet(0.6536)", "verif image answer": "neck(0.6643)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210322.jpg"}, {"question": "what type of soda can is on the table", "gt answer": "pepsi(1.00)", "pred answer": "coke", "question_id": 2968435, "best approach": "", "verif answer": "coke", "anno approach": "wiki, concept, image", "verif wiki answer": "coca cola(0.7216)", "verif concept answer": "coca cola(0.6120)", "verif image answer": "aloe(0.5903)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296843.jpg"}, {"question": "what vitamin is associated with the vegetable found in this picture", "gt answer": "vitamin k(1.00)<br/>calcium(0.60)<br/>(0.60)<br/>potassium(0.60)", "pred answer": "vitamin", "question_id": 10365, "best approach": "wiki, concept, image", "verif answer": "vitamin", "anno approach": "wiki, concept, image", "verif wiki answer": "(0.6734)", "verif concept answer": "potassium(0.6447)", "verif image answer": "potassium(0.6259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001036.jpg"}, {"question": "what movie does the poster in the back come from", "gt answer": "star war(1.00)<br/>0(0.60)", "pred answer": "wizard of oz", "question_id": 5531765, "best approach": "", "verif answer": "forrest gump", "anno approach": "wiki, concept, image", "verif wiki answer": "forrest gump(0.7290)", "verif concept answer": "forrest gump(0.7174)", "verif image answer": "forrest gump(0.5333)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553176.jpg"}, {"question": "what is the weather forecasting on this day", "gt answer": "overcast(1.00)<br/>rain(0.60)", "pred answer": "rainy", "question_id": 102225, "best approach": "wiki, concept, image", "verif answer": "rainy", "anno approach": "wiki, concept, image", "verif wiki answer": "overcast(0.7111)", "verif concept answer": "overcast(0.6811)", "verif image answer": "overcast(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000010222.jpg"}, {"question": "what food in this picture is not edible by a vegetarian", "gt answer": "chicken(1.00)<br/>steak(0.60)", "pred answer": "potato", "question_id": 2875855, "best approach": "image", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "beef(0.6558)", "verif concept answer": "beef(0.6272)", "verif image answer": "chicken(0.7237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287585.jpg"}, {"question": "what happened to his wrist", "gt answer": "sprained it(1.00)", "pred answer": "broken", "question_id": 4180575, "best approach": "", "verif answer": "serve", "anno approach": "wiki, concept, image", "verif wiki answer": "sweat(0.6211)", "verif concept answer": "sweat(0.7254)", "verif image answer": "metal(0.7208)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000418057.jpg"}, {"question": "this animal has what kind of feet", "gt answer": "webbed(1.00)", "pred answer": "pelican", "question_id": 4315985, "best approach": "", "verif answer": "duck", "anno approach": "wiki, concept, image", "verif wiki answer": "duck(0.6389)", "verif concept answer": "duck(0.6473)", "verif image answer": "duck(0.6163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431598.jpg"}, {"question": "name the type of paper material used to print this photo", "gt answer": "photo paper(1.00)<br/>paper(0.60)", "pred answer": "paint", "question_id": 4220645, "best approach": "concept", "verif answer": "plastic", "anno approach": "wiki, concept, image", "verif wiki answer": "wicker(0.6987)", "verif concept answer": "photo paper(0.6646)", "verif image answer": "paper(0.6712)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422064.jpg"}, {"question": "who normally uses these items to make men 's clothes", "gt answer": "tailor(1.00)", "pred answer": "art", "question_id": 2445825, "best approach": "", "verif answer": "sew", "anno approach": "wiki, concept, image", "verif wiki answer": "sew(0.5838)", "verif concept answer": "adult(0.6184)", "verif image answer": "adult(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244582.jpg"}, {"question": "what type of bird is shown in the picture", "gt answer": "robin(1.00)", "pred answer": "sparrow", "question_id": 4614985, "best approach": "", "verif answer": "sparrow", "anno approach": "wiki, concept, image", "verif wiki answer": "sparrow(0.6818)", "verif concept answer": "sparrow(0.6506)", "verif image answer": "hummingbird(0.5688)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461498.jpg"}, {"question": "what is this guy pretending to be", "gt answer": "pirate(1.00)", "pred answer": "clown", "question_id": 5366075, "best approach": "wiki, concept", "verif answer": "pirate", "anno approach": "wiki, concept, image", "verif wiki answer": "pirate(0.6135)", "verif concept answer": "pirate(0.6311)", "verif image answer": "captain morgan(0.5508)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536607.jpg"}, {"question": "what kind of covering is on this bed", "gt answer": "comforter(1.00)<br/>blanket(0.60)", "pred answer": "quilt", "question_id": 3139145, "best approach": "image", "verif answer": "quilt", "anno approach": "wiki, concept, image", "verif wiki answer": "quilt(0.7243)", "verif concept answer": "quilt(0.7198)", "verif image answer": "blanket(0.7242)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313914.jpg"}, {"question": "are the cats indoors our outdoors", "gt answer": "indoor(1.00)", "pred answer": "outdoor", "question_id": 123075, "best approach": "wiki, image", "verif answer": "outdoor", "anno approach": "wiki, concept, image", "verif wiki answer": "indoor(0.5987)", "verif concept answer": "outdoor(0.7046)", "verif image answer": "indoor(0.5546)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012307.jpg"}, {"question": "who makes this product", "gt answer": "citikitty(1.00)", "pred answer": "factory", "question_id": 5763175, "best approach": "image", "verif answer": "coca cola", "anno approach": "wiki, concept, image", "verif wiki answer": "coca cola(0.7050)", "verif concept answer": "coca cola(0.6931)", "verif image answer": "citikitty(0.5228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000576317.jpg"}, {"question": "what are the two gentleman at the forefront of the picture doing", "gt answer": "shake hand(1.00)", "pred answer": "talk", "question_id": 5795335, "best approach": "concept", "verif answer": "talk", "anno approach": "wiki, concept, image", "verif wiki answer": "talk(0.6452)", "verif concept answer": "shake hand(0.6881)", "verif image answer": "hit ball(0.5594)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000579533.jpg"}, {"question": "what type of couch is this", "gt answer": "sectional(1.00)", "pred answer": "loveseat", "question_id": 218725, "best approach": "wiki", "verif answer": "large", "anno approach": "wiki, concept, image", "verif wiki answer": "sectional(0.6173)", "verif concept answer": "pug(0.6653)", "verif image answer": "large(0.6179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000021872.jpg"}, {"question": "what is the material the bracelet worn by the arm in the middle", "gt answer": "gold(1.00)<br/>metal(0.60)<br/>nylon(0.60)<br/>rubber(0.60)", "pred answer": "leather", "question_id": 4593635, "best approach": "wiki, concept, image", "verif answer": "nylon", "anno approach": "wiki, concept, image", "verif wiki answer": "rubber(0.6740)", "verif concept answer": "rubber(0.6094)", "verif image answer": "nylon(0.6344)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459363.jpg"}, {"question": "what is the highest one of these in the world", "gt answer": "mt everest(1.00)<br/>mount everest(0.60)<br/>everest(0.60)", "pred answer": "alp", "question_id": 5118485, "best approach": "concept", "verif answer": "mount saint elias", "anno approach": "wiki, concept, image", "verif wiki answer": "mount everest(0.5874)", "verif concept answer": "mt everest(0.6505)", "verif image answer": "mount saint elias(0.6983)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511848.jpg"}, {"question": "how long will this need to cook", "gt answer": "0 minutes(1.00)<br/>1 hour(0.60)", "pred answer": "10 minutes", "question_id": 124285, "best approach": "image", "verif answer": "1 hour", "anno approach": "wiki, concept, image", "verif wiki answer": "1 hour(0.6821)", "verif concept answer": "3 hours(0.6075)", "verif image answer": "0 minutes(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012428.jpg"}, {"question": "what can happen the objects shown are thrown on the ground", "gt answer": "break(1.00)<br/>shatter(1.00)", "pred answer": "blend", "question_id": 2400745, "best approach": "wiki, concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "shatter(0.6708)", "verif concept answer": "shatter(0.6285)", "verif image answer": "light(0.6480)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240074.jpg"}, {"question": "what is that scooter in the background called", "gt answer": "vespa(1.00)", "pred answer": "van", "question_id": 2096545, "best approach": "", "verif answer": "scooter", "anno approach": "wiki, concept, image", "verif wiki answer": "scooter(0.7299)", "verif concept answer": "scooter(0.7287)", "verif image answer": "scooter(0.7090)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209654.jpg"}, {"question": "what is the large blue vehicle called", "gt answer": "crane(1.00)", "pred answer": "truck", "question_id": 1493315, "best approach": "", "verif answer": "truck", "anno approach": "wiki, concept, image", "verif wiki answer": "bucket truck(0.5508)", "verif concept answer": "bucket truck(0.7245)", "verif image answer": "truck(0.6182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149331.jpg"}, {"question": "what type of boat is this", "gt answer": "raft(1.00)", "pred answer": "canoe", "question_id": 2730355, "best approach": "", "verif answer": "kayak", "anno approach": "wiki, concept, image", "verif wiki answer": "kayak(0.6741)", "verif concept answer": "kayak(0.6825)", "verif image answer": "barge(0.6387)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273035.jpg"}, {"question": "what kind of device is this", "gt answer": "laptop(1.00)", "pred answer": "computer", "question_id": 3665275, "best approach": "", "verif answer": "computer", "anno approach": "wiki, concept, image", "verif wiki answer": "computer(0.7213)", "verif concept answer": "computer(0.7200)", "verif image answer": "work(0.6440)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366527.jpg"}, {"question": "how was the broccoli made", "gt answer": "steamed(1.00)", "pred answer": "toasted", "question_id": 3994615, "best approach": "", "verif answer": "grilled", "anno approach": "wiki, concept, image", "verif wiki answer": "boiled(0.5627)", "verif concept answer": "boiled(0.6052)", "verif image answer": "grilled(0.6543)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399461.jpg"}, {"question": "", "gt answer": "50(0.60)<br/>80(0.60)<br/>$50(0.60)", "pred answer": "15", "question_id": 1005795, "best approach": "concept, image", "verif answer": "20", "anno approach": "wiki, concept, image", "verif wiki answer": "20(0.6295)", "verif concept answer": "80(0.6013)", "verif image answer": "80(0.6465)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100579.jpg"}, {"question": "what sport is played", "gt answer": "cycling(1.00)<br/>bicycling(0.60)", "pred answer": "bike", "question_id": 2922265, "best approach": "wiki", "verif answer": "bike", "anno approach": "wiki, concept, image", "verif wiki answer": "cycling(0.5342)", "verif concept answer": "bike(0.5903)", "verif image answer": "bike(0.5932)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292226.jpg"}, {"question": "how many different types of fruit and vegetables are in this picture", "gt answer": "8(1.00)<br/>12(0.60)", "pred answer": "6", "question_id": 3022165, "best approach": "wiki, concept, image", "verif answer": "6", "anno approach": "wiki, concept, image", "verif wiki answer": "12(0.6915)", "verif concept answer": "12(0.5997)", "verif image answer": "12(0.6120)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302216.jpg"}, {"question": "what do you call the kind of pants that the man on the right is wearing", "gt answer": "flannel(1.00)<br/>pajama(1.00)", "pred answer": "button up", "question_id": 758425, "best approach": "wiki, concept, image", "verif answer": "pajama", "anno approach": "wiki, concept, image", "verif wiki answer": "flannel(0.7077)", "verif concept answer": "flannel(0.6709)", "verif image answer": "flannel(0.5955)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075842.jpg"}, {"question": "what brand of grill is this", "gt answer": "webber(1.00)<br/>coleman(0.60)", "pred answer": "honda", "question_id": 3504975, "best approach": "concept", "verif answer": "ge", "anno approach": "wiki, concept, image", "verif wiki answer": "ge(0.6674)", "verif concept answer": "coleman(0.6871)", "verif image answer": "ge(0.6629)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350497.jpg"}, {"question": "is the man playing with a nintendo product or a sony product", "gt answer": "nintendo(1.00)", "pred answer": "tv", "question_id": 1602555, "best approach": "", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "atari(0.6917)", "verif concept answer": "wii(0.6757)", "verif image answer": "wii(0.6605)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160255.jpg"}, {"question": "what type of machine is this", "gt answer": "conveyor belt(1.00)<br/>line(0.60)", "pred answer": "oven", "question_id": 3057035, "best approach": "concept", "verif answer": "bake", "anno approach": "wiki, concept, image", "verif wiki answer": "coffee(0.6678)", "verif concept answer": "conveyor belt(0.6641)", "verif image answer": "line(0.7143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305703.jpg"}, {"question": "brand of bus", "gt answer": "macbraynes(1.00)<br/>vw(0.60)", "pred answer": "mercedes benz", "question_id": 3004415, "best approach": "", "verif answer": "mercedes benz", "anno approach": "wiki, concept, image", "verif wiki answer": "mercedes benz(0.7284)", "verif concept answer": "mercedes benz(0.7250)", "verif image answer": "coach(0.7215)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300441.jpg"}, {"question": "what children 's movie does this picture remind you of", "gt answer": "black stallion(1.00)", "pred answer": "homeward bound", "question_id": 2836665, "best approach": "wiki", "verif answer": "dumbo", "anno approach": "wiki, concept, image", "verif wiki answer": "black stallion(0.5642)", "verif concept answer": "dumbo(0.7154)", "verif image answer": "dumbo(0.6388)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283666.jpg"}, {"question": "what photography technique was used to make this image", "gt answer": "fade(1.00)<br/>old(0.60)", "pred answer": "black and white", "question_id": 1745215, "best approach": "wiki, image", "verif answer": "black and white", "anno approach": "wiki, concept, image", "verif wiki answer": "fade(0.7160)", "verif concept answer": "black and white(0.6021)", "verif image answer": "fade(0.6037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174521.jpg"}, {"question": "what is the calve doing", "gt answer": "feed(1.00)<br/>drink(0.60)<br/>stand(0.60)<br/>nursing(0.60)", "pred answer": "graze", "question_id": 4079365, "best approach": "wiki, concept, image", "verif answer": "drink", "anno approach": "wiki, concept, image", "verif wiki answer": "drink(0.6449)", "verif concept answer": "drink(0.6593)", "verif image answer": "drink(0.7000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407936.jpg"}, {"question": "what are the messages this object can leave behind called", "gt answer": "skywriting(1.00)<br/>contrail(0.60)<br/>steam(0.60)", "pred answer": "air", "question_id": 1685585, "best approach": "wiki", "verif answer": "contrail", "anno approach": "wiki, concept, image", "verif wiki answer": "contrail(0.6875)", "verif concept answer": "jet(0.6720)", "verif image answer": "smoke(0.6638)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168558.jpg"}, {"question": "what is the name of this sleeve type", "gt answer": "short(1.00)<br/>cap(0.60)", "pred answer": "levis", "question_id": 153545, "best approach": "", "verif answer": "scarf", "anno approach": "wiki, concept, image", "verif wiki answer": "shoe(0.6433)", "verif concept answer": "pixie(0.6955)", "verif image answer": "pixie(0.7027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015354.jpg"}, {"question": "a female adult one of these is called a what", "gt answer": "mare(1.00)", "pred answer": "pony", "question_id": 3176195, "best approach": "concept, image", "verif answer": "female", "anno approach": "wiki, concept, image", "verif wiki answer": "female(0.6650)", "verif concept answer": "mare(0.5843)", "verif image answer": "mare(0.5946)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317619.jpg"}, {"question": "what feature on this clock is very different from most clocks", "gt answer": "letter(1.00)<br/>face(0.60)", "pred answer": "roman numeral", "question_id": 3978265, "best approach": "concept", "verif answer": "face", "anno approach": "wiki, concept, image", "verif wiki answer": "sun(0.6300)", "verif concept answer": "face(0.6533)", "verif image answer": "sun(0.7217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397826.jpg"}, {"question": "who 's better at this sport venus or jordan", "gt answer": "venus(1.00)", "pred answer": "roger federer", "question_id": 3827075, "best approach": "concept", "verif answer": "venus williams", "anno approach": "wiki, concept, image", "verif wiki answer": "venus williams(0.6656)", "verif concept answer": "venus(0.6373)", "verif image answer": "tennis(0.5313)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382707.jpg"}, {"question": "how long does it take for this animal to reach adulthood", "gt answer": "4 years(1.00)<br/>2 years(0.60)<br/>5 years(0.60)", "pred answer": "5 days", "question_id": 2651005, "best approach": "wiki", "verif answer": "5 years", "anno approach": "wiki, concept, image", "verif wiki answer": "4 years(0.6553)", "verif concept answer": "3 years(0.6191)", "verif image answer": "5 years(0.6672)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265100.jpg"}, {"question": "what is the maker of these trucks", "gt answer": "volkswagen(1.00)", "pred answer": "chevy", "question_id": 5474225, "best approach": "concept, image", "verif answer": "ford", "anno approach": "wiki, concept, image", "verif wiki answer": "ford(0.7028)", "verif concept answer": "volkswagen(0.7134)", "verif image answer": "volkswagen(0.7160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000547422.jpg"}, {"question": "what is the name for this collection of images", "gt answer": "collage(1.00)", "pred answer": "map", "question_id": 2117255, "best approach": "", "verif answer": "collage", "anno approach": "wiki, concept, image", "verif wiki answer": "dice(0.6560)", "verif concept answer": "dice(0.5568)", "verif image answer": "wine taster(0.5406)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000211725.jpg"}, {"question": "is the woman on the bike following or breaking the rules of the road", "gt answer": "break(1.00)", "pred answer": "stop", "question_id": 1625475, "best approach": "", "verif answer": "traffic light", "anno approach": "wiki, concept, image", "verif wiki answer": "traffic light(0.6837)", "verif concept answer": "traffic light(0.5856)", "verif image answer": "bus(0.5279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162547.jpg"}, {"question": "what is the appropriate place to walk in this scene", "gt answer": "sidewalk(1.00)", "pred answer": "train station", "question_id": 3219595, "best approach": "", "verif answer": "sidewalk", "anno approach": "wiki, concept, image", "verif wiki answer": "center(0.6122)", "verif concept answer": "pavement(0.6293)", "verif image answer": "pavement(0.5678)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321959.jpg"}, {"question": "what is one thing the person pictured would have to change in order to accomplish a task on the computer in her lap", "gt answer": "turn it on(1.00)", "pred answer": "intel", "question_id": 4943415, "best approach": "", "verif answer": "person", "anno approach": "wiki, concept, image", "verif wiki answer": "semi(0.6958)", "verif concept answer": "person(0.6523)", "verif image answer": "semi(0.5586)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494341.jpg"}, {"question": "what kind of group is named by the word seen here", "gt answer": "osage(1.00)<br/>camper(0.60)", "pred answer": "boy scout", "question_id": 1402845, "best approach": "image", "verif answer": "dinner", "anno approach": "wiki, concept, image", "verif wiki answer": "informal(0.7231)", "verif concept answer": "informal(0.6561)", "verif image answer": "osage(0.7048)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140284.jpg"}, {"question": "what type of television would display this fuzzy image", "gt answer": "tube tv(1.00)<br/>analog(0.60)", "pred answer": "crt", "question_id": 388965, "best approach": "wiki, concept, image", "verif answer": "flatscreen", "anno approach": "wiki, concept, image", "verif wiki answer": "analog(0.7262)", "verif concept answer": "analog(0.6949)", "verif image answer": "analog(0.6281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038896.jpg"}, {"question": "what is a young lamb called", "gt answer": "ewe(1.00)<br/>lamb(1.00)<br/>kid(0.60)", "pred answer": "baby", "question_id": 5013465, "best approach": "wiki, concept", "verif answer": "ewe", "anno approach": "wiki, concept, image", "verif wiki answer": "ewe(0.6125)", "verif concept answer": "ewe(0.6264)", "verif image answer": "kid(0.6828)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501346.jpg"}, {"question": "what part of this image is most likely to have been designed by a civil engineer", "gt answer": "bridge(1.00)", "pred answer": "boat", "question_id": 1668645, "best approach": "wiki", "verif answer": "bridge", "anno approach": "wiki, concept, image", "verif wiki answer": "bridge(0.6815)", "verif concept answer": "overpass(0.6907)", "verif image answer": "train track(0.5442)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166864.jpg"}, {"question": "what brand is this tie", "gt answer": "halston(1.00)", "pred answer": "tie", "question_id": 2734665, "best approach": "", "verif answer": "tie", "anno approach": "wiki, concept, image", "verif wiki answer": "gucci(0.7288)", "verif concept answer": "logitech(0.6910)", "verif image answer": "gucci(0.7178)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273466.jpg"}, {"question": "what country is this place", "gt answer": "nigeria(1.00)<br/>india(0.60)", "pred answer": "vietnam", "question_id": 4334415, "best approach": "concept", "verif answer": "china", "anno approach": "wiki, concept, image", "verif wiki answer": "thailand(0.7068)", "verif concept answer": "nigeria(0.6641)", "verif image answer": "thailand(0.6892)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433441.jpg"}, {"question": "", "gt answer": "$10000(0.60)", "pred answer": "1920", "question_id": 1889025, "best approach": "concept", "verif answer": "2 months", "anno approach": "wiki, concept, image", "verif wiki answer": "2 months(0.5384)", "verif concept answer": "$10000(0.5217)", "verif image answer": "2 months(0.5409)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188902.jpg"}, {"question": "", "gt answer": "brick tile(0.60)<br/>dark(0.60)", "pred answer": "laminate", "question_id": 1722555, "best approach": "wiki, concept, image", "verif answer": "dark", "anno approach": "wiki, concept, image", "verif wiki answer": "brick tile(0.5691)", "verif concept answer": "brick tile(0.6736)", "verif image answer": "brick tile(0.6217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000172255.jpg"}, {"question": "what emotion is this person feeling", "gt answer": "anger(1.00)<br/>sad(0.60)", "pred answer": "happy", "question_id": 2888535, "best approach": "concept", "verif answer": "sad", "anno approach": "wiki, concept, image", "verif wiki answer": "hunger(0.6188)", "verif concept answer": "anger(0.6355)", "verif image answer": "sad(0.6299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288853.jpg"}, {"question": "what sport is performed by jumping out of a vehicle like this one", "gt answer": "parachute(1.00)<br/>taxi(0.60)", "pred answer": "fly", "question_id": 2059185, "best approach": "concept, image", "verif answer": "parachute", "anno approach": "wiki, concept, image", "verif wiki answer": "rope(0.6061)", "verif concept answer": "parachute(0.6144)", "verif image answer": "parachute(0.5987)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205918.jpg"}, {"question": "who sponsors this player", "gt answer": "nike(1.00)<br/>adidas(1.00)<br/>tennis(0.60)", "pred answer": "wilson", "question_id": 3442545, "best approach": "wiki, concept", "verif answer": "nike", "anno approach": "wiki, concept, image", "verif wiki answer": "nike(0.6582)", "verif concept answer": "nike(0.6793)", "verif image answer": "sweat(0.6418)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344254.jpg"}, {"question": "what type of material is the wall made of", "gt answer": "sheetrock(1.00)<br/>concrete(0.60)", "pred answer": "brick", "question_id": 400715, "best approach": "", "verif answer": "tile", "anno approach": "wiki, concept, image", "verif wiki answer": "stone(0.6994)", "verif concept answer": "tile(0.7168)", "verif image answer": "tile(0.7208)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040071.jpg"}, {"question": "which action depicted is a sign of respect", "gt answer": "hat over heart(1.00)", "pred answer": "horseback ride", "question_id": 4867135, "best approach": "image", "verif answer": "backhand", "anno approach": "wiki, concept, image", "verif wiki answer": "backhand(0.6235)", "verif concept answer": "backhand(0.6351)", "verif image answer": "hat over heart(0.5553)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000486713.jpg"}, {"question": "what section of the grocery store would these be in", "gt answer": "produce(1.00)<br/>fruit(0.60)", "pred answer": "farmer market", "question_id": 791725, "best approach": "", "verif answer": "supermarket", "anno approach": "wiki, concept, image", "verif wiki answer": "supermarket(0.6795)", "verif concept answer": "produce department(0.6594)", "verif image answer": "vegetable(0.7115)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079172.jpg"}, {"question": "what object in the photo is used to remember dictation", "gt answer": "recorder(1.00)<br/>gun(0.60)", "pred answer": "phone", "question_id": 5635455, "best approach": "wiki, concept, image", "verif answer": "keyboard", "anno approach": "wiki, concept, image", "verif wiki answer": "recorder(0.7198)", "verif concept answer": "recorder(0.6495)", "verif image answer": "recorder(0.5664)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000563545.jpg"}, {"question": "what type of people drive the vehicle on the left", "gt answer": "firemen(1.00)<br/>firefight(0.60)<br/>human(0.60)", "pred answer": "driver", "question_id": 2376995, "best approach": "image", "verif answer": "passenger", "anno approach": "wiki, concept, image", "verif wiki answer": "passenger(0.7196)", "verif concept answer": "human(0.7200)", "verif image answer": "firemen(0.6923)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237699.jpg"}, {"question": "what is the thing over the water for", "gt answer": "bridge(1.00)<br/>train track(0.60)<br/>cross(0.60)", "pred answer": "boat", "question_id": 3989675, "best approach": "concept, image", "verif answer": "train bridge", "anno approach": "wiki, concept, image", "verif wiki answer": "train bridge(0.6925)", "verif concept answer": "train track(0.6899)", "verif image answer": "train track(0.7245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398967.jpg"}, {"question": "how long can their horns grow", "gt answer": "2 feet(1.00)<br/>15 feet(0.60)<br/>3 feet(0.60)", "pred answer": "8 inches", "question_id": 5503565, "best approach": "image", "verif answer": "2 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "15 feet(0.6695)", "verif concept answer": "short(0.6259)", "verif image answer": "2 feet(0.6505)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550356.jpg"}, {"question": "the name on the first bus is the name of a coffee worker in what show", "gt answer": "friend(1.00)<br/>central park(0.60)", "pred answer": "greenwave", "question_id": 2214755, "best approach": "image", "verif answer": "central park", "anno approach": "wiki, concept, image", "verif wiki answer": "best friend(0.6984)", "verif concept answer": "best friend(0.7143)", "verif image answer": "central park(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221475.jpg"}, {"question": "what was the use of that item in his hand", "gt answer": "take picture(1.00)<br/>picture(0.60)", "pred answer": "camera", "question_id": 4101905, "best approach": "", "verif answer": "take picture", "anno approach": "wiki, concept, image", "verif wiki answer": "mirror(0.7021)", "verif concept answer": "reflector(0.6721)", "verif image answer": "reflector(0.6769)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000410190.jpg"}, {"question": "what kind of plane is this", "gt answer": "private(1.00)<br/>seaplane(0.60)<br/>commercial(0.60)", "pred answer": "cessna", "question_id": 2455035, "best approach": "wiki, image", "verif answer": "glider", "anno approach": "wiki, concept, image", "verif wiki answer": "commercial(0.6927)", "verif concept answer": "airplane(0.6474)", "verif image answer": "commercial(0.5585)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245503.jpg"}, {"question": "what vegetables were used in the creation of this food", "gt answer": "pepper(1.00)", "pred answer": "tomato", "question_id": 2756305, "best approach": "", "verif answer": "potato", "anno approach": "wiki, concept, image", "verif wiki answer": "potato(0.6674)", "verif concept answer": "potato(0.6949)", "verif image answer": "potato(0.5884)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000275630.jpg"}, {"question": "what materials where used for the lights", "gt answer": "glass(1.00)", "pred answer": "metal", "question_id": 4758045, "best approach": "image", "verif answer": "metal", "anno approach": "wiki, concept, image", "verif wiki answer": "lcd(0.6610)", "verif concept answer": "ceramic(0.6413)", "verif image answer": "glass(0.5752)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475804.jpg"}, {"question": "what type of skateboard is being used", "gt answer": "regular(1.00)<br/>small(0.60)<br/>van(0.60)", "pred answer": "longboard", "question_id": 2734255, "best approach": "image", "verif answer": "skateboard", "anno approach": "wiki, concept, image", "verif wiki answer": "kickflip(0.7069)", "verif concept answer": "kickflip(0.6724)", "verif image answer": "regular(0.7030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273425.jpg"}, {"question": "what is the name of this type of cake", "gt answer": "sponge(1.00)<br/>carrot(0.60)", "pred answer": "cheesecake", "question_id": 1769235, "best approach": "wiki, concept", "verif answer": "sponge", "anno approach": "wiki, concept, image", "verif wiki answer": "carrot(0.6390)", "verif concept answer": "carrot(0.6111)", "verif image answer": "towel(0.5909)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176923.jpg"}, {"question": "what are the green items on the plate", "gt answer": "pickle(1.00)", "pred answer": "potato", "question_id": 5509125, "best approach": "wiki", "verif answer": "pea", "anno approach": "wiki, concept, image", "verif wiki answer": "pickle(0.5892)", "verif concept answer": "cucumber(0.5856)", "verif image answer": "pea(0.5707)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550912.jpg"}, {"question": "what fruit is shown", "gt answer": "lime(1.00)<br/>banana(0.60)", "pred answer": "lemon", "question_id": 4927295, "best approach": "wiki", "verif answer": "blueberry", "anno approach": "wiki, concept, image", "verif wiki answer": "lime(0.6100)", "verif concept answer": "blueberry(0.6688)", "verif image answer": "banana(0.6324)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492729.jpg"}, {"question": "how long does a soccer game last", "gt answer": "90 minutes(1.00)<br/>1 hour(0.60)<br/>hour(0.60)", "pred answer": "4 years", "question_id": 412315, "best approach": "wiki, image", "verif answer": "hour", "anno approach": "wiki, concept, image", "verif wiki answer": "hour(0.6679)", "verif concept answer": "6 hours(0.6121)", "verif image answer": "hour(0.5822)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041231.jpg"}, {"question": "what is the lifespan of this animal", "gt answer": "20 years(1.00)<br/>25 years(0.60)<br/>12 years(0.60)<br/>5 years(0.60)", "pred answer": "15 years", "question_id": 3573015, "best approach": "wiki, concept, image", "verif answer": "5 years", "anno approach": "wiki, concept, image", "verif wiki answer": "25 years(0.6767)", "verif concept answer": "12 years(0.6813)", "verif image answer": "12 years(0.6480)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357301.jpg"}, {"question": "what stage of life would this animal be in", "gt answer": "puppy(1.00)<br/>infant(1.00)<br/>early(0.60)", "pred answer": "baby", "question_id": 3851865, "best approach": "wiki, concept", "verif answer": "baby", "anno approach": "wiki, concept, image", "verif wiki answer": "infant(0.6932)", "verif concept answer": "infant(0.6204)", "verif image answer": "2 months(0.5891)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385186.jpg"}, {"question": "what meat is this", "gt answer": "shrimp(1.00)", "pred answer": "pork", "question_id": 843395, "best approach": "", "verif answer": "chicken", "anno approach": "wiki, concept, image", "verif wiki answer": "chicken(0.7024)", "verif concept answer": "chicken(0.6490)", "verif image answer": "crab(0.6262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084339.jpg"}, {"question": "what is he wearing around his neck", "gt answer": "bib(1.00)", "pred answer": "tie", "question_id": 1739985, "best approach": "", "verif answer": "tie", "anno approach": "wiki, concept, image", "verif wiki answer": "collar(0.6986)", "verif concept answer": "tie(0.6681)", "verif image answer": "tie(0.6095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000173998.jpg"}, {"question": "what do you think their job is", "gt answer": "fisherman(1.00)<br/>sail(0.60)<br/>military(0.60)", "pred answer": "boat", "question_id": 3462665, "best approach": "wiki, concept, image", "verif answer": "sail", "anno approach": "wiki, concept, image", "verif wiki answer": "military(0.6264)", "verif concept answer": "military(0.6939)", "verif image answer": "sail(0.6493)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346266.jpg"}, {"question": "what popular alcoholic drink features a stalk the same color as this couch", "gt answer": "bloody mary(1.00)<br/>beer(0.60)<br/>vodka(0.60)", "pred answer": "lemonade", "question_id": 5413195, "best approach": "wiki", "verif answer": "vodka", "anno approach": "wiki, concept, image", "verif wiki answer": "bloody mary(0.7009)", "verif concept answer": "beer(0.5535)", "verif image answer": "captain morgan(0.6420)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541319.jpg"}, {"question": "what kind of shape or style is the kite", "gt answer": "dragon(1.00)<br/>bird(0.60)", "pred answer": "triangle", "question_id": 853495, "best approach": "image", "verif answer": "dragon", "anno approach": "wiki, concept, image", "verif wiki answer": "hummingbird(0.6863)", "verif concept answer": "hummingbird(0.6621)", "verif image answer": "bird(0.7083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085349.jpg"}, {"question": "what position is the person playing in blue", "gt answer": "catcher(1.00)<br/>umpire(0.60)", "pred answer": "batter", "question_id": 4121345, "best approach": "", "verif answer": "catcher", "anno approach": "wiki, concept, image", "verif wiki answer": "shortstop(0.7219)", "verif concept answer": "shortstop(0.7008)", "verif image answer": "pitcher(0.5613)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412134.jpg"}, {"question": "what is the style of jean that is worn by the women", "gt answer": "bell bottom(1.00)", "pred answer": "jean", "question_id": 2771505, "best approach": "wiki", "verif answer": "levis", "anno approach": "wiki, concept, image", "verif wiki answer": "bell bottom(0.6312)", "verif concept answer": "down(0.6496)", "verif image answer": "down(0.6714)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277150.jpg"}, {"question": "why would we suspect this picture what not shot within the last decade", "gt answer": "color(1.00)", "pred answer": "camera", "question_id": 4329475, "best approach": "", "verif answer": "black and white", "anno approach": "wiki, concept, image", "verif wiki answer": "trunk(0.5344)", "verif concept answer": "trunk(0.5468)", "verif image answer": "black and white(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432947.jpg"}, {"question": "what kind of horses are these", "gt answer": "stallion(1.00)<br/>draft(0.60)", "pred answer": "arabian", "question_id": 3443195, "best approach": "", "verif answer": "clydesdale", "anno approach": "wiki, concept, image", "verif wiki answer": "new(0.7192)", "verif concept answer": "clydesdale(0.6334)", "verif image answer": "calico(0.6660)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344319.jpg"}, {"question": "what man made vehicle could follow these animals", "gt answer": "atv(1.00)<br/>4 wheeler(0.60)<br/>bike(0.60)<br/>helicopter(0.60)", "pred answer": "truck", "question_id": 5551025, "best approach": "wiki", "verif answer": "ski lift", "anno approach": "wiki, concept, image", "verif wiki answer": "atv(0.7191)", "verif concept answer": "ski lift(0.6747)", "verif image answer": "ski lift(0.6676)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555102.jpg"}, {"question": "what superhero is on the box", "gt answer": "batman(1.00)", "pred answer": "mickey mouse", "question_id": 4650605, "best approach": "concept, image", "verif answer": "wonder woman", "anno approach": "wiki, concept, image", "verif wiki answer": "wonder woman(0.7268)", "verif concept answer": "batman(0.6476)", "verif image answer": "batman(0.5347)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465060.jpg"}, {"question": "what does this sign show", "gt answer": "direct(1.00)<br/>arrow(0.60)<br/>turn(0.60)<br/>speed limit(0.60)", "pred answer": "no park", "question_id": 1180815, "best approach": "wiki", "verif answer": "direct", "anno approach": "wiki, concept, image", "verif wiki answer": "turn(0.5806)", "verif concept answer": "direction(0.5895)", "verif image answer": "direction(0.6762)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118081.jpg"}, {"question": "", "gt answer": "al fresco(0.60)<br/>dome(0.60)<br/>stone(0.60)", "pred answer": "tile", "question_id": 690545, "best approach": "", "verif answer": "stone", "anno approach": "wiki, concept, image", "verif wiki answer": "arch(0.6322)", "verif concept answer": "arch(0.6866)", "verif image answer": "arch(0.6686)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069054.jpg"}, {"question": "what are the wood structures at the top called", "gt answer": "cabinet(1.00)<br/>counter(0.60)", "pred answer": "house", "question_id": 4806835, "best approach": "wiki, concept", "verif answer": "bar", "anno approach": "wiki, concept, image", "verif wiki answer": "cabinet(0.6665)", "verif concept answer": "cabinet(0.6989)", "verif image answer": "bar(0.5779)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480683.jpg"}, {"question": "what type of tv is this", "gt answer": "analog(1.00)<br/>tube tv(0.60)", "pred answer": "flat screen", "question_id": 833525, "best approach": "", "verif answer": "flatscreen", "anno approach": "wiki, concept, image", "verif wiki answer": "flatscreen(0.7133)", "verif concept answer": "flatscreen(0.5779)", "verif image answer": "grandfather(0.7116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083352.jpg"}, {"question": "in what style is the protein in this dish cooked", "gt answer": "sunny side up(1.00)<br/>egg(0.60)", "pred answer": "grilled", "question_id": 5610825, "best approach": "wiki", "verif answer": "egg", "anno approach": "wiki, concept, image", "verif wiki answer": "egg(0.5826)", "verif concept answer": "italian(0.6569)", "verif image answer": "over easy(0.6348)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561082.jpg"}, {"question": "how fast does this vehicle go", "gt answer": "100 mph(1.00)<br/>80 mph(0.60)", "pred answer": "200 mph", "question_id": 1498335, "best approach": "concept", "verif answer": "80 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "120 mph(0.7201)", "verif concept answer": "100 mph(0.6294)", "verif image answer": "120 mph(0.7119)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149833.jpg"}, {"question": "aww what kind of cat is that", "gt answer": "tabby(1.00)<br/>domestic(1.00)", "pred answer": "calico", "question_id": 3412705, "best approach": "wiki", "verif answer": "american shorthair", "anno approach": "wiki, concept, image", "verif wiki answer": "domestic(0.7011)", "verif concept answer": "persian(0.6776)", "verif image answer": "american shorthair(0.6531)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341270.jpg"}, {"question": "what does the flag in this represent", "gt answer": "gay pride(1.00)", "pred answer": "usa", "question_id": 4966465, "best approach": "", "verif answer": "flag", "anno approach": "wiki, concept, image", "verif wiki answer": "graduation(0.7031)", "verif concept answer": "graduation(0.6807)", "verif image answer": "graduation(0.5731)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496646.jpg"}, {"question": "what candy resembles the man 's tie", "gt answer": "candy cane(1.00)", "pred answer": "teddy bear", "question_id": 2783475, "best approach": "wiki, image", "verif answer": "cherry", "anno approach": "wiki, concept, image", "verif wiki answer": "candy cane(0.5494)", "verif concept answer": "watermelon(0.5292)", "verif image answer": "candy cane(0.6621)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278347.jpg"}, {"question": "what state you think this is", "gt answer": "nevada(1.00)<br/>los angeles(0.60)", "pred answer": "new york", "question_id": 1203755, "best approach": "concept", "verif answer": "florida", "anno approach": "wiki, concept, image", "verif wiki answer": "washington(0.6929)", "verif concept answer": "los angeles(0.6592)", "verif image answer": "washington(0.6326)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000120375.jpg"}, {"question": "what type of phone is this", "gt answer": "cell(1.00)", "pred answer": "smartphone", "question_id": 2897905, "best approach": "", "verif answer": "smartphone", "anno approach": "wiki, concept, image", "verif wiki answer": "cellphone(0.6447)", "verif concept answer": "cellphone(0.6473)", "verif image answer": "smartphone(0.6410)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000289790.jpg"}, {"question": "why is this person wearing a headband", "gt answer": "sweat(1.00)", "pred answer": "hand shake", "question_id": 1396865, "best approach": "image", "verif answer": "serve", "anno approach": "wiki, concept, image", "verif wiki answer": "sweat band(0.5561)", "verif concept answer": "sweat band(0.5960)", "verif image answer": "sweat(0.5564)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139686.jpg"}, {"question": "when was the object in this picture invented", "gt answer": "1948(1.00)<br/>1960's(0.60)", "pred answer": "1880", "question_id": 346805, "best approach": "concept, image", "verif answer": "1948", "anno approach": "wiki, concept, image", "verif wiki answer": "1960(0.6189)", "verif concept answer": "1948(0.6634)", "verif image answer": "1948(0.6625)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000034680.jpg"}, {"question": "what part of the body do you wear the rightmost objects on", "gt answer": "neck(1.00)", "pred answer": "feet", "question_id": 160095, "best approach": "", "verif answer": "arm", "anno approach": "wiki, concept, image", "verif wiki answer": "arm(0.6507)", "verif concept answer": "butt(0.6759)", "verif image answer": "hand(0.5466)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016009.jpg"}, {"question": "what breed are these two ducks", "gt answer": "american pekin(1.00)", "pred answer": "puffin", "question_id": 1692825, "best approach": "", "verif answer": "pelican", "anno approach": "wiki, concept, image", "verif wiki answer": "pelican(0.7105)", "verif concept answer": "pelican(0.6898)", "verif image answer": "calf(0.6189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169282.jpg"}, {"question": "what is the dog laying on", "gt answer": "blanket(1.00)", "pred answer": "bed", "question_id": 4884405, "best approach": "", "verif answer": "blanket", "anno approach": "wiki, concept, image", "verif wiki answer": "quilt(0.7300)", "verif concept answer": "quilt(0.7225)", "verif image answer": "quilt(0.7097)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488440.jpg"}, {"question": "what type of cake is this", "gt answer": "vanilla(1.00)<br/>birthday(0.60)<br/>carrot cake(0.60)", "pred answer": "pastry", "question_id": 1502546, "best approach": "wiki, concept, image", "verif answer": "carrot cake", "anno approach": "wiki, concept, image", "verif wiki answer": "birthday(0.6936)", "verif concept answer": "birthday(0.7105)", "verif image answer": "birthday(0.5323)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000150254.jpg"}, {"question": "how far into the air do you think this snowboarder is", "gt answer": "30 feet(1.00)<br/>20 feet(1.00)", "pred answer": "4 feet", "question_id": 4151315, "best approach": "concept, image", "verif answer": "3 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "3 feet(0.6631)", "verif concept answer": "20 feet(0.5961)", "verif image answer": "30 feet(0.6220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415131.jpg"}, {"question": "what type of event is this", "gt answer": "motorcycle rally(1.00)<br/>rally(0.60)", "pred answer": "motorcycle", "question_id": 389235, "best approach": "wiki, concept, image", "verif answer": "festival", "anno approach": "wiki, concept, image", "verif wiki answer": "rally(0.6791)", "verif concept answer": "rally(0.6799)", "verif image answer": "rally(0.7091)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038923.jpg"}, {"question": "how often does the typical american ride to work in this manner", "gt answer": "never(1.00)", "pred answer": "yearly", "question_id": 1809685, "best approach": "", "verif answer": "rarely", "anno approach": "wiki, concept, image", "verif wiki answer": "rarely(0.5384)", "verif concept answer": "dinner(0.5531)", "verif image answer": "rarely(0.5126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180968.jpg"}, {"question": "what is on the round plate", "gt answer": "croissant(1.00)<br/>pastry(0.60)", "pred answer": "potato", "question_id": 3161705, "best approach": "", "verif answer": "breakfast", "anno approach": "wiki, concept, image", "verif wiki answer": "breakfast(0.7067)", "verif concept answer": "tea time(0.6275)", "verif image answer": "breakfast(0.6503)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316170.jpg"}, {"question": "what is the name of the items inside the cup", "gt answer": "candy cane(1.00)", "pred answer": "coffee", "question_id": 4696485, "best approach": "", "verif answer": "cherry", "anno approach": "wiki, concept, image", "verif wiki answer": "peanut(0.6946)", "verif concept answer": "cherry(0.6565)", "verif image answer": "peanut(0.7089)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469648.jpg"}, {"question": "the vehicle pictured is good for what kind of transportation", "gt answer": "public(1.00)", "pred answer": "bus", "question_id": 1978515, "best approach": "image", "verif answer": "tour bus", "anno approach": "wiki, concept, image", "verif wiki answer": "tour bus(0.7238)", "verif concept answer": "tour bus(0.7210)", "verif image answer": "public(0.6905)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197851.jpg"}, {"question": "what 's it called if one of these crashes", "gt answer": "train crash(1.00)<br/>death(0.60)<br/>crash(0.60)", "pred answer": "fire", "question_id": 2450865, "best approach": "wiki, concept", "verif answer": "death", "anno approach": "wiki, concept, image", "verif wiki answer": "death(0.5700)", "verif concept answer": "death(0.6621)", "verif image answer": "slice(0.6445)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245086.jpg"}, {"question": "what company is responsible for the sign on the right", "gt answer": "under armour(1.00)", "pred answer": "pepsi", "question_id": 92875, "best approach": "image", "verif answer": "7 eleven", "anno approach": "wiki, concept, image", "verif wiki answer": "thomas tank engine(0.5200)", "verif concept answer": "thomas tank engine(0.6030)", "verif image answer": "under armour(0.5061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009287.jpg"}, {"question": "where is this taken", "gt answer": "circus(1.00)<br/>parade(0.60)", "pred answer": "india", "question_id": 3558575, "best approach": "wiki, image", "verif answer": "circus", "anno approach": "wiki, concept, image", "verif wiki answer": "circus(0.7001)", "verif concept answer": "parade(0.6993)", "verif image answer": "circus(0.6882)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355857.jpg"}, {"question": "of the objects in the background what is the name of the tallest one in the world", "gt answer": "mount everest(1.00)<br/>mountain(0.60)", "pred answer": "alp", "question_id": 2517585, "best approach": "concept", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "mountain(0.7033)", "verif concept answer": "mount everest(0.6654)", "verif image answer": "mount saint elias(0.6081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251758.jpg"}, {"question": "how long will the flowers last", "gt answer": "week(1.00)<br/>3 days(0.60)<br/>2 weeks(0.60)", "pred answer": "5 days", "question_id": 5617565, "best approach": "", "verif answer": "5 days", "anno approach": "wiki, concept, image", "verif wiki answer": "2 days(0.6456)", "verif concept answer": "2 days(0.6130)", "verif image answer": "2 days(0.6234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561756.jpg"}, {"question": "what type of light bulb is in the lamp", "gt answer": "led(1.00)", "pred answer": "lamp", "question_id": 3439995, "best approach": "", "verif answer": "fluorescent", "anno approach": "wiki, concept, image", "verif wiki answer": "old(0.7144)", "verif concept answer": "string(0.6141)", "verif image answer": "string(0.7149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343999.jpg"}, {"question": "what kind of planes are these", "gt answer": "steel(0.60)<br/>jet(1.00)<br/>fighter jet(0.60)", "pred answer": "military", "question_id": 5696975, "best approach": "image", "verif answer": "fighter", "anno approach": "wiki, concept, image", "verif wiki answer": "fighter(0.7015)", "verif concept answer": "fighter(0.6476)", "verif image answer": "jet(0.5549)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569697.jpg"}, {"question": "what kind of handlebars does that motorcycle have", "gt answer": "ape hanger(1.00)<br/>large(0.60)", "pred answer": "sidecar", "question_id": 3275725, "best approach": "concept, image", "verif answer": "32 in", "anno approach": "wiki, concept, image", "verif wiki answer": "32 in(0.6584)", "verif concept answer": "ape hanger(0.7193)", "verif image answer": "ape hanger(0.5860)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327572.jpg"}, {"question": "what was the first movie was the character in this image first featured", "gt answer": "star war(1.00)", "pred answer": "forrest gump", "question_id": 1823175, "best approach": "image", "verif answer": "forrest gump", "anno approach": "wiki, concept, image", "verif wiki answer": "disney(0.6865)", "verif concept answer": "forrest gump(0.5319)", "verif image answer": "star war(0.5896)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182317.jpg"}, {"question": "what do most people eat chili in", "gt answer": "bowl(1.00)<br/>bread(0.60)", "pred answer": "cup", "question_id": 3390425, "best approach": "", "verif answer": "bowl", "anno approach": "wiki, concept, image", "verif wiki answer": "soup(0.6762)", "verif concept answer": "soup(0.6700)", "verif image answer": "soup(0.6511)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000339042.jpg"}, {"question": "if an animal eats the greenery these animals are consuming as its sole sustenance it is said to be a what", "gt answer": "herbivore(1.00)<br/>vegetarian(0.60)", "pred answer": "lion", "question_id": 5671865, "best approach": "concept", "verif answer": "herbivore", "anno approach": "wiki, concept, image", "verif wiki answer": "omnivore(0.7195)", "verif concept answer": "herbivore(0.6211)", "verif image answer": "vegetarian(0.5564)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567186.jpg"}, {"question": "what part of the government do these belong to", "gt answer": "air force(1.00)<br/>airforce(0.60)<br/>military(0.60)", "pred answer": "navy", "question_id": 2689215, "best approach": "wiki", "verif answer": "navy", "anno approach": "wiki, concept, image", "verif wiki answer": "air force(0.6477)", "verif concept answer": "army(0.6140)", "verif image answer": "army(0.5419)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268921.jpg"}, {"question": "what town is the road in this photo in", "gt answer": "tarana(1.00)<br/>london(0.60)", "pred answer": "berlin", "question_id": 2377185, "best approach": "", "verif answer": "druid hill", "anno approach": "wiki, concept, image", "verif wiki answer": "colorado(0.6701)", "verif concept answer": "druid hill(0.6910)", "verif image answer": "colorado(0.6944)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237718.jpg"}, {"question": "is this a really big cow or just a huge simulation", "gt answer": "simulation(1.00)", "pred answer": "crowded", "question_id": 1788015, "best approach": "", "verif answer": "normal", "anno approach": "wiki, concept, image", "verif wiki answer": "no saddle(0.5699)", "verif concept answer": "speed(0.6588)", "verif image answer": "no saddle(0.5620)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178801.jpg"}, {"question": "what is the largest of this type of waterway", "gt answer": "canal(1.00)<br/>pacific(0.60)<br/>panama canal(0.60)", "pred answer": "river", "question_id": 4567925, "best approach": "image", "verif answer": "river", "anno approach": "wiki, concept, image", "verif wiki answer": "mississippi(0.7124)", "verif concept answer": "mississippi(0.7021)", "verif image answer": "pacific(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456792.jpg"}, {"question": "what is the oldest ancient artifact", "gt answer": "tool(1.00)", "pred answer": "big ben", "question_id": 4190285, "best approach": "wiki, concept, image", "verif answer": "king", "anno approach": "wiki, concept, image", "verif wiki answer": "tool(0.6409)", "verif concept answer": "tool(0.6654)", "verif image answer": "tool(0.6197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419028.jpg"}, {"question": "what kind of book could the girl in the picture be reading", "gt answer": "fairytale(1.00)<br/>picture(0.60)", "pred answer": "fiction", "question_id": 3692135, "best approach": "wiki, concept", "verif answer": "math", "anno approach": "wiki, concept, image", "verif wiki answer": "fairytale(0.6573)", "verif concept answer": "fairytale(0.6226)", "verif image answer": "picture(0.7041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369213.jpg"}, {"question": "how many spokes are on the average wheel of this type of bicycle", "gt answer": "36(1.00)<br/>22(0.60)<br/>28(0.60)", "pred answer": "4", "question_id": 4814545, "best approach": "wiki", "verif answer": "28", "anno approach": "wiki, concept, image", "verif wiki answer": "22(0.6668)", "verif concept answer": "medium(0.5781)", "verif image answer": "42(0.6611)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481454.jpg"}, {"question": "what company is this yellow truck from", "gt answer": "penske(1.00)", "pred answer": "u haul", "question_id": 4354455, "best approach": "", "verif answer": "chevy", "anno approach": "wiki, concept, image", "verif wiki answer": "chevy(0.6126)", "verif concept answer": "grand canyon(0.7044)", "verif image answer": "grand canyon(0.6610)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435445.jpg"}, {"question": "what is the maximum wind speed the sailboat shown in the image can reach", "gt answer": "20 knots(1.00)<br/>30 mph(0.60)<br/>50 mph(0.60)", "pred answer": "30mph", "question_id": 1289225, "best approach": "wiki", "verif answer": "100 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "20 knots(0.6913)", "verif concept answer": "30 mph(0.6583)", "verif image answer": "100 mph(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128922.jpg"}, {"question": "what animal do these come from", "gt answer": "pig(1.00)<br/>cow(1.00)", "pred answer": "rabbit", "question_id": 5680985, "best approach": "concept", "verif answer": "cow", "anno approach": "wiki, concept, image", "verif wiki answer": "horse(0.6083)", "verif concept answer": "cow(0.5332)", "verif image answer": "food(0.5985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568098.jpg"}, {"question": "where is this photo taken", "gt answer": "stable(1.00)<br/>barn(0.60)<br/>racetrack(0.60)", "pred answer": "yard", "question_id": 4009715, "best approach": "wiki", "verif answer": "stable", "anno approach": "wiki, concept, image", "verif wiki answer": "stable(0.7036)", "verif concept answer": "barn(0.6669)", "verif image answer": "racetrack(0.6559)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400971.jpg"}, {"question": "when did this model of tv come out", "gt answer": "1990's(1.00)<br/>1970(0.60)<br/>1990(0.60)", "pred answer": "2000", "question_id": 2464915, "best approach": "image", "verif answer": "2000", "anno approach": "wiki, concept, image", "verif wiki answer": "2000(0.6801)", "verif concept answer": "2000(0.6131)", "verif image answer": "1970(0.6343)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246491.jpg"}, {"question": "how is this food made", "gt answer": "oven(1.00)<br/>in oven(0.60)<br/>bake(0.60)", "pred answer": "baked", "question_id": 5058765, "best approach": "", "verif answer": "baked", "anno approach": "wiki, concept, image", "verif wiki answer": "baked(0.6398)", "verif concept answer": "baked(0.6539)", "verif image answer": "baked(0.6250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505876.jpg"}, {"question": "what is this guy 's profession", "gt answer": "security(1.00)<br/>horse race(0.60)", "pred answer": "jockey", "question_id": 703475, "best approach": "wiki, concept, image", "verif answer": "police", "anno approach": "wiki, concept, image", "verif wiki answer": "horse race(0.7100)", "verif concept answer": "horse race(0.6203)", "verif image answer": "horse race(0.5155)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070347.jpg"}, {"question": "what drink is this", "gt answer": "whiskey(1.00)", "pred answer": "beer", "question_id": 4420265, "best approach": "wiki, image", "verif answer": "beer", "anno approach": "wiki, concept, image", "verif wiki answer": "whiskey(0.7176)", "verif concept answer": "soda(0.6284)", "verif image answer": "whiskey(0.7038)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442026.jpg"}, {"question": "tell me the name of the vehichle seen in the picture", "gt answer": "cargo van(1.00)<br/>van(1.00)", "pred answer": "trailer", "question_id": 2992445, "best approach": "wiki", "verif answer": "minivan", "anno approach": "wiki, concept, image", "verif wiki answer": "cargo van(0.6898)", "verif concept answer": "minivan(0.7148)", "verif image answer": "minivan(0.6111)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000299244.jpg"}, {"question": "what might the girl slip on after this picture", "gt answer": "banana peel(1.00)<br/>peel(1.00)", "pred answer": "tie", "question_id": 5285625, "best approach": "", "verif answer": "shirt", "anno approach": "wiki, concept, image", "verif wiki answer": "shirt(0.7211)", "verif concept answer": "shirt(0.6127)", "verif image answer": "blanket(0.5846)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528562.jpg"}, {"question": "what is this activity called", "gt answer": "pole dance(1.00)", "pred answer": "kite fly", "question_id": 282305, "best approach": "", "verif answer": "kite", "anno approach": "wiki, concept, image", "verif wiki answer": "aerial(0.6743)", "verif concept answer": "gay pride(0.6308)", "verif image answer": "kite(0.6546)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028230.jpg"}, {"question": "what kind of food is this", "gt answer": "salad(1.00)<br/>stirfry(0.60)<br/>fruit(0.60)<br/>vegetarian(0.60)", "pred answer": "sushi", "question_id": 5071485, "best approach": "image", "verif answer": "soup", "anno approach": "wiki, concept, image", "verif wiki answer": "soup(0.6872)", "verif concept answer": "soup(0.6760)", "verif image answer": "fruit(0.7050)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507148.jpg"}, {"question": "what bay is that", "gt answer": "san francisco(1.00)", "pred answer": "river", "question_id": 2821585, "best approach": "", "verif answer": "central park", "anno approach": "wiki, concept, image", "verif wiki answer": "central park(0.6654)", "verif concept answer": "central park(0.6372)", "verif image answer": "chicago(0.6603)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282158.jpg"}, {"question": "what kind of cream is on the cake", "gt answer": "whipped(1.00)<br/>sour(0.60)", "pred answer": "vanilla", "question_id": 1078865, "best approach": "concept", "verif answer": "vanilla", "anno approach": "wiki, concept, image", "verif wiki answer": "vanilla(0.7028)", "verif concept answer": "whipped(0.7098)", "verif image answer": "vanilla(0.6794)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000107886.jpg"}, {"question": "what brand is the girls outfit from", "gt answer": "gap(1.00)", "pred answer": "disney", "question_id": 3223625, "best approach": "image", "verif answer": "levis", "anno approach": "wiki, concept, image", "verif wiki answer": "target(0.5489)", "verif concept answer": "levis(0.5983)", "verif image answer": "gap(0.7181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322362.jpg"}, {"question": "what is the life span of this animal", "gt answer": "25 years(1.00)<br/>25(1.00)<br/>40 years(0.60)", "pred answer": "60 years", "question_id": 5356515, "best approach": "concept", "verif answer": "30 years", "anno approach": "wiki, concept, image", "verif wiki answer": "30 years(0.7004)", "verif concept answer": "25(0.6623)", "verif image answer": "30 years(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535651.jpg"}, {"question": "", "gt answer": "12450(0.60)", "pred answer": "roman numeral", "question_id": 3587245, "best approach": "wiki, concept, image", "verif answer": "1 hour", "anno approach": "wiki, concept, image", "verif wiki answer": "12450(0.6586)", "verif concept answer": "12450(0.7021)", "verif image answer": "12450(0.5982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358724.jpg"}, {"question": "what make of truck is this", "gt answer": "chevrolet(1.00)<br/>dodge(0.60)<br/>chevy(0.60)", "pred answer": "ford", "question_id": 1197985, "best approach": "wiki, concept", "verif answer": "chevy", "anno approach": "wiki, concept, image", "verif wiki answer": "chevy(0.7214)", "verif concept answer": "chevy(0.7167)", "verif image answer": "gmc(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119798.jpg"}, {"question": "what is this wave doing", "gt answer": "roll(1.00)<br/>crest(1.00)", "pred answer": "wave", "question_id": 2307085, "best approach": "concept, image", "verif answer": "crash", "anno approach": "wiki, concept, image", "verif wiki answer": "surf(0.7013)", "verif concept answer": "crest(0.6996)", "verif image answer": "crest(0.7036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000230708.jpg"}, {"question": "who won the championship in this sport last year", "gt answer": "houston astros(1.00)<br/>giant(0.60)<br/>astros(0.60)<br/>team(0.60)", "pred answer": "baseball", "question_id": 3217005, "best approach": "concept, image", "verif answer": "houston astros", "anno approach": "wiki, concept, image", "verif wiki answer": "team(0.7005)", "verif concept answer": "houston astros(0.5983)", "verif image answer": "houston astros(0.5156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321700.jpg"}, {"question": "what level of baseball is this", "gt answer": "minor league(1.00)<br/>college(0.60)<br/>professional(0.60)<br/>minor(0.60)", "pred answer": "high", "question_id": 3874805, "best approach": "image", "verif answer": "major", "anno approach": "wiki, concept, image", "verif wiki answer": "major(0.6683)", "verif concept answer": "major(0.6395)", "verif image answer": "college(0.6274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387480.jpg"}, {"question": "which fruit associated with the state of georgia is the color of this umbrella", "gt answer": "peach(1.00)", "pred answer": "orange", "question_id": 484085, "best approach": "image", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "apple(0.6970)", "verif concept answer": "apple(0.6368)", "verif image answer": "peach(0.6735)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048408.jpg"}, {"question": "which of these streets is famous for theater", "gt answer": "broadway(1.00)", "pred answer": "new york", "question_id": 4899145, "best approach": "concept", "verif answer": "new york city", "anno approach": "wiki, concept, image", "verif wiki answer": "chicago(0.6932)", "verif concept answer": "broadway(0.6621)", "verif image answer": "chicago(0.7000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489914.jpg"}, {"question": "what famous mountain is in the background", "gt answer": "everest(1.00)<br/>fuji(0.60)", "pred answer": "alp", "question_id": 423855, "best approach": "image", "verif answer": "rockies", "anno approach": "wiki, concept, image", "verif wiki answer": "mt everest(0.7147)", "verif concept answer": "fuji(0.6762)", "verif image answer": "everest(0.6487)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042385.jpg"}, {"question": "what is the electronic device doing in this photo", "gt answer": "charge(1.00)", "pred answer": "watch tv", "question_id": 5403215, "best approach": "image", "verif answer": "online", "anno approach": "wiki, concept, image", "verif wiki answer": "online(0.7181)", "verif concept answer": "online(0.6696)", "verif image answer": "charge(0.6432)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540321.jpg"}, {"question": "what breed is the dog", "gt answer": "shitzu(1.00)<br/>pug(0.60)", "pred answer": "terrier", "question_id": 5187855, "best approach": "", "verif answer": "terrier", "anno approach": "wiki, concept, image", "verif wiki answer": "terrier(0.6959)", "verif concept answer": "terrier(0.6728)", "verif image answer": "terrier(0.6549)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518785.jpg"}, {"question": "what country is this most popular in", "gt answer": "america(1.00)<br/>usa(0.60)", "pred answer": "italy", "question_id": 5704185, "best approach": "wiki, image", "verif answer": "united state", "anno approach": "wiki, concept, image", "verif wiki answer": "america(0.6947)", "verif concept answer": "usa(0.6795)", "verif image answer": "america(0.6120)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570418.jpg"}, {"question": "what food does the animal eat", "gt answer": "meat(1.00)<br/>dog food(0.60)<br/>milk(0.60)", "pred answer": "cat food", "question_id": 5695385, "best approach": "wiki, concept, image", "verif answer": "milk", "anno approach": "wiki, concept, image", "verif wiki answer": "milk(0.6963)", "verif concept answer": "milk(0.6001)", "verif image answer": "milk(0.7030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569538.jpg"}, {"question": "what kind of balloon is in the photo", "gt answer": "hot air(1.00)<br/>parade(0.60)", "pred answer": "kite", "question_id": 1899515, "best approach": "image", "verif answer": "stuffed", "anno approach": "wiki, concept, image", "verif wiki answer": "stuffed(0.6171)", "verif concept answer": "parade(0.5736)", "verif image answer": "hot air(0.5363)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000189951.jpg"}, {"question": "", "gt answer": "50(0.60)<br/>1950's(0.60)<br/>1930s(0.60)<br/>60s(0.60)", "pred answer": "1800's", "question_id": 426805, "best approach": "wiki, concept, image", "verif answer": "1940s", "anno approach": "wiki, concept, image", "verif wiki answer": "1930s(0.5708)", "verif concept answer": "1930s(0.5660)", "verif image answer": "1930s(0.5848)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042680.jpg"}, {"question": "what kind of store would sell this", "gt answer": "gift shop(1.00)<br/>decor(0.60)<br/>craft(0.60)<br/>home depot(0.60)", "pred answer": "walmart", "question_id": 2826695, "best approach": "wiki, concept", "verif answer": "walmart", "anno approach": "wiki, concept, image", "verif wiki answer": "gift shop(0.6883)", "verif concept answer": "gift shop(0.6706)", "verif image answer": "decor(0.6309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282669.jpg"}, {"question": "what kind of band is around the mans wrist", "gt answer": "sweat band(1.00)<br/>sweat(1.00)", "pred answer": "nylon", "question_id": 3000575, "best approach": "", "verif answer": "tennis", "anno approach": "wiki, concept, image", "verif wiki answer": "tennis(0.6904)", "verif concept answer": "tennis(0.6112)", "verif image answer": "federer(0.6426)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300057.jpg"}, {"question": "what hairstyle does this girl have", "gt answer": "pigtail(1.00)<br/>braid(0.60)<br/>ponytail(0.60)", "pred answer": "bun", "question_id": 44425, "best approach": "concept, image", "verif answer": "bun", "anno approach": "wiki, concept, image", "verif wiki answer": "pony tail(0.6555)", "verif concept answer": "ponytail(0.6342)", "verif image answer": "ponytail(0.6581)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004442.jpg"}, {"question": "what is this made on", "gt answer": "pan(1.00)<br/>dough(0.60)", "pred answer": "metal", "question_id": 99935, "best approach": "concept", "verif answer": "oven", "anno approach": "wiki, concept, image", "verif wiki answer": "cheese(0.5906)", "verif concept answer": "pan(0.6166)", "verif image answer": "oven(0.6457)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009993.jpg"}, {"question": "what is the name of this scene", "gt answer": "nativity(1.00)", "pred answer": "bedroom", "question_id": 4973225, "best approach": "concept", "verif answer": "art", "anno approach": "wiki, concept, image", "verif wiki answer": "art(0.5279)", "verif concept answer": "nativity(0.5544)", "verif image answer": "art(0.6189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497322.jpg"}, {"question": "which disney movie featured this type of garb", "gt answer": "mulan(1.00)", "pred answer": "forrest gump", "question_id": 3046255, "best approach": "wiki", "verif answer": "lion king", "anno approach": "wiki, concept, image", "verif wiki answer": "mulan(0.6760)", "verif concept answer": "lion king(0.6517)", "verif image answer": "lion king(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304625.jpg"}, {"question": "what is the purpose of the objects these people are carrying", "gt answer": "stay dry(1.00)<br/>protection(0.60)", "pred answer": "umbrella", "question_id": 5297455, "best approach": "concept", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "protection(0.6834)", "verif concept answer": "stay dry(0.6829)", "verif image answer": "keep dry(0.6798)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529745.jpg"}, {"question": "how are they moving the boat", "gt answer": "oar(1.00)<br/>tow(0.60)<br/>row(0.60)", "pred answer": "boat", "question_id": 525625, "best approach": "wiki, concept", "verif answer": "paddle", "anno approach": "wiki, concept, image", "verif wiki answer": "row(0.7025)", "verif concept answer": "tow(0.6751)", "verif image answer": "dock(0.6027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052562.jpg"}, {"question": "how is the dog carrying this", "gt answer": "mouth(1.00)<br/>teeth(0.60)", "pred answer": "catch", "question_id": 4800165, "best approach": "", "verif answer": "tongue", "anno approach": "wiki, concept, image", "verif wiki answer": "tongue(0.6192)", "verif concept answer": "stomach(0.6604)", "verif image answer": "tongue(0.6697)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480016.jpg"}, {"question": "what type of flowers are in this photo", "gt answer": "lily(1.00)<br/>tulip(0.60)", "pred answer": "daisy", "question_id": 1561515, "best approach": "wiki", "verif answer": "rose", "anno approach": "wiki, concept, image", "verif wiki answer": "tulip(0.6938)", "verif concept answer": "hydrangea(0.6926)", "verif image answer": "pink(0.6703)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000156151.jpg"}, {"question": "what team is this player on", "gt answer": "clearwater(1.00)", "pred answer": "yankees", "question_id": 3220905, "best approach": "", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "yankees(0.6785)", "verif concept answer": "brewer(0.6773)", "verif image answer": "road(0.6389)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322090.jpg"}, {"question": "which actress playing dory in finding nemo", "gt answer": "ellen degeneres(1.00)", "pred answer": "venus williams", "question_id": 79215, "best approach": "image", "verif answer": "serena williams", "anno approach": "wiki, concept, image", "verif wiki answer": "wilson(0.5442)", "verif concept answer": "babe ruth(0.5188)", "verif image answer": "ellen degeneres(0.5032)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007921.jpg"}, {"question": "what kind of knife is this", "gt answer": "butter(1.00)", "pred answer": "craft", "question_id": 3736395, "best approach": "", "verif answer": "hand", "anno approach": "wiki, concept, image", "verif wiki answer": "sponge(0.6729)", "verif concept answer": "spoon(0.6931)", "verif image answer": "spoon(0.6911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373639.jpg"}, {"question": "what type of function is going on", "gt answer": "party(1.00)<br/>family reunion(0.60)<br/>celebration(0.60)", "pred answer": "birthday", "question_id": 4837695, "best approach": "concept, image", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "birthday(0.6756)", "verif concept answer": "family reunion(0.6552)", "verif image answer": "family reunion(0.6634)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483769.jpg"}, {"question": "what does this sign signify", "gt answer": "do not enter(1.00)<br/>stall(0.60)", "pred answer": "no turn", "question_id": 5605635, "best approach": "wiki", "verif answer": "crosswalk", "anno approach": "wiki, concept, image", "verif wiki answer": "do not enter(0.5423)", "verif concept answer": "stall(0.5640)", "verif image answer": "crosswalk(0.6120)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560563.jpg"}, {"question": "what kind of truck is that", "gt answer": "tow(1.00)<br/>tractor trailer(0.60)<br/>tow truck(0.60)", "pred answer": "dump", "question_id": 1844775, "best approach": "", "verif answer": "semi", "anno approach": "wiki, concept, image", "verif wiki answer": "semi(0.7180)", "verif concept answer": "semi(0.7053)", "verif image answer": "semi(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184477.jpg"}, {"question": "why is this woman wearing a coat", "gt answer": "cold(1.00)<br/>rain(0.60)<br/>cold weather(0.60)", "pred answer": "religion", "question_id": 461065, "best approach": "", "verif answer": "cold", "anno approach": "wiki, concept, image", "verif wiki answer": "stay warm(0.6780)", "verif concept answer": "winter(0.6550)", "verif image answer": "winter(0.7036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046106.jpg"}, {"question": "what style of tiling is exhibited by this tile pattern", "gt answer": "star(1.00)<br/>spanish(0.60)<br/>clock(0.60)", "pred answer": "checkered", "question_id": 4407925, "best approach": "image", "verif answer": "star", "anno approach": "wiki, concept, image", "verif wiki answer": "light(0.7023)", "verif concept answer": "light(0.6328)", "verif image answer": "star(0.6478)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440792.jpg"}, {"question": "what do you see", "gt answer": "luggage(1.00)<br/>graffiti(0.60)<br/>garbage can(0.60)", "pred answer": "cloth", "question_id": 1481845, "best approach": "image", "verif answer": "luggage", "anno approach": "wiki, concept, image", "verif wiki answer": "suitcase(0.6922)", "verif concept answer": "suitcase(0.7103)", "verif image answer": "luggage(0.6810)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148184.jpg"}, {"question": "how common is it for people to use the type of transportation pictured here in new york", "gt answer": "common(1.00)", "pred answer": "very", "question_id": 1938785, "best approach": "wiki, concept", "verif answer": "very", "anno approach": "wiki, concept, image", "verif wiki answer": "common(0.6982)", "verif concept answer": "common(0.6654)", "verif image answer": "easy(0.7068)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193878.jpg"}, {"question": "how does the boat propel itself across the water", "gt answer": "motor(1.00)<br/>paddle(0.60)", "pred answer": "boat", "question_id": 4524705, "best approach": "", "verif answer": "motor", "anno approach": "wiki, concept, image", "verif wiki answer": "oar(0.6886)", "verif concept answer": "canoe(0.5983)", "verif image answer": "canoe(0.6147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000452470.jpg"}, {"question": "what emotion is this orange", "gt answer": "sad(1.00)", "pred answer": "happiness", "question_id": 1659365, "best approach": "wiki, image", "verif answer": "sad", "anno approach": "wiki, concept, image", "verif wiki answer": "sad(0.6615)", "verif concept answer": "anger(0.6514)", "verif image answer": "sad(0.5748)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000165936.jpg"}, {"question": "who threw the baseball", "gt answer": "pitcher(1.00)<br/>girl(0.60)", "pred answer": "baby", "question_id": 1558235, "best approach": "", "verif answer": "pitcher", "anno approach": "wiki, concept, image", "verif wiki answer": "boy(0.6947)", "verif concept answer": "catcher(0.6256)", "verif image answer": "catcher(0.6248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155823.jpg"}, {"question": "can these vehicles become safely airborne or are they ground based", "gt answer": "ground based(1.00)<br/>ground(0.60)", "pred answer": "jump", "question_id": 5184335, "best approach": "wiki", "verif answer": "fast", "anno approach": "wiki, concept, image", "verif wiki answer": "ground based(0.6981)", "verif concept answer": "fast(0.6602)", "verif image answer": "ground(0.7243)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518433.jpg"}, {"question": "what famous symbol is on the glass", "gt answer": "playboy bunny(1.00)", "pred answer": "movie", "question_id": 124225, "best approach": "", "verif answer": "pepsi", "anno approach": "wiki, concept, image", "verif wiki answer": "steve job(0.7257)", "verif concept answer": "steve job(0.7238)", "verif image answer": "steve job(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012422.jpg"}, {"question": "this bird evolved from which subspecies", "gt answer": "crane(1.00)<br/>pelican(0.60)<br/>fish(0.60)", "pred answer": "stork", "question_id": 2121745, "best approach": "wiki, concept", "verif answer": "stork", "anno approach": "wiki, concept, image", "verif wiki answer": "fish(0.6638)", "verif concept answer": "fish(0.6113)", "verif image answer": "stork(0.5739)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212174.jpg"}, {"question": "what is the baby doing", "gt answer": "brush teeth(1.00)", "pred answer": "clean teeth", "question_id": 4331225, "best approach": "", "verif answer": "clean teeth", "anno approach": "wiki, concept, image", "verif wiki answer": "teeth(0.6258)", "verif concept answer": "toothbrush(0.6651)", "verif image answer": "brush(0.7106)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433122.jpg"}, {"question": "what field position is being played by the child throwing the baseball", "gt answer": "catcher(1.00)<br/>pitcher(1.00)", "pred answer": "batter", "question_id": 4763415, "best approach": "wiki", "verif answer": "catcher", "anno approach": "wiki, concept, image", "verif wiki answer": "pitcher(0.7116)", "verif concept answer": "shortstop(0.7145)", "verif image answer": "umpire(0.6017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476341.jpg"}, {"question": "what is this person doing", "gt answer": "collect trash(1.00)<br/>work(0.60)<br/>ride(0.60)", "pred answer": "firefight", "question_id": 1612515, "best approach": "image", "verif answer": "construction", "anno approach": "wiki, concept, image", "verif wiki answer": "construction(0.6831)", "verif concept answer": "construction(0.6459)", "verif image answer": "collect trash(0.6372)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161251.jpg"}, {"question": "what element is in side the brightly lit sign", "gt answer": "neon gas(1.00)<br/>neon(0.60)", "pred answer": "clock", "question_id": 4470915, "best approach": "wiki", "verif answer": "helium", "anno approach": "wiki, concept, image", "verif wiki answer": "neon gas(0.7134)", "verif concept answer": "helium(0.6399)", "verif image answer": "neon(0.6871)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447091.jpg"}, {"question": "what breed of cat is this", "gt answer": "tuxedo(1.00)<br/>tabby(0.60)", "pred answer": "calico", "question_id": 4990545, "best approach": "image", "verif answer": "calico", "anno approach": "wiki, concept, image", "verif wiki answer": "calico(0.6647)", "verif concept answer": "tabby(0.6612)", "verif image answer": "tuxedo(0.6439)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499054.jpg"}, {"question": "what era are the hats from", "gt answer": "wwii(1.00)<br/>world war 2(0.60)", "pred answer": "old", "question_id": 4436535, "best approach": "", "verif answer": "1940s", "anno approach": "wiki, concept, image", "verif wiki answer": "1940s(0.7089)", "verif concept answer": "1940s(0.6263)", "verif image answer": "1940s(0.6990)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443653.jpg"}, {"question": "how many mpg does the silver scooter get", "gt answer": "60(1.00)<br/>15(0.60)<br/>20(0.60)<br/>8(0.60)", "pred answer": "2", "question_id": 3453455, "best approach": "wiki, concept", "verif answer": "15", "anno approach": "wiki, concept, image", "verif wiki answer": "60(0.6939)", "verif concept answer": "60(0.6136)", "verif image answer": "15(0.6184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345345.jpg"}, {"question": "what type of event is this", "gt answer": "press conference(1.00)<br/>wed(0.60)", "pred answer": "retirement", "question_id": 391955, "best approach": "concept, image", "verif answer": "retirement", "anno approach": "wiki, concept, image", "verif wiki answer": "wed(0.7077)", "verif concept answer": "press conference(0.7268)", "verif image answer": "press conference(0.6967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039195.jpg"}, {"question": "what is the device sitting on top of the tv", "gt answer": "dvd player(1.00)<br/>remote(0.60)", "pred answer": "television", "question_id": 2410035, "best approach": "", "verif answer": "remote", "anno approach": "wiki, concept, image", "verif wiki answer": "flatscreen(0.6983)", "verif concept answer": "flatscreen(0.5467)", "verif image answer": "remote control(0.5450)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241003.jpg"}, {"question": "what traffic sign is backwards", "gt answer": "yield(1.00)<br/>0(0.60)", "pred answer": "no left turn", "question_id": 2710065, "best approach": "", "verif answer": "stop", "anno approach": "wiki, concept, image", "verif wiki answer": "stop(0.6913)", "verif concept answer": "firetruck(0.6590)", "verif image answer": "slow down(0.6016)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000271006.jpg"}, {"question": "how long does the babies of this animal stay with the parents", "gt answer": "18 years(1.00)<br/>18(0.60)", "pred answer": "2 years", "question_id": 4870615, "best approach": "", "verif answer": "2 weeks", "anno approach": "wiki, concept, image", "verif wiki answer": "2 weeks(0.6530)", "verif concept answer": "2 weeks(0.6061)", "verif image answer": "2 weeks(0.5501)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487061.jpg"}, {"question": "what shoes is this person wearing", "gt answer": "loafer(1.00)<br/>sneaker(0.60)", "pred answer": "boot", "question_id": 4416085, "best approach": "wiki, concept", "verif answer": "dress", "anno approach": "wiki, concept, image", "verif wiki answer": "sneaker(0.6732)", "verif concept answer": "sneaker(0.6016)", "verif image answer": "dress(0.7037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441608.jpg"}, {"question": "what would you place in the black container", "gt answer": "trash(1.00)<br/>garbage(0.60)", "pred answer": "coin", "question_id": 4040135, "best approach": "image", "verif answer": "coin", "anno approach": "wiki, concept, image", "verif wiki answer": "pool(0.6362)", "verif concept answer": "coin(0.5984)", "verif image answer": "garbage(0.6336)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404013.jpg"}, {"question": "what bird flies in this formation", "gt answer": "geese(1.00)<br/>safety(0.60)", "pred answer": "airplane", "question_id": 3002605, "best approach": "image", "verif answer": "seagull", "anno approach": "wiki, concept, image", "verif wiki answer": "seagull(0.6027)", "verif concept answer": "safety(0.5750)", "verif image answer": "geese(0.6353)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300260.jpg"}, {"question": "what is the bridge for", "gt answer": "cross river(1.00)<br/>cross(0.60)<br/>transportation(0.60)", "pred answer": "light", "question_id": 5602385, "best approach": "", "verif answer": "transport", "anno approach": "wiki, concept, image", "verif wiki answer": "transport(0.7175)", "verif concept answer": "transport(0.7224)", "verif image answer": "transport(0.6858)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560238.jpg"}, {"question": "the lunch lady in the movie billy madison says she made this dish a certain way for the students", "gt answer": "sloppy(1.00)", "pred answer": "fry", "question_id": 612155, "best approach": "", "verif answer": "french fry", "anno approach": "wiki, concept, image", "verif wiki answer": "french fry(0.5196)", "verif concept answer": "french fry(0.5660)", "verif image answer": "french fry(0.7271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061215.jpg"}, {"question": "the man in this picture is handling what", "gt answer": "luggage(1.00)", "pred answer": "airplane", "question_id": 1871115, "best approach": "", "verif answer": "airplane", "anno approach": "wiki, concept, image", "verif wiki answer": "airplane(0.7140)", "verif concept answer": "airplane(0.6649)", "verif image answer": "people(0.6776)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187111.jpg"}, {"question": "how high can this kite fly", "gt answer": "300 feet(1.00)<br/>wind(0.60)<br/>200 feet(0.60)<br/>very high(0.60)", "pred answer": "40000 feet", "question_id": 3011945, "best approach": "wiki, concept, image", "verif answer": "200 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "wind(0.7219)", "verif concept answer": "very high(0.5938)", "verif image answer": "very high(0.6723)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301194.jpg"}, {"question": "how would you best describe these people", "gt answer": "student(1.00)<br/>asian(0.60)", "pred answer": "happy", "question_id": 1908825, "best approach": "wiki", "verif answer": "student", "anno approach": "wiki, concept, image", "verif wiki answer": "student(0.5658)", "verif concept answer": "cowboy(0.6839)", "verif image answer": "asian(0.5859)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190882.jpg"}, {"question": "what type of party is this", "gt answer": "bachelorette(1.00)<br/>birthday(1.00)<br/>banana(0.60)", "pred answer": "dinner", "question_id": 1283345, "best approach": "concept", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "carnival(0.6443)", "verif concept answer": "birthday(0.6571)", "verif image answer": "wed(0.6851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128334.jpg"}, {"question": "name a sport this animal is used in", "gt answer": "polo(1.00)<br/>horse race(0.60)<br/>race(0.60)", "pred answer": "equestrian", "question_id": 1627755, "best approach": "wiki, concept, image", "verif answer": "equestrian", "anno approach": "wiki, concept, image", "verif wiki answer": "horse race(0.7017)", "verif concept answer": "horse race(0.6528)", "verif image answer": "horse race(0.7157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162775.jpg"}, {"question": "what are they watching on the tv", "gt answer": "football(1.00)<br/>sport(0.60)<br/>tennis(0.60)<br/>soccer(0.60)", "pred answer": "game", "question_id": 5676635, "best approach": "concept, image", "verif answer": "football", "anno approach": "wiki, concept, image", "verif wiki answer": "basketball(0.5705)", "verif concept answer": "soccer(0.6106)", "verif image answer": "soccer(0.6204)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567663.jpg"}, {"question": "how long would it have taken for this animal to walk after being born", "gt answer": "immediately(1.00)<br/>2 days(0.60)", "pred answer": "4 days", "question_id": 5684555, "best approach": "", "verif answer": "2 years", "anno approach": "wiki, concept, image", "verif wiki answer": "2 years(0.6606)", "verif concept answer": "2 years(0.6362)", "verif image answer": "2 years(0.7120)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568455.jpg"}, {"question": "where are the men standing", "gt answer": "outside(1.00)<br/>outdoor(0.60)", "pred answer": "school", "question_id": 4964445, "best approach": "wiki, image", "verif answer": "outside", "anno approach": "wiki, concept, image", "verif wiki answer": "outside(0.6648)", "verif concept answer": "outdoor(0.5954)", "verif image answer": "outside(0.6384)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496444.jpg"}, {"question": "what is in the mans mouth", "gt answer": "cigarette(1.00)", "pred answer": "toothbrush", "question_id": 5361385, "best approach": "image", "verif answer": "toothbrush", "anno approach": "wiki, concept, image", "verif wiki answer": "toothbrush(0.7005)", "verif concept answer": "toothbrush(0.7234)", "verif image answer": "cigarette(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536138.jpg"}, {"question": "what is the average speed of this vehicle", "gt answer": "20 mph(1.00)<br/>30 mph(0.60)<br/>30mph(0.60)<br/>60 mph(0.60)", "pred answer": "300 mph", "question_id": 1069735, "best approach": "image", "verif answer": "60 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "10 mph(0.7022)", "verif concept answer": "60 mph(0.6779)", "verif image answer": "20 mph(0.7078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106973.jpg"}, {"question": "what makes the hardwood floor shiny", "gt answer": "polish(1.00)", "pred answer": "water", "question_id": 5423915, "best approach": "", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "oil(0.6166)", "verif concept answer": "fan(0.5972)", "verif image answer": "metal(0.7115)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542391.jpg"}, {"question": "what team is this player on", "gt answer": "brewer(1.00)", "pred answer": "yankees", "question_id": 247235, "best approach": "", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "yankees(0.6895)", "verif concept answer": "england(0.6885)", "verif image answer": "yankees(0.6383)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024723.jpg"}, {"question": "the woman in this scene is touching an item usually worn on what part of the body", "gt answer": "foot(1.00)", "pred answer": "feet", "question_id": 3143785, "best approach": "image", "verif answer": "feet", "anno approach": "wiki, concept, image", "verif wiki answer": "1 foot(0.7187)", "verif concept answer": "feet(0.6979)", "verif image answer": "foot(0.7096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314378.jpg"}, {"question": "what do you call this type of window covering", "gt answer": "blind(1.00)<br/>shade(0.60)", "pred answer": "curtain", "question_id": 2471215, "best approach": "concept, image", "verif answer": "blind", "anno approach": "wiki, concept, image", "verif wiki answer": "decor(0.6942)", "verif concept answer": "blind(0.6651)", "verif image answer": "blind(0.5286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247121.jpg"}, {"question": "what rooms are pictured here", "gt answer": "kitchen and dine room(1.00)", "pred answer": "live room", "question_id": 1761745, "best approach": "", "verif answer": "mix", "anno approach": "wiki, concept, image", "verif wiki answer": "friend(0.5323)", "verif concept answer": "friend(0.5472)", "verif image answer": "friend(0.5053)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176174.jpg"}, {"question": "this animal is known to not get along with what other animal", "gt answer": "dog(1.00)<br/>mice(0.60)", "pred answer": "tiger", "question_id": 2937235, "best approach": "", "verif answer": "mice", "anno approach": "wiki, concept, image", "verif wiki answer": "human(0.7053)", "verif concept answer": "human(0.7088)", "verif image answer": "cat food(0.5531)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293723.jpg"}, {"question": "how do i prepare the eggs in this photo", "gt answer": "over easy(1.00)<br/>fry(0.60)", "pred answer": "toasted", "question_id": 1451885, "best approach": "wiki", "verif answer": "fried", "anno approach": "wiki, concept, image", "verif wiki answer": "over easy(0.6183)", "verif concept answer": "french fry(0.6928)", "verif image answer": "fried(0.6645)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145188.jpg"}, {"question": "what kind of cars are near the people", "gt answer": "cadillac(1.00)<br/>family(0.60)", "pred answer": "van", "question_id": 2433335, "best approach": "wiki, concept", "verif answer": "van", "anno approach": "wiki, concept, image", "verif wiki answer": "cadillac(0.5632)", "verif concept answer": "cadillac(0.6032)", "verif image answer": "mercedes(0.5208)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243333.jpg"}, {"question": "where is this celebration taking place", "gt answer": "ship(1.00)<br/>graduation(0.60)", "pred answer": "school", "question_id": 784825, "best approach": "wiki, concept, image", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "graduation(0.7027)", "verif concept answer": "graduation(0.6642)", "verif image answer": "graduation(0.6463)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078482.jpg"}, {"question": "what console does the controller belong to", "gt answer": "xbox(1.00)", "pred answer": "wii", "question_id": 2459325, "best approach": "", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "wii(0.7120)", "verif concept answer": "wii(0.6435)", "verif image answer": "tv(0.6464)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245932.jpg"}, {"question": "how much can they eat in a day", "gt answer": "lot(1.00)<br/>10 pounds(0.60)<br/>100 lbs(0.60)", "pred answer": "15", "question_id": 3219645, "best approach": "concept", "verif answer": "lot", "anno approach": "wiki, concept, image", "verif wiki answer": "20 pounds(0.6282)", "verif concept answer": "lot(0.5844)", "verif image answer": "100 lbs(0.5645)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321964.jpg"}, {"question": "what is the silver item with many steps used for in this situation", "gt answer": "ladder(1.00)<br/>stair(0.60)", "pred answer": "walk", "question_id": 927315, "best approach": "image", "verif answer": "step", "anno approach": "wiki, concept, image", "verif wiki answer": "step(0.7013)", "verif concept answer": "step(0.6606)", "verif image answer": "ladder(0.6419)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092731.jpg"}, {"question": "what well known organization would offer this for adoption", "gt answer": "spca(1.00)<br/>aspca(0.60)", "pred answer": "owner", "question_id": 1790885, "best approach": "wiki", "verif answer": "aspca", "anno approach": "wiki, concept, image", "verif wiki answer": "aspca(0.6242)", "verif concept answer": "ikea(0.5991)", "verif image answer": "ikea(0.6457)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000179088.jpg"}, {"question": "what is the ratio for hitting the ball called", "gt answer": "bat average(1.00)<br/>bat(0.60)", "pred answer": "15", "question_id": 5156385, "best approach": "wiki", "verif answer": "hit", "anno approach": "wiki, concept, image", "verif wiki answer": "bat(0.6771)", "verif concept answer": "hit(0.6403)", "verif image answer": "hit(0.6638)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515638.jpg"}, {"question": "what is the meaning of the white flowers in this arrangement", "gt answer": "purity(1.00)", "pred answer": "love", "question_id": 4636255, "best approach": "", "verif answer": "dandelion", "anno approach": "wiki, concept, image", "verif wiki answer": "dandelion(0.7108)", "verif concept answer": "dandelion(0.7058)", "verif image answer": "dandelion(0.6824)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463625.jpg"}, {"question": "this young man is demonstrating something you shouldn't do what is it", "gt answer": "run with scissor(1.00)<br/>run(0.60)", "pred answer": "camera", "question_id": 817045, "best approach": "wiki, concept", "verif answer": "sing", "anno approach": "wiki, concept, image", "verif wiki answer": "run with scissor(0.6124)", "verif concept answer": "run with scissor(0.5758)", "verif image answer": "sing(0.7021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081704.jpg"}, {"question": "what teams are playing in this image", "gt answer": "angel and dodger(1.00)", "pred answer": "yankees", "question_id": 4735535, "best approach": "", "verif answer": "dodger", "anno approach": "wiki, concept, image", "verif wiki answer": "dodger(0.7179)", "verif concept answer": "dodger(0.6863)", "verif image answer": "dodger(0.5389)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473553.jpg"}, {"question": "who made those shoes", "gt answer": "shoemaker(1.00)<br/>nike(0.60)", "pred answer": "converse", "question_id": 2681905, "best approach": "wiki, concept", "verif answer": "nike", "anno approach": "wiki, concept, image", "verif wiki answer": "shoemaker(0.6244)", "verif concept answer": "shoemaker(0.6537)", "verif image answer": "nike(0.5308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268190.jpg"}, {"question": "what type of event are the motorcyclists going to", "gt answer": "rally(1.00)<br/>party(0.60)", "pred answer": "race", "question_id": 3348405, "best approach": "wiki, concept", "verif answer": "parade", "anno approach": "wiki, concept, image", "verif wiki answer": "rally(0.7171)", "verif concept answer": "rally(0.7011)", "verif image answer": "parade(0.6886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334840.jpg"}, {"question": "what dish is being prepared in this photo", "gt answer": "taco(1.00)", "pred answer": "potato", "question_id": 4251375, "best approach": "", "verif answer": "salad", "anno approach": "wiki, concept, image", "verif wiki answer": "salad(0.6147)", "verif concept answer": "salad(0.6822)", "verif image answer": "deli(0.6096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425137.jpg"}, {"question": "what type of sound does this animal make", "gt answer": "neigh(1.00)", "pred answer": "meow", "question_id": 5194905, "best approach": "", "verif answer": "meow", "anno approach": "wiki, concept, image", "verif wiki answer": "meow(0.7241)", "verif concept answer": "moo(0.6726)", "verif image answer": "moo(0.7230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000519490.jpg"}, {"question": "why is this person using their foot", "gt answer": "flush(1.00)", "pred answer": "leave", "question_id": 4987825, "best approach": "wiki, concept", "verif answer": "wash hand", "anno approach": "wiki, concept, image", "verif wiki answer": "flush(0.6824)", "verif concept answer": "flush(0.5819)", "verif image answer": "bleach(0.6137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000498782.jpg"}, {"question": "where on the body might this device be placed while working", "gt answer": "lap(1.00)<br/>shoulder(0.60)<br/>hand(0.60)", "pred answer": "feet", "question_id": 5583175, "best approach": "wiki, concept, image", "verif answer": "computer", "anno approach": "wiki, concept, image", "verif wiki answer": "hand(0.6766)", "verif concept answer": "shoulder(0.6830)", "verif image answer": "hand(0.5553)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558317.jpg"}, {"question": "", "gt answer": "5 months(0.60)<br/>6 months(0.60)<br/>half(0.60)", "pred answer": "3 feet", "question_id": 5314575, "best approach": "image", "verif answer": "3 months", "anno approach": "wiki, concept, image", "verif wiki answer": "2 years(0.5805)", "verif concept answer": "2 years(0.5897)", "verif image answer": "5 months(0.5699)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531457.jpg"}, {"question": "what skyline is this city in", "gt answer": "new york(1.00)<br/>chicago(0.60)", "pred answer": "city", "question_id": 2685235, "best approach": "wiki, image", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "new york(0.7098)", "verif concept answer": "london(0.6352)", "verif image answer": "new york(0.6916)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268523.jpg"}, {"question": "what kind of jersey is this dog wearing", "gt answer": "football(1.00)<br/>sport(0.60)<br/>blue(0.60)", "pred answer": "button up", "question_id": 4506725, "best approach": "", "verif answer": "shirt", "anno approach": "wiki, concept, image", "verif wiki answer": "shirt(0.7164)", "verif concept answer": "shirt(0.6444)", "verif image answer": "shirt(0.6720)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450672.jpg"}, {"question": "is this an actual game of soccer or is just goofing around", "gt answer": "actual(1.00)", "pred answer": "play", "question_id": 1948455, "best approach": "wiki", "verif answer": "both", "anno approach": "wiki, concept, image", "verif wiki answer": "actual(0.6839)", "verif concept answer": "normal(0.5421)", "verif image answer": "normal(0.6795)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194845.jpg"}, {"question": "how old is that building", "gt answer": "200 years(1.00)", "pred answer": "100 years", "question_id": 5647335, "best approach": "", "verif answer": "100 years", "anno approach": "wiki, concept, image", "verif wiki answer": "roman(0.6759)", "verif concept answer": "100 years(0.6387)", "verif image answer": "roman(0.6578)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564733.jpg"}, {"question": "what type of mac is that", "gt answer": "desktop(1.00)<br/>macbook(0.60)", "pred answer": "mac", "question_id": 936345, "best approach": "wiki, concept, image", "verif answer": "macbook", "anno approach": "wiki, concept, image", "verif wiki answer": "macbook(0.6842)", "verif concept answer": "macbook(0.6371)", "verif image answer": "macbook(0.6581)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093634.jpg"}, {"question": "on what two continents do these animals live in the wild", "gt answer": "asia and africa(1.00)<br/>africa and asia(0.60)", "pred answer": "elephant", "question_id": 3477365, "best approach": "wiki, image", "verif answer": "africa", "anno approach": "wiki, concept, image", "verif wiki answer": "asia and africa(0.7053)", "verif concept answer": "africa(0.6738)", "verif image answer": "asia and africa(0.5626)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347736.jpg"}, {"question": "where is this", "gt answer": "switzerland(1.00)<br/>scotland(0.60)", "pred answer": "mountain", "question_id": 3414205, "best approach": "", "verif answer": "pasture", "anno approach": "wiki, concept, image", "verif wiki answer": "ireland(0.6771)", "verif concept answer": "ireland(0.6724)", "verif image answer": "pasture(0.7036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341420.jpg"}, {"question": "what type of climate does this bird enjoy", "gt answer": "warm(1.00)<br/>rain(0.60)<br/>temperate(0.60)<br/>stormy(0.60)", "pred answer": "tropical", "question_id": 3316975, "best approach": "concept, image", "verif answer": "tropical", "anno approach": "wiki, concept, image", "verif wiki answer": "tropical(0.7122)", "verif concept answer": "temperate(0.6686)", "verif image answer": "temperate(0.5426)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331697.jpg"}, {"question": "where would you store this item in the kitchen", "gt answer": "fridge(1.00)<br/>refridgerator(0.60)", "pred answer": "store", "question_id": 4876875, "best approach": "wiki, concept", "verif answer": "fridge", "anno approach": "wiki, concept, image", "verif wiki answer": "fridge(0.7234)", "verif concept answer": "fridge(0.6823)", "verif image answer": "refridgerator(0.5099)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487687.jpg"}, {"question": "what are each scoring group in the sport called", "gt answer": "set(1.00)<br/>player(0.60)", "pred answer": "double", "question_id": 4006445, "best approach": "", "verif answer": "bieber", "anno approach": "wiki, concept, image", "verif wiki answer": "minor(0.6590)", "verif concept answer": "minor(0.6576)", "verif image answer": "team(0.6342)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400644.jpg"}, {"question": "what kind of beverage is in the french press", "gt answer": "tea(1.00)<br/>coffee(1.00)", "pred answer": "juice", "question_id": 3060805, "best approach": "wiki, concept, image", "verif answer": "coffee", "anno approach": "wiki, concept, image", "verif wiki answer": "coffee(0.6348)", "verif concept answer": "coffee(0.6613)", "verif image answer": "tea(0.6432)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306080.jpg"}, {"question": "what is attached to this item when it is in use", "gt answer": "hose(1.00)", "pred answer": "fire hydrant", "question_id": 4445715, "best approach": "wiki", "verif answer": "hose", "anno approach": "wiki, concept, image", "verif wiki answer": "hose(0.7091)", "verif concept answer": "fire hydrant(0.6967)", "verif image answer": "fire hydrant(0.6714)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000444571.jpg"}, {"question": "what does this truck serve", "gt answer": "icecream(1.00)<br/>ice cream(0.60)", "pred answer": "food", "question_id": 3448935, "best approach": "concept, image", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "food(0.6823)", "verif concept answer": "ice cream(0.6548)", "verif image answer": "ice cream(0.6613)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344893.jpg"}, {"question": "what do they call this outside shopping area", "gt answer": "market(1.00)", "pred answer": "grocery", "question_id": 4604425, "best approach": "concept", "verif answer": "farmer market", "anno approach": "wiki, concept, image", "verif wiki answer": "sell(0.7041)", "verif concept answer": "market(0.6679)", "verif image answer": "store(0.5806)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460442.jpg"}, {"question": "what brand of tissues are in the picture", "gt answer": "kleenex(1.00)", "pred answer": "colgate", "question_id": 5696725, "best approach": "wiki, concept, image", "verif answer": "tissue", "anno approach": "wiki, concept, image", "verif wiki answer": "kleenex(0.6430)", "verif concept answer": "kleenex(0.6506)", "verif image answer": "kleenex(0.6375)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569672.jpg"}, {"question": "what species of bird is this", "gt answer": "sparrow(1.00)<br/>small(0.60)", "pred answer": "finch", "question_id": 4497275, "best approach": "image", "verif answer": "finch", "anno approach": "wiki, concept, image", "verif wiki answer": "hummingbird(0.7055)", "verif concept answer": "hummingbird(0.6639)", "verif image answer": "sparrow(0.5974)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449727.jpg"}, {"question": "what city is this", "gt answer": "new york city(1.00)<br/>new york(0.60)", "pred answer": "berlin", "question_id": 80065, "best approach": "image", "verif answer": "new york city", "anno approach": "wiki, concept, image", "verif wiki answer": "new york(0.7147)", "verif concept answer": "los angeles(0.6690)", "verif image answer": "new york city(0.5613)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008006.jpg"}, {"question": "why is this happening to the dog 's ears", "gt answer": "sad(1.00)<br/>curious(0.60)<br/>fold(0.60)", "pred answer": "move", "question_id": 2384525, "best approach": "wiki, image", "verif answer": "curious", "anno approach": "wiki, concept, image", "verif wiki answer": "sad(0.5716)", "verif concept answer": "fold(0.5685)", "verif image answer": "sad(0.6433)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238452.jpg"}, {"question": "where is this train currently parked at", "gt answer": "station(1.00)", "pred answer": "train station", "question_id": 3358045, "best approach": "wiki", "verif answer": "train station", "anno approach": "wiki, concept, image", "verif wiki answer": "station(0.7148)", "verif concept answer": "train station(0.7120)", "verif image answer": "train station(0.6859)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335804.jpg"}, {"question": "what kind of architecture is shown", "gt answer": "greek(1.00)<br/>italian(0.60)<br/>gothic(0.60)", "pred answer": "roman", "question_id": 5273145, "best approach": "", "verif answer": "roman", "anno approach": "wiki, concept, image", "verif wiki answer": "roman(0.6593)", "verif concept answer": "roman(0.6497)", "verif image answer": "roman(0.6025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527314.jpg"}, {"question": "what decade was this", "gt answer": "1940's(1.00)<br/>1800s(0.60)", "pred answer": "1800's", "question_id": 4362885, "best approach": "", "verif answer": "1930s", "anno approach": "wiki, concept, image", "verif wiki answer": "1930s(0.6532)", "verif concept answer": "1930s(0.6466)", "verif image answer": "1940(0.6648)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436288.jpg"}, {"question": "what kind of dog is surfing", "gt answer": "pitbull(1.00)<br/>labrador(0.60)", "pred answer": "beagle", "question_id": 3652935, "best approach": "", "verif answer": "labrador", "anno approach": "wiki, concept, image", "verif wiki answer": "german shepard(0.6740)", "verif concept answer": "bulldog(0.6296)", "verif image answer": "bulldog(0.6274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365293.jpg"}, {"question": "what animal is chassing this sheep", "gt answer": "cat(1.00)<br/>dog(0.60)<br/>penguin(0.60)<br/>wolf(0.60)", "pred answer": "lion", "question_id": 128245, "best approach": "image", "verif answer": "dog", "anno approach": "wiki, concept, image", "verif wiki answer": "dog(0.7181)", "verif concept answer": "dog(0.7024)", "verif image answer": "cat(0.6898)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012824.jpg"}, {"question": "what kind of pound cake is this", "gt answer": "lemon(1.00)<br/>vanilla(0.60)<br/>coffee(0.60)", "pred answer": "cake", "question_id": 5406335, "best approach": "image", "verif answer": "carrot cake", "anno approach": "wiki, concept, image", "verif wiki answer": "carrot cake(0.7302)", "verif concept answer": "carrot cake(0.7294)", "verif image answer": "vanilla(0.5856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540633.jpg"}, {"question": "how much do you have to pay in order to take one of these", "gt answer": "$2.75(1.00)<br/>2 dollars(0.60)", "pred answer": "$500", "question_id": 4051315, "best approach": "image", "verif answer": "2 dollars", "anno approach": "wiki, concept, image", "verif wiki answer": "2 dollars(0.7053)", "verif concept answer": "2 dollars(0.6430)", "verif image answer": "$2.75(0.6276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405131.jpg"}, {"question": "does this image depict political or apolitical speech", "gt answer": "political(1.00)", "pred answer": "obama", "question_id": 5506425, "best approach": "image", "verif answer": "government", "anno approach": "wiki, concept, image", "verif wiki answer": "government(0.5680)", "verif concept answer": "rally(0.5948)", "verif image answer": "political(0.5379)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550642.jpg"}, {"question": "where is this man standing in this photo", "gt answer": "sidewalk(1.00)<br/>center(0.60)", "pred answer": "street", "question_id": 1058535, "best approach": "wiki, image", "verif answer": "sidewalk", "anno approach": "wiki, concept, image", "verif wiki answer": "center(0.6595)", "verif concept answer": "crosswalk(0.6505)", "verif image answer": "center(0.6687)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105853.jpg"}, {"question": "what fabric was used to construct the red suitcase the woman is pulling behind herself", "gt answer": "canvas(1.00)<br/>plastic(0.60)<br/>nylon(0.60)", "pred answer": "cotton", "question_id": 69355, "best approach": "wiki", "verif answer": "nylon", "anno approach": "wiki, concept, image", "verif wiki answer": "canvas(0.5778)", "verif concept answer": "plastic(0.6003)", "verif image answer": "nylon(0.6262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006935.jpg"}, {"question": "which one should wear sunscreen", "gt answer": "man(1.00)<br/>human(0.60)<br/>person(0.60)", "pred answer": "left", "question_id": 2802065, "best approach": "wiki, concept, image", "verif answer": "person", "anno approach": "wiki, concept, image", "verif wiki answer": "person(0.7227)", "verif concept answer": "person(0.6851)", "verif image answer": "person(0.7211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280206.jpg"}, {"question": "what type of water sport is this", "gt answer": "kayak(1.00)<br/>canoe(0.60)", "pred answer": "wakeboarding", "question_id": 5117845, "best approach": "wiki, concept", "verif answer": "canoe", "anno approach": "wiki, concept, image", "verif wiki answer": "canoe(0.7053)", "verif concept answer": "canoe(0.7128)", "verif image answer": "row(0.6666)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511784.jpg"}, {"question": "what does the remote need to work", "gt answer": "battery(1.00)", "pred answer": "remote", "question_id": 5667135, "best approach": "", "verif answer": "bluetooth", "anno approach": "wiki, concept, image", "verif wiki answer": "bluetooth(0.7017)", "verif concept answer": "bluetooth(0.6435)", "verif image answer": "bluetooth(0.6509)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566713.jpg"}, {"question": "what famous singer dances and sings while holding one of these", "gt answer": "gene kelly(1.00)", "pred answer": "carmen miranda", "question_id": 1960355, "best approach": "wiki, concept", "verif answer": "carmen miranda", "anno approach": "wiki, concept, image", "verif wiki answer": "gene kelly(0.7285)", "verif concept answer": "gene kelly(0.6794)", "verif image answer": "clown(0.6743)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196035.jpg"}, {"question": "what are the doors in the background called", "gt answer": "slide(1.00)<br/>sleep(0.60)", "pred answer": "glass", "question_id": 4414935, "best approach": "image", "verif answer": "watch tv", "anno approach": "wiki, concept, image", "verif wiki answer": "watch tv(0.6658)", "verif concept answer": "watch tv(0.7214)", "verif image answer": "slide(0.5342)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441493.jpg"}, {"question": "which brand of car is shown in this picture", "gt answer": "chevrolet(1.00)<br/>gmc(0.60)", "pred answer": "volkswagen", "question_id": 2074555, "best approach": "image", "verif answer": "dodge", "anno approach": "wiki, concept, image", "verif wiki answer": "dodge(0.6355)", "verif concept answer": "gmc(0.6201)", "verif image answer": "chevrolet(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207455.jpg"}, {"question": "what is a more dangerous species of this animal", "gt answer": "tiger(1.00)<br/>puma(0.60)", "pred answer": "feline", "question_id": 2064125, "best approach": "wiki, concept", "verif answer": "tiger", "anno approach": "wiki, concept, image", "verif wiki answer": "tiger(0.6344)", "verif concept answer": "tiger(0.5358)", "verif image answer": "tigger(0.6912)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206412.jpg"}, {"question": "what brand of shoes are the white shoes with three black stripes", "gt answer": "adidas(1.00)", "pred answer": "converse", "question_id": 938855, "best approach": "", "verif answer": "nike", "anno approach": "wiki, concept, image", "verif wiki answer": "nike(0.5427)", "verif concept answer": "nike(0.5394)", "verif image answer": "columbia(0.6439)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093885.jpg"}, {"question": "what kind of people ride this bus", "gt answer": "school kid(1.00)<br/>children(0.60)<br/>student(0.60)", "pred answer": "passenger", "question_id": 2880155, "best approach": "wiki, concept, image", "verif answer": "student", "anno approach": "wiki, concept, image", "verif wiki answer": "student(0.6707)", "verif concept answer": "student(0.7097)", "verif image answer": "student(0.7004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288015.jpg"}, {"question": "a peahen is the female variant of what metal creatures shown", "gt answer": "peacock(1.00)<br/>bird(0.60)", "pred answer": "copper", "question_id": 3504215, "best approach": "wiki, concept, image", "verif answer": "swan", "anno approach": "wiki, concept, image", "verif wiki answer": "peacock(0.6594)", "verif concept answer": "peacock(0.5451)", "verif image answer": "peacock(0.5047)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350421.jpg"}, {"question": "who carries these around with them more males or females", "gt answer": "female(1.00)", "pred answer": "men", "question_id": 3255235, "best approach": "", "verif answer": "male", "anno approach": "wiki, concept, image", "verif wiki answer": "women(0.6960)", "verif concept answer": "women(0.6509)", "verif image answer": "male(0.6722)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325523.jpg"}, {"question": "where can you find this type of drink in seattle", "gt answer": "bar(1.00)", "pred answer": "cafe", "question_id": 5204725, "best approach": "", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "restaurant(0.6123)", "verif concept answer": "restaurant(0.6978)", "verif image answer": "kitchen(0.6967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520472.jpg"}, {"question": "what is the name of the restaurant where this was served", "gt answer": "martha(1.00)<br/>ihop(0.60)", "pred answer": "diner", "question_id": 394565, "best approach": "wiki, concept", "verif answer": "subway", "anno approach": "wiki, concept, image", "verif wiki answer": "martha(0.6578)", "verif concept answer": "martha(0.6948)", "verif image answer": "subway(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039456.jpg"}, {"question": "what shape is depicted in yellow", "gt answer": "cross(1.00)<br/>square(0.60)", "pred answer": "star", "question_id": 3376385, "best approach": "wiki, concept, image", "verif answer": "heart", "anno approach": "wiki, concept, image", "verif wiki answer": "cross(0.5748)", "verif concept answer": "cross(0.5074)", "verif image answer": "cross(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337638.jpg"}, {"question": "where should this item be placed", "gt answer": "trash(1.00)<br/>garbage(0.60)", "pred answer": "garbage can", "question_id": 1175125, "best approach": "", "verif answer": "pool", "anno approach": "wiki, concept, image", "verif wiki answer": "pool(0.5534)", "verif concept answer": "pool(0.5882)", "verif image answer": "garden(0.7080)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117512.jpg"}, {"question": "this looks delicious what type of meal is this", "gt answer": "pasta(1.00)<br/>brocoli(0.60)", "pred answer": "stir fry", "question_id": 1756095, "best approach": "wiki", "verif answer": "ramen", "anno approach": "wiki, concept, image", "verif wiki answer": "pasta(0.5294)", "verif concept answer": "brocoli(0.5818)", "verif image answer": "broccoli(0.7214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000175609.jpg"}, {"question": "what countries flag is shown", "gt answer": "britain(1.00)<br/>england(0.60)<br/>great britain(0.60)", "pred answer": "france", "question_id": 5219825, "best approach": "wiki", "verif answer": "great britain", "anno approach": "wiki, concept, image", "verif wiki answer": "britain(0.7054)", "verif concept answer": "great britain(0.7244)", "verif image answer": "england(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521982.jpg"}, {"question": "what function does this vehicle perform", "gt answer": "delivery(1.00)<br/>collect trash(0.60)<br/>deliver(0.60)", "pred answer": "tow", "question_id": 1029745, "best approach": "", "verif answer": "delivery", "anno approach": "wiki, concept, image", "verif wiki answer": "camp(0.5118)", "verif concept answer": "police(0.5050)", "verif image answer": "camp(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000102974.jpg"}, {"question": "how close to a city is this photo taken", "gt answer": "far(1.00)", "pred answer": "1 mile", "question_id": 1369035, "best approach": "image", "verif answer": "far", "anno approach": "wiki, concept, image", "verif wiki answer": "yard(0.5214)", "verif concept answer": "yard(0.5319)", "verif image answer": "far(0.5428)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136903.jpg"}, {"question": "what type of steak is this", "gt answer": "sirloin(1.00)<br/>grilled(0.60)", "pred answer": "roast beef", "question_id": 1261295, "best approach": "wiki, concept", "verif answer": "steak", "anno approach": "wiki, concept, image", "verif wiki answer": "grilled(0.5119)", "verif concept answer": "grilled(0.5654)", "verif image answer": "steak(0.7237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126129.jpg"}, {"question": "what is the term for a craftsman that specializes in producing this object", "gt answer": "clockmaker(1.00)<br/>clock maker(1.00)", "pred answer": "big ben", "question_id": 3574435, "best approach": "wiki, concept", "verif answer": "old", "anno approach": "wiki, concept, image", "verif wiki answer": "clock maker(0.5041)", "verif concept answer": "clock maker(0.5114)", "verif image answer": "old(0.6469)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357443.jpg"}, {"question": "what famous bear character from children 's books does this look like", "gt answer": "winnie pooh(1.00)", "pred answer": "theodore roosevelt", "question_id": 4589315, "best approach": "wiki", "verif answer": "mickey mouse", "anno approach": "wiki, concept, image", "verif wiki answer": "winnie pooh(0.5010)", "verif concept answer": "mickey mouse(0.5078)", "verif image answer": "mickey mouse(0.5816)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458931.jpg"}, {"question": "how many pillons are in this photo", "gt answer": "15(1.00)<br/>16(0.60)", "pred answer": "6", "question_id": 1565105, "best approach": "", "verif answer": "15", "anno approach": "wiki, concept, image", "verif wiki answer": "35(0.5150)", "verif concept answer": "35(0.5356)", "verif image answer": "50(0.7199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000156510.jpg"}, {"question": "what is front of this horse", "gt answer": "door(1.00)<br/>gate(1.00)<br/>stall(0.60)", "pred answer": "bridle", "question_id": 4804645, "best approach": "wiki, concept", "verif answer": "fence", "anno approach": "wiki, concept, image", "verif wiki answer": "door(0.7213)", "verif concept answer": "door(0.6888)", "verif image answer": "stall(0.6936)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480464.jpg"}, {"question": "what made these tracks", "gt answer": "4 wheeler(1.00)<br/>truck(1.00)<br/>vehicle(0.60)", "pred answer": "gravity", "question_id": 1452905, "best approach": "wiki, concept", "verif answer": "vehicle", "anno approach": "wiki, concept, image", "verif wiki answer": "vehicle(0.5387)", "verif concept answer": "vehicle(0.5420)", "verif image answer": "atv(0.6605)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145290.jpg"}, {"question": "what is this room used for", "gt answer": "relax(1.00)", "pred answer": "read", "question_id": 2351765, "best approach": "concept", "verif answer": "relax", "anno approach": "wiki, concept, image", "verif wiki answer": "rest(0.5271)", "verif concept answer": "relax(0.5396)", "verif image answer": "bath(0.5961)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000235176.jpg"}, {"question": "did the batter hit a home run or foul ball", "gt answer": "home run(1.00)<br/>run(0.60)", "pred answer": "homerun", "question_id": 5654435, "best approach": "wiki, concept, image", "verif answer": "home run", "anno approach": "wiki, concept, image", "verif wiki answer": "home run(0.7306)", "verif concept answer": "home run(0.6975)", "verif image answer": "home run(0.7197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000565443.jpg"}, {"question": "would you say this is daytime or nighttime", "gt answer": "nighttime(1.00)<br/>even(0.60)<br/>daytime(0.60)", "pred answer": "night", "question_id": 774555, "best approach": "image", "verif answer": "night", "anno approach": "wiki, concept, image", "verif wiki answer": "morn(0.6351)", "verif concept answer": "night(0.6943)", "verif image answer": "nighttime(0.7108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077455.jpg"}, {"question": "what event is this", "gt answer": "horse show(1.00)<br/>horse race(0.60)", "pred answer": "race", "question_id": 1327605, "best approach": "wiki, concept, image", "verif answer": "horse show", "anno approach": "wiki, concept, image", "verif wiki answer": "horse race(0.6802)", "verif concept answer": "horse race(0.7098)", "verif image answer": "horse race(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000132760.jpg"}, {"question": "does a southpaw batter grip the bat with his left hand or right hand on top", "gt answer": "left(1.00)<br/>baseball(0.60)", "pred answer": "right", "question_id": 1033385, "best approach": "wiki, concept, image", "verif answer": "left", "anno approach": "wiki, concept, image", "verif wiki answer": "left(0.5340)", "verif concept answer": "left(0.5999)", "verif image answer": "left(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103338.jpg"}, {"question": "what desserts can be made with these", "gt answer": "apple pie(1.00)<br/>pie(1.00)", "pred answer": "doughnut", "question_id": 4620715, "best approach": "wiki, concept", "verif answer": "cheesecake", "anno approach": "wiki, concept, image", "verif wiki answer": "apple pie(0.7259)", "verif concept answer": "apple pie(0.7034)", "verif image answer": "cheesecake(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000462071.jpg"}, {"question": "what is something you might do at that place", "gt answer": "swim(1.00)<br/>surf(0.60)", "pred answer": "tan", "question_id": 4703545, "best approach": "wiki, concept", "verif answer": "swim", "anno approach": "wiki, concept, image", "verif wiki answer": "swim(0.7153)", "verif concept answer": "swim(0.6924)", "verif image answer": "sunbath(0.6979)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470354.jpg"}, {"question": "which rodent has a similar name to the technical device seen", "gt answer": "mouse(1.00)", "pred answer": "dell", "question_id": 3237655, "best approach": "wiki, concept", "verif answer": "cat", "anno approach": "wiki, concept, image", "verif wiki answer": "mouse(0.5238)", "verif concept answer": "mouse(0.5307)", "verif image answer": "mice(0.6808)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323765.jpg"}, {"question": "what is the name of a person who tends to these animals", "gt answer": "shepherd(1.00)<br/>sheep herder(0.60)", "pred answer": "farmer", "question_id": 1221375, "best approach": "wiki, image", "verif answer": "farmer", "anno approach": "wiki, concept, image", "verif wiki answer": "shepherd(0.6346)", "verif concept answer": "farmer(0.6822)", "verif image answer": "shepherd(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122137.jpg"}, {"question": "what fruit is shown in the picture", "gt answer": "grape(1.00)", "pred answer": "apple", "question_id": 1347555, "best approach": "", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "apple(0.6611)", "verif concept answer": "apple(0.7012)", "verif image answer": "wine(0.6883)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134755.jpg"}, {"question": "how long does it take someone to go to school for this profession", "gt answer": "4 years(1.00)<br/>2 years(0.60)<br/>3 years(0.60)<br/>1 year(0.60)", "pred answer": "1 hour", "question_id": 5159175, "best approach": "image", "verif answer": "1 year", "anno approach": "wiki, concept, image", "verif wiki answer": "1 year(0.5924)", "verif concept answer": "1 year(0.5440)", "verif image answer": "4 years(0.7142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515917.jpg"}, {"question": "mention a place in the world where this transport is in use", "gt answer": "pennsylvania(1.00)<br/>texas(0.60)", "pred answer": "us", "question_id": 4807765, "best approach": "wiki, concept, image", "verif answer": "florida", "anno approach": "wiki, concept, image", "verif wiki answer": "pennsylvania(0.5828)", "verif concept answer": "pennsylvania(0.6000)", "verif image answer": "pennsylvania(0.7088)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480776.jpg"}, {"question": "what mobile device are they using", "gt answer": "cell phone(1.00)<br/>iphones(0.60)", "pred answer": "phone", "question_id": 2391445, "best approach": "wiki", "verif answer": "cell phone", "anno approach": "wiki, concept, image", "verif wiki answer": "iphones(0.5519)", "verif concept answer": "1973(0.5804)", "verif image answer": "1973(0.7116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000239144.jpg"}, {"question": "even though the sky is grey we know the sun is out because of what item that we can see on the concrete", "gt answer": "shadow(1.00)", "pred answer": "sunscreen", "question_id": 1778455, "best approach": "wiki", "verif answer": "sunset", "anno approach": "wiki, concept, image", "verif wiki answer": "shadow(0.6781)", "verif concept answer": "sunset(0.5569)", "verif image answer": "reflection(0.6814)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177845.jpg"}, {"question": "what do you do in this room", "gt answer": "urinate(1.00)", "pred answer": "poop", "question_id": 195815, "best approach": "wiki, concept", "verif answer": "poop", "anno approach": "wiki, concept, image", "verif wiki answer": "urinate(0.6529)", "verif concept answer": "urinate(0.6621)", "verif image answer": "poop(0.6228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019581.jpg"}, {"question": "who made the trailer being towed by the motorcycle", "gt answer": "harley davidson(1.00)", "pred answer": "chevy", "question_id": 3826885, "best approach": "concept", "verif answer": "bmw", "anno approach": "wiki, concept, image", "verif wiki answer": "honda(0.5650)", "verif concept answer": "harley davidson(0.6110)", "verif image answer": "bmw(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382688.jpg"}, {"question": "what brand of truck is this", "gt answer": "kenworth(1.00)<br/>ford(0.60)", "pred answer": "chevrolet", "question_id": 2108615, "best approach": "wiki", "verif answer": "ford", "anno approach": "wiki, concept, image", "verif wiki answer": "kenworth(0.6659)", "verif concept answer": "ford(0.6001)", "verif image answer": "ford(0.6941)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210861.jpg"}, {"question": "who is the co founder of the company of this laptop who passed away in 2011", "gt answer": "steve job(1.00)", "pred answer": "apple", "question_id": 5681555, "best approach": "", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "thomas edison(0.6609)", "verif concept answer": "apple(0.6326)", "verif image answer": "thomas edison(0.6218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568155.jpg"}, {"question": "is the boy swimming or doing another water activity", "gt answer": "another activity(1.00)<br/>wakeboarding(0.60)<br/>fish(0.60)<br/>surf(0.60)", "pred answer": "swim", "question_id": 4789035, "best approach": "image", "verif answer": "wakeboarding", "anno approach": "wiki, concept, image", "verif wiki answer": "wakeboarding(0.5540)", "verif concept answer": "boogie board(0.5419)", "verif image answer": "another activity(0.6653)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478903.jpg"}, {"question": "based on the image on the screen what kind of science project is the person working on", "gt answer": "chemistry(1.00)", "pred answer": "study", "question_id": 2177075, "best approach": "", "verif answer": "dell", "anno approach": "wiki, concept, image", "verif wiki answer": "mechanical(0.7302)", "verif concept answer": "fraction(0.7176)", "verif image answer": "mechanical(0.7276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217707.jpg"}, {"question": "when people are forced to walk they often say they are doing what which is a term which sounds like this animal 's feet", "gt answer": "hoof it(1.00)<br/>march(0.60)", "pred answer": "horseback ride", "question_id": 4796205, "best approach": "wiki, concept", "verif answer": "horse ride", "anno approach": "wiki, concept, image", "verif wiki answer": "march(0.5979)", "verif concept answer": "march(0.5215)", "verif image answer": "horse ride(0.6598)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479620.jpg"}, {"question": "what is the atomic symbol for the element on the ground", "gt answer": "h2o(1.00)", "pred answer": "fire", "question_id": 4537045, "best approach": "", "verif answer": "sun", "anno approach": "wiki, concept, image", "verif wiki answer": "sun(0.6899)", "verif concept answer": "sun(0.7068)", "verif image answer": "salt(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453704.jpg"}, {"question": "what type of work happens here", "gt answer": "pilot(1.00)<br/>transportation(0.60)", "pred answer": "boat", "question_id": 682315, "best approach": "image", "verif answer": "military", "anno approach": "wiki, concept, image", "verif wiki answer": "transportation(0.6868)", "verif concept answer": "transportation(0.7080)", "verif image answer": "pilot(0.6522)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068231.jpg"}, {"question": "what kind of dessert is this", "gt answer": "cake(1.00)", "pred answer": "cheesecake", "question_id": 1925815, "best approach": "wiki, concept", "verif answer": "cake", "anno approach": "wiki, concept, image", "verif wiki answer": "cake(0.7258)", "verif concept answer": "cake(0.6748)", "verif image answer": "bread(0.7046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000192581.jpg"}, {"question": "what is the wingspan of these birds", "gt answer": "1 foot(1.00)<br/>12 inches(0.60)<br/>6 inches(0.60)", "pred answer": "15 years", "question_id": 1984065, "best approach": "wiki, concept", "verif answer": "8 inches", "anno approach": "wiki, concept, image", "verif wiki answer": "6 inches(0.6146)", "verif concept answer": "12 inches(0.6770)", "verif image answer": "8 inches(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198406.jpg"}, {"question": "what brand is this bike", "gt answer": "triumph(1.00)", "pred answer": "harley davidson", "question_id": 3686455, "best approach": "wiki", "verif answer": "harley davidson", "anno approach": "wiki, concept, image", "verif wiki answer": "triumph(0.6434)", "verif concept answer": "harley davidson(0.5865)", "verif image answer": "harley davidson(0.6577)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000368645.jpg"}, {"question": "what brand of car is this", "gt answer": "volkswagen(1.00)<br/>volkswagon(0.60)<br/>vw(0.60)", "pred answer": "ford", "question_id": 3742825, "best approach": "image", "verif answer": "volkswagen", "anno approach": "wiki, concept, image", "verif wiki answer": "vw(0.6393)", "verif concept answer": "vw(0.6576)", "verif image answer": "volkswagen(0.7194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374282.jpg"}, {"question": "what company has their logo on thes cups", "gt answer": "nestea(1.00)<br/>dixie(0.60)", "pred answer": "pepsi", "question_id": 1968885, "best approach": "", "verif answer": "kraft", "anno approach": "wiki, concept, image", "verif wiki answer": "200 years(0.5110)", "verif concept answer": "kraft(0.6361)", "verif image answer": "200 years(0.5685)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196888.jpg"}, {"question": "what is the percentage of people in america that have this animal as a pet", "gt answer": "40(1.00)<br/>35(0.60)<br/>20(0.60)", "pred answer": "80", "question_id": 4351025, "best approach": "wiki, concept", "verif answer": "35", "anno approach": "wiki, concept, image", "verif wiki answer": "35(0.6386)", "verif concept answer": "35(0.6780)", "verif image answer": "21(0.7130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435102.jpg"}, {"question": "what movie has a song about flying these", "gt answer": "mary poppins(1.00)<br/>chicago(0.60)", "pred answer": "baywatch", "question_id": 4284775, "best approach": "image", "verif answer": "mary poppins", "anno approach": "wiki, concept, image", "verif wiki answer": "san francisco(0.5023)", "verif concept answer": "san francisco(0.5200)", "verif image answer": "mary poppins(0.5596)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428477.jpg"}, {"question": "what level spf do i need to wear while skiing", "gt answer": "15(1.00)<br/>50(0.60)<br/>30(0.60)", "pred answer": "professional", "question_id": 872145, "best approach": "image", "verif answer": "50", "anno approach": "wiki, concept, image", "verif wiki answer": "20(0.5035)", "verif concept answer": "20(0.5090)", "verif image answer": "50(0.6244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087214.jpg"}, {"question": "what sport are they playing", "gt answer": "volleyball(1.00)", "pred answer": "wind surf", "question_id": 4815065, "best approach": "wiki, concept", "verif answer": "volleyball", "anno approach": "wiki, concept, image", "verif wiki answer": "volleyball(0.7135)", "verif concept answer": "volleyball(0.7221)", "verif image answer": "badminton(0.7191)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481506.jpg"}, {"question": "which kind of aeroplane is shown in this photo", "gt answer": "airbus(1.00)<br/>boeing(0.60)<br/>airplane(0.60)<br/>jet(0.60)", "pred answer": "boeing 747", "question_id": 651355, "best approach": "concept", "verif answer": "airplane", "anno approach": "wiki, concept, image", "verif wiki answer": "jet(0.5765)", "verif concept answer": "airbus(0.5130)", "verif image answer": "boeing(0.6693)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065135.jpg"}, {"question": "what type of bird is this", "gt answer": "pigeon(1.00)<br/>white(0.60)", "pred answer": "pelican", "question_id": 3789775, "best approach": "wiki, concept, image", "verif answer": "pigeon", "anno approach": "wiki, concept, image", "verif wiki answer": "pigeon(0.6563)", "verif concept answer": "pigeon(0.7262)", "verif image answer": "pigeon(0.6892)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378977.jpg"}, {"question": "which fork do you eat main entree with", "gt answer": "right fork(1.00)<br/>larger(0.60)<br/>fork(0.60)", "pred answer": "spoon", "question_id": 581535, "best approach": "wiki", "verif answer": "fork", "anno approach": "wiki, concept, image", "verif wiki answer": "right fork(0.7173)", "verif concept answer": "larger(0.6953)", "verif image answer": "larger(0.7273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058153.jpg"}, {"question": "what plant is this", "gt answer": "lettuce(1.00)<br/>pumpkin(0.60)", "pred answer": "broccoli", "question_id": 3635705, "best approach": "", "verif answer": "broccoli", "anno approach": "wiki, concept, image", "verif wiki answer": "broccoli(0.6965)", "verif concept answer": "broccoli(0.6996)", "verif image answer": "broccoli(0.6911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363570.jpg"}, {"question": "what command should i use to get this animal away from the tv", "gt answer": "move(1.00)<br/>down(0.60)", "pred answer": "bark", "question_id": 3185945, "best approach": "", "verif answer": "gallop", "anno approach": "wiki, concept, image", "verif wiki answer": "on(0.5000)", "verif concept answer": "on(0.5001)", "verif image answer": "gallop(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318594.jpg"}, {"question": "what brand of sofa is on the right wall", "gt answer": "ashley(1.00)<br/>ikea(0.60)", "pred answer": "dupont", "question_id": 2017385, "best approach": "", "verif answer": "ikea", "anno approach": "wiki, concept, image", "verif wiki answer": "theodore roosevelt(0.7209)", "verif concept answer": "theodore roosevelt(0.7297)", "verif image answer": "theodore roosevelt(0.6683)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201738.jpg"}, {"question": "what kind of trucks are these", "gt answer": "tractor trailer(1.00)<br/>tractor(0.60)<br/>semi(0.60)", "pred answer": "dump", "question_id": 4670715, "best approach": "image", "verif answer": "tow", "anno approach": "wiki, concept, image", "verif wiki answer": "tow(0.6977)", "verif concept answer": "tow(0.6441)", "verif image answer": "semi(0.5797)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467071.jpg"}, {"question": "what website is displayed", "gt answer": "youtube(1.00)<br/>facebook(0.60)", "pred answer": "picture", "question_id": 5068085, "best approach": "image", "verif answer": "youtube", "anno approach": "wiki, concept, image", "verif wiki answer": "flickr(0.6137)", "verif concept answer": "flickr(0.7203)", "verif image answer": "youtube(0.6371)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506808.jpg"}, {"question": "what material is the knife made of", "gt answer": "metal(1.00)<br/>steel(0.60)<br/>silver(0.60)", "pred answer": "stainless steel", "question_id": 3517965, "best approach": "wiki", "verif answer": "silver", "anno approach": "wiki, concept, image", "verif wiki answer": "steel(0.6824)", "verif concept answer": "bronze(0.7167)", "verif image answer": "bronze(0.7213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351796.jpg"}, {"question": "what is the man wearing", "gt answer": "hat(1.00)<br/>beanie(0.60)", "pred answer": "cap", "question_id": 4589605, "best approach": "wiki, concept, image", "verif answer": "beanie", "anno approach": "wiki, concept, image", "verif wiki answer": "beanie(0.7072)", "verif concept answer": "beanie(0.7289)", "verif image answer": "beanie(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458960.jpg"}, {"question": "what item seen here might be used to identify this animal if lost", "gt answer": "collar(0.60)<br/>tag(1.00)", "pred answer": "leash", "question_id": 102485, "best approach": "concept", "verif answer": "tag", "anno approach": "wiki, concept, image", "verif wiki answer": "accident(0.5252)", "verif concept answer": "tag(0.5016)", "verif image answer": "accident(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000010248.jpg"}, {"question": "", "gt answer": "power(0.60)<br/>metal(0.60)<br/>electric(0.60)<br/>phone(0.60)<br/>electrical(0.60)", "pred answer": "telephone", "question_id": 2737105, "best approach": "wiki, concept, image", "verif answer": "power", "anno approach": "wiki, concept, image", "verif wiki answer": "electrical(0.5486)", "verif concept answer": "phone(0.5664)", "verif image answer": "power(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273710.jpg"}, {"question": "how do you score points in this game", "gt answer": "point(0.60)<br/>serve(0.60)<br/>hit ball(1.00)", "pred answer": "goal", "question_id": 5606305, "best approach": "wiki, concept, image", "verif answer": "point", "anno approach": "wiki, concept, image", "verif wiki answer": "point(0.7112)", "verif concept answer": "point(0.7164)", "verif image answer": "point(0.7218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560630.jpg"}, {"question": "in what media format are the movies and television shows seen here recorded", "gt answer": "dvd(1.00)<br/>adult(0.60)", "pred answer": "picture", "question_id": 1127855, "best approach": "wiki, concept, image", "verif answer": "dvd", "anno approach": "wiki, concept, image", "verif wiki answer": "adult(0.6253)", "verif concept answer": "adult(0.6731)", "verif image answer": "adult(0.6695)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000112785.jpg"}, {"question": "what activity is this", "gt answer": "horse race(1.00)<br/>race(0.60)<br/>chariot race(0.60)", "pred answer": "cycling", "question_id": 77585, "best approach": "image", "verif answer": "horse race", "anno approach": "wiki, concept, image", "verif wiki answer": "race(0.6396)", "verif concept answer": "dog show(0.6512)", "verif image answer": "horse race(0.6657)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007758.jpg"}, {"question": "in what era did this sport begin", "gt answer": "medieval(1.00)<br/>1920's(0.60)", "pred answer": "1800s", "question_id": 5773625, "best approach": "concept, image", "verif answer": "1940's", "anno approach": "wiki, concept, image", "verif wiki answer": "1940's(0.5326)", "verif concept answer": "medieval(0.5210)", "verif image answer": "medieval(0.7246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000577362.jpg"}, {"question": "how do we know this is not a modern train", "gt answer": "steam engine(1.00)", "pred answer": "engine", "question_id": 3149435, "best approach": "", "verif answer": "track", "anno approach": "wiki, concept, image", "verif wiki answer": "steam(0.5348)", "verif concept answer": "steam(0.5254)", "verif image answer": "commuter(0.7076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314943.jpg"}, {"question": "how many gallons of water can the tub in the image hold", "gt answer": "50(1.00)<br/>200(0.60)<br/>100(0.60)", "pred answer": "30", "question_id": 452045, "best approach": "concept", "verif answer": "50", "anno approach": "wiki, concept, image", "verif wiki answer": "fifty(0.7255)", "verif concept answer": "50(0.6116)", "verif image answer": "100(0.6789)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045204.jpg"}, {"question": "why type of stuffed animal is she holding", "gt answer": "lizard(1.00)", "pred answer": "bear", "question_id": 1956775, "best approach": "concept", "verif answer": "bear", "anno approach": "wiki, concept, image", "verif wiki answer": "bear(0.7279)", "verif concept answer": "lizard(0.6746)", "verif image answer": "levis(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195677.jpg"}, {"question": "what type of pavement is the bus traveling on", "gt answer": "cement(1.00)<br/>concrete(1.00)<br/>stone(0.60)", "pred answer": "asphalt", "question_id": 4880115, "best approach": "image", "verif answer": "asphalt", "anno approach": "wiki, concept, image", "verif wiki answer": "asphalt(0.7305)", "verif concept answer": "asphalt(0.6981)", "verif image answer": "concrete(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488011.jpg"}, {"question": "how much does the appliance pictured typically cost", "gt answer": "$500(1.00)", "pred answer": "$40", "question_id": 1169445, "best approach": "wiki, concept", "verif answer": "2 dollars", "anno approach": "wiki, concept, image", "verif wiki answer": "$500(0.6812)", "verif concept answer": "$500(0.6945)", "verif image answer": "10000(0.7065)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116944.jpg"}, {"question": "what kind of trick is the skateboarder performing", "gt answer": "wall(1.00)<br/>ollie(0.60)<br/>semi(0.60)", "pred answer": "jump", "question_id": 1970015, "best approach": "", "verif answer": "jump", "anno approach": "wiki, concept, image", "verif wiki answer": "grind(0.6782)", "verif concept answer": "grind(0.6755)", "verif image answer": "grind(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197001.jpg"}, {"question": "what instrument is being played", "gt answer": "violin(1.00)", "pred answer": "piano", "question_id": 3241035, "best approach": "", "verif answer": "violin", "anno approach": "wiki, concept, image", "verif wiki answer": "mandolin(0.7307)", "verif concept answer": "mandolin(0.7236)", "verif image answer": "mandolin(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324103.jpg"}, {"question": "what is he holding", "gt answer": "game control(1.00)<br/>ipod(0.60)", "pred answer": "wii", "question_id": 2494555, "best approach": "concept, image", "verif answer": "video game", "anno approach": "wiki, concept, image", "verif wiki answer": "video game(0.7248)", "verif concept answer": "ipod(0.7277)", "verif image answer": "ipod(0.7171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249455.jpg"}, {"question": "what is this maneuver called", "gt answer": "grind(1.00)", "pred answer": "snowboard", "question_id": 4637155, "best approach": "concept", "verif answer": "jump", "anno approach": "wiki, concept, image", "verif wiki answer": "kickflip(0.6510)", "verif concept answer": "grind(0.6071)", "verif image answer": "kickflip(0.6837)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463715.jpg"}, {"question": "what industry is this useful for", "gt answer": "farm(1.00)<br/>horse race(0.60)<br/>lumber(0.60)", "pred answer": "construction", "question_id": 1946695, "best approach": "concept, image", "verif answer": "transport", "anno approach": "wiki, concept, image", "verif wiki answer": "transport(0.6955)", "verif concept answer": "lumber(0.6209)", "verif image answer": "horse race(0.6107)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194669.jpg"}, {"question": "is the beach sandy or rocky", "gt answer": "sandy(1.00)", "pred answer": "wet", "question_id": 4175715, "best approach": "wiki, concept, image", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "sandy(0.5001)", "verif concept answer": "sandy(0.5004)", "verif image answer": "sandy(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417571.jpg"}, {"question": "where is the bus in this photo going", "gt answer": "villa adelina chacarita(1.00)", "pred answer": "downtown", "question_id": 1958105, "best approach": "wiki, concept", "verif answer": "downtown", "anno approach": "wiki, concept, image", "verif wiki answer": "villa adelina chacarita(0.6752)", "verif concept answer": "villa adelina chacarita(0.7152)", "verif image answer": "first base(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195810.jpg"}, {"question": "how can these scissors be a danger", "gt answer": "stab(1.00)<br/>sharp(0.60)", "pred answer": "safe", "question_id": 591575, "best approach": "wiki, concept, image", "verif answer": "music", "anno approach": "wiki, concept, image", "verif wiki answer": "stab(0.6442)", "verif concept answer": "stab(0.6207)", "verif image answer": "stab(0.5621)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059157.jpg"}, {"question": "what is on the mans ear", "gt answer": "bluetooth(1.00)", "pred answer": "glass", "question_id": 844895, "best approach": "wiki, concept", "verif answer": "bluetooth", "anno approach": "wiki, concept, image", "verif wiki answer": "bluetooth(0.6088)", "verif concept answer": "bluetooth(0.6877)", "verif image answer": "cord(0.5207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084489.jpg"}, {"question": "what city are these fans rooting for", "gt answer": "chicago(1.00)", "pred answer": "philadelphia", "question_id": 4529635, "best approach": "concept", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "los angeles(0.5961)", "verif concept answer": "chicago(0.7055)", "verif image answer": "new york(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000452963.jpg"}, {"question": "what is the name of the large cat of the same colour", "gt answer": "panther(1.00)<br/>bombay(0.60)", "pred answer": "domestic", "question_id": 5367385, "best approach": "", "verif answer": "domestic", "anno approach": "wiki, concept, image", "verif wiki answer": "domestic(0.5552)", "verif concept answer": "domesticated(0.5730)", "verif image answer": "domestic(0.5618)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536738.jpg"}, {"question": "what branch of the military flies this aircraft", "gt answer": "air force(1.00)<br/>army(0.60)<br/>airforce(0.60)", "pred answer": "navy", "question_id": 2282265, "best approach": "wiki, image", "verif answer": "air force", "anno approach": "wiki, concept, image", "verif wiki answer": "air force(0.6495)", "verif concept answer": "ww2(0.5785)", "verif image answer": "air force(0.6735)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000228226.jpg"}, {"question": "what breed of cat is this", "gt answer": "tabby(1.00)<br/>american shorthair(0.60)<br/>mixed(0.60)", "pred answer": "persian", "question_id": 4337865, "best approach": "", "verif answer": "persian", "anno approach": "wiki, concept, image", "verif wiki answer": "domestic shorthair(0.6968)", "verif concept answer": "domestic shorthair(0.7205)", "verif image answer": "persian(0.7004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433786.jpg"}, {"question": "why is the animal wearing this", "gt answer": "ride(1.00)", "pred answer": "warmth", "question_id": 4589465, "best approach": "wiki, concept, image", "verif answer": "race", "anno approach": "wiki, concept, image", "verif wiki answer": "ride(0.6291)", "verif concept answer": "ride(0.6401)", "verif image answer": "ride(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458946.jpg"}, {"question": "name the brand of water bottle shown in this picture", "gt answer": "aquafina(1.00)", "pred answer": "sprite", "question_id": 5145135, "best approach": "image", "verif answer": "vodka", "anno approach": "wiki, concept, image", "verif wiki answer": "vodka(0.5642)", "verif concept answer": "vodka(0.6082)", "verif image answer": "aquafina(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514513.jpg"}, {"question": "what type of wood is used to manufacture the chairs shown in the image", "gt answer": "bamboo(1.00)<br/>wicker(1.00)<br/>cherry(0.60)", "pred answer": "oak", "question_id": 578705, "best approach": "concept, image", "verif answer": "oak", "anno approach": "wiki, concept, image", "verif wiki answer": "oak(0.7176)", "verif concept answer": "bamboo(0.6739)", "verif image answer": "bamboo(0.5336)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000057870.jpg"}, {"question": "are these cattle free or caged", "gt answer": "free(1.00)", "pred answer": "locked up", "question_id": 3116375, "best approach": "", "verif answer": "locked up", "anno approach": "wiki, concept, image", "verif wiki answer": "locked up(0.7083)", "verif concept answer": "locked up(0.6949)", "verif image answer": "locked up(0.6417)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311637.jpg"}, {"question": "are these male or females or both", "gt answer": "both(1.00)", "pred answer": "male", "question_id": 1369515, "best approach": "", "verif answer": "female", "anno approach": "wiki, concept, image", "verif wiki answer": "female(0.6527)", "verif concept answer": "female(0.6612)", "verif image answer": "female(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136951.jpg"}, {"question": "what are the statues for", "gt answer": "model(1.00)", "pred answer": "transportation", "question_id": 1945505, "best approach": "wiki, concept", "verif answer": "advertising", "anno approach": "wiki, concept, image", "verif wiki answer": "model(0.7271)", "verif concept answer": "model(0.5876)", "verif image answer": "advertising(0.6091)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194550.jpg"}, {"question": "in what religion do women wear this headcovering", "gt answer": "muslim(1.00)<br/>islam(0.60)", "pred answer": "christianity", "question_id": 4058425, "best approach": "", "verif answer": "hindu", "anno approach": "wiki, concept, image", "verif wiki answer": "catholic(0.7075)", "verif concept answer": "catholic(0.6608)", "verif image answer": "catholic(0.6939)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405842.jpg"}, {"question": "what is this man destination", "gt answer": "work(1.00)<br/>office(0.60)", "pred answer": "new york city", "question_id": 5408405, "best approach": "image", "verif answer": "office", "anno approach": "wiki, concept, image", "verif wiki answer": "meet(0.5150)", "verif concept answer": "meet(0.5019)", "verif image answer": "office(0.5766)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540840.jpg"}, {"question": "how much vitamim c does these have", "gt answer": "lot(1.00)", "pred answer": "500", "question_id": 762545, "best approach": "", "verif answer": "100 lbs", "anno approach": "wiki, concept, image", "verif wiki answer": "20 grams(0.6631)", "verif concept answer": "100 lbs(0.6520)", "verif image answer": "100 lbs(0.7190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076254.jpg"}, {"question": "what is a reason that an animal might wear that on his face", "gt answer": "prevent bite(1.00)", "pred answer": "sad", "question_id": 4442265, "best approach": "", "verif answer": "helmet", "anno approach": "wiki, concept, image", "verif wiki answer": "helmet(0.6012)", "verif concept answer": "helmet(0.6468)", "verif image answer": "helmet(0.6544)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000444226.jpg"}, {"question": "what is the owner of these items probably wearing", "gt answer": "coat(1.00)<br/>hat(0.60)<br/>boot(0.60)", "pred answer": "ski", "question_id": 4370935, "best approach": "concept", "verif answer": "beanie", "anno approach": "wiki, concept, image", "verif wiki answer": "beanie(0.5754)", "verif concept answer": "hat(0.6331)", "verif image answer": "beanie(0.7010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437093.jpg"}, {"question": "what do you call the red building in the background", "gt answer": "barn(1.00)", "pred answer": "house", "question_id": 4463455, "best approach": "wiki, concept", "verif answer": "barn", "anno approach": "wiki, concept, image", "verif wiki answer": "barn(0.7105)", "verif concept answer": "barn(0.7239)", "verif image answer": "stable(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000446345.jpg"}, {"question": "what genus and species is the cake shaped like", "gt answer": "ladybug(1.00)<br/>mushroom(0.60)", "pred answer": "mammal", "question_id": 1481765, "best approach": "image", "verif answer": "dolphin", "anno approach": "wiki, concept, image", "verif wiki answer": "dolphin(0.5693)", "verif concept answer": "scissor(0.5684)", "verif image answer": "mushroom(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148176.jpg"}, {"question": "how long in feet is the boat pictured here", "gt answer": "20(1.00)<br/>10(0.60)<br/>25(0.60)", "pred answer": "15 feet", "question_id": 3885005, "best approach": "wiki, concept", "verif answer": "20", "anno approach": "wiki, concept, image", "verif wiki answer": "20(0.6608)", "verif concept answer": "20(0.5627)", "verif image answer": "30(0.6649)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388500.jpg"}, {"question": "what is the childrens show that stars one of these", "gt answer": "thomas tank engine(1.00)", "pred answer": "clock", "question_id": 2837575, "best approach": "", "verif answer": "thomas train", "anno approach": "wiki, concept, image", "verif wiki answer": "thomas train(0.5446)", "verif concept answer": "thomas train(0.5245)", "verif image answer": "thomas train(0.5956)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283757.jpg"}, {"question": "what kind of dog is under the desk", "gt answer": "beagle(1.00)<br/>lab(0.60)<br/>chihuahua(0.60)", "pred answer": "labrador", "question_id": 2811945, "best approach": "wiki, image", "verif answer": "labrador", "anno approach": "wiki, concept, image", "verif wiki answer": "lab(0.5747)", "verif concept answer": "hound(0.5820)", "verif image answer": "lab(0.6163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281194.jpg"}, {"question": "what language is shown here", "gt answer": "japanese(1.00)<br/>chinese(1.00)", "pred answer": "english", "question_id": 4385145, "best approach": "concept", "verif answer": "japanese", "anno approach": "wiki, concept, image", "verif wiki answer": "fast food(0.5839)", "verif concept answer": "japanese(0.7174)", "verif image answer": "korean(0.7114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000438514.jpg"}, {"question": "what type of device is this", "gt answer": "boombox(1.00)<br/>radio(0.60)", "pred answer": "remote", "question_id": 2218655, "best approach": "", "verif answer": "radio", "anno approach": "wiki, concept, image", "verif wiki answer": "speaker(0.7219)", "verif concept answer": "speaker(0.7120)", "verif image answer": "laptop(0.6934)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221865.jpg"}, {"question": "why is the truck indoors", "gt answer": "truck show(1.00)", "pred answer": "parked", "question_id": 1576425, "best approach": "image", "verif answer": "internet", "anno approach": "wiki, concept, image", "verif wiki answer": "internet(0.5788)", "verif concept answer": "internet(0.5418)", "verif image answer": "truck show(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157642.jpg"}, {"question": "what type of shape is the object the people are holding", "gt answer": "oval(1.00)<br/>fish(0.60)<br/>rectangle(0.60)", "pred answer": "circle", "question_id": 1499965, "best approach": "wiki, concept, image", "verif answer": "rectangle", "anno approach": "wiki, concept, image", "verif wiki answer": "rectangle(0.5015)", "verif concept answer": "rectangle(0.5034)", "verif image answer": "rectangle(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149996.jpg"}, {"question": "what vitamins does this fruit provide", "gt answer": "calcium(1.00)<br/>potassium(0.60)", "pred answer": "vitamin c", "question_id": 2835455, "best approach": "", "verif answer": "potassium", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin k(0.7019)", "verif concept answer": "vitamin k(0.6094)", "verif image answer": "vitamin k(0.7074)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283545.jpg"}, {"question": "where is this station located", "gt answer": "netherlands(1.00)<br/>london(0.60)<br/>city(0.60)<br/>new york(0.60)", "pred answer": "train station", "question_id": 60755, "best approach": "wiki, concept, image", "verif answer": "city", "anno approach": "wiki, concept, image", "verif wiki answer": "london(0.6828)", "verif concept answer": "city(0.7112)", "verif image answer": "new york(0.7189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006075.jpg"}, {"question": "is there a grazing animal that has a name similar to one of these pets", "gt answer": "bull(1.00)<br/>cow(0.60)", "pred answer": "dog", "question_id": 1142695, "best approach": "wiki", "verif answer": "cow", "anno approach": "wiki, concept, image", "verif wiki answer": "bull(0.5967)", "verif concept answer": "cow(0.5517)", "verif image answer": "dairy(0.5014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114269.jpg"}, {"question": "what kind of houseplant is this", "gt answer": "palm(1.00)<br/>tree(1.00)", "pred answer": "succulent", "question_id": 1986215, "best approach": "wiki, concept", "verif answer": "tree", "anno approach": "wiki, concept, image", "verif wiki answer": "tree(0.7184)", "verif concept answer": "tree(0.6545)", "verif image answer": "palm tree(0.7219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198621.jpg"}, {"question": "what are these skiers waiting in line for", "gt answer": "lift(1.00)<br/>turn(0.60)<br/>ski lift(0.60)<br/>race(0.60)", "pred answer": "ski", "question_id": 3278205, "best approach": "wiki, concept", "verif answer": "ski lift", "anno approach": "wiki, concept, image", "verif wiki answer": "ski lift(0.6775)", "verif concept answer": "race(0.6439)", "verif image answer": "skier(0.6131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327820.jpg"}, {"question": "what type of lighting was usued for this picture", "gt answer": "flash(1.00)<br/>dim(0.60)<br/>lamp(0.60)", "pred answer": "fluorescent", "question_id": 4639035, "best approach": "", "verif answer": "overhead", "anno approach": "wiki, concept, image", "verif wiki answer": "overhead(0.6905)", "verif concept answer": "overhead(0.6923)", "verif image answer": "street light(0.6577)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463903.jpg"}, {"question": "how are these festive lights held in place", "gt answer": "string(1.00)<br/>rope(0.60)", "pred answer": "light", "question_id": 3453315, "best approach": "", "verif answer": "strap", "anno approach": "wiki, concept, image", "verif wiki answer": "strap(0.7210)", "verif concept answer": "strap(0.7149)", "verif image answer": "strap(0.6329)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345331.jpg"}, {"question": "what is a wild animal that belongs to the same family as this animal", "gt answer": "tiger(1.00)", "pred answer": "feline", "question_id": 478485, "best approach": "concept", "verif answer": "lion", "anno approach": "wiki, concept, image", "verif wiki answer": "lion(0.7253)", "verif concept answer": "tiger(0.6101)", "verif image answer": "puma(0.6857)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047848.jpg"}, {"question": "what is in the brown bowl", "gt answer": "sausage(1.00)<br/>meat(0.60)", "pred answer": "tea", "question_id": 5349255, "best approach": "wiki, concept", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "meat(0.5573)", "verif concept answer": "meat(0.7102)", "verif image answer": "beef(0.5272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534925.jpg"}, {"question": "the catcher is trowing the ball where", "gt answer": "pitcher(1.00)<br/>home(0.60)", "pred answer": "first base", "question_id": 2367605, "best approach": "", "verif answer": "catcher", "anno approach": "wiki, concept, image", "verif wiki answer": "catcher(0.7060)", "verif concept answer": "mike trout(0.6795)", "verif image answer": "catcher(0.7049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236760.jpg"}, {"question": "what types of seasonings are on the table", "gt answer": "salt and pepper(1.00)<br/>salt(1.00)", "pred answer": "pepper", "question_id": 4833055, "best approach": "wiki", "verif answer": "fondant", "anno approach": "wiki, concept, image", "verif wiki answer": "salt(0.6392)", "verif concept answer": "fondant(0.7157)", "verif image answer": "fondant(0.6153)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483305.jpg"}, {"question": "at what temperature should this food be baked", "gt answer": "350(1.00)<br/>350 degrees(0.60)<br/>medium(0.60)", "pred answer": "165", "question_id": 3838415, "best approach": "wiki", "verif answer": "165", "anno approach": "wiki, concept, image", "verif wiki answer": "medium(0.6599)", "verif concept answer": "$350(0.5901)", "verif image answer": "$350(0.6905)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383841.jpg"}, {"question": "what makeup product is the woman wearing on her lips", "gt answer": "lipstick(1.00)", "pred answer": "toothbrush", "question_id": 291455, "best approach": "", "verif answer": "mascara", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin(0.5507)", "verif concept answer": "vitamin(0.5395)", "verif image answer": "mascara(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029145.jpg"}, {"question": "bench surrounded by", "gt answer": "tree(1.00)<br/>palm(0.60)", "pred answer": "wood", "question_id": 326395, "best approach": "image", "verif answer": "umbrella", "anno approach": "wiki, concept, image", "verif wiki answer": "umbrella(0.5500)", "verif concept answer": "umbrella(0.6429)", "verif image answer": "palm(0.6273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032639.jpg"}, {"question": "what type of cat is in the picture", "gt answer": "angry(1.00)<br/>domestic(0.60)", "pred answer": "persian", "question_id": 5565545, "best approach": "wiki, image", "verif answer": "persian", "anno approach": "wiki, concept, image", "verif wiki answer": "domestic(0.6800)", "verif concept answer": "persian(0.6843)", "verif image answer": "domestic(0.6969)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556554.jpg"}, {"question": "what is the man in black 's job", "gt answer": "umpire(1.00)", "pred answer": "catcher", "question_id": 4024075, "best approach": "", "verif answer": "catcher", "anno approach": "wiki, concept, image", "verif wiki answer": "catcher(0.5869)", "verif concept answer": "catcher(0.6282)", "verif image answer": "catcher(0.5648)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402407.jpg"}, {"question": "what restaurant is this couple dining in", "gt answer": "fast food(1.00)<br/>japanese(0.60)<br/>chinese(0.60)", "pred answer": "diner", "question_id": 2793455, "best approach": "wiki, concept", "verif answer": "fast food", "anno approach": "wiki, concept, image", "verif wiki answer": "fast food(0.5514)", "verif concept answer": "fast food(0.6163)", "verif image answer": "asian(0.6443)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000279345.jpg"}, {"question": "what is the circular object in the center of the room used for", "gt answer": "heat(1.00)<br/>heater(0.60)<br/>trash(0.60)", "pred answer": "storage", "question_id": 1838275, "best approach": "wiki, concept", "verif answer": "heat", "anno approach": "wiki, concept, image", "verif wiki answer": "heat(0.7292)", "verif concept answer": "heat(0.7165)", "verif image answer": "heater(0.7049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183827.jpg"}, {"question": "what is used for washing in this picture", "gt answer": "soap(1.00)<br/>sink(0.60)<br/>toothpaste(0.60)", "pred answer": "water", "question_id": 4284865, "best approach": "wiki", "verif answer": "soap", "anno approach": "wiki, concept, image", "verif wiki answer": "soap(0.5696)", "verif concept answer": "dish soap(0.5254)", "verif image answer": "dish soap(0.6122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428486.jpg"}, {"question": "what staple food is normally stored in this cylindrical buildings", "gt answer": "corn(1.00)<br/>grain(1.00)", "pred answer": "bread", "question_id": 3655235, "best approach": "image", "verif answer": "grain", "anno approach": "wiki, concept, image", "verif wiki answer": "oil(0.5970)", "verif concept answer": "oil(0.5557)", "verif image answer": "grain(0.6870)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365523.jpg"}, {"question": "which type not brand of television is this", "gt answer": "crt(1.00)<br/>sony(0.60)", "pred answer": "samsung", "question_id": 1352785, "best approach": "wiki, concept", "verif answer": "sony", "anno approach": "wiki, concept, image", "verif wiki answer": "crt(0.6320)", "verif concept answer": "crt(0.5246)", "verif image answer": "ibm(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000135278.jpg"}, {"question": "what sort of machine is shown in front of the vehicles", "gt answer": "park meter(1.00)", "pred answer": "truck", "question_id": 5458325, "best approach": "wiki, image", "verif answer": "park meter", "anno approach": "wiki, concept, image", "verif wiki answer": "park meter(0.5427)", "verif concept answer": "coin(0.5104)", "verif image answer": "park meter(0.5543)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545832.jpg"}, {"question": "what vitamin is this vegetable associated with", "gt answer": "(1.00)", "pred answer": "vitamin", "question_id": 479525, "best approach": "", "verif answer": "vitamin k", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin k(0.7117)", "verif concept answer": "vitamin(0.6641)", "verif image answer": "vitamin k(0.6754)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047952.jpg"}, {"question": "what is the name of the skiing object that child is sitting on", "gt answer": "sled(1.00)", "pred answer": "ski", "question_id": 3962125, "best approach": "image", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "snowboarder(0.7231)", "verif concept answer": "surfboard(0.6878)", "verif image answer": "sled(0.6782)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396212.jpg"}, {"question": "what type of skiing is shown", "gt answer": "cross country(1.00)<br/>regular(0.60)", "pred answer": "downhill", "question_id": 4926575, "best approach": "wiki, concept", "verif answer": "cross country", "anno approach": "wiki, concept, image", "verif wiki answer": "cross country(0.7263)", "verif concept answer": "cross country(0.7178)", "verif image answer": "downhill(0.7078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492657.jpg"}, {"question": "what type of plant is this", "gt answer": "aloe(1.00)<br/>basil(0.60)", "pred answer": "cactus", "question_id": 2166015, "best approach": "", "verif answer": "succulent", "anno approach": "wiki, concept, image", "verif wiki answer": "succulent(0.7153)", "verif concept answer": "succulent(0.7217)", "verif image answer": "succulent(0.7100)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216601.jpg"}, {"question": "what event was this photograph taken at", "gt answer": "concert(1.00)<br/>sale(0.60)<br/>festival(0.60)<br/>open(0.60)", "pred answer": "skateboard", "question_id": 3580705, "best approach": "concept", "verif answer": "festival", "anno approach": "wiki, concept, image", "verif wiki answer": "open(0.5036)", "verif concept answer": "concert(0.5132)", "verif image answer": "festival(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358070.jpg"}, {"question": "what language is sign", "gt answer": "korean(1.00)<br/>japanese(0.60)<br/>chinese(0.60)", "pred answer": "english", "question_id": 2400575, "best approach": "", "verif answer": "english", "anno approach": "wiki, concept, image", "verif wiki answer": "english(0.6649)", "verif concept answer": "english(0.7113)", "verif image answer": "english(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240057.jpg"}, {"question": "how much dose the case the man is pulling behind him weigh when empty", "gt answer": "5 pounds(1.00)<br/>1 pound(0.60)", "pred answer": "20 pounds", "question_id": 2213115, "best approach": "wiki, concept", "verif answer": "20 pounds", "anno approach": "wiki, concept, image", "verif wiki answer": "1 pound(0.6309)", "verif concept answer": "1 pound(0.5621)", "verif image answer": "ton(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221311.jpg"}, {"question": "what are these types of umbrellas called", "gt answer": "beach umbrella(1.00)<br/>sun(1.00)", "pred answer": "palm tree", "question_id": 4340455, "best approach": "", "verif answer": "striped", "anno approach": "wiki, concept, image", "verif wiki answer": "dandelion(0.6130)", "verif concept answer": "dandelion(0.6121)", "verif image answer": "stripe(0.6890)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434045.jpg"}, {"question": "what holiday is it", "gt answer": "easter(1.00)<br/>christmas(0.60)<br/>0(0.60)", "pred answer": "july 4th", "question_id": 5470825, "best approach": "image", "verif answer": "valentine's day", "anno approach": "wiki, concept, image", "verif wiki answer": "valentine's day(0.7245)", "verif concept answer": "valentine's day(0.6272)", "verif image answer": "easter(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000547082.jpg"}, {"question": "what type of luck is this animal associated with", "gt answer": "bad(1.00)", "pred answer": "black cat", "question_id": 985495, "best approach": "wiki, concept", "verif answer": "bad", "anno approach": "wiki, concept, image", "verif wiki answer": "bad(0.7171)", "verif concept answer": "bad(0.7133)", "verif image answer": "over ripe(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098549.jpg"}, {"question": "the leather used in the neck of the horse is made up of which material", "gt answer": "cowhide(1.00)<br/>leather(0.60)", "pred answer": "nylon", "question_id": 274955, "best approach": "", "verif answer": "leather", "anno approach": "wiki, concept, image", "verif wiki answer": "wool(0.6121)", "verif concept answer": "wool(0.5915)", "verif image answer": "wool(0.5871)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027495.jpg"}, {"question": "what type of gasoline is used to fill up this vehicle", "gt answer": "unleaded(1.00)<br/>diesel(0.60)<br/>regular(0.60)", "pred answer": "gasoline", "question_id": 3993325, "best approach": "wiki, concept, image", "verif answer": "regular", "anno approach": "wiki, concept, image", "verif wiki answer": "regular(0.6919)", "verif concept answer": "regular(0.6957)", "verif image answer": "regular(0.7114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399332.jpg"}, {"question": "what are these animals eating", "gt answer": "grass(1.00)<br/>cow(0.60)", "pred answer": "meat", "question_id": 5613845, "best approach": "wiki", "verif answer": "grass", "anno approach": "wiki, concept, image", "verif wiki answer": "grass(0.6550)", "verif concept answer": "pasture(0.7008)", "verif image answer": "pasture(0.7273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561384.jpg"}, {"question": "why is that bus taking up three lanes", "gt answer": "turn(1.00)<br/>pull over(0.60)<br/>big(0.60)", "pred answer": "broken", "question_id": 1653475, "best approach": "image", "verif answer": "turn", "anno approach": "wiki, concept, image", "verif wiki answer": "parade(0.5713)", "verif concept answer": "parade(0.5552)", "verif image answer": "big(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000165347.jpg"}, {"question": "for what kind of art would this setting be use for", "gt answer": "play(1.00)<br/>sing(0.60)", "pred answer": "circus", "question_id": 1368115, "best approach": "", "verif answer": "dance", "anno approach": "wiki, concept, image", "verif wiki answer": "trick(0.6825)", "verif concept answer": "trick(0.6951)", "verif image answer": "dance(0.5767)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136811.jpg"}, {"question": "is this an entree or dessert", "gt answer": "dessert(1.00)", "pred answer": "cake", "question_id": 3587885, "best approach": "", "verif answer": "dessert", "anno approach": "wiki, concept, image", "verif wiki answer": "cupcake(0.5589)", "verif concept answer": "cupcake(0.6282)", "verif image answer": "cupcake(0.5017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358788.jpg"}, {"question": "what would the cat 's claws destroy", "gt answer": "furniture(1.00)<br/>purse(1.00)<br/>couch(0.60)", "pred answer": "teeth", "question_id": 4216895, "best approach": "wiki, concept, image", "verif answer": "furniture", "anno approach": "wiki, concept, image", "verif wiki answer": "furniture(0.5005)", "verif concept answer": "furniture(0.5081)", "verif image answer": "purse(0.5011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421689.jpg"}, {"question": "how organized does this seem", "gt answer": "not organized(1.00)<br/>not very(0.60)<br/>not at all(0.60)", "pred answer": "messy", "question_id": 2532655, "best approach": "wiki", "verif answer": "not at all", "anno approach": "wiki, concept, image", "verif wiki answer": "not at all(0.6154)", "verif concept answer": "disorganized(0.5392)", "verif image answer": "disorganized(0.7282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253265.jpg"}, {"question": "the common saying says that eating one of these keeps what away", "gt answer": "doctor(1.00)<br/>apple(1.00)", "pred answer": "fiber", "question_id": 79345, "best approach": "wiki", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "doctor(0.5004)", "verif concept answer": "nurse(0.5001)", "verif image answer": "tomato(0.5111)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007934.jpg"}, {"question": "what is the popular brand of soda", "gt answer": "coca cola(1.00)", "pred answer": "coke", "question_id": 3500775, "best approach": "", "verif answer": "coke", "anno approach": "wiki, concept, image", "verif wiki answer": "coco cola(0.7080)", "verif concept answer": "coke(0.6867)", "verif image answer": "coco cola(0.5458)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350077.jpg"}, {"question": "what would you have to remove from this animal before cooking it", "gt answer": "feather(1.00)", "pred answer": "meat", "question_id": 1366685, "best approach": "wiki, concept", "verif answer": "bark", "anno approach": "wiki, concept, image", "verif wiki answer": "feather(0.6703)", "verif concept answer": "feather(0.7040)", "verif image answer": "bark(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136668.jpg"}, {"question": "what is funny about this picture", "gt answer": "nothing(1.00)<br/>sing(0.60)<br/>kid(0.60)", "pred answer": "toothpaste", "question_id": 5424435, "best approach": "image", "verif answer": "sing", "anno approach": "wiki, concept, image", "verif wiki answer": "child(0.5586)", "verif concept answer": "parade(0.6419)", "verif image answer": "kid(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542443.jpg"}, {"question": "when people see this car on the freeway what are they most likely to do in their vehicles", "gt answer": "pull over(1.00)<br/>slow down(0.60)", "pred answer": "tow", "question_id": 5362655, "best approach": "wiki, concept", "verif answer": "ride", "anno approach": "wiki, concept, image", "verif wiki answer": "pull over(0.6852)", "verif concept answer": "pull over(0.7291)", "verif image answer": "ride(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536265.jpg"}, {"question": "what can you cut with this", "gt answer": "thread(1.00)<br/>paper(0.60)", "pred answer": "silk", "question_id": 4384475, "best approach": "image", "verif answer": "fabric", "anno approach": "wiki, concept, image", "verif wiki answer": "paper(0.5033)", "verif concept answer": "paper(0.5101)", "verif image answer": "thread(0.5958)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000438447.jpg"}, {"question": "what is the best way to repair the damage to this mirror", "gt answer": "wash it(1.00)<br/>glue(0.60)", "pred answer": "bleach", "question_id": 3191975, "best approach": "", "verif answer": "clean", "anno approach": "wiki, concept, image", "verif wiki answer": "de ice(0.6446)", "verif concept answer": "clean(0.6046)", "verif image answer": "clean(0.5908)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319197.jpg"}, {"question": "what clothing is her wool used for", "gt answer": "sweater(1.00)<br/>coat(0.60)<br/>hat(0.60)<br/>scarf(0.60)", "pred answer": "wool", "question_id": 2721625, "best approach": "wiki, concept, image", "verif answer": "wool", "anno approach": "wiki, concept, image", "verif wiki answer": "coat(0.6598)", "verif concept answer": "coat(0.6184)", "verif image answer": "coat(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000272162.jpg"}, {"question": "what is the apparatus on the front of the plane called", "gt answer": "propeller(1.00)<br/>prop(0.60)", "pred answer": "engine", "question_id": 3656205, "best approach": "image", "verif answer": "propeller", "anno approach": "wiki, concept, image", "verif wiki answer": "biplane(0.7262)", "verif concept answer": "biplane(0.6449)", "verif image answer": "prop(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365620.jpg"}, {"question": "what is underneath the flowered blanket", "gt answer": "bed(1.00)<br/>person(1.00)<br/>pillow(0.60)", "pred answer": "quilt", "question_id": 5782135, "best approach": "wiki", "verif answer": "person", "anno approach": "wiki, concept, image", "verif wiki answer": "pillow(0.5008)", "verif concept answer": "skier(0.5011)", "verif image answer": "man(0.5187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578213.jpg"}, {"question": "is this a ground or aerodynamic vehicle", "gt answer": "aerodynamic(1.00)", "pred answer": "on ground", "question_id": 2593125, "best approach": "", "verif answer": "wind", "anno approach": "wiki, concept, image", "verif wiki answer": "wind(0.5018)", "verif concept answer": "wind(0.5005)", "verif image answer": "wind(0.5046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259312.jpg"}, {"question": "what material is the table made of", "gt answer": "wicker(1.00)<br/>wood(0.60)", "pred answer": "marble", "question_id": 224155, "best approach": "image", "verif answer": "wood", "anno approach": "wiki, concept, image", "verif wiki answer": "bamboo(0.7146)", "verif concept answer": "bamboo(0.6386)", "verif image answer": "wood(0.6889)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000022415.jpg"}, {"question": "where might the ball be headed", "gt answer": "outfield(1.00)<br/>field(0.60)", "pred answer": "first base", "question_id": 3604525, "best approach": "image", "verif answer": "baseball field", "anno approach": "wiki, concept, image", "verif wiki answer": "batter(0.6784)", "verif concept answer": "batter(0.6635)", "verif image answer": "outfield(0.6944)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000360452.jpg"}, {"question": "", "gt answer": "age(0.60)<br/>slice(0.60)<br/>bake(0.60)", "pred answer": "roast", "question_id": 4912045, "best approach": "", "verif answer": "mix", "anno approach": "wiki, concept, image", "verif wiki answer": "mix(0.6401)", "verif concept answer": "mix(0.6986)", "verif image answer": "mix(0.6456)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491204.jpg"}, {"question": "why does the disc look so much smaller than the hand", "gt answer": "perspective(1.00)", "pred answer": "price tag", "question_id": 1488795, "best approach": "image", "verif answer": "big", "anno approach": "wiki, concept, image", "verif wiki answer": "big(0.5454)", "verif concept answer": "big(0.5259)", "verif image answer": "perspective(0.6278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148879.jpg"}, {"question": "what animal did these animals descend from", "gt answer": "lion(1.00)<br/>tiger(0.60)", "pred answer": "feline", "question_id": 3593205, "best approach": "image", "verif answer": "feline", "anno approach": "wiki, concept, image", "verif wiki answer": "feline(0.5102)", "verif concept answer": "tiger(0.5588)", "verif image answer": "lion(0.5808)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359320.jpg"}, {"question": "in what city does this police man work", "gt answer": "new york(1.00)<br/>pennsylvania(0.60)", "pred answer": "london", "question_id": 4822525, "best approach": "", "verif answer": "london", "anno approach": "wiki, concept, image", "verif wiki answer": "texas(0.6914)", "verif concept answer": "ohio(0.6667)", "verif image answer": "texas(0.6239)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482252.jpg"}, {"question": "what do these lines help bring", "gt answer": "electricity(1.00)<br/>power(1.00)<br/>communication(0.60)", "pred answer": "wind", "question_id": 4656035, "best approach": "image", "verif answer": "travel", "anno approach": "wiki, concept, image", "verif wiki answer": "travel(0.6152)", "verif concept answer": "travel(0.6325)", "verif image answer": "communication(0.7002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465603.jpg"}, {"question": "how many degrees wide can these birds open their mouths", "gt answer": "45(1.00)<br/>180(1.00)", "pred answer": "3", "question_id": 5032125, "best approach": "wiki, concept, image", "verif answer": "180", "anno approach": "wiki, concept, image", "verif wiki answer": "180(0.7030)", "verif concept answer": "180(0.5702)", "verif image answer": "45(0.7242)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503212.jpg"}, {"question": "what are some popular myths regarding the animal in the photo", "gt answer": "bad luck(1.00)", "pred answer": "domestic", "question_id": 3766435, "best approach": "", "verif answer": "domestic", "anno approach": "wiki, concept, image", "verif wiki answer": "domestic(0.7256)", "verif concept answer": "domestic(0.6637)", "verif image answer": "orange(0.7052)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376643.jpg"}, {"question": "from what era is this vehicle likely to be", "gt answer": "1940(1.00)<br/>wwii(0.60)", "pred answer": "1800s", "question_id": 2043825, "best approach": "", "verif answer": "1940s", "anno approach": "wiki, concept, image", "verif wiki answer": "1940s(0.7048)", "verif concept answer": "1940s(0.5542)", "verif image answer": "1950(0.6502)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000204382.jpg"}, {"question": "what kind of table is that", "gt answer": "coffee table(1.00)<br/>coffee(0.60)", "pred answer": "table", "question_id": 4965095, "best approach": "wiki, concept, image", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "coffee table(0.7306)", "verif concept answer": "coffee table(0.7044)", "verif image answer": "coffee table(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496509.jpg"}, {"question": "what type of haircut is this called", "gt answer": "bang(1.00)", "pred answer": "pony tail", "question_id": 4135855, "best approach": "", "verif answer": "bob", "anno approach": "wiki, concept, image", "verif wiki answer": "bob(0.6598)", "verif concept answer": "messy(0.6503)", "verif image answer": "messy(0.5903)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000413585.jpg"}, {"question": "what would you call a join like this between two roads on the picture", "gt answer": "intersection(1.00)<br/>cross(0.60)", "pred answer": "sidewalk", "question_id": 5583185, "best approach": "", "verif answer": "intersection", "anno approach": "wiki, concept, image", "verif wiki answer": "above(0.6185)", "verif concept answer": "crossroad(0.6409)", "verif image answer": "crossroad(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558318.jpg"}, {"question": "what make and model is the car pictured", "gt answer": "toyota avalon(1.00)", "pred answer": "sedan", "question_id": 1392145, "best approach": "", "verif answer": "sedan", "anno approach": "wiki, concept, image", "verif wiki answer": "bmw(0.6088)", "verif concept answer": "bmw(0.5964)", "verif image answer": "light(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139214.jpg"}, {"question": "why are they riding an elephant", "gt answer": "for fun(1.00)<br/>pleasure(0.60)", "pred answer": "transportation", "question_id": 1889876, "best approach": "wiki, concept", "verif answer": "fun", "anno approach": "wiki, concept, image", "verif wiki answer": "pleasure(0.6493)", "verif concept answer": "pleasure(0.6460)", "verif image answer": "to eat(0.7219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188987.jpg"}, {"question": "is this train coming or going", "gt answer": "come(1.00)<br/>go(0.60)<br/>both(0.60)", "pred answer": "leave", "question_id": 4523435, "best approach": "", "verif answer": "move", "anno approach": "wiki, concept, image", "verif wiki answer": "move(0.7028)", "verif concept answer": "move(0.7261)", "verif image answer": "move(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000452343.jpg"}, {"question": "what does the black object in the foreground of the picture usually hold", "gt answer": "napkin(1.00)", "pred answer": "candle", "question_id": 5260575, "best approach": "image", "verif answer": "candle", "anno approach": "wiki, concept, image", "verif wiki answer": "candle(0.7189)", "verif concept answer": "candle(0.6757)", "verif image answer": "napkin(0.6970)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526057.jpg"}, {"question": "what is the manwearing on his head", "gt answer": "hat(1.00)<br/>baseball cap(1.00)<br/>cap(0.60)", "pred answer": "beanie", "question_id": 2873105, "best approach": "", "verif answer": "cap", "anno approach": "wiki, concept, image", "verif wiki answer": "apron(0.7237)", "verif concept answer": "apron(0.7118)", "verif image answer": "apron(0.5850)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287310.jpg"}, {"question": "what are the ingredients are used for preparing the dish shown in this photo", "gt answer": "bread and meat(1.00)<br/>wheat(0.60)", "pred answer": "bread", "question_id": 1140605, "best approach": "wiki, concept, image", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "wheat(0.6996)", "verif concept answer": "wheat(0.7040)", "verif image answer": "wheat(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114060.jpg"}, {"question": "what is the contraption on the back of the truck", "gt answer": "tow(1.00)<br/>ladder(1.00)", "pred answer": "trailer", "question_id": 2246885, "best approach": "wiki, concept", "verif answer": "tow", "anno approach": "wiki, concept, image", "verif wiki answer": "tow(0.7138)", "verif concept answer": "ladder(0.7156)", "verif image answer": "stair(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224688.jpg"}, {"question": "when was the last time that the bedsheets were cleaned", "gt answer": "today(1.00)<br/>recently(0.60)", "pred answer": "1970", "question_id": 5301875, "best approach": "image", "verif answer": "recently", "anno approach": "wiki, concept, image", "verif wiki answer": "washington(0.5251)", "verif concept answer": "sunset(0.5726)", "verif image answer": "today(0.5866)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000530187.jpg"}, {"question": "what team represents cleveland ohio for this sport", "gt answer": "indians(1.00)", "pred answer": "yankees", "question_id": 802935, "best approach": "", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "major league baseball(0.5995)", "verif concept answer": "major league baseball(0.7158)", "verif image answer": "americas(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080293.jpg"}, {"question": "what kind of meat is that", "gt answer": "pork(1.00)<br/>bbq(0.60)", "pred answer": "roast beef", "question_id": 2730815, "best approach": "image", "verif answer": "beef", "anno approach": "wiki, concept, image", "verif wiki answer": "pulled pork(0.7033)", "verif concept answer": "pulled pork(0.6573)", "verif image answer": "pork(0.7204)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273081.jpg"}, {"question": "how do they decide which cars are antique", "gt answer": "age(1.00)", "pred answer": "rust", "question_id": 2034405, "best approach": "image", "verif answer": "age", "anno approach": "wiki, concept, image", "verif wiki answer": "bake(0.5000)", "verif concept answer": "bake(0.5001)", "verif image answer": "age(0.5095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203440.jpg"}, {"question": "what facial expression can be found on these children", "gt answer": "smile(1.00)<br/>joy(0.60)<br/>happiness(0.60)", "pred answer": "sad", "question_id": 5376875, "best approach": "", "verif answer": "sad", "anno approach": "wiki, concept, image", "verif wiki answer": "sad(0.7216)", "verif concept answer": "sad(0.7235)", "verif image answer": "happy(0.6525)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537687.jpg"}, {"question": "what breed of sheep is that", "gt answer": "merino(1.00)<br/>regular(0.60)", "pred answer": "sheep", "question_id": 5533715, "best approach": "wiki, concept, image", "verif answer": "sheep", "anno approach": "wiki, concept, image", "verif wiki answer": "merino(0.7162)", "verif concept answer": "merino(0.7085)", "verif image answer": "merino(0.7083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553371.jpg"}, {"question": "can you the place name where this animal is shown in this picture", "gt answer": "state fair(1.00)<br/>sheep(0.60)<br/>harness(0.60)", "pred answer": "zoo", "question_id": 2362955, "best approach": "image", "verif answer": "barn", "anno approach": "wiki, concept, image", "verif wiki answer": "barn(0.5709)", "verif concept answer": "barn(0.6782)", "verif image answer": "harness(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236295.jpg"}, {"question": "what seems to be the occasion for the event", "gt answer": "retirement(0.60)<br/>award(1.00)<br/>meet(0.60)", "pred answer": "dinner", "question_id": 4327425, "best approach": "wiki, concept, image", "verif answer": "meet", "anno approach": "wiki, concept, image", "verif wiki answer": "meet(0.6849)", "verif concept answer": "meet(0.6962)", "verif image answer": "meet(0.7282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432742.jpg"}, {"question": "what 's the brand of bus", "gt answer": "trailways(1.00)", "pred answer": "greyhound", "question_id": 2360755, "best approach": "", "verif answer": "target", "anno approach": "wiki, concept, image", "verif wiki answer": "target(0.5004)", "verif concept answer": "target(0.5007)", "verif image answer": "hotdog(0.5001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236075.jpg"}, {"question": "what does the yellow sign mean", "gt answer": "cow cross(1.00)", "pred answer": "pedestrian cross", "question_id": 3918075, "best approach": "", "verif answer": "do not enter", "anno approach": "wiki, concept, image", "verif wiki answer": "speed limit(0.7187)", "verif concept answer": "do not enter(0.6530)", "verif image answer": "do not enter(0.7049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391807.jpg"}, {"question": "what size wheels does the yellow vehicle have", "gt answer": "32 in(1.00)<br/>large(0.60)", "pred answer": "big", "question_id": 5091285, "best approach": "", "verif answer": "big", "anno approach": "wiki, concept, image", "verif wiki answer": "huge(0.6351)", "verif concept answer": "big(0.6493)", "verif image answer": "huge(0.5019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509128.jpg"}, {"question": "do these bags belong to a tour group or are they on sale", "gt answer": "sale(1.00)", "pred answer": "competition", "question_id": 4829405, "best approach": "", "verif answer": "competition", "anno approach": "wiki, concept, image", "verif wiki answer": "for sale(0.5646)", "verif concept answer": "competition(0.5736)", "verif image answer": "litter(0.5179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482940.jpg"}, {"question": "what is the man doing to the animal", "gt answer": "measure(1.00)<br/>show(0.60)", "pred answer": "shear", "question_id": 3782145, "best approach": "", "verif answer": "herd", "anno approach": "wiki, concept, image", "verif wiki answer": "fly(0.5089)", "verif concept answer": "fly(0.5023)", "verif image answer": "fly(0.5981)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378214.jpg"}, {"question": "what is the dog doing", "gt answer": "eat(1.00)<br/>smell(0.60)", "pred answer": "herd", "question_id": 5380185, "best approach": "image", "verif answer": "eat", "anno approach": "wiki, concept, image", "verif wiki answer": "smell(0.6507)", "verif concept answer": "smell(0.6131)", "verif image answer": "eat(0.7082)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538018.jpg"}, {"question": "is this sink fine or are they fixing it", "gt answer": "fine(1.00)", "pred answer": "trail", "question_id": 1117375, "best approach": "wiki, concept", "verif answer": "jail", "anno approach": "wiki, concept, image", "verif wiki answer": "fine(0.5098)", "verif concept answer": "fine(0.5006)", "verif image answer": "jail(0.6668)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111737.jpg"}, {"question": "where did they get these pizzas", "gt answer": "restaurant(1.00)<br/>delivery(0.60)", "pred answer": "domino", "question_id": 4941955, "best approach": "wiki, image", "verif answer": "home", "anno approach": "wiki, concept, image", "verif wiki answer": "delivery(0.7273)", "verif concept answer": "cafe(0.7302)", "verif image answer": "delivery(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494195.jpg"}, {"question": "what are the other roads that buses can travel without cars", "gt answer": "bus lane(1.00)", "pred answer": "bus", "question_id": 125675, "best approach": "", "verif answer": "tour bus", "anno approach": "wiki, concept, image", "verif wiki answer": "tour bus(0.5115)", "verif concept answer": "tour bus(0.5360)", "verif image answer": "tour bus(0.5285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012567.jpg"}, {"question": "how old is this plane", "gt answer": "5 years(1.00)<br/>50 years(0.60)<br/>4(0.60)", "pred answer": "200", "question_id": 402015, "best approach": "wiki, concept", "verif answer": "4", "anno approach": "wiki, concept, image", "verif wiki answer": "5 years(0.5746)", "verif concept answer": "5 years(0.5753)", "verif image answer": "4 years(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040201.jpg"}, {"question": "how long will the light stay green", "gt answer": "1 minute(1.00)<br/>second(0.60)<br/>3 minutes(0.60)", "pred answer": "10 hours", "question_id": 5053435, "best approach": "image", "verif answer": "5 minutes", "anno approach": "wiki, concept, image", "verif wiki answer": "3 minutes(0.7009)", "verif concept answer": "3 minutes(0.6835)", "verif image answer": "1 minute(0.7075)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505343.jpg"}, {"question": "when a person wears a purse or bag in this way what is it called", "gt answer": "crossbody(1.00)<br/>satchel(0.60)", "pred answer": "tank top", "question_id": 3770555, "best approach": "image", "verif answer": "backpack", "anno approach": "wiki, concept, image", "verif wiki answer": "backpack(0.7044)", "verif concept answer": "backpack(0.5414)", "verif image answer": "satchel(0.6551)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377055.jpg"}, {"question": "what is a popular holiday for this food", "gt answer": "4th of july(1.00)<br/>independence day(0.60)", "pred answer": "july 4th", "question_id": 668775, "best approach": "", "verif answer": "july 4th", "anno approach": "wiki, concept, image", "verif wiki answer": "july 4th(0.7066)", "verif concept answer": "thanksgiving(0.5107)", "verif image answer": "july 4th(0.5536)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000066877.jpg"}, {"question": "what is the reason an orange disc is flying", "gt answer": "thrown(1.00)<br/>play(0.60)", "pred answer": "accident", "question_id": 3359125, "best approach": "wiki", "verif answer": "accident", "anno approach": "wiki, concept, image", "verif wiki answer": "thrown(0.5699)", "verif concept answer": "broken(0.5286)", "verif image answer": "accident(0.7174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335912.jpg"}, {"question": "what company does this plane belong to", "gt answer": "british airway(1.00)<br/>american airline(0.60)", "pred answer": "united", "question_id": 2438465, "best approach": "", "verif answer": "american", "anno approach": "wiki, concept, image", "verif wiki answer": "american(0.5083)", "verif concept answer": "virgin(0.5002)", "verif image answer": "virgin(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243846.jpg"}, {"question": "on average how many people commute on this transport daily", "gt answer": "10000(1.00)<br/>500(0.60)", "pred answer": "million", "question_id": 2669105, "best approach": "", "verif answer": "thousand", "anno approach": "wiki, concept, image", "verif wiki answer": "thousand(0.6943)", "verif concept answer": "thousand(0.6712)", "verif image answer": "thousand(0.6843)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266910.jpg"}, {"question": "what type of food does this seem to be", "gt answer": "chinese(1.00)<br/>asian(0.60)<br/>korean(0.60)", "pred answer": "breakfast", "question_id": 5185095, "best approach": "wiki", "verif answer": "japanese", "anno approach": "wiki, concept, image", "verif wiki answer": "asian(0.6491)", "verif concept answer": "japanese(0.5266)", "verif image answer": "french(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518509.jpg"}, {"question": "what are these vehicles known for", "gt answer": "race(1.00)<br/>speed(0.60)<br/>transportation(0.60)", "pred answer": "cycling", "question_id": 2871405, "best approach": "image", "verif answer": "race", "anno approach": "wiki, concept, image", "verif wiki answer": "fun(0.6975)", "verif concept answer": "fun(0.6755)", "verif image answer": "transportation(0.6124)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287140.jpg"}, {"question": "what does one typically say when answering", "gt answer": "hello(1.00)", "pred answer": "sad", "question_id": 3946005, "best approach": "", "verif answer": "engineer", "anno approach": "wiki, concept, image", "verif wiki answer": "conductor(0.5444)", "verif concept answer": "conductor(0.7246)", "verif image answer": "engineer(0.7282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000394600.jpg"}, {"question": "", "gt answer": "victorian(0.60)<br/>classic(0.60)", "pred answer": "gothic", "question_id": 4849085, "best approach": "wiki, concept", "verif answer": "gothic", "anno approach": "wiki, concept, image", "verif wiki answer": "classic(0.5995)", "verif concept answer": "classic(0.6773)", "verif image answer": "country(0.6681)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484908.jpg"}, {"question": "why would we suspect that this park is dedicated to the sport seen here", "gt answer": "ramp(1.00)<br/>skateboard(0.60)", "pred answer": "skate park", "question_id": 4888895, "best approach": "wiki, concept", "verif answer": "skate", "anno approach": "wiki, concept, image", "verif wiki answer": "ramp(0.5561)", "verif concept answer": "ramp(0.5311)", "verif image answer": "skate(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488889.jpg"}, {"question": "what is this type of food called when it reaches 12 inches", "gt answer": "footlong(1.00)", "pred answer": "hot dog", "question_id": 5385445, "best approach": "", "verif answer": "high", "anno approach": "wiki, concept, image", "verif wiki answer": "high(0.5024)", "verif concept answer": "high(0.5013)", "verif image answer": "high(0.5581)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538544.jpg"}, {"question": "what does the different colors on top of a red fire hydrant means", "gt answer": "gallon per minute(1.00)", "pred answer": "caution", "question_id": 2250555, "best approach": "wiki, concept, image", "verif answer": "face", "anno approach": "wiki, concept, image", "verif wiki answer": "gallon per minute(0.7297)", "verif concept answer": "gallon per minute(0.5790)", "verif image answer": "gallon per minute(0.5828)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225055.jpg"}, {"question": "what famous cartoon have these birds in it", "gt answer": "looney tune(1.00)", "pred answer": "yogi", "question_id": 2561775, "best approach": "wiki, concept", "verif answer": "looney tune", "anno approach": "wiki, concept, image", "verif wiki answer": "looney tune(0.6984)", "verif concept answer": "looney tune(0.7296)", "verif image answer": "roosevelt(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256177.jpg"}, {"question": "is this animal a pet or zoo animal", "gt answer": "pet(1.00)", "pred answer": "feline", "question_id": 1188895, "best approach": "", "verif answer": "domestic", "anno approach": "wiki, concept, image", "verif wiki answer": "domestic(0.7285)", "verif concept answer": "domestic(0.7236)", "verif image answer": "domestic(0.7183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118889.jpg"}, {"question": "what do those windows bring into the room", "gt answer": "light(1.00)<br/>sunlight(1.00)", "pred answer": "window", "question_id": 525185, "best approach": "", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "reflection(0.7188)", "verif concept answer": "reflection(0.6891)", "verif image answer": "stop light(0.5956)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052518.jpg"}, {"question": "what other games require this type of netting", "gt answer": "volleyball(1.00)<br/>badminton(0.60)", "pred answer": "soccer", "question_id": 2611725, "best approach": "", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "baseball(0.7150)", "verif concept answer": "baseball(0.7147)", "verif image answer": "frisbee(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261172.jpg"}, {"question": "what hairstyles are most popular for women of this age", "gt answer": "pixie(1.00)<br/>short(1.00)", "pred answer": "bob", "question_id": 3422555, "best approach": "wiki, concept, image", "verif answer": "short", "anno approach": "wiki, concept, image", "verif wiki answer": "short(0.6567)", "verif concept answer": "short(0.7108)", "verif image answer": "short(0.5339)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342255.jpg"}, {"question": "what does the dog have around its neck", "gt answer": "collar(1.00)", "pred answer": "leash", "question_id": 1938195, "best approach": "wiki", "verif answer": "collar", "anno approach": "wiki, concept, image", "verif wiki answer": "collar(0.5199)", "verif concept answer": "tie(0.5145)", "verif image answer": "tag(0.6928)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193819.jpg"}, {"question": "what type of restaurant would you find these", "gt answer": "bakery(1.00)<br/>coffee shop(0.60)", "pred answer": "donuts", "question_id": 3214485, "best approach": "", "verif answer": "donut", "anno approach": "wiki, concept, image", "verif wiki answer": "donut(0.7285)", "verif concept answer": "donut(0.6777)", "verif image answer": "donut(0.7221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321448.jpg"}, {"question": "what type of flooring is shown in this photo", "gt answer": "laminate(1.00)<br/>wood(1.00)<br/>hardwood(0.60)", "pred answer": "carpet", "question_id": 496735, "best approach": "wiki, concept, image", "verif answer": "laminate", "anno approach": "wiki, concept, image", "verif wiki answer": "laminate(0.7244)", "verif concept answer": "laminate(0.6391)", "verif image answer": "laminate(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049673.jpg"}, {"question": "which type of implement is the man holding", "gt answer": "knife(1.00)", "pred answer": "luggage", "question_id": 875075, "best approach": "", "verif answer": "right", "anno approach": "wiki, concept, image", "verif wiki answer": "right(0.7186)", "verif concept answer": "right(0.6310)", "verif image answer": "scissor(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087507.jpg"}, {"question": "what type of instrument is this", "gt answer": "knife(1.00)", "pred answer": "guitar", "question_id": 3357995, "best approach": "", "verif answer": "scissor", "anno approach": "wiki, concept, image", "verif wiki answer": "spatula(0.7296)", "verif concept answer": "spatula(0.7268)", "verif image answer": "scissor(0.7080)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335799.jpg"}, {"question": "what kind of building is this", "gt answer": "hut(1.00)<br/>shelter(0.60)<br/>gazebo(0.60)", "pred answer": "school", "question_id": 1430515, "best approach": "wiki, concept, image", "verif answer": "shelter", "anno approach": "wiki, concept, image", "verif wiki answer": "shelter(0.7074)", "verif concept answer": "shelter(0.7289)", "verif image answer": "shelter(0.5705)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143051.jpg"}, {"question": "what mascot is this", "gt answer": "beaver(1.00)", "pred answer": "rat", "question_id": 3198186, "best approach": "", "verif answer": "oriole", "anno approach": "wiki, concept, image", "verif wiki answer": "oriole(0.7295)", "verif concept answer": "poodle(0.7236)", "verif image answer": "poodle(0.7198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319818.jpg"}, {"question": "the lorry shown in the photo is in which road", "gt answer": "interstate(1.00)<br/>highway(0.60)", "pred answer": "london", "question_id": 4149845, "best approach": "wiki, concept", "verif answer": "interstate", "anno approach": "wiki, concept, image", "verif wiki answer": "highway(0.7184)", "verif concept answer": "highway(0.7252)", "verif image answer": "straight(0.6975)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000414984.jpg"}, {"question": "what does the machine on the refrigerator do", "gt answer": "make coffee(1.00)", "pred answer": "cook", "question_id": 1504805, "best approach": "", "verif answer": "drink", "anno approach": "wiki, concept, image", "verif wiki answer": "drink(0.5050)", "verif concept answer": "drink(0.5029)", "verif image answer": "drink(0.6300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000150480.jpg"}, {"question": "what is this kind of vehicle called", "gt answer": "cherry picker(1.00)<br/>fire truck(0.60)", "pred answer": "tow", "question_id": 5698275, "best approach": "wiki, concept", "verif answer": "garbage truck", "anno approach": "wiki, concept, image", "verif wiki answer": "fire truck(0.7298)", "verif concept answer": "fire truck(0.7205)", "verif image answer": "construction(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569827.jpg"}, {"question": "what are these called", "gt answer": "keyboard(1.00)", "pred answer": "computer", "question_id": 1593565, "best approach": "", "verif answer": "computer", "anno approach": "wiki, concept, image", "verif wiki answer": "mouse and keyboard(0.7222)", "verif concept answer": "mouse and keyboard(0.6700)", "verif image answer": "computer(0.6613)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159356.jpg"}, {"question": "what is the sign saying to be cautious of", "gt answer": "snake(1.00)", "pred answer": "stop", "question_id": 4230285, "best approach": "", "verif answer": "1 way", "anno approach": "wiki, concept, image", "verif wiki answer": "1 way(0.7024)", "verif concept answer": "1 way(0.5922)", "verif image answer": "1 way(0.7140)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000423028.jpg"}, {"question": "are these animals free or in captivity", "gt answer": "captivity(1.00)", "pred answer": "wild", "question_id": 43185, "best approach": "wiki, image", "verif answer": "locked up", "anno approach": "wiki, concept, image", "verif wiki answer": "captivity(0.5021)", "verif concept answer": "free(0.5005)", "verif image answer": "captivity(0.5081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004318.jpg"}, {"question": "what fuel does this train run on", "gt answer": "kerosene(1.00)<br/>coal(0.60)<br/>electricity(0.60)<br/>gas(0.60)", "pred answer": "diesel", "question_id": 1418485, "best approach": "wiki", "verif answer": "gas", "anno approach": "wiki, concept, image", "verif wiki answer": "kerosene(0.5610)", "verif concept answer": "coal(0.5676)", "verif image answer": "gas(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000141848.jpg"}, {"question": "what lunch foods are healthy for young children", "gt answer": "vegetable(1.00)<br/>sandwich(0.60)<br/>hot dog(0.60)", "pred answer": "hotdog", "question_id": 5771265, "best approach": "wiki, concept, image", "verif answer": "hot dog", "anno approach": "wiki, concept, image", "verif wiki answer": "sandwich(0.7241)", "verif concept answer": "hot dog(0.6927)", "verif image answer": "sandwich(0.5916)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000577126.jpg"}, {"question": "what country are these two people from", "gt answer": "great britain(1.00)<br/>london(0.60)<br/>united kingdom(0.60)<br/>england(0.60)", "pred answer": "united state", "question_id": 3057325, "best approach": "image", "verif answer": "london", "anno approach": "wiki, concept, image", "verif wiki answer": "britain(0.6838)", "verif concept answer": "britain(0.6608)", "verif image answer": "great britain(0.6387)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305732.jpg"}, {"question": "which program is being watched on the laptop", "gt answer": "game show(1.00)<br/>american idol(1.00)", "pred answer": "type", "question_id": 460025, "best approach": "", "verif answer": "delete", "anno approach": "wiki, concept, image", "verif wiki answer": "delete(0.5493)", "verif concept answer": "delete(0.5748)", "verif image answer": "delete(0.6063)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046002.jpg"}, {"question": "what kind of lamp is lighting up the corner of this room", "gt answer": "lava(1.00)<br/>chandelier(0.60)", "pred answer": "lamp", "question_id": 5071965, "best approach": "image", "verif answer": "lava", "anno approach": "wiki, concept, image", "verif wiki answer": "vintage(0.6306)", "verif concept answer": "vintage(0.5648)", "verif image answer": "lava(0.6698)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507196.jpg"}, {"question": "what event is this", "gt answer": "political(1.00)<br/>speech(0.60)<br/>rally(0.60)", "pred answer": "fair", "question_id": 5155505, "best approach": "image", "verif answer": "speech", "anno approach": "wiki, concept, image", "verif wiki answer": "parade(0.7225)", "verif concept answer": "parade(0.5103)", "verif image answer": "speech(0.6322)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515550.jpg"}, {"question": "what happened here", "gt answer": "accident(1.00)<br/>crash(0.60)", "pred answer": "construction", "question_id": 523825, "best approach": "image", "verif answer": "tow", "anno approach": "wiki, concept, image", "verif wiki answer": "fall(0.6846)", "verif concept answer": "fall(0.6314)", "verif image answer": "crash(0.6045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052382.jpg"}, {"question": "what language are the books written in", "gt answer": "english(1.00)", "pred answer": "spanish", "question_id": 2603175, "best approach": "wiki", "verif answer": "spanish", "anno approach": "wiki, concept, image", "verif wiki answer": "english(0.7253)", "verif concept answer": "french(0.7117)", "verif image answer": "french(0.6388)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260317.jpg"}, {"question": "is this flora or fauna", "gt answer": "flora(1.00)", "pred answer": "fauna", "question_id": 1917315, "best approach": "", "verif answer": "fauna", "anno approach": "wiki, concept, image", "verif wiki answer": "fauna(0.7283)", "verif concept answer": "fauna(0.7208)", "verif image answer": "decoration(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191731.jpg"}, {"question": "what is a good side dish for this meal", "gt answer": "breadsticks(1.00)<br/>wing(0.60)<br/>salad(0.60)<br/>bread(0.60)", "pred answer": "cheese", "question_id": 131695, "best approach": "wiki, concept, image", "verif answer": "cheese", "anno approach": "wiki, concept, image", "verif wiki answer": "wing(0.7083)", "verif concept answer": "salad(0.6309)", "verif image answer": "salad(0.6868)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013169.jpg"}, {"question": "what healthy oil is this dish a source of", "gt answer": "omega 3(1.00)", "pred answer": "olive oil", "question_id": 4573355, "best approach": "wiki, concept, image", "verif answer": "omega 3", "anno approach": "wiki, concept, image", "verif wiki answer": "omega 3(0.6883)", "verif concept answer": "omega 3(0.6750)", "verif image answer": "omega 3(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457335.jpg"}, {"question": "is this a coal powered or electric train", "gt answer": "coal(1.00)<br/>electric(0.60)", "pred answer": "gas", "question_id": 555855, "best approach": "wiki", "verif answer": "steam", "anno approach": "wiki, concept, image", "verif wiki answer": "coal(0.6933)", "verif concept answer": "steam(0.7065)", "verif image answer": "diesel(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000055585.jpg"}, {"question": "what is the green item in the white item on the ground", "gt answer": "plant(1.00)<br/>chair(1.00)<br/>bush(0.60)", "pred answer": "island", "question_id": 2174335, "best approach": "image", "verif answer": "chair", "anno approach": "wiki, concept, image", "verif wiki answer": "leaf(0.5811)", "verif concept answer": "grass(0.5720)", "verif image answer": "bush(0.5101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217433.jpg"}, {"question": "what kind of cheesecake is this", "gt answer": "blackberry(1.00)<br/>new york(1.00)<br/>vanilla(0.60)", "pred answer": "powdered", "question_id": 1635945, "best approach": "wiki, concept, image", "verif answer": "vanilla", "anno approach": "wiki, concept, image", "verif wiki answer": "blackberry(0.7272)", "verif concept answer": "new york(0.7291)", "verif image answer": "new york(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163594.jpg"}, {"question": "what is the movie that made these types of shoes popular", "gt answer": "wizard of oz(1.00)", "pred answer": "scifi", "question_id": 1081645, "best approach": "", "verif answer": "beauty and beast", "anno approach": "wiki, concept, image", "verif wiki answer": "disney(0.6126)", "verif concept answer": "disney(0.6188)", "verif image answer": "disney(0.6573)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108164.jpg"}, {"question": "what type of painting is hanging on the wall above the sofa", "gt answer": "abstract(1.00)<br/>art(0.60)<br/>map(0.60)", "pred answer": "paint", "question_id": 1706165, "best approach": "image", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "paint(0.7275)", "verif concept answer": "paint(0.6088)", "verif image answer": "abstract(0.7012)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000170616.jpg"}, {"question": "if the hitter hits the ball so it soars in a high arc it is called a what", "gt answer": "fly ball(1.00)", "pred answer": "home run", "question_id": 52605, "best approach": "wiki", "verif answer": "homerun", "anno approach": "wiki, concept, image", "verif wiki answer": "fly ball(0.6979)", "verif concept answer": "homerun(0.6292)", "verif image answer": "homerun(0.6633)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005260.jpg"}, {"question": "how old do i have to be at least to fly a plane in the eu", "gt answer": "21(1.00)<br/>18(0.60)<br/>11(0.60)", "pred answer": "2000", "question_id": 2012465, "best approach": "wiki, concept", "verif answer": "21", "anno approach": "wiki, concept, image", "verif wiki answer": "21(0.7143)", "verif concept answer": "21(0.6449)", "verif image answer": "22(0.6098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201246.jpg"}, {"question": "what is unique about this man", "gt answer": "santa(1.00)<br/>beard(0.60)", "pred answer": "drown", "question_id": 1502865, "best approach": "image", "verif answer": "woman", "anno approach": "wiki, concept, image", "verif wiki answer": "woman(0.6934)", "verif concept answer": "woman(0.5829)", "verif image answer": "beard(0.6416)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000150286.jpg"}, {"question": "how many stories is the building", "gt answer": "20(1.00)<br/>32(0.60)<br/>15(0.60)", "pred answer": "6", "question_id": 2422575, "best approach": "concept", "verif answer": "12", "anno approach": "wiki, concept, image", "verif wiki answer": "32(0.6840)", "verif concept answer": "20(0.6769)", "verif image answer": "12(0.6575)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000242257.jpg"}, {"question": "how many miles an hour are these cars going", "gt answer": "30(1.00)<br/>40(0.60)<br/>forty(0.60)<br/>20(0.60)", "pred answer": "200", "question_id": 5734015, "best approach": "image", "verif answer": "forty", "anno approach": "wiki, concept, image", "verif wiki answer": "40(0.5972)", "verif concept answer": "40(0.6239)", "verif image answer": "30(0.6523)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000573401.jpg"}, {"question": "", "gt answer": "1800's(0.60)<br/>1800s(0.60)", "pred answer": "1940's", "question_id": 5105405, "best approach": "", "verif answer": "1940's", "anno approach": "wiki, concept, image", "verif wiki answer": "1940's(0.6063)", "verif concept answer": "1804(0.5977)", "verif image answer": "1804(0.6602)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510540.jpg"}, {"question": "the device that the mug is in emits what kind of waves", "gt answer": "micro(1.00)<br/>radiation(0.60)<br/>microwave(0.60)", "pred answer": "brew", "question_id": 3374225, "best approach": "wiki", "verif answer": "microwave", "anno approach": "wiki, concept, image", "verif wiki answer": "microwave(0.6665)", "verif concept answer": "phone(0.6336)", "verif image answer": "phone(0.6380)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337422.jpg"}, {"question": "name the place where these persons are playing in this picture", "gt answer": "field(1.00)<br/>park(0.60)", "pred answer": "baseball field", "question_id": 2093535, "best approach": "concept, image", "verif answer": "field", "anno approach": "wiki, concept, image", "verif wiki answer": "garbage can(0.7013)", "verif concept answer": "park(0.7108)", "verif image answer": "park(0.5160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209353.jpg"}, {"question": "what kind of vegatable topping is on the hotdog", "gt answer": "onion(1.00)", "pred answer": "mustard", "question_id": 2875125, "best approach": "", "verif answer": "ketchup", "anno approach": "wiki, concept, image", "verif wiki answer": "ketchup(0.6965)", "verif concept answer": "ketchup(0.7189)", "verif image answer": "olives(0.7256)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287512.jpg"}, {"question": "what comes out of this item", "gt answer": "water(1.00)", "pred answer": "fire", "question_id": 681795, "best approach": "image", "verif answer": "water", "anno approach": "wiki, concept, image", "verif wiki answer": "lake(0.5684)", "verif concept answer": "fire hydrant(0.6669)", "verif image answer": "water(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068179.jpg"}, {"question": "what type of boats are these", "gt answer": "fish(0.60)<br/>fish boat(1.00)", "pred answer": "yacht", "question_id": 2600345, "best approach": "concept", "verif answer": "fish boat", "anno approach": "wiki, concept, image", "verif wiki answer": "canoe(0.7307)", "verif concept answer": "fish boat(0.6387)", "verif image answer": "ship(0.7225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260034.jpg"}, {"question": "what is her bag made of", "gt answer": "leather(1.00)", "pred answer": "denim", "question_id": 2067475, "best approach": "", "verif answer": "canvas", "anno approach": "wiki, concept, image", "verif wiki answer": "rubber(0.7289)", "verif concept answer": "rubber(0.5579)", "verif image answer": "canvas(0.6678)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206747.jpg"}, {"question": "a constellation is generally made up from which items that are featured here on a horse 's rump", "gt answer": "star(1.00)", "pred answer": "rein", "question_id": 5461055, "best approach": "", "verif answer": "clock", "anno approach": "wiki, concept, image", "verif wiki answer": "clock(0.5016)", "verif concept answer": "clock(0.6705)", "verif image answer": "clock(0.5005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546105.jpg"}, {"question": "what would answer if i said this reminds me of the phrase watching the water blank", "gt answer": "boil(1.00)", "pred answer": "cook", "question_id": 231765, "best approach": "wiki", "verif answer": "cook", "anno approach": "wiki, concept, image", "verif wiki answer": "boil(0.5167)", "verif concept answer": "cook(0.6111)", "verif image answer": "baked in oven(0.5387)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000023176.jpg"}, {"question": "what is holding the wooden fence together", "gt answer": "rope(1.00)", "pred answer": "wind", "question_id": 3742115, "best approach": "image", "verif answer": "rope", "anno approach": "wiki, concept, image", "verif wiki answer": "anchored(0.7307)", "verif concept answer": "strap(0.5595)", "verif image answer": "rope(0.6935)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374211.jpg"}, {"question": "is this a formal or informal gathering", "gt answer": "informal(1.00)", "pred answer": "casual", "question_id": 2561905, "best approach": "concept", "verif answer": "before", "anno approach": "wiki, concept, image", "verif wiki answer": "before(0.6795)", "verif concept answer": "informal(0.6689)", "verif image answer": "before(0.7190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256190.jpg"}, {"question": "how far above the headboard is the base of those lights hung on the wall", "gt answer": "3 feet(1.00)", "pred answer": "1 foot", "question_id": 4279465, "best approach": "image", "verif answer": "3 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "2 feet(0.5862)", "verif concept answer": "2 feet(0.5833)", "verif image answer": "3 feet(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427946.jpg"}, {"question": "what is the cause of the color of the vehicle", "gt answer": "rust(1.00)<br/>oxidation(0.60)", "pred answer": "green", "question_id": 4546815, "best approach": "concept, image", "verif answer": "oxidation", "anno approach": "wiki, concept, image", "verif wiki answer": "shadow(0.5925)", "verif concept answer": "oxidation(0.5605)", "verif image answer": "oxidation(0.7068)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000454681.jpg"}, {"question": "what is the symbol on the man 's head in the photo used for", "gt answer": "scan(1.00)", "pred answer": "park", "question_id": 2568515, "best approach": "", "verif answer": "scan", "anno approach": "wiki, concept, image", "verif wiki answer": "qr code(0.6466)", "verif concept answer": "teeth(0.5602)", "verif image answer": "teeth(0.6069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256851.jpg"}, {"question": "is this the home of a hoarder or normal person", "gt answer": "hoarder(1.00)", "pred answer": "normal", "question_id": 887595, "best approach": "", "verif answer": "normal", "anno approach": "wiki, concept, image", "verif wiki answer": "vegetarian(0.7207)", "verif concept answer": "normal(0.6864)", "verif image answer": "normal(0.5110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088759.jpg"}, {"question": "what model racket is that", "gt answer": "prince(1.00)", "pred answer": "wilson", "question_id": 1954845, "best approach": "wiki, concept, image", "verif answer": "tennis", "anno approach": "wiki, concept, image", "verif wiki answer": "prince(0.5436)", "verif concept answer": "prince(0.6591)", "verif image answer": "prince(0.5257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195484.jpg"}, {"question": "who invented the traffic device pictured here", "gt answer": "garrett morgan(1.00)", "pred answer": "electrician", "question_id": 1425105, "best approach": "wiki, image", "verif answer": "garrett morgan", "anno approach": "wiki, concept, image", "verif wiki answer": "garrett morgan(0.6943)", "verif concept answer": "human(0.5184)", "verif image answer": "garrett morgan(0.7203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142510.jpg"}, {"question": "what is the name of this game", "gt answer": "disc golf(1.00)", "pred answer": "frisbee", "question_id": 2336725, "best approach": "wiki, concept, image", "verif answer": "frisbee", "anno approach": "wiki, concept, image", "verif wiki answer": "disc golf(0.6845)", "verif concept answer": "disc golf(0.6717)", "verif image answer": "disc golf(0.7095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233672.jpg"}, {"question": "what is this guy pointing at", "gt answer": "tv(1.00)<br/>plant(0.60)<br/>screen(0.60)<br/>leaf(0.60)", "pred answer": "television", "question_id": 5759385, "best approach": "wiki, concept, image", "verif answer": "tv", "anno approach": "wiki, concept, image", "verif wiki answer": "screen(0.6726)", "verif concept answer": "screen(0.6770)", "verif image answer": "leaf(0.5479)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575938.jpg"}, {"question": "how old is the baby giraffe", "gt answer": "6 months(1.00)<br/>2 years(0.60)<br/>4 years(0.60)<br/>1 week(0.60)", "pred answer": "3", "question_id": 2701665, "best approach": "wiki, concept, image", "verif answer": "6 months", "anno approach": "wiki, concept, image", "verif wiki answer": "2 years(0.5989)", "verif concept answer": "1 week(0.6242)", "verif image answer": "2 years(0.6400)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270166.jpg"}, {"question": "is this person taking their dog for a walk or flying a kite", "gt answer": "both(1.00)<br/>fly kite(1.00)", "pred answer": "kite", "question_id": 3658175, "best approach": "concept", "verif answer": "fly kite", "anno approach": "wiki, concept, image", "verif wiki answer": "manmade(0.7272)", "verif concept answer": "fly kite(0.6969)", "verif image answer": "manmade(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365817.jpg"}, {"question": "what is the woman in yellow holding", "gt answer": "fan(1.00)<br/>bowl(0.60)", "pred answer": "row", "question_id": 2597175, "best approach": "wiki", "verif answer": "tablet", "anno approach": "wiki, concept, image", "verif wiki answer": "bowl(0.5909)", "verif concept answer": "tablet(0.7251)", "verif image answer": "tablet(0.6741)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259717.jpg"}, {"question": "what did he use to make the salad", "gt answer": "green(1.00)<br/>arugula(0.60)<br/>leaf(0.60)", "pred answer": "spoon", "question_id": 862855, "best approach": "wiki", "verif answer": "spinach", "anno approach": "wiki, concept, image", "verif wiki answer": "arugula(0.5477)", "verif concept answer": "spinach(0.5031)", "verif image answer": "spinach(0.5400)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086285.jpg"}, {"question": "", "gt answer": "1980's(0.60)<br/>1970\u00e2\u20ac\u2122s(0.60)<br/>70s(0.60)", "pred answer": "1970's", "question_id": 2707995, "best approach": "", "verif answer": "1970's", "anno approach": "wiki, concept, image", "verif wiki answer": "1950s(0.5364)", "verif concept answer": "1950s(0.5442)", "verif image answer": "1950s(0.5785)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270799.jpg"}, {"question": "name the place shown in this picture where the man is standing", "gt answer": "sidewalk(1.00)<br/>on sidewalk(0.60)<br/>new york(0.60)", "pred answer": "new york city", "question_id": 3304265, "best approach": "wiki, concept", "verif answer": "sidewalk", "anno approach": "wiki, concept, image", "verif wiki answer": "sidewalk(0.6966)", "verif concept answer": "sidewalk(0.7023)", "verif image answer": "crosswalk(0.5933)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000330426.jpg"}, {"question": "how long is this animals beak", "gt answer": "8 inches(1.00)<br/>1 foot(0.60)<br/>10 inches(0.60)", "pred answer": "2 feet", "question_id": 2969895, "best approach": "concept", "verif answer": "10 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "12 inches(0.7096)", "verif concept answer": "8 inches(0.5790)", "verif image answer": "12 inches(0.7018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296989.jpg"}, {"question": "what is the item in this picture used for", "gt answer": "fire hydrant(1.00)<br/>extinguish fire(0.60)<br/>hydrant(0.60)<br/>water(0.60)", "pred answer": "firefight", "question_id": 3923155, "best approach": "wiki, concept, image", "verif answer": "fire hydrant", "anno approach": "wiki, concept, image", "verif wiki answer": "hydrant(0.6748)", "verif concept answer": "hydrant(0.6852)", "verif image answer": "hydrant(0.5717)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392315.jpg"}, {"question": "what would i use to keep warm", "gt answer": "blanket(1.00)", "pred answer": "curtain", "question_id": 4665805, "best approach": "", "verif answer": "pillow", "anno approach": "wiki, concept, image", "verif wiki answer": "pillow(0.7304)", "verif concept answer": "pillow(0.7304)", "verif image answer": "quilt(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466580.jpg"}, {"question": "what are the dangers in bringing home this if it 's stray", "gt answer": "rabies(1.00)<br/>rabbi(0.60)", "pred answer": "toxoplasmosis", "question_id": 2990665, "best approach": "image", "verif answer": "aspca", "anno approach": "wiki, concept, image", "verif wiki answer": "aspca(0.6719)", "verif concept answer": "aspca(0.6239)", "verif image answer": "rabbi(0.7215)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000299066.jpg"}, {"question": "what is the name of this airplane company", "gt answer": "lufthansa(1.00)<br/>united(0.60)", "pred answer": "boeing", "question_id": 5792135, "best approach": "", "verif answer": "boeing", "anno approach": "wiki, concept, image", "verif wiki answer": "boeing(0.5547)", "verif concept answer": "boeing(0.5051)", "verif image answer": "american(0.6866)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000579213.jpg"}, {"question": "", "gt answer": "$1200(0.60)<br/>500(0.60)", "pred answer": "$100", "question_id": 5390565, "best approach": "", "verif answer": "$100", "anno approach": "wiki, concept, image", "verif wiki answer": "$100(0.5305)", "verif concept answer": "$100(0.5492)", "verif image answer": "$100(0.7205)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539056.jpg"}, {"question": "what is this man trying to do", "gt answer": "tennis(1.00)<br/>play tennis(1.00)<br/>backhand(0.60)", "pred answer": "serve", "question_id": 2162375, "best approach": "wiki, concept, image", "verif answer": "play tennis", "anno approach": "wiki, concept, image", "verif wiki answer": "play tennis(0.6738)", "verif concept answer": "play tennis(0.6764)", "verif image answer": "play tennis(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216237.jpg"}, {"question": "this bird is associated with which famous cartoon", "gt answer": "woody woodpecker(1.00)", "pred answer": "despicable me", "question_id": 3732925, "best approach": "image", "verif answer": "bird", "anno approach": "wiki, concept, image", "verif wiki answer": "bird(0.5009)", "verif concept answer": "schwinn(0.5511)", "verif image answer": "woody woodpecker(0.5421)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373292.jpg"}, {"question": "what is the portion of street between the two white lines called", "gt answer": "cross walk(1.00)<br/>crosswalk(1.00)", "pred answer": "sidewalk", "question_id": 2901745, "best approach": "", "verif answer": "crosswalk", "anno approach": "wiki, concept, image", "verif wiki answer": "line(0.5974)", "verif concept answer": "line(0.5678)", "verif image answer": "no park(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000290174.jpg"}, {"question": "what is there four of in the window", "gt answer": "pane(1.00)<br/>glass(0.60)", "pred answer": "shade", "question_id": 3989255, "best approach": "", "verif answer": "blind", "anno approach": "wiki, concept, image", "verif wiki answer": "blind(0.7297)", "verif concept answer": "blind(0.6974)", "verif image answer": "blind(0.5545)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398925.jpg"}, {"question": "how tall do these animals typically grow to be", "gt answer": "11 feet(1.00)<br/>12 feet(0.60)", "pred answer": "4 feet", "question_id": 2583815, "best approach": "", "verif answer": "20 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "20 feet(0.7060)", "verif concept answer": "20 feet(0.6397)", "verif image answer": "15 feet(0.5993)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258381.jpg"}, {"question": "what are these animals used for", "gt answer": "cloth(1.00)<br/>wool(1.00)", "pred answer": "eat", "question_id": 4982975, "best approach": "concept, image", "verif answer": "cloth", "anno approach": "wiki, concept, image", "verif wiki answer": "milk(0.7246)", "verif concept answer": "cloth(0.6943)", "verif image answer": "cloth(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000498297.jpg"}, {"question": "what activities suggest that these children may be having field day at school", "gt answer": "frisbee(1.00)", "pred answer": "catch", "question_id": 3971865, "best approach": "", "verif answer": "catch", "anno approach": "wiki, concept, image", "verif wiki answer": "hasbro(0.6651)", "verif concept answer": "catch(0.7084)", "verif image answer": "catch(0.7042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397186.jpg"}, {"question": "who invented this famous summer treat", "gt answer": "david evans strickler(1.00)", "pred answer": "ben franklin", "question_id": 4964295, "best approach": "wiki, concept", "verif answer": "italy", "anno approach": "wiki, concept, image", "verif wiki answer": "david evans strickler(0.7217)", "verif concept answer": "david evans strickler(0.6777)", "verif image answer": "mexico(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496429.jpg"}, {"question": "people do this for exercise why else do they do this", "gt answer": "competition(0.60)<br/>fun(0.60)<br/>run(1.00)", "pred answer": "rain", "question_id": 3085685, "best approach": "concept, image", "verif answer": "fun", "anno approach": "wiki, concept, image", "verif wiki answer": "for fun(0.7299)", "verif concept answer": "fun(0.7210)", "verif image answer": "fun(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308568.jpg"}, {"question": "what soda brand is in the background", "gt answer": "coca cola(1.00)", "pred answer": "coke", "question_id": 2870275, "best approach": "wiki, concept, image", "verif answer": "coca cola", "anno approach": "wiki, concept, image", "verif wiki answer": "coca cola(0.6786)", "verif concept answer": "coca cola(0.7202)", "verif image answer": "coca cola(0.6112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287027.jpg"}, {"question": "what does this bed need", "gt answer": "sheet(1.00)<br/>bed(0.60)", "pred answer": "vacuum", "question_id": 755585, "best approach": "concept", "verif answer": "duvet", "anno approach": "wiki, concept, image", "verif wiki answer": "duvet(0.5616)", "verif concept answer": "bed(0.6924)", "verif image answer": "hotel(0.5351)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075558.jpg"}, {"question": "how many different veggies are there", "gt answer": "5(1.00)<br/>6(1.00)<br/>4(0.60)", "pred answer": "8", "question_id": 2493655, "best approach": "wiki", "verif answer": "5", "anno approach": "wiki, concept, image", "verif wiki answer": "5(0.7232)", "verif concept answer": "3(0.6330)", "verif image answer": "4(0.5287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249365.jpg"}, {"question": "what type of weather is this", "gt answer": "cloudy(1.00)<br/>drought(0.60)<br/>cold(0.60)", "pred answer": "overcast", "question_id": 3859295, "best approach": "wiki, concept, image", "verif answer": "cloudy", "anno approach": "wiki, concept, image", "verif wiki answer": "cloudy(0.7079)", "verif concept answer": "cloudy(0.6762)", "verif image answer": "cloudy(0.7193)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385929.jpg"}, {"question": "what are these people wearing to protect from the sun", "gt answer": "sunscreen(1.00)<br/>bikini(0.60)", "pred answer": "umbrella", "question_id": 2662005, "best approach": "concept", "verif answer": "sunscreen", "anno approach": "wiki, concept, image", "verif wiki answer": "sun screen(0.7128)", "verif concept answer": "sunscreen(0.6932)", "verif image answer": "sun protection(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266200.jpg"}, {"question": "what company does this plane fly for", "gt answer": "american airline(1.00)", "pred answer": "united", "question_id": 2431025, "best approach": "wiki, concept", "verif answer": "american airline", "anno approach": "wiki, concept, image", "verif wiki answer": "american airline(0.5491)", "verif concept answer": "american airline(0.5269)", "verif image answer": "air canada(0.5195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243102.jpg"}, {"question": "what kind of food is he cooking", "gt answer": "hibachi(1.00)<br/>japanese(0.60)<br/>steak(0.60)", "pred answer": "meat", "question_id": 5494265, "best approach": "concept", "verif answer": "chinese", "anno approach": "wiki, concept, image", "verif wiki answer": "steak(0.6184)", "verif concept answer": "hibachi(0.6975)", "verif image answer": "japanese(0.6942)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000549426.jpg"}, {"question": "what is the imaginary line between these two groups of players called", "gt answer": "center(1.00)", "pred answer": "net", "question_id": 4742555, "best approach": "wiki, concept", "verif answer": "bleacher", "anno approach": "wiki, concept, image", "verif wiki answer": "center(0.5132)", "verif concept answer": "center(0.5435)", "verif image answer": "downtown(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000474255.jpg"}, {"question": "what is the actual name of this kind of tub", "gt answer": "hot tub(1.00)<br/>basin(0.60)<br/>ceramic(0.60)", "pred answer": "bath", "question_id": 2802675, "best approach": "concept", "verif answer": "bathroom", "anno approach": "wiki, concept, image", "verif wiki answer": "bathroom(0.7080)", "verif concept answer": "ceramic(0.7100)", "verif image answer": "bathroom(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280267.jpg"}, {"question": "what species of animal is this", "gt answer": "buffalo(1.00)<br/>zebra(0.60)", "pred answer": "duck", "question_id": 948135, "best approach": "", "verif answer": "elephant", "anno approach": "wiki, concept, image", "verif wiki answer": "cow(0.7213)", "verif concept answer": "elephant(0.6913)", "verif image answer": "elephant(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094813.jpg"}, {"question": "what can you eat after dinner is over", "gt answer": "cupcake(1.00)<br/>dessert(1.00)<br/>desert(0.60)", "pred answer": "cake", "question_id": 4368305, "best approach": "image", "verif answer": "cake", "anno approach": "wiki, concept, image", "verif wiki answer": "cake(0.7259)", "verif concept answer": "cake(0.7028)", "verif image answer": "cupcake(0.6944)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436830.jpg"}, {"question": "what company produces the most of the cooking appliance in this photo", "gt answer": "ge(1.00)<br/>frigidaire(0.60)<br/>lg(0.60)", "pred answer": "maytag", "question_id": 872175, "best approach": "wiki, concept, image", "verif answer": "kenmore", "anno approach": "wiki, concept, image", "verif wiki answer": "frigidaire(0.7200)", "verif concept answer": "frigidaire(0.6161)", "verif image answer": "frigidaire(0.6990)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087217.jpg"}, {"question": "what covers the animal 's body", "gt answer": "feather(1.00)", "pred answer": "fur", "question_id": 4687305, "best approach": "wiki, concept, image", "verif answer": "dog", "anno approach": "wiki, concept, image", "verif wiki answer": "feather(0.5301)", "verif concept answer": "feather(0.5184)", "verif image answer": "feather(0.5607)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000468730.jpg"}, {"question": "what holiday is this related to", "gt answer": "valentine(1.00)", "pred answer": "christmas", "question_id": 5184555, "best approach": "", "verif answer": "valentine's day", "anno approach": "wiki, concept, image", "verif wiki answer": "valentine's day(0.6613)", "verif concept answer": "teddy bear(0.6702)", "verif image answer": "valentine's day(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518455.jpg"}, {"question": "is this train regulated or unregulated", "gt answer": "regulated(1.00)", "pred answer": "legal", "question_id": 3767465, "best approach": "wiki, image", "verif answer": "both", "anno approach": "wiki, concept, image", "verif wiki answer": "regulated(0.5111)", "verif concept answer": "both(0.5022)", "verif image answer": "regulated(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376746.jpg"}, {"question": "what does the sign say", "gt answer": "western ave(1.00)", "pred answer": "street name", "question_id": 1425615, "best approach": "wiki, concept", "verif answer": "direction", "anno approach": "wiki, concept, image", "verif wiki answer": "western ave(0.5002)", "verif concept answer": "western ave(0.5009)", "verif image answer": "snake(0.5037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142561.jpg"}, {"question": "who was the famous african american urban legend to compete against one of these vehicular machines", "gt answer": "john henry(1.00)", "pred answer": "richard trevithick", "question_id": 946255, "best approach": "wiki, concept, image", "verif answer": "servihanca", "anno approach": "wiki, concept, image", "verif wiki answer": "john henry(0.5091)", "verif concept answer": "john henry(0.5201)", "verif image answer": "john henry(0.6170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094625.jpg"}, {"question": "what is on the bus", "gt answer": "ad(1.00)<br/>people(0.60)", "pred answer": "passenger", "question_id": 4846205, "best approach": "wiki, concept", "verif answer": "people", "anno approach": "wiki, concept, image", "verif wiki answer": "people(0.7274)", "verif concept answer": "people(0.7158)", "verif image answer": "bear(0.6589)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484620.jpg"}, {"question": "what is the most likely source of protein on this plate", "gt answer": "bacon(1.00)", "pred answer": "beef", "question_id": 1221445, "best approach": "", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "croissant(0.7027)", "verif concept answer": "croissant(0.6997)", "verif image answer": "cheese(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122144.jpg"}, {"question": "which group do these people belong to", "gt answer": "scout(1.00)<br/>boy scout(1.00)", "pred answer": "biker", "question_id": 812945, "best approach": "wiki, concept", "verif answer": "school", "anno approach": "wiki, concept, image", "verif wiki answer": "boy scout(0.6231)", "verif concept answer": "boy scout(0.5789)", "verif image answer": "school(0.5052)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081294.jpg"}, {"question": "what beverage is being served", "gt answer": "beer(1.00)", "pred answer": "tea", "question_id": 4978565, "best approach": "", "verif answer": "tea", "anno approach": "wiki, concept, image", "verif wiki answer": "tea(0.5236)", "verif concept answer": "tea(0.7220)", "verif image answer": "tea(0.5839)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497856.jpg"}, {"question": "which us state is known for its dairy farming and frequently displays statues like the one shown", "gt answer": "wisconsin(1.00)<br/>minnesota(0.60)<br/>california(0.60)", "pred answer": "washington", "question_id": 1235235, "best approach": "", "verif answer": "minnesota", "anno approach": "wiki, concept, image", "verif wiki answer": "china(0.5719)", "verif concept answer": "china(0.5445)", "verif image answer": "new york(0.6699)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123523.jpg"}, {"question": "what is different about these benches", "gt answer": "color(1.00)", "pred answer": "sit", "question_id": 1128055, "best approach": "", "verif answer": "nothing", "anno approach": "wiki, concept, image", "verif wiki answer": "nothing(0.6650)", "verif concept answer": "nothing(0.5185)", "verif image answer": "brand(0.5126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000112805.jpg"}, {"question": "why do small towns always have so many bars", "gt answer": "nothing else to do(1.00)<br/>boredom(0.60)", "pred answer": "bus stop", "question_id": 3832135, "best approach": "wiki, concept", "verif answer": "chicago", "anno approach": "wiki, concept, image", "verif wiki answer": "boredom(0.5665)", "verif concept answer": "boredom(0.5544)", "verif image answer": "chicago(0.6313)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383213.jpg"}, {"question": "what breed of dog is this", "gt answer": "bloodhound(1.00)<br/>hound(0.60)", "pred answer": "lab", "question_id": 712365, "best approach": "image", "verif answer": "hound", "anno approach": "wiki, concept, image", "verif wiki answer": "hound(0.6516)", "verif concept answer": "hound(0.6998)", "verif image answer": "bloodhound(0.7171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071236.jpg"}, {"question": "are these people competing or just enjoying the day skiing", "gt answer": "compete(1.00)", "pred answer": "fun", "question_id": 206115, "best approach": "", "verif answer": "eat", "anno approach": "wiki, concept, image", "verif wiki answer": "eat(0.7271)", "verif concept answer": "hike(0.6228)", "verif image answer": "hike(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020611.jpg"}, {"question": "what delightful insect is present on the upper blade", "gt answer": "ladybug(1.00)<br/>scissor(0.60)", "pred answer": "bee", "question_id": 3672715, "best approach": "wiki", "verif answer": "ladybug", "anno approach": "wiki, concept, image", "verif wiki answer": "ladybug(0.5578)", "verif concept answer": "mushroom(0.5205)", "verif image answer": "good(0.6729)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367271.jpg"}, {"question": "what type of geese are these", "gt answer": "canadian(1.00)<br/>canada goose(0.60)", "pred answer": "geese", "question_id": 3075075, "best approach": "image", "verif answer": "mallard", "anno approach": "wiki, concept, image", "verif wiki answer": "mallard(0.7255)", "verif concept answer": "canada goose(0.7161)", "verif image answer": "canadian(0.7032)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307507.jpg"}, {"question": "what is the name of the field where the yankees play at home", "gt answer": "yankee stadium(1.00)", "pred answer": "baseball field", "question_id": 5391805, "best approach": "image", "verif answer": "baseball stadium", "anno approach": "wiki, concept, image", "verif wiki answer": "yankees(0.6281)", "verif concept answer": "baseball stadium(0.6824)", "verif image answer": "yankee stadium(0.7159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539180.jpg"}, {"question": "what company does this plane belong to", "gt answer": "click(1.00)", "pred answer": "boeing", "question_id": 167845, "best approach": "", "verif answer": "csa", "anno approach": "wiki, concept, image", "verif wiki answer": "british airway(0.6355)", "verif concept answer": "american airline(0.5295)", "verif image answer": "csa(0.5852)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016784.jpg"}, {"question": "in what state in this being played", "gt answer": "ohio(1.00)<br/>new york(0.60)", "pred answer": "texas", "question_id": 1392305, "best approach": "wiki, concept", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "ohio(0.6465)", "verif concept answer": "ohio(0.6610)", "verif image answer": "boston(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139230.jpg"}, {"question": "where are these fruits most commonly farmed in the usa", "gt answer": "florida(1.00)<br/>banana(0.60)<br/>south(0.60)<br/>hawaii(0.60)", "pred answer": "tree", "question_id": 4277495, "best approach": "wiki, concept", "verif answer": "tropic", "anno approach": "wiki, concept, image", "verif wiki answer": "florida(0.7125)", "verif concept answer": "florida(0.7021)", "verif image answer": "hawaii(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427749.jpg"}, {"question": "what is this on the wall", "gt answer": "oven(1.00)", "pred answer": "tile", "question_id": 1829685, "best approach": "wiki, concept", "verif answer": "oven", "anno approach": "wiki, concept, image", "verif wiki answer": "oven(0.5080)", "verif concept answer": "oven(0.6888)", "verif image answer": "in oven(0.5051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182968.jpg"}, {"question": "does this person look more like a catholic or more like a slam poet", "gt answer": "catholic(1.00)", "pred answer": "cowboy", "question_id": 5367605, "best approach": "", "verif answer": "catholic", "anno approach": "wiki, concept, image", "verif wiki answer": "christian(0.7191)", "verif concept answer": "christian(0.6000)", "verif image answer": "christian(0.5520)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536760.jpg"}, {"question": "what news channel is she reporting for", "gt answer": "day today(1.00)<br/>morn(0.60)<br/>3(0.60)", "pred answer": "cnn", "question_id": 3214955, "best approach": "wiki, concept, image", "verif answer": "noon", "anno approach": "wiki, concept, image", "verif wiki answer": "day today(0.6372)", "verif concept answer": "day today(0.7282)", "verif image answer": "day today(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321495.jpg"}, {"question": "who is she dressed like", "gt answer": "sailor(1.00)", "pred answer": "police officer", "question_id": 5318615, "best approach": "", "verif answer": "baseball player", "anno approach": "wiki, concept, image", "verif wiki answer": "happy(0.6081)", "verif concept answer": "happy(0.5973)", "verif image answer": "bieber(0.5021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531861.jpg"}, {"question": "what does a person with a bad head cold have in common with this view", "gt answer": "congested(1.00)<br/>nothing(0.60)", "pred answer": "cold", "question_id": 1085005, "best approach": "wiki, concept", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "congested(0.7006)", "verif concept answer": "congested(0.6713)", "verif image answer": "sing(0.6779)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108500.jpg"}, {"question": "what are the birthday candles made from", "gt answer": "wax(1.00)", "pred answer": "candle", "question_id": 1088975, "best approach": "", "verif answer": "plastic", "anno approach": "wiki, concept, image", "verif wiki answer": "storage(0.5955)", "verif concept answer": "storage(0.6812)", "verif image answer": "storage(0.6891)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108897.jpg"}, {"question": "how is the man staying on the motorcycle", "gt answer": "balance(1.00)<br/>sit(0.60)", "pred answer": "helmet", "question_id": 3466535, "best approach": "wiki, concept", "verif answer": "balance", "anno approach": "wiki, concept, image", "verif wiki answer": "balance(0.6932)", "verif concept answer": "balance(0.6852)", "verif image answer": "sit(0.5710)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346653.jpg"}, {"question": "who was the train built for", "gt answer": "children(1.00)<br/>kid(1.00)", "pred answer": "transportation", "question_id": 4736425, "best approach": "wiki, image", "verif answer": "children", "anno approach": "wiki, concept, image", "verif wiki answer": "children(0.5841)", "verif concept answer": "child(0.5552)", "verif image answer": "children(0.5865)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473642.jpg"}, {"question": "what sort of vitamins do you get from eggs like this", "gt answer": "protein(1.00)<br/>(0.60)<br/>d(0.60)", "pred answer": "c", "question_id": 4273825, "best approach": "image", "verif answer": "", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin k(0.7221)", "verif concept answer": "vitamin k(0.6814)", "verif image answer": "(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427382.jpg"}, {"question": "what color is the vanity", "gt answer": "black(1.00)<br/>silver(0.60)", "pred answer": "white", "question_id": 493315, "best approach": "image", "verif answer": "black", "anno approach": "wiki, concept, image", "verif wiki answer": "red(0.7140)", "verif concept answer": "silver(0.7173)", "verif image answer": "black(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049331.jpg"}, {"question": "what kind of environment is in this image", "gt answer": "desert(1.00)", "pred answer": "mountain", "question_id": 4756565, "best approach": "wiki", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "desert(0.7299)", "verif concept answer": "mountain(0.6979)", "verif image answer": "mountain(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475656.jpg"}, {"question": "what are the rainbow colored items in the lawn called", "gt answer": "windmill(1.00)", "pred answer": "umbrella", "question_id": 1362025, "best approach": "", "verif answer": "umbrella", "anno approach": "wiki, concept, image", "verif wiki answer": "umbrella(0.7262)", "verif concept answer": "umbrella(0.7295)", "verif image answer": "umbrella(0.7161)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136202.jpg"}, {"question": "what kind of food is this", "gt answer": "condiment(1.00)", "pred answer": "cheese", "question_id": 410275, "best approach": "wiki", "verif answer": "smoothie", "anno approach": "wiki, concept, image", "verif wiki answer": "condiment(0.6915)", "verif concept answer": "tea(0.6740)", "verif image answer": "smoothie(0.6456)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041027.jpg"}, {"question": "what kind of relationship do these people have", "gt answer": "co worker(1.00)<br/>friend(0.60)", "pred answer": "family", "question_id": 494245, "best approach": "concept", "verif answer": "teammate", "anno approach": "wiki, concept, image", "verif wiki answer": "teammate(0.7241)", "verif concept answer": "friend(0.7037)", "verif image answer": "teammate(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049424.jpg"}, {"question": "what equiptment is needed to sit on the back of this animal", "gt answer": "saddle(1.00)", "pred answer": "mane", "question_id": 3749715, "best approach": "", "verif answer": "saddle", "anno approach": "wiki, concept, image", "verif wiki answer": "vest(0.6483)", "verif concept answer": "vest(0.7293)", "verif image answer": "vest(0.5869)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374971.jpg"}, {"question": "what do you do with these instruments", "gt answer": "sew(1.00)<br/>knit(0.60)", "pred answer": "cut", "question_id": 4270365, "best approach": "", "verif answer": "sew", "anno approach": "wiki, concept, image", "verif wiki answer": "crochet(0.5145)", "verif concept answer": "sew machine(0.5025)", "verif image answer": "crochet(0.5538)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427036.jpg"}, {"question": "when and what country was the toilet invented", "gt answer": "1596 england(1.00)<br/>japan(0.60)", "pred answer": "france", "question_id": 3652515, "best approach": "wiki, concept", "verif answer": "america", "anno approach": "wiki, concept, image", "verif wiki answer": "1596 england(0.5344)", "verif concept answer": "1596 england(0.5325)", "verif image answer": "europe(0.6063)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365251.jpg"}, {"question": "what brand are the clementines", "gt answer": "halo(1.00)", "pred answer": "mcintosh", "question_id": 4733725, "best approach": "", "verif answer": "mcintosh", "anno approach": "wiki, concept, image", "verif wiki answer": "mcintosh(0.7231)", "verif concept answer": "mcintosh(0.6570)", "verif image answer": "orange(0.6305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473372.jpg"}, {"question": "what does this sign signify", "gt answer": "texas(1.00)<br/>road(0.60)<br/>shop(0.60)", "pred answer": "street name", "question_id": 3125745, "best approach": "concept", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.6567)", "verif concept answer": "road(0.7248)", "verif image answer": "street(0.6624)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312574.jpg"}, {"question": "how tall is the batter", "gt answer": "5'10(1.00)<br/>6(0.60)", "pred answer": "4 feet", "question_id": 1159115, "best approach": "image", "verif answer": "6", "anno approach": "wiki, concept, image", "verif wiki answer": "6(0.7212)", "verif concept answer": "6(0.5875)", "verif image answer": "5'10(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115911.jpg"}, {"question": "what is making it impossible to see through the windows", "gt answer": "blind(1.00)<br/>glass(0.60)", "pred answer": "sun", "question_id": 5191135, "best approach": "image", "verif answer": "shade", "anno approach": "wiki, concept, image", "verif wiki answer": "curtain(0.6325)", "verif concept answer": "shade(0.6779)", "verif image answer": "glass(0.5672)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000519113.jpg"}, {"question": "how does this table close", "gt answer": "fold(1.00)", "pred answer": "anchor", "question_id": 4059205, "best approach": "wiki, concept, image", "verif answer": "umbrella", "anno approach": "wiki, concept, image", "verif wiki answer": "fold(0.5073)", "verif concept answer": "fold(0.5412)", "verif image answer": "fold(0.5522)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405920.jpg"}, {"question": "what is going to be cooked in the pot", "gt answer": "carrot(1.00)", "pred answer": "pasta", "question_id": 416455, "best approach": "wiki, concept", "verif answer": "carrot", "anno approach": "wiki, concept, image", "verif wiki answer": "carrot(0.7022)", "verif concept answer": "carrot(0.6898)", "verif image answer": "stew(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041645.jpg"}, {"question": "what is the life span of this animal", "gt answer": "30 years(1.00)<br/>40 years(0.60)", "pred answer": "20", "question_id": 491845, "best approach": "concept", "verif answer": "40 years", "anno approach": "wiki, concept, image", "verif wiki answer": "20 years(0.6704)", "verif concept answer": "30 years(0.6562)", "verif image answer": "25 years(0.6880)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049184.jpg"}, {"question": "how much do all of these animals drink in a day", "gt answer": "10 gallons(1.00)<br/>lot(0.60)", "pred answer": "50 gallons", "question_id": 3471115, "best approach": "concept, image", "verif answer": "500", "anno approach": "wiki, concept, image", "verif wiki answer": "5 gallons(0.6266)", "verif concept answer": "10 gallons(0.5624)", "verif image answer": "10 gallons(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347111.jpg"}, {"question": "what is this outfit used for", "gt answer": "ski(1.00)<br/>stay warm(0.60)<br/>cold weather(0.60)", "pred answer": "helmet", "question_id": 5219505, "best approach": "wiki, concept, image", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "cold weather(0.5574)", "verif concept answer": "stay warm(0.5313)", "verif image answer": "stay warm(0.5801)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521950.jpg"}, {"question": "what kind of shirt is this guy wearing", "gt answer": "button down(1.00)", "pred answer": "button up", "question_id": 390655, "best approach": "wiki, concept", "verif answer": "button up", "anno approach": "wiki, concept, image", "verif wiki answer": "button down(0.7083)", "verif concept answer": "button down(0.6964)", "verif image answer": "button up(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039065.jpg"}, {"question": "which mary poppins song features this high flyer", "gt answer": "let go fly kite(1.00)<br/>kite(0.60)", "pred answer": "beach boy", "question_id": 1653415, "best approach": "wiki, concept, image", "verif answer": "let go fly kite", "anno approach": "wiki, concept, image", "verif wiki answer": "let go fly kite(0.7027)", "verif concept answer": "let go fly kite(0.7287)", "verif image answer": "let go fly kite(0.6119)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000165341.jpg"}, {"question": "where are these people", "gt answer": "bar(1.00)<br/>restaurant(1.00)", "pred answer": "dine room", "question_id": 4586045, "best approach": "wiki, image", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "restaurant(0.6267)", "verif concept answer": "cafe(0.6828)", "verif image answer": "bar(0.6647)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458604.jpg"}, {"question": "what is the most offten accident that happens in this recreational activity", "gt answer": "drown(1.00)<br/>wipeout(0.60)", "pred answer": "wave", "question_id": 3411455, "best approach": "", "verif answer": "wave", "anno approach": "wiki, concept, image", "verif wiki answer": "crash(0.7173)", "verif concept answer": "wave(0.7130)", "verif image answer": "wave(0.7223)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341145.jpg"}, {"question": "what sort of items does this store sell", "gt answer": "bike(1.00)<br/>bicycle(0.60)", "pred answer": "cloth", "question_id": 4012255, "best approach": "wiki, concept", "verif answer": "bike", "anno approach": "wiki, concept, image", "verif wiki answer": "bike(0.5768)", "verif concept answer": "bike(0.6619)", "verif image answer": "cycling(0.5549)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401225.jpg"}, {"question": "what surface is this motorcycle on", "gt answer": "sand(1.00)<br/>beach(1.00)", "pred answer": "asphalt", "question_id": 2769095, "best approach": "image", "verif answer": "beach", "anno approach": "wiki, concept, image", "verif wiki answer": "ocean(0.6062)", "verif concept answer": "ocean(0.5785)", "verif image answer": "sand(0.6445)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276909.jpg"}, {"question": "in what country is the airline which operates this plane headquartered", "gt answer": "australia(1.00)<br/>london(0.60)<br/>japan(0.60)", "pred answer": "france", "question_id": 5114385, "best approach": "wiki, concept, image", "verif answer": "london", "anno approach": "wiki, concept, image", "verif wiki answer": "australia(0.5310)", "verif concept answer": "australia(0.5164)", "verif image answer": "australia(0.7165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511438.jpg"}, {"question": "what kind of motor do these types of boats have", "gt answer": "outboard(1.00)<br/>outdoor(0.60)<br/>gas(0.60)", "pred answer": "boat", "question_id": 5048945, "best approach": "wiki, concept, image", "verif answer": "outboard", "anno approach": "wiki, concept, image", "verif wiki answer": "outboard(0.7280)", "verif concept answer": "outboard(0.7090)", "verif image answer": "outboard(0.7017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000504894.jpg"}, {"question": "where do dolls call home", "gt answer": "dollhouse(1.00)<br/>wood(0.60)", "pred answer": "home", "question_id": 5123085, "best approach": "image", "verif answer": "house", "anno approach": "wiki, concept, image", "verif wiki answer": "wood(0.5046)", "verif concept answer": "house(0.7018)", "verif image answer": "dollhouse(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512308.jpg"}, {"question": "what 's the red items on the ground", "gt answer": "plantain(0.60)<br/>banana(1.00)<br/>feet(0.60)", "pred answer": "tomato", "question_id": 4860845, "best approach": "wiki, concept, image", "verif answer": "plantain", "anno approach": "wiki, concept, image", "verif wiki answer": "plantain(0.7275)", "verif concept answer": "plantain(0.6796)", "verif image answer": "plantain(0.7042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000486084.jpg"}, {"question": "what ingredients are in the first and second dishes", "gt answer": "potato(1.00)", "pred answer": "french fry", "question_id": 810125, "best approach": "wiki, concept", "verif answer": "potato", "anno approach": "wiki, concept, image", "verif wiki answer": "potato(0.5313)", "verif concept answer": "potato(0.5942)", "verif image answer": "bread(0.5122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081012.jpg"}, {"question": "what style crust is this pizza", "gt answer": "thin(1.00)", "pred answer": "deep dish", "question_id": 712655, "best approach": "wiki, concept, image", "verif answer": "french", "anno approach": "wiki, concept, image", "verif wiki answer": "thin(0.7284)", "verif concept answer": "thin(0.5593)", "verif image answer": "thin(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071265.jpg"}, {"question": "what type of jewelry uses a term similar to one of these veggies", "gt answer": "carrot(1.00)", "pred answer": "apple", "question_id": 204185, "best approach": "", "verif answer": "vegetable", "anno approach": "wiki, concept, image", "verif wiki answer": "root(0.6565)", "verif concept answer": "root(0.6470)", "verif image answer": "salmon(0.5882)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020418.jpg"}, {"question": "what does the bright red light on the vehicle mean", "gt answer": "brake(0.60)<br/>stopped(0.60)<br/>stop(1.00)<br/>break(0.60)", "pred answer": "caution", "question_id": 2918685, "best approach": "wiki, concept", "verif answer": "break", "anno approach": "wiki, concept, image", "verif wiki answer": "break(0.7247)", "verif concept answer": "break(0.6251)", "verif image answer": "drive(0.7116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291868.jpg"}, {"question": "how much do these dogs shed", "gt answer": "lot(1.00)", "pred answer": "1 pound", "question_id": 3867155, "best approach": "", "verif answer": "10 gallons", "anno approach": "wiki, concept, image", "verif wiki answer": "20 grams(0.6213)", "verif concept answer": "20 grams(0.6177)", "verif image answer": "10 gallons(0.6554)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000386715.jpg"}, {"question": "what kind of flowers are these", "gt answer": "orchid(1.00)", "pred answer": "daisy", "question_id": 3035075, "best approach": "", "verif answer": "daisy", "anno approach": "wiki, concept, image", "verif wiki answer": "daisy(0.7161)", "verif concept answer": "daisy(0.7122)", "verif image answer": "daisy(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303507.jpg"}, {"question": "should i continue straight or merge right", "gt answer": "merge right(1.00)<br/>straight(0.60)<br/>right(0.60)", "pred answer": "look", "question_id": 161135, "best approach": "wiki, concept, image", "verif answer": "down", "anno approach": "wiki, concept, image", "verif wiki answer": "merge right(0.7302)", "verif concept answer": "merge right(0.7280)", "verif image answer": "merge right(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016113.jpg"}, {"question": "what kind of bird is this", "gt answer": "cardinal(1.00)", "pred answer": "robin", "question_id": 594515, "best approach": "", "verif answer": "robin", "anno approach": "wiki, concept, image", "verif wiki answer": "robin(0.7048)", "verif concept answer": "robin(0.7182)", "verif image answer": "robin(0.6891)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059451.jpg"}, {"question": "is this kitchen clean or dirty", "gt answer": "clean(1.00)", "pred answer": "messy", "question_id": 3089795, "best approach": "wiki, concept", "verif answer": "messy", "anno approach": "wiki, concept, image", "verif wiki answer": "clean(0.5426)", "verif concept answer": "clean(0.5033)", "verif image answer": "messy(0.6017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308979.jpg"}, {"question": "how did this person fall out of their skis", "gt answer": "slipped(1.00)<br/>accident(0.60)", "pred answer": "lift", "question_id": 304375, "best approach": "wiki, concept", "verif answer": "lift", "anno approach": "wiki, concept, image", "verif wiki answer": "slipped(0.7186)", "verif concept answer": "slipped(0.6332)", "verif image answer": "lift(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030437.jpg"}, {"question": "what breed is the dog in this picture", "gt answer": "labrador(1.00)<br/>golden retriever(0.60)<br/>lab(0.60)", "pred answer": "poodle", "question_id": 1185635, "best approach": "wiki", "verif answer": "labrador", "anno approach": "wiki, concept, image", "verif wiki answer": "labrador(0.7222)", "verif concept answer": "greyhound(0.6206)", "verif image answer": "golden retriever(0.7069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118563.jpg"}, {"question": "which digit here is opposable", "gt answer": "thumb(1.00)<br/>first(0.60)", "pred answer": "pinkie", "question_id": 3372655, "best approach": "wiki, concept, image", "verif answer": "911", "anno approach": "wiki, concept, image", "verif wiki answer": "thumb(0.7127)", "verif concept answer": "thumb(0.5941)", "verif image answer": "thumb(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337265.jpg"}, {"question": "what shade of green did they use", "gt answer": "olive(1.00)<br/>pear(0.60)<br/>neon(0.60)<br/>lime(0.60)", "pred answer": "canola", "question_id": 5678995, "best approach": "concept, image", "verif answer": "olive", "anno approach": "wiki, concept, image", "verif wiki answer": "onion(0.7016)", "verif concept answer": "pear(0.6685)", "verif image answer": "pear(0.6361)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567899.jpg"}, {"question": "what fuel does the vehicle depicted consume", "gt answer": "coal(1.00)<br/>diesel(0.60)", "pred answer": "steam", "question_id": 4385755, "best approach": "wiki, concept, image", "verif answer": "coal", "anno approach": "wiki, concept, image", "verif wiki answer": "coal(0.7108)", "verif concept answer": "coal(0.6403)", "verif image answer": "coal(0.6091)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000438575.jpg"}, {"question": "what natural feature of space is seen as this colour", "gt answer": "sun(1.00)<br/>yellow(0.60)", "pred answer": "island", "question_id": 3211405, "best approach": "wiki, concept", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "sun(0.6111)", "verif concept answer": "sun(0.7209)", "verif image answer": "green(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321140.jpg"}, {"question": "based off of the technology what do you think this person is doing with it", "gt answer": "compos music(1.00)<br/>music(0.60)", "pred answer": "work", "question_id": 1425575, "best approach": "", "verif answer": "video game", "anno approach": "wiki, concept, image", "verif wiki answer": "video game(0.6907)", "verif concept answer": "picture(0.6807)", "verif image answer": "picture(0.6906)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142557.jpg"}, {"question": "what do the green letters and numbers on this bill mean", "gt answer": "money(0.60)<br/>serial number(1.00)", "pred answer": "love", "question_id": 2547955, "best approach": "wiki, image", "verif answer": "$15", "anno approach": "wiki, concept, image", "verif wiki answer": "money(0.6874)", "verif concept answer": "$15(0.7272)", "verif image answer": "money(0.6131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000254795.jpg"}, {"question": "what is an example of popular lingo this person might use", "gt answer": "hang 10(1.00)", "pred answer": "wave", "question_id": 419205, "best approach": "wiki", "verif answer": "o'neill world cup of surf", "anno approach": "wiki, concept, image", "verif wiki answer": "hang 10(0.7107)", "verif concept answer": "o'neill world cup of surf(0.6951)", "verif image answer": "sailboat(0.6455)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041920.jpg"}, {"question": "how do you tie a windsor knot", "gt answer": "hand(1.00)", "pred answer": "windsor", "question_id": 2052175, "best approach": "image", "verif answer": "brush", "anno approach": "wiki, concept, image", "verif wiki answer": "brush(0.5394)", "verif concept answer": "handmade(0.6743)", "verif image answer": "hand(0.7030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205217.jpg"}, {"question": "what brand of skis are being used", "gt answer": "rossignol(1.00)<br/>wilson(0.60)", "pred answer": "burton", "question_id": 2964035, "best approach": "wiki", "verif answer": "burton", "anno approach": "wiki, concept, image", "verif wiki answer": "wilson(0.7097)", "verif concept answer": "burton(0.6805)", "verif image answer": "burton(0.6662)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296403.jpg"}, {"question": "is this a homosexual or heterosexual relationship", "gt answer": "heterosexual(1.00)", "pred answer": "mother and son", "question_id": 3330665, "best approach": "", "verif answer": "female", "anno approach": "wiki, concept, image", "verif wiki answer": "happy(0.5215)", "verif concept answer": "happy(0.5162)", "verif image answer": "female(0.6080)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333066.jpg"}, {"question": "what chemical causes the fog to appear behind the objects in the air", "gt answer": "carbon(1.00)<br/>fertilizer(0.60)<br/>water(0.60)", "pred answer": "contrail", "question_id": 3320125, "best approach": "wiki, concept, image", "verif answer": "gas", "anno approach": "wiki, concept, image", "verif wiki answer": "carbon(0.6344)", "verif concept answer": "carbon(0.6439)", "verif image answer": "carbon(0.5712)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332012.jpg"}, {"question": "what airline does the plane belong to", "gt answer": "airbus(1.00)<br/>american(0.60)", "pred answer": "united", "question_id": 5397295, "best approach": "", "verif answer": "united", "anno approach": "wiki, concept, image", "verif wiki answer": "4300(0.5014)", "verif concept answer": "4300(0.5026)", "verif image answer": "united(0.6280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539729.jpg"}, {"question": "are the screens in this picture showing images or blank screens", "gt answer": "blank(1.00)", "pred answer": "type", "question_id": 5132405, "best approach": "", "verif answer": "manual", "anno approach": "wiki, concept, image", "verif wiki answer": "manual(0.5090)", "verif concept answer": "manual(0.5044)", "verif image answer": "manual(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513240.jpg"}, {"question": "what book is that man holding", "gt answer": "bible(1.00)", "pred answer": "magazine", "question_id": 1715665, "best approach": "image", "verif answer": "fairytale", "anno approach": "wiki, concept, image", "verif wiki answer": "kindergarten(0.6940)", "verif concept answer": "kindergarten(0.7139)", "verif image answer": "bible(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171566.jpg"}, {"question": "what are the materials used for making this toy shown in this photo", "gt answer": "legos(1.00)<br/>plastic(0.60)<br/>lego(0.60)", "pred answer": "cement", "question_id": 579695, "best approach": "", "verif answer": "paper", "anno approach": "wiki, concept, image", "verif wiki answer": "styrofoam(0.7019)", "verif concept answer": "styrofoam(0.6173)", "verif image answer": "styrofoam(0.6149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000057969.jpg"}, {"question": "what african country is this", "gt answer": "kenya(1.00)", "pred answer": "africa", "question_id": 5113905, "best approach": "", "verif answer": "africa", "anno approach": "wiki, concept, image", "verif wiki answer": "africa(0.5559)", "verif concept answer": "africa(0.6885)", "verif image answer": "africa(0.6740)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511390.jpg"}, {"question": "what base is this", "gt answer": "second(1.00)<br/>2nd(0.60)", "pred answer": "1st", "question_id": 1499165, "best approach": "", "verif answer": "1st", "anno approach": "wiki, concept, image", "verif wiki answer": "third(0.7308)", "verif concept answer": "1st(0.6868)", "verif image answer": "1st(0.7106)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149916.jpg"}, {"question": "what hit reality show features this environment", "gt answer": "hell kitchen(1.00)", "pred answer": "friend", "question_id": 2356835, "best approach": "concept, image", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "friend(0.7072)", "verif concept answer": "hell kitchen(0.5523)", "verif image answer": "hell kitchen(0.6194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000235683.jpg"}, {"question": "what company is featured in this picture", "gt answer": "sprint(1.00)", "pred answer": "internet", "question_id": 5180715, "best approach": "", "verif answer": "dunkin donuts", "anno approach": "wiki, concept, image", "verif wiki answer": "dunkin donuts(0.5214)", "verif concept answer": "krispy kreme(0.5176)", "verif image answer": "dunkin donuts(0.6828)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518071.jpg"}, {"question": "when would you usually use the item the woman is looking at", "gt answer": "travel(1.00)<br/>vacation(0.60)", "pred answer": "night", "question_id": 134175, "best approach": "wiki, concept", "verif answer": "travel", "anno approach": "wiki, concept, image", "verif wiki answer": "travel(0.7139)", "verif concept answer": "travel(0.5052)", "verif image answer": "luggage(0.5014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013417.jpg"}, {"question": "what song does this make", "gt answer": "chirp(1.00)", "pred answer": "national anthem", "question_id": 4014345, "best approach": "", "verif answer": "national anthem", "anno approach": "wiki, concept, image", "verif wiki answer": "national anthem(0.7258)", "verif concept answer": "national anthem(0.6899)", "verif image answer": "national anthem(0.5028)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401434.jpg"}, {"question": "what is being prepared for", "gt answer": "fire(1.00)<br/>heat(0.60)<br/>warmth(0.60)", "pred answer": "cook", "question_id": 4421815, "best approach": "wiki, concept", "verif answer": "cook", "anno approach": "wiki, concept, image", "verif wiki answer": "fire(0.6174)", "verif concept answer": "fire(0.6658)", "verif image answer": "warmth(0.6594)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442181.jpg"}, {"question": "what ethnic type of cuisne is the food shown", "gt answer": "greek(1.00)<br/>american(1.00)", "pred answer": "indian", "question_id": 789095, "best approach": "", "verif answer": "american", "anno approach": "wiki, concept, image", "verif wiki answer": "italian(0.7113)", "verif concept answer": "roman(0.6995)", "verif image answer": "roman(0.6789)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078909.jpg"}, {"question": "what activity is this", "gt answer": "snowboard(1.00)", "pred answer": "golf", "question_id": 1327245, "best approach": "wiki, concept, image", "verif answer": "snowboard", "anno approach": "wiki, concept, image", "verif wiki answer": "snowboard(0.6540)", "verif concept answer": "snowboard(0.5882)", "verif image answer": "snowboard(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000132724.jpg"}, {"question": "what geologic process creates terrain of this type", "gt answer": "erosion(1.00)<br/>rock(0.60)", "pred answer": "mountain", "question_id": 2643775, "best approach": "wiki, concept, image", "verif answer": "stone", "anno approach": "wiki, concept, image", "verif wiki answer": "erosion(0.7169)", "verif concept answer": "erosion(0.5402)", "verif image answer": "erosion(0.6780)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000264377.jpg"}, {"question": "what kind of food is being sold in the image", "gt answer": "snack(1.00)<br/>street(0.60)<br/>bread(0.60)<br/>rice(0.60)", "pred answer": "sushi", "question_id": 2631115, "best approach": "wiki, concept", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "snack(0.7251)", "verif concept answer": "snack(0.7296)", "verif image answer": "rice(0.7157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263111.jpg"}, {"question": "whichi sesame street character would eat this", "gt answer": "cookie monster(1.00)", "pred answer": "mickey mouse", "question_id": 2284195, "best approach": "wiki, concept, image", "verif answer": "van", "anno approach": "wiki, concept, image", "verif wiki answer": "cookie monster(0.7239)", "verif concept answer": "cookie monster(0.7201)", "verif image answer": "cookie monster(0.7257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000228419.jpg"}, {"question": "what kind of bicycle is he riding", "gt answer": "regular(1.00)<br/>mountain bike(0.60)", "pred answer": "schwinn", "question_id": 5393585, "best approach": "concept", "verif answer": "bicycle", "anno approach": "wiki, concept, image", "verif wiki answer": "bicycle(0.6622)", "verif concept answer": "regular(0.7170)", "verif image answer": "van(0.7222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539358.jpg"}, {"question": "what might this man be shouting while running towards his destination", "gt answer": "surf up(1.00)", "pred answer": "wave", "question_id": 4306105, "best approach": "wiki, concept", "verif answer": "anger", "anno approach": "wiki, concept, image", "verif wiki answer": "surf up(0.7153)", "verif concept answer": "surf up(0.6689)", "verif image answer": "anger(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430610.jpg"}, {"question": "the base that the hitter is touching with his foot is also called what sort of plate", "gt answer": "home plate(1.00)<br/>diamond(0.60)<br/>home(0.60)", "pred answer": "base", "question_id": 1778215, "best approach": "image", "verif answer": "home plate", "anno approach": "wiki, concept, image", "verif wiki answer": "diamond(0.6436)", "verif concept answer": "diamond(0.5308)", "verif image answer": "home plate(0.6021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177821.jpg"}, {"question": "why is this activity forbidden", "gt answer": "danger(1.00)<br/>unsafe(0.60)", "pred answer": "hot", "question_id": 3198555, "best approach": "", "verif answer": "distraction", "anno approach": "wiki, concept, image", "verif wiki answer": "distraction(0.7228)", "verif concept answer": "distraction(0.6704)", "verif image answer": "wild(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319855.jpg"}, {"question": "what kind of bear is depicted here", "gt answer": "polar(1.00)<br/>brown(0.60)", "pred answer": "grizzly", "question_id": 2044585, "best approach": "", "verif answer": "grizzly", "anno approach": "wiki, concept, image", "verif wiki answer": "grizzly(0.7246)", "verif concept answer": "polar bear(0.6652)", "verif image answer": "polar bear(0.5660)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000204458.jpg"}, {"question": "what technological device has replaced the object the woman is holding", "gt answer": "tablet(1.00)<br/>television(0.60)<br/>laptop(0.60)", "pred answer": "remote", "question_id": 4364535, "best approach": "wiki, concept", "verif answer": "samsung", "anno approach": "wiki, concept, image", "verif wiki answer": "laptop(0.5011)", "verif concept answer": "television(0.5006)", "verif image answer": "samsung(0.5072)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436453.jpg"}, {"question": "name the type of birds shown in the cage", "gt answer": "parakeet(1.00)<br/>parrot(0.60)", "pred answer": "pelican", "question_id": 884705, "best approach": "wiki", "verif answer": "parakeet", "anno approach": "wiki, concept, image", "verif wiki answer": "parrot(0.6733)", "verif concept answer": "blue(0.6664)", "verif image answer": "pigeon(0.7153)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088470.jpg"}, {"question": "what is the name of the bean that the flavor of the cupcake comes from", "gt answer": "cocoa(1.00)<br/>coffee(0.60)", "pred answer": "chocolate", "question_id": 5388215, "best approach": "", "verif answer": "vanilla", "anno approach": "wiki, concept, image", "verif wiki answer": "espresso(0.6127)", "verif concept answer": "espresso(0.7273)", "verif image answer": "vanilla(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538821.jpg"}, {"question": "what kind of bird is pictured", "gt answer": "vulture(1.00)<br/>turkey(0.60)", "pred answer": "pigeon", "question_id": 1499155, "best approach": "wiki", "verif answer": "pelican", "anno approach": "wiki, concept, image", "verif wiki answer": "vulture(0.7183)", "verif concept answer": "crow(0.6490)", "verif image answer": "pelican(0.6118)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149915.jpg"}, {"question": "where is the light source coming from", "gt answer": "lamp(1.00)<br/>ceiling(0.60)", "pred answer": "window", "question_id": 5092105, "best approach": "wiki", "verif answer": "lamp", "anno approach": "wiki, concept, image", "verif wiki answer": "lamp(0.7056)", "verif concept answer": "overhead(0.6684)", "verif image answer": "fluorescent(0.7038)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509210.jpg"}, {"question": "what kind of trick is this", "gt answer": "skateboard(1.00)<br/>ollie(0.60)", "pred answer": "kickflip", "question_id": 3999735, "best approach": "", "verif answer": "ollie", "anno approach": "wiki, concept, image", "verif wiki answer": "skate(0.7102)", "verif concept answer": "skate(0.6762)", "verif image answer": "jump(0.7110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399973.jpg"}, {"question": "who won the game", "gt answer": "girl(1.00)<br/>boy(0.60)", "pred answer": "ben franklin", "question_id": 3079685, "best approach": "wiki, concept", "verif answer": "pitcher", "anno approach": "wiki, concept, image", "verif wiki answer": "boy(0.5926)", "verif concept answer": "boy(0.6410)", "verif image answer": "box(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307968.jpg"}, {"question": "what is the food resting on", "gt answer": "plate(1.00)", "pred answer": "table", "question_id": 4993665, "best approach": "wiki", "verif answer": "cake", "anno approach": "wiki, concept, image", "verif wiki answer": "plate(0.6640)", "verif concept answer": "cake(0.5615)", "verif image answer": "pan(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499366.jpg"}, {"question": "what is behind the curtain", "gt answer": "shower(1.00)<br/>bathtub(1.00)<br/>door(0.60)", "pred answer": "wall", "question_id": 1114325, "best approach": "concept", "verif answer": "bath", "anno approach": "wiki, concept, image", "verif wiki answer": "bath(0.7234)", "verif concept answer": "door(0.7298)", "verif image answer": "cabinet(0.5007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111432.jpg"}, {"question": "how old is the lamb", "gt answer": "2(1.00)<br/>newborn(0.60)<br/>15(0.60)<br/>baby(0.60)", "pred answer": "8 months", "question_id": 1255675, "best approach": "wiki, concept, image", "verif answer": "15", "anno approach": "wiki, concept, image", "verif wiki answer": "newborn(0.5519)", "verif concept answer": "newborn(0.6174)", "verif image answer": "15(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125567.jpg"}, {"question": "when was this company on the watch founded", "gt answer": "1946(1.00)<br/>1900(0.60)<br/>1950(0.60)<br/>1948(0.60)", "pred answer": "1950s", "question_id": 229585, "best approach": "wiki, concept", "verif answer": "1945", "anno approach": "wiki, concept, image", "verif wiki answer": "1950(0.5238)", "verif concept answer": "1950(0.5283)", "verif image answer": "1945(0.5368)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000022958.jpg"}, {"question": "when do you pay to use this transportation online or at the door", "gt answer": "online(1.00)", "pred answer": "take off", "question_id": 5198455, "best approach": "wiki, concept", "verif answer": "online", "anno approach": "wiki, concept, image", "verif wiki answer": "online(0.5025)", "verif concept answer": "online(0.5031)", "verif image answer": "store(0.5090)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000519845.jpg"}, {"question": "what is the process used to make the material this sofa is made from", "gt answer": "tan(1.00)", "pred answer": "microfiber", "question_id": 2813826, "best approach": "", "verif answer": "cotton", "anno approach": "wiki, concept, image", "verif wiki answer": "relaxation(0.6204)", "verif concept answer": "relaxation(0.5037)", "verif image answer": "swim(0.6073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281382.jpg"}, {"question": "what is the brown sand made out of", "gt answer": "rock(1.00)<br/>stone(0.60)<br/>shell(0.60)", "pred answer": "sand", "question_id": 1460845, "best approach": "wiki, image", "verif answer": "sand", "anno approach": "wiki, concept, image", "verif wiki answer": "stone(0.7245)", "verif concept answer": "sand(0.7005)", "verif image answer": "stone(0.7276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146084.jpg"}, {"question": "what makes bread brown", "gt answer": "heat(1.00)<br/>toaster(0.60)<br/>wheat(0.60)", "pred answer": "0", "question_id": 4943835, "best approach": "wiki, image", "verif answer": "wheat", "anno approach": "wiki, concept, image", "verif wiki answer": "heat(0.5480)", "verif concept answer": "wheat(0.5434)", "verif image answer": "heat(0.6007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494383.jpg"}, {"question": "is that a tv or a computer", "gt answer": "tv(1.00)", "pred answer": "pc", "question_id": 1461715, "best approach": "wiki, concept, image", "verif answer": "television", "anno approach": "wiki, concept, image", "verif wiki answer": "tv(0.7275)", "verif concept answer": "tv(0.7281)", "verif image answer": "tv(0.6673)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146171.jpg"}, {"question": "what is the best color is best for keeping in heat", "gt answer": "black(1.00)", "pred answer": "red", "question_id": 4048995, "best approach": "", "verif answer": "red", "anno approach": "wiki, concept, image", "verif wiki answer": "red(0.6546)", "verif concept answer": "black bear(0.6934)", "verif image answer": "red(0.7054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404899.jpg"}, {"question": "how far they are away from the shore", "gt answer": "30 feet(1.00)<br/>50 feet(0.60)", "pred answer": "2 miles", "question_id": 3589655, "best approach": "wiki", "verif answer": "30 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "30 feet(0.5711)", "verif concept answer": "50 feet(0.6596)", "verif image answer": "close(0.5045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358965.jpg"}, {"question": "where is the natural habitat of this animal", "gt answer": "north pole(1.00)<br/>canada(0.60)<br/>wood(0.60)<br/>wild(0.60)", "pred answer": "alaska", "question_id": 3439935, "best approach": "wiki, concept, image", "verif answer": "wild", "anno approach": "wiki, concept, image", "verif wiki answer": "wild(0.7204)", "verif concept answer": "wild(0.6529)", "verif image answer": "wood(0.6862)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343993.jpg"}, {"question": "of what kind of materials is this house constructed", "gt answer": "concrete(1.00)", "pred answer": "wood", "question_id": 191365, "best approach": "concept", "verif answer": "wood", "anno approach": "wiki, concept, image", "verif wiki answer": "cement(0.6788)", "verif concept answer": "concrete(0.6126)", "verif image answer": "cement(0.7035)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019136.jpg"}, {"question": "what year is the plane in the air from", "gt answer": "1960(1.00)<br/>1940(0.60)<br/>1941(0.60)<br/>1946(0.60)", "pred answer": "1970", "question_id": 369075, "best approach": "wiki", "verif answer": "1970's", "anno approach": "wiki, concept, image", "verif wiki answer": "1940(0.6817)", "verif concept answer": "1970's(0.6308)", "verif image answer": "1970's(0.7112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036907.jpg"}, {"question": "which sports team does her jersey represent", "gt answer": "georgia(1.00)<br/>softball(0.60)", "pred answer": "football", "question_id": 3578985, "best approach": "wiki, image", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "georgia(0.5632)", "verif concept answer": "yankees(0.6965)", "verif image answer": "georgia(0.6780)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357898.jpg"}, {"question": "what breed of sheep are these", "gt answer": "merino(1.00)<br/>white(0.60)", "pred answer": "sheep", "question_id": 948265, "best approach": "concept", "verif answer": "ewe", "anno approach": "wiki, concept, image", "verif wiki answer": "ewe(0.6374)", "verif concept answer": "white(0.5879)", "verif image answer": "ewe(0.6649)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094826.jpg"}, {"question": "what creatures live in these dwellings", "gt answer": "human(1.00)<br/>people(1.00)", "pred answer": "monkey", "question_id": 3598975, "best approach": "wiki, concept, image", "verif answer": "human", "anno approach": "wiki, concept, image", "verif wiki answer": "human(0.7153)", "verif concept answer": "human(0.6601)", "verif image answer": "human(0.7072)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359897.jpg"}, {"question": "why would we suspect that this meal is occurring during the autumn season", "gt answer": "thanksgiving(1.00)<br/>beer(0.60)", "pred answer": "hot", "question_id": 3736975, "best approach": "", "verif answer": "july 4th", "anno approach": "wiki, concept, image", "verif wiki answer": "christmas(0.5040)", "verif concept answer": "july 4th(0.5347)", "verif image answer": "july 4th(0.6254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373697.jpg"}, {"question": "what type of dog is that", "gt answer": "chow(1.00)<br/>terrier(0.60)<br/>lab(0.60)", "pred answer": "pomeranian", "question_id": 3449215, "best approach": "image", "verif answer": "chihuahua", "anno approach": "wiki, concept, image", "verif wiki answer": "chihuahua(0.6480)", "verif concept answer": "chihuahua(0.5852)", "verif image answer": "chow(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344921.jpg"}, {"question": "when was this sign first used", "gt answer": "1920(1.00)<br/>2000(0.60)<br/>train(0.60)", "pred answer": "1914", "question_id": 168395, "best approach": "", "verif answer": "1950", "anno approach": "wiki, concept, image", "verif wiki answer": "1950(0.5837)", "verif concept answer": "1989(0.5480)", "verif image answer": "1989(0.6830)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016839.jpg"}, {"question": "is this used for food or music", "gt answer": "music(1.00)", "pred answer": "computer", "question_id": 5569835, "best approach": "concept", "verif answer": "music", "anno approach": "wiki, concept, image", "verif wiki answer": "decoration(0.6905)", "verif concept answer": "music(0.5732)", "verif image answer": "compos music(0.7032)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556983.jpg"}, {"question": "what kind of mask is this", "gt answer": "gimp(1.00)<br/>leather(0.60)", "pred answer": "sunglasses", "question_id": 2062795, "best approach": "", "verif answer": "sunglasses", "anno approach": "wiki, concept, image", "verif wiki answer": "faux(0.6939)", "verif concept answer": "sunglasses(0.7129)", "verif image answer": "rubber(0.7227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206279.jpg"}, {"question": "what drinks might be served in this environment", "gt answer": "alcohol(1.00)<br/>wine(0.60)<br/>lemonade(0.60)<br/>alcoholic(0.60)", "pred answer": "beer", "question_id": 1183305, "best approach": "wiki, concept", "verif answer": "cocktail", "anno approach": "wiki, concept, image", "verif wiki answer": "alcoholic(0.6571)", "verif concept answer": "alcoholic(0.6877)", "verif image answer": "cocktail(0.7084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118330.jpg"}, {"question": "what type of food is this", "gt answer": "pastry(1.00)<br/>danish(0.60)", "pred answer": "donut", "question_id": 2270665, "best approach": "image", "verif answer": "pastry", "anno approach": "wiki, concept, image", "verif wiki answer": "cupcake(0.7085)", "verif concept answer": "cupcake(0.6662)", "verif image answer": "pastry(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000227066.jpg"}, {"question": "what type of fuel does this airplane use", "gt answer": "jet fuel(1.00)<br/>oil(0.60)<br/>jet(0.60)", "pred answer": "gasoline", "question_id": 171475, "best approach": "wiki, concept", "verif answer": "gasoline", "anno approach": "wiki, concept, image", "verif wiki answer": "jet fuel(0.6966)", "verif concept answer": "jet fuel(0.5610)", "verif image answer": "jet(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000017147.jpg"}, {"question": "why are there so many bears", "gt answer": "collection(1.00)<br/>child(0.60)", "pred answer": "sleepover", "question_id": 5514345, "best approach": "image", "verif answer": "child", "anno approach": "wiki, concept, image", "verif wiki answer": "child(0.6379)", "verif concept answer": "child(0.6611)", "verif image answer": "collection(0.6229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000551434.jpg"}, {"question": "name the metal structure where some audience is sitting", "gt answer": "bleacher(1.00)<br/>bench(0.60)", "pred answer": "fence", "question_id": 153025, "best approach": "image", "verif answer": "bleacher", "anno approach": "wiki, concept, image", "verif wiki answer": "swing(0.5452)", "verif concept answer": "table(0.6055)", "verif image answer": "bleacher(0.5935)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015302.jpg"}, {"question": "in which century was this photo taken", "gt answer": "nineteenth(1.00)<br/>18(0.60)<br/>1800(0.60)", "pred answer": "19th", "question_id": 94655, "best approach": "wiki, concept, image", "verif answer": "1800s", "anno approach": "wiki, concept, image", "verif wiki answer": "nineteenth(0.6792)", "verif concept answer": "nineteenth(0.6539)", "verif image answer": "nineteenth(0.6232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009465.jpg"}, {"question": "how much time per day does the average person spend on the device", "gt answer": "2 hours(1.00)<br/>1 hour(0.60)", "pred answer": "80", "question_id": 4064465, "best approach": "wiki, concept, image", "verif answer": "1 hour", "anno approach": "wiki, concept, image", "verif wiki answer": "2 hours(0.6458)", "verif concept answer": "2 hours(0.6011)", "verif image answer": "2 hours(0.6542)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000406446.jpg"}, {"question": "is this a girl or boy room", "gt answer": "girl(1.00)<br/>both(0.60)", "pred answer": "boy", "question_id": 4325985, "best approach": "wiki, concept, image", "verif answer": "boy", "anno approach": "wiki, concept, image", "verif wiki answer": "girl(0.7143)", "verif concept answer": "girl(0.6824)", "verif image answer": "girl(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432598.jpg"}, {"question": "is it raining or sunny", "gt answer": "rain(1.00)<br/>sunny(0.60)", "pred answer": "rainy", "question_id": 5651105, "best approach": "", "verif answer": "rainy", "anno approach": "wiki, concept, image", "verif wiki answer": "rainy(0.6872)", "verif concept answer": "it rain(0.6436)", "verif image answer": "it rain(0.7256)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000565110.jpg"}, {"question": "what is all of this food for", "gt answer": "picnic(1.00)<br/>party(1.00)", "pred answer": "eat", "question_id": 5059035, "best approach": "wiki, concept, image", "verif answer": "party", "anno approach": "wiki, concept, image", "verif wiki answer": "picnic(0.5297)", "verif concept answer": "picnic(0.5008)", "verif image answer": "party(0.6368)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505903.jpg"}, {"question": "what is the speed limit on this road", "gt answer": "65 mph(1.00)", "pred answer": "30mph", "question_id": 3596255, "best approach": "image", "verif answer": "low", "anno approach": "wiki, concept, image", "verif wiki answer": "40 mph(0.6836)", "verif concept answer": "80 beats per second(0.5428)", "verif image answer": "65 mph(0.6414)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359625.jpg"}, {"question": "where would water flow down if it rained", "gt answer": "gutter(1.00)<br/>down(0.60)<br/>street(0.60)", "pred answer": "philadelphia", "question_id": 781965, "best approach": "wiki", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.6213)", "verif concept answer": "outside(0.6572)", "verif image answer": "pavement(0.7031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078196.jpg"}, {"question": "what animal is the bush remind you of", "gt answer": "elephant(1.00)", "pred answer": "bear", "question_id": 2395055, "best approach": "wiki, concept, image", "verif answer": "elephant", "anno approach": "wiki, concept, image", "verif wiki answer": "elephant(0.7292)", "verif concept answer": "elephant(0.7200)", "verif image answer": "elephant(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000239505.jpg"}, {"question": "what famous circus is this", "gt answer": "ringling bros(1.00)", "pred answer": "california", "question_id": 1762135, "best approach": "concept, image", "verif answer": "chicago", "anno approach": "wiki, concept, image", "verif wiki answer": "chicago(0.5312)", "verif concept answer": "ringling bros(0.5332)", "verif image answer": "ringling bros(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176213.jpg"}, {"question": "what muscles are being flexed in this photo", "gt answer": "arm(1.00)", "pred answer": "leg", "question_id": 4992395, "best approach": "wiki, concept, image", "verif answer": "leg", "anno approach": "wiki, concept, image", "verif wiki answer": "arm(0.6497)", "verif concept answer": "arm(0.6383)", "verif image answer": "arm(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499239.jpg"}, {"question": "what are they making", "gt answer": "cake(1.00)<br/>cookies(0.60)<br/>cupcake(0.60)<br/>pancake(0.60)", "pred answer": "food", "question_id": 3432845, "best approach": "wiki, image", "verif answer": "cupcake", "anno approach": "wiki, concept, image", "verif wiki answer": "cupcake(0.5981)", "verif concept answer": "desert(0.6094)", "verif image answer": "pancake(0.6886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343284.jpg"}, {"question": "what is the scientific name for the imprint made from the sun", "gt answer": "shadow(1.00)<br/>reflection(0.60)", "pred answer": "sun", "question_id": 1716565, "best approach": "concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "reflection(0.7303)", "verif concept answer": "shadow(0.6741)", "verif image answer": "light(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171656.jpg"}, {"question": "where is the photographer taking this picture from", "gt answer": "under umbrella(1.00)<br/>germany(0.60)<br/>table(0.60)", "pred answer": "city", "question_id": 3190055, "best approach": "", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "restaurant(0.6473)", "verif concept answer": "restaurant(0.6929)", "verif image answer": "restaurant(0.6879)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319005.jpg"}, {"question": "how old do you have to be to ride a bike like that", "gt answer": "16(1.00)<br/>18(1.00)<br/>18 years(0.60)", "pred answer": "17", "question_id": 2978705, "best approach": "", "verif answer": "18", "anno approach": "wiki, concept, image", "verif wiki answer": "nineteenth(0.5688)", "verif concept answer": "nineteenth(0.5995)", "verif image answer": "nineteenth(0.6686)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297870.jpg"}, {"question": "what kind of carpet is the baby sitting on", "gt answer": "rug(1.00)", "pred answer": "oriental", "question_id": 5586195, "best approach": "", "verif answer": "carpet", "anno approach": "wiki, concept, image", "verif wiki answer": "maple(0.6144)", "verif concept answer": "maple(0.6941)", "verif image answer": "maple(0.6477)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558619.jpg"}, {"question": "what city is this from", "gt answer": "washington dc(1.00)<br/>california(0.60)<br/>rome(0.60)<br/>washington(0.60)", "pred answer": "beijing", "question_id": 3162755, "best approach": "wiki, concept", "verif answer": "washington", "anno approach": "wiki, concept, image", "verif wiki answer": "washington(0.6602)", "verif concept answer": "washington(0.6740)", "verif image answer": "usa(0.5874)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316275.jpg"}, {"question": "what does the sign say", "gt answer": "no u turn(1.00)", "pred answer": "1 way", "question_id": 5154275, "best approach": "wiki, concept, image", "verif answer": "1 way", "anno approach": "wiki, concept, image", "verif wiki answer": "no u turn(0.7284)", "verif concept answer": "no u turn(0.7191)", "verif image answer": "no u turn(0.7311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515427.jpg"}, {"question": "what warm covering is used when sleep in this place", "gt answer": "blanket(1.00)<br/>comforter(1.00)", "pred answer": "curtain", "question_id": 590825, "best approach": "wiki, concept, image", "verif answer": "comforter", "anno approach": "wiki, concept, image", "verif wiki answer": "blanket(0.7280)", "verif concept answer": "blanket(0.5028)", "verif image answer": "blanket(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059082.jpg"}, {"question": "are these veggies home grown or bought", "gt answer": "bought(1.00)<br/>organic(0.60)", "pred answer": "store bought", "question_id": 2845455, "best approach": "wiki, concept, image", "verif answer": "grocery store", "anno approach": "wiki, concept, image", "verif wiki answer": "organic(0.6937)", "verif concept answer": "organic(0.6954)", "verif image answer": "organic(0.7230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284545.jpg"}, {"question": "what is this bird perched on", "gt answer": "wire(1.00)", "pred answer": "fence", "question_id": 5509065, "best approach": "concept, image", "verif answer": "power line", "anno approach": "wiki, concept, image", "verif wiki answer": "power line(0.5133)", "verif concept answer": "wire(0.5155)", "verif image answer": "wire(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550906.jpg"}, {"question": "are these adults or college kids", "gt answer": "college kid(1.00)<br/>college(0.60)<br/>adult(0.60)", "pred answer": "guest", "question_id": 4159035, "best approach": "wiki, concept, image", "verif answer": "college", "anno approach": "wiki, concept, image", "verif wiki answer": "adult(0.6733)", "verif concept answer": "adult(0.6212)", "verif image answer": "adult(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415903.jpg"}, {"question": "do the lanes in the picture run in the same or opposing direction", "gt answer": "same(1.00)", "pred answer": "united", "question_id": 3877595, "best approach": "wiki, concept", "verif answer": "same", "anno approach": "wiki, concept, image", "verif wiki answer": "same(0.5050)", "verif concept answer": "same(0.5135)", "verif image answer": "triangle(0.5112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387759.jpg"}, {"question": "what kind of drivers license is required for this vehicle", "gt answer": "cdl(1.00)<br/>commercial(1.00)", "pred answer": "driver", "question_id": 2052705, "best approach": "concept", "verif answer": "driver", "anno approach": "wiki, concept, image", "verif wiki answer": "convection(0.7289)", "verif concept answer": "cdl(0.6611)", "verif image answer": "convection(0.7281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205270.jpg"}, {"question": "what does this building sell", "gt answer": "car(1.00)<br/>motorcycle(0.60)", "pred answer": "people", "question_id": 955185, "best approach": "concept", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "bike(0.6231)", "verif concept answer": "car(0.6460)", "verif image answer": "ride(0.6179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000095518.jpg"}, {"question": "what are these sunbrellas made from", "gt answer": "rattan(1.00)<br/>wicker(0.60)<br/>canvas(0.60)<br/>straw(0.60)", "pred answer": "nylon", "question_id": 1599575, "best approach": "wiki, concept", "verif answer": "wicker", "anno approach": "wiki, concept, image", "verif wiki answer": "rattan(0.6926)", "verif concept answer": "rattan(0.5171)", "verif image answer": "canvas(0.5978)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159957.jpg"}, {"question": "what type of special airplane is this", "gt answer": "bomber(1.00)<br/>biplane(0.60)", "pred answer": "military", "question_id": 3166405, "best approach": "wiki", "verif answer": "military", "anno approach": "wiki, concept, image", "verif wiki answer": "bomber(0.6604)", "verif concept answer": "military(0.6027)", "verif image answer": "military(0.6138)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316640.jpg"}, {"question": "what kind of plane is this", "gt answer": "jet(1.00)<br/>fighter(1.00)", "pred answer": "fighter jet", "question_id": 363885, "best approach": "", "verif answer": "fighter jet", "anno approach": "wiki, concept, image", "verif wiki answer": "military(0.6539)", "verif concept answer": "fighter jet(0.6916)", "verif image answer": "fighter jet(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036388.jpg"}, {"question": "what is it called when a woman feels like this in the morning", "gt answer": "morn sick(1.00)", "pred answer": "tired", "question_id": 3814705, "best approach": "", "verif answer": "pushups", "anno approach": "wiki, concept, image", "verif wiki answer": "pushups(0.7035)", "verif concept answer": "pushups(0.7044)", "verif image answer": "pushups(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381470.jpg"}, {"question": "where might you find the object in the mug", "gt answer": "desk(1.00)<br/>drawer(0.60)<br/>office(0.60)", "pred answer": "garden", "question_id": 302765, "best approach": "", "verif answer": "desk", "anno approach": "wiki, concept, image", "verif wiki answer": "backpack(0.5224)", "verif concept answer": "backpack(0.5903)", "verif image answer": "backpack(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030276.jpg"}, {"question": "what type of horse is this", "gt answer": "pony(1.00)<br/>ride(0.60)", "pred answer": "stallion", "question_id": 4375625, "best approach": "concept", "verif answer": "pony", "anno approach": "wiki, concept, image", "verif wiki answer": "clydesdale(0.6873)", "verif concept answer": "ride(0.6509)", "verif image answer": "shetland(0.7218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437562.jpg"}, {"question": "what is the name of the furniture that has books on it", "gt answer": "bookshelf(1.00)<br/>shelf(0.60)", "pred answer": "desk", "question_id": 4595575, "best approach": "wiki", "verif answer": "bookshelf", "anno approach": "wiki, concept, image", "verif wiki answer": "bookshelf(0.7228)", "verif concept answer": "shelve(0.6368)", "verif image answer": "shelve(0.6820)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459557.jpg"}, {"question": "what is the last letter in the sign", "gt answer": "e(1.00)", "pred answer": "c", "question_id": 2566555, "best approach": "", "verif answer": "white", "anno approach": "wiki, concept, image", "verif wiki answer": "white(0.5127)", "verif concept answer": "white(0.5224)", "verif image answer": "left(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256655.jpg"}, {"question": "what is the orange food", "gt answer": "salmon(0.60)<br/>carrot(1.00)", "pred answer": "cheese", "question_id": 675315, "best approach": "", "verif answer": "salmon", "anno approach": "wiki, concept, image", "verif wiki answer": "stew(0.6340)", "verif concept answer": "stew(0.6836)", "verif image answer": "fish(0.7256)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067531.jpg"}, {"question": "whose birthday is being celebrated", "gt answer": "baby(1.00)", "pred answer": "grandma", "question_id": 2378315, "best approach": "", "verif answer": "baby", "anno approach": "wiki, concept, image", "verif wiki answer": "child(0.6613)", "verif concept answer": "teddy bear(0.5787)", "verif image answer": "teddy bear(0.5867)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237831.jpg"}, {"question": "how fast is the vehicle pictured capable of reaching", "gt answer": "200 mph(1.00)<br/>0(0.60)", "pred answer": "80 mph", "question_id": 4196095, "best approach": "concept", "verif answer": "200 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "300 mph(0.6793)", "verif concept answer": "200 mph(0.6525)", "verif image answer": "300 mph(0.6917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419609.jpg"}, {"question": "what is the person on the computer on the right looking at", "gt answer": "map(1.00)<br/>camera(0.60)", "pred answer": "window", "question_id": 199805, "best approach": "concept, image", "verif answer": "map", "anno approach": "wiki, concept, image", "verif wiki answer": "tv(0.5843)", "verif concept answer": "map(0.6400)", "verif image answer": "map(0.5077)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019980.jpg"}, {"question": "name the ingredients used for preparing this dish", "gt answer": "carrot(1.00)", "pred answer": "vegetable", "question_id": 3244505, "best approach": "concept", "verif answer": "vegetable", "anno approach": "wiki, concept, image", "verif wiki answer": "vegetable(0.6797)", "verif concept answer": "carrot(0.6521)", "verif image answer": "pepper(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324450.jpg"}, {"question": "what kind of allergies can people have to this dessert", "gt answer": "peanut(1.00)<br/>nut(0.60)", "pred answer": "sugar", "question_id": 4952435, "best approach": "wiki, concept, image", "verif answer": "nut", "anno approach": "wiki, concept, image", "verif wiki answer": "peanut(0.6480)", "verif concept answer": "peanut(0.6219)", "verif image answer": "peanut(0.5785)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495243.jpg"}, {"question": "what is the elephant doing", "gt answer": "paint(1.00)", "pred answer": "play", "question_id": 5506605, "best approach": "image", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "art(0.6236)", "verif concept answer": "abstract(0.5993)", "verif image answer": "paint(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550660.jpg"}, {"question": "what is the elevation difference between the land the picnic table is on and the top of those mountain peaks", "gt answer": "2000 feet(1.00)<br/>6000 feet(0.60)<br/>100 feet(0.60)", "pred answer": "mountain", "question_id": 4252965, "best approach": "wiki, concept, image", "verif answer": "6000 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "100 feet(0.7184)", "verif concept answer": "100 feet(0.5275)", "verif image answer": "100 feet(0.5254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425296.jpg"}, {"question": "what is the road in this image refers as as it relates to what it 's made from", "gt answer": "cobblestone(1.00)<br/>brick(1.00)", "pred answer": "sidewalk", "question_id": 1813055, "best approach": "wiki", "verif answer": "brick", "anno approach": "wiki, concept, image", "verif wiki answer": "brick(0.6646)", "verif concept answer": "limestone(0.5507)", "verif image answer": "stone(0.5058)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181305.jpg"}, {"question": "what is the silver tool called", "gt answer": "tong(1.00)<br/>eat(0.60)", "pred answer": "spoon", "question_id": 248425, "best approach": "", "verif answer": "fork", "anno approach": "wiki, concept, image", "verif wiki answer": "fork(0.6833)", "verif concept answer": "fork(0.6464)", "verif image answer": "fork(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024842.jpg"}, {"question": "how long does it take to grow a beard to that length", "gt answer": "2 months(1.00)<br/>6 months(1.00)<br/>2 weeks(0.60)", "pred answer": "4 months", "question_id": 1848135, "best approach": "concept, image", "verif answer": "4 months", "anno approach": "wiki, concept, image", "verif wiki answer": "2 weeks(0.6257)", "verif concept answer": "6 months(0.5489)", "verif image answer": "2 months(0.7198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184813.jpg"}, {"question": "how many kids can this animal give birth to", "gt answer": "6(1.00)<br/>10(0.60)<br/>3(0.60)<br/>5(0.60)", "pred answer": "1", "question_id": 3563305, "best approach": "wiki, concept", "verif answer": "3", "anno approach": "wiki, concept, image", "verif wiki answer": "6(0.6086)", "verif concept answer": "6(0.5984)", "verif image answer": "4(0.6648)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356330.jpg"}, {"question": "what are these animals doing", "gt answer": "run(1.00)<br/>gallop(0.60)", "pred answer": "horseback ride", "question_id": 5364965, "best approach": "concept, image", "verif answer": "horseback ride", "anno approach": "wiki, concept, image", "verif wiki answer": "horseback ride(0.7147)", "verif concept answer": "run(0.7034)", "verif image answer": "run(0.7054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536496.jpg"}, {"question": "how is this vehicle powered", "gt answer": "horse(1.00)<br/>food(0.60)", "pred answer": "engine", "question_id": 1422995, "best approach": "", "verif answer": "horse", "anno approach": "wiki, concept, image", "verif wiki answer": "cow(0.6936)", "verif concept answer": "cow(0.6194)", "verif image answer": "donkey(0.5828)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142299.jpg"}, {"question": "what type of clouds are these", "gt answer": "stratus(1.00)<br/>rain(0.60)", "pred answer": "cumulus", "question_id": 775505, "best approach": "", "verif answer": "cirrus", "anno approach": "wiki, concept, image", "verif wiki answer": "cirrus(0.7257)", "verif concept answer": "cirrus(0.7280)", "verif image answer": "cirrus(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077550.jpg"}, {"question": "what is the pink item in the pocket called", "gt answer": "handkerchief(1.00)<br/>lapel(0.60)", "pred answer": "suspend", "question_id": 4774755, "best approach": "", "verif answer": "tie", "anno approach": "wiki, concept, image", "verif wiki answer": "tie(0.6613)", "verif concept answer": "tie(0.7096)", "verif image answer": "tie(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477475.jpg"}, {"question": "what item are these vases displayed on", "gt answer": "shelf(1.00)<br/>shelve(0.60)<br/>ceramic(0.60)<br/>bookshelf(0.60)", "pred answer": "table", "question_id": 3316295, "best approach": "concept, image", "verif answer": "bookshelf", "anno approach": "wiki, concept, image", "verif wiki answer": "closet(0.6702)", "verif concept answer": "ceramic(0.5874)", "verif image answer": "bookshelf(0.7095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331629.jpg"}, {"question": "why does the shower not have a see through door", "gt answer": "privacy(1.00)", "pred answer": "reflection", "question_id": 2929215, "best approach": "wiki", "verif answer": "privacy", "anno approach": "wiki, concept, image", "verif wiki answer": "privacy(0.7260)", "verif concept answer": "ceramic(0.6407)", "verif image answer": "overhead(0.5412)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292921.jpg"}, {"question": "how do you make this dish", "gt answer": "grill(1.00)", "pred answer": "bake", "question_id": 1083845, "best approach": "", "verif answer": "fried", "anno approach": "wiki, concept, image", "verif wiki answer": "fried(0.7240)", "verif concept answer": "fried(0.6571)", "verif image answer": "counter(0.5935)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108384.jpg"}, {"question": "what religious symbol is in this picture", "gt answer": "cross(1.00)", "pred answer": "catholic", "question_id": 3882935, "best approach": "", "verif answer": "christ redeemer", "anno approach": "wiki, concept, image", "verif wiki answer": "christ redeemer(0.5713)", "verif concept answer": "christ redeemer(0.5634)", "verif image answer": "christ redeemer(0.5033)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388293.jpg"}, {"question": "what vitamins do you get from these vegetables", "gt answer": "c(1.00)<br/>beta carotene(0.60)<br/>b(0.60)", "pred answer": "vitamin", "question_id": 3017145, "best approach": "", "verif answer": "d", "anno approach": "wiki, concept, image", "verif wiki answer": "d(0.6803)", "verif concept answer": "d(0.6367)", "verif image answer": "d(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301714.jpg"}, {"question": "how long has the car been parked", "gt answer": "15 minutes(1.00)<br/>15(0.60)<br/>2 hours(0.60)", "pred answer": "1 hour", "question_id": 1957975, "best approach": "wiki, concept", "verif answer": "2 hours", "anno approach": "wiki, concept, image", "verif wiki answer": "2 hours(0.7215)", "verif concept answer": "2 hours(0.5162)", "verif image answer": "26(0.5597)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195797.jpg"}, {"question": "what is the calorie content of a dish like this", "gt answer": "500(1.00)<br/>1000(0.60)<br/>lot(0.60)", "pred answer": "75", "question_id": 4595155, "best approach": "wiki, image", "verif answer": "300", "anno approach": "wiki, concept, image", "verif wiki answer": "1000(0.6407)", "verif concept answer": "300(0.6396)", "verif image answer": "1000(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459515.jpg"}, {"question": "which kind of material is used for the hair band shown in the head of the lady", "gt answer": "plastic(1.00)", "pred answer": "leather", "question_id": 5138955, "best approach": "image", "verif answer": "plastic", "anno approach": "wiki, concept, image", "verif wiki answer": "rubber(0.6207)", "verif concept answer": "rubber(0.6429)", "verif image answer": "plastic(0.6343)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513895.jpg"}, {"question": "what instrument is being shown in the image", "gt answer": "piano(1.00)", "pred answer": "guitar", "question_id": 4629875, "best approach": "wiki, concept, image", "verif answer": "piano", "anno approach": "wiki, concept, image", "verif wiki answer": "piano(0.7307)", "verif concept answer": "piano(0.7310)", "verif image answer": "piano(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000462987.jpg"}, {"question": "what is in front of these people", "gt answer": "stair(1.00)<br/>step(1.00)<br/>fence(0.60)", "pred answer": "bridge", "question_id": 3256965, "best approach": "wiki, concept, image", "verif answer": "fence", "anno approach": "wiki, concept, image", "verif wiki answer": "fence(0.5733)", "verif concept answer": "fence(0.5541)", "verif image answer": "fence(0.6819)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325696.jpg"}, {"question": "who invented this dish", "gt answer": "chef(1.00)<br/>italians(0.60)", "pred answer": "chinese", "question_id": 321835, "best approach": "", "verif answer": "cook", "anno approach": "wiki, concept, image", "verif wiki answer": "cook(0.5659)", "verif concept answer": "cook(0.6987)", "verif image answer": "restaurant(0.6484)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032183.jpg"}, {"question": "how are the trails made by the camera", "gt answer": "light(1.00)<br/>1(0.60)", "pred answer": "shadow", "question_id": 633655, "best approach": "", "verif answer": "reflection", "anno approach": "wiki, concept, image", "verif wiki answer": "rainbow(0.6847)", "verif concept answer": "stop light(0.6056)", "verif image answer": "rainbow(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063365.jpg"}, {"question": "what food does this animal eat", "gt answer": "seed(1.00)<br/>worm(0.60)", "pred answer": "bug", "question_id": 3263775, "best approach": "wiki, concept", "verif answer": "seed", "anno approach": "wiki, concept, image", "verif wiki answer": "worm(0.5080)", "verif concept answer": "worm(0.5081)", "verif image answer": "grain(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000326377.jpg"}, {"question": "what brand is shown here", "gt answer": "lexus(1.00)<br/>wilson(0.60)", "pred answer": "mercedes", "question_id": 4360705, "best approach": "wiki, concept, image", "verif answer": "mercedes", "anno approach": "wiki, concept, image", "verif wiki answer": "wilson(0.7296)", "verif concept answer": "wilson(0.7283)", "verif image answer": "wilson(0.5747)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436070.jpg"}, {"question": "what other vegetable is closely related to the green one pictured", "gt answer": "cauliflower(1.00)", "pred answer": "potato", "question_id": 1453135, "best approach": "concept", "verif answer": "broccoli", "anno approach": "wiki, concept, image", "verif wiki answer": "broccoli(0.7000)", "verif concept answer": "cauliflower(0.7195)", "verif image answer": "broccoli(0.7040)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145313.jpg"}, {"question": "what trick is this snowboarder doing", "gt answer": "grind(1.00)<br/>rail(0.60)", "pred answer": "jump", "question_id": 4096695, "best approach": "wiki", "verif answer": "jump", "anno approach": "wiki, concept, image", "verif wiki answer": "grind(0.6083)", "verif concept answer": "ride rail(0.6237)", "verif image answer": "ollie(0.7008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409669.jpg"}, {"question": "where are we going from here", "gt answer": "1 way(1.00)<br/>shop(0.60)", "pred answer": "vacation", "question_id": 3357875, "best approach": "", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.7254)", "verif concept answer": "street(0.7247)", "verif image answer": "street(0.7257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335787.jpg"}, {"question": "what kind of monkey is this stuff animal", "gt answer": "chimp(1.00)", "pred answer": "teddy", "question_id": 2378535, "best approach": "", "verif answer": "bear", "anno approach": "wiki, concept, image", "verif wiki answer": "1 foot(0.5656)", "verif concept answer": "1 foot(0.6077)", "verif image answer": "1 foot(0.6787)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237853.jpg"}, {"question": "what was the name of the famous disney song sung by julie andrews featuring the eating utensil above", "gt answer": "spoonful of sugar(1.00)<br/>spoon(0.60)<br/>picnic(0.60)", "pred answer": "shrimp", "question_id": 1177685, "best approach": "wiki, concept, image", "verif answer": "chopstick", "anno approach": "wiki, concept, image", "verif wiki answer": "spoonful of sugar(0.6763)", "verif concept answer": "spoonful of sugar(0.7309)", "verif image answer": "spoonful of sugar(0.7019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117768.jpg"}, {"question": "can you guess the place name shown in this picture", "gt answer": "colorado(1.00)<br/>pennsylvania(0.60)<br/>alaska(0.60)", "pred answer": "intersection", "question_id": 698745, "best approach": "image", "verif answer": "colorado", "anno approach": "wiki, concept, image", "verif wiki answer": "country(0.6410)", "verif concept answer": "country(0.7225)", "verif image answer": "colorado(0.7086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069874.jpg"}, {"question": "what safety equipment is the rider missing", "gt answer": "elbow pad(1.00)<br/>shirt(1.00)", "pred answer": "helmet", "question_id": 1479605, "best approach": "wiki, concept, image", "verif answer": "shirt", "anno approach": "wiki, concept, image", "verif wiki answer": "elbow pad(0.7184)", "verif concept answer": "elbow pad(0.6552)", "verif image answer": "elbow pad(0.5102)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147960.jpg"}, {"question": "how many calories in this dish", "gt answer": "500(1.00)<br/>350(0.60)<br/>600(0.60)", "pred answer": "fifty", "question_id": 4167765, "best approach": "", "verif answer": "400", "anno approach": "wiki, concept, image", "verif wiki answer": "400(0.5916)", "verif concept answer": "400(0.6244)", "verif image answer": "2000(0.6704)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416776.jpg"}, {"question": "what healthy food is on this pizza", "gt answer": "tomato(1.00)<br/>olives(0.60)<br/>pepper(0.60)", "pred answer": "cheese", "question_id": 5207655, "best approach": "wiki, concept", "verif answer": "cheese", "anno approach": "wiki, concept, image", "verif wiki answer": "pepper(0.7161)", "verif concept answer": "pepper(0.7229)", "verif image answer": "onion(0.7264)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520765.jpg"}, {"question": "why is there a clock on the building", "gt answer": "to tell time(1.00)", "pred answer": "wait", "question_id": 4769675, "best approach": "wiki, image", "verif answer": "tell time", "anno approach": "wiki, concept, image", "verif wiki answer": "to tell time(0.5052)", "verif concept answer": "tell time(0.5819)", "verif image answer": "to tell time(0.5556)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476967.jpg"}, {"question": "what wii generation is this", "gt answer": "1st(1.00)<br/>2nd(0.60)<br/>3(0.60)", "pred answer": "wii", "question_id": 2661035, "best approach": "concept", "verif answer": "2nd", "anno approach": "wiki, concept, image", "verif wiki answer": "first(0.5097)", "verif concept answer": "2nd(0.5438)", "verif image answer": "second(0.5809)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266103.jpg"}, {"question": "what is the occupation of the man cutting the cake", "gt answer": "priest(1.00)", "pred answer": "baker", "question_id": 482675, "best approach": "wiki, concept, image", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "priest(0.7295)", "verif concept answer": "priest(0.7120)", "verif image answer": "priest(0.5657)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048267.jpg"}, {"question": "what kind of equipment is under the banana", "gt answer": "telephone(1.00)<br/>speaker(0.60)<br/>phone(0.60)<br/>clock(0.60)", "pred answer": "purse", "question_id": 4999135, "best approach": "image", "verif answer": "phone", "anno approach": "wiki, concept, image", "verif wiki answer": "speaker(0.5031)", "verif concept answer": "electric(0.5041)", "verif image answer": "telephone(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499913.jpg"}, {"question": "what is the name of the knot used in this photo", "gt answer": "sailor(1.00)", "pred answer": "windsor", "question_id": 826225, "best approach": "", "verif answer": "ring", "anno approach": "wiki, concept, image", "verif wiki answer": "ring(0.6960)", "verif concept answer": "ring(0.5817)", "verif image answer": "ring(0.7031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082622.jpg"}, {"question": "what are these materials out for", "gt answer": "paint(1.00)<br/>art(0.60)<br/>plastic(0.60)", "pred answer": "sew", "question_id": 991595, "best approach": "concept", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "painted(0.6582)", "verif concept answer": "art(0.6243)", "verif image answer": "painted(0.6927)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099159.jpg"}, {"question": "which style of crust does this appear to be", "gt answer": "thick(1.00)<br/>deep dish(0.60)<br/>stuffed(0.60)<br/>flour(0.60)", "pred answer": "chicago", "question_id": 2033595, "best approach": "image", "verif answer": "stuffed", "anno approach": "wiki, concept, image", "verif wiki answer": "stuffed(0.7304)", "verif concept answer": "stuffed(0.7264)", "verif image answer": "thick(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203359.jpg"}, {"question": "what is the name of this event", "gt answer": "monster truck rally(1.00)<br/>truck(0.60)<br/>monster truck(0.60)", "pred answer": "tow", "question_id": 622045, "best approach": "wiki", "verif answer": "monster truck", "anno approach": "wiki, concept, image", "verif wiki answer": "monster truck(0.6410)", "verif concept answer": "flatbed(0.6380)", "verif image answer": "flatbed(0.7213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000062204.jpg"}, {"question": "what kind of event is presented on this picture", "gt answer": "celebration(1.00)<br/>birthday(0.60)<br/>formal(0.60)", "pred answer": "retirement", "question_id": 736205, "best approach": "wiki, concept, image", "verif answer": "retirement", "anno approach": "wiki, concept, image", "verif wiki answer": "celebration(0.7087)", "verif concept answer": "celebration(0.6645)", "verif image answer": "celebration(0.6663)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073620.jpg"}, {"question": "what style do these people protray", "gt answer": "preppy(1.00)<br/>casual(0.60)", "pred answer": "formal", "question_id": 2801195, "best approach": "wiki, concept", "verif answer": "modern", "anno approach": "wiki, concept, image", "verif wiki answer": "preppy(0.5770)", "verif concept answer": "preppy(0.6253)", "verif image answer": "modern(0.6341)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280119.jpg"}, {"question": "which national holiday celebrates these green growing things", "gt answer": "arbor day(1.00)", "pred answer": "fourth of july", "question_id": 1011155, "best approach": "concept", "verif answer": "st patrick's day", "anno approach": "wiki, concept, image", "verif wiki answer": "st patrick's day(0.5030)", "verif concept answer": "arbor day(0.6208)", "verif image answer": "winter(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000101115.jpg"}, {"question": "what type of dog breed is that", "gt answer": "terrier(1.00)", "pred answer": "shitzu", "question_id": 3504845, "best approach": "", "verif answer": "terrier", "anno approach": "wiki, concept, image", "verif wiki answer": "chihuahua(0.7181)", "verif concept answer": "schnauzer(0.5799)", "verif image answer": "chihuahua(0.6705)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350484.jpg"}, {"question": "why is she wearing that type of glasses", "gt answer": "sun protection(1.00)<br/>sun(0.60)<br/>for sun(0.60)", "pred answer": "shade", "question_id": 3248295, "best approach": "wiki, concept, image", "verif answer": "shade", "anno approach": "wiki, concept, image", "verif wiki answer": "sun(0.6954)", "verif concept answer": "sun(0.7238)", "verif image answer": "sun(0.5593)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324829.jpg"}, {"question": "who is famous for playing this sport", "gt answer": "oscar potting(1.00)", "pred answer": "ben franklin", "question_id": 5424445, "best approach": "wiki", "verif answer": "ben franklin", "anno approach": "wiki, concept, image", "verif wiki answer": "oscar potting(0.6859)", "verif concept answer": "ben franklin(0.7168)", "verif image answer": "ben franklin(0.5051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542444.jpg"}, {"question": "what queen rules here", "gt answer": "elizabeth(1.00)", "pred answer": "picture", "question_id": 4056225, "best approach": "", "verif answer": "bullet", "anno approach": "wiki, concept, image", "verif wiki answer": "tiffany(0.7052)", "verif concept answer": "tiffany(0.6980)", "verif image answer": "tiffany(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405622.jpg"}, {"question": "what is this object used for", "gt answer": "blend(1.00)<br/>eat(0.60)", "pred answer": "measure", "question_id": 4976985, "best approach": "wiki, concept", "verif answer": "cook", "anno approach": "wiki, concept, image", "verif wiki answer": "eat(0.6725)", "verif concept answer": "eat(0.6557)", "verif image answer": "cook(0.7100)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497698.jpg"}, {"question": "what style of chair is pictured", "gt answer": "armchair(1.00)", "pred answer": "modern", "question_id": 692145, "best approach": "wiki, image", "verif answer": "modern", "anno approach": "wiki, concept, image", "verif wiki answer": "armchair(0.7181)", "verif concept answer": "modern(0.6271)", "verif image answer": "armchair(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069214.jpg"}, {"question": "how was this cooked", "gt answer": "steamed(1.00)<br/>boiled(0.60)", "pred answer": "grilled", "question_id": 5411825, "best approach": "wiki", "verif answer": "grilled", "anno approach": "wiki, concept, image", "verif wiki answer": "boiled(0.5780)", "verif concept answer": "grilled(0.6702)", "verif image answer": "steam(0.6816)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541182.jpg"}, {"question": "what is the make of this car", "gt answer": "ford(1.00)<br/>toyota(1.00)", "pred answer": "mercedes", "question_id": 3432795, "best approach": "wiki, concept, image", "verif answer": "toyota", "anno approach": "wiki, concept, image", "verif wiki answer": "ford(0.6390)", "verif concept answer": "toyota(0.6745)", "verif image answer": "ford(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343279.jpg"}, {"question": "what kinds of haircuts to these men have", "gt answer": "crew cut(1.00)<br/>brush(0.60)<br/>short(0.60)", "pred answer": "afro", "question_id": 5135775, "best approach": "wiki", "verif answer": "crew cut", "anno approach": "wiki, concept, image", "verif wiki answer": "crew cut(0.6044)", "verif concept answer": "small(0.6454)", "verif image answer": "small(0.7025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513577.jpg"}, {"question": "who usually rides this type of vehicle", "gt answer": "racer(1.00)<br/>thrill seeker(0.60)<br/>man(0.60)<br/>biker(0.60)", "pred answer": "police officer", "question_id": 4473795, "best approach": "concept, image", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "jockey(0.7277)", "verif concept answer": "biker(0.7249)", "verif image answer": "man(0.7211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447379.jpg"}, {"question": "what do the objects in the foreground consist of", "gt answer": "rock(1.00)<br/>stone(0.60)<br/>wood(0.60)<br/>concrete(0.60)", "pred answer": "book", "question_id": 2186015, "best approach": "wiki, concept, image", "verif answer": "wood", "anno approach": "wiki, concept, image", "verif wiki answer": "wood(0.7273)", "verif concept answer": "wood(0.6016)", "verif image answer": "concrete(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218601.jpg"}, {"question": "what brand is the mouthwash", "gt answer": "listerine(1.00)", "pred answer": "colgate", "question_id": 1969715, "best approach": "", "verif answer": "colgate", "anno approach": "wiki, concept, image", "verif wiki answer": "crest(0.7151)", "verif concept answer": "crest(0.7001)", "verif image answer": "colgate(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196971.jpg"}, {"question": "the white twisty things are called what", "gt answer": "rotini(1.00)<br/>pasta(0.60)<br/>noodle(0.60)", "pred answer": "pea", "question_id": 4364105, "best approach": "", "verif answer": "noodle", "anno approach": "wiki, concept, image", "verif wiki answer": "shrimp(0.7039)", "verif concept answer": "shrimp(0.6602)", "verif image answer": "shrimp(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436410.jpg"}, {"question": "what airline company 's plane is this", "gt answer": "united(1.00)<br/>american(0.60)<br/>boeing(0.60)", "pred answer": "american airline", "question_id": 5072435, "best approach": "image", "verif answer": "american airline", "anno approach": "wiki, concept, image", "verif wiki answer": "american airline(0.5676)", "verif concept answer": "american airline(0.5615)", "verif image answer": "boeing(0.5149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507243.jpg"}, {"question": "what athlete who uses the above tool competed at wimbledon after nearly dying from complications during childbirth", "gt answer": "serena williams(1.00)", "pred answer": "roger federer", "question_id": 632705, "best approach": "", "verif answer": "roger federer", "anno approach": "wiki, concept, image", "verif wiki answer": "venus williams(0.7279)", "verif concept answer": "venus williams(0.6583)", "verif image answer": "williams(0.6780)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063270.jpg"}, {"question": "what type of dog is this", "gt answer": "samoyed(1.00)<br/>husky(0.60)", "pred answer": "poodle", "question_id": 1704065, "best approach": "image", "verif answer": "poodle", "anno approach": "wiki, concept, image", "verif wiki answer": "poodle(0.7140)", "verif concept answer": "poodle(0.6293)", "verif image answer": "samoyed(0.7181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000170406.jpg"}, {"question": "who wrote those", "gt answer": "graffiti(1.00)<br/>graffiti artist(0.60)", "pred answer": "frederick graff sr", "question_id": 2069345, "best approach": "wiki, concept", "verif answer": "spray paint", "anno approach": "wiki, concept, image", "verif wiki answer": "graffiti artist(0.5002)", "verif concept answer": "graffiti artist(0.5111)", "verif image answer": "spray paint(0.5135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206934.jpg"}, {"question": "what type of table in the house would this be called", "gt answer": "dine room(1.00)<br/>kitchen(0.60)<br/>dine(0.60)", "pred answer": "dinner", "question_id": 4869365, "best approach": "wiki", "verif answer": "kitchen", "anno approach": "wiki, concept, image", "verif wiki answer": "dine room(0.6398)", "verif concept answer": "kitchen(0.6439)", "verif image answer": "kitchen(0.6709)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000486936.jpg"}, {"question": "who has the fastest serve on record for this sport", "gt answer": "samuel groth(1.00)", "pred answer": "roger federer", "question_id": 1443535, "best approach": "image", "verif answer": "roger federer", "anno approach": "wiki, concept, image", "verif wiki answer": "houston astros(0.7156)", "verif concept answer": "houston astros(0.6732)", "verif image answer": "samuel groth(0.7208)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144353.jpg"}, {"question": "the shoes the man is wearing were designed by what company", "gt answer": "adidas(1.00)", "pred answer": "converse", "question_id": 2025115, "best approach": "", "verif answer": "tennis", "anno approach": "wiki, concept, image", "verif wiki answer": "tennis(0.6151)", "verif concept answer": "tennis(0.6007)", "verif image answer": "tennis(0.6940)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202511.jpg"}, {"question": "why might the man be kicking up sand", "gt answer": "anger(1.00)<br/>rock(0.60)", "pred answer": "tan", "question_id": 1981195, "best approach": "", "verif answer": "danger", "anno approach": "wiki, concept, image", "verif wiki answer": "fear(0.6397)", "verif concept answer": "fear(0.6182)", "verif image answer": "danger(0.7144)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198119.jpg"}, {"question": "what is this man talking about", "gt answer": "racism(1.00)", "pred answer": "politic", "question_id": 3106545, "best approach": "", "verif answer": "politic", "anno approach": "wiki, concept, image", "verif wiki answer": "politic(0.6550)", "verif concept answer": "politic(0.6617)", "verif image answer": "business(0.7212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310654.jpg"}, {"question": "why does this man have his cellphone out", "gt answer": "take picture(1.00)<br/>selfie(0.60)", "pred answer": "play game", "question_id": 2449755, "best approach": "", "verif answer": "take picture", "anno approach": "wiki, concept, image", "verif wiki answer": "candid(0.6870)", "verif concept answer": "call(0.6799)", "verif image answer": "candid(0.6280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244975.jpg"}, {"question": "why might we suspect this person likes analogue equipment", "gt answer": "camera(1.00)<br/>television(0.60)", "pred answer": "mirror", "question_id": 3621405, "best approach": "image", "verif answer": "mirror", "anno approach": "wiki, concept, image", "verif wiki answer": "mirror(0.5988)", "verif concept answer": "mirror(0.6316)", "verif image answer": "camera(0.6533)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362140.jpg"}, {"question": "which airline is this", "gt answer": "united parcel service(1.00)<br/>up(1.00)", "pred answer": "lufthansa", "question_id": 4021745, "best approach": "wiki, concept, image", "verif answer": "amazon", "anno approach": "wiki, concept, image", "verif wiki answer": "up(0.7182)", "verif concept answer": "up(0.7294)", "verif image answer": "up(0.7237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402174.jpg"}, {"question": "what component in human skin allows it to darken with the sun like the woman 's on the right has", "gt answer": "melanin(1.00)<br/>shark(0.60)", "pred answer": "sunscreen", "question_id": 4245365, "best approach": "concept, image", "verif answer": "sun", "anno approach": "wiki, concept, image", "verif wiki answer": "sun(0.7199)", "verif concept answer": "melanin(0.6052)", "verif image answer": "melanin(0.6369)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424536.jpg"}, {"question": "what is that flag made out of", "gt answer": "fabric(1.00)<br/>cloth(0.60)<br/>color(0.60)", "pred answer": "silk", "question_id": 97635, "best approach": "wiki", "verif answer": "fabric", "anno approach": "wiki, concept, image", "verif wiki answer": "fabric(0.7219)", "verif concept answer": "leather(0.6047)", "verif image answer": "cloth(0.6907)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009763.jpg"}, {"question": "what style of sweater is the woman on the left wearing", "gt answer": "cardigan(1.00)<br/>button down(0.60)<br/>flower(0.60)", "pred answer": "button up", "question_id": 3736455, "best approach": "wiki, concept, image", "verif answer": "flower", "anno approach": "wiki, concept, image", "verif wiki answer": "cardigan(0.7304)", "verif concept answer": "cardigan(0.7294)", "verif image answer": "cardigan(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373645.jpg"}, {"question": "which wild animal that hunts in packs is related to this animal seen here", "gt answer": "wolf(1.00)", "pred answer": "cat", "question_id": 4001345, "best approach": "", "verif answer": "dog", "anno approach": "wiki, concept, image", "verif wiki answer": "bear(0.7272)", "verif concept answer": "lion(0.6615)", "verif image answer": "bear(0.6361)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400134.jpg"}, {"question": "what was the predecessor to this common appliance", "gt answer": "radio(1.00)", "pred answer": "television", "question_id": 4564125, "best approach": "", "verif answer": "speaker", "anno approach": "wiki, concept, image", "verif wiki answer": "speaker(0.5769)", "verif concept answer": "speaker(0.7203)", "verif image answer": "microwave(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456412.jpg"}, {"question": "is this produce or processed food", "gt answer": "produce(1.00)", "pred answer": "manmade", "question_id": 1772535, "best approach": "", "verif answer": "fruit", "anno approach": "wiki, concept, image", "verif wiki answer": "fruit(0.7211)", "verif concept answer": "fruit(0.6202)", "verif image answer": "fruit(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177253.jpg"}, {"question": "what is the empty weight of this bus", "gt answer": "2 tons(1.00)<br/>ton(0.60)", "pred answer": "2 dollars", "question_id": 5018015, "best approach": "", "verif answer": "1000 lbs", "anno approach": "wiki, concept, image", "verif wiki answer": "1000 lbs(0.6170)", "verif concept answer": "1000 lbs(0.6517)", "verif image answer": "500 lbs(0.6896)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501801.jpg"}, {"question": "what is this area known as", "gt answer": "train station(1.00)", "pred answer": "bridge", "question_id": 5485595, "best approach": "wiki, concept", "verif answer": "gate", "anno approach": "wiki, concept, image", "verif wiki answer": "train station(0.7242)", "verif concept answer": "train station(0.7292)", "verif image answer": "gate(0.7263)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548559.jpg"}, {"question": "what do you wear on your lower legs in this sport", "gt answer": "shin guard(1.00)", "pred answer": "cleat", "question_id": 2628935, "best approach": "", "verif answer": "sneaker", "anno approach": "wiki, concept, image", "verif wiki answer": "skirt(0.7133)", "verif concept answer": "skirt(0.5310)", "verif image answer": "skirt(0.6987)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262893.jpg"}, {"question": "what is this ram doing", "gt answer": "stand(1.00)", "pred answer": "graze", "question_id": 4564365, "best approach": "wiki, concept", "verif answer": "feed", "anno approach": "wiki, concept, image", "verif wiki answer": "stand(0.6733)", "verif concept answer": "stand(0.6797)", "verif image answer": "wait(0.7155)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456436.jpg"}, {"question": "why would someone do that", "gt answer": "fun(1.00)", "pred answer": "surf", "question_id": 257845, "best approach": "", "verif answer": "fun", "anno approach": "wiki, concept, image", "verif wiki answer": "for fun(0.7201)", "verif concept answer": "for fun(0.6601)", "verif image answer": "competition(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025784.jpg"}, {"question": "is this person making a call or just holding it", "gt answer": "hold(1.00)", "pred answer": "cell phone", "question_id": 334085, "best approach": "wiki, image", "verif answer": "play", "anno approach": "wiki, concept, image", "verif wiki answer": "hold(0.5733)", "verif concept answer": "play(0.5448)", "verif image answer": "hold(0.6861)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033408.jpg"}, {"question": "what store would you go to for these cakes", "gt answer": "bakery(1.00)<br/>supermarket(0.60)<br/>walmart(0.60)", "pred answer": "dunkin donuts", "question_id": 5695845, "best approach": "wiki", "verif answer": "bakery", "anno approach": "wiki, concept, image", "verif wiki answer": "bakery(0.7071)", "verif concept answer": "grocery store(0.6006)", "verif image answer": "supermarket(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569584.jpg"}, {"question": "what is he jumping off of", "gt answer": "ramp(1.00)<br/>skateboard(0.60)", "pred answer": "stair", "question_id": 2019295, "best approach": "concept", "verif answer": "skateboard", "anno approach": "wiki, concept, image", "verif wiki answer": "skate(0.5278)", "verif concept answer": "skateboard(0.6251)", "verif image answer": "tony hawk(0.7071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201929.jpg"}, {"question": "what is the name of the park these benches reside in", "gt answer": "central park(1.00)<br/>central(0.60)", "pred answer": "philadelphia", "question_id": 821315, "best approach": "wiki", "verif answer": "central park", "anno approach": "wiki, concept, image", "verif wiki answer": "central park(0.7283)", "verif concept answer": "chicago(0.7042)", "verif image answer": "central(0.6818)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082131.jpg"}, {"question": "is this tokyo or time square", "gt answer": "tokyo(1.00)", "pred answer": "roman", "question_id": 2789215, "best approach": "image", "verif answer": "tokyo", "anno approach": "wiki, concept, image", "verif wiki answer": "new york(0.5001)", "verif concept answer": "new york(0.5002)", "verif image answer": "tokyo(0.5972)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278921.jpg"}, {"question": "what is this snowboarding technique called", "gt answer": "jump(1.00)<br/>olly(0.60)<br/>half pipe(0.60)", "pred answer": "kickflip", "question_id": 5739805, "best approach": "wiki, concept, image", "verif answer": "olly", "anno approach": "wiki, concept, image", "verif wiki answer": "olly(0.6342)", "verif concept answer": "olly(0.6438)", "verif image answer": "half pipe(0.6735)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000573980.jpg"}, {"question": "what type of shoes are those", "gt answer": "high heel(1.00)", "pred answer": "sneaker", "question_id": 2998335, "best approach": "wiki, concept", "verif answer": "flip flop", "anno approach": "wiki, concept, image", "verif wiki answer": "high heel(0.7261)", "verif concept answer": "high heel(0.7307)", "verif image answer": "flip flop(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000299833.jpg"}, {"question": "why is this round item here", "gt answer": "cook(1.00)<br/>pizza(0.60)", "pred answer": "eat", "question_id": 2933775, "best approach": "wiki, concept", "verif answer": "cook", "anno approach": "wiki, concept, image", "verif wiki answer": "cook(0.6737)", "verif concept answer": "cook(0.6403)", "verif image answer": "chef(0.5619)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293377.jpg"}, {"question": "what type of horse is this", "gt answer": "arabian(1.00)<br/>brown(0.60)<br/>mustang(0.60)", "pred answer": "palomino", "question_id": 2666315, "best approach": "concept", "verif answer": "brown", "anno approach": "wiki, concept, image", "verif wiki answer": "brown(0.6338)", "verif concept answer": "arabian(0.5538)", "verif image answer": "mustang(0.6121)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266631.jpg"}, {"question": "the plate pattern is similar to what ubiquitous city vehicle", "gt answer": "taxi(1.00)<br/>square(0.60)", "pred answer": "flower", "question_id": 3282985, "best approach": "wiki, concept", "verif answer": "taxi", "anno approach": "wiki, concept, image", "verif wiki answer": "taxi(0.5834)", "verif concept answer": "taxi(0.7222)", "verif image answer": "diamond(0.6990)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328298.jpg"}, {"question": "what type of camera was used to take this picture", "gt answer": "cell phone(1.00)<br/>phone(0.60)", "pred answer": "digital", "question_id": 3894985, "best approach": "concept", "verif answer": "smartphone", "anno approach": "wiki, concept, image", "verif wiki answer": "smartphone(0.5051)", "verif concept answer": "cell phone(0.5537)", "verif image answer": "cellphone(0.5079)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389498.jpg"}, {"question": "what is this device used for", "gt answer": "video game(1.00)<br/>play video game(0.60)<br/>music(0.60)<br/>charger(0.60)", "pred answer": "compute", "question_id": 1586475, "best approach": "image", "verif answer": "music", "anno approach": "wiki, concept, image", "verif wiki answer": "charger(0.7071)", "verif concept answer": "charger(0.6721)", "verif image answer": "video game(0.6851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000158647.jpg"}, {"question": "who manufactures this bag", "gt answer": "ll bean(1.00)<br/>gucci(0.60)<br/>columbia(0.60)", "pred answer": "samsonite", "question_id": 1447465, "best approach": "wiki, concept, image", "verif answer": "columbia", "anno approach": "wiki, concept, image", "verif wiki answer": "gucci(0.7219)", "verif concept answer": "gucci(0.6521)", "verif image answer": "gucci(0.7059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144746.jpg"}, {"question": "what type of bear is this", "gt answer": "polar(1.00)", "pred answer": "grizzly", "question_id": 1405485, "best approach": "wiki, concept", "verif answer": "polar", "anno approach": "wiki, concept, image", "verif wiki answer": "polar(0.7195)", "verif concept answer": "polar(0.6614)", "verif image answer": "polar bear(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140548.jpg"}, {"question": "how are onions cut", "gt answer": "with knife(1.00)", "pred answer": "grilled", "question_id": 1328745, "best approach": "wiki, concept", "verif answer": "knife", "anno approach": "wiki, concept, image", "verif wiki answer": "with knife(0.6385)", "verif concept answer": "with knife(0.6222)", "verif image answer": "butter(0.6181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000132874.jpg"}, {"question": "what are donuts topped with", "gt answer": "ice(1.00)<br/>chocolate(0.60)<br/>sprinkle(0.60)<br/>frost(0.60)", "pred answer": "jelly", "question_id": 862675, "best approach": "wiki, concept, image", "verif answer": "chocolate", "anno approach": "wiki, concept, image", "verif wiki answer": "chocolate(0.6736)", "verif concept answer": "chocolate(0.6700)", "verif image answer": "chocolate(0.5002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086267.jpg"}, {"question": "how tall is the average adult male animal in this picture", "gt answer": "15 feet(1.00)<br/>10 feet(0.60)<br/>11 feet(0.60)", "pred answer": "20 feet", "question_id": 367185, "best approach": "", "verif answer": "12 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "8 feet(0.6510)", "verif concept answer": "8 feet(0.5571)", "verif image answer": "12 feet(0.5004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036718.jpg"}, {"question": "how old is this grandfather clock", "gt answer": "100 years(1.00)<br/>early 19th century(0.60)<br/>old(0.60)", "pred answer": "200 years", "question_id": 3070505, "best approach": "concept", "verif answer": "100 years", "anno approach": "wiki, concept, image", "verif wiki answer": "50 years(0.7207)", "verif concept answer": "100 years(0.6598)", "verif image answer": "old(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307050.jpg"}, {"question": "what is the latitude longatude of this location", "gt answer": "4300(1.00)<br/>1000 feet(0.60)", "pred answer": "street name", "question_id": 3748915, "best approach": "", "verif answer": "idaho", "anno approach": "wiki, concept, image", "verif wiki answer": "idaho(0.6812)", "verif concept answer": "idaho(0.6788)", "verif image answer": "idaho(0.5845)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374891.jpg"}, {"question": "what items here may cause sleep problems", "gt answer": "computer(1.00)<br/>light(0.60)<br/>laptop(0.60)", "pred answer": "curtain", "question_id": 5158035, "best approach": "wiki, concept", "verif answer": "laptop", "anno approach": "wiki, concept, image", "verif wiki answer": "laptop(0.5337)", "verif concept answer": "laptop(0.6323)", "verif image answer": "work(0.5106)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515803.jpg"}, {"question": "what nutrient do humans receive from the meat in the picture", "gt answer": "protein(1.00)", "pred answer": "calcium", "question_id": 4416785, "best approach": "wiki, image", "verif answer": "protein", "anno approach": "wiki, concept, image", "verif wiki answer": "protein(0.7146)", "verif concept answer": "vitamin(0.6787)", "verif image answer": "protein(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441678.jpg"}, {"question": "what is the truck doing", "gt answer": "sell(1.00)", "pred answer": "tow", "question_id": 3674255, "best approach": "", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "eat(0.6779)", "verif concept answer": "work(0.6402)", "verif image answer": "eat(0.7017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367425.jpg"}, {"question": "what significant contribution to the atmosphere do these make", "gt answer": "methane(1.00)", "pred answer": "oxygen", "question_id": 3597165, "best approach": "wiki, image", "verif answer": "methane", "anno approach": "wiki, concept, image", "verif wiki answer": "methane(0.5086)", "verif concept answer": "calcium(0.5067)", "verif image answer": "methane(0.6185)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359716.jpg"}, {"question": "what is the largest mammal in this pictures shoes made of", "gt answer": "iron(1.00)<br/>steel(0.60)<br/>horse(0.60)", "pred answer": "rubber", "question_id": 638935, "best approach": "concept", "verif answer": "metal", "anno approach": "wiki, concept, image", "verif wiki answer": "horse(0.6061)", "verif concept answer": "iron(0.5595)", "verif image answer": "metal(0.7087)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063893.jpg"}, {"question": "what sport is being attempted here", "gt answer": "row(1.00)<br/>canoe(0.60)", "pred answer": "water ski", "question_id": 873785, "best approach": "concept", "verif answer": "canoe", "anno approach": "wiki, concept, image", "verif wiki answer": "row boat(0.7309)", "verif concept answer": "canoe(0.5732)", "verif image answer": "row boat(0.7263)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087378.jpg"}, {"question": "to assess the health of the creature on the right you touch which of its body parts", "gt answer": "nose(1.00)<br/>arm(0.60)", "pred answer": "torso", "question_id": 4518255, "best approach": "wiki", "verif answer": "feet", "anno approach": "wiki, concept, image", "verif wiki answer": "nose(0.7274)", "verif concept answer": "nicely(0.5011)", "verif image answer": "arm(0.7166)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451825.jpg"}, {"question": "what are vehicles supposed to do", "gt answer": "slow(1.00)<br/>slow down(1.00)<br/>travel(0.60)", "pred answer": "fly", "question_id": 3797435, "best approach": "wiki", "verif answer": "travel", "anno approach": "wiki, concept, image", "verif wiki answer": "slow down(0.5498)", "verif concept answer": "travel(0.5218)", "verif image answer": "travel(0.5674)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379743.jpg"}, {"question": "what warm clothing can she make", "gt answer": "sweater(1.00)<br/>scarf(0.60)", "pred answer": "button up", "question_id": 2810605, "best approach": "wiki, concept", "verif answer": "sweater", "anno approach": "wiki, concept, image", "verif wiki answer": "sweater(0.5204)", "verif concept answer": "sweater(0.5015)", "verif image answer": "wool(0.5005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281060.jpg"}, {"question": "what are some materials that this train could be transporting", "gt answer": "grain(1.00)<br/>coal(0.60)<br/>lumber(0.60)<br/>banana(0.60)", "pred answer": "cargo", "question_id": 4152885, "best approach": "wiki, concept", "verif answer": "lumber", "anno approach": "wiki, concept, image", "verif wiki answer": "banana(0.6919)", "verif concept answer": "coal(0.5936)", "verif image answer": "corn(0.7133)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415288.jpg"}, {"question": "how many calories are in the food in this picture", "gt answer": "300(1.00)<br/>lot(0.60)<br/>500(0.60)<br/>many(0.60)", "pred answer": "200", "question_id": 4929675, "best approach": "concept", "verif answer": "lot", "anno approach": "wiki, concept, image", "verif wiki answer": "thousand(0.6760)", "verif concept answer": "lot(0.6378)", "verif image answer": "thousand(0.6746)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492967.jpg"}, {"question": "why does the bike have a basket", "gt answer": "to carry object(1.00)<br/>cold(0.60)", "pred answer": "shop", "question_id": 4249155, "best approach": "wiki, concept", "verif answer": "hot", "anno approach": "wiki, concept, image", "verif wiki answer": "to carry object(0.6894)", "verif concept answer": "to carry object(0.7083)", "verif image answer": "christmas(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424915.jpg"}, {"question": "what is the correct color of the animal in this picture", "gt answer": "gray(1.00)<br/>grey(1.00)<br/>purple(0.60)", "pred answer": "red", "question_id": 4193535, "best approach": "wiki, concept, image", "verif answer": "purple", "anno approach": "wiki, concept, image", "verif wiki answer": "grey(0.7269)", "verif concept answer": "grey(0.7171)", "verif image answer": "grey(0.6990)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419353.jpg"}, {"question": "who is serving food to everyone sitting at the table", "gt answer": "waiter(1.00)", "pred answer": "chef", "question_id": 2929235, "best approach": "", "verif answer": "table", "anno approach": "wiki, concept, image", "verif wiki answer": "fan(0.5638)", "verif concept answer": "fan(0.5804)", "verif image answer": "table(0.7242)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292923.jpg"}, {"question": "what breed of horses are those", "gt answer": "clydesdale(1.00)<br/>winter(0.60)", "pred answer": "stallion", "question_id": 3172105, "best approach": "", "verif answer": "stallion", "anno approach": "wiki, concept, image", "verif wiki answer": "stallion(0.6530)", "verif concept answer": "stallion(0.6572)", "verif image answer": "mule(0.6288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317210.jpg"}, {"question": "which us political party is represented by major color here", "gt answer": "republican(1.00)", "pred answer": "washington", "question_id": 3632435, "best approach": "", "verif answer": "obama", "anno approach": "wiki, concept, image", "verif wiki answer": "obama(0.5152)", "verif concept answer": "obama(0.5361)", "verif image answer": "jackie robinson(0.6835)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363243.jpg"}, {"question": "what is this food served on", "gt answer": "plate(1.00)<br/>breakfast(0.60)<br/>bun(0.60)", "pred answer": "table", "question_id": 1789875, "best approach": "", "verif answer": "snack", "anno approach": "wiki, concept, image", "verif wiki answer": "snack(0.7234)", "verif concept answer": "snack(0.7290)", "verif image answer": "snack(0.5246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178987.jpg"}, {"question": "what does the number eight signify", "gt answer": "player(1.00)", "pred answer": "mlb", "question_id": 3501295, "best approach": "", "verif answer": "baseball player", "anno approach": "wiki, concept, image", "verif wiki answer": "set(0.5059)", "verif concept answer": "set(0.5427)", "verif image answer": "set(0.5051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350129.jpg"}, {"question": "is this the home or visiting team", "gt answer": "home(1.00)", "pred answer": "stadium", "question_id": 4883965, "best approach": "", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "office(0.6961)", "verif concept answer": "office(0.6808)", "verif image answer": "office(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488396.jpg"}, {"question": "what collection is this", "gt answer": "teddy bear(1.00)<br/>bear(0.60)", "pred answer": "stuffed animal", "question_id": 4464715, "best approach": "image", "verif answer": "stuffed animal", "anno approach": "wiki, concept, image", "verif wiki answer": "stuffing(0.6562)", "verif concept answer": "stuffed animal(0.6695)", "verif image answer": "teddy bear(0.7028)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000446471.jpg"}, {"question": "where in florida may you see many of these", "gt answer": "beach(1.00)", "pred answer": "california", "question_id": 4741745, "best approach": "wiki, image", "verif answer": "beach", "anno approach": "wiki, concept, image", "verif wiki answer": "beach(0.5759)", "verif concept answer": "california hawaii(0.5792)", "verif image answer": "beach(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000474174.jpg"}, {"question": "is this girl performing a forehand or a backhand", "gt answer": "forehand(1.00)", "pred answer": "backhand", "question_id": 5449135, "best approach": "", "verif answer": "backhand", "anno approach": "wiki, concept, image", "verif wiki answer": "backhand(0.7298)", "verif concept answer": "backhand(0.7122)", "verif image answer": "backhand(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544913.jpg"}, {"question": "what type of signs are these", "gt answer": "traffic(1.00)<br/>stop and pedestrian cross(1.00)", "pred answer": "stop", "question_id": 793035, "best approach": "", "verif answer": "stop and pedestrian cross", "anno approach": "wiki, concept, image", "verif wiki answer": "stop light(0.6907)", "verif concept answer": "stop light(0.6853)", "verif image answer": "stop light(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079303.jpg"}, {"question": "what type of plant is this", "gt answer": "tree(1.00)", "pred answer": "bird", "question_id": 555345, "best approach": "wiki", "verif answer": "cactus", "anno approach": "wiki, concept, image", "verif wiki answer": "tree(0.6901)", "verif concept answer": "oxygen(0.6213)", "verif image answer": "florida(0.6479)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000055534.jpg"}, {"question": "what is the yellow object on the stove", "gt answer": "kettle(1.00)", "pred answer": "candle", "question_id": 3412575, "best approach": "", "verif answer": "1920", "anno approach": "wiki, concept, image", "verif wiki answer": "1920(0.6547)", "verif concept answer": "1920(0.5479)", "verif image answer": "1920(0.5571)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341257.jpg"}, {"question": "would this be safe or unsafe from a three year old with an open box of markers", "gt answer": "unsafe(1.00)", "pred answer": "safe", "question_id": 5027265, "best approach": "image", "verif answer": "safe", "anno approach": "wiki, concept, image", "verif wiki answer": "safe(0.5472)", "verif concept answer": "safe(0.5882)", "verif image answer": "unsafe(0.7117)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502726.jpg"}, {"question": "why is the man in the vest dressed differently", "gt answer": "groom(1.00)<br/>wed(0.60)", "pred answer": "business", "question_id": 4029385, "best approach": "wiki, image", "verif answer": "wed", "anno approach": "wiki, concept, image", "verif wiki answer": "wed(0.6623)", "verif concept answer": "birthday(0.6693)", "verif image answer": "wed(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402938.jpg"}, {"question": "what do the dark clouds mean the plan is flying into", "gt answer": "storm(1.00)<br/>rain(0.60)", "pred answer": "cloud", "question_id": 1476985, "best approach": "wiki, concept", "verif answer": "storm", "anno approach": "wiki, concept, image", "verif wiki answer": "storm(0.5923)", "verif concept answer": "storm(0.5467)", "verif image answer": "flood(0.5467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147698.jpg"}, {"question": "would you wet mop or vacuum this type of floor", "gt answer": "mop(1.00)", "pred answer": "bleach", "question_id": 5714315, "best approach": "", "verif answer": "bleach", "anno approach": "wiki, concept, image", "verif wiki answer": "brush(0.7298)", "verif concept answer": "brush(0.7157)", "verif image answer": "bleach(0.5003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571431.jpg"}, {"question": "how did he get there", "gt answer": "walked(1.00)<br/>jumped(0.60)", "pred answer": "work", "question_id": 4237185, "best approach": "wiki, concept, image", "verif answer": "not at all", "anno approach": "wiki, concept, image", "verif wiki answer": "walked(0.6123)", "verif concept answer": "walked(0.6457)", "verif image answer": "walked(0.6965)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000423718.jpg"}, {"question": "what objects in this photo are living", "gt answer": "flower(1.00)", "pred answer": "lamp", "question_id": 4848355, "best approach": "", "verif answer": "flower", "anno approach": "wiki, concept, image", "verif wiki answer": "decoration(0.7075)", "verif concept answer": "rose(0.6146)", "verif image answer": "rose(0.7009)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484835.jpg"}, {"question": "what is the penalty for breaking the law on the sign", "gt answer": "ticket(1.00)<br/>fine(1.00)", "pred answer": "$50", "question_id": 4726595, "best approach": "wiki, concept", "verif answer": "jail", "anno approach": "wiki, concept, image", "verif wiki answer": "ticket(0.6933)", "verif concept answer": "ticket(0.6195)", "verif image answer": "100(0.6759)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000472659.jpg"}, {"question": "how is part of the girl shown on the ground", "gt answer": "reflection(1.00)<br/>sit(1.00)", "pred answer": "foot", "question_id": 3414135, "best approach": "wiki", "verif answer": "sit", "anno approach": "wiki, concept, image", "verif wiki answer": "reflection(0.5489)", "verif concept answer": "mirror(0.6788)", "verif image answer": "mirror(0.5304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341413.jpg"}, {"question": "what is the use of the black thing on his wrist", "gt answer": "tell time(1.00)<br/>watch(1.00)<br/>to tell time(0.60)", "pred answer": "take picture", "question_id": 5670795, "best approach": "wiki, concept, image", "verif answer": "watch", "anno approach": "wiki, concept, image", "verif wiki answer": "watch(0.7310)", "verif concept answer": "watch(0.7238)", "verif image answer": "tell time(0.6503)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567079.jpg"}, {"question": "what kind of wine is the pink one", "gt answer": "rose(1.00)", "pred answer": "red", "question_id": 620385, "best approach": "image", "verif answer": "rose", "anno approach": "wiki, concept, image", "verif wiki answer": "daisy(0.6501)", "verif concept answer": "daisy(0.6737)", "verif image answer": "rose(0.7034)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000062038.jpg"}, {"question": "what formation of planes is this", "gt answer": "square(1.00)<br/>diamond(0.60)<br/>triangle(0.60)<br/>box(0.60)", "pred answer": "jet", "question_id": 1645695, "best approach": "wiki, concept, image", "verif answer": "triangle", "anno approach": "wiki, concept, image", "verif wiki answer": "triangle(0.5839)", "verif concept answer": "triangle(0.5763)", "verif image answer": "diamond(0.7143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000164569.jpg"}, {"question": "what is the race of the man or woman in this picture", "gt answer": "african american(1.00)<br/>african(0.60)<br/>indian(0.60)", "pred answer": "caucasian", "question_id": 4811245, "best approach": "image", "verif answer": "indian", "anno approach": "wiki, concept, image", "verif wiki answer": "male(0.6890)", "verif concept answer": "male(0.6748)", "verif image answer": "african american(0.6634)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481124.jpg"}, {"question": "which of these animals can run the fastest", "gt answer": "zebra(1.00)<br/>horse(1.00)", "pred answer": "foal", "question_id": 3647425, "best approach": "concept", "verif answer": "horse", "anno approach": "wiki, concept, image", "verif wiki answer": "lion(0.7227)", "verif concept answer": "horse(0.6950)", "verif image answer": "donkey(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364742.jpg"}, {"question": "what course of a meal is this", "gt answer": "dessert(1.00)<br/>desert(1.00)", "pred answer": "lunch", "question_id": 4358865, "best approach": "image", "verif answer": "cake", "anno approach": "wiki, concept, image", "verif wiki answer": "after meal(0.6882)", "verif concept answer": "after meal(0.6986)", "verif image answer": "dessert(0.7167)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435886.jpg"}, {"question": "what kind of plant is this", "gt answer": "tree(1.00)<br/>tomato(0.60)<br/>bush(0.60)", "pred answer": "succulent", "question_id": 4194745, "best approach": "", "verif answer": "bush", "anno approach": "wiki, concept, image", "verif wiki answer": "shrub(0.6893)", "verif concept answer": "shrub(0.6702)", "verif image answer": "shrub(0.6569)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419474.jpg"}, {"question": "what era is the decor from", "gt answer": "victorian(1.00)<br/>1500(0.60)<br/>1900(0.60)", "pred answer": "1970's", "question_id": 3616205, "best approach": "image", "verif answer": "classic", "anno approach": "wiki, concept, image", "verif wiki answer": "gothic(0.6093)", "verif concept answer": "1900(0.6301)", "verif image answer": "victorian(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361620.jpg"}, {"question": "what is the man doing on the surfboard", "gt answer": "paddleboarding(1.00)<br/>paddle(0.60)<br/>paddle board(0.60)", "pred answer": "row", "question_id": 106005, "best approach": "image", "verif answer": "row", "anno approach": "wiki, concept, image", "verif wiki answer": "paddle(0.6886)", "verif concept answer": "paddle(0.6383)", "verif image answer": "paddleboarding(0.7185)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000010600.jpg"}, {"question": "should you bake or roast this item", "gt answer": "bake(1.00)", "pred answer": "baked", "question_id": 5373715, "best approach": "", "verif answer": "baked", "anno approach": "wiki, concept, image", "verif wiki answer": "baked(0.5285)", "verif concept answer": "baked(0.5287)", "verif image answer": "bake it(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537371.jpg"}, {"question": "what technology does the left device use to connect with the bottom right device", "gt answer": "bluetooth(1.00)<br/>cord(0.60)", "pred answer": "text", "question_id": 5547445, "best approach": "", "verif answer": "wireless", "anno approach": "wiki, concept, image", "verif wiki answer": "wireless(0.6984)", "verif concept answer": "wireless(0.6676)", "verif image answer": "wireless(0.7103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554744.jpg"}, {"question": "which kind of dishes can be made using the fruits shown in this picture", "gt answer": "fruit salad(1.00)<br/>pie(0.60)<br/>dessert(0.60)", "pred answer": "banana split", "question_id": 2839685, "best approach": "", "verif answer": "dessert", "anno approach": "wiki, concept, image", "verif wiki answer": "cereal(0.7279)", "verif concept answer": "pancake(0.6818)", "verif image answer": "pancake(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283968.jpg"}, {"question": "what can you do with the largest object in the cup", "gt answer": "cut(1.00)", "pred answer": "brush teeth", "question_id": 5135515, "best approach": "", "verif answer": "chop", "anno approach": "wiki, concept, image", "verif wiki answer": "chop(0.5704)", "verif concept answer": "chop(0.5699)", "verif image answer": "chop(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513551.jpg"}, {"question": "where is this plane heading next", "gt answer": "las vegas(1.00)<br/>europe(0.60)<br/>spain(0.60)", "pred answer": "runway", "question_id": 2927635, "best approach": "concept", "verif answer": "europe", "anno approach": "wiki, concept, image", "verif wiki answer": "europe(0.5537)", "verif concept answer": "las vegas(0.5369)", "verif image answer": "spain(0.5019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292763.jpg"}, {"question": "is the zebra free or fenced in", "gt answer": "fenced(1.00)<br/>free(0.60)", "pred answer": "locked up", "question_id": 2252645, "best approach": "wiki", "verif answer": "locked up", "anno approach": "wiki, concept, image", "verif wiki answer": "fenced(0.5125)", "verif concept answer": "locked up(0.5004)", "verif image answer": "locked up(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225264.jpg"}, {"question": "which food when prepared has been known to cause watery eyes", "gt answer": "onion(1.00)", "pred answer": "hot dog", "question_id": 2946885, "best approach": "", "verif answer": "ketchup", "anno approach": "wiki, concept, image", "verif wiki answer": "ketchup(0.6828)", "verif concept answer": "ketchup(0.6121)", "verif image answer": "olive(0.5829)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000294688.jpg"}, {"question": "what is the likely relationship between these people", "gt answer": "father and son(1.00)", "pred answer": "family", "question_id": 3202345, "best approach": "concept", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "friend(0.7216)", "verif concept answer": "father and son(0.7137)", "verif image answer": "woman(0.6910)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320234.jpg"}, {"question": "which pan should you use to bake this", "gt answer": "bundt(1.00)<br/>cake(0.60)", "pred answer": "dough", "question_id": 5455735, "best approach": "", "verif answer": "cookies", "anno approach": "wiki, concept, image", "verif wiki answer": "eat(0.5993)", "verif concept answer": "eat(0.5770)", "verif image answer": "eat(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545573.jpg"}, {"question": "what establishment is serving this food", "gt answer": "food truck(1.00)<br/>food(0.60)<br/>united state(0.60)", "pred answer": "cafe", "question_id": 4277275, "best approach": "", "verif answer": "chicago", "anno approach": "wiki, concept, image", "verif wiki answer": "chicago(0.7134)", "verif concept answer": "restaurant(0.5337)", "verif image answer": "chicago(0.7270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427727.jpg"}, {"question": "how might this animal carry one of the items behind him should one fall", "gt answer": "trunk(1.00)", "pred answer": "paddle", "question_id": 1139445, "best approach": "concept, image", "verif answer": "trunk", "anno approach": "wiki, concept, image", "verif wiki answer": "through his trunk(0.5054)", "verif concept answer": "trunk(0.5022)", "verif image answer": "trunk(0.7110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113944.jpg"}, {"question": "what brand of purse might she be carrying", "gt answer": "gucci(1.00)", "pred answer": "louis vitton", "question_id": 968815, "best approach": "image", "verif answer": "ll bean", "anno approach": "wiki, concept, image", "verif wiki answer": "dell(0.6504)", "verif concept answer": "nokia(0.6951)", "verif image answer": "gucci(0.6146)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096881.jpg"}, {"question": "what organization are some of these kids wearing the uniform for", "gt answer": "boy scout(1.00)<br/>scout(0.60)<br/>school(0.60)", "pred answer": "kid", "question_id": 4478635, "best approach": "concept, image", "verif answer": "scout", "anno approach": "wiki, concept, image", "verif wiki answer": "church(0.6021)", "verif concept answer": "scout(0.5220)", "verif image answer": "scout(0.6897)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447863.jpg"}, {"question": "in what country would you see a meal like this", "gt answer": "china(1.00)<br/>usa(0.60)<br/>india(0.60)", "pred answer": "america", "question_id": 4067535, "best approach": "image", "verif answer": "usa", "anno approach": "wiki, concept, image", "verif wiki answer": "us(0.5738)", "verif concept answer": "us(0.6158)", "verif image answer": "usa(0.6608)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000406753.jpg"}, {"question": "what is the name of the red headed girlfriend of the character on the boy 's shoes", "gt answer": "mary jane(1.00)<br/>cherry(0.60)", "pred answer": "bart", "question_id": 2680945, "best approach": "wiki, concept, image", "verif answer": "strawberry", "anno approach": "wiki, concept, image", "verif wiki answer": "mary jane(0.7305)", "verif concept answer": "mary jane(0.7306)", "verif image answer": "mary jane(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268094.jpg"}, {"question": "if one of the dogs falls off this apparatus will it likely float or sink", "gt answer": "float(1.00)<br/>sink(0.60)", "pred answer": "boat", "question_id": 62295, "best approach": "wiki", "verif answer": "float", "anno approach": "wiki, concept, image", "verif wiki answer": "float(0.5281)", "verif concept answer": "flotation(0.5040)", "verif image answer": "sink(0.7120)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006229.jpg"}, {"question": "what is the brand of eyeglasses this man is wearing", "gt answer": "rayban(1.00)", "pred answer": "target", "question_id": 5806785, "best approach": "", "verif answer": "rayban", "anno approach": "wiki, concept, image", "verif wiki answer": "oakley(0.5718)", "verif concept answer": "apollo(0.5999)", "verif image answer": "ray ban(0.6927)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580678.jpg"}, {"question": "if you want to practice what this boy is doing you need to go into a what", "gt answer": "bat cage(1.00)<br/>baseball(0.60)<br/>hit(0.60)", "pred answer": "first base", "question_id": 890935, "best approach": "", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "bat(0.7258)", "verif concept answer": "bat(0.6401)", "verif image answer": "yard(0.7195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089093.jpg"}, {"question": "what is this elephant doing", "gt answer": "walk(1.00)<br/>smile(0.60)", "pred answer": "stand", "question_id": 1165625, "best approach": "wiki, concept", "verif answer": "walk", "anno approach": "wiki, concept, image", "verif wiki answer": "walk(0.6329)", "verif concept answer": "walk(0.6980)", "verif image answer": "smile(0.6921)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000116562.jpg"}, {"question": "is this man just lazy or homeless", "gt answer": "homeless(1.00)<br/>lazy(0.60)", "pred answer": "tired", "question_id": 3132635, "best approach": "image", "verif answer": "homeless", "anno approach": "wiki, concept, image", "verif wiki answer": "pirate(0.7242)", "verif concept answer": "pirate(0.7275)", "verif image answer": "lazy(0.6023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313263.jpg"}, {"question": "what is the brand of bananas", "gt answer": "dole(1.00)<br/>sun(0.60)", "pred answer": "plantain", "question_id": 5217635, "best approach": "", "verif answer": "levis", "anno approach": "wiki, concept, image", "verif wiki answer": "levis(0.7302)", "verif concept answer": "levis(0.6346)", "verif image answer": "brocoli(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521763.jpg"}, {"question": "who would likely be standing in front of this equipment", "gt answer": "child(1.00)", "pred answer": "wife", "question_id": 2703885, "best approach": "concept, image", "verif answer": "child", "anno approach": "wiki, concept, image", "verif wiki answer": "artist(0.6924)", "verif concept answer": "child(0.5969)", "verif image answer": "child(0.6884)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270388.jpg"}, {"question": "what 's on tv", "gt answer": "speed skate(1.00)<br/>olympics(0.60)<br/>race(0.60)", "pred answer": "movie", "question_id": 626525, "best approach": "concept, image", "verif answer": "cow", "anno approach": "wiki, concept, image", "verif wiki answer": "cow(0.7309)", "verif concept answer": "olympics(0.5957)", "verif image answer": "olympics(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000062652.jpg"}, {"question": "what northern european country are these men in", "gt answer": "switzerland(1.00)<br/>london(0.60)<br/>germany(0.60)<br/>england(0.60)", "pred answer": "uk", "question_id": 2185955, "best approach": "image", "verif answer": "uk", "anno approach": "wiki, concept, image", "verif wiki answer": "uk(0.7146)", "verif concept answer": "uk(0.5560)", "verif image answer": "england(0.6792)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218595.jpg"}, {"question": "which mount is this", "gt answer": "tv(1.00)<br/>television(0.60)", "pred answer": "northern", "question_id": 4064525, "best approach": "wiki, concept", "verif answer": "screen", "anno approach": "wiki, concept, image", "verif wiki answer": "television(0.5300)", "verif concept answer": "television(0.5042)", "verif image answer": "screen(0.5545)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000406452.jpg"}, {"question": "what is this type of kite called", "gt answer": "japanese(1.00)<br/>fabric(0.60)<br/>box(0.60)", "pred answer": "octopus", "question_id": 2916255, "best approach": "wiki, concept, image", "verif answer": "chinese", "anno approach": "wiki, concept, image", "verif wiki answer": "fabric(0.5346)", "verif concept answer": "fabric(0.6539)", "verif image answer": "fabric(0.6114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291625.jpg"}, {"question": "what is the person standing in front of the netted cage called", "gt answer": "goalie(1.00)", "pred answer": "umpire", "question_id": 4891865, "best approach": "wiki, concept, image", "verif answer": "goalie", "anno approach": "wiki, concept, image", "verif wiki answer": "goalie(0.6722)", "verif concept answer": "goalie(0.5932)", "verif image answer": "goalie(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489186.jpg"}, {"question": "how is the waste removed from this object", "gt answer": "flush(1.00)<br/>suction(0.60)", "pred answer": "bleach", "question_id": 507355, "best approach": "wiki", "verif answer": "bleach", "anno approach": "wiki, concept, image", "verif wiki answer": "flush(0.7271)", "verif concept answer": "wash hand(0.7082)", "verif image answer": "wash hand(0.7036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050735.jpg"}, {"question": "what brand of pen was used", "gt answer": "bic(1.00)", "pred answer": "amazon", "question_id": 5308485, "best approach": "", "verif answer": "colgate", "anno approach": "wiki, concept, image", "verif wiki answer": "theodore roosevelt(0.7221)", "verif concept answer": "theodore roosevelt(0.6976)", "verif image answer": "theodore roosevelt(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000530848.jpg"}, {"question": "who is directing traffic", "gt answer": "police officer(0.60)<br/>cross guard(1.00)<br/>guard(0.60)", "pred answer": "bus driver", "question_id": 1354125, "best approach": "wiki", "verif answer": "cross guard", "anno approach": "wiki, concept, image", "verif wiki answer": "cross guard(0.7271)", "verif concept answer": "traffic control(0.6952)", "verif image answer": "policeman(0.7257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000135412.jpg"}, {"question": "this animal is most common in which continent", "gt answer": "north america(1.00)<br/>europe(0.60)<br/>australia(0.60)", "pred answer": "africa", "question_id": 4587055, "best approach": "image", "verif answer": "africa", "anno approach": "wiki, concept, image", "verif wiki answer": "africa(0.6882)", "verif concept answer": "america(0.7243)", "verif image answer": "europe(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458705.jpg"}, {"question": "what type of material is underneath the railroad tracks", "gt answer": "rock(1.00)<br/>stone(0.60)", "pred answer": "track", "question_id": 1264575, "best approach": "image", "verif answer": "concrete", "anno approach": "wiki, concept, image", "verif wiki answer": "concrete(0.7156)", "verif concept answer": "concrete(0.6338)", "verif image answer": "stone(0.6878)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126457.jpg"}, {"question": "the sandwich in the corner has a bread associated with what cosmopolitan city", "gt answer": "paris(1.00)", "pred answer": "italy", "question_id": 15585, "best approach": "wiki, concept, image", "verif answer": "france", "anno approach": "wiki, concept, image", "verif wiki answer": "paris(0.6377)", "verif concept answer": "paris(0.7057)", "verif image answer": "paris(0.6692)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001558.jpg"}, {"question": "what nationallity is the little girl", "gt answer": "indian(1.00)<br/>african(0.60)", "pred answer": "england", "question_id": 1778405, "best approach": "image", "verif answer": "asian", "anno approach": "wiki, concept, image", "verif wiki answer": "asian(0.6949)", "verif concept answer": "asian(0.5582)", "verif image answer": "african(0.6991)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177840.jpg"}, {"question": "what type of horse is in the image", "gt answer": "clydesdale(1.00)<br/>pony(1.00)", "pred answer": "arabian", "question_id": 4973845, "best approach": "", "verif answer": "thoroughbred", "anno approach": "wiki, concept, image", "verif wiki answer": "thoroughbred(0.7287)", "verif concept answer": "thoroughbred(0.6132)", "verif image answer": "thoroughbred(0.7262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497384.jpg"}, {"question": "what type of window is this", "gt answer": "arched(1.00)<br/>wooden(0.60)<br/>gothic(0.60)<br/>cathedral(0.60)", "pred answer": "oculus", "question_id": 3530905, "best approach": "concept, image", "verif answer": "gothic", "anno approach": "wiki, concept, image", "verif wiki answer": "wooden(0.7103)", "verif concept answer": "arched(0.6969)", "verif image answer": "arched(0.6363)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353090.jpg"}, {"question": "what are these airplanes doing", "gt answer": "trick(1.00)", "pred answer": "land", "question_id": 5501445, "best approach": "", "verif answer": "fall", "anno approach": "wiki, concept, image", "verif wiki answer": "fall(0.6331)", "verif concept answer": "fall(0.6556)", "verif image answer": "fall(0.5051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550144.jpg"}, {"question": "which first lady campaigned for healthier school meals", "gt answer": "michelle obama(1.00)", "pred answer": "banana", "question_id": 247025, "best approach": "", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "clean(0.6775)", "verif concept answer": "clean(0.7141)", "verif image answer": "friend(0.6657)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024702.jpg"}, {"question": "can you guess the place where the zebras are shown in this picture", "gt answer": "serengeti(1.00)<br/>africa(0.60)", "pred answer": "forest", "question_id": 1813515, "best approach": "", "verif answer": "grassland", "anno approach": "wiki, concept, image", "verif wiki answer": "savanna(0.7039)", "verif concept answer": "savanna(0.7114)", "verif image answer": "savanna(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181351.jpg"}, {"question": "what sport can you play here", "gt answer": "soccer(1.00)", "pred answer": "frisbee", "question_id": 5659395, "best approach": "", "verif answer": "frisbee", "anno approach": "wiki, concept, image", "verif wiki answer": "soccer ball(0.6234)", "verif concept answer": "discus(0.6794)", "verif image answer": "discus(0.6823)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000565939.jpg"}, {"question": "is the banana whole or cut into pieces", "gt answer": "cut(1.00)", "pred answer": "full", "question_id": 3601855, "best approach": "", "verif answer": "slice", "anno approach": "wiki, concept, image", "verif wiki answer": "chop(0.5120)", "verif concept answer": "chop(0.5099)", "verif image answer": "slice(0.7230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000360185.jpg"}, {"question": "what type of headwear is the man in the background wearing", "gt answer": "wizard hat(1.00)<br/>hat(0.60)", "pred answer": "kilt", "question_id": 2056725, "best approach": "wiki, image", "verif answer": "hijab", "anno approach": "wiki, concept, image", "verif wiki answer": "wizard hat(0.7190)", "verif concept answer": "bonnet(0.7069)", "verif image answer": "wizard hat(0.6984)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205672.jpg"}, {"question": "what is this fixture for that is next to the train", "gt answer": "light(1.00)<br/>illumination(0.60)", "pred answer": "transport", "question_id": 91785, "best approach": "wiki, concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "illumination(0.7095)", "verif concept answer": "illumination(0.6116)", "verif image answer": "sunlight(0.5783)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009178.jpg"}, {"question": "what is the scientific name of this bird", "gt answer": "cyanocitta cristata(1.00)<br/>bluejay(0.60)<br/>robin(0.60)", "pred answer": "parrot", "question_id": 743485, "best approach": "wiki, concept", "verif answer": "finch", "anno approach": "wiki, concept, image", "verif wiki answer": "cyanocitta cristata(0.7194)", "verif concept answer": "cyanocitta cristata(0.7148)", "verif image answer": "finch(0.6795)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074348.jpg"}, {"question": "what are ways to help babies fall asleep", "gt answer": "drive(1.00)<br/>noise(0.60)<br/>rock(0.60)", "pred answer": "comforter", "question_id": 1517645, "best approach": "wiki, concept, image", "verif answer": "rock", "anno approach": "wiki, concept, image", "verif wiki answer": "rock(0.6281)", "verif concept answer": "noise(0.6656)", "verif image answer": "rock(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151764.jpg"}, {"question": "what company owns this bus", "gt answer": "kingston transit(1.00)<br/>greyhound(0.60)", "pred answer": "greenwave", "question_id": 3382105, "best approach": "", "verif answer": "vw", "anno approach": "wiki, concept, image", "verif wiki answer": "vw(0.5485)", "verif concept answer": "vw(0.5289)", "verif image answer": "vw(0.6761)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338210.jpg"}, {"question": "the studs at the bottom of this player 's shoes are called what", "gt answer": "cleat(1.00)", "pred answer": "home run", "question_id": 1547545, "best approach": "", "verif answer": "cleat", "anno approach": "wiki, concept, image", "verif wiki answer": "border collie(0.6620)", "verif concept answer": "border collie(0.6902)", "verif image answer": "border collie(0.6894)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154754.jpg"}, {"question": "what is the name for this type of waterway", "gt answer": "canal(1.00)<br/>river(0.60)<br/>lake(0.60)", "pred answer": "panama canal", "question_id": 2328895, "best approach": "concept", "verif answer": "panama canal", "anno approach": "wiki, concept, image", "verif wiki answer": "panama canal(0.7255)", "verif concept answer": "lake(0.7191)", "verif image answer": "panama canal(0.7237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232889.jpg"}, {"question": "what style of motorcycles are pictured here", "gt answer": "chopper(1.00)<br/>police(0.60)<br/>street(0.60)<br/>harley davidson(0.60)", "pred answer": "honda", "question_id": 4530965, "best approach": "wiki, concept, image", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.6715)", "verif concept answer": "harley davidson(0.6649)", "verif image answer": "police(0.6330)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453096.jpg"}, {"question": "what company makes the car in the background", "gt answer": "volvo(1.00)<br/>toyota(0.60)<br/>chevy(0.60)<br/>fiat(0.60)", "pred answer": "mercedes", "question_id": 1393975, "best approach": "image", "verif answer": "chevy", "anno approach": "wiki, concept, image", "verif wiki answer": "fiat(0.6734)", "verif concept answer": "fiat(0.5780)", "verif image answer": "volvo(0.5370)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139397.jpg"}, {"question": "what year was the first vehicle of the type in the photo invented", "gt answer": "1800s(1.00)<br/>1850(0.60)", "pred answer": "1930", "question_id": 4111555, "best approach": "", "verif answer": "1900", "anno approach": "wiki, concept, image", "verif wiki answer": "1950(0.6226)", "verif concept answer": "1800's(0.6235)", "verif image answer": "1900(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000411155.jpg"}, {"question": "what are these traffic lights preventing", "gt answer": "traffic(1.00)<br/>car(0.60)<br/>people(0.60)", "pred answer": "stop", "question_id": 1876115, "best approach": "image", "verif answer": "traffic", "anno approach": "wiki, concept, image", "verif wiki answer": "city(0.6767)", "verif concept answer": "city(0.7029)", "verif image answer": "traffic(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187611.jpg"}, {"question": "what do these poles all open up into when water falls", "gt answer": "umbrella(1.00)<br/>rain(0.60)", "pred answer": "pool", "question_id": 5027245, "best approach": "", "verif answer": "decor", "anno approach": "wiki, concept, image", "verif wiki answer": "decor(0.5785)", "verif concept answer": "decor(0.5581)", "verif image answer": "decor(0.6982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502724.jpg"}, {"question": "why is this street sign yellow", "gt answer": "caution(1.00)", "pred answer": "pedestrian cross", "question_id": 990105, "best approach": "", "verif answer": "pedestrian cross", "anno approach": "wiki, concept, image", "verif wiki answer": "slow down(0.5510)", "verif concept answer": "slow down(0.6941)", "verif image answer": "slow down(0.5791)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099010.jpg"}, {"question": "what kind of pizza has meatballs on top", "gt answer": "meatball(1.00)<br/>italian(0.60)", "pred answer": "pepperoni", "question_id": 3698895, "best approach": "wiki", "verif answer": "sub", "anno approach": "wiki, concept, image", "verif wiki answer": "italian(0.5105)", "verif concept answer": "grill(0.6678)", "verif image answer": "sub(0.6371)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369889.jpg"}, {"question": "what did people ride during the pony express", "gt answer": "horse(1.00)", "pred answer": "carriage", "question_id": 2177265, "best approach": "", "verif answer": "horse", "anno approach": "wiki, concept, image", "verif wiki answer": "pony(0.5938)", "verif concept answer": "pony(0.7076)", "verif image answer": "zebra(0.6894)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217726.jpg"}, {"question": "what year was this photo taken", "gt answer": "1950(1.00)<br/>1800(0.60)<br/>1930(0.60)", "pred answer": "1945", "question_id": 1472775, "best approach": "", "verif answer": "1930", "anno approach": "wiki, concept, image", "verif wiki answer": "1965(0.6874)", "verif concept answer": "1965(0.5980)", "verif image answer": "1965(0.6902)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147277.jpg"}, {"question": "what would you call that blueish color", "gt answer": "teal(1.00)<br/>grey(0.60)", "pred answer": "light", "question_id": 3721225, "best approach": "", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "green(0.5927)", "verif concept answer": "green(0.5184)", "verif image answer": "white(0.5016)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372122.jpg"}, {"question": "what is the item the man is standing on made from", "gt answer": "surfboard(1.00)<br/>wood(0.60)<br/>surf board(0.60)", "pred answer": "plastic", "question_id": 5577255, "best approach": "concept, image", "verif answer": "plastic", "anno approach": "wiki, concept, image", "verif wiki answer": "plastic(0.5841)", "verif concept answer": "wood(0.5605)", "verif image answer": "wood(0.6637)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557725.jpg"}, {"question": "what activity is this", "gt answer": "haircut(1.00)<br/>cut(0.60)", "pred answer": "brush teeth", "question_id": 2619565, "best approach": "wiki, concept, image", "verif answer": "haircut", "anno approach": "wiki, concept, image", "verif wiki answer": "haircut(0.7121)", "verif concept answer": "haircut(0.7101)", "verif image answer": "haircut(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261956.jpg"}, {"question": "how do you make the drink in the front of the picture", "gt answer": "mix it(1.00)", "pred answer": "brew", "question_id": 1984265, "best approach": "", "verif answer": "brew", "anno approach": "wiki, concept, image", "verif wiki answer": "napkin(0.7223)", "verif concept answer": "napkin(0.6828)", "verif image answer": "hand(0.6277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198426.jpg"}, {"question": "this that the front or back of the train", "gt answer": "back(1.00)<br/>front(0.60)", "pred answer": "engine", "question_id": 2492615, "best approach": "wiki, concept", "verif answer": "back", "anno approach": "wiki, concept, image", "verif wiki answer": "back(0.7010)", "verif concept answer": "back(0.5378)", "verif image answer": "behind(0.7060)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249261.jpg"}, {"question": "what are these kids doing", "gt answer": "play(1.00)<br/>game(0.60)<br/>play video game(0.60)<br/>video game(0.60)", "pred answer": "study", "question_id": 1243645, "best approach": "", "verif answer": "game", "anno approach": "wiki, concept, image", "verif wiki answer": "play game(0.6154)", "verif concept answer": "play game(0.7057)", "verif image answer": "play game(0.7092)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000124364.jpg"}, {"question": "", "gt answer": "get lost(0.60)<br/>low(0.60)", "pred answer": "drown", "question_id": 2860515, "best approach": "wiki, concept, image", "verif answer": "get lost", "anno approach": "wiki, concept, image", "verif wiki answer": "low(0.5977)", "verif concept answer": "low(0.5925)", "verif image answer": "get lost(0.6471)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000286051.jpg"}, {"question": "how any passengers would this plane hold", "gt answer": "300(1.00)<br/>500(0.60)<br/>60(0.60)<br/>lot(0.60)", "pred answer": "200", "question_id": 5381705, "best approach": "concept", "verif answer": "200", "anno approach": "wiki, concept, image", "verif wiki answer": "60(0.6300)", "verif concept answer": "300(0.6362)", "verif image answer": "60(0.6377)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538170.jpg"}, {"question": "what is this animal used for", "gt answer": "food(1.00)<br/>cow(0.60)<br/>milk(0.60)", "pred answer": "eat", "question_id": 987035, "best approach": "wiki", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "food(0.7281)", "verif concept answer": "meat(0.5796)", "verif image answer": "meat(0.7130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098703.jpg"}, {"question": "how much does an average business spend on these", "gt answer": "$500(1.00)<br/>1000(0.60)<br/>10000(0.60)", "pred answer": "350", "question_id": 225005, "best approach": "wiki, concept, image", "verif answer": "million", "anno approach": "wiki, concept, image", "verif wiki answer": "$500(0.5596)", "verif concept answer": "$500(0.6027)", "verif image answer": "$500(0.6721)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000022500.jpg"}, {"question": "which city is this", "gt answer": "paris(1.00)", "pred answer": "london", "question_id": 2097726, "best approach": "", "verif answer": "london", "anno approach": "wiki, concept, image", "verif wiki answer": "city(0.5081)", "verif concept answer": "london(0.5704)", "verif image answer": "london(0.5205)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209772.jpg"}, {"question": "they won or lose the game", "gt answer": "lose(1.00)<br/>lost(0.60)", "pred answer": "tennis", "question_id": 528975, "best approach": "", "verif answer": "family", "anno approach": "wiki, concept, image", "verif wiki answer": "best friend(0.6148)", "verif concept answer": "family(0.6860)", "verif image answer": "family(0.6709)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052897.jpg"}, {"question": "what is the red and blue object in the photo used for", "gt answer": "fire hydrant(1.00)<br/>fight fire(0.60)<br/>put out fire(0.60)<br/>fire(0.60)", "pred answer": "firefight", "question_id": 1251175, "best approach": "wiki", "verif answer": "firefight", "anno approach": "wiki, concept, image", "verif wiki answer": "fire hydrant(0.7078)", "verif concept answer": "firefight(0.6921)", "verif image answer": "firefight(0.6615)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125117.jpg"}, {"question": "what type of cat is this", "gt answer": "domestic shorthair(1.00)<br/>tabby(0.60)<br/>grey(0.60)<br/>maine coon(0.60)", "pred answer": "persian", "question_id": 5768505, "best approach": "wiki, concept", "verif answer": "domestic", "anno approach": "wiki, concept, image", "verif wiki answer": "domestic shorthair(0.6888)", "verif concept answer": "domestic shorthair(0.7055)", "verif image answer": "maine coon(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000576850.jpg"}, {"question": "the truck was made in what year", "gt answer": "1995(1.00)<br/>2010(0.60)<br/>1990(0.60)", "pred answer": "1970", "question_id": 1884405, "best approach": "wiki, concept, image", "verif answer": "1995", "anno approach": "wiki, concept, image", "verif wiki answer": "1995(0.5963)", "verif concept answer": "1995(0.5814)", "verif image answer": "1995(0.6942)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188440.jpg"}, {"question": "what allergy is associated with this substance", "gt answer": "pollen(1.00)<br/>spring(0.60)", "pred answer": "fiber", "question_id": 5695305, "best approach": "wiki, concept, image", "verif answer": "spring", "anno approach": "wiki, concept, image", "verif wiki answer": "pollen(0.5928)", "verif concept answer": "pollen(0.6140)", "verif image answer": "pollen(0.6406)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569530.jpg"}, {"question": "how many passengers can this vehicle hold", "gt answer": "52(1.00)<br/>60(0.60)<br/>lot(0.60)", "pred answer": "200", "question_id": 1665295, "best approach": "wiki, concept", "verif answer": "60", "anno approach": "wiki, concept, image", "verif wiki answer": "60(0.6741)", "verif concept answer": "60(0.6625)", "verif image answer": "50 inch(0.7193)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166529.jpg"}, {"question": "what can be done to prevent this device from overheating", "gt answer": "turn it off(1.00)<br/>fan(0.60)", "pred answer": "window", "question_id": 2413415, "best approach": "image", "verif answer": "bill gate", "anno approach": "wiki, concept, image", "verif wiki answer": "air conditioning(0.5179)", "verif concept answer": "bill gate(0.5064)", "verif image answer": "turn it off(0.7065)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241341.jpg"}, {"question": "what kind of machine is this", "gt answer": "stove(1.00)", "pred answer": "microwave", "question_id": 3388895, "best approach": "", "verif answer": "microwave", "anno approach": "wiki, concept, image", "verif wiki answer": "mixer(0.5045)", "verif concept answer": "mixer(0.5962)", "verif image answer": "mixer(0.5528)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338889.jpg"}, {"question": "this dog is an example of what breed", "gt answer": "terrier(1.00)<br/>pug(0.60)<br/>collie(0.60)", "pred answer": "mutt", "question_id": 1536015, "best approach": "wiki, concept", "verif answer": "chihuahua", "anno approach": "wiki, concept, image", "verif wiki answer": "collie(0.6726)", "verif concept answer": "collie(0.6380)", "verif image answer": "chihuahua(0.7143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153601.jpg"}, {"question": "how far from shore would you practice this activity", "gt answer": "100 yards(1.00)<br/>close(0.60)<br/>100 feet(0.60)", "pred answer": "8 feet", "question_id": 338695, "best approach": "image", "verif answer": "far", "anno approach": "wiki, concept, image", "verif wiki answer": "6000 feet(0.6848)", "verif concept answer": "6000 feet(0.6737)", "verif image answer": "100 yards(0.7301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033869.jpg"}, {"question": "what is the boy pretending to do", "gt answer": "talk on phone(1.00)<br/>telephone(0.60)", "pred answer": "sleep", "question_id": 5756315, "best approach": "wiki, concept, image", "verif answer": "sleep", "anno approach": "wiki, concept, image", "verif wiki answer": "talk on phone(0.5025)", "verif concept answer": "talk on phone(0.5061)", "verif image answer": "talk on phone(0.6533)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575631.jpg"}, {"question": "what is the main idea of the book this girl is reading", "gt answer": "math(1.00)<br/>number(0.60)", "pred answer": "fairytale", "question_id": 5272245, "best approach": "", "verif answer": "study", "anno approach": "wiki, concept, image", "verif wiki answer": "school(0.5087)", "verif concept answer": "school(0.5275)", "verif image answer": "school(0.5130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527224.jpg"}, {"question": "is this lawn unkept or manicured", "gt answer": "unkept(1.00)", "pred answer": "deciduous", "question_id": 3909435, "best approach": "wiki, concept", "verif answer": "wet", "anno approach": "wiki, concept, image", "verif wiki answer": "unkept(0.5610)", "verif concept answer": "unkept(0.5858)", "verif image answer": "free(0.5960)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390943.jpg"}, {"question": "which breed of dogs do you think these are", "gt answer": "mutt(1.00)<br/>doberman(0.60)", "pred answer": "bulldog", "question_id": 2196335, "best approach": "", "verif answer": "doberman", "anno approach": "wiki, concept, image", "verif wiki answer": "chihuahua(0.7142)", "verif concept answer": "chihuahua(0.6909)", "verif image answer": "chihuahua(0.5774)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219633.jpg"}, {"question": "name the dish prepared used to make using this fruit", "gt answer": "apple pie(1.00)<br/>pie(1.00)", "pred answer": "apple", "question_id": 3088295, "best approach": "image", "verif answer": "pie", "anno approach": "wiki, concept, image", "verif wiki answer": "fork(0.5646)", "verif concept answer": "cheesecake(0.7158)", "verif image answer": "pie(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308829.jpg"}, {"question": "what type of company is in the bottom left", "gt answer": "van(1.00)<br/>shoe(1.00)", "pred answer": "skateboard", "question_id": 5175845, "best approach": "", "verif answer": "skateboard", "anno approach": "wiki, concept, image", "verif wiki answer": "skateboard(0.6307)", "verif concept answer": "skateboard(0.6354)", "verif image answer": "skateboard(0.6954)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517584.jpg"}, {"question": "what is the likely location", "gt answer": "restaurant(1.00)<br/>coffee shop(0.60)", "pred answer": "cafe", "question_id": 4251755, "best approach": "concept", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "school(0.7203)", "verif concept answer": "restaurant(0.6862)", "verif image answer": "bakery(0.7021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425175.jpg"}, {"question": "is the little girl inside or outside the cage", "gt answer": "outside(1.00)", "pred answer": "inside", "question_id": 3633635, "best approach": "concept", "verif answer": "inside", "anno approach": "wiki, concept, image", "verif wiki answer": "inside(0.7027)", "verif concept answer": "outside(0.6222)", "verif image answer": "inside(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363363.jpg"}, {"question": "does this recipe call for more or less chocolate than a different recipe", "gt answer": "less(1.00)", "pred answer": "even", "question_id": 277935, "best approach": "", "verif answer": "even", "anno approach": "wiki, concept, image", "verif wiki answer": "even(0.5346)", "verif concept answer": "even(0.5387)", "verif image answer": "both(0.6816)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027793.jpg"}, {"question": "how are these two people related", "gt answer": "sibling(1.00)", "pred answer": "family", "question_id": 4223115, "best approach": "wiki", "verif answer": "sister", "anno approach": "wiki, concept, image", "verif wiki answer": "sibling(0.6270)", "verif concept answer": "sister(0.6856)", "verif image answer": "center(0.6935)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422311.jpg"}, {"question": "the yellow rubber item gets attached to what item often seen on sidewalks", "gt answer": "fire hydrant(1.00)<br/>hose(0.60)", "pred answer": "stair", "question_id": 4029415, "best approach": "wiki, concept", "verif answer": "hose", "anno approach": "wiki, concept, image", "verif wiki answer": "hose(0.6280)", "verif concept answer": "hose(0.6609)", "verif image answer": "extinguish fire(0.5029)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402941.jpg"}, {"question": "how open is the young man with the orange cap to what the other man is saying", "gt answer": "not at all(1.00)<br/>not very(0.60)", "pred answer": "far", "question_id": 1286475, "best approach": "wiki", "verif answer": "not very", "anno approach": "wiki, concept, image", "verif wiki answer": "not at all(0.7256)", "verif concept answer": "easy(0.6659)", "verif image answer": "easy(0.6958)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128647.jpg"}, {"question": "what shape is hanging in the window", "gt answer": "star(1.00)<br/>rectangle(0.60)", "pred answer": "triangle", "question_id": 5737245, "best approach": "wiki, concept, image", "verif answer": "star", "anno approach": "wiki, concept, image", "verif wiki answer": "star(0.7310)", "verif concept answer": "star(0.7307)", "verif image answer": "star(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000573724.jpg"}, {"question": "which culture are these women a part of", "gt answer": "african(1.00)<br/>indian(0.60)", "pred answer": "hindu", "question_id": 3197985, "best approach": "wiki, concept", "verif answer": "indian", "anno approach": "wiki, concept, image", "verif wiki answer": "african(0.5771)", "verif concept answer": "african(0.6551)", "verif image answer": "zoo(0.6743)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319798.jpg"}, {"question": "what is the green vegatable in the salad", "gt answer": "green pepper(1.00)<br/>lettuce(0.60)", "pred answer": "kale", "question_id": 2595945, "best approach": "", "verif answer": "kale", "anno approach": "wiki, concept, image", "verif wiki answer": "spinach(0.7134)", "verif concept answer": "kale(0.6934)", "verif image answer": "spinach(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259594.jpg"}, {"question": "is this vehicle an automatic or manual", "gt answer": "manual(1.00)", "pred answer": "automatic", "question_id": 2559045, "best approach": "", "verif answer": "automatic", "anno approach": "wiki, concept, image", "verif wiki answer": "automatic(0.7267)", "verif concept answer": "automatic(0.7191)", "verif image answer": "automatic(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255904.jpg"}, {"question": "what city does this player play for", "gt answer": "oakland(1.00)", "pred answer": "baltimore", "question_id": 857745, "best approach": "", "verif answer": "baltimore", "anno approach": "wiki, concept, image", "verif wiki answer": "san francisco(0.5290)", "verif concept answer": "baltimore(0.6067)", "verif image answer": "baltimore(0.6627)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085774.jpg"}, {"question": "how long does this animal usually live", "gt answer": "9 years(1.00)<br/>15 years(0.60)<br/>10 years(0.60)", "pred answer": "20 years", "question_id": 113985, "best approach": "image", "verif answer": "10 years", "anno approach": "wiki, concept, image", "verif wiki answer": "18 years(0.6704)", "verif concept answer": "18 years(0.6525)", "verif image answer": "9 years(0.6535)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011398.jpg"}, {"question": "where would you purchase office furniture like this", "gt answer": "ikea(1.00)<br/>furniture store(0.60)<br/>store(0.60)", "pred answer": "online", "question_id": 1305185, "best approach": "concept", "verif answer": "store", "anno approach": "wiki, concept, image", "verif wiki answer": "hardware store(0.6255)", "verif concept answer": "store(0.6278)", "verif image answer": "hardware store(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130518.jpg"}, {"question": "what kind of credit card if this", "gt answer": "mastercard(1.00)", "pred answer": "purse", "question_id": 2687335, "best approach": "", "verif answer": "polo", "anno approach": "wiki, concept, image", "verif wiki answer": "polo(0.5001)", "verif concept answer": "mint(0.5009)", "verif image answer": "polo(0.5043)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268733.jpg"}, {"question": "what kind of bushes are on the other side of the fence", "gt answer": "shrub(1.00)<br/>hedge(0.60)", "pred answer": "fern", "question_id": 3797775, "best approach": "concept, image", "verif answer": "hedge", "anno approach": "wiki, concept, image", "verif wiki answer": "lavender(0.6923)", "verif concept answer": "hedge(0.7029)", "verif image answer": "hedge(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379777.jpg"}, {"question": "what are these kids learning", "gt answer": "read(0.60)<br/>alphabet(1.00)", "pred answer": "fetch", "question_id": 4592095, "best approach": "wiki", "verif answer": "cut cake", "anno approach": "wiki, concept, image", "verif wiki answer": "alphabet(0.7046)", "verif concept answer": "read(0.5769)", "verif image answer": "cut cake(0.7104)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459209.jpg"}, {"question": "what team do these players play for", "gt answer": "yankees(1.00)<br/>white sox(0.60)<br/>indians(0.60)", "pred answer": "cardinal", "question_id": 2839995, "best approach": "wiki, concept, image", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "indians(0.7195)", "verif concept answer": "indians(0.7278)", "verif image answer": "indians(0.5429)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283999.jpg"}, {"question": "what is the brown liquid on this plate", "gt answer": "sauce(1.00)<br/>gravy(0.60)<br/>beef(0.60)", "pred answer": "meat", "question_id": 330345, "best approach": "concept", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "meat(0.7065)", "verif concept answer": "sauce(0.7043)", "verif image answer": "gravy(0.5605)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033034.jpg"}, {"question": "who is the number one ranked male player in the world right now", "gt answer": "rafael nadal(1.00)", "pred answer": "roger federer", "question_id": 1948505, "best approach": "image", "verif answer": "roger federer", "anno approach": "wiki, concept, image", "verif wiki answer": "roger federer(0.7082)", "verif concept answer": "roger federer(0.6887)", "verif image answer": "rafael nadal(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194850.jpg"}, {"question": "can this room be rented to hold meetings in or is it free", "gt answer": "rented(1.00)<br/>free(0.60)", "pred answer": "business", "question_id": 3117065, "best approach": "", "verif answer": "unsafe", "anno approach": "wiki, concept, image", "verif wiki answer": "owned(0.7224)", "verif concept answer": "captivity(0.6952)", "verif image answer": "owned(0.5780)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311706.jpg"}, {"question": "what website is the user on", "gt answer": "flickr(1.00)", "pred answer": "picture", "question_id": 116945, "best approach": "wiki", "verif answer": "target", "anno approach": "wiki, concept, image", "verif wiki answer": "flickr(0.6126)", "verif concept answer": "target(0.7220)", "verif image answer": "overnite(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011694.jpg"}, {"question": "why are there bags sitting at the base of the sign", "gt answer": "weight(1.00)", "pred answer": "storage", "question_id": 991805, "best approach": "image", "verif answer": "sidewalk", "anno approach": "wiki, concept, image", "verif wiki answer": "poor(0.5551)", "verif concept answer": "balance(0.5192)", "verif image answer": "weight(0.5310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099180.jpg"}, {"question": "what are the name of the ceo of the company that made this product", "gt answer": "frans van houten(1.00)", "pred answer": "nokia", "question_id": 2476315, "best approach": "wiki, image", "verif answer": "toshiba", "anno approach": "wiki, concept, image", "verif wiki answer": "frans van houten(0.6629)", "verif concept answer": "toshiba(0.5491)", "verif image answer": "frans van houten(0.7019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247631.jpg"}, {"question": "what does this fly through", "gt answer": "sky(1.00)<br/>air(0.60)<br/>storm(0.60)", "pred answer": "runway", "question_id": 2467965, "best approach": "wiki, image", "verif answer": "air", "anno approach": "wiki, concept, image", "verif wiki answer": "sky(0.6553)", "verif concept answer": "storm(0.7080)", "verif image answer": "sky(0.7020)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246796.jpg"}, {"question": "what does those papers mean", "gt answer": "receipt(1.00)<br/>work(0.60)", "pred answer": "stop", "question_id": 2200625, "best approach": "", "verif answer": "study", "anno approach": "wiki, concept, image", "verif wiki answer": "study(0.5000)", "verif concept answer": "study(0.5000)", "verif image answer": "business(0.5010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220062.jpg"}, {"question": "what type of skiing are the people participating in", "gt answer": "downhill(1.00)<br/>ski(0.60)", "pred answer": "cross country", "question_id": 3839185, "best approach": "wiki, concept", "verif answer": "downhill", "anno approach": "wiki, concept, image", "verif wiki answer": "downhill(0.6918)", "verif concept answer": "downhill(0.6945)", "verif image answer": "olympics(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383918.jpg"}, {"question": "is this place more often where someone brushes their teeth or relaxes", "gt answer": "relax(1.00)", "pred answer": "clean", "question_id": 3258335, "best approach": "", "verif answer": "watch tv", "anno approach": "wiki, concept, image", "verif wiki answer": "watch tv(0.5403)", "verif concept answer": "watch tv(0.6978)", "verif image answer": "watch tv(0.5037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325833.jpg"}, {"question": "how do you win the game that these guys play", "gt answer": "more run(1.00)", "pred answer": "sponsor", "question_id": 1363945, "best approach": "", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "baseball(0.6130)", "verif concept answer": "baseball(0.6224)", "verif image answer": "very fast(0.6753)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136394.jpg"}, {"question": "what does the woman 's outfit imply", "gt answer": "military(1.00)<br/>army(0.60)", "pred answer": "collar", "question_id": 2154625, "best approach": "image", "verif answer": "military", "anno approach": "wiki, concept, image", "verif wiki answer": "marine(0.5002)", "verif concept answer": "marine(0.5005)", "verif image answer": "military(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215462.jpg"}, {"question": "what do these animals usually do after drinking a lot", "gt answer": "pee(1.00)", "pred answer": "drink", "question_id": 3147145, "best approach": "", "verif answer": "pee", "anno approach": "wiki, concept, image", "verif wiki answer": "wash(0.6389)", "verif concept answer": "wash(0.6835)", "verif image answer": "wash(0.6255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314714.jpg"}, {"question": "what place is shown", "gt answer": "bar(1.00)", "pred answer": "cafe", "question_id": 4417145, "best approach": "", "verif answer": "cafe", "anno approach": "wiki, concept, image", "verif wiki answer": "men bathroom(0.5255)", "verif concept answer": "diner(0.5828)", "verif image answer": "cafe(0.7151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441714.jpg"}, {"question": "why is this person happy", "gt answer": "win(1.00)", "pred answer": "ski", "question_id": 921705, "best approach": "", "verif answer": "freeze", "anno approach": "wiki, concept, image", "verif wiki answer": "freeze(0.5233)", "verif concept answer": "freeze(0.5090)", "verif image answer": "accident(0.5873)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092170.jpg"}, {"question": "why might there be multiple of these items", "gt answer": "multiple people(1.00)<br/>family(0.60)<br/>people(0.60)", "pred answer": "brush teeth", "question_id": 5137445, "best approach": "wiki, concept", "verif answer": "children", "anno approach": "wiki, concept, image", "verif wiki answer": "multiple people(0.5169)", "verif concept answer": "multiple people(0.5016)", "verif image answer": "children(0.5045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513744.jpg"}, {"question": "what does this train car usually carry", "gt answer": "fuel(1.00)<br/>oil(0.60)<br/>gas(0.60)", "pred answer": "passenger", "question_id": 2744135, "best approach": "wiki, concept", "verif answer": "oil", "anno approach": "wiki, concept, image", "verif wiki answer": "gas(0.5254)", "verif concept answer": "gas(0.6397)", "verif image answer": "engine(0.6128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274413.jpg"}, {"question": "what breed of dog is this", "gt answer": "pug(1.00)", "pred answer": "chihuahua", "question_id": 1762985, "best approach": "wiki, concept, image", "verif answer": "pug", "anno approach": "wiki, concept, image", "verif wiki answer": "pug(0.7134)", "verif concept answer": "pug(0.5800)", "verif image answer": "pug(0.6197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176298.jpg"}, {"question": "is that a pc or mac", "gt answer": "mac(1.00)", "pred answer": "pc", "question_id": 2148005, "best approach": "", "verif answer": "pc", "anno approach": "wiki, concept, image", "verif wiki answer": "ios(0.7277)", "verif concept answer": "ios(0.7222)", "verif image answer": "dell(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214800.jpg"}, {"question": "what do you call the things on the feet of these men", "gt answer": "snowshoe(1.00)<br/>ski(1.00)", "pred answer": "snowboard", "question_id": 1574245, "best approach": "", "verif answer": "snowboard", "anno approach": "wiki, concept, image", "verif wiki answer": "snowboard(0.6100)", "verif concept answer": "snowboard(0.5003)", "verif image answer": "snowboard(0.5007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157424.jpg"}, {"question": "why does the bus need to have it 's lights on", "gt answer": "fog(1.00)<br/>foggy(1.00)", "pred answer": "rain", "question_id": 5513275, "best approach": "image", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "storm(0.6485)", "verif concept answer": "storm(0.6180)", "verif image answer": "fog(0.7034)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000551327.jpg"}, {"question": "where was her helmet manufactured", "gt answer": "china(1.00)<br/>america(0.60)<br/>england(0.60)", "pred answer": "japan", "question_id": 1148435, "best approach": "concept, image", "verif answer": "japan", "anno approach": "wiki, concept, image", "verif wiki answer": "france(0.6207)", "verif concept answer": "england(0.6520)", "verif image answer": "america(0.7003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114843.jpg"}, {"question": "what is the brand of the red plastic cup", "gt answer": "dixie(1.00)", "pred answer": "heinz", "question_id": 5218995, "best approach": "", "verif answer": "heinz", "anno approach": "wiki, concept, image", "verif wiki answer": "nestea(0.7301)", "verif concept answer": "nestea(0.7241)", "verif image answer": "kraft(0.6059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521899.jpg"}, {"question": "is this a slope or back country", "gt answer": "slope(1.00)", "pred answer": "mountain", "question_id": 3676395, "best approach": "image", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "mountain(0.5003)", "verif concept answer": "mountain(0.5247)", "verif image answer": "slope(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367639.jpg"}, {"question": "what is the name of the profession of the person manning the object centered in the photo", "gt answer": "gondolier(1.00)<br/>captain(0.60)", "pred answer": "sail", "question_id": 673205, "best approach": "image", "verif answer": "farmer", "anno approach": "wiki, concept, image", "verif wiki answer": "captain(0.7294)", "verif concept answer": "captain(0.7262)", "verif image answer": "gondolier(0.6758)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067320.jpg"}, {"question": "how does this animal clean itself", "gt answer": "lick(1.00)", "pred answer": "brush", "question_id": 3066775, "best approach": "concept", "verif answer": "clean", "anno approach": "wiki, concept, image", "verif wiki answer": "clean(0.7248)", "verif concept answer": "lick(0.6886)", "verif image answer": "heterochromia(0.6499)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306677.jpg"}, {"question": "what a ethniticity would this food fall under", "gt answer": "asian(1.00)<br/>thai(0.60)<br/>italian(0.60)", "pred answer": "calcium", "question_id": 4073135, "best approach": "concept", "verif answer": "thai", "anno approach": "wiki, concept, image", "verif wiki answer": "japanese(0.5038)", "verif concept answer": "asian(0.5163)", "verif image answer": "italian(0.6990)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407313.jpg"}, {"question": "who is the armored car picking up from", "gt answer": "bank(1.00)<br/>jail(0.60)", "pred answer": "cowboy", "question_id": 1918735, "best approach": "wiki, concept, image", "verif answer": "bank", "anno approach": "wiki, concept, image", "verif wiki answer": "bank(0.5610)", "verif concept answer": "bank(0.6186)", "verif image answer": "bank(0.5234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191873.jpg"}, {"question": "what is the purpose of the cart", "gt answer": "carry bag(1.00)<br/>move luggage(0.60)", "pred answer": "travel", "question_id": 2620995, "best approach": "wiki", "verif answer": "decoration", "anno approach": "wiki, concept, image", "verif wiki answer": "move luggage(0.5848)", "verif concept answer": "decoration(0.6379)", "verif image answer": "decoration(0.5081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262099.jpg"}, {"question": "when was the item being pulled by the man in this photo invented", "gt answer": "suitcase(1.00)<br/>1970(0.60)<br/>1940(0.60)", "pred answer": "1950", "question_id": 2278255, "best approach": "concept, image", "verif answer": "1950", "anno approach": "wiki, concept, image", "verif wiki answer": "1950(0.6273)", "verif concept answer": "1940(0.6768)", "verif image answer": "1940(0.6264)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000227825.jpg"}, {"question": "what kind of trains are those", "gt answer": "freight(1.00)<br/>caboose(0.60)", "pred answer": "commuter", "question_id": 2219165, "best approach": "wiki, concept, image", "verif answer": "commuter", "anno approach": "wiki, concept, image", "verif wiki answer": "freight(0.7111)", "verif concept answer": "freight(0.6985)", "verif image answer": "freight(0.7136)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221916.jpg"}, {"question": "what style of chair is the cat laying in", "gt answer": "wicker(1.00)<br/>rattan(0.60)", "pred answer": "bowl", "question_id": 3399875, "best approach": "wiki, concept", "verif answer": "basket", "anno approach": "wiki, concept, image", "verif wiki answer": "wicker(0.5666)", "verif concept answer": "wicker(0.6388)", "verif image answer": "straw(0.7167)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000339987.jpg"}, {"question": "what genre music is attributed to these items", "gt answer": "country(1.00)", "pred answer": "piano", "question_id": 4058735, "best approach": "", "verif answer": "bicycle built for 2", "anno approach": "wiki, concept, image", "verif wiki answer": "bicycle built for 2(0.5358)", "verif concept answer": "bicycle built for 2(0.5329)", "verif image answer": "bicycle built for 2(0.5465)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405873.jpg"}, {"question": "if there were more of these walking together they would be called what", "gt answer": "herd(1.00)<br/>parade(0.60)", "pred answer": "elephant", "question_id": 3980515, "best approach": "image", "verif answer": "elephant", "anno approach": "wiki, concept, image", "verif wiki answer": "pack(0.5806)", "verif concept answer": "elephant(0.6603)", "verif image answer": "parade(0.6321)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398051.jpg"}, {"question": "what company owns this plane", "gt answer": "continental(1.00)<br/>virgin(0.60)<br/>boeing(0.60)", "pred answer": "american", "question_id": 1498345, "best approach": "image", "verif answer": "american airline", "anno approach": "wiki, concept, image", "verif wiki answer": "american airline(0.7223)", "verif concept answer": "american airline(0.6881)", "verif image answer": "virgin(0.6953)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149834.jpg"}, {"question": "can you guess the zoo name shown in this picture where this giraffee is standing", "gt answer": "bronx(1.00)", "pred answer": "zoo", "question_id": 2918545, "best approach": "wiki, concept", "verif answer": "wooden", "anno approach": "wiki, concept, image", "verif wiki answer": "bronx(0.6383)", "verif concept answer": "bronx(0.5966)", "verif image answer": "base(0.7041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291854.jpg"}, {"question": "what is the largest one of these natural occurances ever recorded", "gt answer": "50 feet(0.60)<br/>pacific(0.60)<br/>wave(1.00)<br/>100 feet(0.60)", "pred answer": "sky", "question_id": 5373455, "best approach": "wiki", "verif answer": "100 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "wave(0.5527)", "verif concept answer": "50 feet(0.6200)", "verif image answer": "100 feet(0.7198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537345.jpg"}, {"question": "what year was this photo taken", "gt answer": "1930(1.00)<br/>1940s(0.60)<br/>1955(0.60)", "pred answer": "1950", "question_id": 499775, "best approach": "wiki, concept", "verif answer": "1930", "anno approach": "wiki, concept, image", "verif wiki answer": "1930(0.6709)", "verif concept answer": "1930(0.6806)", "verif image answer": "1950s(0.6890)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049977.jpg"}, {"question": "what race is this", "gt answer": "bike(1.00)<br/>cycling(0.60)", "pred answer": "dirt bike", "question_id": 5399775, "best approach": "concept", "verif answer": "motorcycle", "anno approach": "wiki, concept, image", "verif wiki answer": "bicycle(0.6870)", "verif concept answer": "bike(0.6320)", "verif image answer": "motorcycle(0.7189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539977.jpg"}, {"question": "what is the season", "gt answer": "fall(1.00)<br/>spring(1.00)", "pred answer": "summer", "question_id": 2343525, "best approach": "wiki, concept", "verif answer": "summer", "anno approach": "wiki, concept, image", "verif wiki answer": "fall(0.7131)", "verif concept answer": "fall(0.7016)", "verif image answer": "summer(0.5393)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000234352.jpg"}, {"question": "can you guess where these type of urinals are seen", "gt answer": "bar(0.60)<br/>men bathroom(1.00)<br/>public(0.60)", "pred answer": "toilet", "question_id": 5413015, "best approach": "wiki, image", "verif answer": "school", "anno approach": "wiki, concept, image", "verif wiki answer": "public(0.6373)", "verif concept answer": "restaurant(0.6698)", "verif image answer": "public(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541301.jpg"}, {"question": "what is the horse hook to", "gt answer": "plow(1.00)<br/>carriage(0.60)<br/>cart(0.60)", "pred answer": "car", "question_id": 1958375, "best approach": "wiki, concept, image", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "plow(0.7060)", "verif concept answer": "plow(0.7229)", "verif image answer": "plow(0.7031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195837.jpg"}, {"question": "who is the sponsor of this event", "gt answer": "mercedes benz(1.00)<br/>mercedes(1.00)", "pred answer": "polo", "question_id": 4736165, "best approach": "wiki, concept, image", "verif answer": "lexus", "anno approach": "wiki, concept, image", "verif wiki answer": "mercedes benz(0.7130)", "verif concept answer": "mercedes benz(0.6955)", "verif image answer": "mercedes benz(0.6461)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473616.jpg"}, {"question": "what do the colors on the boards represent", "gt answer": "country(1.00)<br/>flag(0.60)<br/>usa(0.60)", "pred answer": "paint", "question_id": 1531425, "best approach": "wiki, image", "verif answer": "usa", "anno approach": "wiki, concept, image", "verif wiki answer": "usa(0.6762)", "verif concept answer": "germany(0.6442)", "verif image answer": "flag(0.6749)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153142.jpg"}, {"question": "what is a common condiment for the side dish", "gt answer": "ketchup(1.00)", "pred answer": "onion", "question_id": 1438625, "best approach": "wiki, concept", "verif answer": "onion", "anno approach": "wiki, concept, image", "verif wiki answer": "ketchup(0.7048)", "verif concept answer": "ketchup(0.7019)", "verif image answer": "mustard and ketchup(0.6179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143862.jpg"}, {"question": "what is this skateboarding trick called", "gt answer": "kickflip(1.00)<br/>jump(0.60)<br/>grind(0.60)", "pred answer": "ollie", "question_id": 5254675, "best approach": "wiki, concept", "verif answer": "ollie", "anno approach": "wiki, concept, image", "verif wiki answer": "kickflip(0.7239)", "verif concept answer": "kickflip(0.7033)", "verif image answer": "grind(0.7133)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525467.jpg"}, {"question": "", "gt answer": "25 year old(0.60)", "pred answer": "grandma", "question_id": 1061005, "best approach": "wiki, concept, image", "verif answer": "0", "anno approach": "wiki, concept, image", "verif wiki answer": "25 year old(0.5672)", "verif concept answer": "25 year old(0.6008)", "verif image answer": "25 year old(0.5225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106100.jpg"}, {"question": "where is the sun in this picture", "gt answer": "behind mountain(1.00)", "pred answer": "behind", "question_id": 1414825, "best approach": "wiki, concept, image", "verif answer": "behind", "anno approach": "wiki, concept, image", "verif wiki answer": "behind mountain(0.7253)", "verif concept answer": "behind mountain(0.6859)", "verif image answer": "behind mountain(0.7031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000141482.jpg"}, {"question": "what evidence do we see here of a desire to make use of natural energy", "gt answer": "windmill(1.00)<br/>wind turbine(0.60)<br/>jet fuel(0.60)", "pred answer": "electricity", "question_id": 5254095, "best approach": "wiki, concept, image", "verif answer": "jet fuel", "anno approach": "wiki, concept, image", "verif wiki answer": "wind turbine(0.6426)", "verif concept answer": "wind turbine(0.5975)", "verif image answer": "wind turbine(0.6116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525409.jpg"}, {"question": "what kind of bed is pictured", "gt answer": "twin(1.00)", "pred answer": "bunk", "question_id": 2790895, "best approach": "", "verif answer": "single", "anno approach": "wiki, concept, image", "verif wiki answer": "single(0.7067)", "verif concept answer": "single(0.6643)", "verif image answer": "double(0.6845)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000279089.jpg"}, {"question": "what breed of tree is growing outside the window", "gt answer": "willow(1.00)<br/>oak(0.60)<br/>pine(0.60)", "pred answer": "maple", "question_id": 1122285, "best approach": "wiki, concept, image", "verif answer": "pine", "anno approach": "wiki, concept, image", "verif wiki answer": "oak(0.7195)", "verif concept answer": "oak(0.7093)", "verif image answer": "oak(0.6938)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000112228.jpg"}, {"question": "what do you call the yellow parts", "gt answer": "yolk(1.00)", "pred answer": "egg", "question_id": 1461285, "best approach": "concept", "verif answer": "noodle", "anno approach": "wiki, concept, image", "verif wiki answer": "chicago(0.5197)", "verif concept answer": "yolk(0.5498)", "verif image answer": "chicago(0.7275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146128.jpg"}, {"question": "how are those items cooked", "gt answer": "baked(1.00)<br/>bake in oven(0.60)<br/>1(0.60)", "pred answer": "oven", "question_id": 2218565, "best approach": "concept, image", "verif answer": "grilled", "anno approach": "wiki, concept, image", "verif wiki answer": "1(0.6510)", "verif concept answer": "baked(0.6632)", "verif image answer": "baked(0.6764)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221856.jpg"}, {"question": "what does the boy appear to be at", "gt answer": "krispy kreme(1.00)<br/>bakery(0.60)", "pred answer": "home", "question_id": 2931425, "best approach": "wiki, concept, image", "verif answer": "walmart", "anno approach": "wiki, concept, image", "verif wiki answer": "bakery(0.6239)", "verif concept answer": "bakery(0.6520)", "verif image answer": "bakery(0.6608)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293142.jpg"}, {"question": "what kind of meat is used on these tacos", "gt answer": "pork(1.00)<br/>beef(0.60)", "pred answer": "steak", "question_id": 562665, "best approach": "wiki, concept", "verif answer": "chicken", "anno approach": "wiki, concept, image", "verif wiki answer": "pork(0.6725)", "verif concept answer": "pork(0.6412)", "verif image answer": "chicken(0.6306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000056266.jpg"}, {"question": "what world describes the men 's attire", "gt answer": "dress(1.00)<br/>suit(1.00)<br/>business(0.60)", "pred answer": "asia", "question_id": 202535, "best approach": "", "verif answer": "business", "anno approach": "wiki, concept, image", "verif wiki answer": "tie(0.6523)", "verif concept answer": "tie(0.6600)", "verif image answer": "tie(0.5763)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020253.jpg"}, {"question": "what is the name of the teams playing in this soccer game", "gt answer": "athens fc(1.00)", "pred answer": "soccer", "question_id": 4150675, "best approach": "wiki, image", "verif answer": "soccer", "anno approach": "wiki, concept, image", "verif wiki answer": "athens fc(0.5193)", "verif concept answer": "soccer(0.5356)", "verif image answer": "athens fc(0.5030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415067.jpg"}, {"question": "who uses this mode of transportation", "gt answer": "travel(1.00)<br/>people(0.60)", "pred answer": "human", "question_id": 5297885, "best approach": "wiki, concept, image", "verif answer": "human", "anno approach": "wiki, concept, image", "verif wiki answer": "travel(0.5798)", "verif concept answer": "travel(0.6114)", "verif image answer": "travel(0.7165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529788.jpg"}, {"question": "what vitamin might this vegetable be a good source of", "gt answer": "vitamin(1.00)<br/>vitamin c(1.00)<br/>(0.60)", "pred answer": "c", "question_id": 5295115, "best approach": "wiki, concept, image", "verif answer": "vitamin c", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin(0.6950)", "verif concept answer": "vitamin(0.6731)", "verif image answer": "vitamin c(0.6914)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529511.jpg"}, {"question": "when this falling matter makes it impossible to see then that condition is called a what out", "gt answer": "white(1.00)<br/>wipe(0.60)", "pred answer": "snow", "question_id": 5507875, "best approach": "concept", "verif answer": "white", "anno approach": "wiki, concept, image", "verif wiki answer": "red(0.6063)", "verif concept answer": "white(0.5971)", "verif image answer": "brighten(0.6745)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550787.jpg"}, {"question": "is the material tweed or canvas", "gt answer": "canvas(1.00)", "pred answer": "plastic", "question_id": 394705, "best approach": "concept", "verif answer": "paper", "anno approach": "wiki, concept, image", "verif wiki answer": "knife(0.7223)", "verif concept answer": "canvas(0.7205)", "verif image answer": "paper(0.5119)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039470.jpg"}, {"question": "what kind of fries are shown", "gt answer": "waffle(1.00)", "pred answer": "curly", "question_id": 2566645, "best approach": "", "verif answer": "curly", "anno approach": "wiki, concept, image", "verif wiki answer": "curly(0.7012)", "verif concept answer": "curly(0.7143)", "verif image answer": "curly(0.7140)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256664.jpg"}, {"question": "what is the name of the purple vegetable on the pizza", "gt answer": "onion(1.00)", "pred answer": "tomato", "question_id": 2019195, "best approach": "", "verif answer": "pepper", "anno approach": "wiki, concept, image", "verif wiki answer": "ketchup(0.7300)", "verif concept answer": "ketchup(0.7182)", "verif image answer": "ketchup(0.6874)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201919.jpg"}, {"question": "what was the wind speed at the time this photo was taken", "gt answer": "30mph(1.00)<br/>very high(0.60)<br/>25 mph(0.60)", "pred answer": "20 mph", "question_id": 2345695, "best approach": "wiki, concept", "verif answer": "20 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "30mph(0.7230)", "verif concept answer": "30mph(0.6856)", "verif image answer": "20 mph(0.6331)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000234569.jpg"}, {"question": "what trick is the skateboarder doing", "gt answer": "jump(1.00)<br/>olly(0.60)", "pred answer": "ollie", "question_id": 5540705, "best approach": "wiki, concept, image", "verif answer": "ollie", "anno approach": "wiki, concept, image", "verif wiki answer": "olly(0.7181)", "verif concept answer": "olly(0.7048)", "verif image answer": "olly(0.7184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554070.jpg"}, {"question": "what type of ticket will you need to board", "gt answer": "plane(1.00)<br/>board(0.60)", "pred answer": "online", "question_id": 1557515, "best approach": "wiki, concept", "verif answer": "luggage", "anno approach": "wiki, concept, image", "verif wiki answer": "plane(0.6663)", "verif concept answer": "plane(0.6637)", "verif image answer": "water(0.5904)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155751.jpg"}, {"question": "what type of exercise is the woman doing", "gt answer": "walk(1.00)", "pred answer": "bike", "question_id": 681635, "best approach": "wiki", "verif answer": "ride", "anno approach": "wiki, concept, image", "verif wiki answer": "walk(0.6124)", "verif concept answer": "smile(0.6719)", "verif image answer": "shop(0.6491)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068163.jpg"}, {"question": "what is he most probable relation between these two people", "gt answer": "mother and son(1.00)", "pred answer": "sibling", "question_id": 2871195, "best approach": "wiki, image", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "mother and son(0.6763)", "verif concept answer": "friend(0.6549)", "verif image answer": "mother and son(0.7141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287119.jpg"}, {"question": "what event are these girls attending", "gt answer": "concert(1.00)<br/>party(0.60)<br/>soccer(0.60)", "pred answer": "mardi gras", "question_id": 1747735, "best approach": "image", "verif answer": "concert", "anno approach": "wiki, concept, image", "verif wiki answer": "festival(0.6587)", "verif concept answer": "festival(0.6659)", "verif image answer": "concert(0.6590)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174773.jpg"}, {"question": "what type of profession is this", "gt answer": "photographer(1.00)<br/>photography(0.60)", "pred answer": "politic", "question_id": 426985, "best approach": "wiki, concept", "verif answer": "photographer", "anno approach": "wiki, concept, image", "verif wiki answer": "photographer(0.6985)", "verif concept answer": "photographer(0.6337)", "verif image answer": "watch(0.6592)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042698.jpg"}, {"question": "who owns these kinds of animals", "gt answer": "farmer(1.00)", "pred answer": "shepherd", "question_id": 662995, "best approach": "wiki, concept, image", "verif answer": "sheep herder", "anno approach": "wiki, concept, image", "verif wiki answer": "farmer(0.6627)", "verif concept answer": "farmer(0.6648)", "verif image answer": "farmer(0.5719)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000066299.jpg"}, {"question": "can you guess which metal is used for making the ring weared by the lady", "gt answer": "gold(1.00)<br/>silver(0.60)", "pred answer": "aluminum", "question_id": 798835, "best approach": "wiki, concept", "verif answer": "gold", "anno approach": "wiki, concept, image", "verif wiki answer": "gold(0.7150)", "verif concept answer": "gold(0.6753)", "verif image answer": "silver(0.6253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079883.jpg"}, {"question": "can a normal person operate this or is it for professionals", "gt answer": "profession(1.00)<br/>professional(0.60)", "pred answer": "manual", "question_id": 4814645, "best approach": "concept, image", "verif answer": "professional", "anno approach": "wiki, concept, image", "verif wiki answer": "cook(0.6788)", "verif concept answer": "professional(0.6062)", "verif image answer": "professional(0.6509)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481464.jpg"}, {"question": "in photography terms what type of photo is being taken by the man", "gt answer": "action(1.00)<br/>candid(0.60)", "pred answer": "selfie", "question_id": 1623965, "best approach": "wiki", "verif answer": "selfie", "anno approach": "wiki, concept, image", "verif wiki answer": "candid(0.6209)", "verif concept answer": "selfie(0.6117)", "verif image answer": "selfie(0.7056)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162396.jpg"}, {"question": "what is the name of this man 's profession", "gt answer": "shepherd(1.00)<br/>farmer(0.60)", "pred answer": "soldier", "question_id": 3093145, "best approach": "", "verif answer": "sheep herder", "anno approach": "wiki, concept, image", "verif wiki answer": "sheep herder(0.6535)", "verif concept answer": "sheep herder(0.7028)", "verif image answer": "sheep herder(0.6556)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000309314.jpg"}, {"question": "what is the name of the phenomenom that is destroying the habitat of this animal", "gt answer": "global warm(1.00)<br/>climate change(0.60)", "pred answer": "bear", "question_id": 4754655, "best approach": "concept", "verif answer": "shark", "anno approach": "wiki, concept, image", "verif wiki answer": "shark(0.5843)", "verif concept answer": "global warm(0.5665)", "verif image answer": "bee(0.6843)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475465.jpg"}, {"question": "what was inside that round object", "gt answer": "air(1.00)<br/>helium(0.60)", "pred answer": "balloon", "question_id": 2050865, "best approach": "wiki, concept", "verif answer": "helium", "anno approach": "wiki, concept, image", "verif wiki answer": "helium(0.5671)", "verif concept answer": "helium(0.7036)", "verif image answer": "aerodynamic(0.5053)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205086.jpg"}, {"question": "what type of wine is in the glass", "gt answer": "red wine(1.00)<br/>red(1.00)", "pred answer": "rose", "question_id": 4005715, "best approach": "", "verif answer": "red wine", "anno approach": "wiki, concept, image", "verif wiki answer": "raspberry(0.6718)", "verif concept answer": "raspberry(0.7109)", "verif image answer": "dark(0.7211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400571.jpg"}, {"question": "how hard would it be for the motorcyle to navigate through the city", "gt answer": "easy(1.00)<br/>not at all(0.60)", "pred answer": "fast", "question_id": 3920605, "best approach": "wiki, concept", "verif answer": "easy", "anno approach": "wiki, concept, image", "verif wiki answer": "easy(0.6488)", "verif concept answer": "easy(0.6596)", "verif image answer": "quiet(0.6123)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392060.jpg"}, {"question": "what is the name of the platform to the left and in front of the person in the picture", "gt answer": "counter(1.00)<br/>grill(0.60)<br/>bar(0.60)", "pred answer": "table", "question_id": 2326705, "best approach": "wiki, concept, image", "verif answer": "table", "anno approach": "wiki, concept, image", "verif wiki answer": "bar(0.7198)", "verif concept answer": "bar(0.6942)", "verif image answer": "bar(0.5143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232670.jpg"}, {"question": "what opbect is used to protect the eyes which doing water activities at this location", "gt answer": "goggle(1.00)<br/>sunglasses(0.60)", "pred answer": "sunscreen", "question_id": 2476045, "best approach": "wiki, concept, image", "verif answer": "sunglasses", "anno approach": "wiki, concept, image", "verif wiki answer": "sunglasses(0.7284)", "verif concept answer": "sunglasses(0.6442)", "verif image answer": "sunglasses(0.7027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247604.jpg"}, {"question": "where do all those donations go", "gt answer": "goodwill(1.00)<br/>poor(0.60)", "pred answer": "amazon", "question_id": 4945485, "best approach": "wiki, concept", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "goodwill(0.6926)", "verif concept answer": "goodwill(0.6535)", "verif image answer": "mexico(0.5427)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494548.jpg"}, {"question": "this character is from what popular kids movie", "gt answer": "despicable me(1.00)", "pred answer": "winnie pooh", "question_id": 3337395, "best approach": "wiki", "verif answer": "garfield", "anno approach": "wiki, concept, image", "verif wiki answer": "despicable me(0.7186)", "verif concept answer": "gandalf(0.5348)", "verif image answer": "orange(0.6196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333739.jpg"}, {"question": "what is the glowing white object used for", "gt answer": "move cursor(1.00)<br/>mouse(0.60)<br/>work(0.60)", "pred answer": "music", "question_id": 548925, "best approach": "concept", "verif answer": "computer", "anno approach": "wiki, concept, image", "verif wiki answer": "work(0.5667)", "verif concept answer": "move cursor(0.6348)", "verif image answer": "computer(0.6415)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054892.jpg"}, {"question": "what food do these animals eat", "gt answer": "bread(1.00)<br/>popcorn(0.60)", "pred answer": "meat", "question_id": 5600375, "best approach": "concept", "verif answer": "cake", "anno approach": "wiki, concept, image", "verif wiki answer": "banana bread(0.6838)", "verif concept answer": "popcorn(0.7038)", "verif image answer": "pie(0.5660)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560037.jpg"}, {"question": "what breed of cat is this", "gt answer": "bombay(1.00)<br/>domestic shorthair(0.60)<br/>domestic(0.60)", "pred answer": "siamese", "question_id": 679065, "best approach": "wiki", "verif answer": "domestic shorthair", "anno approach": "wiki, concept, image", "verif wiki answer": "bombay(0.6665)", "verif concept answer": "domestic shorthair(0.7088)", "verif image answer": "domestic shorthair(0.6773)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067906.jpg"}, {"question": "what type of device does this remote control", "gt answer": "roku(1.00)<br/>dvd(0.60)<br/>manual(0.60)", "pred answer": "television", "question_id": 3632475, "best approach": "concept, image", "verif answer": "phone", "anno approach": "wiki, concept, image", "verif wiki answer": "phone(0.7152)", "verif concept answer": "dvd(0.7128)", "verif image answer": "dvd(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363247.jpg"}, {"question": "what state does this team play for", "gt answer": "indiana(1.00)<br/>texas(0.60)", "pred answer": "ohio", "question_id": 3068245, "best approach": "", "verif answer": "ohio", "anno approach": "wiki, concept, image", "verif wiki answer": "washington(0.7079)", "verif concept answer": "idaho(0.7146)", "verif image answer": "washington(0.7121)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306824.jpg"}, {"question": "how many speeds does this motorcycle have", "gt answer": "5(1.00)<br/>2(1.00)<br/>4(0.60)", "pred answer": "100", "question_id": 5802865, "best approach": "image", "verif answer": "3", "anno approach": "wiki, concept, image", "verif wiki answer": "6(0.7089)", "verif concept answer": "3(0.6591)", "verif image answer": "4(0.6572)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580286.jpg"}, {"question": "where can you buy this skiing accessory", "gt answer": "sport store(1.00)<br/>colorado(0.60)", "pred answer": "store", "question_id": 4773435, "best approach": "", "verif answer": "aspen", "anno approach": "wiki, concept, image", "verif wiki answer": "vail(0.6148)", "verif concept answer": "vail(0.6949)", "verif image answer": "vail(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477343.jpg"}, {"question": "this trick is called what", "gt answer": "kick flip(1.00)<br/>ollie(0.60)<br/>180(0.60)<br/>flip(0.60)", "pred answer": "skateboard", "question_id": 4262545, "best approach": "", "verif answer": "180", "anno approach": "wiki, concept, image", "verif wiki answer": "kickflip(0.7223)", "verif concept answer": "kickflip(0.7233)", "verif image answer": "kickflip(0.7217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426254.jpg"}, {"question": "what famous alcohol does this resemble", "gt answer": "captain morgan(1.00)<br/>wine(0.60)<br/>beer(0.60)<br/>vodka(0.60)", "pred answer": "budweiser", "question_id": 5584245, "best approach": "concept", "verif answer": "beer", "anno approach": "wiki, concept, image", "verif wiki answer": "wine(0.5163)", "verif concept answer": "captain morgan(0.5069)", "verif image answer": "wine(0.5022)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558424.jpg"}, {"question": "what is strange about this cat", "gt answer": "tie(1.00)", "pred answer": "face", "question_id": 1603175, "best approach": "image", "verif answer": "collar", "anno approach": "wiki, concept, image", "verif wiki answer": "collar(0.6839)", "verif concept answer": "collar(0.6487)", "verif image answer": "tie(0.5653)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160317.jpg"}, {"question": "what city is this from", "gt answer": "columbus(1.00)<br/>ohio(0.60)", "pred answer": "new york", "question_id": 1551675, "best approach": "", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "los angeles(0.7000)", "verif concept answer": "los angeles(0.7098)", "verif image answer": "charlottesville(0.6917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155167.jpg"}, {"question": "do the umbrellas work or is this art", "gt answer": "art(1.00)", "pred answer": "artwork", "question_id": 2023725, "best approach": "", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "paint(0.7176)", "verif concept answer": "abstract(0.7094)", "verif image answer": "supply(0.5933)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202372.jpg"}, {"question": "apart from making calls what other form of communication can the keyboards on these devices be used to send", "gt answer": "text(1.00)", "pred answer": "usb", "question_id": 5674075, "best approach": "wiki, image", "verif answer": "text", "anno approach": "wiki, concept, image", "verif wiki answer": "text(0.7128)", "verif concept answer": "camera(0.6762)", "verif image answer": "text(0.6346)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567407.jpg"}, {"question": "what breed of dog is represented", "gt answer": "hound(1.00)<br/>beagle(0.60)<br/>bloodhound(0.60)", "pred answer": "collie", "question_id": 2342075, "best approach": "image", "verif answer": "dachsund", "anno approach": "wiki, concept, image", "verif wiki answer": "dachshund(0.7174)", "verif concept answer": "dachshund(0.7136)", "verif image answer": "beagle(0.7100)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000234207.jpg"}, {"question": "what type of plane is this", "gt answer": "boeing(1.00)", "pred answer": "biplane", "question_id": 5484285, "best approach": "concept", "verif answer": "airbus", "anno approach": "wiki, concept, image", "verif wiki answer": "wright brother(0.6550)", "verif concept answer": "boeing(0.6771)", "verif image answer": "wright brother(0.6856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548428.jpg"}, {"question": "what does this activity do for a person", "gt answer": "clean teeth(1.00)<br/>clean(0.60)", "pred answer": "brush teeth", "question_id": 4827065, "best approach": "wiki, concept", "verif answer": "brush teeth", "anno approach": "wiki, concept, image", "verif wiki answer": "clean teeth(0.7278)", "verif concept answer": "clean teeth(0.7194)", "verif image answer": "brush teeth(0.7115)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482706.jpg"}, {"question": "is this a traction kit or a stunt kite", "gt answer": "stunt kite(1.00)", "pred answer": "parachute", "question_id": 1289775, "best approach": "wiki, concept, image", "verif answer": "amatuer", "anno approach": "wiki, concept, image", "verif wiki answer": "stunt kite(0.5630)", "verif concept answer": "stunt kite(0.7093)", "verif image answer": "stunt kite(0.6340)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128977.jpg"}, {"question": "what is it called when these animals travel from one location to another much further away place", "gt answer": "migrate(1.00)<br/>migration(0.60)", "pred answer": "fly", "question_id": 3653585, "best approach": "wiki", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "migrate(0.6994)", "verif concept answer": "fly(0.6722)", "verif image answer": "migration(0.6761)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365358.jpg"}, {"question": "what is this beverage made with", "gt answer": "hop(1.00)", "pred answer": "beer", "question_id": 3328165, "best approach": "", "verif answer": "plastic", "anno approach": "wiki, concept, image", "verif wiki answer": "flour(0.7048)", "verif concept answer": "flour(0.6961)", "verif image answer": "glass(0.6488)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332816.jpg"}, {"question": "is this closer to a vehicle in the complete franchise of top gun both canon and non canon or closer to a vehicle in the x men franchise both canon and non canon", "gt answer": "top gun(1.00)", "pred answer": "pad", "question_id": 4976225, "best approach": "", "verif answer": "air", "anno approach": "wiki, concept, image", "verif wiki answer": "air(0.6269)", "verif concept answer": "fall(0.6830)", "verif image answer": "fall(0.6833)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497622.jpg"}, {"question": "what is the name of the famous dreamworks animated film where this animal was voiced by chris rock", "gt answer": "madagascar(1.00)", "pred answer": "fruit stripe", "question_id": 2141375, "best approach": "", "verif answer": "toy r us", "anno approach": "wiki, concept, image", "verif wiki answer": "yogi(0.7112)", "verif concept answer": "toy r us(0.5947)", "verif image answer": "yogi(0.7276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214137.jpg"}, {"question": "how old is this little boy", "gt answer": "4(1.00)<br/>3(0.60)<br/>5 years(0.60)<br/>2(0.60)", "pred answer": "6", "question_id": 3739645, "best approach": "wiki", "verif answer": "2", "anno approach": "wiki, concept, image", "verif wiki answer": "4(0.6929)", "verif concept answer": "2(0.6130)", "verif image answer": "5 years(0.6132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373964.jpg"}, {"question": "what company manufactured the yellow bike", "gt answer": "vespa(1.00)<br/>yamaha(0.60)<br/>bmw(0.60)", "pred answer": "honda", "question_id": 903075, "best approach": "concept, image", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "van(0.6881)", "verif concept answer": "vespa(0.7063)", "verif image answer": "vespa(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000090307.jpg"}, {"question": "what body part do you use to do this sport", "gt answer": "feet(1.00)<br/>leg(1.00)<br/>foot(0.60)", "pred answer": "arm", "question_id": 2212935, "best approach": "image", "verif answer": "arm", "anno approach": "wiki, concept, image", "verif wiki answer": "arm(0.7285)", "verif concept answer": "arm(0.7229)", "verif image answer": "foot(0.7168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221293.jpg"}, {"question": "how much weight does the boat shown in the image withstand", "gt answer": "400 lbs(1.00)", "pred answer": "ton", "question_id": 5146285, "best approach": "concept", "verif answer": "500 pounds", "anno approach": "wiki, concept, image", "verif wiki answer": "500 pounds(0.6588)", "verif concept answer": "400 lbs(0.6753)", "verif image answer": "potassium(0.6105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514628.jpg"}, {"question": "putting one shirt stop another is a technique called what", "gt answer": "layer(1.00)", "pred answer": "throw", "question_id": 2631895, "best approach": "wiki", "verif answer": "catch", "anno approach": "wiki, concept, image", "verif wiki answer": "layer(0.7114)", "verif concept answer": "steal(0.6827)", "verif image answer": "steal(0.7023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263189.jpg"}, {"question": "where would you likely need to have supply stations like this one", "gt answer": "office(1.00)<br/>school(0.60)", "pred answer": "dollhouse", "question_id": 20935, "best approach": "", "verif answer": "office", "anno approach": "wiki, concept, image", "verif wiki answer": "desk(0.7036)", "verif concept answer": "cafeteria(0.6678)", "verif image answer": "cafeteria(0.7271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002093.jpg"}, {"question": "how do you think this child is feeling", "gt answer": "tired(1.00)<br/>sleepy(0.60)", "pred answer": "happy", "question_id": 2553925, "best approach": "concept, image", "verif answer": "tired", "anno approach": "wiki, concept, image", "verif wiki answer": "boredom(0.6598)", "verif concept answer": "sleepy(0.7130)", "verif image answer": "sleepy(0.5467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255392.jpg"}, {"question": "why is the tv on the floor", "gt answer": "still in box(1.00)<br/>new(0.60)", "pred answer": "video game", "question_id": 2540075, "best approach": "image", "verif answer": "crt", "anno approach": "wiki, concept, image", "verif wiki answer": "crt(0.7090)", "verif concept answer": "crt(0.7044)", "verif image answer": "new(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000254007.jpg"}, {"question": "since the time is expired on the meter what might the car receive from the police", "gt answer": "ticket(1.00)", "pred answer": "money", "question_id": 578285, "best approach": "", "verif answer": "money", "anno approach": "wiki, concept, image", "verif wiki answer": "pass(0.6735)", "verif concept answer": "pass(0.5881)", "verif image answer": "money(0.5235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000057828.jpg"}, {"question": "what is the name of this style of hot dog", "gt answer": "chicago(1.00)<br/>corndog(0.60)<br/>new york(0.60)", "pred answer": "hotdog", "question_id": 5306705, "best approach": "wiki, concept", "verif answer": "deep dish", "anno approach": "wiki, concept, image", "verif wiki answer": "new york(0.7195)", "verif concept answer": "corndog(0.6986)", "verif image answer": "beef(0.7065)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000530670.jpg"}, {"question": "what type of truck is this", "gt answer": "semi(1.00)", "pred answer": "garbage", "question_id": 1054015, "best approach": "", "verif answer": "semi", "anno approach": "wiki, concept, image", "verif wiki answer": "trailer(0.6868)", "verif concept answer": "industrial(0.6905)", "verif image answer": "industrial(0.6542)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105401.jpg"}, {"question": "what kind of plane is this", "gt answer": "fire fighter plane(1.00)<br/>fire(0.60)", "pred answer": "biplane", "question_id": 4831465, "best approach": "wiki, image", "verif answer": "steel", "anno approach": "wiki, concept, image", "verif wiki answer": "fire fighter plane(0.6767)", "verif concept answer": "fire(0.5908)", "verif image answer": "fire fighter plane(0.5923)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483146.jpg"}, {"question": "is the toilet seat up or down", "gt answer": "down(1.00)", "pred answer": "low", "question_id": 762645, "best approach": "", "verif answer": "downhill", "anno approach": "wiki, concept, image", "verif wiki answer": "downhill(0.6933)", "verif concept answer": "downhill(0.6937)", "verif image answer": "downhill(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076264.jpg"}, {"question": "what is the possible manufacturer of the orange cone", "gt answer": "walmart(1.00)<br/>home depot(0.60)", "pred answer": "van", "question_id": 4868075, "best approach": "concept", "verif answer": "walmart", "anno approach": "wiki, concept, image", "verif wiki answer": "target(0.7150)", "verif concept answer": "home depot(0.6617)", "verif image answer": "target(0.7069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000486807.jpg"}, {"question": "what is the green vegatable on top", "gt answer": "spinach(1.00)<br/>kale(1.00)<br/>basil(0.60)", "pred answer": "lettuce", "question_id": 953975, "best approach": "wiki, concept", "verif answer": "spinach", "anno approach": "wiki, concept, image", "verif wiki answer": "spinach(0.7014)", "verif concept answer": "spinach(0.7029)", "verif image answer": "green(0.5913)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000095397.jpg"}, {"question": "what is happening to this person", "gt answer": "fall(1.00)<br/>fell(0.60)<br/>crash(0.60)", "pred answer": "accident", "question_id": 4571495, "best approach": "image", "verif answer": "fall", "anno approach": "wiki, concept, image", "verif wiki answer": "death(0.7230)", "verif concept answer": "trick(0.6553)", "verif image answer": "fell(0.5171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457149.jpg"}, {"question": "what breed is that dog", "gt answer": "sheep dog(1.00)<br/>border collie(1.00)", "pred answer": "collie", "question_id": 301635, "best approach": "concept, image", "verif answer": "collie", "anno approach": "wiki, concept, image", "verif wiki answer": "sheepdog(0.7004)", "verif concept answer": "sheep dog(0.7264)", "verif image answer": "sheep dog(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030163.jpg"}, {"question": "what is the name of the bus line", "gt answer": "green bus(1.00)", "pred answer": "5 star", "question_id": 4325935, "best approach": "", "verif answer": "5 star", "anno approach": "wiki, concept, image", "verif wiki answer": "5 star(0.6791)", "verif concept answer": "5 star(0.6101)", "verif image answer": "5 star(0.6429)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432593.jpg"}, {"question": "what kinf od bread is the man cutting into", "gt answer": "wheat(1.00)<br/>white(1.00)<br/>whole grain(0.60)", "pred answer": "roast beef", "question_id": 836275, "best approach": "", "verif answer": "banana bread", "anno approach": "wiki, concept, image", "verif wiki answer": "banana bread(0.7093)", "verif concept answer": "banana bread(0.6788)", "verif image answer": "banana bread(0.5727)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083627.jpg"}, {"question": "what happen to the rest of this cake", "gt answer": "eaten(1.00)", "pred answer": "slice", "question_id": 2158475, "best approach": "wiki, image", "verif answer": "dessert", "anno approach": "wiki, concept, image", "verif wiki answer": "eaten(0.7161)", "verif concept answer": "bitten(0.7081)", "verif image answer": "eaten(0.5953)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215847.jpg"}, {"question": "what type of board is that", "gt answer": "surf(1.00)<br/>longboard(0.60)", "pred answer": "surf board", "question_id": 5140735, "best approach": "", "verif answer": "surf", "anno approach": "wiki, concept, image", "verif wiki answer": "shortboard(0.7198)", "verif concept answer": "surfboard(0.7124)", "verif image answer": "shortboard(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514073.jpg"}, {"question": "what topping is on the pizza", "gt answer": "pepperoni(1.00)<br/>hotdog(0.60)", "pred answer": "hot dog", "question_id": 2539065, "best approach": "wiki, image", "verif answer": "hot dog", "anno approach": "wiki, concept, image", "verif wiki answer": "pepperoni(0.7146)", "verif concept answer": "hotdog(0.7166)", "verif image answer": "pepperoni(0.6991)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253906.jpg"}, {"question": "what children 's song talks about this item", "gt answer": "wheel on bus(1.00)", "pred answer": "thomas tank engine", "question_id": 190855, "best approach": "image", "verif answer": "simonds", "anno approach": "wiki, concept, image", "verif wiki answer": "sit(0.7041)", "verif concept answer": "sit(0.6827)", "verif image answer": "wheel on bus(0.7114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019085.jpg"}, {"question": "what can you make with this items", "gt answer": "craft(1.00)", "pred answer": "sew", "question_id": 4927155, "best approach": "wiki", "verif answer": "cut", "anno approach": "wiki, concept, image", "verif wiki answer": "craft(0.6538)", "verif concept answer": "decor(0.6559)", "verif image answer": "decor(0.6168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492715.jpg"}, {"question": "the term multi tasking refers to which two activities seen here", "gt answer": "talk and eat(1.00)", "pred answer": "turn", "question_id": 4262745, "best approach": "wiki, image", "verif answer": "square", "anno approach": "wiki, concept, image", "verif wiki answer": "talk and eat(0.7151)", "verif concept answer": "square(0.6938)", "verif image answer": "talk and eat(0.7217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426274.jpg"}, {"question": "what is needed to take item from this appliance", "gt answer": "oven mitt(1.00)<br/>glove(0.60)", "pred answer": "grill", "question_id": 707805, "best approach": "wiki, concept", "verif answer": "case", "anno approach": "wiki, concept, image", "verif wiki answer": "glove(0.6441)", "verif concept answer": "glove(0.6490)", "verif image answer": "case(0.5765)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070780.jpg"}, {"question": "what is the complimentary color to the rust", "gt answer": "white(1.00)<br/>grey(0.60)", "pred answer": "green", "question_id": 104845, "best approach": "wiki", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "white(0.7123)", "verif concept answer": "green(0.6810)", "verif image answer": "red(0.6464)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000010484.jpg"}, {"question": "which type of building is the bus in front of", "gt answer": "bar(1.00)<br/>brick(0.60)", "pred answer": "apartment", "question_id": 5609105, "best approach": "concept", "verif answer": "apartment", "anno approach": "wiki, concept, image", "verif wiki answer": "apartment(0.7150)", "verif concept answer": "brick(0.7052)", "verif image answer": "kitchen(0.6462)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560910.jpg"}, {"question": "who is the manufacturer of the refrigerator", "gt answer": "whirlpool(1.00)<br/>kenmore(0.60)<br/>refrigerator(0.60)", "pred answer": "ge", "question_id": 967235, "best approach": "concept", "verif answer": "frigidaire", "anno approach": "wiki, concept, image", "verif wiki answer": "refrigerator(0.7146)", "verif concept answer": "whirlpool(0.6933)", "verif image answer": "kenmore(0.6042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096723.jpg"}, {"question": "what type of advertisement which looks like this typically exhibits product names and logos in movies or popular culture", "gt answer": "commercial(1.00)<br/>tv(0.60)", "pred answer": "historical", "question_id": 4808075, "best approach": "", "verif answer": "coca cola", "anno approach": "wiki, concept, image", "verif wiki answer": "coca cola(0.6958)", "verif concept answer": "coca cola(0.7134)", "verif image answer": "coca cola(0.5175)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480807.jpg"}, {"question": "what types of technology are shown in the picture", "gt answer": "computer(1.00)", "pred answer": "laptop", "question_id": 3372775, "best approach": "", "verif answer": "laptop", "anno approach": "wiki, concept, image", "verif wiki answer": "monitor(0.6901)", "verif concept answer": "laptop(0.6898)", "verif image answer": "laptop(0.5899)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337277.jpg"}, {"question": "what is the brand of the plane", "gt answer": "polar(1.00)<br/>boeing(0.60)", "pred answer": "united", "question_id": 1371275, "best approach": "image", "verif answer": "boeing", "anno approach": "wiki, concept, image", "verif wiki answer": "boeing(0.7223)", "verif concept answer": "polar bear(0.7200)", "verif image answer": "polar(0.6413)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000137127.jpg"}, {"question": "what stage of life are these birds in", "gt answer": "infant(1.00)<br/>baby(1.00)", "pred answer": "early", "question_id": 3871055, "best approach": "wiki, concept, image", "verif answer": "early", "anno approach": "wiki, concept, image", "verif wiki answer": "infant(0.6963)", "verif concept answer": "infant(0.6897)", "verif image answer": "infant(0.6744)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387105.jpg"}, {"question": "what word beginninng with the letter p is another word for umbrella", "gt answer": "parasol(1.00)", "pred answer": "umbrella", "question_id": 1829605, "best approach": "wiki", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "parasol(0.6947)", "verif concept answer": "rain(0.5435)", "verif image answer": "onion(0.6125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182960.jpg"}, {"question": "what famous fantasy author shares an almost identical name to this baseball player", "gt answer": "tad williams(1.00)<br/>ty cobb(0.60)<br/>jk rowling(0.60)", "pred answer": "babe ruth", "question_id": 4157285, "best approach": "wiki", "verif answer": "babe ruth", "anno approach": "wiki, concept, image", "verif wiki answer": "tad williams(0.7264)", "verif concept answer": "major league baseball(0.6998)", "verif image answer": "major league baseball(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000415728.jpg"}, {"question": "what kind of terrain is pictured in the background", "gt answer": "hilly(1.00)<br/>desert(0.60)", "pred answer": "mountain", "question_id": 1470495, "best approach": "wiki", "verif answer": "desert", "anno approach": "wiki, concept, image", "verif wiki answer": "hilly(0.6730)", "verif concept answer": "farm(0.6933)", "verif image answer": "farm(0.5594)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147049.jpg"}, {"question": "is this recreational or a skiing competition", "gt answer": "competition(1.00)", "pred answer": "cross country", "question_id": 2801585, "best approach": "", "verif answer": "competition", "anno approach": "wiki, concept, image", "verif wiki answer": "friendly(0.7285)", "verif concept answer": "friendly(0.7026)", "verif image answer": "friendly(0.7225)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280158.jpg"}, {"question": "what kind of blanket is on the bed", "gt answer": "quilt(1.00)", "pred answer": "plaid", "question_id": 2375055, "best approach": "wiki", "verif answer": "quilt", "anno approach": "wiki, concept, image", "verif wiki answer": "quilt(0.6986)", "verif concept answer": "blanket(0.7083)", "verif image answer": "blanket(0.7183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000237505.jpg"}, {"question": "what brand is the television", "gt answer": "sharp(1.00)<br/>toshiba(0.60)", "pred answer": "sony", "question_id": 4524985, "best approach": "", "verif answer": "samsung", "anno approach": "wiki, concept, image", "verif wiki answer": "ge(0.7236)", "verif concept answer": "stab(0.7275)", "verif image answer": "ge(0.7034)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000452498.jpg"}, {"question": "these doors are used for what", "gt answer": "elevator(1.00)", "pred answer": "privacy", "question_id": 2710795, "best approach": "", "verif answer": "door", "anno approach": "wiki, concept, image", "verif wiki answer": "door(0.6863)", "verif concept answer": "antique(0.6568)", "verif image answer": "door(0.6913)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000271079.jpg"}, {"question": "what furniture is there", "gt answer": "table(1.00)", "pred answer": "couch", "question_id": 338965, "best approach": "", "verif answer": "table", "anno approach": "wiki, concept, image", "verif wiki answer": "tablecloth(0.7269)", "verif concept answer": "countertop(0.7238)", "verif image answer": "tablecloth(0.6966)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033896.jpg"}, {"question": "what kind of event would a person need those glasses for", "gt answer": "movie(1.00)", "pred answer": "party", "question_id": 2569155, "best approach": "", "verif answer": "party", "anno approach": "wiki, concept, image", "verif wiki answer": "watch tv(0.6364)", "verif concept answer": "watch tv(0.7212)", "verif image answer": "band(0.7123)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256915.jpg"}, {"question": "what architectural style is the furniture in this picture", "gt answer": "gothic(1.00)", "pred answer": "antique", "question_id": 3503035, "best approach": "wiki", "verif answer": "victorian", "anno approach": "wiki, concept, image", "verif wiki answer": "gothic(0.7096)", "verif concept answer": "victorian(0.6816)", "verif image answer": "classic(0.6848)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350303.jpg"}, {"question": "what is this thing that firefighters work on", "gt answer": "fire hydrant(1.00)<br/>fire(0.60)", "pred answer": "sand", "question_id": 5487265, "best approach": "concept", "verif answer": "fire", "anno approach": "wiki, concept, image", "verif wiki answer": "hydrant(0.6645)", "verif concept answer": "fire hydrant(0.7050)", "verif image answer": "fight fire(0.6500)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548726.jpg"}, {"question": "what is in the middle between the two tennis players", "gt answer": "net(1.00)", "pred answer": "fence", "question_id": 650125, "best approach": "", "verif answer": "fence", "anno approach": "wiki, concept, image", "verif wiki answer": "line(0.6961)", "verif concept answer": "shake hand(0.6705)", "verif image answer": "line(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065012.jpg"}, {"question": "what even is this", "gt answer": "wed(1.00)", "pred answer": "formal", "question_id": 2584885, "best approach": "wiki, concept", "verif answer": "wed", "anno approach": "wiki, concept, image", "verif wiki answer": "wed(0.7210)", "verif concept answer": "wed(0.7272)", "verif image answer": "birthday(0.6490)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258488.jpg"}, {"question": "waitresses or private school girls", "gt answer": "private school(1.00)", "pred answer": "college", "question_id": 3460215, "best approach": "", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "mascara(0.7239)", "verif concept answer": "mascara(0.6064)", "verif image answer": "mascara(0.6175)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346021.jpg"}, {"question": "what is this animal on top of", "gt answer": "cake(1.00)<br/>dog(1.00)", "pred answer": "bread", "question_id": 3009935, "best approach": "wiki", "verif answer": "cake", "anno approach": "wiki, concept, image", "verif wiki answer": "cake(0.6243)", "verif concept answer": "sugar(0.6126)", "verif image answer": "sugar(0.7008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300993.jpg"}, {"question": "why might one wish to stand under the blue tarp", "gt answer": "shade(1.00)<br/>rain(0.60)", "pred answer": "umbrella", "question_id": 4279815, "best approach": "", "verif answer": "umbrella", "anno approach": "wiki, concept, image", "verif wiki answer": "block sun(0.7150)", "verif concept answer": "block sun(0.6836)", "verif image answer": "umbrella(0.5039)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427981.jpg"}, {"question": "is this difficult or easy", "gt answer": "difficult(1.00)", "pred answer": "easy", "question_id": 392585, "best approach": "", "verif answer": "danger", "anno approach": "wiki, concept, image", "verif wiki answer": "stopped(0.6278)", "verif concept answer": "stopped(0.6407)", "verif image answer": "danger(0.6172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039258.jpg"}, {"question": "what traveling device is being used", "gt answer": "trailer(1.00)<br/>car(0.60)", "pred answer": "truck", "question_id": 973675, "best approach": "wiki, concept", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "trailer(0.7166)", "verif concept answer": "trailer(0.6719)", "verif image answer": "rv(0.7142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097367.jpg"}, {"question": "the object the meat is in is called what", "gt answer": "bun(1.00)<br/>sandwich(0.60)<br/>boat(0.60)", "pred answer": "case", "question_id": 1855776, "best approach": "concept", "verif answer": "bun", "anno approach": "wiki, concept, image", "verif wiki answer": "sandwich(0.6037)", "verif concept answer": "bun(0.6281)", "verif image answer": "hot dog(0.6277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185577.jpg"}, {"question": "what type of alcoholic beverage is displayed in this image", "gt answer": "champagne(1.00)<br/>wine(1.00)", "pred answer": "beer", "question_id": 3551755, "best approach": "image", "verif answer": "beer", "anno approach": "wiki, concept, image", "verif wiki answer": "beer(0.6899)", "verif concept answer": "chardonnay(0.7073)", "verif image answer": "wine(0.6143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355175.jpg"}, {"question": "where can i buy those lights hanging from the ceiling", "gt answer": "home depot(1.00)", "pred answer": "walmart", "question_id": 5614645, "best approach": "", "verif answer": "walmart", "anno approach": "wiki, concept, image", "verif wiki answer": "walmart(0.6757)", "verif concept answer": "walmart(0.7115)", "verif image answer": "walmart(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561464.jpg"}, {"question": "what body of water is in this picture", "gt answer": "sea(1.00)<br/>lake(1.00)", "pred answer": "ocean", "question_id": 1746775, "best approach": "concept", "verif answer": "ocean", "anno approach": "wiki, concept, image", "verif wiki answer": "ocean(0.7202)", "verif concept answer": "lake(0.7089)", "verif image answer": "river(0.7195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174677.jpg"}, {"question": "what animal is pictured", "gt answer": "octopus(1.00)<br/>bear(0.60)", "pred answer": "bird", "question_id": 3817955, "best approach": "", "verif answer": "stingray", "anno approach": "wiki, concept, image", "verif wiki answer": "stingray(0.6532)", "verif concept answer": "stingray(0.6762)", "verif image answer": "dragon(0.6819)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381795.jpg"}, {"question": "what kind of cargo is the lorry in the photo carrying", "gt answer": "lumber(1.00)<br/>wood(1.00)", "pred answer": "garbage", "question_id": 5003175, "best approach": "wiki, image", "verif answer": "wood", "anno approach": "wiki, concept, image", "verif wiki answer": "wood(0.7082)", "verif concept answer": "forest(0.6534)", "verif image answer": "wood(0.6074)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500317.jpg"}, {"question": "what emotions are expressed by the girl", "gt answer": "joy(1.00)<br/>happiness(0.60)", "pred answer": "happy", "question_id": 2109095, "best approach": "", "verif answer": "happiness", "anno approach": "wiki, concept, image", "verif wiki answer": "smile(0.7222)", "verif concept answer": "sad(0.6900)", "verif image answer": "smile(0.6788)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210909.jpg"}, {"question": "what type of dog is that", "gt answer": "pug(1.00)<br/>bulldog(0.60)", "pred answer": "golden retriever", "question_id": 4891995, "best approach": "image", "verif answer": "pug", "anno approach": "wiki, concept, image", "verif wiki answer": "schnauzer(0.7189)", "verif concept answer": "schnauzer(0.7070)", "verif image answer": "pug(0.7110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489199.jpg"}, {"question": "all the photos in this pictuare are what", "gt answer": "framed(1.00)<br/>city(0.60)", "pred answer": "movie", "question_id": 3577505, "best approach": "concept", "verif answer": "selfie", "anno approach": "wiki, concept, image", "verif wiki answer": "selfie(0.6955)", "verif concept answer": "city(0.6427)", "verif image answer": "tourist(0.5967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357750.jpg"}, {"question": "can you guess the place name where the train is shown in this picture", "gt answer": "cardiff(1.00)<br/>train station(1.00)", "pred answer": "station", "question_id": 884145, "best approach": "image", "verif answer": "station", "anno approach": "wiki, concept, image", "verif wiki answer": "station(0.7193)", "verif concept answer": "train depot(0.7211)", "verif image answer": "train station(0.5517)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088414.jpg"}, {"question": "what ethic group makes this food most commonly", "gt answer": "italians(1.00)<br/>italian(0.60)", "pred answer": "vegetable", "question_id": 187805, "best approach": "", "verif answer": "italian", "anno approach": "wiki, concept, image", "verif wiki answer": "pizza(0.6783)", "verif concept answer": "chef(0.7002)", "verif image answer": "chef(0.7125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000018780.jpg"}, {"question": "where are the hundreds and thousands in this illustration", "gt answer": "sprinkle(1.00)<br/>donut(0.60)<br/>table(0.60)", "pred answer": "dunkin donuts", "question_id": 3412095, "best approach": "wiki, concept", "verif answer": "donut", "anno approach": "wiki, concept, image", "verif wiki answer": "table(0.5915)", "verif concept answer": "table(0.5932)", "verif image answer": "cinnamon(0.6728)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341209.jpg"}, {"question": "what is the brand name of shoes in this picture", "gt answer": "adidas(1.00)", "pred answer": "converse", "question_id": 1932815, "best approach": "wiki, concept", "verif answer": "nike", "anno approach": "wiki, concept, image", "verif wiki answer": "adidas(0.6855)", "verif concept answer": "adidas(0.7077)", "verif image answer": "nike(0.5187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193281.jpg"}, {"question": "", "gt answer": "cross legged(0.60)<br/>sit(0.60)", "pred answer": "batter", "question_id": 52945, "best approach": "wiki, concept, image", "verif answer": "cross legged", "anno approach": "wiki, concept, image", "verif wiki answer": "cross legged(0.6918)", "verif concept answer": "cross legged(0.6188)", "verif image answer": "cross legged(0.5769)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005294.jpg"}, {"question": "what keeps these animals warm", "gt answer": "fur(1.00)", "pred answer": "wool", "question_id": 2056215, "best approach": "wiki, concept", "verif answer": "wool", "anno approach": "wiki, concept, image", "verif wiki answer": "fur(0.7279)", "verif concept answer": "fur(0.7147)", "verif image answer": "wool(0.7117)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205621.jpg"}, {"question": "what types of events have this type of food items", "gt answer": "party(1.00)<br/>wed(0.60)<br/>birthday(0.60)", "pred answer": "buffet", "question_id": 5669685, "best approach": "image", "verif answer": "party", "anno approach": "wiki, concept, image", "verif wiki answer": "wed(0.6781)", "verif concept answer": "birthday party(0.6756)", "verif image answer": "party(0.6604)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566968.jpg"}, {"question": "what breed of dog is in the picture", "gt answer": "mutt(1.00)<br/>terrier(0.60)<br/>collie(0.60)<br/>boxer(0.60)", "pred answer": "golden retriever", "question_id": 3253805, "best approach": "wiki, concept, image", "verif answer": "boxer", "anno approach": "wiki, concept, image", "verif wiki answer": "mutt(0.7239)", "verif concept answer": "mutt(0.7275)", "verif image answer": "mutt(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325380.jpg"}, {"question": "what is the purpose of this company", "gt answer": "cellular(0.60)<br/>cellphone(0.60)<br/>communication(1.00)", "pred answer": "internet", "question_id": 4761065, "best approach": "wiki", "verif answer": "cellular", "anno approach": "wiki, concept, image", "verif wiki answer": "communication(0.6278)", "verif concept answer": "cell phone(0.5894)", "verif image answer": "cellular(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476106.jpg"}, {"question": "what color would the eyes likely show as if using a flash to take a picture", "gt answer": "red(1.00)<br/>green(1.00)<br/>yellow(0.60)", "pred answer": "white", "question_id": 4012325, "best approach": "image", "verif answer": "white", "anno approach": "wiki, concept, image", "verif wiki answer": "white(0.7229)", "verif concept answer": "white(0.6593)", "verif image answer": "red(0.6699)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401232.jpg"}, {"question": "what holiday is being celebrated", "gt answer": "valentine(1.00)<br/>valentine's day(0.60)<br/>valentine's(0.60)", "pred answer": "christmas", "question_id": 588765, "best approach": "wiki", "verif answer": "christmas", "anno approach": "wiki, concept, image", "verif wiki answer": "valentine's(0.6793)", "verif concept answer": "christmas(0.7013)", "verif image answer": "st patrick's day(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058876.jpg"}, {"question": "this item is often referred to as the royal throne", "gt answer": "toilet(1.00)<br/>bathroom(0.60)", "pred answer": "bidet", "question_id": 150965, "best approach": "wiki, image", "verif answer": "toilet", "anno approach": "wiki, concept, image", "verif wiki answer": "toilet(0.6748)", "verif concept answer": "ceramic(0.6752)", "verif image answer": "toilet(0.6785)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015096.jpg"}, {"question": "what is billowing in the background of the picture", "gt answer": "smoke(1.00)<br/>fire(1.00)", "pred answer": "trash", "question_id": 971725, "best approach": "wiki, image", "verif answer": "smoke", "anno approach": "wiki, concept, image", "verif wiki answer": "fire(0.7222)", "verif concept answer": "gas(0.7022)", "verif image answer": "fire(0.6121)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097172.jpg"}, {"question": "what do men sleep on when their wives kick them out of the bedroom", "gt answer": "sofa(1.00)<br/>couch(1.00)", "pred answer": "bed", "question_id": 5497145, "best approach": "wiki, concept, image", "verif answer": "couch", "anno approach": "wiki, concept, image", "verif wiki answer": "sofa(0.7169)", "verif concept answer": "sofa(0.6566)", "verif image answer": "sofa(0.7267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000549714.jpg"}, {"question": "what type of lighting is noticeably absent from this room", "gt answer": "overhead(1.00)<br/>ceiling(0.60)<br/>indoor(0.60)<br/>fluorescent(0.60)", "pred answer": "lamp", "question_id": 95395, "best approach": "wiki, concept, image", "verif answer": "fluorescent", "anno approach": "wiki, concept, image", "verif wiki answer": "fluorescent(0.7262)", "verif concept answer": "ceiling(0.6968)", "verif image answer": "indoor(0.6436)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009539.jpg"}, {"question": "does a woman or a man own the contents of this bag", "gt answer": "woman(1.00)", "pred answer": "man", "question_id": 984395, "best approach": "image", "verif answer": "female", "anno approach": "wiki, concept, image", "verif wiki answer": "female(0.6378)", "verif concept answer": "female(0.6218)", "verif image answer": "woman(0.5041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098439.jpg"}, {"question": "what kind of dish is being made", "gt answer": "burrito(1.00)<br/>lemon(0.60)<br/>cookies(0.60)", "pred answer": "pie", "question_id": 3534845, "best approach": "wiki, concept", "verif answer": "cereal", "anno approach": "wiki, concept, image", "verif wiki answer": "burrito(0.7237)", "verif concept answer": "burrito(0.7137)", "verif image answer": "cookies(0.6719)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353484.jpg"}, {"question": "what kind of dog is this", "gt answer": "collie(1.00)<br/>domesticated(0.60)<br/>mix(0.60)", "pred answer": "chihuahua", "question_id": 1191695, "best approach": "concept", "verif answer": "collie", "anno approach": "wiki, concept, image", "verif wiki answer": "retriever(0.6841)", "verif concept answer": "collie(0.7105)", "verif image answer": "mix(0.6718)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119169.jpg"}, {"question": "what type of drinks are served at this location", "gt answer": "alcohol(0.60)<br/>juice(1.00)<br/>smoothies(0.60)", "pred answer": "beer", "question_id": 2861815, "best approach": "image", "verif answer": "beer", "anno approach": "wiki, concept, image", "verif wiki answer": "beer(0.7181)", "verif concept answer": "smoothie(0.7182)", "verif image answer": "smoothies(0.6637)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000286181.jpg"}, {"question": "what activity is this guy doing", "gt answer": "kite fly(1.00)<br/>frisbee(0.60)", "pred answer": "kite", "question_id": 4822235, "best approach": "", "verif answer": "kite", "anno approach": "wiki, concept, image", "verif wiki answer": "kite(0.6850)", "verif concept answer": "kite(0.6715)", "verif image answer": "kite(0.6528)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482223.jpg"}, {"question": "what is the woman taking a picture of", "gt answer": "waterfall(1.00)<br/>sea(0.60)", "pred answer": "car", "question_id": 1827995, "best approach": "wiki, concept", "verif answer": "shark", "anno approach": "wiki, concept, image", "verif wiki answer": "waterfall(0.6186)", "verif concept answer": "waterfall(0.6317)", "verif image answer": "black(0.6944)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182799.jpg"}, {"question": "how do these people know each other", "gt answer": "family(1.00)", "pred answer": "friend", "question_id": 5334515, "best approach": "wiki, concept", "verif answer": "family", "anno approach": "wiki, concept, image", "verif wiki answer": "family(0.7072)", "verif concept answer": "family(0.6073)", "verif image answer": "alone(0.5037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000533451.jpg"}, {"question": "what is on her leg", "gt answer": "tattoo(1.00)", "pred answer": "triangle", "question_id": 2512925, "best approach": "wiki", "verif answer": "tattoo", "anno approach": "wiki, concept, image", "verif wiki answer": "tattoo(0.6887)", "verif concept answer": "bed(0.5807)", "verif image answer": "meter(0.6671)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251292.jpg"}, {"question": "what type of skateboard is this", "gt answer": "standard(1.00)<br/>kid(0.60)<br/>street(0.60)", "pred answer": "longboard", "question_id": 4107395, "best approach": "", "verif answer": "long board", "anno approach": "wiki, concept, image", "verif wiki answer": "long board(0.7092)", "verif concept answer": "long board(0.6868)", "verif image answer": "long board(0.6826)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000410739.jpg"}, {"question": "what city is this meeting taking place", "gt answer": "beverly hill(1.00)<br/>boston(0.60)", "pred answer": "new york", "question_id": 2851325, "best approach": "image", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "new york(0.6663)", "verif concept answer": "seattle(0.7236)", "verif image answer": "boston(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285132.jpg"}, {"question": "what alcohol is this", "gt answer": "vodka(1.00)", "pred answer": "cider", "question_id": 5648375, "best approach": "wiki", "verif answer": "beer", "anno approach": "wiki, concept, image", "verif wiki answer": "vodka(0.6949)", "verif concept answer": "wine(0.5748)", "verif image answer": "captain morgan(0.5883)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564837.jpg"}, {"question": "what country is famous for making this food item", "gt answer": "italy(1.00)", "pred answer": "chicago", "question_id": 4379485, "best approach": "", "verif answer": "italy", "anno approach": "wiki, concept, image", "verif wiki answer": "mexico(0.7123)", "verif concept answer": "egypt(0.6863)", "verif image answer": "egypt(0.6544)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437948.jpg"}, {"question": "the umbrella in this photo looks like what fruit", "gt answer": "strawberry(1.00)<br/>watermelon(0.60)<br/>pussy(0.60)", "pred answer": "peach", "question_id": 2034295, "best approach": "wiki", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "strawberry(0.6364)", "verif concept answer": "cherry(0.7200)", "verif image answer": "cherry(0.5246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203429.jpg"}, {"question": "when was that red spoked implement invented", "gt answer": "4000 bc(1.00)", "pred answer": "1800's", "question_id": 423715, "best approach": "wiki", "verif answer": "1800s", "anno approach": "wiki, concept, image", "verif wiki answer": "4000 bc(0.6830)", "verif concept answer": "1800s(0.6758)", "verif image answer": "china(0.7242)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042371.jpg"}, {"question": "what airline is this plane", "gt answer": "hawaiian(1.00)", "pred answer": "american", "question_id": 520355, "best approach": "", "verif answer": "click", "anno approach": "wiki, concept, image", "verif wiki answer": "sunexpress(0.7212)", "verif concept answer": "sunexpress(0.7197)", "verif image answer": "sunexpress(0.6618)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052035.jpg"}, {"question": "how tall are these giraffes", "gt answer": "20 feet(1.00)<br/>12 feet(0.60)", "pred answer": "15 feet", "question_id": 4505515, "best approach": "image", "verif answer": "20 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "11 feet(0.6541)", "verif concept answer": "11 feet(0.6595)", "verif image answer": "12 feet(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450551.jpg"}, {"question": "what type of screen would be most useful in this situation", "gt answer": "sunscreen(1.00)<br/>wide(0.60)", "pred answer": "wide angle", "question_id": 2938005, "best approach": "image", "verif answer": "wide angle", "anno approach": "wiki, concept, image", "verif wiki answer": "wide angle(0.6970)", "verif concept answer": "wide angle(0.7135)", "verif image answer": "wide(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293800.jpg"}, {"question": "name the ingredients used to make this dish in this picture", "gt answer": "hot dog(1.00)", "pred answer": "vegetable", "question_id": 167415, "best approach": "", "verif answer": "hot dog", "anno approach": "wiki, concept, image", "verif wiki answer": "hotdogs(0.6886)", "verif concept answer": "hotdogs(0.7241)", "verif image answer": "french fry(0.7110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016741.jpg"}, {"question": "what city is this", "gt answer": "washington dc(1.00)", "pred answer": "berlin", "question_id": 3470425, "best approach": "", "verif answer": "washington dc", "anno approach": "wiki, concept, image", "verif wiki answer": "washington(0.6872)", "verif concept answer": "st louis(0.7133)", "verif image answer": "st louis(0.6054)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347042.jpg"}, {"question": "who could this boys role model be", "gt answer": "roger federer(1.00)<br/>federer(0.60)", "pred answer": "opponent", "question_id": 498195, "best approach": "", "verif answer": "john mcenroe", "anno approach": "wiki, concept, image", "verif wiki answer": "tennis(0.6465)", "verif concept answer": "john mcenroe(0.6310)", "verif image answer": "sharapova(0.6914)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049819.jpg"}, {"question": "what is this author 's most well known work", "gt answer": "walk in wood(1.00)", "pred answer": "forrest gump", "question_id": 2518355, "best approach": "image", "verif answer": "van gogh", "anno approach": "wiki, concept, image", "verif wiki answer": "gothic(0.7102)", "verif concept answer": "van gogh(0.7076)", "verif image answer": "walk in wood(0.6926)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251835.jpg"}, {"question": "what language is the paper on the bottom written in", "gt answer": "spanish(1.00)<br/>chinese(0.60)", "pred answer": "english", "question_id": 3647485, "best approach": "concept, image", "verif answer": "english", "anno approach": "wiki, concept, image", "verif wiki answer": "english(0.7252)", "verif concept answer": "spanish(0.6294)", "verif image answer": "spanish(0.5368)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364748.jpg"}, {"question": "what does this scene have in common with the fifties movie star annette funicello", "gt answer": "beach(1.00)<br/>sand(0.60)<br/>umbrella(0.60)", "pred answer": "bikini", "question_id": 4010715, "best approach": "image", "verif answer": "umbrella", "anno approach": "wiki, concept, image", "verif wiki answer": "umbrella(0.5942)", "verif concept answer": "umbrella(0.5418)", "verif image answer": "beach(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401071.jpg"}, {"question": "do the giraffes look to be in a playful mood or in an aggrresive one", "gt answer": "playful(1.00)<br/>giraffe(0.60)", "pred answer": "happy", "question_id": 1802715, "best approach": "concept, image", "verif answer": "herbivore", "anno approach": "wiki, concept, image", "verif wiki answer": "run(0.6946)", "verif concept answer": "giraffe(0.6902)", "verif image answer": "giraffe(0.5086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180271.jpg"}, {"question": "what is the name of this pizza chain 's mascot", "gt answer": "chuck e cheese(1.00)", "pred answer": "penguin", "question_id": 4192325, "best approach": "wiki, concept, image", "verif answer": "snake", "anno approach": "wiki, concept, image", "verif wiki answer": "chuck e cheese(0.7258)", "verif concept answer": "chuck e cheese(0.7298)", "verif image answer": "chuck e cheese(0.7113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419232.jpg"}, {"question": "what is that basin used for", "gt answer": "wash hand(1.00)<br/>wash(0.60)<br/>shower(0.60)", "pred answer": "bath", "question_id": 440395, "best approach": "wiki", "verif answer": "wash hand", "anno approach": "wiki, concept, image", "verif wiki answer": "wash hand(0.6894)", "verif concept answer": "poop(0.6594)", "verif image answer": "shower(0.6334)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000044039.jpg"}, {"question": "what type of bird is this", "gt answer": "peacock(1.00)", "pred answer": "flamingo", "question_id": 4049825, "best approach": "wiki", "verif answer": "cardinal", "anno approach": "wiki, concept, image", "verif wiki answer": "peacock(0.6946)", "verif concept answer": "cardinal(0.6917)", "verif image answer": "owl(0.6490)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404982.jpg"}, {"question": "name the object used for putting nails in walls", "gt answer": "hammer(1.00)", "pred answer": "scissor", "question_id": 5450715, "best approach": "", "verif answer": "hammer", "anno approach": "wiki, concept, image", "verif wiki answer": "paint(0.6944)", "verif concept answer": "paint(0.6973)", "verif image answer": "paint(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545071.jpg"}, {"question": "what is that black item in his hand used for", "gt answer": "catch(1.00)", "pred answer": "bat", "question_id": 3662685, "best approach": "", "verif answer": "catch", "anno approach": "wiki, concept, image", "verif wiki answer": "catcher(0.6747)", "verif concept answer": "fetch(0.6212)", "verif image answer": "catcher(0.7046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366268.jpg"}, {"question": "what could be done to improve the organization of this kitchen", "gt answer": "shelve(1.00)<br/>clean(0.60)<br/>cabinet(0.60)", "pred answer": "cook", "question_id": 5469845, "best approach": "wiki, concept", "verif answer": "cabinet", "anno approach": "wiki, concept, image", "verif wiki answer": "cabinet(0.7063)", "verif concept answer": "cabinet(0.6105)", "verif image answer": "hand(0.6881)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546984.jpg"}, {"question": "what is the leaf in the smoothie called", "gt answer": "mint(1.00)", "pred answer": "basil", "question_id": 2968925, "best approach": "wiki, concept", "verif answer": "cell phone", "anno approach": "wiki, concept, image", "verif wiki answer": "mint(0.6926)", "verif concept answer": "mint(0.7039)", "verif image answer": "cell phone(0.6971)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296892.jpg"}, {"question": "what kind of are crafts are both of these", "gt answer": "airplane(1.00)<br/>plane(0.60)", "pred answer": "biplane", "question_id": 4031185, "best approach": "wiki, image", "verif answer": "jet", "anno approach": "wiki, concept, image", "verif wiki answer": "airplane(0.6513)", "verif concept answer": "jet(0.6553)", "verif image answer": "airplane(0.6541)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403118.jpg"}, {"question": "what is this man doing to the surfboard", "gt answer": "wax(1.00)", "pred answer": "paddle", "question_id": 4918795, "best approach": "", "verif answer": "wax", "anno approach": "wiki, concept, image", "verif wiki answer": "sail(0.6142)", "verif concept answer": "sail(0.6308)", "verif image answer": "sail(0.7143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491879.jpg"}, {"question": "is this bus still in operation or is it headed back to the bus depot", "gt answer": "in operation(1.00)", "pred answer": "tour", "question_id": 2740225, "best approach": "", "verif answer": "bus", "anno approach": "wiki, concept, image", "verif wiki answer": "shut down(0.7111)", "verif concept answer": "normal(0.6546)", "verif image answer": "normal(0.6567)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274022.jpg"}, {"question": "who is the famous singer in the bottom right of the photo", "gt answer": "elvis(1.00)<br/>elvis presley(1.00)", "pred answer": "gene kelly", "question_id": 2882155, "best approach": "wiki, concept", "verif answer": "roger federer", "anno approach": "wiki, concept, image", "verif wiki answer": "elvis(0.7224)", "verif concept answer": "elvis(0.7256)", "verif image answer": "apple(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288215.jpg"}, {"question": "the bike mirror shown in the picture is of which type", "gt answer": "side mirror(1.00)", "pred answer": "honda", "question_id": 735415, "best approach": "wiki, image", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "side mirror(0.6841)", "verif concept answer": "honda(0.7089)", "verif image answer": "side mirror(0.6976)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073541.jpg"}, {"question": "which city is the given sport originated from", "gt answer": "los angeles(1.00)<br/>philadelphia(1.00)", "pred answer": "california", "question_id": 2929285, "best approach": "wiki, concept, image", "verif answer": "london", "anno approach": "wiki, concept, image", "verif wiki answer": "los angeles(0.7214)", "verif concept answer": "los angeles(0.7289)", "verif image answer": "philadelphia(0.7109)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292928.jpg"}, {"question": "how much of that boat is under water", "gt answer": "1 4(1.00)<br/>8 feet(0.60)<br/>0(0.60)", "pred answer": "2", "question_id": 3274505, "best approach": "wiki, concept, image", "verif answer": "10", "anno approach": "wiki, concept, image", "verif wiki answer": "0(0.6914)", "verif concept answer": "8 feet(0.6416)", "verif image answer": "8 feet(0.5699)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327450.jpg"}, {"question": "what kind of bird is this", "gt answer": "parakeet(1.00)<br/>blue(0.60)", "pred answer": "robin", "question_id": 2106795, "best approach": "wiki, concept, image", "verif answer": "robin", "anno approach": "wiki, concept, image", "verif wiki answer": "parakeet(0.7045)", "verif concept answer": "parakeet(0.7072)", "verif image answer": "parakeet(0.6736)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210679.jpg"}, {"question": "who manufactured the blue bicycle in the foreground", "gt answer": "giant(1.00)<br/>schwinn(0.60)", "pred answer": "huffy", "question_id": 2921465, "best approach": "", "verif answer": "huffy", "anno approach": "wiki, concept, image", "verif wiki answer": "tony(0.6298)", "verif concept answer": "tony(0.6246)", "verif image answer": "huffy(0.5868)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292146.jpg"}, {"question": "what is this tool used for", "gt answer": "cut(1.00)", "pred answer": "sew", "question_id": 501515, "best approach": "", "verif answer": "sew", "anno approach": "wiki, concept, image", "verif wiki answer": "scissor(0.7201)", "verif concept answer": "scissor(0.6876)", "verif image answer": "scissor(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050151.jpg"}, {"question": "is the elephants in a river or pond", "gt answer": "river(1.00)", "pred answer": "lake", "question_id": 4857705, "best approach": "", "verif answer": "lake", "anno approach": "wiki, concept, image", "verif wiki answer": "lake(0.7179)", "verif concept answer": "lake(0.7018)", "verif image answer": "lake(0.6017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485770.jpg"}, {"question": "what type of plant does this come from", "gt answer": "pumpkin(1.00)", "pred answer": "potato", "question_id": 4761135, "best approach": "", "verif answer": "carrot", "anno approach": "wiki, concept, image", "verif wiki answer": "broccoli(0.6933)", "verif concept answer": "broccoli(0.7101)", "verif image answer": "carrot(0.7146)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476113.jpg"}, {"question": "what country is that fruit known from", "gt answer": "brazil(1.00)<br/>costa rica(0.60)<br/>south america(0.60)<br/>india(0.60)", "pred answer": "usa", "question_id": 2211875, "best approach": "wiki, concept, image", "verif answer": "india", "anno approach": "wiki, concept, image", "verif wiki answer": "south america(0.6375)", "verif concept answer": "costa rica(0.7046)", "verif image answer": "india(0.6980)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221187.jpg"}, {"question": "who is this woman dressed as", "gt answer": "merida(1.00)", "pred answer": "halloween", "question_id": 2282245, "best approach": "", "verif answer": "bear", "anno approach": "wiki, concept, image", "verif wiki answer": "toy(0.6706)", "verif concept answer": "toy(0.6498)", "verif image answer": "toy(0.5892)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000228224.jpg"}, {"question": "what brain parasite often affects owners of this animal", "gt answer": "toxoplasmosis(1.00)<br/>0(0.60)", "pred answer": "goatee", "question_id": 4580835, "best approach": "wiki", "verif answer": "jaywalk", "anno approach": "wiki, concept, image", "verif wiki answer": "toxoplasmosis(0.7182)", "verif concept answer": "jaywalk(0.6805)", "verif image answer": "0(0.6258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458083.jpg"}, {"question": "what is this made from", "gt answer": "tree(1.00)<br/>paper(0.60)<br/>ceramic(0.60)", "pred answer": "plastic", "question_id": 2192465, "best approach": "", "verif answer": "ceramic", "anno approach": "wiki, concept, image", "verif wiki answer": "cloth(0.7059)", "verif concept answer": "cloth(0.7077)", "verif image answer": "cloth(0.6193)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219246.jpg"}, {"question": "what type of areas do cows typically inhabit", "gt answer": "pasture(1.00)<br/>grassland(1.00)", "pred answer": "farm", "question_id": 5665925, "best approach": "", "verif answer": "hill", "anno approach": "wiki, concept, image", "verif wiki answer": "hill(0.6661)", "verif concept answer": "hill(0.6057)", "verif image answer": "cow(0.6603)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566592.jpg"}, {"question": "is this a recreational or commercial activity", "gt answer": "commercial(1.00)<br/>recreational(0.60)", "pred answer": "business", "question_id": 858555, "best approach": "wiki", "verif answer": "commercial", "anno approach": "wiki, concept, image", "verif wiki answer": "commercial(0.6809)", "verif concept answer": "public(0.6826)", "verif image answer": "recreational(0.6884)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085855.jpg"}, {"question": "what food item is on the plate", "gt answer": "pie(1.00)<br/>cake(1.00)", "pred answer": "donut", "question_id": 533175, "best approach": "wiki", "verif answer": "dessert", "anno approach": "wiki, concept, image", "verif wiki answer": "cake(0.6937)", "verif concept answer": "cheesecake(0.6848)", "verif image answer": "cheesecake(0.6799)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053317.jpg"}, {"question": "what kind of system is the computer running", "gt answer": "window(1.00)<br/>business(0.60)", "pred answer": "laptop", "question_id": 5103205, "best approach": "concept", "verif answer": "window", "anno approach": "wiki, concept, image", "verif wiki answer": "mac(0.6966)", "verif concept answer": "business(0.5958)", "verif image answer": "intel(0.6253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510320.jpg"}, {"question": "what 's the tallest tree", "gt answer": "redwood(1.00)<br/>pine(0.60)", "pred answer": "oak", "question_id": 3136745, "best approach": "concept", "verif answer": "oak", "anno approach": "wiki, concept, image", "verif wiki answer": "pine(0.7083)", "verif concept answer": "redwood(0.7014)", "verif image answer": "oak(0.6126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313674.jpg"}, {"question": "which type of accessory is the bear wearing", "gt answer": "bow(1.00)<br/>scarf(1.00)<br/>necklace(0.60)", "pred answer": "tie", "question_id": 613515, "best approach": "concept, image", "verif answer": "necklace", "anno approach": "wiki, concept, image", "verif wiki answer": "sweater(0.7220)", "verif concept answer": "necklace(0.7237)", "verif image answer": "necklace(0.7086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061351.jpg"}, {"question": "what type of dog breed is this", "gt answer": "shepard(1.00)<br/>german shepherd(0.60)<br/>mixed(0.60)", "pred answer": "mutt", "question_id": 770275, "best approach": "concept", "verif answer": "german shepard", "anno approach": "wiki, concept, image", "verif wiki answer": "beagle(0.7140)", "verif concept answer": "shepard(0.7166)", "verif image answer": "beagle(0.6644)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077027.jpg"}, {"question": "what ethnicity are the people in this photo", "gt answer": "asian(1.00)<br/>chinese(0.60)", "pred answer": "white", "question_id": 2264425, "best approach": "concept", "verif answer": "asian", "anno approach": "wiki, concept, image", "verif wiki answer": "asia(0.6903)", "verif concept answer": "chinese(0.6806)", "verif image answer": "asia(0.5921)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226442.jpg"}, {"question": "what happens next", "gt answer": "chop(0.60)<br/>eat(1.00)", "pred answer": "cook", "question_id": 1873365, "best approach": "wiki, image", "verif answer": "cook", "anno approach": "wiki, concept, image", "verif wiki answer": "eat(0.6876)", "verif concept answer": "chop(0.6893)", "verif image answer": "eat(0.6438)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187336.jpg"}, {"question": "what animal print is on her coat", "gt answer": "leopard(1.00)", "pred answer": "stripe", "question_id": 2101045, "best approach": "concept", "verif answer": "stripe", "anno approach": "wiki, concept, image", "verif wiki answer": "stripe(0.7046)", "verif concept answer": "leopard(0.7240)", "verif image answer": "striped(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210104.jpg"}, {"question": "who is likely riding in these buses", "gt answer": "tourist(1.00)<br/>people(1.00)", "pred answer": "passenger", "question_id": 3149645, "best approach": "wiki", "verif answer": "passenger", "anno approach": "wiki, concept, image", "verif wiki answer": "tourist(0.7157)", "verif concept answer": "human(0.6672)", "verif image answer": "human(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314964.jpg"}, {"question": "what was the rod in the boy 's hand used for", "gt answer": "hike(1.00)<br/>balance(0.60)", "pred answer": "protection", "question_id": 1434535, "best approach": "image", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "carefully(0.7131)", "verif concept answer": "balance(0.6435)", "verif image answer": "hike(0.6437)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143453.jpg"}, {"question": "are these herbivorous or carnivorous animals", "gt answer": "herbivorous(1.00)", "pred answer": "herbivore", "question_id": 1749325, "best approach": "concept", "verif answer": "herbivore", "anno approach": "wiki, concept, image", "verif wiki answer": "herbivore(0.7199)", "verif concept answer": "herbivorous(0.7139)", "verif image answer": "vegetarian(0.6578)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174932.jpg"}, {"question": "what material makes up the ground these people are walking on", "gt answer": "stone(1.00)<br/>cobblestone(0.60)<br/>brick(1.00)", "pred answer": "concrete", "question_id": 2454155, "best approach": "wiki, concept, image", "verif answer": "concrete", "anno approach": "wiki, concept, image", "verif wiki answer": "cobblestone(0.7208)", "verif concept answer": "cobblestone(0.7076)", "verif image answer": "cobblestone(0.6317)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245415.jpg"}, {"question": "what is in the girl 's mouth", "gt answer": "toothbrush(1.00)<br/>brush(0.60)", "pred answer": "cigarette", "question_id": 4161575, "best approach": "wiki, concept", "verif answer": "cigarette", "anno approach": "wiki, concept, image", "verif wiki answer": "toothbrush(0.7162)", "verif concept answer": "toothbrush(0.7235)", "verif image answer": "clean teeth(0.7239)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416157.jpg"}, {"question": "what are the two girls behind the man on the motorcycle likely dressed for", "gt answer": "school(1.00)", "pred answer": "ride", "question_id": 2456835, "best approach": "", "verif answer": "school", "anno approach": "wiki, concept, image", "verif wiki answer": "home(0.6496)", "verif concept answer": "restaurant(0.6824)", "verif image answer": "college(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245683.jpg"}, {"question": "what style of jeans are these women wearing", "gt answer": "skinny(1.00)", "pred answer": "jean", "question_id": 481605, "best approach": "concept", "verif answer": "jean", "anno approach": "wiki, concept, image", "verif wiki answer": "jean(0.7150)", "verif concept answer": "skinny(0.7263)", "verif image answer": "jean(0.5311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048160.jpg"}, {"question": "what planet do you recognize", "gt answer": "saturn(1.00)", "pred answer": "0", "question_id": 343875, "best approach": "", "verif answer": "clock tower", "anno approach": "wiki, concept, image", "verif wiki answer": "pure(0.6366)", "verif concept answer": "sony(0.6509)", "verif image answer": "clock tower(0.5198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000034387.jpg"}, {"question": "where is the firetruck headed", "gt answer": "emergency(1.00)<br/>fire(0.60)<br/>house(0.60)", "pred answer": "construction site", "question_id": 3417565, "best approach": "concept", "verif answer": "house", "anno approach": "wiki, concept, image", "verif wiki answer": "house(0.6981)", "verif concept answer": "emergency(0.6629)", "verif image answer": "fire(0.6882)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341756.jpg"}, {"question": "what materials are the objects then men are holding made from", "gt answer": "polyurethane(1.00)<br/>plastic(0.60)<br/>styrofoam(0.60)<br/>fiberglass(0.60)", "pred answer": "wood", "question_id": 1665565, "best approach": "wiki, concept, image", "verif answer": "polyurethane", "anno approach": "wiki, concept, image", "verif wiki answer": "fiberglass(0.7246)", "verif concept answer": "fiberglass(0.7113)", "verif image answer": "fiberglass(0.6845)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166556.jpg"}, {"question": "what kind of clouds are in this picture", "gt answer": "cumulus(1.00)", "pred answer": "stratus", "question_id": 1757565, "best approach": "", "verif answer": "stratus", "anno approach": "wiki, concept, image", "verif wiki answer": "stratus(0.7241)", "verif concept answer": "stratus(0.7287)", "verif image answer": "stratus(0.7164)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000175756.jpg"}, {"question": "this is the smallest of what group of vertebrates", "gt answer": "bird(1.00)", "pred answer": "lavender", "question_id": 4666715, "best approach": "wiki", "verif answer": "bird", "anno approach": "wiki, concept, image", "verif wiki answer": "bird(0.6432)", "verif concept answer": "monkey(0.6768)", "verif image answer": "monkey(0.6461)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466671.jpg"}, {"question": "where was this picture taken", "gt answer": "china(1.00)<br/>japan(0.60)<br/>pond(0.60)<br/>asia(0.60)", "pred answer": "harbor", "question_id": 5404865, "best approach": "wiki, image", "verif answer": "china", "anno approach": "wiki, concept, image", "verif wiki answer": "japan(0.6333)", "verif concept answer": "america(0.6838)", "verif image answer": "pond(0.5875)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540486.jpg"}, {"question": "what team is this up to bat", "gt answer": "cardinal(1.00)<br/>red(0.60)", "pred answer": "yankees", "question_id": 918865, "best approach": "", "verif answer": "red sox", "anno approach": "wiki, concept, image", "verif wiki answer": "red sox(0.6726)", "verif concept answer": "red sox(0.6789)", "verif image answer": "red sox(0.6196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000091886.jpg"}, {"question": "what type of dog is this", "gt answer": "sheep dog(1.00)<br/>sheepdog(0.60)", "pred answer": "poodle", "question_id": 53555, "best approach": "", "verif answer": "labrador", "anno approach": "wiki, concept, image", "verif wiki answer": "border collie(0.7175)", "verif concept answer": "border collie(0.7243)", "verif image answer": "border collie(0.7114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005355.jpg"}, {"question": "what type of plane is this", "gt answer": "private jet(1.00)<br/>passenger(0.60)<br/>boeing(0.60)<br/>jet(0.60)", "pred answer": "private", "question_id": 5047695, "best approach": "wiki", "verif answer": "jet", "anno approach": "wiki, concept, image", "verif wiki answer": "private jet(0.7166)", "verif concept answer": "jet(0.7207)", "verif image answer": "passenger(0.6640)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000504769.jpg"}, {"question": "", "gt answer": "daisy(0.60)<br/>lily(0.60)<br/>tulip(0.60)", "pred answer": "rose", "question_id": 1058815, "best approach": "", "verif answer": "rose", "anno approach": "wiki, concept, image", "verif wiki answer": "rose(0.6816)", "verif concept answer": "rose(0.6934)", "verif image answer": "rose(0.6961)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105881.jpg"}, {"question": "how productive could this person be in this work space", "gt answer": "not very(1.00)<br/>disorganized(0.60)<br/>not(0.60)", "pred answer": "very", "question_id": 1683565, "best approach": "concept, image", "verif answer": "very", "anno approach": "wiki, concept, image", "verif wiki answer": "not at all(0.7159)", "verif concept answer": "not very(0.7126)", "verif image answer": "not very(0.7029)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168356.jpg"}, {"question": "what is the weather like outside this window", "gt answer": "sunny(1.00)<br/>clear(0.60)<br/>rainy(0.60)", "pred answer": "cloudy", "question_id": 4378895, "best approach": "image", "verif answer": "clear", "anno approach": "wiki, concept, image", "verif wiki answer": "rainy(0.6981)", "verif concept answer": "rainy(0.6736)", "verif image answer": "sunny(0.5402)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437889.jpg"}, {"question": "what is the role of the person with the bat", "gt answer": "hitter(1.00)<br/>batter(0.60)<br/>baseball player(0.60)", "pred answer": "catcher", "question_id": 2530315, "best approach": "wiki, concept", "verif answer": "batter", "anno approach": "wiki, concept, image", "verif wiki answer": "baseball player(0.7296)", "verif concept answer": "baseball player(0.7273)", "verif image answer": "baseball(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253031.jpg"}, {"question": "what clothing designer 's logo is one of the advertiser 's pictured here", "gt answer": "lacoste(1.00)", "pred answer": "nike", "question_id": 624725, "best approach": "image", "verif answer": "nike", "anno approach": "wiki, concept, image", "verif wiki answer": "nike(0.7225)", "verif concept answer": "nike(0.7190)", "verif image answer": "lacoste(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000062472.jpg"}, {"question": "what type of wine is in the two glasses", "gt answer": "red(1.00)<br/>red wine(0.60)", "pred answer": "white wine", "question_id": 374295, "best approach": "", "verif answer": "red", "anno approach": "wiki, concept, image", "verif wiki answer": "raspberry(0.6429)", "verif concept answer": "raspberry(0.6934)", "verif image answer": "green(0.6610)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000037429.jpg"}, {"question": "is the stetson hat named after a person or place", "gt answer": "person(1.00)", "pred answer": "wild", "question_id": 2335205, "best approach": "wiki, image", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "person(0.7109)", "verif concept answer": "human(0.6893)", "verif image answer": "person(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000233520.jpg"}, {"question": "is this a spare bedroom or is someone staying in it", "gt answer": "spare(1.00)", "pred answer": "private house", "question_id": 1689545, "best approach": "", "verif answer": "both", "anno approach": "wiki, concept, image", "verif wiki answer": "upscale(0.5153)", "verif concept answer": "1 year(0.5090)", "verif image answer": "1 year(0.6410)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168954.jpg"}, {"question": "was this a special or normal event", "gt answer": "special(1.00)<br/>normal(1.00)", "pred answer": "healthy", "question_id": 5767765, "best approach": "concept, image", "verif answer": "special", "anno approach": "wiki, concept, image", "verif wiki answer": "normal kid(0.6624)", "verif concept answer": "special(0.7214)", "verif image answer": "special(0.7067)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000576776.jpg"}, {"question": "what are these painted objects used for", "gt answer": "toilet seat(1.00)<br/>game(0.60)<br/>toilet(0.60)", "pred answer": "shop", "question_id": 5105915, "best approach": "wiki, concept", "verif answer": "toilet", "anno approach": "wiki, concept, image", "verif wiki answer": "toilet seat(0.6115)", "verif concept answer": "toilet seat(0.7088)", "verif image answer": "tv(0.7215)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510591.jpg"}, {"question": "what kind of clock is on the meter", "gt answer": "digital(1.00)", "pred answer": "analog", "question_id": 5263015, "best approach": "wiki", "verif answer": "canon", "anno approach": "wiki, concept, image", "verif wiki answer": "digital(0.6213)", "verif concept answer": "canon(0.6925)", "verif image answer": "kodak(0.6742)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526301.jpg"}, {"question": "what do people do here", "gt answer": "relax(1.00)<br/>swim(0.60)", "pred answer": "tan", "question_id": 613385, "best approach": "wiki", "verif answer": "tan", "anno approach": "wiki, concept, image", "verif wiki answer": "relax(0.6144)", "verif concept answer": "sunbath(0.6855)", "verif image answer": "tan(0.6394)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061338.jpg"}, {"question": "what is material is the polka dotted object on the man 's neck made out of", "gt answer": "silk(1.00)<br/>cotton(0.60)<br/>tie(0.60)", "pred answer": "polyester", "question_id": 5060585, "best approach": "", "verif answer": "polyester", "anno approach": "wiki, concept, image", "verif wiki answer": "flannel(0.7271)", "verif concept answer": "flannel(0.7263)", "verif image answer": "polyester(0.6031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506058.jpg"}, {"question": "what 's popular with gangs", "gt answer": "motorcycle(1.00)<br/>bandana(0.60)", "pred answer": "park", "question_id": 4391855, "best approach": "wiki", "verif answer": "bike", "anno approach": "wiki, concept, image", "verif wiki answer": "motorcycle(0.6374)", "verif concept answer": "parade(0.6963)", "verif image answer": "parade(0.6711)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439185.jpg"}, {"question": "what is this athlete doing", "gt answer": "horseback ride(1.00)<br/>horse(0.60)", "pred answer": "horse jump", "question_id": 3784195, "best approach": "image", "verif answer": "horseback ride", "anno approach": "wiki, concept, image", "verif wiki answer": "equestrian(0.6826)", "verif concept answer": "horse race(0.6921)", "verif image answer": "horse(0.6820)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378419.jpg"}, {"question": "what is the name of the girl who lost her arm in a shark attack while doing this activity", "gt answer": "bethany hamilton(1.00)<br/>surf(0.60)", "pred answer": "kelly slater", "question_id": 3194405, "best approach": "wiki, concept", "verif answer": "bethany hamilton", "anno approach": "wiki, concept, image", "verif wiki answer": "bethany hamilton(0.7218)", "verif concept answer": "bethany hamilton(0.6996)", "verif image answer": "wind surf(0.5471)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319440.jpg"}, {"question": "what utensil is this", "gt answer": "fork(1.00)", "pred answer": "chopstick", "question_id": 3422945, "best approach": "", "verif answer": "spoon", "anno approach": "wiki, concept, image", "verif wiki answer": "fork and knife(0.7290)", "verif concept answer": "fork and knife(0.7103)", "verif image answer": "pie(0.6693)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342294.jpg"}, {"question": "what 's the name of airliner", "gt answer": "southern air(1.00)", "pred answer": "lufthansa", "question_id": 5148255, "best approach": "image", "verif answer": "united", "anno approach": "wiki, concept, image", "verif wiki answer": "american airline(0.6933)", "verif concept answer": "american airline(0.6925)", "verif image answer": "southern air(0.5782)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514825.jpg"}, {"question": "what type of health condition would you say this cow is in", "gt answer": "starvation(1.00)<br/>poor(0.60)", "pred answer": "good", "question_id": 4349515, "best approach": "", "verif answer": "poor", "anno approach": "wiki, concept, image", "verif wiki answer": "bald(0.6561)", "verif concept answer": "bald(0.7176)", "verif image answer": "bald(0.7107)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434951.jpg"}, {"question": "what year is this truck from", "gt answer": "1955(1.00)<br/>1950s(0.60)<br/>1940(0.60)", "pred answer": "1950", "question_id": 4510245, "best approach": "wiki, image", "verif answer": "1930", "anno approach": "wiki, concept, image", "verif wiki answer": "1950s(0.6759)", "verif concept answer": "1970(0.6503)", "verif image answer": "1950s(0.6744)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000451024.jpg"}, {"question": "what do you do with these", "gt answer": "drink(1.00)", "pred answer": "eat", "question_id": 4729005, "best approach": "wiki", "verif answer": "drink", "anno approach": "wiki, concept, image", "verif wiki answer": "drink(0.7145)", "verif concept answer": "take picture(0.7112)", "verif image answer": "drink water(0.5502)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000472900.jpg"}, {"question": "what are the two cruciferous vegetables shown here", "gt answer": "broccoli cauliflower(1.00)", "pred answer": "broccoli", "question_id": 4633055, "best approach": "wiki, concept, image", "verif answer": "broccoli", "anno approach": "wiki, concept, image", "verif wiki answer": "broccoli cauliflower(0.7255)", "verif concept answer": "broccoli cauliflower(0.7217)", "verif image answer": "broccoli cauliflower(0.5887)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463305.jpg"}, {"question": "what type of traveler would this room be suitable for", "gt answer": "business(1.00)<br/>luxury(0.60)", "pred answer": "hospital", "question_id": 2543255, "best approach": "wiki", "verif answer": "business", "anno approach": "wiki, concept, image", "verif wiki answer": "business(0.6237)", "verif concept answer": "online(0.5599)", "verif image answer": "casual(0.5190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000254325.jpg"}, {"question": "would you say that there has been inclement weather for awhile or only recently", "gt answer": "recently(1.00)<br/>awhile(1.00)", "pred answer": "rainy", "question_id": 5576105, "best approach": "wiki", "verif answer": "both", "anno approach": "wiki, concept, image", "verif wiki answer": "recently(0.7042)", "verif concept answer": "today(0.6410)", "verif image answer": "today(0.5481)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557610.jpg"}, {"question": "how was this light effect created", "gt answer": "photoshop(1.00)<br/>computer(0.60)<br/>long exposure(0.60)", "pred answer": "light", "question_id": 4212295, "best approach": "wiki, concept, image", "verif answer": "computer", "anno approach": "wiki, concept, image", "verif wiki answer": "computer(0.7186)", "verif concept answer": "computer(0.6386)", "verif image answer": "long exposure(0.6994)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421229.jpg"}, {"question": "what brand are these motorcycles", "gt answer": "bmw(1.00)<br/>kawasaki(1.00)<br/>yamaha(0.60)", "pred answer": "harley davidson", "question_id": 629585, "best approach": "concept", "verif answer": "bmw", "anno approach": "wiki, concept, image", "verif wiki answer": "yamaha(0.6500)", "verif concept answer": "bmw(0.6511)", "verif image answer": "honda(0.5722)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000062958.jpg"}, {"question": "what kind of event is this", "gt answer": "rally(1.00)<br/>festival(0.60)", "pred answer": "bear", "question_id": 2220865, "best approach": "", "verif answer": "parade", "anno approach": "wiki, concept, image", "verif wiki answer": "parade(0.6406)", "verif concept answer": "parade(0.6790)", "verif image answer": "parade(0.6801)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222086.jpg"}, {"question": "what kind of cake is this", "gt answer": "birthday(1.00)<br/>birthday cake(0.60)", "pred answer": "cupcake", "question_id": 4758125, "best approach": "wiki, concept", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "birthday cake(0.7094)", "verif concept answer": "birthday cake(0.7173)", "verif image answer": "celebration(0.6554)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475812.jpg"}, {"question": "what is the girl doing with the stuffed animal", "gt answer": "hold(1.00)<br/>hug(0.60)", "pred answer": "play", "question_id": 2043785, "best approach": "wiki, concept, image", "verif answer": "play", "anno approach": "wiki, concept, image", "verif wiki answer": "hug(0.7103)", "verif concept answer": "hug(0.7226)", "verif image answer": "hug(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000204378.jpg"}, {"question": "what is the color of the tile in the pic", "gt answer": "beige(1.00)<br/>cream(0.60)<br/>salmon(0.60)", "pred answer": "white", "question_id": 2276635, "best approach": "wiki", "verif answer": "brown", "anno approach": "wiki, concept, image", "verif wiki answer": "beige(0.7120)", "verif concept answer": "salmon(0.6677)", "verif image answer": "brown(0.6814)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000227663.jpg"}, {"question": "what is this boy using a piece of wood for", "gt answer": "bat(1.00)", "pred answer": "hit baseball", "question_id": 4084815, "best approach": "", "verif answer": "hit baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "hit baseball(0.7003)", "verif concept answer": "hit baseball(0.6783)", "verif image answer": "baseball bat(0.6687)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408481.jpg"}, {"question": "what nutrients does the fruit on the plate provide", "gt answer": "vitamin(1.00)<br/>vitamin c(0.60)", "pred answer": "calcium", "question_id": 837536, "best approach": "image", "verif answer": "potassium", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin c(0.7193)", "verif concept answer": "vitamin c(0.6697)", "verif image answer": "vitamin(0.6744)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083753.jpg"}, {"question": "what main nutrient is contained in the green vegetable", "gt answer": "iron(1.00)<br/>calcium(0.60)<br/>vitamin c(0.60)<br/>fiber(0.60)", "pred answer": "vitamin", "question_id": 3988505, "best approach": "wiki, concept, image", "verif answer": "fiber", "anno approach": "wiki, concept, image", "verif wiki answer": "calcium(0.7089)", "verif concept answer": "calcium(0.6904)", "verif image answer": "calcium(0.6722)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398850.jpg"}, {"question": "would the meal shown appeal more to a vegetarian or a meat eater", "gt answer": "vegetarian(1.00)", "pred answer": "healthy", "question_id": 3703295, "best approach": "", "verif answer": "healthy", "anno approach": "wiki, concept, image", "verif wiki answer": "herbivorous(0.7063)", "verif concept answer": "herbivorous(0.6831)", "verif image answer": "herbivorous(0.7164)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370329.jpg"}, {"question": "what type of motorcycle is this", "gt answer": "scooter(1.00)<br/>honda(0.60)", "pred answer": "harley davidson", "question_id": 2833935, "best approach": "wiki", "verif answer": "harley davidson", "anno approach": "wiki, concept, image", "verif wiki answer": "scooter(0.7141)", "verif concept answer": "harley davidson(0.7222)", "verif image answer": "harley davidson(0.7213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283393.jpg"}, {"question": "what sort of relish is often served with this meat", "gt answer": "pickle(1.00)<br/>green(0.60)", "pred answer": "onion", "question_id": 5130275, "best approach": "wiki", "verif answer": "pickle", "anno approach": "wiki, concept, image", "verif wiki answer": "pickle(0.7172)", "verif concept answer": "arugula(0.7274)", "verif image answer": "spinach(0.6561)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513027.jpg"}, {"question": "what type of boat can you see in the picture", "gt answer": "houseboat(1.00)<br/>boat(0.60)", "pred answer": "barge", "question_id": 796805, "best approach": "", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "tugboat(0.6989)", "verif concept answer": "tugboat(0.7057)", "verif image answer": "tugboat(0.6830)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079680.jpg"}, {"question": "what type of writing instrument would be used for the writings on this street", "gt answer": "marker(1.00)<br/>chalk(1.00)", "pred answer": "graffiti", "question_id": 4281425, "best approach": "", "verif answer": "marker", "anno approach": "wiki, concept, image", "verif wiki answer": "fence post(0.6519)", "verif concept answer": "fence post(0.5208)", "verif image answer": "chinese(0.5122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428142.jpg"}, {"question": "what is one name for an apartment that looks like this", "gt answer": "studio(1.00)<br/>micro(0.60)", "pred answer": "home", "question_id": 973715, "best approach": "wiki", "verif answer": "house", "anno approach": "wiki, concept, image", "verif wiki answer": "studio(0.7030)", "verif concept answer": "hotel(0.6588)", "verif image answer": "hotel(0.6943)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097371.jpg"}, {"question": "how many jets does this airplane have", "gt answer": "3(1.00)<br/>2(1.00)", "pred answer": "300", "question_id": 5218945, "best approach": "wiki", "verif answer": "4", "anno approach": "wiki, concept, image", "verif wiki answer": "3(0.7135)", "verif concept answer": "1(0.6744)", "verif image answer": "5(0.6404)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521894.jpg"}, {"question": "where does this guy work at", "gt answer": "geek squad(1.00)", "pred answer": "home", "question_id": 1530365, "best approach": "wiki", "verif answer": "microsoft", "anno approach": "wiki, concept, image", "verif wiki answer": "geek squad(0.7051)", "verif concept answer": "microsoft(0.6339)", "verif image answer": "microsoft(0.6346)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153036.jpg"}, {"question": "where can i buy a backpack like that", "gt answer": "pet store(1.00)", "pred answer": "walmart", "question_id": 886715, "best approach": "", "verif answer": "store", "anno approach": "wiki, concept, image", "verif wiki answer": "store(0.6979)", "verif concept answer": "store(0.6447)", "verif image answer": "football(0.6775)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088671.jpg"}, {"question": "what can this hold", "gt answer": "cloth(1.00)<br/>money(0.60)<br/>paper(0.60)", "pred answer": "people", "question_id": 3202535, "best approach": "wiki, concept, image", "verif answer": "cloth", "anno approach": "wiki, concept, image", "verif wiki answer": "money(0.6640)", "verif concept answer": "money(0.7116)", "verif image answer": "money(0.6182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320253.jpg"}, {"question": "what material makes up this court 's surface", "gt answer": "asphalt(1.00)<br/>stone(0.60)<br/>cement(0.60)", "pred answer": "concrete", "question_id": 3358025, "best approach": "", "verif answer": "concrete", "anno approach": "wiki, concept, image", "verif wiki answer": "concrete(0.7133)", "verif concept answer": "concrete(0.7039)", "verif image answer": "concrete(0.5927)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335802.jpg"}, {"question": "where can you usually find this animal", "gt answer": "house(1.00)<br/>home(0.60)", "pred answer": "bedroom", "question_id": 3896735, "best approach": "wiki", "verif answer": "home", "anno approach": "wiki, concept, image", "verif wiki answer": "home(0.6722)", "verif concept answer": "dinner(0.6330)", "verif image answer": "hotel(0.6334)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000389673.jpg"}, {"question": "what is the purpose of the big screen", "gt answer": "score(1.00)", "pred answer": "game", "question_id": 330915, "best approach": "image", "verif answer": "game", "anno approach": "wiki, concept, image", "verif wiki answer": "watch(0.6916)", "verif concept answer": "serve(0.6997)", "verif image answer": "score(0.5583)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033091.jpg"}, {"question": "what type of shop is it according to the white item on the sign", "gt answer": "tea room(1.00)<br/>tea(1.00)", "pred answer": "newspaper", "question_id": 3990975, "best approach": "wiki, concept, image", "verif answer": "starbucks", "anno approach": "wiki, concept, image", "verif wiki answer": "tea room(0.5589)", "verif concept answer": "tea room(0.6744)", "verif image answer": "tea(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399097.jpg"}, {"question": "when did this type of transportation originate", "gt answer": "1662(1.00)<br/>1950s(0.60)<br/>1930(0.60)", "pred answer": "1804", "question_id": 1369795, "best approach": "wiki, concept", "verif answer": "1930", "anno approach": "wiki, concept, image", "verif wiki answer": "1930(0.6361)", "verif concept answer": "1930(0.6918)", "verif image answer": "2000(0.5670)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000136979.jpg"}, {"question": "what type of dog is in this picture", "gt answer": "golden retriever(1.00)<br/>shepard(0.60)", "pred answer": "dalmation", "question_id": 799125, "best approach": "", "verif answer": "labrador", "anno approach": "wiki, concept, image", "verif wiki answer": "beagle(0.7290)", "verif concept answer": "german shepherd(0.6175)", "verif image answer": "beagle(0.6816)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079912.jpg"}, {"question": "", "gt answer": "abdominal(0.60)<br/>leg(0.60)<br/>stomach(0.60)", "pred answer": "arm", "question_id": 3424325, "best approach": "wiki, concept", "verif answer": "leg", "anno approach": "wiki, concept, image", "verif wiki answer": "abdominal(0.5632)", "verif concept answer": "abdominal(0.6254)", "verif image answer": "torso(0.5473)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342432.jpg"}, {"question": "which type of boat is roared in this picture", "gt answer": "canoe(1.00)<br/>pontoon(0.60)<br/>fish(0.60)<br/>row(0.60)", "pred answer": "raft", "question_id": 117025, "best approach": "concept", "verif answer": "canoe", "anno approach": "wiki, concept, image", "verif wiki answer": "fish(0.6131)", "verif concept answer": "canoe(0.6337)", "verif image answer": "fish(0.6601)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011702.jpg"}, {"question": "what type of vegetable was linked to an e coli outbreak in early 2018", "gt answer": "lettuce(1.00)<br/>spinach(0.60)", "pred answer": "carrot", "question_id": 2218945, "best approach": "", "verif answer": "broccoli", "anno approach": "wiki, concept, image", "verif wiki answer": "broccoli(0.7103)", "verif concept answer": "broccoli(0.7226)", "verif image answer": "broccoli(0.6644)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221894.jpg"}, {"question": "what is normally dispensed within the contents of this box", "gt answer": "newspaper(1.00)<br/>food(0.60)", "pred answer": "money", "question_id": 1957725, "best approach": "wiki", "verif answer": "cloth", "anno approach": "wiki, concept, image", "verif wiki answer": "newspaper(0.6288)", "verif concept answer": "cloth(0.6930)", "verif image answer": "pizza(0.7147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195772.jpg"}, {"question": "what type of material is the sink made of", "gt answer": "granite(1.00)<br/>marble(0.60)", "pred answer": "ceramic", "question_id": 4489175, "best approach": "", "verif answer": "copper", "anno approach": "wiki, concept, image", "verif wiki answer": "formica(0.7212)", "verif concept answer": "formica(0.7258)", "verif image answer": "formica(0.6767)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448917.jpg"}, {"question": "how can i find the closest vietnam vet memorial cemetery near me", "gt answer": "google(1.00)<br/>sign(1.00)", "pred answer": "all way", "question_id": 1937325, "best approach": "wiki, image", "verif answer": "sign", "anno approach": "wiki, concept, image", "verif wiki answer": "sign(0.6836)", "verif concept answer": "graffiti(0.6967)", "verif image answer": "sign(0.7223)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193732.jpg"}, {"question": "what looks like it increases the temperature here", "gt answer": "sun(1.00)", "pred answer": "gravity", "question_id": 4855025, "best approach": "wiki, image", "verif answer": "sunlight", "anno approach": "wiki, concept, image", "verif wiki answer": "sun(0.7257)", "verif concept answer": "sun protection(0.6459)", "verif image answer": "sun(0.5420)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485502.jpg"}, {"question": "what is the meaning of this sign in regards to driving", "gt answer": "1 way(1.00)", "pred answer": "direction", "question_id": 258855, "best approach": "wiki, image", "verif answer": "direction", "anno approach": "wiki, concept, image", "verif wiki answer": "1 way(0.6061)", "verif concept answer": "no entry(0.6888)", "verif image answer": "1 way(0.6706)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025885.jpg"}, {"question": "what is the device shown used for", "gt answer": "park meter(1.00)", "pred answer": "traffic control", "question_id": 2226295, "best approach": "", "verif answer": "park", "anno approach": "wiki, concept, image", "verif wiki answer": "park(0.7025)", "verif concept answer": "park(0.6679)", "verif image answer": "meter(0.7149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222629.jpg"}, {"question": "what is the max speed of this type of aircraft", "gt answer": "564 mph(1.00)<br/>300 mph(0.60)<br/>500 mph(0.60)", "pred answer": "150 mph", "question_id": 1928275, "best approach": "wiki, concept", "verif answer": "500 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "564 mph(0.7290)", "verif concept answer": "564 mph(0.7295)", "verif image answer": "300 mph(0.6983)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000192827.jpg"}, {"question": "what 's big and grand that people go to see on vacation", "gt answer": "grand canyon(1.00)", "pred answer": "rock", "question_id": 4847695, "best approach": "", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "mountain(0.6511)", "verif concept answer": "europe(0.5965)", "verif image answer": "peru(0.5945)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484769.jpg"}, {"question": "what type of paint is used to make graffiti", "gt answer": "spray(1.00)<br/>spray paint(1.00)", "pred answer": "graffiti", "question_id": 2907615, "best approach": "wiki", "verif answer": "graffiti", "anno approach": "wiki, concept, image", "verif wiki answer": "spray paint(0.6882)", "verif concept answer": "graffiti(0.6936)", "verif image answer": "plastic(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000290761.jpg"}, {"question": "what type of dog is seen here", "gt answer": "dalmatian(1.00)<br/>dalmation(1.00)", "pred answer": "golden retriever", "question_id": 2389945, "best approach": "wiki, concept, image", "verif answer": "dalmation", "anno approach": "wiki, concept, image", "verif wiki answer": "dalmatian(0.6995)", "verif concept answer": "dalmation(0.6998)", "verif image answer": "dalmation(0.6764)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238994.jpg"}, {"question": "what is there a lot of here", "gt answer": "pedestrian(1.00)<br/>traffic(0.60)", "pred answer": "book", "question_id": 1612295, "best approach": "wiki, image", "verif answer": "traffic", "anno approach": "wiki, concept, image", "verif wiki answer": "pedestrian(0.6784)", "verif concept answer": "traffic(0.6730)", "verif image answer": "pedestrian(0.5474)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161229.jpg"}, {"question": "what is the name of someone who competes in this sport", "gt answer": "cowboy(1.00)<br/>equestrian(0.60)", "pred answer": "jockey", "question_id": 1821265, "best approach": "", "verif answer": "polo", "anno approach": "wiki, concept, image", "verif wiki answer": "polo(0.6902)", "verif concept answer": "fedora(0.7257)", "verif image answer": "fedora(0.5176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182126.jpg"}, {"question": "what problems will horses have when walking on sand", "gt answer": "sink(1.00)<br/>run(0.60)", "pred answer": "drown", "question_id": 2578755, "best approach": "wiki, concept, image", "verif answer": "gallop", "anno approach": "wiki, concept, image", "verif wiki answer": "run(0.7301)", "verif concept answer": "run(0.7294)", "verif image answer": "run(0.7272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257875.jpg"}, {"question": "what type of dog is this", "gt answer": "shitzu(1.00)<br/>terrier(0.60)<br/>poodle(0.60)", "pred answer": "pug", "question_id": 669765, "best approach": "wiki", "verif answer": "poodle", "anno approach": "wiki, concept, image", "verif wiki answer": "poodle(0.7203)", "verif concept answer": "chihuahua(0.7194)", "verif image answer": "chihuahua(0.6888)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000066976.jpg"}, {"question": "what will happen to this person soon", "gt answer": "crash(1.00)<br/>surf(0.60)", "pred answer": "drown", "question_id": 1509315, "best approach": "", "verif answer": "wave", "anno approach": "wiki, concept, image", "verif wiki answer": "wave(0.7104)", "verif concept answer": "wave(0.6078)", "verif image answer": "crest(0.6848)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000150931.jpg"}, {"question": "what type of airplane is this", "gt answer": "commercial(1.00)<br/>passenger(0.60)", "pred answer": "747", "question_id": 877265, "best approach": "image", "verif answer": "747", "anno approach": "wiki, concept, image", "verif wiki answer": "747(0.7128)", "verif concept answer": "passenger(0.6887)", "verif image answer": "commercial(0.5844)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087726.jpg"}, {"question": "what radio station is on", "gt answer": "book radio(1.00)", "pred answer": "news", "question_id": 4394935, "best approach": "", "verif answer": "day today", "anno approach": "wiki, concept, image", "verif wiki answer": "cell phone(0.5531)", "verif concept answer": "day today(0.7105)", "verif image answer": "day today(0.7151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439493.jpg"}, {"question": "is this in europe or america", "gt answer": "america(1.00)<br/>europe(1.00)", "pred answer": "france", "question_id": 5408825, "best approach": "", "verif answer": "america", "anno approach": "wiki, concept, image", "verif wiki answer": "japan(0.6530)", "verif concept answer": "usa(0.6759)", "verif image answer": "japan(0.5909)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540882.jpg"}, {"question": "what kind of boat is this", "gt answer": "canoe(1.00)<br/>fish(0.60)", "pred answer": "canoes", "question_id": 3029005, "best approach": "image", "verif answer": "row boat", "anno approach": "wiki, concept, image", "verif wiki answer": "row boat(0.7201)", "verif concept answer": "pontoon(0.7098)", "verif image answer": "fish(0.6564)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302900.jpg"}, {"question": "what kind of headwear are these people wearing", "gt answer": "turban(1.00)<br/>cap(0.60)<br/>hijab(0.60)", "pred answer": "hat", "question_id": 816765, "best approach": "", "verif answer": "hat", "anno approach": "wiki, concept, image", "verif wiki answer": "hat(0.7227)", "verif concept answer": "beanie(0.7288)", "verif image answer": "hat(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081676.jpg"}, {"question": "what brand is this truck", "gt answer": "isuzu(1.00)", "pred answer": "ford", "question_id": 4386635, "best approach": "wiki, image", "verif answer": "ford", "anno approach": "wiki, concept, image", "verif wiki answer": "isuzu(0.7192)", "verif concept answer": "ford(0.7186)", "verif image answer": "isuzu(0.7154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000438663.jpg"}, {"question": "what breed of dogs are these", "gt answer": "bulldog(1.00)<br/>pug(0.60)<br/>pitbull(0.60)", "pred answer": "lab", "question_id": 2980805, "best approach": "image", "verif answer": "labrador", "anno approach": "wiki, concept, image", "verif wiki answer": "pitbull(0.7132)", "verif concept answer": "labrador(0.7215)", "verif image answer": "bulldog(0.6419)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000298080.jpg"}, {"question": "what are the occasion these people are celebrating", "gt answer": "anniversary(1.00)<br/>christmas(1.00)", "pred answer": "birthday", "question_id": 2618435, "best approach": "wiki, image", "verif answer": "easter", "anno approach": "wiki, concept, image", "verif wiki answer": "anniversary(0.6994)", "verif concept answer": "holiday(0.6723)", "verif image answer": "anniversary(0.5663)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261843.jpg"}, {"question": "what time era does this photo appear to be from", "gt answer": "20's(1.00)<br/>1800(0.60)", "pred answer": "1800s", "question_id": 5006755, "best approach": "", "verif answer": "1950's", "anno approach": "wiki, concept, image", "verif wiki answer": "1930(0.6391)", "verif concept answer": "1930(0.6744)", "verif image answer": "16(0.5955)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500675.jpg"}, {"question": "what store did the drink cup come from", "gt answer": "7 11(1.00)<br/>7 eleven(0.60)", "pred answer": "walmart", "question_id": 2484615, "best approach": "", "verif answer": "coca cola", "anno approach": "wiki, concept, image", "verif wiki answer": "coca cola(0.6220)", "verif concept answer": "coca cola(0.7227)", "verif image answer": "coca cola(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248461.jpg"}, {"question": "what kind of laptop does she have", "gt answer": "toshiba(1.00)", "pred answer": "macbook", "question_id": 1939475, "best approach": "", "verif answer": "dell", "anno approach": "wiki, concept, image", "verif wiki answer": "dell(0.6953)", "verif concept answer": "flatscreen(0.7186)", "verif image answer": "ford(0.7097)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193947.jpg"}, {"question": "what kind of utensil is being used", "gt answer": "fork(1.00)", "pred answer": "chopstick", "question_id": 56195, "best approach": "wiki", "verif answer": "spoon", "anno approach": "wiki, concept, image", "verif wiki answer": "fork(0.6648)", "verif concept answer": "spoon(0.6277)", "verif image answer": "right fork(0.6823)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005619.jpg"}, {"question": "what sport is this vehicle used for", "gt answer": "offroading(1.00)<br/>monster truck(0.60)", "pred answer": "construction", "question_id": 5355265, "best approach": "wiki, concept", "verif answer": "monster truck", "anno approach": "wiki, concept, image", "verif wiki answer": "monster truck(0.6824)", "verif concept answer": "monster truck(0.6789)", "verif image answer": "monster truck rally(0.6898)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535526.jpg"}, {"question": "what kind of shoes go with those clothes", "gt answer": "dress(1.00)<br/>loafer(0.60)<br/>dark(0.60)", "pred answer": "boot", "question_id": 4700365, "best approach": "image", "verif answer": "dark", "anno approach": "wiki, concept, image", "verif wiki answer": "dark(0.7199)", "verif concept answer": "dark(0.7121)", "verif image answer": "dress(0.6799)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470036.jpg"}, {"question": "what kind of truck do you see", "gt answer": "bucket truck(1.00)<br/>crane(0.60)<br/>utility(0.60)", "pred answer": "dump", "question_id": 3556575, "best approach": "wiki, concept, image", "verif answer": "utility", "anno approach": "wiki, concept, image", "verif wiki answer": "bucket truck(0.6989)", "verif concept answer": "bucket truck(0.6772)", "verif image answer": "bucket truck(0.7042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355657.jpg"}, {"question": "what state does the plant look like", "gt answer": "texas(1.00)", "pred answer": "idaho", "question_id": 709835, "best approach": "", "verif answer": "florida", "anno approach": "wiki, concept, image", "verif wiki answer": "south(0.6323)", "verif concept answer": "south(0.6914)", "verif image answer": "south(0.5351)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070983.jpg"}, {"question": "how is the object in the background floating", "gt answer": "kite(1.00)<br/>string(0.60)<br/>wind(0.60)", "pred answer": "parachute", "question_id": 1448325, "best approach": "wiki", "verif answer": "kite", "anno approach": "wiki, concept, image", "verif wiki answer": "kite(0.6439)", "verif concept answer": "fly kite(0.6846)", "verif image answer": "string(0.7204)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144832.jpg"}, {"question": "in which stadium does this scene take place", "gt answer": "baseball stadium(1.00)<br/>baseball(0.60)", "pred answer": "wimbledon", "question_id": 654255, "best approach": "", "verif answer": "baseball stadium", "anno approach": "wiki, concept, image", "verif wiki answer": "baseball field(0.6569)", "verif concept answer": "baseball field(0.7090)", "verif image answer": "dirt(0.5155)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065425.jpg"}, {"question": "what breed of dog is in this photo", "gt answer": "bulldog(1.00)", "pred answer": "golden retriever", "question_id": 2951035, "best approach": "", "verif answer": "pug", "anno approach": "wiki, concept, image", "verif wiki answer": "pug(0.7023)", "verif concept answer": "pug(0.7178)", "verif image answer": "pug(0.5748)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295103.jpg"}, {"question": "what is the primary habitat of this flower", "gt answer": "garden(1.00)<br/>dirt(0.60)<br/>ground(0.60)", "pred answer": "africa", "question_id": 2722115, "best approach": "wiki", "verif answer": "garden", "anno approach": "wiki, concept, image", "verif wiki answer": "garden(0.6800)", "verif concept answer": "ground(0.6744)", "verif image answer": "ground(0.6685)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000272211.jpg"}, {"question": "is this a new or old vehicle", "gt answer": "old(1.00)", "pred answer": "vintage", "question_id": 5611265, "best approach": "wiki", "verif answer": "old", "anno approach": "wiki, concept, image", "verif wiki answer": "old(0.7217)", "verif concept answer": "antique(0.7020)", "verif image answer": "led(0.5698)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561126.jpg"}, {"question": "what kind of bird", "gt answer": "hummingbird(1.00)<br/>hum(0.60)<br/>hum bird(0.60)", "pred answer": "robin", "question_id": 924455, "best approach": "", "verif answer": "sparrow", "anno approach": "wiki, concept, image", "verif wiki answer": "sparrow(0.6604)", "verif concept answer": "sparrow(0.6625)", "verif image answer": "sparrow(0.6533)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092445.jpg"}, {"question": "what is the source of light in this picture", "gt answer": "sun(1.00)<br/>window(1.00)", "pred answer": "overhead", "question_id": 1817715, "best approach": "concept, image", "verif answer": "lamp", "anno approach": "wiki, concept, image", "verif wiki answer": "sunlight(0.6859)", "verif concept answer": "sun(0.6465)", "verif image answer": "sun(0.6552)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181771.jpg"}, {"question": "what activity are these boys taking part in", "gt answer": "pet(1.00)<br/>rodeo(0.60)<br/>shear(0.60)", "pred answer": "herd", "question_id": 2766395, "best approach": "wiki", "verif answer": "herd", "anno approach": "wiki, concept, image", "verif wiki answer": "pet(0.7041)", "verif concept answer": "circus(0.6544)", "verif image answer": "herd(0.6908)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276639.jpg"}, {"question": "what happened to the players bat", "gt answer": "broke(1.00)<br/>thrown(0.60)<br/>broken(0.60)", "pred answer": "hit", "question_id": 3799405, "best approach": "wiki, image", "verif answer": "thrown", "anno approach": "wiki, concept, image", "verif wiki answer": "broken(0.6946)", "verif concept answer": "fell(0.7210)", "verif image answer": "thrown(0.5711)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379940.jpg"}, {"question": "where would i find this room", "gt answer": "jail(1.00)<br/>prison(1.00)", "pred answer": "bathroom", "question_id": 4106225, "best approach": "", "verif answer": "hardware store", "anno approach": "wiki, concept, image", "verif wiki answer": "hardware store(0.7301)", "verif concept answer": "hardware store(0.7269)", "verif image answer": "hardware store(0.6929)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000410622.jpg"}, {"question": "what object in the picture amplifies your voice", "gt answer": "microphone(1.00)", "pred answer": "music", "question_id": 5292405, "best approach": "wiki, image", "verif answer": "microphone", "anno approach": "wiki, concept, image", "verif wiki answer": "microphone(0.7047)", "verif concept answer": "guitar(0.7113)", "verif image answer": "microphone(0.6805)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529240.jpg"}, {"question": "what type of food is in the image", "gt answer": "vegetable(1.00)", "pred answer": "asian", "question_id": 3389885, "best approach": "", "verif answer": "vegetable", "anno approach": "wiki, concept, image", "verif wiki answer": "kale(0.6616)", "verif concept answer": "veggies(0.7198)", "verif image answer": "carrot and cauliflower(0.7241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338988.jpg"}, {"question": "what character is that", "gt answer": "mickey mouse(1.00)", "pred answer": "pac man", "question_id": 5473785, "best approach": "wiki, concept, image", "verif answer": "mickey mouse", "anno approach": "wiki, concept, image", "verif wiki answer": "mickey mouse(0.7302)", "verif concept answer": "mickey mouse(0.7267)", "verif image answer": "mickey mouse(0.7226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000547378.jpg"}, {"question": "what is the name of this clock", "gt answer": "big ben(1.00)", "pred answer": "analog", "question_id": 736855, "best approach": "wiki, concept, image", "verif answer": "big ben", "anno approach": "wiki, concept, image", "verif wiki answer": "big ben(0.7116)", "verif concept answer": "big ben(0.7065)", "verif image answer": "big ben(0.6048)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073685.jpg"}, {"question": "where can that toilet seat be bought", "gt answer": "low(1.00)<br/>hardware store(0.60)<br/>home depot(0.60)", "pred answer": "walmart", "question_id": 1522095, "best approach": "image", "verif answer": "walmart", "anno approach": "wiki, concept, image", "verif wiki answer": "walmart(0.7113)", "verif concept answer": "walmart(0.7173)", "verif image answer": "hardware store(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000152209.jpg"}, {"question": "why does she have a towel on her head", "gt answer": "wet hair(1.00)<br/>dry(0.60)", "pred answer": "clean teeth", "question_id": 1479635, "best approach": "wiki, concept", "verif answer": "dry hand", "anno approach": "wiki, concept, image", "verif wiki answer": "wet hair(0.7295)", "verif concept answer": "wet hair(0.7296)", "verif image answer": "dry hand(0.6690)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147963.jpg"}, {"question": "what is the material used on the exterior of the fireplace", "gt answer": "marble(1.00)<br/>stone(0.60)", "pred answer": "brick", "question_id": 4651375, "best approach": "image", "verif answer": "stone", "anno approach": "wiki, concept, image", "verif wiki answer": "tile(0.6931)", "verif concept answer": "tile(0.6902)", "verif image answer": "stone(0.7045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465137.jpg"}, {"question": "what law may he be breaking", "gt answer": "trespass(1.00)<br/>safety(0.60)", "pred answer": "0", "question_id": 1721965, "best approach": "wiki", "verif answer": "safety", "anno approach": "wiki, concept, image", "verif wiki answer": "safety(0.7077)", "verif concept answer": "air force 1(0.6785)", "verif image answer": "air force 1(0.6851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000172196.jpg"}, {"question": "what is that counter top made of", "gt answer": "marble(1.00)<br/>fiberglass(0.60)", "pred answer": "granite", "question_id": 1082545, "best approach": "image", "verif answer": "marble", "anno approach": "wiki, concept, image", "verif wiki answer": "stone(0.7042)", "verif concept answer": "fiberglass(0.7198)", "verif image answer": "marble(0.6939)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108254.jpg"}, {"question": "what kind of sandwhiches are those", "gt answer": "sub(1.00)<br/>deli(0.60)", "pred answer": "steak", "question_id": 4900995, "best approach": "", "verif answer": "meatball", "anno approach": "wiki, concept, image", "verif wiki answer": "meatball(0.7299)", "verif concept answer": "meatball(0.7283)", "verif image answer": "meatball(0.6516)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490099.jpg"}, {"question": "who invented the colorful objects in the image", "gt answer": "samuel fox(1.00)", "pred answer": "ben franklin", "question_id": 4713755, "best approach": "wiki, image", "verif answer": "ben franklin", "anno approach": "wiki, concept, image", "verif wiki answer": "samuel fox(0.7201)", "verif concept answer": "ben franklin(0.7067)", "verif image answer": "samuel fox(0.6710)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471375.jpg"}, {"question": "what is the penalty for abusing one of these in the united states", "gt answer": "jail(1.00)<br/>5 years(0.60)", "pred answer": "fine", "question_id": 3662405, "best approach": "", "verif answer": "fine", "anno approach": "wiki, concept, image", "verif wiki answer": "prison(0.6737)", "verif concept answer": "fine(0.6808)", "verif image answer": "fine(0.6105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366240.jpg"}, {"question": "the horse seen here has a friend that is shaped like a stick of gum called what", "gt answer": "gumby(1.00)", "pred answer": "teddy bear", "question_id": 94795, "best approach": "wiki, concept", "verif answer": "ice", "anno approach": "wiki, concept, image", "verif wiki answer": "gumby(0.6685)", "verif concept answer": "gumby(0.7184)", "verif image answer": "1977(0.6727)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009479.jpg"}, {"question": "what kind of bird is this", "gt answer": "finch(1.00)<br/>sparrow(0.60)", "pred answer": "robin", "question_id": 1470945, "best approach": "", "verif answer": "robin", "anno approach": "wiki, concept, image", "verif wiki answer": "wren(0.6818)", "verif concept answer": "robin(0.6762)", "verif image answer": "wren(0.6885)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147094.jpg"}, {"question": "is this a home or work setting", "gt answer": "work(1.00)", "pred answer": "home", "question_id": 1602145, "best approach": "", "verif answer": "office", "anno approach": "wiki, concept, image", "verif wiki answer": "office(0.6963)", "verif concept answer": "office(0.6295)", "verif image answer": "office(0.6873)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160214.jpg"}, {"question": "what race is this man", "gt answer": "caucasian(1.00)<br/>white(0.60)", "pred answer": "indian", "question_id": 5092355, "best approach": "concept", "verif answer": "white", "anno approach": "wiki, concept, image", "verif wiki answer": "british(0.7194)", "verif concept answer": "white(0.6267)", "verif image answer": "british(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509235.jpg"}, {"question": "what kind of airplane is this", "gt answer": "private jet(1.00)<br/>propeller(0.60)<br/>passenger(0.60)", "pred answer": "biplane", "question_id": 5417025, "best approach": "wiki, concept", "verif answer": "passenger", "anno approach": "wiki, concept, image", "verif wiki answer": "private jet(0.7175)", "verif concept answer": "private jet(0.7119)", "verif image answer": "passenger(0.6368)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541702.jpg"}, {"question": "how long is this", "gt answer": "12 inches(1.00)<br/>6 inches(0.60)<br/>foot(0.60)", "pred answer": "15 minutes", "question_id": 5252125, "best approach": "wiki", "verif answer": "8 inches", "anno approach": "wiki, concept, image", "verif wiki answer": "foot(0.6521)", "verif concept answer": "8 inches(0.6400)", "verif image answer": "8 inches(0.6859)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000525212.jpg"}, {"question": "what type of food is this called that 's on a stick", "gt answer": "corndog(1.00)", "pred answer": "hot dog", "question_id": 1100895, "best approach": "", "verif answer": "hot dog", "anno approach": "wiki, concept, image", "verif wiki answer": "hot dog(0.6946)", "verif concept answer": "hotdog(0.7119)", "verif image answer": "chicago(0.6892)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000110089.jpg"}, {"question": "what type of asian cuisine is this", "gt answer": "lo mein(1.00)<br/>mandarin(0.60)<br/>ramen(0.60)", "pred answer": "asian", "question_id": 4538025, "best approach": "", "verif answer": "italian", "anno approach": "wiki, concept, image", "verif wiki answer": "italian(0.6784)", "verif concept answer": "italian(0.6774)", "verif image answer": "wheat(0.6970)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453802.jpg"}, {"question": "is this a normal or extreme sport", "gt answer": "extreme(1.00)<br/>normal(1.00)", "pred answer": "atypical", "question_id": 314655, "best approach": "wiki, concept, image", "verif answer": "extreme", "anno approach": "wiki, concept, image", "verif wiki answer": "extreme(0.7222)", "verif concept answer": "extreme(0.7178)", "verif image answer": "extreme(0.5900)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000031465.jpg"}, {"question": "what country is in the name of this rolled bread", "gt answer": "france(1.00)<br/>italy(0.60)<br/>french(0.60)", "pred answer": "america", "question_id": 5289715, "best approach": "wiki, image", "verif answer": "france", "anno approach": "wiki, concept, image", "verif wiki answer": "french(0.7028)", "verif concept answer": "venice(0.6502)", "verif image answer": "italy(0.6542)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528971.jpg"}, {"question": "what is the boy in the background doing", "gt answer": "boogie board(1.00)<br/>surf(1.00)<br/>swim(0.60)", "pred answer": "paddle board", "question_id": 1911595, "best approach": "wiki, image", "verif answer": "swim", "anno approach": "wiki, concept, image", "verif wiki answer": "swim(0.6524)", "verif concept answer": "surfboard(0.6389)", "verif image answer": "swim(0.6704)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191159.jpg"}, {"question": "how thick is the skin of these animals", "gt answer": "1 inch(1.00)", "pred answer": "2.5 cm", "question_id": 2691995, "best approach": "", "verif answer": "2.5 cm", "anno approach": "wiki, concept, image", "verif wiki answer": "2.5 cm(0.6945)", "verif concept answer": "2.5 cm(0.7258)", "verif image answer": "2 inches(0.7005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269199.jpg"}, {"question": "what type of license would the person operating this vehicle need", "gt answer": "cdl(1.00)<br/>bus(0.60)", "pred answer": "driver", "question_id": 2250415, "best approach": "", "verif answer": "driver", "anno approach": "wiki, concept, image", "verif wiki answer": "driver(0.7195)", "verif concept answer": "driver(0.6945)", "verif image answer": "commercial(0.6970)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225041.jpg"}, {"question": "is this room better for baking a cake or taking a shower", "gt answer": "bake(1.00)<br/>cake(0.60)", "pred answer": "mess", "question_id": 3649175, "best approach": "concept", "verif answer": "bake", "anno approach": "wiki, concept, image", "verif wiki answer": "cookies(0.6898)", "verif concept answer": "bake(0.6906)", "verif image answer": "bake it(0.5069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364917.jpg"}, {"question": "how is the vehicle in the picture manufactured", "gt answer": "weld(1.00)", "pred answer": "bicycle", "question_id": 486825, "best approach": "", "verif answer": "schwinn", "anno approach": "wiki, concept, image", "verif wiki answer": "schwinn(0.6464)", "verif concept answer": "artist(0.6459)", "verif image answer": "schwinn(0.5521)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048682.jpg"}, {"question": "what is the green fruit on the plate", "gt answer": "kiwi(1.00)", "pred answer": "banana", "question_id": 5069655, "best approach": "", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "banana(0.6829)", "verif concept answer": "apple(0.6123)", "verif image answer": "apple(0.5263)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506965.jpg"}, {"question": "what are the most popular countries for this sport", "gt answer": "brazil(1.00)<br/>france(0.60)", "pred answer": "america", "question_id": 4082725, "best approach": "concept, image", "verif answer": "france", "anno approach": "wiki, concept, image", "verif wiki answer": "thailand(0.7195)", "verif concept answer": "france(0.6736)", "verif image answer": "france(0.6708)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408272.jpg"}, {"question": "what material are these couches made of", "gt answer": "microfiber(1.00)<br/>polyester(0.60)", "pred answer": "fabric", "question_id": 2206885, "best approach": "wiki, concept, image", "verif answer": "fabric", "anno approach": "wiki, concept, image", "verif wiki answer": "polyester(0.7160)", "verif concept answer": "polyester(0.7255)", "verif image answer": "polyester(0.7142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220688.jpg"}, {"question": "what song would people sing on this occasion", "gt answer": "happy birthday(1.00)", "pred answer": "bohemian rhapsody", "question_id": 3437995, "best approach": "concept", "verif answer": "english", "anno approach": "wiki, concept, image", "verif wiki answer": "bake(0.5436)", "verif concept answer": "happy birthday(0.5819)", "verif image answer": "english(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343799.jpg"}, {"question": "levi is a popular brand of what item shown here", "gt answer": "jean(1.00)", "pred answer": "gucci", "question_id": 4578685, "best approach": "", "verif answer": "levis", "anno approach": "wiki, concept, image", "verif wiki answer": "levis(0.7124)", "verif concept answer": "levis(0.6043)", "verif image answer": "levis(0.6947)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457868.jpg"}, {"question": "what landmark is below the plane", "gt answer": "grand canyon(1.00)", "pred answer": "mountain", "question_id": 3872485, "best approach": "", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "mountain(0.7258)", "verif concept answer": "mount everest(0.7008)", "verif image answer": "mountain(0.6014)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387248.jpg"}, {"question": "what do these signs tell a driver", "gt answer": "street name(1.00)<br/>direct(0.60)", "pred answer": "direction", "question_id": 5742075, "best approach": "wiki, concept", "verif answer": "direction", "anno approach": "wiki, concept, image", "verif wiki answer": "direct(0.7271)", "verif concept answer": "direct(0.7062)", "verif image answer": "direction(0.7081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000574207.jpg"}, {"question": "what is this animal doing", "gt answer": "lay down(1.00)<br/>relax(0.60)<br/>rest(0.60)", "pred answer": "sleep", "question_id": 490625, "best approach": "wiki, concept", "verif answer": "relax", "anno approach": "wiki, concept, image", "verif wiki answer": "lay down(0.7124)", "verif concept answer": "lay down(0.7120)", "verif image answer": "warmth(0.5799)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049062.jpg"}, {"question": "what types of fruits are there", "gt answer": "apple(1.00)", "pred answer": "orange", "question_id": 804955, "best approach": "concept, image", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "peach(0.7223)", "verif concept answer": "apple(0.7195)", "verif image answer": "apple(0.7249)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080495.jpg"}, {"question": "describe this picture in one word", "gt answer": "ocean(1.00)", "pred answer": "beach", "question_id": 4352245, "best approach": "", "verif answer": "beach", "anno approach": "wiki, concept, image", "verif wiki answer": "pacific ocean(0.7113)", "verif concept answer": "pacific ocean(0.7190)", "verif image answer": "pacific ocean(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435224.jpg"}, {"question": "where is this", "gt answer": "dine room(1.00)<br/>inside(0.60)<br/>table(0.60)", "pred answer": "restaurant", "question_id": 4891915, "best approach": "image", "verif answer": "kitchen", "anno approach": "wiki, concept, image", "verif wiki answer": "kitchen(0.7130)", "verif concept answer": "outside(0.6723)", "verif image answer": "inside(0.6507)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489191.jpg"}, {"question": "what can this make you become if you eat a lot of it", "gt answer": "fat(1.00)", "pred answer": "donut", "question_id": 4671095, "best approach": "", "verif answer": "donuts", "anno approach": "wiki, concept, image", "verif wiki answer": "fried(0.6961)", "verif concept answer": "donuts(0.6461)", "verif image answer": "fried(0.7151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467109.jpg"}, {"question": "what type of natural occurrence do you need for this to happen", "gt answer": "wind(1.00)<br/>hurricane(0.60)", "pred answer": "kite", "question_id": 1549075, "best approach": "wiki", "verif answer": "wind", "anno approach": "wiki, concept, image", "verif wiki answer": "wind(0.7254)", "verif concept answer": "relaxation(0.7122)", "verif image answer": "string(0.7160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154907.jpg"}, {"question": "what is hanging from this chair that would usually be in a closet", "gt answer": "coat(1.00)", "pred answer": "towel", "question_id": 4653015, "best approach": "", "verif answer": "blanket", "anno approach": "wiki, concept, image", "verif wiki answer": "robe(0.7295)", "verif concept answer": "scarf(0.7003)", "verif image answer": "hat(0.7282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465301.jpg"}, {"question": "what movie contains a city with name of one of these streets in the photo", "gt answer": "wizard of oz(1.00)", "pred answer": "san francisco", "question_id": 3493525, "best approach": "", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "beauty and beast(0.6300)", "verif concept answer": "new york(0.6086)", "verif image answer": "new york(0.5217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000349352.jpg"}, {"question": "what appliance is this man moving", "gt answer": "refrigerator(1.00)<br/>refridgerator(0.60)<br/>fridge(0.60)", "pred answer": "wash machine", "question_id": 2548615, "best approach": "image", "verif answer": "refrigerator", "anno approach": "wiki, concept, image", "verif wiki answer": "fridge(0.7183)", "verif concept answer": "fridge(0.6797)", "verif image answer": "refrigerator(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000254861.jpg"}, {"question": "what year was the computer monitor on the desk made", "gt answer": "1990(1.00)<br/>2000(0.60)<br/>1996(0.60)<br/>1980(0.60)", "pred answer": "2010", "question_id": 4661365, "best approach": "wiki, concept", "verif answer": "1990", "anno approach": "wiki, concept, image", "verif wiki answer": "1990(0.6969)", "verif concept answer": "1990(0.6805)", "verif image answer": "2000(0.6952)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466136.jpg"}, {"question": "why aren't these planes flying in the air", "gt answer": "parked(1.00)<br/>landed(0.60)<br/>strike(0.60)", "pred answer": "fly", "question_id": 90395, "best approach": "concept", "verif answer": "land", "anno approach": "wiki, concept, image", "verif wiki answer": "take off(0.7239)", "verif concept answer": "parked(0.6686)", "verif image answer": "take off(0.7046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009039.jpg"}, {"question": "what breed are these dogs", "gt answer": "dalmation(1.00)<br/>dalmatian(0.60)", "pred answer": "mixed", "question_id": 4984435, "best approach": "image", "verif answer": "collie", "anno approach": "wiki, concept, image", "verif wiki answer": "dalmatian(0.7066)", "verif concept answer": "dalmatian(0.7237)", "verif image answer": "dalmation(0.7200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000498443.jpg"}, {"question": "what are these vegetables known for making their chefs do", "gt answer": "cry(1.00)", "pred answer": "vitamin", "question_id": 2094495, "best approach": "concept", "verif answer": "tomato", "anno approach": "wiki, concept, image", "verif wiki answer": "tomato(0.6929)", "verif concept answer": "cry(0.6552)", "verif image answer": "cut(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209449.jpg"}, {"question": "what are these kids protecting", "gt answer": "teeth(1.00)", "pred answer": "toothpaste", "question_id": 742325, "best approach": "image", "verif answer": "brush teeth", "anno approach": "wiki, concept, image", "verif wiki answer": "clean teeth(0.7166)", "verif concept answer": "clean teeth(0.6563)", "verif image answer": "teeth(0.7105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074232.jpg"}, {"question": "what is the name of this hairstyle", "gt answer": "afro(1.00)", "pred answer": "pony tail", "question_id": 2256455, "best approach": "", "verif answer": "pony tail", "anno approach": "wiki, concept, image", "verif wiki answer": "pony tail(0.7227)", "verif concept answer": "ponytail(0.7175)", "verif image answer": "ponytail(0.7226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225645.jpg"}, {"question": "what activity is taking place here", "gt answer": "hug(1.00)<br/>bond(0.60)<br/>birthday(0.60)", "pred answer": "brush hair", "question_id": 2135325, "best approach": "concept", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "celebration(0.6838)", "verif concept answer": "hug(0.6809)", "verif image answer": "birthday(0.7176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000213532.jpg"}, {"question": "what airline is this", "gt answer": "colombia(1.00)", "pred answer": "southwest", "question_id": 5708525, "best approach": "", "verif answer": "eva air", "anno approach": "wiki, concept, image", "verif wiki answer": "klm(0.7302)", "verif concept answer": "klm(0.7292)", "verif image answer": "klm(0.7115)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570852.jpg"}, {"question": "is this vehicle designed primarily for utility or appearance value", "gt answer": "utility(1.00)", "pred answer": "good", "question_id": 4029805, "best approach": "", "verif answer": "good", "anno approach": "wiki, concept, image", "verif wiki answer": "wine(0.5894)", "verif concept answer": "bucket truck(0.6057)", "verif image answer": "salty(0.6977)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402980.jpg"}, {"question": "what are the bananas stacked up for", "gt answer": "storage(1.00)", "pred answer": "eat", "question_id": 4499475, "best approach": "image", "verif answer": "storage", "anno approach": "wiki, concept, image", "verif wiki answer": "cook(0.6472)", "verif concept answer": "cook(0.6559)", "verif image answer": "storage(0.5994)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449947.jpg"}, {"question": "what is this woman cooking", "gt answer": "stir fry(1.00)<br/>noodle(0.60)<br/>stirfry(0.60)<br/>meat(0.60)", "pred answer": "steak", "question_id": 3469155, "best approach": "wiki, concept, image", "verif answer": "salad", "anno approach": "wiki, concept, image", "verif wiki answer": "stir fry(0.7071)", "verif concept answer": "stir fry(0.7202)", "verif image answer": "stir fry(0.6656)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346915.jpg"}, {"question": "what are the piles of wood on the beach called", "gt answer": "driftwood(1.00)", "pred answer": "surf board", "question_id": 679745, "best approach": "wiki, image", "verif answer": "cupcake", "anno approach": "wiki, concept, image", "verif wiki answer": "driftwood(0.6878)", "verif concept answer": "pancake(0.7244)", "verif image answer": "driftwood(0.6942)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067974.jpg"}, {"question": "what are the shapes around the cayt", "gt answer": "round(1.00)<br/>circle(1.00)", "pred answer": "square", "question_id": 3984345, "best approach": "wiki, concept, image", "verif answer": "square", "anno approach": "wiki, concept, image", "verif wiki answer": "round(0.7079)", "verif concept answer": "round(0.6899)", "verif image answer": "circle(0.6306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398434.jpg"}, {"question": "what fast food chain sells the item shown as well as their famous pasta bowls", "gt answer": "domino(1.00)", "pred answer": "fast food", "question_id": 5318605, "best approach": "wiki", "verif answer": "hotdog", "anno approach": "wiki, concept, image", "verif wiki answer": "domino(0.6540)", "verif concept answer": "hotdog(0.7131)", "verif image answer": "hotdog(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531860.jpg"}, {"question": "what are the vehicles on the back of the trucks", "gt answer": "camper(1.00)", "pred answer": "tow", "question_id": 5593825, "best approach": "", "verif answer": "rv", "anno approach": "wiki, concept, image", "verif wiki answer": "trailer(0.7242)", "verif concept answer": "garbage(0.6548)", "verif image answer": "trailer(0.7173)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559382.jpg"}, {"question": "a picture like this taken from above is called a what sort of view", "gt answer": "aerial(1.00)", "pred answer": "sky", "question_id": 1826245, "best approach": "image", "verif answer": "jump", "anno approach": "wiki, concept, image", "verif wiki answer": "jump(0.5291)", "verif concept answer": "jump(0.5727)", "verif image answer": "aerial(0.5071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182624.jpg"}, {"question": "what emotion is being shown", "gt answer": "despair(1.00)<br/>sad(0.60)", "pred answer": "happiness", "question_id": 3036275, "best approach": "", "verif answer": "happiness", "anno approach": "wiki, concept, image", "verif wiki answer": "happiness(0.7003)", "verif concept answer": "anger(0.7089)", "verif image answer": "anger(0.6184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303627.jpg"}, {"question": "what are the ingredients of the dish in the oven", "gt answer": "chicken(1.00)<br/>bread(0.60)<br/>pizza(0.60)", "pred answer": "flour", "question_id": 5388145, "best approach": "concept, image", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "cookies(0.6980)", "verif concept answer": "pizza(0.6782)", "verif image answer": "pizza(0.6778)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538814.jpg"}, {"question": "what type of plane is this", "gt answer": "passenger(1.00)", "pred answer": "747", "question_id": 418085, "best approach": "concept", "verif answer": "747", "anno approach": "wiki, concept, image", "verif wiki answer": "private jet(0.7109)", "verif concept answer": "passenger(0.6872)", "verif image answer": "people(0.6224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041808.jpg"}, {"question": "what is weird about this hotdog", "gt answer": "eye(1.00)", "pred answer": "face", "question_id": 5082275, "best approach": "", "verif answer": "heart", "anno approach": "wiki, concept, image", "verif wiki answer": "skin(0.7216)", "verif concept answer": "eat(0.6608)", "verif image answer": "eat(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000508227.jpg"}, {"question": "how high up in the air did the horse jump", "gt answer": "4 feet(1.00)<br/>3 feet(0.60)<br/>5 feet(0.60)", "pred answer": "20 feet", "question_id": 5134965, "best approach": "wiki, image", "verif answer": "3 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "5 feet(0.6786)", "verif concept answer": "8 inches(0.7054)", "verif image answer": "5 feet(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000513496.jpg"}, {"question": "who bottles this water", "gt answer": "nestle(1.00)", "pred answer": "factory", "question_id": 408555, "best approach": "wiki", "verif answer": "trash", "anno approach": "wiki, concept, image", "verif wiki answer": "nestle(0.6867)", "verif concept answer": "tom blake(0.6908)", "verif image answer": "trash(0.6462)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040855.jpg"}, {"question": "what model of truck is this", "gt answer": "dodge(1.00)<br/>chevy(0.60)<br/>1960(0.60)", "pred answer": "toyota", "question_id": 326745, "best approach": "image", "verif answer": "1960", "anno approach": "wiki, concept, image", "verif wiki answer": "ford(0.6438)", "verif concept answer": "ford(0.7088)", "verif image answer": "chevy(0.5587)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032674.jpg"}, {"question": "what model plane is this", "gt answer": "cessna(1.00)<br/>cesna(0.60)<br/>2(0.60)", "pred answer": "biplane", "question_id": 5249255, "best approach": "wiki, concept", "verif answer": "cessna", "anno approach": "wiki, concept, image", "verif wiki answer": "cessna(0.7247)", "verif concept answer": "cessna(0.6806)", "verif image answer": "boat(0.6587)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000524925.jpg"}, {"question": "what kind of place this kitchen located", "gt answer": "house(1.00)<br/>hotel(0.60)<br/>sink(0.60)<br/>apartment(0.60)", "pred answer": "home", "question_id": 1530645, "best approach": "concept, image", "verif answer": "home", "anno approach": "wiki, concept, image", "verif wiki answer": "home(0.6160)", "verif concept answer": "sink(0.6415)", "verif image answer": "apartment(0.6585)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153064.jpg"}, {"question": "what airlines does this plane belong to", "gt answer": "air macau(1.00)", "pred answer": "air canada", "question_id": 3643035, "best approach": "", "verif answer": "air france", "anno approach": "wiki, concept, image", "verif wiki answer": "air france(0.7284)", "verif concept answer": "air france(0.7257)", "verif image answer": "air france(0.7173)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364303.jpg"}, {"question": "where is roy g biv in this picture", "gt answer": "in sky(1.00)<br/>rainbow(1.00)", "pred answer": "street", "question_id": 3283505, "best approach": "", "verif answer": "air", "anno approach": "wiki, concept, image", "verif wiki answer": "sky(0.7035)", "verif concept answer": "air(0.6783)", "verif image answer": "sky(0.6075)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328350.jpg"}, {"question": "what is being advertised", "gt answer": "donuts(1.00)<br/>doughnut(0.60)", "pred answer": "donut", "question_id": 3202225, "best approach": "", "verif answer": "donut", "anno approach": "wiki, concept, image", "verif wiki answer": "donut(0.7074)", "verif concept answer": "donut(0.7031)", "verif image answer": "donut(0.6505)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320222.jpg"}, {"question": "what european citizens have the same name as the sticks this man is holding", "gt answer": "pole(1.00)<br/>stick(0.60)<br/>polish(0.60)", "pred answer": "bode miller", "question_id": 4398835, "best approach": "wiki", "verif answer": "pole", "anno approach": "wiki, concept, image", "verif wiki answer": "pole(0.5969)", "verif concept answer": "ski pole(0.6454)", "verif image answer": "ski pole(0.6896)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439883.jpg"}, {"question": "what is the make and model of this vehicle", "gt answer": "isuzu(1.00)", "pred answer": "ford", "question_id": 91485, "best approach": "wiki, concept, image", "verif answer": "construction", "anno approach": "wiki, concept, image", "verif wiki answer": "isuzu(0.7243)", "verif concept answer": "isuzu(0.6933)", "verif image answer": "isuzu(0.7241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009148.jpg"}, {"question": "where would vendors sell their goods", "gt answer": "under tent(1.00)<br/>flea market(0.60)<br/>tent(0.60)", "pred answer": "market", "question_id": 1912775, "best approach": "wiki, concept, image", "verif answer": "walmart", "anno approach": "wiki, concept, image", "verif wiki answer": "tent(0.5714)", "verif concept answer": "flea market(0.6574)", "verif image answer": "tent(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191277.jpg"}, {"question": "what is the purpose of the white vehicle shown", "gt answer": "tow(1.00)<br/>bus(0.60)", "pred answer": "delivery", "question_id": 3351095, "best approach": "wiki", "verif answer": "tow", "anno approach": "wiki, concept, image", "verif wiki answer": "bus(0.7089)", "verif concept answer": "tow truck(0.6926)", "verif image answer": "tow truck(0.7093)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335109.jpg"}, {"question": "does the person eating pizza look more like carmen sandiego or michael jackson", "gt answer": "michael jackson(1.00)", "pred answer": "asian", "question_id": 818095, "best approach": "concept, image", "verif answer": "hotdogs", "anno approach": "wiki, concept, image", "verif wiki answer": "bun(0.6510)", "verif concept answer": "michael jackson(0.6980)", "verif image answer": "michael jackson(0.6920)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081809.jpg"}, {"question": "what type of craft is shown here", "gt answer": "crochet(1.00)<br/>sew(0.60)", "pred answer": "teddy bear", "question_id": 2608995, "best approach": "concept", "verif answer": "sew", "anno approach": "wiki, concept, image", "verif wiki answer": "sew(0.6574)", "verif concept answer": "crochet(0.7179)", "verif image answer": "guitar hero(0.6520)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260899.jpg"}, {"question": "which type of steel is used for making this kitchen", "gt answer": "stainless(1.00)", "pred answer": "aluminum", "question_id": 474815, "best approach": "wiki", "verif answer": "propeller", "anno approach": "wiki, concept, image", "verif wiki answer": "stainless(0.6774)", "verif concept answer": "towel(0.6291)", "verif image answer": "propeller(0.7196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047481.jpg"}, {"question": "what is the red sauce at the end of the knife made of", "gt answer": "tomato(1.00)<br/>chili(1.00)<br/>marinara(0.60)", "pred answer": "butter", "question_id": 860725, "best approach": "wiki, concept", "verif answer": "grape", "anno approach": "wiki, concept, image", "verif wiki answer": "chili(0.7099)", "verif concept answer": "tomato(0.6863)", "verif image answer": "marinara(0.7006)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086072.jpg"}, {"question": "what happened to the rod", "gt answer": "fell(1.00)", "pred answer": "broken", "question_id": 4119875, "best approach": "wiki", "verif answer": "died", "anno approach": "wiki, concept, image", "verif wiki answer": "fell(0.7192)", "verif concept answer": "died(0.7249)", "verif image answer": "fly(0.6184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000411987.jpg"}, {"question": "which large appliance typically found in this room is missing", "gt answer": "dishwasher(1.00)<br/>microwave(1.00)", "pred answer": "oven", "question_id": 2830595, "best approach": "concept", "verif answer": "refrigerator", "anno approach": "wiki, concept, image", "verif wiki answer": "refrigerator(0.6891)", "verif concept answer": "dishwasher(0.7117)", "verif image answer": "micro(0.6243)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283059.jpg"}, {"question": "how long has he been snowboarding", "gt answer": "3 years(1.00)<br/>5 years(0.60)", "pred answer": "15 minutes", "question_id": 3840375, "best approach": "", "verif answer": "1 year", "anno approach": "wiki, concept, image", "verif wiki answer": "2 years(0.6298)", "verif concept answer": "2 years(0.6670)", "verif image answer": "1 year(0.6467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384037.jpg"}, {"question": "what food is this", "gt answer": "cake(1.00)<br/>desert(0.60)", "pred answer": "dessert", "question_id": 2461605, "best approach": "image", "verif answer": "dessert", "anno approach": "wiki, concept, image", "verif wiki answer": "donut(0.7029)", "verif concept answer": "donut(0.7144)", "verif image answer": "cake(0.7032)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246160.jpg"}, {"question": "what breed of dog is on the skateboard", "gt answer": "bulldog(1.00)<br/>pug(0.60)", "pred answer": "german shepard", "question_id": 1723105, "best approach": "", "verif answer": "terrier", "anno approach": "wiki, concept, image", "verif wiki answer": "terrier(0.7125)", "verif concept answer": "terrier(0.7162)", "verif image answer": "terrier(0.6967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000172310.jpg"}, {"question": "the majority of the items are of which character", "gt answer": "hello kitty(1.00)", "pred answer": "bear", "question_id": 5305335, "best approach": "wiki, concept, image", "verif answer": "kid", "anno approach": "wiki, concept, image", "verif wiki answer": "hello kitty(0.7185)", "verif concept answer": "hello kitty(0.7159)", "verif image answer": "hello kitty(0.6550)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000530533.jpg"}, {"question": "where is the farm depicted on the sign located", "gt answer": "south(1.00)<br/>midwest(0.60)<br/>us(0.60)", "pred answer": "usa", "question_id": 4597935, "best approach": "image", "verif answer": "usa", "anno approach": "wiki, concept, image", "verif wiki answer": "west(0.6400)", "verif concept answer": "west(0.6339)", "verif image answer": "us(0.6434)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459793.jpg"}, {"question": "what type event would they win these at", "gt answer": "fair(1.00)<br/>carnival(0.60)<br/>beer(0.60)<br/>game(0.60)", "pred answer": "party", "question_id": 3750435, "best approach": "wiki, concept, image", "verif answer": "game", "anno approach": "wiki, concept, image", "verif wiki answer": "carnival(0.6293)", "verif concept answer": "carnival(0.6483)", "verif image answer": "carnival(0.6614)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375043.jpg"}, {"question": "in this old fashioned picture what do you call the outfit worn by the swimmers", "gt answer": "bath suit(1.00)", "pred answer": "wet suit", "question_id": 1472045, "best approach": "", "verif answer": "wet suit", "anno approach": "wiki, concept, image", "verif wiki answer": "wet suit(0.7027)", "verif concept answer": "wet suit(0.6932)", "verif image answer": "shirt(0.5213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147204.jpg"}, {"question": "", "gt answer": "15 pound(0.60)<br/>15 pounds(0.60)", "pred answer": "1 pound", "question_id": 4619895, "best approach": "wiki, concept, image", "verif answer": "500 pounds", "anno approach": "wiki, concept, image", "verif wiki answer": "15 pound(0.6595)", "verif concept answer": "15 pounds(0.6879)", "verif image answer": "15 pounds(0.6937)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461989.jpg"}, {"question": "what fruit is growing from the trees", "gt answer": "lime(1.00)<br/>apple(1.00)", "pred answer": "grape", "question_id": 221425, "best approach": "wiki, image", "verif answer": "lime", "anno approach": "wiki, concept, image", "verif wiki answer": "lime(0.7190)", "verif concept answer": "peach(0.6848)", "verif image answer": "lime(0.6596)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000022142.jpg"}, {"question": "what is the name of the type of shirt the guy is wearing in black", "gt answer": "tee(1.00)<br/>polo(0.60)", "pred answer": "t shirt", "question_id": 5107295, "best approach": "", "verif answer": "t shirt", "anno approach": "wiki, concept, image", "verif wiki answer": "tshirt(0.7202)", "verif concept answer": "tshirt(0.7178)", "verif image answer": "tshirt(0.6192)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510729.jpg"}, {"question": "what is the black box in the middle of the screen", "gt answer": "qr code(1.00)<br/>scan(0.60)<br/>code(0.60)", "pred answer": "name", "question_id": 4571465, "best approach": "concept, image", "verif answer": "code", "anno approach": "wiki, concept, image", "verif wiki answer": "b(0.6941)", "verif concept answer": "qr code(0.7155)", "verif image answer": "qr code(0.6523)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457146.jpg"}, {"question": "what part of the world is this photo taken in", "gt answer": "northern(1.00)<br/>sweden(0.60)<br/>everest(0.60)<br/>us(0.60)", "pred answer": "mountain", "question_id": 4524685, "best approach": "image", "verif answer": "colorado", "anno approach": "wiki, concept, image", "verif wiki answer": "colorado(0.5891)", "verif concept answer": "colorado(0.6258)", "verif image answer": "sweden(0.5911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000452468.jpg"}, {"question": "what is the purpose of this channel", "gt answer": "travel(1.00)<br/>boat(0.60)", "pred answer": "dock", "question_id": 506585, "best approach": "concept", "verif answer": "fish", "anno approach": "wiki, concept, image", "verif wiki answer": "people(0.6663)", "verif concept answer": "boat(0.6508)", "verif image answer": "people(0.6064)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050658.jpg"}, {"question": "what type of clounds are these", "gt answer": "cirrus(1.00)<br/>cumulus(0.60)<br/>stratus(0.60)", "pred answer": "sparrow", "question_id": 2842475, "best approach": "concept, image", "verif answer": "white", "anno approach": "wiki, concept, image", "verif wiki answer": "stratus(0.7151)", "verif concept answer": "cirrus(0.7125)", "verif image answer": "cirrus(0.6931)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284247.jpg"}, {"question": "what causes the fogginess on the window", "gt answer": "condensation(1.00)", "pred answer": "rain", "question_id": 2059865, "best approach": "", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "moon(0.6928)", "verif concept answer": "smoothie(0.6792)", "verif image answer": "rain(0.5689)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205986.jpg"}, {"question": "what other animals have this colouration", "gt answer": "skunk(1.00)<br/>0(0.60)<br/>tiger(0.60)<br/>panda(0.60)", "pred answer": "horse", "question_id": 4652205, "best approach": "wiki, concept, image", "verif answer": "panda", "anno approach": "wiki, concept, image", "verif wiki answer": "panda(0.7120)", "verif concept answer": "panda(0.7074)", "verif image answer": "panda(0.5941)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000465220.jpg"}, {"question": "what is this man 's most probable job title", "gt answer": "sommelier(1.00)<br/>wine taster(0.60)", "pred answer": "chef", "question_id": 709525, "best approach": "wiki", "verif answer": "president", "anno approach": "wiki, concept, image", "verif wiki answer": "sommelier(0.7084)", "verif concept answer": "president(0.6961)", "verif image answer": "president(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070952.jpg"}, {"question": "what are those paintings of", "gt answer": "map(1.00)", "pred answer": "flower", "question_id": 2517905, "best approach": "", "verif answer": "map", "anno approach": "wiki, concept, image", "verif wiki answer": "abstract(0.6931)", "verif concept answer": "abstract(0.6985)", "verif image answer": "abstract(0.6621)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251790.jpg"}, {"question": "what job does this setup allow you to do", "gt answer": "type(1.00)<br/>business(0.60)<br/>video game(0.60)<br/>online(0.60)", "pred answer": "television", "question_id": 4855295, "best approach": "wiki, concept, image", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "business(0.7178)", "verif concept answer": "online(0.6877)", "verif image answer": "online(0.7154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485529.jpg"}, {"question": "how much saturated fat is in a piece of chocolate pie shown in the image", "gt answer": "too much(1.00)<br/>40(0.60)", "pred answer": "lot", "question_id": 77465, "best approach": "wiki, concept", "verif answer": "20 grams", "anno approach": "wiki, concept, image", "verif wiki answer": "40(0.7157)", "verif concept answer": "40(0.7047)", "verif image answer": "200(0.6490)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007746.jpg"}, {"question": "which fruit poisoned a princess in the tale of snow white", "gt answer": "apple(1.00)", "pred answer": "banana", "question_id": 438925, "best approach": "", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "peach(0.6783)", "verif concept answer": "peach(0.6749)", "verif image answer": "peach(0.5793)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043892.jpg"}, {"question": "what kind of bicyle is this", "gt answer": "penny farthing(1.00)<br/>unicycle(0.60)", "pred answer": "bicycle", "question_id": 3239635, "best approach": "", "verif answer": "bicycle", "anno approach": "wiki, concept, image", "verif wiki answer": "bicycle(0.7207)", "verif concept answer": "bicycle(0.6776)", "verif image answer": "kite(0.6187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323963.jpg"}, {"question": "where are the white bears found", "gt answer": "north pole(1.00)<br/>arctic(0.60)<br/>antarctica(0.60)", "pred answer": "wood", "question_id": 5387375, "best approach": "wiki, concept", "verif answer": "north pole", "anno approach": "wiki, concept, image", "verif wiki answer": "north pole(0.7188)", "verif concept answer": "north pole(0.7273)", "verif image answer": "canada(0.5675)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538737.jpg"}, {"question": "what can a person use to open this", "gt answer": "wrench(1.00)<br/>ring(0.60)<br/>fire truck(0.60)", "pred answer": "shovel", "question_id": 4815325, "best approach": "image", "verif answer": "wrench", "anno approach": "wiki, concept, image", "verif wiki answer": "saddle(0.5813)", "verif concept answer": "saddle(0.6064)", "verif image answer": "ring(0.6482)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481532.jpg"}, {"question": "how old is the child in this photograph", "gt answer": "2(1.00)<br/>3(0.60)<br/>4(0.60)<br/>1(0.60)", "pred answer": "1 year", "question_id": 3685775, "best approach": "wiki", "verif answer": "2", "anno approach": "wiki, concept, image", "verif wiki answer": "2(0.7016)", "verif concept answer": "3(0.6819)", "verif image answer": "5(0.6622)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000368577.jpg"}, {"question": "what type of fruit is in the bowl", "gt answer": "strawberry(1.00)", "pred answer": "blueberry", "question_id": 4134015, "best approach": "wiki, concept, image", "verif answer": "strawberry", "anno approach": "wiki, concept, image", "verif wiki answer": "strawberry(0.6782)", "verif concept answer": "strawberry(0.7066)", "verif image answer": "strawberry(0.6924)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000413401.jpg"}, {"question": "why is this person laying like that", "gt answer": "relax(1.00)<br/>rest(0.60)", "pred answer": "sick", "question_id": 2809685, "best approach": "", "verif answer": "sick", "anno approach": "wiki, concept, image", "verif wiki answer": "sick(0.7022)", "verif concept answer": "watch tv(0.7136)", "verif image answer": "sick(0.6031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280968.jpg"}, {"question": "the name on the jacket is the name of a character in which 90s tv show", "gt answer": "friend(1.00)", "pred answer": "mickey mouse", "question_id": 3804475, "best approach": "concept", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "baywatch(0.5075)", "verif concept answer": "friend(0.5113)", "verif image answer": "father and son(0.5131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000380447.jpg"}, {"question": "what does this website do", "gt answer": "picture(1.00)", "pred answer": "flickr", "question_id": 2861205, "best approach": "", "verif answer": "picture", "anno approach": "wiki, concept, image", "verif wiki answer": "screen(0.7252)", "verif concept answer": "screen(0.5184)", "verif image answer": "cat(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000286120.jpg"}, {"question": "which brand of tv is seen in this picture", "gt answer": "toshiba(1.00)<br/>flatscreen(0.60)", "pred answer": "sony", "question_id": 3960395, "best approach": "", "verif answer": "samsung", "anno approach": "wiki, concept, image", "verif wiki answer": "honda(0.7120)", "verif concept answer": "honda(0.7083)", "verif image answer": "samsung(0.6807)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396039.jpg"}, {"question": "how long each day does this animal sleep", "gt answer": "10 hours(1.00)<br/>12 hours(0.60)<br/>8 hours(0.60)", "pred answer": "1 year", "question_id": 2213135, "best approach": "wiki", "verif answer": "8 hours", "anno approach": "wiki, concept, image", "verif wiki answer": "12 hours(0.6792)", "verif concept answer": "5(0.6496)", "verif image answer": "2 days(0.7045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221313.jpg"}, {"question": "is this man relaxing or is he hurt", "gt answer": "relax(1.00)", "pred answer": "tired", "question_id": 1066665, "best approach": "concept", "verif answer": "rest", "anno approach": "wiki, concept, image", "verif wiki answer": "relaxation(0.6669)", "verif concept answer": "relax(0.6897)", "verif image answer": "relaxation(0.6583)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106666.jpg"}, {"question": "when were these first created", "gt answer": "5th century bc(1.00)", "pred answer": "1970", "question_id": 162535, "best approach": "", "verif answer": "1903", "anno approach": "wiki, concept, image", "verif wiki answer": "1900(0.7049)", "verif concept answer": "1903(0.7213)", "verif image answer": "1903(0.7122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016253.jpg"}, {"question": "what states do these highways pass through", "gt answer": "minnesota(1.00)<br/>florida(0.60)", "pred answer": "new york", "question_id": 2655445, "best approach": "concept", "verif answer": "california", "anno approach": "wiki, concept, image", "verif wiki answer": "california(0.6588)", "verif concept answer": "minnesota(0.7042)", "verif image answer": "california(0.6112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265544.jpg"}, {"question": "where were all these items probably found", "gt answer": "purse(1.00)<br/>desk(1.00)<br/>backpack(0.60)", "pred answer": "airport", "question_id": 3070395, "best approach": "wiki, image", "verif answer": "drawer", "anno approach": "wiki, concept, image", "verif wiki answer": "desk(0.6272)", "verif concept answer": "furniture(0.6245)", "verif image answer": "purse(0.5830)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307039.jpg"}, {"question": "what genus of bananas are in the picture", "gt answer": "musa(1.00)<br/>plantain(1.00)<br/>yellow(0.60)", "pred answer": "banana", "question_id": 4411695, "best approach": "wiki, image", "verif answer": "plantain", "anno approach": "wiki, concept, image", "verif wiki answer": "musa(0.6575)", "verif concept answer": "miniature(0.6848)", "verif image answer": "plantain(0.6663)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441169.jpg"}, {"question": "what kind of pattern is on the floor", "gt answer": "checkered(1.00)<br/>diamond(0.60)<br/>black and white(0.60)", "pred answer": "striped", "question_id": 1515735, "best approach": "wiki, concept", "verif answer": "checkered", "anno approach": "wiki, concept, image", "verif wiki answer": "checkered(0.6221)", "verif concept answer": "checkered(0.7014)", "verif image answer": "gray(0.5446)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151573.jpg"}, {"question": "where is this player standing", "gt answer": "home plate(1.00)", "pred answer": "base", "question_id": 3210365, "best approach": "wiki, concept", "verif answer": "base", "anno approach": "wiki, concept, image", "verif wiki answer": "home plate(0.7173)", "verif concept answer": "home plate(0.7222)", "verif image answer": "home(0.6870)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000321036.jpg"}, {"question": "these animals are traditionally depicted as playing with a ball of what item used to make garments", "gt answer": "yarn(1.00)", "pred answer": "cloth", "question_id": 3237175, "best approach": "wiki, concept, image", "verif answer": "cotton", "anno approach": "wiki, concept, image", "verif wiki answer": "yarn(0.7128)", "verif concept answer": "yarn(0.6671)", "verif image answer": "yarn(0.5240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000323717.jpg"}, {"question": "what branch of the military is the man giving the ball to the child in", "gt answer": "air force(1.00)<br/>navy(1.00)<br/>marine(0.60)", "pred answer": "army", "question_id": 1790955, "best approach": "", "verif answer": "army", "anno approach": "wiki, concept, image", "verif wiki answer": "army(0.7055)", "verif concept answer": "airforce(0.6966)", "verif image answer": "army(0.5717)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000179095.jpg"}, {"question": "which decade is this hand gesture most associated with", "gt answer": "1960's(1.00)", "pred answer": "1950's", "question_id": 3122525, "best approach": "", "verif answer": "1950's", "anno approach": "wiki, concept, image", "verif wiki answer": "1950's(0.7066)", "verif concept answer": "1950's(0.6696)", "verif image answer": "1948(0.6312)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312252.jpg"}, {"question": "what time of day is the man in the picture going surfing", "gt answer": "sunrise(1.00)<br/>even(0.60)<br/>morn(0.60)<br/>dusk(0.60)", "pred answer": "sunset", "question_id": 1516586, "best approach": "image", "verif answer": "dusk", "anno approach": "wiki, concept, image", "verif wiki answer": "dusk(0.6612)", "verif concept answer": "morn(0.5952)", "verif image answer": "sunrise(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151658.jpg"}, {"question": "what is the young school girl demonstrating something to the gentleman", "gt answer": "project(1.00)", "pred answer": "math", "question_id": 1341695, "best approach": "concept", "verif answer": "name", "anno approach": "wiki, concept, image", "verif wiki answer": "name(0.6768)", "verif concept answer": "project(0.5550)", "verif image answer": "map(0.7183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134169.jpg"}, {"question": "how do you make this kind of covering", "gt answer": "sew(1.00)<br/>quilt(0.60)", "pred answer": "sew machine", "question_id": 4691915, "best approach": "wiki, concept, image", "verif answer": "sew machine", "anno approach": "wiki, concept, image", "verif wiki answer": "quilt(0.6733)", "verif concept answer": "quilt(0.7110)", "verif image answer": "quilt(0.6269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469191.jpg"}, {"question": "when do the flowers on these trees blossom", "gt answer": "spring(1.00)<br/>park(0.60)", "pred answer": "2000", "question_id": 4497785, "best approach": "wiki", "verif answer": "spring", "anno approach": "wiki, concept, image", "verif wiki answer": "spring(0.6860)", "verif concept answer": "fall(0.6775)", "verif image answer": "park(0.5837)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000449778.jpg"}, {"question": "how many light sources were used to create this effect in the picture", "gt answer": "1(1.00)<br/>3(0.60)", "pred answer": "4", "question_id": 168905, "best approach": "concept", "verif answer": "4", "anno approach": "wiki, concept, image", "verif wiki answer": "0(0.7251)", "verif concept answer": "1(0.6839)", "verif image answer": "3(0.5547)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016890.jpg"}, {"question": "this animal typically is a predator to which other animal", "gt answer": "mouse(1.00)<br/>mice(0.60)<br/>rat(0.60)", "pred answer": "human", "question_id": 5528195, "best approach": "wiki", "verif answer": "mouse", "anno approach": "wiki, concept, image", "verif wiki answer": "mouse(0.7027)", "verif concept answer": "mice(0.6979)", "verif image answer": "mice(0.5110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552819.jpg"}, {"question": "is it time for more food shopping or is there enough food", "gt answer": "enough(1.00)<br/>shop(0.60)", "pred answer": "meal", "question_id": 5547705, "best approach": "wiki, concept, image", "verif answer": "shop", "anno approach": "wiki, concept, image", "verif wiki answer": "enough(0.7268)", "verif concept answer": "enough(0.7218)", "verif image answer": "enough(0.5361)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554770.jpg"}, {"question": "what is the main thing you do in this sport", "gt answer": "kick(1.00)", "pred answer": "soccer", "question_id": 4110095, "best approach": "wiki, image", "verif answer": "soccer", "anno approach": "wiki, concept, image", "verif wiki answer": "kick(0.6332)", "verif concept answer": "steal(0.7104)", "verif image answer": "kick(0.7122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000411009.jpg"}, {"question": "what is the area in which these animals are at called", "gt answer": "savanna(1.00)<br/>brush(0.60)<br/>serengeti(0.60)", "pred answer": "savannah", "question_id": 4677605, "best approach": "image", "verif answer": "savannah", "anno approach": "wiki, concept, image", "verif wiki answer": "savannah(0.7278)", "verif concept answer": "savannah(0.7222)", "verif image answer": "savanna(0.7276)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467760.jpg"}, {"question": "how does this stop", "gt answer": "brake(1.00)", "pred answer": "track", "question_id": 2191175, "best approach": "wiki, concept", "verif answer": "stopped", "anno approach": "wiki, concept, image", "verif wiki answer": "brake(0.6054)", "verif concept answer": "brake(0.6375)", "verif image answer": "slow(0.5255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219117.jpg"}, {"question": "what sound do these animals make", "gt answer": "baa(1.00)<br/>wool(0.60)", "pred answer": "moo", "question_id": 3910185, "best approach": "wiki, concept, image", "verif answer": "milk", "anno approach": "wiki, concept, image", "verif wiki answer": "baa(0.6102)", "verif concept answer": "baa(0.6890)", "verif image answer": "baa(0.6765)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391018.jpg"}, {"question": "which shade of green is closer to that used in the military", "gt answer": "right(1.00)<br/>olive(0.60)", "pred answer": "blue", "question_id": 1181695, "best approach": "wiki, image", "verif answer": "olive", "anno approach": "wiki, concept, image", "verif wiki answer": "olive(0.6055)", "verif concept answer": "lime(0.6520)", "verif image answer": "olive(0.5429)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118169.jpg"}, {"question": "", "gt answer": "50 years(0.60)<br/>70 years(0.60)<br/>1930s(0.60)<br/>1930's(0.60)", "pred answer": "100 years", "question_id": 1596495, "best approach": "concept, image", "verif answer": "black and white", "anno approach": "wiki, concept, image", "verif wiki answer": "black and white(0.6787)", "verif concept answer": "1930s(0.6598)", "verif image answer": "70 years(0.5818)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159649.jpg"}, {"question": "how many steak eaters are depicted here", "gt answer": "0(1.00)<br/>1(0.60)", "pred answer": "thousand", "question_id": 4634775, "best approach": "", "verif answer": "5", "anno approach": "wiki, concept, image", "verif wiki answer": "3(0.7028)", "verif concept answer": "3(0.5566)", "verif image answer": "5(0.6217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463477.jpg"}, {"question": "which city is featured in the image", "gt answer": "venice(1.00)<br/>italy(0.60)", "pred answer": "london", "question_id": 3169285, "best approach": "", "verif answer": "rome", "anno approach": "wiki, concept, image", "verif wiki answer": "rome(0.6239)", "verif concept answer": "copenhagen(0.6664)", "verif image answer": "rome(0.5335)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316928.jpg"}, {"question": "when was this type of transportation first used in france", "gt answer": "1823(1.00)<br/>1920(0.60)<br/>1900(0.60)", "pred answer": "1804", "question_id": 1703485, "best approach": "concept", "verif answer": "1800's", "anno approach": "wiki, concept, image", "verif wiki answer": "2000(0.6716)", "verif concept answer": "1823(0.6673)", "verif image answer": "1920(0.6623)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000170348.jpg"}, {"question": "what type of environment do these animals live in", "gt answer": "water(1.00)<br/>park(0.60)<br/>lake(0.60)<br/>forest(0.60)", "pred answer": "tropical", "question_id": 1380075, "best approach": "concept", "verif answer": "lake", "anno approach": "wiki, concept, image", "verif wiki answer": "park(0.7056)", "verif concept answer": "water(0.6753)", "verif image answer": "forest(0.6924)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138007.jpg"}, {"question": "what kind of sandwich is this", "gt answer": "pulled pork(1.00)<br/>barbeque(1.00)<br/>bbq(0.60)", "pred answer": "sub", "question_id": 3916155, "best approach": "concept, image", "verif answer": "roast", "anno approach": "wiki, concept, image", "verif wiki answer": "roast(0.6919)", "verif concept answer": "barbeque(0.7152)", "verif image answer": "barbeque(0.7022)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391615.jpg"}, {"question": "why might one assume the driver of the van is internet savvy", "gt answer": "bumper sticker(1.00)", "pred answer": "phone", "question_id": 2885475, "best approach": "", "verif answer": "type", "anno approach": "wiki, concept, image", "verif wiki answer": "remote(0.6205)", "verif concept answer": "mirrored(0.5298)", "verif image answer": "type(0.6470)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288547.jpg"}, {"question": "is this person most likely speeding up or slowing down", "gt answer": "slow down(1.00)", "pred answer": "below", "question_id": 898775, "best approach": "", "verif answer": "slow", "anno approach": "wiki, concept, image", "verif wiki answer": "go(0.7002)", "verif concept answer": "slow(0.7163)", "verif image answer": "slow(0.7025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089877.jpg"}, {"question": "which items depicted here would also be at home in a salad bowl", "gt answer": "lettuce(1.00)", "pred answer": "potato", "question_id": 251925, "best approach": "wiki", "verif answer": "lettuce", "anno approach": "wiki, concept, image", "verif wiki answer": "lettuce(0.6609)", "verif concept answer": "broccoli(0.7126)", "verif image answer": "arugula(0.7098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025192.jpg"}, {"question": "were these vehicles built before or after 1950", "gt answer": "after(1.00)", "pred answer": "before", "question_id": 1324125, "best approach": "", "verif answer": "before", "anno approach": "wiki, concept, image", "verif wiki answer": "boy(0.6448)", "verif concept answer": "normal(0.6710)", "verif image answer": "normal(0.5232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000132412.jpg"}, {"question": "what are they wearing", "gt answer": "bear costume(1.00)<br/>costume(0.60)", "pred answer": "helmet", "question_id": 2541765, "best approach": "wiki, image", "verif answer": "helmet", "anno approach": "wiki, concept, image", "verif wiki answer": "bear costume(0.7174)", "verif concept answer": "helmet(0.6800)", "verif image answer": "bear costume(0.6439)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000254176.jpg"}, {"question": "what do cops usually eat and drink in the mornings", "gt answer": "coffee and donuts(1.00)<br/>donuts(0.60)", "pred answer": "coffee", "question_id": 2115705, "best approach": "wiki, image", "verif answer": "donut", "anno approach": "wiki, concept, image", "verif wiki answer": "coffee and donuts(0.7126)", "verif concept answer": "doughnut(0.6604)", "verif image answer": "coffee and donuts(0.6879)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000211570.jpg"}, {"question": "what kind of donuts are these", "gt answer": "glazed(1.00)", "pred answer": "cruller", "question_id": 937245, "best approach": "wiki, concept, image", "verif answer": "glazed", "anno approach": "wiki, concept, image", "verif wiki answer": "glazed(0.7217)", "verif concept answer": "glazed(0.7205)", "verif image answer": "glazed(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093724.jpg"}, {"question": "what could you dip the food item in", "gt answer": "milk(1.00)<br/>coffee(0.60)", "pred answer": "bread", "question_id": 2660715, "best approach": "concept", "verif answer": "coffee", "anno approach": "wiki, concept, image", "verif wiki answer": "beer(0.5703)", "verif concept answer": "milk(0.5889)", "verif image answer": "coffee(0.6777)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266071.jpg"}, {"question": "what method of cooking is used to make the chicken", "gt answer": "fry(1.00)<br/>fried(0.60)", "pred answer": "grill", "question_id": 4384295, "best approach": "wiki", "verif answer": "fry", "anno approach": "wiki, concept, image", "verif wiki answer": "fry(0.6913)", "verif concept answer": "over easy(0.7083)", "verif image answer": "french fry(0.6858)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000438429.jpg"}, {"question": "where is this", "gt answer": "new york city(1.00)<br/>city(1.00)<br/>san francisco(0.60)", "pred answer": "street", "question_id": 2786565, "best approach": "wiki, concept, image", "verif answer": "new york city", "anno approach": "wiki, concept, image", "verif wiki answer": "new york city(0.6979)", "verif concept answer": "new york city(0.6780)", "verif image answer": "new york city(0.6069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278656.jpg"}, {"question": "what commercial did a dog like this appear in", "gt answer": "taco bell(1.00)<br/>pet food(0.60)<br/>purina(0.60)", "pred answer": "build bear", "question_id": 434255, "best approach": "wiki, concept, image", "verif answer": "dunkin donuts", "anno approach": "wiki, concept, image", "verif wiki answer": "taco bell(0.7250)", "verif concept answer": "taco bell(0.7224)", "verif image answer": "taco bell(0.6715)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043425.jpg"}, {"question": "what do the buttons make happen", "gt answer": "open door(1.00)", "pred answer": "stop", "question_id": 4981655, "best approach": "wiki, concept, image", "verif answer": "go", "anno approach": "wiki, concept, image", "verif wiki answer": "open door(0.6792)", "verif concept answer": "open door(0.7139)", "verif image answer": "open door(0.5099)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000498165.jpg"}, {"question": "what source of heat", "gt answer": "radiator(1.00)<br/>heater(0.60)", "pred answer": "gas", "question_id": 2321435, "best approach": "wiki", "verif answer": "heater", "anno approach": "wiki, concept, image", "verif wiki answer": "radiator(0.7230)", "verif concept answer": "heater(0.7198)", "verif image answer": "candle(0.6849)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232143.jpg"}, {"question": "what kind of tie does the man have on", "gt answer": "bow(1.00)<br/>bow tie(1.00)<br/>bowtie(0.60)", "pred answer": "tie", "question_id": 947706, "best approach": "wiki, concept", "verif answer": "tie", "anno approach": "wiki, concept, image", "verif wiki answer": "bow(0.7122)", "verif concept answer": "bow(0.7147)", "verif image answer": "tie(0.6860)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094770.jpg"}, {"question": "why are lights on", "gt answer": "night time(1.00)<br/>night(0.60)<br/>nighttime(0.60)", "pred answer": "fog", "question_id": 2840185, "best approach": "wiki, image", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "night(0.7074)", "verif concept answer": "light(0.6771)", "verif image answer": "nighttime(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284018.jpg"}, {"question": "what type of bird is this", "gt answer": "parakeet(1.00)", "pred answer": "parrot", "question_id": 2241085, "best approach": "concept", "verif answer": "parrot", "anno approach": "wiki, concept, image", "verif wiki answer": "dove(0.6159)", "verif concept answer": "parakeet(0.7185)", "verif image answer": "stork(0.7047)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224108.jpg"}, {"question": "what amount of people could this plane hold: more or less than 100", "gt answer": "less(1.00)", "pred answer": "300", "question_id": 2548455, "best approach": "", "verif answer": "both", "anno approach": "wiki, concept, image", "verif wiki answer": "20 hours(0.7231)", "verif concept answer": "both(0.7004)", "verif image answer": "both(0.6626)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000254845.jpg"}, {"question": "which type of material is used in the shown umbrella", "gt answer": "nylon(1.00)", "pred answer": "plastic", "question_id": 2175835, "best approach": "", "verif answer": "plastic", "anno approach": "wiki, concept, image", "verif wiki answer": "polyester(0.7148)", "verif concept answer": "polyester(0.7115)", "verif image answer": "metal(0.6966)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217583.jpg"}, {"question": "what is the reason this athlete is squatting and tucking in his arms", "gt answer": "speed(0.60)<br/>aerodynamic(1.00)", "pred answer": "protection", "question_id": 1475205, "best approach": "", "verif answer": "aerodynamic", "anno approach": "wiki, concept, image", "verif wiki answer": "fake(0.6572)", "verif concept answer": "fake(0.5918)", "verif image answer": "air(0.5189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147520.jpg"}, {"question": "what year was the transportation in this picture invented", "gt answer": "1800(1.00)<br/>1804(1.00)", "pred answer": "1950", "question_id": 3485105, "best approach": "concept, image", "verif answer": "1950", "anno approach": "wiki, concept, image", "verif wiki answer": "1950(0.6675)", "verif concept answer": "1800(0.6507)", "verif image answer": "1800(0.6477)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348510.jpg"}, {"question": "what is the name of the lamp shown in this photo", "gt answer": "lava(1.00)", "pred answer": "lamp", "question_id": 3318855, "best approach": "", "verif answer": "lamp", "anno approach": "wiki, concept, image", "verif wiki answer": "chandelier(0.7235)", "verif concept answer": "chandelier(0.7256)", "verif image answer": "chandelier(0.7060)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331885.jpg"}, {"question": "what are these green signs typically used for", "gt answer": "street name(1.00)<br/>street sign(0.60)", "pred answer": "street", "question_id": 4532875, "best approach": "wiki, concept, image", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "street sign(0.7068)", "verif concept answer": "street sign(0.6850)", "verif image answer": "street sign(0.7025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453287.jpg"}, {"question": "what might she tell her dog to make it go faster in this situation", "gt answer": "mush(1.00)<br/>run(0.60)<br/>come(0.60)", "pred answer": "lift", "question_id": 1890275, "best approach": "", "verif answer": "come", "anno approach": "wiki, concept, image", "verif wiki answer": "slow(0.6412)", "verif concept answer": "slow(0.6675)", "verif image answer": "slow(0.6501)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000189027.jpg"}, {"question": "what does this woman need for what is in her lap", "gt answer": "bottle(1.00)<br/>food(0.60)<br/>chair(0.60)", "pred answer": "computer", "question_id": 1275815, "best approach": "wiki, concept", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "food(0.6999)", "verif concept answer": "chair(0.6695)", "verif image answer": "alcohol(0.6759)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127581.jpg"}, {"question": "if you had to guess what section of the school would this meal be eaten", "gt answer": "cafeteria(1.00)<br/>lunch(0.60)<br/>lounge(0.60)", "pred answer": "restaurant", "question_id": 5147255, "best approach": "wiki", "verif answer": "lounge", "anno approach": "wiki, concept, image", "verif wiki answer": "cafeteria(0.7201)", "verif concept answer": "lunch(0.5743)", "verif image answer": "lounge(0.6490)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514725.jpg"}, {"question": "what famous european painter shares a name with this street", "gt answer": "flanders(1.00)", "pred answer": "john", "question_id": 423455, "best approach": "", "verif answer": "classic", "anno approach": "wiki, concept, image", "verif wiki answer": "fruit stripe(0.5390)", "verif concept answer": "fruit stripe(0.5323)", "verif image answer": "classic(0.5572)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042345.jpg"}, {"question": "how many travel days is this bag for", "gt answer": "2(1.00)<br/>3(0.60)", "pred answer": "50", "question_id": 731725, "best approach": "image", "verif answer": "4", "anno approach": "wiki, concept, image", "verif wiki answer": "1(0.7092)", "verif concept answer": "1(0.6650)", "verif image answer": "3(0.6104)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073172.jpg"}, {"question": "what would you call a combination of the two eating utensils pictured", "gt answer": "spork(1.00)<br/>silverware(0.60)", "pred answer": "chopstick", "question_id": 1551065, "best approach": "", "verif answer": "chopstick", "anno approach": "wiki, concept, image", "verif wiki answer": "fork and knife(0.7296)", "verif concept answer": "scissor(0.7163)", "verif image answer": "scissor(0.6928)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155106.jpg"}, {"question": "what kinds of paintings are there in this picture", "gt answer": "abstract(1.00)<br/>paint(0.60)", "pred answer": "graffiti", "question_id": 4442335, "best approach": "wiki, concept", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "abstract(0.6553)", "verif concept answer": "abstract(0.6859)", "verif image answer": "paint(0.7138)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000444233.jpg"}, {"question": "what kinds of bannanas are these", "gt answer": "plantain(1.00)<br/>miniature(0.60)", "pred answer": "banana", "question_id": 5590215, "best approach": "", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "banana(0.6746)", "verif concept answer": "banana(0.7167)", "verif image answer": "apple(0.6452)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559021.jpg"}, {"question": "who is doing the eating here", "gt answer": "doll(1.00)<br/>baby(0.60)", "pred answer": "kid", "question_id": 1026075, "best approach": "image", "verif answer": "baby", "anno approach": "wiki, concept, image", "verif wiki answer": "child(0.6851)", "verif concept answer": "baby(0.6441)", "verif image answer": "doll(0.7158)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000102607.jpg"}, {"question": "from what time period is this piece", "gt answer": "roman(1.00)<br/>greek(0.60)", "pred answer": "1800s", "question_id": 2120235, "best approach": "wiki", "verif answer": "victorian", "anno approach": "wiki, concept, image", "verif wiki answer": "roman(0.7011)", "verif concept answer": "victorian(0.6691)", "verif image answer": "gothic(0.6759)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212023.jpg"}, {"question": "is this animal likely closer to the north or the south pole", "gt answer": "north(1.00)<br/>south(0.60)", "pred answer": "west", "question_id": 4815525, "best approach": "wiki", "verif answer": "south", "anno approach": "wiki, concept, image", "verif wiki answer": "south(0.6860)", "verif concept answer": "west(0.6237)", "verif image answer": "west(0.5532)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481552.jpg"}, {"question": "what is the round structure in the middle of the phot", "gt answer": "statue(1.00)", "pred answer": "lighthouse", "question_id": 879805, "best approach": "concept", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "park lot(0.7175)", "verif concept answer": "statue(0.6540)", "verif image answer": "park lot(0.5420)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000087980.jpg"}, {"question": "how might this area be cooled other than by open windows", "gt answer": "air conditioning(1.00)<br/>fan(0.60)", "pred answer": "light", "question_id": 5537965, "best approach": "wiki", "verif answer": "fan", "anno approach": "wiki, concept, image", "verif wiki answer": "fan(0.7167)", "verif concept answer": "battery(0.6795)", "verif image answer": "battery(0.6737)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553796.jpg"}, {"question": "what is the most busiest departure time for this type of transportation", "gt answer": "morn(1.00)<br/>holiday(0.60)", "pred answer": "even", "question_id": 1567685, "best approach": "concept", "verif answer": "even", "anno approach": "wiki, concept, image", "verif wiki answer": "day(0.6675)", "verif concept answer": "morn(0.6546)", "verif image answer": "even(0.5468)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000156768.jpg"}, {"question": "which cuisine is the green vegetable associated with", "gt answer": "japanese(1.00)<br/>edamame(1.00)<br/>pepper(0.60)", "pred answer": "asian", "question_id": 3721725, "best approach": "wiki", "verif answer": "edamame", "anno approach": "wiki, concept, image", "verif wiki answer": "japanese(0.6853)", "verif concept answer": "pepper(0.6781)", "verif image answer": "thai(0.6551)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372172.jpg"}, {"question": "what nutrient is received from the orange fruit depicted", "gt answer": "vitamin c(1.00)", "pred answer": "vitamin", "question_id": 594835, "best approach": "", "verif answer": "vitamin", "anno approach": "wiki, concept, image", "verif wiki answer": "c(0.7027)", "verif concept answer": "potassium(0.6750)", "verif image answer": "c(0.6737)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059483.jpg"}, {"question": "what part of the body do you wear what is depicted on the wall", "gt answer": "foot(1.00)<br/>feet(0.60)", "pred answer": "arm", "question_id": 5216525, "best approach": "wiki, image", "verif answer": "foot", "anno approach": "wiki, concept, image", "verif wiki answer": "feet(0.7259)", "verif concept answer": "leg(0.6090)", "verif image answer": "feet(0.5241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521652.jpg"}, {"question": "what is the name of the shape of the hydrant cap", "gt answer": "octagon(1.00)", "pred answer": "round", "question_id": 1930235, "best approach": "", "verif answer": "diamond", "anno approach": "wiki, concept, image", "verif wiki answer": "hexagon(0.6746)", "verif concept answer": "hexagon(0.6951)", "verif image answer": "hexagon(0.6900)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193023.jpg"}, {"question": "what type of bird in background", "gt answer": "duck(1.00)", "pred answer": "pelican", "question_id": 1983825, "best approach": "image", "verif answer": "duck", "anno approach": "wiki, concept, image", "verif wiki answer": "seagull(0.6924)", "verif concept answer": "seagull(0.7049)", "verif image answer": "duck(0.6508)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198382.jpg"}, {"question": "what substance is the countertop in the photo made from", "gt answer": "marble(1.00)<br/>laminate(0.60)", "pred answer": "granite", "question_id": 5022045, "best approach": "wiki, concept", "verif answer": "marble", "anno approach": "wiki, concept, image", "verif wiki answer": "marble(0.7025)", "verif concept answer": "marble(0.7052)", "verif image answer": "laminate(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502204.jpg"}, {"question": "who wins the tennis match", "gt answer": "no 1(1.00)", "pred answer": "houston astros", "question_id": 5451165, "best approach": "", "verif answer": "houston astros", "anno approach": "wiki, concept, image", "verif wiki answer": "houston astros(0.6885)", "verif concept answer": "houston astros(0.6566)", "verif image answer": "girl(0.7264)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545116.jpg"}, {"question": "what brand of purse is this bag", "gt answer": "louis vitton(1.00)<br/>louis vuitton(0.60)", "pred answer": "gucci", "question_id": 2483205, "best approach": "wiki, concept", "verif answer": "columbia", "anno approach": "wiki, concept, image", "verif wiki answer": "louis vitton(0.7242)", "verif concept answer": "louis vitton(0.7231)", "verif image answer": "harley davidson(0.7098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248320.jpg"}, {"question": "what kind of nuts", "gt answer": "cherry(1.00)<br/>grape(0.60)", "pred answer": "walnut", "question_id": 1267335, "best approach": "", "verif answer": "blueberry", "anno approach": "wiki, concept, image", "verif wiki answer": "strawberry(0.6769)", "verif concept answer": "blueberry(0.6950)", "verif image answer": "rose(0.7243)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126733.jpg"}, {"question": "where is this player running", "gt answer": "first base(1.00)<br/>baseball field(0.60)", "pred answer": "field", "question_id": 2167715, "best approach": "image", "verif answer": "first base", "anno approach": "wiki, concept, image", "verif wiki answer": "home run(0.7023)", "verif concept answer": "home run(0.7235)", "verif image answer": "baseball field(0.6584)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216771.jpg"}, {"question": "where is this lobby located", "gt answer": "hotel(1.00)<br/>museum(0.60)<br/>bank(0.60)<br/>house(0.60)", "pred answer": "mall", "question_id": 5516575, "best approach": "wiki, concept, image", "verif answer": "bank", "anno approach": "wiki, concept, image", "verif wiki answer": "bank(0.7185)", "verif concept answer": "bank(0.6674)", "verif image answer": "bank(0.7157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000551657.jpg"}, {"question": "what kind of dinner setting would this attire be appropriate for", "gt answer": "casual(1.00)<br/>party(0.60)", "pred answer": "dinner", "question_id": 4699145, "best approach": "", "verif answer": "party", "anno approach": "wiki, concept, image", "verif wiki answer": "birthday party(0.7083)", "verif concept answer": "birthday party(0.7217)", "verif image answer": "tuxedo(0.5911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469914.jpg"}, {"question": "what kinda bread is this", "gt answer": "sourdough(1.00)", "pred answer": "bun", "question_id": 5535015, "best approach": "wiki", "verif answer": "bun", "anno approach": "wiki, concept, image", "verif wiki answer": "sourdough(0.6843)", "verif concept answer": "bagel(0.6956)", "verif image answer": "bagel(0.6693)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553501.jpg"}, {"question": "why wouldn't you want this animal for a pet", "gt answer": "wild(1.00)<br/>predator(0.60)<br/>danger(0.60)", "pred answer": "bear", "question_id": 2451355, "best approach": "image", "verif answer": "wild", "anno approach": "wiki, concept, image", "verif wiki answer": "no saddle(0.6454)", "verif concept answer": "no saddle(0.6806)", "verif image answer": "predator(0.6448)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245135.jpg"}, {"question": "what liquid does this chef use to fry food", "gt answer": "oil(1.00)", "pred answer": "sauce", "question_id": 731595, "best approach": "wiki, concept", "verif answer": "oil", "anno approach": "wiki, concept, image", "verif wiki answer": "oil(0.7180)", "verif concept answer": "oil(0.6672)", "verif image answer": "cargo(0.6745)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073159.jpg"}, {"question": "is bed checkered or plain", "gt answer": "checkered(1.00)<br/>metal(0.60)", "pred answer": "plaid", "question_id": 1451635, "best approach": "wiki", "verif answer": "checkered", "anno approach": "wiki, concept, image", "verif wiki answer": "checkered(0.6913)", "verif concept answer": "aluminum(0.7018)", "verif image answer": "metal(0.5982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145163.jpg"}, {"question": "what could be used to get the wrinkles out of his shirt", "gt answer": "iron(1.00)", "pred answer": "belt", "question_id": 4479675, "best approach": "image", "verif answer": "leather", "anno approach": "wiki, concept, image", "verif wiki answer": "skillet(0.5298)", "verif concept answer": "skillet(0.6632)", "verif image answer": "iron(0.7025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447967.jpg"}, {"question": "what is the leather strap that these animals are wearing called", "gt answer": "bridle(1.00)<br/>rein(0.60)", "pred answer": "saddle", "question_id": 605995, "best approach": "concept", "verif answer": "saddle", "anno approach": "wiki, concept, image", "verif wiki answer": "harness(0.6848)", "verif concept answer": "bridle(0.6973)", "verif image answer": "blinder(0.6141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060599.jpg"}, {"question": "what kind of dish is this", "gt answer": "stir fry(1.00)<br/>salad(0.60)", "pred answer": "pasta", "question_id": 1955085, "best approach": "wiki, concept", "verif answer": "salad", "anno approach": "wiki, concept, image", "verif wiki answer": "stir fry(0.7077)", "verif concept answer": "stir fry(0.7150)", "verif image answer": "salad(0.7057)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195508.jpg"}, {"question": "what is this animal 's primary mode of propulsion", "gt answer": "wing(1.00)<br/>fly(0.60)<br/>flight(0.60)", "pred answer": "beak", "question_id": 1855885, "best approach": "image", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "radar(0.6885)", "verif concept answer": "radar(0.6552)", "verif image answer": "wing(0.6089)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185588.jpg"}, {"question": "what size is the bed", "gt answer": "twin(1.00)", "pred answer": "king", "question_id": 3123265, "best approach": "wiki", "verif answer": "queen", "anno approach": "wiki, concept, image", "verif wiki answer": "twin(0.6944)", "verif concept answer": "queen(0.6864)", "verif image answer": "daisy(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312326.jpg"}, {"question": "what kind of job does this person have", "gt answer": "office(1.00)", "pred answer": "account", "question_id": 3422065, "best approach": "", "verif answer": "computer", "anno approach": "wiki, concept, image", "verif wiki answer": "desk(0.7227)", "verif concept answer": "computer(0.6024)", "verif image answer": "computer(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342206.jpg"}, {"question": "this room is named after what tub like item", "gt answer": "bath(1.00)<br/>bathtub(0.60)", "pred answer": "bathroom", "question_id": 1593135, "best approach": "concept, image", "verif answer": "bath", "anno approach": "wiki, concept, image", "verif wiki answer": "bathtub(0.7200)", "verif concept answer": "bath(0.7141)", "verif image answer": "bath(0.6236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159313.jpg"}, {"question": "what has already happened to this food", "gt answer": "eaten(1.00)<br/>bitten(1.00)", "pred answer": "eat it", "question_id": 1199045, "best approach": "wiki, concept", "verif answer": "bent", "anno approach": "wiki, concept, image", "verif wiki answer": "eaten(0.6805)", "verif concept answer": "bitten(0.7021)", "verif image answer": "bent(0.7002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119904.jpg"}, {"question": "why might one assume at least one of these items was new", "gt answer": "price tag(1.00)<br/>wooden(0.60)<br/>tag(0.60)", "pred answer": "sew", "question_id": 4111785, "best approach": "concept, image", "verif answer": "price tag", "anno approach": "wiki, concept, image", "verif wiki answer": "wooden(0.6659)", "verif concept answer": "price tag(0.6491)", "verif image answer": "price tag(0.7239)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000411178.jpg"}, {"question": "what type of gas is inside these lit up signs", "gt answer": "neon(1.00)<br/>lithium(0.60)<br/>carbon(0.60)", "pred answer": "car", "question_id": 1405855, "best approach": "concept", "verif answer": "gas", "anno approach": "wiki, concept, image", "verif wiki answer": "gas(0.7042)", "verif concept answer": "neon(0.6646)", "verif image answer": "gas(0.6809)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140585.jpg"}, {"question": "what type of outdoor bench is that", "gt answer": "picnic table(1.00)<br/>picnic(0.60)", "pred answer": "wood", "question_id": 689535, "best approach": "image", "verif answer": "bench", "anno approach": "wiki, concept, image", "verif wiki answer": "bench(0.7120)", "verif concept answer": "bench(0.6799)", "verif image answer": "picnic(0.6531)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068953.jpg"}, {"question": "what geographic feature is shown", "gt answer": "ocean(1.00)<br/>wave(1.00)", "pred answer": "sand", "question_id": 1553735, "best approach": "wiki, concept", "verif answer": "wave", "anno approach": "wiki, concept, image", "verif wiki answer": "wave(0.6197)", "verif concept answer": "ocean(0.7194)", "verif image answer": "tide(0.7156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155373.jpg"}, {"question": "what terminal is this and which country", "gt answer": "grand central usa(1.00)", "pred answer": "london", "question_id": 686545, "best approach": "", "verif answer": "france", "anno approach": "wiki, concept, image", "verif wiki answer": "washington dc(0.6959)", "verif concept answer": "washington dc(0.7067)", "verif image answer": "usa(0.6925)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068654.jpg"}, {"question": "is it more likely to find a bed or a blender in this room", "gt answer": "blender(1.00)", "pred answer": "towel", "question_id": 1127475, "best approach": "wiki, image", "verif answer": "oven", "anno approach": "wiki, concept, image", "verif wiki answer": "blender(0.6313)", "verif concept answer": "smoothie(0.7253)", "verif image answer": "blender(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000112747.jpg"}, {"question": "can you guess the location where these people are playing this sport", "gt answer": "alp(1.00)<br/>canada(0.60)<br/>colorado(0.60)", "pred answer": "mountain", "question_id": 3348675, "best approach": "concept", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "mountain(0.6415)", "verif concept answer": "colorado(0.6693)", "verif image answer": "mountain(0.7165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334867.jpg"}, {"question": "when were these transportation vessels first created", "gt answer": "8200bc(1.00)<br/>1800's(0.60)", "pred answer": "1800s", "question_id": 2025225, "best approach": "image", "verif answer": "1800s", "anno approach": "wiki, concept, image", "verif wiki answer": "1920(0.6429)", "verif concept answer": "1920(0.6384)", "verif image answer": "8200bc(0.6896)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202522.jpg"}, {"question": "is this for a normal or special occasion", "gt answer": "special occasion(1.00)<br/>special(0.60)<br/>normal(0.60)", "pred answer": "healthy", "question_id": 2781835, "best approach": "concept, image", "verif answer": "both", "anno approach": "wiki, concept, image", "verif wiki answer": "both(0.5466)", "verif concept answer": "normal(0.6890)", "verif image answer": "special(0.7193)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278183.jpg"}, {"question": "what are hot dogs made out of", "gt answer": "pork(1.00)<br/>meat(0.60)<br/>beef(0.60)", "pred answer": "dough", "question_id": 5406265, "best approach": "image", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "chicken(0.6855)", "verif concept answer": "meat(0.6633)", "verif image answer": "pork(0.7001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540626.jpg"}, {"question": "what is the best way to eat this", "gt answer": "peel(1.00)<br/>hand(0.60)", "pred answer": "slice", "question_id": 2957765, "best approach": "image", "verif answer": "brush", "anno approach": "wiki, concept, image", "verif wiki answer": "brush(0.6252)", "verif concept answer": "b(0.6704)", "verif image answer": "hand(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295776.jpg"}, {"question": "who rides in this", "gt answer": "human(1.00)<br/>travel(0.60)<br/>people(0.60)", "pred answer": "pilot", "question_id": 4611285, "best approach": "wiki, concept, image", "verif answer": "human", "anno approach": "wiki, concept, image", "verif wiki answer": "people(0.5515)", "verif concept answer": "people(0.5413)", "verif image answer": "people(0.5027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461128.jpg"}, {"question": "what language is on the sign", "gt answer": "thai(1.00)<br/>indian(0.60)<br/>persian(0.60)", "pred answer": "english", "question_id": 1381485, "best approach": "wiki, concept, image", "verif answer": "persian", "anno approach": "wiki, concept, image", "verif wiki answer": "indian(0.6701)", "verif concept answer": "indian(0.6304)", "verif image answer": "indian(0.6853)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138148.jpg"}, {"question": "", "gt answer": "white(0.60)<br/>brighten(0.60)", "pred answer": "green", "question_id": 3199965, "best approach": "", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "sepia(0.6338)", "verif concept answer": "sepia(0.6510)", "verif image answer": "sepia(0.6465)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319996.jpg"}, {"question": "what is the profession of the older gentleman", "gt answer": "military(1.00)<br/>army(0.60)", "pred answer": "hair stylist", "question_id": 4824545, "best approach": "concept", "verif answer": "military", "anno approach": "wiki, concept, image", "verif wiki answer": "navy(0.6187)", "verif concept answer": "army(0.6642)", "verif image answer": "navy(0.7189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482454.jpg"}, {"question": "of what artistic movement is this painting an example", "gt answer": "modernism(1.00)<br/>modern(0.60)<br/>abstract(0.60)", "pred answer": "graffiti", "question_id": 3770565, "best approach": "wiki, concept", "verif answer": "abstract", "anno approach": "wiki, concept, image", "verif wiki answer": "abstract(0.6560)", "verif concept answer": "abstract(0.6238)", "verif image answer": "old(0.5524)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377056.jpg"}, {"question": "what is the statue behind the skateboarder", "gt answer": "george washington(1.00)", "pred answer": "bear", "question_id": 498865, "best approach": "wiki, concept", "verif answer": "george washington", "anno approach": "wiki, concept, image", "verif wiki answer": "george washington(0.6715)", "verif concept answer": "george washington(0.7151)", "verif image answer": "richard trevithick(0.6590)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049886.jpg"}, {"question": "what shape is the sign", "gt answer": "rectangle(1.00)", "pred answer": "square", "question_id": 3764365, "best approach": "", "verif answer": "square", "anno approach": "wiki, concept, image", "verif wiki answer": "square(0.7250)", "verif concept answer": "octagon(0.7128)", "verif image answer": "square(0.7152)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376436.jpg"}, {"question": "what is the power wattage of the wall lamp shown in the image", "gt answer": "60(1.00)<br/>100(0.60)", "pred answer": "50", "question_id": 2684545, "best approach": "wiki, concept", "verif answer": "50", "anno approach": "wiki, concept, image", "verif wiki answer": "100(0.7193)", "verif concept answer": "100(0.6505)", "verif image answer": "50(0.6487)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268454.jpg"}, {"question": "what is the name the bus company", "gt answer": "greyhound(1.00)", "pred answer": "greenwave", "question_id": 5226615, "best approach": "", "verif answer": "greyhound", "anno approach": "wiki, concept, image", "verif wiki answer": "kingston transit(0.7128)", "verif concept answer": "kingston transit(0.7132)", "verif image answer": "city bus(0.7047)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522661.jpg"}, {"question": "what level skiier is this", "gt answer": "beginner(1.00)<br/>professional(0.60)", "pred answer": "minor league", "question_id": 2158585, "best approach": "concept", "verif answer": "professional", "anno approach": "wiki, concept, image", "verif wiki answer": "amatuer(0.6416)", "verif concept answer": "beginner(0.7170)", "verif image answer": "minor(0.6939)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215858.jpg"}, {"question": "what is the proper way to pet this type of animal", "gt answer": "nicely(1.00)<br/>nose(0.60)", "pred answer": "saddle", "question_id": 5198435, "best approach": "", "verif answer": "rein", "anno approach": "wiki, concept, image", "verif wiki answer": "rein(0.7146)", "verif concept answer": "rein(0.7270)", "verif image answer": "arm(0.7099)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000519843.jpg"}, {"question": "what company is associated with the sign", "gt answer": "pepsi(1.00)", "pred answer": "starbucks", "question_id": 2467505, "best approach": "wiki", "verif answer": "coke", "anno approach": "wiki, concept, image", "verif wiki answer": "pepsi(0.7117)", "verif concept answer": "coke(0.6532)", "verif image answer": "french(0.6336)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246750.jpg"}, {"question": "what holiday do people give these to each other on", "gt answer": "valentine's day(1.00)<br/>valentine(0.60)", "pred answer": "christmas", "question_id": 1638035, "best approach": "", "verif answer": "christmas", "anno approach": "wiki, concept, image", "verif wiki answer": "christmas(0.7266)", "verif concept answer": "teddy bear(0.7224)", "verif image answer": "valentine's(0.6585)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163803.jpg"}, {"question": "which region of the united states is well known for the white object", "gt answer": "texas(1.00)<br/>western(0.60)<br/>south(0.60)<br/>west(0.60)", "pred answer": "north america", "question_id": 3416175, "best approach": "concept", "verif answer": "south", "anno approach": "wiki, concept, image", "verif wiki answer": "west(0.5868)", "verif concept answer": "texas(0.6025)", "verif image answer": "south(0.6524)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341617.jpg"}, {"question": "what type of bird is shown in the image", "gt answer": "parakeet(1.00)<br/>parrot(0.60)", "pred answer": "robin", "question_id": 2203765, "best approach": "concept", "verif answer": "robin", "anno approach": "wiki, concept, image", "verif wiki answer": "parrot(0.7051)", "verif concept answer": "parakeet(0.6941)", "verif image answer": "cardinal(0.7203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220376.jpg"}, {"question": "what sport will the reporters be commenting on", "gt answer": "hockey(1.00)", "pred answer": "guitar hero", "question_id": 542285, "best approach": "", "verif answer": "hockey", "anno approach": "wiki, concept, image", "verif wiki answer": "basketball(0.6603)", "verif concept answer": "box(0.6347)", "verif image answer": "basketball(0.7044)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054228.jpg"}, {"question": "what is the man dressed as", "gt answer": "blue brother(1.00)", "pred answer": "suit", "question_id": 5694845, "best approach": "concept, image", "verif answer": "black", "anno approach": "wiki, concept, image", "verif wiki answer": "black(0.7079)", "verif concept answer": "blue brother(0.5470)", "verif image answer": "blue brother(0.6626)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000569484.jpg"}, {"question": "what time of day was this picture taken", "gt answer": "night(1.00)", "pred answer": "even", "question_id": 3709285, "best approach": "image", "verif answer": "even", "anno approach": "wiki, concept, image", "verif wiki answer": "even(0.6652)", "verif concept answer": "even(0.7120)", "verif image answer": "night(0.6554)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370928.jpg"}, {"question": "what type of club is this", "gt answer": "dance(1.00)<br/>night(0.60)", "pred answer": "ship", "question_id": 1193375, "best approach": "wiki", "verif answer": "football", "anno approach": "wiki, concept, image", "verif wiki answer": "dance(0.6498)", "verif concept answer": "football(0.6527)", "verif image answer": "football(0.7172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000119337.jpg"}, {"question": "what object is the shape of this", "gt answer": "kangaroo(1.00)<br/>rectangle(0.60)", "pred answer": "round", "question_id": 5001655, "best approach": "concept", "verif answer": "star", "anno approach": "wiki, concept, image", "verif wiki answer": "square(0.7066)", "verif concept answer": "rectangle(0.7198)", "verif image answer": "star(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500165.jpg"}, {"question": "does this plane have turboprop or turbofan engines", "gt answer": "turboprop(1.00)", "pred answer": "jet", "question_id": 2083295, "best approach": "concept, image", "verif answer": "jet", "anno approach": "wiki, concept, image", "verif wiki answer": "6 inches(0.6885)", "verif concept answer": "turboprop(0.6874)", "verif image answer": "turboprop(0.7030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208329.jpg"}, {"question": "where is the person parked", "gt answer": "intersection(1.00)<br/>street(0.60)<br/>park lot(0.60)", "pred answer": "highway", "question_id": 363265, "best approach": "wiki, concept", "verif answer": "park lot", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.6512)", "verif concept answer": "park lot(0.7122)", "verif image answer": "outside(0.7095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036326.jpg"}, {"question": "what kind of panel tv is that", "gt answer": "led(1.00)<br/>old(0.60)", "pred answer": "flat screen", "question_id": 1061485, "best approach": "", "verif answer": "flat screen", "anno approach": "wiki, concept, image", "verif wiki answer": "flat screen(0.7208)", "verif concept answer": "flat screen(0.7116)", "verif image answer": "flatscreen(0.6239)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106148.jpg"}, {"question": "this meal is being eaten at what festive period", "gt answer": "christmas(1.00)", "pred answer": "easter", "question_id": 2660435, "best approach": "wiki", "verif answer": "christmas", "anno approach": "wiki, concept, image", "verif wiki answer": "christmas(0.7128)", "verif concept answer": "mardi gras(0.6837)", "verif image answer": "anniversary(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266043.jpg"}, {"question": "what is this cake made from", "gt answer": "flour(1.00)<br/>sugar(0.60)", "pred answer": "ice", "question_id": 1097525, "best approach": "wiki, image", "verif answer": "chocolate", "anno approach": "wiki, concept, image", "verif wiki answer": "sugar(0.7125)", "verif concept answer": "chocolate(0.6988)", "verif image answer": "sugar(0.6199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000109752.jpg"}, {"question": "what are the black things on these pizzas", "gt answer": "olives(1.00)", "pred answer": "tomato", "question_id": 5354555, "best approach": "", "verif answer": "tomato", "anno approach": "wiki, concept, image", "verif wiki answer": "tomato(0.6461)", "verif concept answer": "tomato(0.6958)", "verif image answer": "onion(0.6126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535455.jpg"}, {"question": "what is the tone of this picture", "gt answer": "dark(1.00)<br/>sepia(0.60)<br/>blue(0.60)", "pred answer": "day", "question_id": 5358915, "best approach": "wiki, concept, image", "verif answer": "black and white", "anno approach": "wiki, concept, image", "verif wiki answer": "sepia(0.6709)", "verif concept answer": "blue(0.6768)", "verif image answer": "blue(0.6546)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535891.jpg"}, {"question": "what is the woman about to do", "gt answer": "hit tennis ball(1.00)<br/>play tennis(0.60)<br/>swing(0.60)", "pred answer": "hit ball", "question_id": 5165825, "best approach": "wiki", "verif answer": "hit ball", "anno approach": "wiki, concept, image", "verif wiki answer": "hit tennis ball(0.7284)", "verif concept answer": "shake hand(0.7275)", "verif image answer": "hit ball(0.6964)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516582.jpg"}, {"question": "", "gt answer": "hindi(0.60)<br/>asian(0.60)<br/>indian(0.60)", "pred answer": "african", "question_id": 2324345, "best approach": "wiki, concept, image", "verif answer": "indian", "anno approach": "wiki, concept, image", "verif wiki answer": "asian(0.5800)", "verif concept answer": "asian(0.6655)", "verif image answer": "asian(0.6031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232434.jpg"}, {"question": "what time was this taken", "gt answer": "dusk(1.00)<br/>even(0.60)", "pred answer": "night", "question_id": 3427575, "best approach": "", "verif answer": "even", "anno approach": "wiki, concept, image", "verif wiki answer": "sunrise(0.6819)", "verif concept answer": "sunset(0.6649)", "verif image answer": "dawn(0.5986)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342757.jpg"}, {"question": "what is the main ingredient in the soup", "gt answer": "broth(1.00)<br/>vegetable(0.60)", "pred answer": "cheese", "question_id": 3380615, "best approach": "wiki", "verif answer": "vegetable", "anno approach": "wiki, concept, image", "verif wiki answer": "broth(0.6943)", "verif concept answer": "grass(0.7042)", "verif image answer": "grass(0.6734)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338061.jpg"}, {"question": "what kind of instrument is this man playing", "gt answer": "cello(1.00)<br/>bass(0.60)", "pred answer": "wii", "question_id": 3258095, "best approach": "concept", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "bass(0.7255)", "verif concept answer": "cello(0.6890)", "verif image answer": "bass(0.6258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325809.jpg"}, {"question": "what type of computer is shown in this image", "gt answer": "desktop(1.00)<br/>pc(0.60)", "pred answer": "macbook", "question_id": 341285, "best approach": "concept", "verif answer": "laptop", "anno approach": "wiki, concept, image", "verif wiki answer": "laptop(0.7130)", "verif concept answer": "pc(0.7205)", "verif image answer": "ibm(0.7073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000034128.jpg"}, {"question": "what makes the vegetable shown here unhealthy", "gt answer": "fry(1.00)<br/>grease(0.60)", "pred answer": "egg salad", "question_id": 5025295, "best approach": "", "verif answer": "fry", "anno approach": "wiki, concept, image", "verif wiki answer": "fried(0.6954)", "verif concept answer": "french fry(0.7043)", "verif image answer": "french fry(0.5208)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502529.jpg"}, {"question": "what 's a good way to show good sportsmanship", "gt answer": "hand shake(1.00)<br/>shake hand(0.60)", "pred answer": "tennis", "question_id": 2154605, "best approach": "wiki, concept", "verif answer": "net", "anno approach": "wiki, concept, image", "verif wiki answer": "hand shake(0.5554)", "verif concept answer": "hand shake(0.6806)", "verif image answer": "talk(0.5684)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215460.jpg"}, {"question": "who creates this item", "gt answer": "baker(1.00)<br/>bakery(0.60)", "pred answer": "italians", "question_id": 2457605, "best approach": "concept", "verif answer": "chef", "anno approach": "wiki, concept, image", "verif wiki answer": "cook(0.6653)", "verif concept answer": "baker(0.7000)", "verif image answer": "cook(0.6267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245760.jpg"}, {"question": "is riding these better or worse for the environment than a car", "gt answer": "better(1.00)", "pred answer": "good", "question_id": 5284675, "best approach": "wiki, concept", "verif answer": "herbivore", "anno approach": "wiki, concept, image", "verif wiki answer": "better(0.6393)", "verif concept answer": "better(0.6996)", "verif image answer": "herbivore(0.5215)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528467.jpg"}, {"question": "what kind of sandwich is this", "gt answer": "turkey(1.00)<br/>chicken(0.60)", "pred answer": "steak", "question_id": 673565, "best approach": "concept, image", "verif answer": "turkey", "anno approach": "wiki, concept, image", "verif wiki answer": "meat(0.6945)", "verif concept answer": "turkey(0.6772)", "verif image answer": "turkey(0.7095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067356.jpg"}, {"question": "what type of building is depicted", "gt answer": "castle(1.00)<br/>church(1.00)<br/>cathedral(0.60)", "pred answer": "skyscraper", "question_id": 1342365, "best approach": "concept", "verif answer": "castle", "anno approach": "wiki, concept, image", "verif wiki answer": "gothic(0.7159)", "verif concept answer": "church(0.6416)", "verif image answer": "cathedral(0.5658)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134236.jpg"}, {"question": "what type of horse is this", "gt answer": "albino(1.00)<br/>white(0.60)", "pred answer": "palomino", "question_id": 5507595, "best approach": "wiki, concept, image", "verif answer": "mustang", "anno approach": "wiki, concept, image", "verif wiki answer": "albino(0.7267)", "verif concept answer": "albino(0.7228)", "verif image answer": "albino(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550759.jpg"}, {"question": "what is this arrangement of plants called", "gt answer": "bouquet(1.00)", "pred answer": "rose", "question_id": 1375525, "best approach": "wiki", "verif answer": "rose", "anno approach": "wiki, concept, image", "verif wiki answer": "bouquet(0.7128)", "verif concept answer": "lily(0.6613)", "verif image answer": "rose(0.6879)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000137552.jpg"}, {"question": "what might you do in this room", "gt answer": "wash hand(1.00)<br/>bathe(0.60)<br/>poop(0.60)<br/>pee(0.60)", "pred answer": "bath", "question_id": 4899785, "best approach": "wiki", "verif answer": "wash hand", "anno approach": "wiki, concept, image", "verif wiki answer": "wash hand(0.7254)", "verif concept answer": "bathe(0.6915)", "verif image answer": "pee(0.6339)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489978.jpg"}, {"question": "what rights were the women in this picture working towrds", "gt answer": "vote(1.00)", "pred answer": "first", "question_id": 3849075, "best approach": "", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "black and white(0.6163)", "verif concept answer": "new york(0.6416)", "verif image answer": "seattle(0.6520)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384907.jpg"}, {"question": "what kind of bushes are behind that bench", "gt answer": "hedge(1.00)", "pred answer": "shrub", "question_id": 751905, "best approach": "", "verif answer": "shrub", "anno approach": "wiki, concept, image", "verif wiki answer": "succulent(0.7175)", "verif concept answer": "succulent(0.7246)", "verif image answer": "shrub(0.7118)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075190.jpg"}, {"question": "which sign has a word that featured famously as one of the plagues of egypt in the bible", "gt answer": "locust(1.00)", "pred answer": "street", "question_id": 4706725, "best approach": "", "verif answer": "honk", "anno approach": "wiki, concept, image", "verif wiki answer": "open(0.6862)", "verif concept answer": "open(0.6224)", "verif image answer": "2 months(0.5510)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470672.jpg"}, {"question": "", "gt answer": "grazed(0.60)<br/>pack(0.60)", "pred answer": "snow", "question_id": 8975, "best approach": "concept, image", "verif answer": "soft", "anno approach": "wiki, concept, image", "verif wiki answer": "very(0.6083)", "verif concept answer": "grazed(0.6496)", "verif image answer": "grazed(0.6369)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000897.jpg"}, {"question": "if the items shown in the photo are for sale in what kind of store is this photo taken", "gt answer": "antique(1.00)", "pred answer": "ikea", "question_id": 3733425, "best approach": "concept", "verif answer": "antique", "anno approach": "wiki, concept, image", "verif wiki answer": "formal(0.5275)", "verif concept answer": "antique(0.6435)", "verif image answer": "formal(0.5287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373342.jpg"}, {"question": "what kind of garden is this", "gt answer": "zen(1.00)<br/>fruit(0.60)", "pred answer": "ceramic", "question_id": 2799905, "best approach": "wiki, concept, image", "verif answer": "vegetable", "anno approach": "wiki, concept, image", "verif wiki answer": "zen(0.6583)", "verif concept answer": "zen(0.6529)", "verif image answer": "zen(0.6317)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000279990.jpg"}, {"question": "what airport is this", "gt answer": "san diego(1.00)<br/>las vegas(0.60)", "pred answer": "jfk", "question_id": 1767325, "best approach": "concept", "verif answer": "city", "anno approach": "wiki, concept, image", "verif wiki answer": "miami(0.6653)", "verif concept answer": "las vegas(0.6736)", "verif image answer": "miami(0.5281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176732.jpg"}, {"question": "when did the company on this cup begin marketing coffee", "gt answer": "1938(1.00)<br/>1950(0.60)", "pred answer": "1977", "question_id": 2187885, "best approach": "", "verif answer": "1950s", "anno approach": "wiki, concept, image", "verif wiki answer": "1950s(0.5937)", "verif concept answer": "1950s(0.6052)", "verif image answer": "1950s(0.7132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218788.jpg"}, {"question": "what is this woman tuning", "gt answer": "mandolin(1.00)<br/>violin(0.60)", "pred answer": "bed", "question_id": 4202445, "best approach": "concept, image", "verif answer": "lettuce", "anno approach": "wiki, concept, image", "verif wiki answer": "cow(0.5788)", "verif concept answer": "mandolin(0.6846)", "verif image answer": "mandolin(0.6957)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000420244.jpg"}, {"question": "are these classic or newer vehicles", "gt answer": "classic(1.00)", "pred answer": "vintage", "question_id": 4012315, "best approach": "wiki, concept", "verif answer": "classic", "anno approach": "wiki, concept, image", "verif wiki answer": "classic(0.6154)", "verif concept answer": "classic(0.5396)", "verif image answer": "deep dish(0.5177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401231.jpg"}, {"question": "what type of burners are on the stove", "gt answer": "electric(1.00)<br/>glass(0.60)", "pred answer": "gas", "question_id": 724215, "best approach": "concept", "verif answer": "gas", "anno approach": "wiki, concept, image", "verif wiki answer": "gas(0.6899)", "verif concept answer": "glass(0.6171)", "verif image answer": "gas(0.5675)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072421.jpg"}, {"question": "what are the items to the right used for", "gt answer": "read(1.00)", "pred answer": "sleep", "question_id": 556075, "best approach": "", "verif answer": "sleep", "anno approach": "wiki, concept, image", "verif wiki answer": "eat(0.6479)", "verif concept answer": "sleep(0.6723)", "verif image answer": "sleep(0.6914)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000055607.jpg"}, {"question": "who would want this", "gt answer": "child(1.00)<br/>baby(1.00)", "pred answer": "kid", "question_id": 1423225, "best approach": "wiki, image", "verif answer": "kid", "anno approach": "wiki, concept, image", "verif wiki answer": "child(0.6827)", "verif concept answer": "kid(0.6511)", "verif image answer": "child(0.6073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142322.jpg"}, {"question": "what room are they in and who is the politician", "gt answer": "oval office(1.00)", "pred answer": "president", "question_id": 3639575, "best approach": "", "verif answer": "government", "anno approach": "wiki, concept, image", "verif wiki answer": "hallway(0.7130)", "verif concept answer": "hallway(0.5922)", "verif image answer": "queen(0.7001)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363957.jpg"}, {"question": "what tv show is on the screen", "gt answer": "cartoon(1.00)<br/>mickey mouse(0.60)", "pred answer": "friend", "question_id": 38775, "best approach": "wiki", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "mickey mouse(0.7258)", "verif concept answer": "friend(0.7160)", "verif image answer": "sony(0.7042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003877.jpg"}, {"question": "what make of car is that", "gt answer": "sedan(1.00)<br/>honda(1.00)<br/>ford(0.60)", "pred answer": "mercedes", "question_id": 524615, "best approach": "image", "verif answer": "sedan", "anno approach": "wiki, concept, image", "verif wiki answer": "nissan(0.7156)", "verif concept answer": "nissan(0.6966)", "verif image answer": "honda(0.6777)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052461.jpg"}, {"question": "why would we suspect this infant is female", "gt answer": "pink cloth(1.00)", "pred answer": "advertising", "question_id": 1538925, "best approach": "wiki, concept, image", "verif answer": "cancer", "anno approach": "wiki, concept, image", "verif wiki answer": "pink cloth(0.7272)", "verif concept answer": "pink cloth(0.7050)", "verif image answer": "pink cloth(0.7113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153892.jpg"}, {"question": "a group of these type of people are called what", "gt answer": "biker(1.00)", "pred answer": "hell angel", "question_id": 3783125, "best approach": "", "verif answer": "hell angel", "anno approach": "wiki, concept, image", "verif wiki answer": "hell angel(0.7003)", "verif concept answer": "hell angel(0.6600)", "verif image answer": "hell angel(0.5040)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378312.jpg"}, {"question": "who invented the tie", "gt answer": "croatian mercenary(1.00)<br/>man(0.60)", "pred answer": "ben franklin", "question_id": 2033365, "best approach": "image", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "leonardo da vinci(0.6923)", "verif concept answer": "leonardo da vinci(0.6957)", "verif image answer": "man(0.7075)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203336.jpg"}, {"question": "what did these people likely just do", "gt answer": "get married(1.00)", "pred answer": "pray", "question_id": 1839105, "best approach": "concept, image", "verif answer": "wed", "anno approach": "wiki, concept, image", "verif wiki answer": "formal(0.6658)", "verif concept answer": "get married(0.6752)", "verif image answer": "get married(0.5453)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183910.jpg"}, {"question": "", "gt answer": "adhesive(0.60)<br/>painted(0.60)<br/>paint(0.60)", "pred answer": "internet", "question_id": 4283265, "best approach": "wiki, concept, image", "verif answer": "painted", "anno approach": "wiki, concept, image", "verif wiki answer": "adhesive(0.5909)", "verif concept answer": "adhesive(0.6194)", "verif image answer": "adhesive(0.6380)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428326.jpg"}, {"question": "how do the british spell the color of the woman 's jacket", "gt answer": "gray(1.00)<br/>grey(0.60)<br/>green(0.60)", "pred answer": "red", "question_id": 50215, "best approach": "wiki, concept, image", "verif answer": "grey", "anno approach": "wiki, concept, image", "verif wiki answer": "grey(0.6864)", "verif concept answer": "grey(0.6713)", "verif image answer": "green(0.6142)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005021.jpg"}, {"question": "what type of hat is on the cats head", "gt answer": "santa hat(1.00)<br/>santa(1.00)", "pred answer": "bonnet", "question_id": 2694965, "best approach": "concept", "verif answer": "fedora", "anno approach": "wiki, concept, image", "verif wiki answer": "fedora(0.7243)", "verif concept answer": "santa hat(0.7255)", "verif image answer": "fedora(0.7143)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269496.jpg"}, {"question": "what move is being done by the skateboarder", "gt answer": "kickflip(1.00)<br/>flip(0.60)<br/>kick flip(0.60)", "pred answer": "ollie", "question_id": 199185, "best approach": "wiki, concept", "verif answer": "ollie", "anno approach": "wiki, concept, image", "verif wiki answer": "kickflip(0.7067)", "verif concept answer": "kickflip(0.7077)", "verif image answer": "flip(0.6358)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019918.jpg"}, {"question": "why are these bananas green", "gt answer": "unripe(1.00)<br/>not ripe(1.00)", "pred answer": "ripe", "question_id": 1649185, "best approach": "concept, image", "verif answer": "unripe", "anno approach": "wiki, concept, image", "verif wiki answer": "very ripe(0.7212)", "verif concept answer": "not ripe(0.7237)", "verif image answer": "not ripe(0.6343)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000164918.jpg"}, {"question": "what item needs to be added to make this bathroom complete", "gt answer": "toilet paper(1.00)", "pred answer": "toilet", "question_id": 2856675, "best approach": "wiki, concept", "verif answer": "toilet", "anno approach": "wiki, concept, image", "verif wiki answer": "toilet paper(0.7290)", "verif concept answer": "toilet paper(0.7283)", "verif image answer": "bidet(0.7160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285667.jpg"}, {"question": "what type of material is this man standing on", "gt answer": "gravel(1.00)<br/>sand(0.60)<br/>rock(0.60)", "pred answer": "wood", "question_id": 1171195, "best approach": "image", "verif answer": "rock", "anno approach": "wiki, concept, image", "verif wiki answer": "rock(0.5638)", "verif concept answer": "sand(0.6123)", "verif image answer": "gravel(0.6923)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117119.jpg"}, {"question": "when was this plane made", "gt answer": "1930s(1.00)<br/>1940's(0.60)<br/>1924(0.60)", "pred answer": "1903", "question_id": 4936265, "best approach": "concept, image", "verif answer": "1930s", "anno approach": "wiki, concept, image", "verif wiki answer": "2010(0.6175)", "verif concept answer": "1924(0.6863)", "verif image answer": "1924(0.6173)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000493626.jpg"}, {"question": "are the wall colors primary or secondary colors", "gt answer": "primary(1.00)", "pred answer": "pinkish", "question_id": 3989625, "best approach": "wiki", "verif answer": "vitamin c", "anno approach": "wiki, concept, image", "verif wiki answer": "primary(0.5484)", "verif concept answer": "vitamin c(0.6451)", "verif image answer": "annual(0.7191)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398962.jpg"}, {"question": "what is the name of this road", "gt answer": "paddockhurst road(1.00)", "pred answer": "railroad", "question_id": 2205275, "best approach": "wiki, concept, image", "verif answer": "asphalt", "anno approach": "wiki, concept, image", "verif wiki answer": "paddockhurst road(0.7141)", "verif concept answer": "paddockhurst road(0.7111)", "verif image answer": "paddockhurst road(0.6953)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220527.jpg"}, {"question": "what is the name of the item that is hit back and forth in this game", "gt answer": "tennis ball(1.00)<br/>ball(0.60)", "pred answer": "tennis racket", "question_id": 261185, "best approach": "", "verif answer": "ball", "anno approach": "wiki, concept, image", "verif wiki answer": "backhand(0.7301)", "verif concept answer": "backhand(0.7286)", "verif image answer": "backhand(0.6992)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000026118.jpg"}, {"question": "what is this tennis player wearing", "gt answer": "dress(1.00)<br/>tank top(0.60)", "pred answer": "glass", "question_id": 2024315, "best approach": "concept", "verif answer": "tank top", "anno approach": "wiki, concept, image", "verif wiki answer": "suit(0.7214)", "verif concept answer": "dress(0.6988)", "verif image answer": "suit(0.7127)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202431.jpg"}, {"question": "what style is this dish", "gt answer": "deep dish(1.00)", "pred answer": "pizza", "question_id": 2967905, "best approach": "", "verif answer": "deep dish", "anno approach": "wiki, concept, image", "verif wiki answer": "chicago(0.6770)", "verif concept answer": "pan(0.6636)", "verif image answer": "chicago(0.6727)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296790.jpg"}, {"question": "which elvis movie features a color and location similar to that seen here", "gt answer": "blue hawaii(1.00)", "pred answer": "black and white", "question_id": 5756645, "best approach": "", "verif answer": "red", "anno approach": "wiki, concept, image", "verif wiki answer": "hot dog(0.6505)", "verif concept answer": "hot dog(0.6651)", "verif image answer": "disney(0.6807)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575664.jpg"}, {"question": "what does the thing in the sky need for it to be aimed by the user", "gt answer": "string(1.00)<br/>wind(0.60)<br/>0(0.60)", "pred answer": "kite", "question_id": 923535, "best approach": "concept", "verif answer": "kite", "anno approach": "wiki, concept, image", "verif wiki answer": "0(0.7221)", "verif concept answer": "string(0.6326)", "verif image answer": "kite(0.7227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092353.jpg"}, {"question": "what event is this", "gt answer": "retirement(1.00)<br/>birthday(0.60)", "pred answer": "celebration", "question_id": 4015895, "best approach": "image", "verif answer": "celebration", "anno approach": "wiki, concept, image", "verif wiki answer": "celebration(0.7124)", "verif concept answer": "celebration(0.7090)", "verif image answer": "birthday(0.6206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401589.jpg"}, {"question": "what war may this be from", "gt answer": "wwii(1.00)", "pred answer": "ww2", "question_id": 2461615, "best approach": "", "verif answer": "world war 2", "anno approach": "wiki, concept, image", "verif wiki answer": "world war 2(0.7173)", "verif concept answer": "world war 2(0.6762)", "verif image answer": "1940s(0.5489)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246161.jpg"}, {"question": "is the child a boy or girl", "gt answer": "girl(1.00)", "pred answer": "boy", "question_id": 5804345, "best approach": "", "verif answer": "boy", "anno approach": "wiki, concept, image", "verif wiki answer": "boy(0.7264)", "verif concept answer": "boy(0.7067)", "verif image answer": "both(0.7152)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580434.jpg"}, {"question": "what element is this person snowboarding on", "gt answer": "water(1.00)<br/>snowy(0.60)<br/>air(0.60)<br/>snow(0.60)", "pred answer": "wood", "question_id": 4477285, "best approach": "image", "verif answer": "snow", "anno approach": "wiki, concept, image", "verif wiki answer": "hydrogen and oxygen(0.6340)", "verif concept answer": "hydrogen and oxygen(0.6906)", "verif image answer": "water(0.5529)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447728.jpg"}, {"question": "who is the famous woman that this mode of transportation reminds you of", "gt answer": "rosa park(1.00)", "pred answer": "lord of ring", "question_id": 1754615, "best approach": "concept", "verif answer": "van gogh", "anno approach": "wiki, concept, image", "verif wiki answer": "serena williams(0.6812)", "verif concept answer": "rosa park(0.6739)", "verif image answer": "van gogh(0.5258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000175461.jpg"}, {"question": "is this surfer standing or sitting", "gt answer": "stand(1.00)", "pred answer": "parked", "question_id": 1083555, "best approach": "wiki, concept", "verif answer": "stand", "anno approach": "wiki, concept, image", "verif wiki answer": "stand(0.7164)", "verif concept answer": "stand(0.6711)", "verif image answer": "wait(0.5948)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000108355.jpg"}, {"question": "what is the degree of the slope this skiier is on", "gt answer": "45(1.00)<br/>60(0.60)", "pred answer": "freeze", "question_id": 3903955, "best approach": "", "verif answer": "45", "anno approach": "wiki, concept, image", "verif wiki answer": "30 degrees(0.7238)", "verif concept answer": "180(0.6387)", "verif image answer": "30 degrees(0.6823)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390395.jpg"}, {"question": "how far can this animal jump", "gt answer": "8 feet(1.00)<br/>5 feet(0.60)", "pred answer": "3 feet", "question_id": 2316095, "best approach": "image", "verif answer": "10 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "5 feet(0.6904)", "verif concept answer": "far(0.6402)", "verif image answer": "8 feet(0.6429)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231609.jpg"}, {"question": "where was this picture taken", "gt answer": "comicon(1.00)<br/>airport(0.60)", "pred answer": "bar", "question_id": 5007615, "best approach": "", "verif answer": "mall", "anno approach": "wiki, concept, image", "verif wiki answer": "mall(0.6833)", "verif concept answer": "mall(0.6501)", "verif image answer": "city(0.6339)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500761.jpg"}, {"question": "who is she talking to", "gt answer": "friend(1.00)", "pred answer": "bank", "question_id": 271425, "best approach": "", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "couple(0.7129)", "verif concept answer": "family(0.5710)", "verif image answer": "father and son(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027142.jpg"}, {"question": "what is the symbol in the center of this person 's shirt", "gt answer": "sun(1.00)<br/>dandelion(0.60)", "pred answer": "cross", "question_id": 4805955, "best approach": "concept", "verif answer": "beach umbrella", "anno approach": "wiki, concept, image", "verif wiki answer": "beach umbrella(0.7285)", "verif concept answer": "dandelion(0.7202)", "verif image answer": "yellow(0.6856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000480595.jpg"}, {"question": "what type of chore is being done", "gt answer": "laundry(1.00)", "pred answer": "travel", "question_id": 4649035, "best approach": "image", "verif answer": "laundry", "anno approach": "wiki, concept, image", "verif wiki answer": "bathtub(0.7162)", "verif concept answer": "bathtub(0.7188)", "verif image answer": "laundry(0.7010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464903.jpg"}, {"question": "what are these two guys doing", "gt answer": "talk(1.00)<br/>compete(0.60)<br/>play game(0.60)", "pred answer": "fly kite", "question_id": 1260545, "best approach": "image", "verif answer": "play tennis", "anno approach": "wiki, concept, image", "verif wiki answer": "play tennis(0.7012)", "verif concept answer": "shake hand(0.7039)", "verif image answer": "compete(0.5700)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126054.jpg"}, {"question": "what level of schooling are these people in", "gt answer": "college(1.00)", "pred answer": "high", "question_id": 3463515, "best approach": "concept, image", "verif answer": "college", "anno approach": "wiki, concept, image", "verif wiki answer": "university(0.6780)", "verif concept answer": "college(0.6065)", "verif image answer": "college(0.7084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346351.jpg"}, {"question": "what are they celebrating", "gt answer": "gay pride(1.00)", "pred answer": "birthday", "question_id": 310805, "best approach": "concept", "verif answer": "graduation", "anno approach": "wiki, concept, image", "verif wiki answer": "city(0.6956)", "verif concept answer": "gay pride(0.6978)", "verif image answer": "graduation(0.5208)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000031080.jpg"}, {"question": "what type of plant is that in the vase", "gt answer": "leafy(1.00)<br/>leaf(0.60)<br/>hydrangea(0.60)", "pred answer": "aloe", "question_id": 968335, "best approach": "wiki, concept", "verif answer": "leaf", "anno approach": "wiki, concept, image", "verif wiki answer": "leaf(0.6604)", "verif concept answer": "leaf(0.6710)", "verif image answer": "plant(0.6867)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096833.jpg"}, {"question": "when you get on a horse you must grab a tuft of mane and what", "gt answer": "rein(1.00)", "pred answer": "saddle", "question_id": 4197145, "best approach": "concept", "verif answer": "saddle", "anno approach": "wiki, concept, image", "verif wiki answer": "vest(0.7228)", "verif concept answer": "rein(0.7096)", "verif image answer": "saddle(0.7113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419714.jpg"}, {"question": "how is the elephant squirting", "gt answer": "through his trunk(1.00)<br/>trunk(0.60)<br/>truck(0.60)", "pred answer": "drink", "question_id": 1904075, "best approach": "wiki, image", "verif answer": "truck", "anno approach": "wiki, concept, image", "verif wiki answer": "through his trunk(0.7031)", "verif concept answer": "truck(0.6282)", "verif image answer": "through his trunk(0.5227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190407.jpg"}, {"question": "what is this type of keyboard called", "gt answer": "qwerty(1.00)<br/>ibm(0.60)<br/>mechanical(0.60)", "pred answer": "keyboard", "question_id": 3343025, "best approach": "concept, image", "verif answer": "mechanical", "anno approach": "wiki, concept, image", "verif wiki answer": "ibm(0.6748)", "verif concept answer": "qwerty(0.7195)", "verif image answer": "qwerty(0.7239)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334302.jpg"}, {"question": "how do you know this isn't a professional chef", "gt answer": "child(1.00)<br/>little(0.60)", "pred answer": "clean", "question_id": 1488105, "best approach": "", "verif answer": "child", "anno approach": "wiki, concept, image", "verif wiki answer": "baby(0.5522)", "verif concept answer": "baby(0.5361)", "verif image answer": "kid(0.6051)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148810.jpg"}, {"question": "what type of photography is this called", "gt answer": "shadow(1.00)<br/>sunset(1.00)", "pred answer": "selfie", "question_id": 1217955, "best approach": "", "verif answer": "candid", "anno approach": "wiki, concept, image", "verif wiki answer": "candid(0.6594)", "verif concept answer": "candid(0.6615)", "verif image answer": "candid(0.6106)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000121795.jpg"}, {"question": "what kind of job would these people have", "gt answer": "office(1.00)", "pred answer": "president", "question_id": 3351895, "best approach": "concept", "verif answer": "drawer", "anno approach": "wiki, concept, image", "verif wiki answer": "nursery(0.5232)", "verif concept answer": "office(0.5611)", "verif image answer": "drawer(0.5837)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335189.jpg"}, {"question": "how many players are on the field during a regulation game", "gt answer": "22(1.00)<br/>9(0.60)<br/>18(0.60)<br/>10(0.60)", "pred answer": "6", "question_id": 3594145, "best approach": "wiki, concept, image", "verif answer": "9", "anno approach": "wiki, concept, image", "verif wiki answer": "9(0.7171)", "verif concept answer": "9(0.6325)", "verif image answer": "10(0.7010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359414.jpg"}, {"question": "what material are the walls made of", "gt answer": "cement(1.00)<br/>stone(0.60)", "pred answer": "brick", "question_id": 4480775, "best approach": "wiki, image", "verif answer": "concrete", "anno approach": "wiki, concept, image", "verif wiki answer": "stone(0.7198)", "verif concept answer": "chalk(0.6236)", "verif image answer": "stone(0.5355)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000448077.jpg"}, {"question": "how much to these animals need to drink each day", "gt answer": "50 gallons(1.00)<br/>gallon(0.60)", "pred answer": "lot", "question_id": 4710965, "best approach": "", "verif answer": "lot", "anno approach": "wiki, concept, image", "verif wiki answer": "fast(0.6963)", "verif concept answer": "fast(0.6926)", "verif image answer": "lot(0.6985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471096.jpg"}, {"question": "is this a drive thru or a car repair shop", "gt answer": "car repair shop(1.00)<br/>repair(0.60)", "pred answer": "sale", "question_id": 4089225, "best approach": "image", "verif answer": "walmart", "anno approach": "wiki, concept, image", "verif wiki answer": "custom(0.6567)", "verif concept answer": "walmart(0.6987)", "verif image answer": "repair(0.6967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408922.jpg"}, {"question": "what is around the man", "gt answer": "wine(1.00)<br/>bottle(0.60)", "pred answer": "glass", "question_id": 4171605, "best approach": "wiki, image", "verif answer": "alcohol", "anno approach": "wiki, concept, image", "verif wiki answer": "bottle(0.7188)", "verif concept answer": "alcoholic(0.6847)", "verif image answer": "bottle(0.6403)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000417160.jpg"}, {"question": "what children 's nursery rhym features this animal and a young girl attending school", "gt answer": "mary had little lamb(1.00)", "pred answer": "sheep", "question_id": 1873345, "best approach": "wiki", "verif answer": "teddy bear", "anno approach": "wiki, concept, image", "verif wiki answer": "mary had little lamb(0.7238)", "verif concept answer": "teddy bear(0.6659)", "verif image answer": "bear(0.6744)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000187334.jpg"}, {"question": "why are people behind this man", "gt answer": "watch(1.00)<br/>score(0.60)", "pred answer": "play tennis", "question_id": 5445025, "best approach": "", "verif answer": "shake hand", "anno approach": "wiki, concept, image", "verif wiki answer": "illumination(0.6947)", "verif concept answer": "shake hand(0.6359)", "verif image answer": "shake hand(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544502.jpg"}, {"question": "is this photo from the 50 's or the 90 's", "gt answer": "50's(1.00)", "pred answer": "1950's", "question_id": 2925965, "best approach": "", "verif answer": "1940", "anno approach": "wiki, concept, image", "verif wiki answer": "both(0.6425)", "verif concept answer": "1940(0.5998)", "verif image answer": "1940(0.5930)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292596.jpg"}, {"question": "how much fuel does this vehicle consume", "gt answer": "100 gallons(1.00)<br/>lot(0.60)", "pred answer": "ton", "question_id": 5161905, "best approach": "concept, image", "verif answer": "60", "anno approach": "wiki, concept, image", "verif wiki answer": "2 gallons(0.7205)", "verif concept answer": "100 gallons(0.7139)", "verif image answer": "100 gallons(0.7255)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516190.jpg"}, {"question": "what ethnicty are they", "gt answer": "white(1.00)<br/>american(0.60)", "pred answer": "indian", "question_id": 2073605, "best approach": "concept", "verif answer": "american", "anno approach": "wiki, concept, image", "verif wiki answer": "asian(0.7215)", "verif concept answer": "american(0.7257)", "verif image answer": "french(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207360.jpg"}, {"question": "which profession can make this", "gt answer": "baker(1.00)", "pred answer": "chef", "question_id": 1132165, "best approach": "concept", "verif answer": "baker", "anno approach": "wiki, concept, image", "verif wiki answer": "bakery(0.6344)", "verif concept answer": "baker(0.7000)", "verif image answer": "cook(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113216.jpg"}, {"question": "what breed are the cats", "gt answer": "domestic(1.00)<br/>domestic shorthair(0.60)<br/>feline(0.60)", "pred answer": "ragdoll", "question_id": 2907825, "best approach": "wiki, concept", "verif answer": "feline", "anno approach": "wiki, concept, image", "verif wiki answer": "feline(0.7075)", "verif concept answer": "domestic shorthair(0.7259)", "verif image answer": "cat(0.6713)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000290782.jpg"}, {"question": "which channel is sponsoring the game", "gt answer": "tennis channel(1.00)<br/>tennis(1.00)", "pred answer": "wimbledon", "question_id": 298945, "best approach": "", "verif answer": "wilson", "anno approach": "wiki, concept, image", "verif wiki answer": "wilson(0.6893)", "verif concept answer": "wilson(0.7246)", "verif image answer": "double(0.5990)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029894.jpg"}, {"question": "what does this woman need to wear to do this", "gt answer": "bath suit(1.00)<br/>wet suit(0.60)", "pred answer": "wetsuit", "question_id": 561195, "best approach": "wiki, image", "verif answer": "wetsuit", "anno approach": "wiki, concept, image", "verif wiki answer": "wet suit(0.7111)", "verif concept answer": "wetsuit(0.7065)", "verif image answer": "wet suit(0.6497)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000056119.jpg"}, {"question": "what kind of bus is this", "gt answer": "double decker(1.00)", "pred answer": "tour", "question_id": 5680505, "best approach": "wiki, concept, image", "verif answer": "double decker", "anno approach": "wiki, concept, image", "verif wiki answer": "double decker(0.7289)", "verif concept answer": "double decker(0.7294)", "verif image answer": "double decker(0.7282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568050.jpg"}, {"question": "what kind of trick is this skateboarder doing", "gt answer": "hard flip(1.00)<br/>180(0.60)<br/>jump(0.60)<br/>high(0.60)", "pred answer": "ollie", "question_id": 3464695, "best approach": "wiki", "verif answer": "ollie", "anno approach": "wiki, concept, image", "verif wiki answer": "hard flip(0.6872)", "verif concept answer": "ollie(0.6648)", "verif image answer": "ollie(0.6443)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346469.jpg"}, {"question": "what kind of food is being served here", "gt answer": "hot dog(1.00)", "pred answer": "hotdog", "question_id": 1067145, "best approach": "concept, image", "verif answer": "hotdog", "anno approach": "wiki, concept, image", "verif wiki answer": "hotdog(0.7147)", "verif concept answer": "hot dog(0.7081)", "verif image answer": "hot dog(0.6851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106714.jpg"}, {"question": "what emotion does the symbol on this purse traditionally represent", "gt answer": "love(1.00)", "pred answer": "happiness", "question_id": 4279755, "best approach": "concept, image", "verif answer": "happiness", "anno approach": "wiki, concept, image", "verif wiki answer": "sad(0.6819)", "verif concept answer": "love(0.6800)", "verif image answer": "love(0.6105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427975.jpg"}, {"question": "what is the name of the board on the left", "gt answer": "surfboard(1.00)<br/>surf(0.60)<br/>boogie board(0.60)", "pred answer": "surf board", "question_id": 1148865, "best approach": "", "verif answer": "surf board", "anno approach": "wiki, concept, image", "verif wiki answer": "surf board(0.7270)", "verif concept answer": "surf board(0.6475)", "verif image answer": "surf board(0.7003)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114886.jpg"}, {"question": "how old is this cat", "gt answer": "7(1.00)<br/>5(0.60)<br/>10 years(0.60)", "pred answer": "15 years", "question_id": 2713575, "best approach": "concept", "verif answer": "10 years", "anno approach": "wiki, concept, image", "verif wiki answer": "14(0.6716)", "verif concept answer": "10 years(0.6501)", "verif image answer": "3(0.6687)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000271357.jpg"}, {"question": "where would you have a party like this", "gt answer": "college(1.00)<br/>home(1.00)<br/>dorm(0.60)", "pred answer": "house", "question_id": 3797325, "best approach": "wiki", "verif answer": "school", "anno approach": "wiki, concept, image", "verif wiki answer": "home(0.6949)", "verif concept answer": "hotel(0.6873)", "verif image answer": "school(0.5325)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379732.jpg"}, {"question": "what is the total calories in this box of donuts", "gt answer": "4000(1.00)<br/>5000(0.60)", "pred answer": "200", "question_id": 753625, "best approach": "concept, image", "verif answer": "200", "anno approach": "wiki, concept, image", "verif wiki answer": "50(0.7146)", "verif concept answer": "5000(0.7137)", "verif image answer": "5000(0.6396)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075362.jpg"}, {"question": "what is the top speed of a typical vehicle like this", "gt answer": "50 mph(1.00)<br/>100 mph(0.60)<br/>100(0.60)", "pred answer": "30 mph", "question_id": 83945, "best approach": "image", "verif answer": "30 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "100(0.7206)", "verif concept answer": "100(0.7009)", "verif image answer": "50 mph(0.7147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008394.jpg"}, {"question": "what style of lamp are in the room 's corner", "gt answer": "stand(1.00)<br/>modern(0.60)", "pred answer": "lamp", "question_id": 541215, "best approach": "wiki", "verif answer": "modern", "anno approach": "wiki, concept, image", "verif wiki answer": "stand(0.7243)", "verif concept answer": "modern(0.6155)", "verif image answer": "feed(0.6493)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000054121.jpg"}, {"question": "when was this piece of sporting equipment invented", "gt answer": "1926(1.00)<br/>1965(0.60)<br/>surfboard(0.60)", "pred answer": "1769", "question_id": 250245, "best approach": "wiki, concept, image", "verif answer": "surf board", "anno approach": "wiki, concept, image", "verif wiki answer": "1926(0.6271)", "verif concept answer": "1926(0.6958)", "verif image answer": "1926(0.6500)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025024.jpg"}, {"question": "which ball park meat frequently appears surrounded by bread like this", "gt answer": "hotdog(1.00)<br/>hot dog(1.00)", "pred answer": "bacon", "question_id": 70285, "best approach": "wiki", "verif answer": "hotdog", "anno approach": "wiki, concept, image", "verif wiki answer": "hotdog(0.7139)", "verif concept answer": "find nemo(0.6281)", "verif image answer": "find nemo(0.5908)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007028.jpg"}, {"question": "what do these green vegetables originate as", "gt answer": "cucumber(1.00)", "pred answer": "produce", "question_id": 1714295, "best approach": "", "verif answer": "zucchini", "anno approach": "wiki, concept, image", "verif wiki answer": "zucchini(0.7180)", "verif concept answer": "zucchini(0.7121)", "verif image answer": "zucchini(0.5190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171429.jpg"}, {"question": "what city is known for hosting the us open of this sport", "gt answer": "huntington beach(1.00)<br/>san diego(0.60)", "pred answer": "california", "question_id": 2421335, "best approach": "image", "verif answer": "san diego", "anno approach": "wiki, concept, image", "verif wiki answer": "philadelphia(0.7016)", "verif concept answer": "philadelphia(0.7273)", "verif image answer": "huntington beach(0.6109)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000242133.jpg"}, {"question": "which model of bike is shown in this picture", "gt answer": "vespa(1.00)<br/>bike(0.60)<br/>scooter(0.60)", "pred answer": "motorcycle", "question_id": 886975, "best approach": "image", "verif answer": "bicycle", "anno approach": "wiki, concept, image", "verif wiki answer": "bike(0.7104)", "verif concept answer": "bmw(0.6873)", "verif image answer": "vespa(0.5886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088697.jpg"}, {"question": "what type of plane is this", "gt answer": "jet(1.00)<br/>private jet(0.60)", "pred answer": "biplane", "question_id": 4357775, "best approach": "wiki, concept", "verif answer": "jet", "anno approach": "wiki, concept, image", "verif wiki answer": "private jet(0.7190)", "verif concept answer": "private jet(0.7017)", "verif image answer": "fighter(0.7046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435777.jpg"}, {"question": "who invented the stuffed animal in the picture", "gt answer": "morris michtom(1.00)<br/>theodore roosevelt(0.60)<br/>ted(0.60)<br/>roosevelt(0.60)", "pred answer": "build bear", "question_id": 5270735, "best approach": "wiki, concept, image", "verif answer": "roosevelt", "anno approach": "wiki, concept, image", "verif wiki answer": "ted(0.7271)", "verif concept answer": "roosevelt(0.7227)", "verif image answer": "roosevelt(0.7197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527073.jpg"}, {"question": "what is this kid doing on his phone", "gt answer": "play game(1.00)<br/>text(1.00)<br/>play(0.60)", "pred answer": "take picture", "question_id": 3287405, "best approach": "wiki, concept", "verif answer": "talk", "anno approach": "wiki, concept, image", "verif wiki answer": "text(0.7264)", "verif concept answer": "text(0.7241)", "verif image answer": "talk(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328740.jpg"}, {"question": "what is she eating", "gt answer": "hotdog(1.00)<br/>bread(0.60)", "pred answer": "hotdogs", "question_id": 5072525, "best approach": "concept", "verif answer": "hot dog", "anno approach": "wiki, concept, image", "verif wiki answer": "hot dog(0.6798)", "verif concept answer": "hotdog(0.6758)", "verif image answer": "bread(0.5248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507252.jpg"}, {"question": "what kind of toy is shown in this picture", "gt answer": "lego(1.00)<br/>build(0.60)", "pred answer": "toilet", "question_id": 3662555, "best approach": "concept, image", "verif answer": "ring", "anno approach": "wiki, concept, image", "verif wiki answer": "build(0.7080)", "verif concept answer": "lego(0.6726)", "verif image answer": "lego(0.5917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366255.jpg"}, {"question": "what is hindering these people from seeing clearly", "gt answer": "fog(1.00)<br/>rain(0.60)", "pred answer": "light", "question_id": 1684885, "best approach": "wiki", "verif answer": "umbrella", "anno approach": "wiki, concept, image", "verif wiki answer": "fog(0.6225)", "verif concept answer": "umbrella(0.5326)", "verif image answer": "rain(0.5146)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168488.jpg"}, {"question": "what kind of dancer", "gt answer": "hula(1.00)", "pred answer": "dumbo", "question_id": 572645, "best approach": "image", "verif answer": "asian", "anno approach": "wiki, concept, image", "verif wiki answer": "race(0.5257)", "verif concept answer": "asian(0.5404)", "verif image answer": "hula(0.5524)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000057264.jpg"}, {"question": "what fruit family are these from", "gt answer": "citrus(1.00)<br/>fruit(0.60)", "pred answer": "orange", "question_id": 2612355, "best approach": "concept", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "fruit(0.7198)", "verif concept answer": "citrus(0.7205)", "verif image answer": "fruit(0.7197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261235.jpg"}, {"question": "what kind of job does the person with this desk have", "gt answer": "writer(1.00)<br/>artist(0.60)", "pred answer": "account", "question_id": 4600685, "best approach": "concept", "verif answer": "cook", "anno approach": "wiki, concept, image", "verif wiki answer": "aspca(0.6733)", "verif concept answer": "writer(0.5493)", "verif image answer": "barber(0.5833)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460068.jpg"}, {"question": "what does this sign signify", "gt answer": "crosswalk(1.00)<br/>pedestrian cross(0.60)<br/>cross(0.60)<br/>road(0.60)", "pred answer": "no park", "question_id": 726015, "best approach": "wiki, concept, image", "verif answer": "pedestrian cross", "anno approach": "wiki, concept, image", "verif wiki answer": "crosswalk(0.6782)", "verif concept answer": "crosswalk(0.7176)", "verif image answer": "crosswalk(0.5598)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000072601.jpg"}, {"question": "what style of architecture is pictured in this photo", "gt answer": "gothic(1.00)<br/>victorian(0.60)<br/>roman(0.60)<br/>cathedral(0.60)", "pred answer": "classic", "question_id": 2756315, "best approach": "wiki", "verif answer": "roman", "anno approach": "wiki, concept, image", "verif wiki answer": "gothic(0.6967)", "verif concept answer": "roman(0.6760)", "verif image answer": "roman(0.6595)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000275631.jpg"}, {"question": "why do these bikes likely belong to the same person", "gt answer": "same color(1.00)", "pred answer": "children", "question_id": 2163785, "best approach": "", "verif answer": "50 years", "anno approach": "wiki, concept, image", "verif wiki answer": "easy(0.7091)", "verif concept answer": "easy(0.7052)", "verif image answer": "easy(0.7002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216378.jpg"}, {"question": "what ethnicity this picture can be related", "gt answer": "british(1.00)<br/>india(0.60)<br/>english(0.60)<br/>indian(0.60)", "pred answer": "asian", "question_id": 3929435, "best approach": "wiki", "verif answer": "american", "anno approach": "wiki, concept, image", "verif wiki answer": "british(0.6831)", "verif concept answer": "american(0.7118)", "verif image answer": "english(0.7141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392943.jpg"}, {"question": "what type of cat would you say is relaxing on the chair", "gt answer": "burmese(1.00)<br/>calico(0.60)<br/>house cat(0.60)", "pred answer": "siamese", "question_id": 5716715, "best approach": "wiki, concept", "verif answer": "domestic", "anno approach": "wiki, concept, image", "verif wiki answer": "calico(0.6648)", "verif concept answer": "calico(0.7235)", "verif image answer": "domestic(0.6491)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571671.jpg"}, {"question": "what do people use elephant tusks for", "gt answer": "ivory(1.00)<br/>jewelry(0.60)", "pred answer": "forget", "question_id": 2104515, "best approach": "wiki, concept, image", "verif answer": "ivory", "anno approach": "wiki, concept, image", "verif wiki answer": "ivory(0.6763)", "verif concept answer": "ivory(0.6373)", "verif image answer": "ivory(0.7263)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210451.jpg"}, {"question": "what company makes the famous red bottle that the woman is holding", "gt answer": "heinz(1.00)", "pred answer": "coca cola", "question_id": 3355255, "best approach": "", "verif answer": "walmart", "anno approach": "wiki, concept, image", "verif wiki answer": "walmart(0.6556)", "verif concept answer": "walmart(0.5771)", "verif image answer": "walmart(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335525.jpg"}, {"question": "who is this famous person in this picture", "gt answer": "lindsey vonn(1.00)<br/>skier(0.60)", "pred answer": "bode miller", "question_id": 711225, "best approach": "wiki", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "lindsey vonn(0.7206)", "verif concept answer": "ski lift(0.6163)", "verif image answer": "person(0.6560)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071122.jpg"}, {"question": "what type of net is in the photo", "gt answer": "volleyball(1.00)", "pred answer": "polo", "question_id": 3371515, "best approach": "", "verif answer": "polo", "anno approach": "wiki, concept, image", "verif wiki answer": "badminton(0.5415)", "verif concept answer": "polo(0.5520)", "verif image answer": "frisbee(0.5195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337151.jpg"}, {"question": "how old is the cat", "gt answer": "4 weeks(1.00)<br/>0(0.60)<br/>2 weeks(0.60)", "pred answer": "10 years", "question_id": 3688525, "best approach": "wiki, concept, image", "verif answer": "10 years", "anno approach": "wiki, concept, image", "verif wiki answer": "2 weeks(0.6930)", "verif concept answer": "0(0.6615)", "verif image answer": "0(0.6933)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000368852.jpg"}, {"question": "which bus has a higer top speed", "gt answer": "coach(1.00)<br/>right(0.60)<br/>left(0.60)", "pred answer": "tour", "question_id": 3229695, "best approach": "", "verif answer": "right", "anno approach": "wiki, concept, image", "verif wiki answer": "front(0.6792)", "verif concept answer": "front(0.6203)", "verif image answer": "mother(0.6463)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322969.jpg"}, {"question": "what type of hat is the middle boy wearing", "gt answer": "baseball(1.00)<br/>helmet(0.60)", "pred answer": "fedora", "question_id": 3821005, "best approach": "wiki, concept", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "helmet(0.7140)", "verif concept answer": "helmet(0.6062)", "verif image answer": "baseball game(0.6239)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382100.jpg"}, {"question": "what female garment is also a part of this animal 's name", "gt answer": "bra(1.00)", "pred answer": "stripe", "question_id": 4983545, "best approach": "wiki, concept, image", "verif answer": "mare", "anno approach": "wiki, concept, image", "verif wiki answer": "bra(0.6385)", "verif concept answer": "bra(0.6987)", "verif image answer": "bra(0.6923)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000498354.jpg"}, {"question": "is this cow on a farm or at an animal show", "gt answer": "show(1.00)", "pred answer": "stable", "question_id": 1852915, "best approach": "image", "verif answer": "guard", "anno approach": "wiki, concept, image", "verif wiki answer": "functional(0.7303)", "verif concept answer": "guard(0.7222)", "verif image answer": "show(0.7203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185291.jpg"}, {"question": "what is the purpose of this vehicle", "gt answer": "sail(1.00)<br/>transportation(0.60)<br/>tug(0.60)", "pred answer": "transport", "question_id": 5102605, "best approach": "wiki, concept, image", "verif answer": "tug", "anno approach": "wiki, concept, image", "verif wiki answer": "tug(0.6761)", "verif concept answer": "tug(0.6690)", "verif image answer": "tug(0.6281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510260.jpg"}, {"question": "is she fighting or playing", "gt answer": "play(1.00)<br/>play tennis(0.60)", "pred answer": "hit", "question_id": 3450535, "best approach": "wiki, concept", "verif answer": "play", "anno approach": "wiki, concept, image", "verif wiki answer": "play(0.6973)", "verif concept answer": "play(0.6367)", "verif image answer": "perform(0.6439)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345053.jpg"}, {"question": "how do you make this make noise", "gt answer": "pluck string(1.00)", "pred answer": "music", "question_id": 4681635, "best approach": "concept", "verif answer": "hair", "anno approach": "wiki, concept, image", "verif wiki answer": "tail(0.6737)", "verif concept answer": "pluck string(0.5322)", "verif image answer": "hair(0.6962)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000468163.jpg"}, {"question": "what is the name of this type of motorcycle", "gt answer": "kawasaki(1.00)", "pred answer": "honda", "question_id": 4702075, "best approach": "concept", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "racer(0.6940)", "verif concept answer": "kawasaki(0.7137)", "verif image answer": "honda(0.6856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470207.jpg"}, {"question": "what are these men", "gt answer": "pilot(1.00)<br/>military(0.60)<br/>protest(0.60)", "pred answer": "parade", "question_id": 5514185, "best approach": "wiki, concept, image", "verif answer": "military", "anno approach": "wiki, concept, image", "verif wiki answer": "military(0.7237)", "verif concept answer": "military(0.7278)", "verif image answer": "military(0.5257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000551418.jpg"}, {"question": "what might be some alternate uses of the can shown in the photo", "gt answer": "vase(1.00)<br/>cookie cutter(0.60)<br/>pot(0.60)", "pred answer": "food", "question_id": 1824685, "best approach": "concept, image", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "pottery(0.5828)", "verif concept answer": "pot(0.6318)", "verif image answer": "pot(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182468.jpg"}, {"question": "what is the appliance that the man has opened the door or", "gt answer": "refrigerator(1.00)<br/>fridge(0.60)", "pred answer": "oven", "question_id": 3976455, "best approach": "wiki", "verif answer": "refrigerator", "anno approach": "wiki, concept, image", "verif wiki answer": "refrigerator(0.7278)", "verif concept answer": "fridge(0.6956)", "verif image answer": "c(0.5565)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397645.jpg"}, {"question": "what type of phone does he have in his hand", "gt answer": "flip(1.00)<br/>cell(0.60)<br/>flip phone(0.60)", "pred answer": "smartphone", "question_id": 4991795, "best approach": "wiki, image", "verif answer": "cellphone", "anno approach": "wiki, concept, image", "verif wiki answer": "cell(0.7287)", "verif concept answer": "motorola(0.7098)", "verif image answer": "cell(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499179.jpg"}, {"question": "what brand of paint is on the walls", "gt answer": "behr(1.00)", "pred answer": "graffiti", "question_id": 2815785, "best approach": "wiki, concept", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "behr(0.5501)", "verif concept answer": "behr(0.5939)", "verif image answer": "bad(0.6323)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281578.jpg"}, {"question": "what people group is known for this type of architecture", "gt answer": "romans(1.00)<br/>greek(0.60)", "pred answer": "urban", "question_id": 5678585, "best approach": "", "verif answer": "greek", "anno approach": "wiki, concept, image", "verif wiki answer": "chinese(0.6507)", "verif concept answer": "chinese(0.6278)", "verif image answer": "cowboy(0.6400)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567858.jpg"}, {"question": "what hemisphere is this location", "gt answer": "southern(1.00)<br/>northern(0.60)<br/>rainforest(0.60)<br/>asia(0.60)", "pred answer": "forest", "question_id": 5229465, "best approach": "image", "verif answer": "north america", "anno approach": "wiki, concept, image", "verif wiki answer": "asia(0.6595)", "verif concept answer": "north america(0.6469)", "verif image answer": "southern(0.5257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522946.jpg"}, {"question": "what sort of room is this woman sitting in", "gt answer": "nursery(1.00)<br/>office(0.60)", "pred answer": "live room", "question_id": 1747585, "best approach": "wiki", "verif answer": "home", "anno approach": "wiki, concept, image", "verif wiki answer": "office(0.6849)", "verif concept answer": "home(0.6339)", "verif image answer": "home(0.7222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174758.jpg"}, {"question": "what do these animals eat", "gt answer": "grain(1.00)<br/>seed(0.60)", "pred answer": "grass", "question_id": 1626825, "best approach": "wiki", "verif answer": "seed", "anno approach": "wiki, concept, image", "verif wiki answer": "grain(0.6782)", "verif concept answer": "seed(0.6508)", "verif image answer": "seed(0.7072)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162682.jpg"}, {"question": "is it this a stuff animal or a cake", "gt answer": "stuff animal(1.00)<br/>stuffed(0.60)<br/>stuffed animal(0.60)", "pred answer": "bear", "question_id": 192385, "best approach": "wiki", "verif answer": "bear", "anno approach": "wiki, concept, image", "verif wiki answer": "stuff animal(0.6346)", "verif concept answer": "teddy bear(0.7045)", "verif image answer": "bear(0.6259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019238.jpg"}, {"question": "how much is a slice of pizza", "gt answer": "3.2(1.00)", "pred answer": "20 pounds", "question_id": 4785975, "best approach": "", "verif answer": "300", "anno approach": "wiki, concept, image", "verif wiki answer": "300(0.6160)", "verif concept answer": "dough(0.6829)", "verif image answer": "10000(0.6517)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478597.jpg"}, {"question": "what are plates napkins silverware and glasses arranged in this manner called", "gt answer": "set(1.00)", "pred answer": "chopstick", "question_id": 551305, "best approach": "wiki, image", "verif answer": "triangle", "anno approach": "wiki, concept, image", "verif wiki answer": "set(0.6938)", "verif concept answer": "triangle(0.6028)", "verif image answer": "set(0.5544)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000055130.jpg"}, {"question": "who is this attraction for", "gt answer": "adult(0.60)<br/>human(0.60)<br/>tourist(1.00)", "pred answer": "kid", "question_id": 2867045, "best approach": "wiki, concept, image", "verif answer": "people", "anno approach": "wiki, concept, image", "verif wiki answer": "human(0.7114)", "verif concept answer": "human(0.5864)", "verif image answer": "human(0.5887)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000286704.jpg"}, {"question": "what is inside the red and white barrel", "gt answer": "trash(1.00)<br/>garbage(1.00)", "pred answer": "cloth", "question_id": 4002985, "best approach": "wiki", "verif answer": "trash", "anno approach": "wiki, concept, image", "verif wiki answer": "garbage(0.6792)", "verif concept answer": "garbage truck(0.7163)", "verif image answer": "food(0.6048)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400298.jpg"}, {"question": "when is best to use this toy", "gt answer": "windy day(1.00)<br/>windy(0.60)", "pred answer": "no wind", "question_id": 2383015, "best approach": "concept", "verif answer": "night", "anno approach": "wiki, concept, image", "verif wiki answer": "night(0.6986)", "verif concept answer": "windy day(0.6982)", "verif image answer": "saturday(0.6518)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238301.jpg"}, {"question": "crumpets and a side of", "gt answer": "grape(1.00)<br/>jam(0.60)", "pred answer": "butter", "question_id": 1329935, "best approach": "image", "verif answer": "tomato", "anno approach": "wiki, concept, image", "verif wiki answer": "jelly(0.6859)", "verif concept answer": "apple(0.7107)", "verif image answer": "grape(0.7246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000132993.jpg"}, {"question": "what is the name of the name show that said help control population of these", "gt answer": "aspca(1.00)<br/>cat(0.60)", "pred answer": "rabies", "question_id": 1747005, "best approach": "image", "verif answer": "cat", "anno approach": "wiki, concept, image", "verif wiki answer": "cat(0.6878)", "verif concept answer": "cat(0.6821)", "verif image answer": "aspca(0.6875)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174700.jpg"}, {"question": "what is the man in this image doing", "gt answer": "talk on cell phone(1.00)<br/>leave(0.60)<br/>stand(0.60)", "pred answer": "talk", "question_id": 1815095, "best approach": "wiki", "verif answer": "talk", "anno approach": "wiki, concept, image", "verif wiki answer": "talk on cell phone(0.6370)", "verif concept answer": "stand(0.6261)", "verif image answer": "leave(0.6759)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181509.jpg"}, {"question": "what is the orange triangle in the road called", "gt answer": "cone(1.00)<br/>street sign(0.60)", "pred answer": "crosswalk", "question_id": 4963625, "best approach": "wiki, concept, image", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "street sign(0.7022)", "verif concept answer": "street sign(0.7089)", "verif image answer": "street sign(0.5113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496362.jpg"}, {"question": "what is the weather like today", "gt answer": "warm(1.00)<br/>windy(0.60)<br/>hot(0.60)", "pred answer": "sunny", "question_id": 628445, "best approach": "concept", "verif answer": "sunny", "anno approach": "wiki, concept, image", "verif wiki answer": "even(0.7200)", "verif concept answer": "hot(0.7034)", "verif image answer": "sunny(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000062844.jpg"}, {"question": "how big is the ocean", "gt answer": "very big(1.00)", "pred answer": "1 mile", "question_id": 2401295, "best approach": "", "verif answer": "15 pounds", "anno approach": "wiki, concept, image", "verif wiki answer": "15 pounds(0.7056)", "verif concept answer": "pacific(0.6227)", "verif image answer": "50 feet(0.5632)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240129.jpg"}, {"question": "does she seem to be a telemarketer or goofing off", "gt answer": "goof off(1.00)", "pred answer": "karaoke", "question_id": 3080535, "best approach": "concept, image", "verif answer": "play", "anno approach": "wiki, concept, image", "verif wiki answer": "play(0.6739)", "verif concept answer": "goof off(0.7122)", "verif image answer": "goof off(0.5392)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308053.jpg"}, {"question": "what language is featured on the cart", "gt answer": "spanish(1.00)<br/>hispanic(0.60)", "pred answer": "arabic", "question_id": 2307125, "best approach": "concept", "verif answer": "spanish", "anno approach": "wiki, concept, image", "verif wiki answer": "italian(0.7103)", "verif concept answer": "spanish(0.7087)", "verif image answer": "italian(0.7037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000230712.jpg"}, {"question": "what year was this picture taken", "gt answer": "1930(1.00)<br/>1912(0.60)", "pred answer": "1950", "question_id": 1651995, "best approach": "", "verif answer": "1930", "anno approach": "wiki, concept, image", "verif wiki answer": "1914(0.7223)", "verif concept answer": "1914(0.7223)", "verif image answer": "1914(0.5925)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000165199.jpg"}, {"question": "what evolutionary advantage does the neck of a giraffe give it", "gt answer": "reach(1.00)", "pred answer": "neck", "question_id": 2873605, "best approach": "image", "verif answer": "be tall", "anno approach": "wiki, concept, image", "verif wiki answer": "be tall(0.7286)", "verif concept answer": "be tall(0.7073)", "verif image answer": "reach(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287360.jpg"}, {"question": "what are the items on top of the microwave", "gt answer": "bread(1.00)<br/>cookies(0.60)", "pred answer": "towel", "question_id": 5373495, "best approach": "image", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "cookies(0.6732)", "verif concept answer": "cookies(0.6534)", "verif image answer": "bread(0.5828)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537349.jpg"}, {"question": "the frontmost car is known as what brand", "gt answer": "mini cooper(1.00)", "pred answer": "toyota", "question_id": 4621295, "best approach": "concept", "verif answer": "ford", "anno approach": "wiki, concept, image", "verif wiki answer": "ford(0.7108)", "verif concept answer": "mini cooper(0.6995)", "verif image answer": "ford(0.7219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000462129.jpg"}, {"question": "what animal depicted here is famously associated with squares", "gt answer": "pigeon(1.00)<br/>bird(0.60)", "pred answer": "duck", "question_id": 630175, "best approach": "", "verif answer": "pelican", "anno approach": "wiki, concept, image", "verif wiki answer": "pelican(0.7258)", "verif concept answer": "pelican(0.7176)", "verif image answer": "pelican(0.6331)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063017.jpg"}, {"question": "which category of food is in the photo", "gt answer": "sandwich(1.00)<br/>fast(0.60)<br/>bread(0.60)", "pred answer": "hotdogs", "question_id": 5615455, "best approach": "image", "verif answer": "hot dog", "anno approach": "wiki, concept, image", "verif wiki answer": "hot dog(0.7219)", "verif concept answer": "hot dog(0.7180)", "verif image answer": "sandwich(0.6583)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561545.jpg"}, {"question": "do these snacks need to be cooked or can they be prepared raw", "gt answer": "raw(1.00)<br/>cooked(1.00)", "pred answer": "steamed", "question_id": 1627605, "best approach": "wiki", "verif answer": "cooked", "anno approach": "wiki, concept, image", "verif wiki answer": "raw(0.7163)", "verif concept answer": "undercooked(0.7148)", "verif image answer": "bad(0.6150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162760.jpg"}, {"question": "who invented the object being held", "gt answer": "tom blake(1.00)", "pred answer": "ben franklin", "question_id": 5556065, "best approach": "", "verif answer": "kelly slater", "anno approach": "wiki, concept, image", "verif wiki answer": "kelly slater(0.7006)", "verif concept answer": "kelly slater(0.6695)", "verif image answer": "kelly slater(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555606.jpg"}, {"question": "what type of plant is in the green jar", "gt answer": "flower(1.00)", "pred answer": "fern", "question_id": 3728705, "best approach": "wiki", "verif answer": "flower", "anno approach": "wiki, concept, image", "verif wiki answer": "flower(0.7038)", "verif concept answer": "orange(0.6412)", "verif image answer": "orange(0.6930)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372870.jpg"}, {"question": "why would this person need an umbrella", "gt answer": "snow(1.00)", "pred answer": "rain", "question_id": 5011185, "best approach": "concept", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "rain(0.7020)", "verif concept answer": "snow(0.6490)", "verif image answer": "rain(0.7012)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501118.jpg"}, {"question": "what plane is that", "gt answer": "pacific southwest(1.00)", "pred answer": "747", "question_id": 1770235, "best approach": "", "verif answer": "double decker", "anno approach": "wiki, concept, image", "verif wiki answer": "double decker(0.7237)", "verif concept answer": "double decker(0.7112)", "verif image answer": "double decker(0.7071)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177023.jpg"}, {"question": "why are these dogs on the floor", "gt answer": "sleep(1.00)", "pred answer": "rest", "question_id": 2963855, "best approach": "wiki", "verif answer": "sleep", "anno approach": "wiki, concept, image", "verif wiki answer": "sleep(0.7151)", "verif concept answer": "read(0.7034)", "verif image answer": "tired(0.5671)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296385.jpg"}, {"question": "what country exports the most of this fruit", "gt answer": "ecuador(1.00)<br/>peru(0.60)<br/>brazil(0.60)", "pred answer": "south america", "question_id": 3667955, "best approach": "", "verif answer": "brazil", "anno approach": "wiki, concept, image", "verif wiki answer": "india(0.6281)", "verif concept answer": "guatemala(0.6065)", "verif image answer": "india(0.5948)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366795.jpg"}, {"question": "what part of the neighborhood would you find this", "gt answer": "playground(1.00)<br/>park(0.60)", "pred answer": "field", "question_id": 4056305, "best approach": "concept", "verif answer": "park", "anno approach": "wiki, concept, image", "verif wiki answer": "park(0.6664)", "verif concept answer": "playground(0.6625)", "verif image answer": "pasture(0.7113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405630.jpg"}, {"question": "what country 's flag is pictured on this skier 's jacket", "gt answer": "switzerland(1.00)", "pred answer": "canada", "question_id": 825135, "best approach": "", "verif answer": "norway", "anno approach": "wiki, concept, image", "verif wiki answer": "germany(0.5971)", "verif concept answer": "germany(0.6936)", "verif image answer": "sweden(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082513.jpg"}, {"question": "which type of road is the person riding on", "gt answer": "racetrack(1.00)<br/>asphalt(1.00)<br/>track(0.60)", "pred answer": "road", "question_id": 814165, "best approach": "wiki, concept", "verif answer": "road", "anno approach": "wiki, concept, image", "verif wiki answer": "asphalt(0.6319)", "verif concept answer": "racetrack(0.6280)", "verif image answer": "wood(0.6967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081416.jpg"}, {"question": "am i a brown bear or a black bear", "gt answer": "black(1.00)", "pred answer": "black bear", "question_id": 2068305, "best approach": "", "verif answer": "black bear", "anno approach": "wiki, concept, image", "verif wiki answer": "black bear(0.7114)", "verif concept answer": "black bear(0.7116)", "verif image answer": "black bear(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206830.jpg"}, {"question": "what should you do before doing this", "gt answer": "look(1.00)<br/>look both way(1.00)", "pred answer": "forget", "question_id": 3560605, "best approach": "wiki, image", "verif answer": "turn", "anno approach": "wiki, concept, image", "verif wiki answer": "look(0.6981)", "verif concept answer": "turn(0.6843)", "verif image answer": "look(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356060.jpg"}, {"question": "what variant of this fruit has the same name as the human belly button", "gt answer": "navel(1.00)", "pred answer": "orange", "question_id": 208825, "best approach": "image", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "orange(0.6849)", "verif concept answer": "orange(0.6612)", "verif image answer": "navel(0.5359)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020882.jpg"}, {"question": "how do these plants improve the quality of our air", "gt answer": "photosynthesis(1.00)<br/>oxygen(0.60)", "pred answer": "water", "question_id": 5759185, "best approach": "concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "oxygen(0.7265)", "verif concept answer": "photosynthesis(0.6466)", "verif image answer": "oxygen(0.6300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575918.jpg"}, {"question": "what is the woman doing", "gt answer": "puke(1.00)<br/>vomit(0.60)", "pred answer": "wash", "question_id": 5070495, "best approach": "concept, image", "verif answer": "wash", "anno approach": "wiki, concept, image", "verif wiki answer": "vomit(0.6265)", "verif concept answer": "puke(0.6892)", "verif image answer": "puke(0.6229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507049.jpg"}, {"question": "what is the area on this device where you control what you see and do called", "gt answer": "screen(1.00)<br/>monitor(0.60)", "pred answer": "turn it off", "question_id": 4609165, "best approach": "wiki, concept, image", "verif answer": "monitor", "anno approach": "wiki, concept, image", "verif wiki answer": "screen(0.7237)", "verif concept answer": "screen(0.6369)", "verif image answer": "screen(0.6464)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460916.jpg"}, {"question": "what is the object above the plane", "gt answer": "shuttle(1.00)<br/>cloud(0.60)", "pred answer": "air", "question_id": 2039695, "best approach": "image", "verif answer": "sky", "anno approach": "wiki, concept, image", "verif wiki answer": "helicopter(0.6775)", "verif concept answer": "helicopter(0.6805)", "verif image answer": "shuttle(0.6254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203969.jpg"}, {"question": "what type of shoes does the man have sitting in front of him", "gt answer": "sandal(1.00)<br/>0(0.60)<br/>flip flop(0.60)", "pred answer": "loafer", "question_id": 4915975, "best approach": "image", "verif answer": "sandal", "anno approach": "wiki, concept, image", "verif wiki answer": "flip flop(0.7296)", "verif concept answer": "flip flop(0.7294)", "verif image answer": "sandal(0.6103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491597.jpg"}, {"question": "how high can this jet fly", "gt answer": "40000 feet(1.00)", "pred answer": "30000 feet", "question_id": 3178615, "best approach": "wiki, concept", "verif answer": "200 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "40000 feet(0.7233)", "verif concept answer": "40000 feet(0.7099)", "verif image answer": "200 feet(0.6983)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317861.jpg"}, {"question": "who invented carpet", "gt answer": "sprague(1.00)", "pred answer": "ben franklin", "question_id": 573005, "best approach": "wiki, concept, image", "verif answer": "maid", "anno approach": "wiki, concept, image", "verif wiki answer": "sprague(0.7122)", "verif concept answer": "sprague(0.7196)", "verif image answer": "sprague(0.7009)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000057300.jpg"}, {"question": "this sport is often done in spring for what reason", "gt answer": "weather(1.00)<br/>wind(0.60)", "pred answer": "tan", "question_id": 2706365, "best approach": "wiki, image", "verif answer": "wind", "anno approach": "wiki, concept, image", "verif wiki answer": "weather(0.6679)", "verif concept answer": "string(0.6380)", "verif image answer": "weather(0.6950)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270636.jpg"}, {"question": "what are they doing to the plane", "gt answer": "wash(1.00)<br/>de ice(1.00)<br/>wash it(0.60)", "pred answer": "fly", "question_id": 3513825, "best approach": "concept, image", "verif answer": "wash", "anno approach": "wiki, concept, image", "verif wiki answer": "poop(0.6256)", "verif concept answer": "wash(0.5835)", "verif image answer": "wash(0.6187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000351382.jpg"}, {"question": "what type of boats are those", "gt answer": "ferry(1.00)<br/>house(0.60)<br/>raft(0.60)", "pred answer": "fish", "question_id": 1865525, "best approach": "image", "verif answer": "barge", "anno approach": "wiki, concept, image", "verif wiki answer": "barge(0.6849)", "verif concept answer": "sailboat(0.6997)", "verif image answer": "raft(0.7103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186552.jpg"}, {"question": "what emotions do you think she is feeling", "gt answer": "boredom(1.00)<br/>happiness(0.60)<br/>tired(0.60)", "pred answer": "happy", "question_id": 4432435, "best approach": "", "verif answer": "happy", "anno approach": "wiki, concept, image", "verif wiki answer": "happy(0.7227)", "verif concept answer": "happy(0.7119)", "verif image answer": "happy(0.6528)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443243.jpg"}, {"question": "what kind of zebra is that and what food do they eat the most of", "gt answer": "african and grass(1.00)<br/>african(0.60)", "pred answer": "vegetarian", "question_id": 2115295, "best approach": "wiki, concept", "verif answer": "zebra", "anno approach": "wiki, concept, image", "verif wiki answer": "african and grass(0.7166)", "verif concept answer": "african and grass(0.7186)", "verif image answer": "dumbo(0.6715)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000211529.jpg"}, {"question": "is this dog a working dog or just a companion for a boat owner", "gt answer": "companion(1.00)", "pred answer": "navy", "question_id": 2565445, "best approach": "", "verif answer": "danger", "anno approach": "wiki, concept, image", "verif wiki answer": "professional(0.7121)", "verif concept answer": "professional(0.6953)", "verif image answer": "professional(0.7037)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000256544.jpg"}, {"question": "it appears a giant what is trying to board the bus", "gt answer": "rat(1.00)<br/>mouse(0.60)", "pred answer": "pirate", "question_id": 4364065, "best approach": "wiki, concept", "verif answer": "mouse", "anno approach": "wiki, concept, image", "verif wiki answer": "mouse(0.7017)", "verif concept answer": "mouse(0.6713)", "verif image answer": "mcdonalds(0.6906)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436406.jpg"}, {"question": "what company is being advertised", "gt answer": "ryanair(1.00)", "pred answer": "polo", "question_id": 3633535, "best approach": "", "verif answer": "gucci", "anno approach": "wiki, concept, image", "verif wiki answer": "gucci(0.7203)", "verif concept answer": "kentucky derby(0.6259)", "verif image answer": "kentucky derby(0.6812)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363353.jpg"}, {"question": "what type of relationship might they have", "gt answer": "teammate(1.00)<br/>partner(0.60)", "pred answer": "friend", "question_id": 2323875, "best approach": "", "verif answer": "same team", "anno approach": "wiki, concept, image", "verif wiki answer": "team(0.7182)", "verif concept answer": "same team(0.7128)", "verif image answer": "team(0.6638)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232387.jpg"}, {"question": "what does this animal eat", "gt answer": "plant(1.00)<br/>fruit(0.60)<br/>grass(0.60)", "pred answer": "peanut", "question_id": 5433035, "best approach": "image", "verif answer": "leaf", "anno approach": "wiki, concept, image", "verif wiki answer": "grass(0.6844)", "verif concept answer": "leaf(0.6840)", "verif image answer": "plant(0.6533)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543303.jpg"}, {"question": "what kind of stroke is this woman about to use", "gt answer": "forehand(1.00)<br/>tennis(0.60)<br/>right(0.60)", "pred answer": "backhand", "question_id": 4677385, "best approach": "image", "verif answer": "backhand", "anno approach": "wiki, concept, image", "verif wiki answer": "backhand(0.7255)", "verif concept answer": "backhand(0.6789)", "verif image answer": "forehand(0.7180)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467738.jpg"}, {"question": "if i needed a quick source to get money by looking at the picture what store could i go to", "gt answer": "pawn shop(1.00)", "pred answer": "shop", "question_id": 3690495, "best approach": "", "verif answer": "shop", "anno approach": "wiki, concept, image", "verif wiki answer": "shop(0.7240)", "verif concept answer": "shop(0.7225)", "verif image answer": "bakery(0.5459)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369049.jpg"}, {"question": "where is this tiger going", "gt answer": "zoo(1.00)<br/>home(0.60)", "pred answer": "south", "question_id": 1656095, "best approach": "wiki, concept", "verif answer": "zoo", "anno approach": "wiki, concept, image", "verif wiki answer": "zoo(0.6998)", "verif concept answer": "zoo(0.6909)", "verif image answer": "restaurant(0.7271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000165609.jpg"}, {"question": "what topping is on the bagel", "gt answer": "cream cheese(1.00)", "pred answer": "coconut", "question_id": 3901685, "best approach": "", "verif answer": "coconut", "anno approach": "wiki, concept, image", "verif wiki answer": "vanilla(0.7177)", "verif concept answer": "vanilla(0.6811)", "verif image answer": "chocolate(0.6821)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390168.jpg"}, {"question": "for which activity does the man in orange wear the item on his head for", "gt answer": "bicycling(1.00)<br/>helmet(0.60)<br/>bicycle(0.60)", "pred answer": "rest", "question_id": 3529085, "best approach": "image", "verif answer": "bicycle", "anno approach": "wiki, concept, image", "verif wiki answer": "bicycle(0.6577)", "verif concept answer": "helmet(0.6150)", "verif image answer": "bicycling(0.6979)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000352908.jpg"}, {"question": "how long is the cord for this mouse", "gt answer": "2 feet(1.00)<br/>3(0.60)", "pred answer": "long", "question_id": 4566665, "best approach": "wiki", "verif answer": "2 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "2 feet(0.7043)", "verif concept answer": "6(0.6668)", "verif image answer": "6(0.5815)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456666.jpg"}, {"question": "what ingredient in this dish is actually a fungus that grows in the woods", "gt answer": "mushroom(1.00)", "pred answer": "spinach", "question_id": 564865, "best approach": "", "verif answer": "spinach", "anno approach": "wiki, concept, image", "verif wiki answer": "spinach(0.7045)", "verif concept answer": "spinach(0.6767)", "verif image answer": "carrot(0.7192)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000056486.jpg"}, {"question": "what fields are these vechicles used to spray", "gt answer": "crop(1.00)<br/>corn(0.60)", "pred answer": "skate park", "question_id": 584355, "best approach": "", "verif answer": "hay", "anno approach": "wiki, concept, image", "verif wiki answer": "hay(0.5673)", "verif concept answer": "hay(0.6332)", "verif image answer": "grain(0.5669)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058435.jpg"}, {"question": "when is it bad luck to open the black and pink object in the photo", "gt answer": "inside(1.00)", "pred answer": "rainy", "question_id": 5625175, "best approach": "", "verif answer": "rainy", "anno approach": "wiki, concept, image", "verif wiki answer": "overcast(0.6703)", "verif concept answer": "overcast(0.7029)", "verif image answer": "overcast(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000562517.jpg"}, {"question": "what color ball does she use", "gt answer": "yellow(1.00)<br/>green(0.60)", "pred answer": "red", "question_id": 5503965, "best approach": "", "verif answer": "white", "anno approach": "wiki, concept, image", "verif wiki answer": "rose(0.5858)", "verif concept answer": "white(0.6251)", "verif image answer": "white(0.7215)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550396.jpg"}, {"question": "what law is this man breaking", "gt answer": "ride on sidewalk(1.00)", "pred answer": "distracted drive", "question_id": 3122865, "best approach": "", "verif answer": "0", "anno approach": "wiki, concept, image", "verif wiki answer": "0(0.5571)", "verif concept answer": "0(0.7180)", "verif image answer": "0(0.5022)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000312286.jpg"}, {"question": "what is this ny 'town' called", "gt answer": "chinatown(1.00)<br/>china(0.60)", "pred answer": "city", "question_id": 29985, "best approach": "image", "verif answer": "europe", "anno approach": "wiki, concept, image", "verif wiki answer": "minnesota(0.5218)", "verif concept answer": "minnesota(0.6794)", "verif image answer": "chinatown(0.5204)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002998.jpg"}, {"question": "what can this silver device clean", "gt answer": "dish(1.00)<br/>dishwasher(0.60)", "pred answer": "refrigerator", "question_id": 4017215, "best approach": "", "verif answer": "dish", "anno approach": "wiki, concept, image", "verif wiki answer": "dish soap(0.7203)", "verif concept answer": "laundry(0.6911)", "verif image answer": "laundry(0.6868)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401721.jpg"}, {"question": "what is this plane about to do", "gt answer": "take off(1.00)<br/>fly(0.60)", "pred answer": "land", "question_id": 4986015, "best approach": "wiki, concept", "verif answer": "take off", "anno approach": "wiki, concept, image", "verif wiki answer": "take off(0.6797)", "verif concept answer": "take off(0.6642)", "verif image answer": "airport(0.5390)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000498601.jpg"}, {"question": "what type of dog is driving the truck", "gt answer": "german shepherd(1.00)<br/>labrador(0.60)<br/>mutt(0.60)<br/>shepard(0.60)", "pred answer": "german shepard", "question_id": 5185185, "best approach": "wiki, concept, image", "verif answer": "german shepard", "anno approach": "wiki, concept, image", "verif wiki answer": "shepard(0.7067)", "verif concept answer": "shepard(0.6455)", "verif image answer": "shepard(0.7091)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518518.jpg"}, {"question": "what airliner is this", "gt answer": "private(1.00)<br/>private jet(0.60)<br/>jet(0.60)", "pred answer": "boeing 747", "question_id": 2494415, "best approach": "image", "verif answer": "passenger", "anno approach": "wiki, concept, image", "verif wiki answer": "glider(0.7058)", "verif concept answer": "passenger(0.7081)", "verif image answer": "private jet(0.7049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249441.jpg"}, {"question": "what types of trains are these", "gt answer": "passenger(1.00)<br/>electric(0.60)<br/>passenger train(0.60)", "pred answer": "commuter", "question_id": 5767585, "best approach": "concept", "verif answer": "commuter", "anno approach": "wiki, concept, image", "verif wiki answer": "commuter(0.7116)", "verif concept answer": "passenger(0.7158)", "verif image answer": "electric(0.6946)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000576758.jpg"}, {"question": "what is used to clean the surface the girl is sitting on", "gt answer": "vacuum(1.00)", "pred answer": "brush", "question_id": 3693215, "best approach": "wiki", "verif answer": "bleach", "anno approach": "wiki, concept, image", "verif wiki answer": "vacuum(0.6953)", "verif concept answer": "bleach(0.6622)", "verif image answer": "wood(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369321.jpg"}, {"question": "what is the name of the icing used on this cake", "gt answer": "fondant(1.00)<br/>cream(0.60)<br/>vanilla(0.60)", "pred answer": "chocolate", "question_id": 3341875, "best approach": "wiki", "verif answer": "chocolate", "anno approach": "wiki, concept, image", "verif wiki answer": "fondant(0.7270)", "verif concept answer": "cream(0.6723)", "verif image answer": "vanilla(0.6251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334187.jpg"}, {"question": "what is this type of room called", "gt answer": "cafeteria(1.00)<br/>dine room(0.60)<br/>office(0.60)", "pred answer": "kitchen", "question_id": 5004575, "best approach": "wiki, concept", "verif answer": "dine room", "anno approach": "wiki, concept, image", "verif wiki answer": "cafeteria(0.7161)", "verif concept answer": "cafeteria(0.6487)", "verif image answer": "meet(0.6916)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500457.jpg"}, {"question": "what type of show would you see these at", "gt answer": "air show(1.00)<br/>airshow(1.00)<br/>air(0.60)", "pred answer": "bomber", "question_id": 990665, "best approach": "wiki, concept", "verif answer": "airshow", "anno approach": "wiki, concept, image", "verif wiki answer": "air show(0.6920)", "verif concept answer": "air show(0.7025)", "verif image answer": "air(0.5341)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099066.jpg"}, {"question": "is that jam or jelly in the jar", "gt answer": "jam(1.00)<br/>jelly(0.60)", "pred answer": "coconut", "question_id": 4370805, "best approach": "wiki", "verif answer": "chocolate", "anno approach": "wiki, concept, image", "verif wiki answer": "jam(0.7199)", "verif concept answer": "jelly(0.6152)", "verif image answer": "grape(0.6779)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437080.jpg"}, {"question": "what kind of clouds are pictured", "gt answer": "storm(1.00)<br/>cumulous(1.00)<br/>rain(0.60)", "pred answer": "stratus", "question_id": 846835, "best approach": "concept", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "rain(0.7005)", "verif concept answer": "cumulous(0.6538)", "verif image answer": "rain(0.6832)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084683.jpg"}, {"question": "how hot are these peppers", "gt answer": "very hot(1.00)<br/>very(0.60)", "pred answer": "350 degrees", "question_id": 716015, "best approach": "concept", "verif answer": "extremely", "anno approach": "wiki, concept, image", "verif wiki answer": "very healthy(0.6088)", "verif concept answer": "very hot(0.6789)", "verif image answer": "very healthy(0.6615)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071601.jpg"}, {"question": "what is the average life span of this animal", "gt answer": "60 years(1.00)<br/>100 years(0.60)", "pred answer": "50 years", "question_id": 653455, "best approach": "wiki, concept", "verif answer": "50 years", "anno approach": "wiki, concept, image", "verif wiki answer": "100 years(0.7032)", "verif concept answer": "100 years(0.6178)", "verif image answer": "4 months(0.6906)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065345.jpg"}, {"question": "what vegitation is growing on the wall below this train", "gt answer": "ivy(1.00)<br/>moss(0.60)", "pred answer": "grass", "question_id": 1585365, "best approach": "concept", "verif answer": "aloe", "anno approach": "wiki, concept, image", "verif wiki answer": "plant(0.6883)", "verif concept answer": "moss(0.6293)", "verif image answer": "aloe(0.5294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000158536.jpg"}, {"question": "what is around the horses neck", "gt answer": "bridle(1.00)<br/>harness(0.60)", "pred answer": "collar", "question_id": 4505925, "best approach": "", "verif answer": "rein", "anno approach": "wiki, concept, image", "verif wiki answer": "rein(0.6544)", "verif concept answer": "rein(0.6952)", "verif image answer": "rein(0.5987)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450592.jpg"}, {"question": "what type of jellly is shown", "gt answer": "orange(1.00)<br/>jam(0.60)", "pred answer": "green", "question_id": 786955, "best approach": "wiki, concept", "verif answer": "blueberry", "anno approach": "wiki, concept, image", "verif wiki answer": "orange(0.5348)", "verif concept answer": "orange(0.5218)", "verif image answer": "blueberry(0.6717)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078695.jpg"}, {"question": "what is the smaller item on the floor called", "gt answer": "toilet paper(1.00)", "pred answer": "potty", "question_id": 1394925, "best approach": "wiki, concept", "verif answer": "chair", "anno approach": "wiki, concept, image", "verif wiki answer": "toilet paper(0.5928)", "verif concept answer": "toilet paper(0.7154)", "verif image answer": "tile(0.7300)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139492.jpg"}, {"question": "what food group makes up this meal", "gt answer": "dairy(1.00)<br/>protein(0.60)", "pred answer": "vegetable", "question_id": 55895, "best approach": "concept", "verif answer": "protein", "anno approach": "wiki, concept, image", "verif wiki answer": "protein(0.6897)", "verif concept answer": "dairy(0.7245)", "verif image answer": "holstein(0.5078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005589.jpg"}, {"question": "what kind of grass is grown in the field these players are running on", "gt answer": "turf(1.00)", "pred answer": "green", "question_id": 164655, "best approach": "concept", "verif answer": "park", "anno approach": "wiki, concept, image", "verif wiki answer": "park(0.5568)", "verif concept answer": "turf(0.6333)", "verif image answer": "natural(0.7021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016465.jpg"}, {"question": "what activity does it appear the girl is doing", "gt answer": "run(1.00)", "pred answer": "walk", "question_id": 4883955, "best approach": "wiki, concept, image", "verif answer": "run", "anno approach": "wiki, concept, image", "verif wiki answer": "run(0.7237)", "verif concept answer": "run(0.6743)", "verif image answer": "run(0.6509)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488395.jpg"}, {"question": "in what piazza is the the persons in the costume at", "gt answer": "disney(1.00)<br/>christmas(0.60)", "pred answer": "philadelphia", "question_id": 1260905, "best approach": "wiki, concept", "verif answer": "disney", "anno approach": "wiki, concept, image", "verif wiki answer": "disney(0.6271)", "verif concept answer": "disney(0.5437)", "verif image answer": "mickey mouse(0.6584)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126090.jpg"}, {"question": "what is the yellow substance in the sandwich", "gt answer": "egg(1.00)<br/>egg salad(0.60)", "pred answer": "potato", "question_id": 852815, "best approach": "image", "verif answer": "egg salad", "anno approach": "wiki, concept, image", "verif wiki answer": "rice(0.6581)", "verif concept answer": "rice(0.6087)", "verif image answer": "egg(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085281.jpg"}, {"question": "what are the parents risking by using this type of float device", "gt answer": "drown(1.00)", "pred answer": "swim", "question_id": 5080085, "best approach": "wiki", "verif answer": "fall", "anno approach": "wiki, concept, image", "verif wiki answer": "drown(0.7152)", "verif concept answer": "hurricane(0.6835)", "verif image answer": "hurricane(0.7125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000508008.jpg"}, {"question": "what would a skydiver need before he jumps out into this view", "gt answer": "parachute(1.00)", "pred answer": "lift", "question_id": 2682125, "best approach": "", "verif answer": "lift", "anno approach": "wiki, concept, image", "verif wiki answer": "harness(0.6710)", "verif concept answer": "harness(0.6661)", "verif image answer": "harness(0.6965)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268212.jpg"}, {"question": "where is the picture taken from", "gt answer": "car(1.00)", "pred answer": "vehicle", "question_id": 1358205, "best approach": "concept", "verif answer": "vehicle", "anno approach": "wiki, concept, image", "verif wiki answer": "vehicle(0.6593)", "verif concept answer": "car(0.6562)", "verif image answer": "vehicle(0.6311)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000135820.jpg"}, {"question": "what was his vest used for", "gt answer": "flotation(1.00)<br/>float(0.60)<br/>storage(0.60)", "pred answer": "protection", "question_id": 2809085, "best approach": "wiki, concept", "verif answer": "surf", "anno approach": "wiki, concept, image", "verif wiki answer": "float(0.6530)", "verif concept answer": "float(0.6391)", "verif image answer": "surf(0.6524)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280908.jpg"}, {"question": "where are these people serving food at", "gt answer": "cafeteria(1.00)<br/>school(0.60)", "pred answer": "restaurant", "question_id": 769785, "best approach": "wiki", "verif answer": "restaurant", "anno approach": "wiki, concept, image", "verif wiki answer": "school(0.6361)", "verif concept answer": "office(0.6153)", "verif image answer": "restaurant(0.7089)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076978.jpg"}, {"question": "where would you see me", "gt answer": "alaska(1.00)<br/>forest(0.60)<br/>lake(0.60)<br/>arctic(0.60)", "pred answer": "north pole", "question_id": 3532845, "best approach": "image", "verif answer": "north pole", "anno approach": "wiki, concept, image", "verif wiki answer": "north pole(0.7198)", "verif concept answer": "north pole(0.7192)", "verif image answer": "forest(0.7172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353284.jpg"}, {"question": "what kind of flowers are these", "gt answer": "daffodil(1.00)<br/>tulip(1.00)<br/>daisy(0.60)", "pred answer": "lily", "question_id": 3145615, "best approach": "wiki, concept, image", "verif answer": "lily", "anno approach": "wiki, concept, image", "verif wiki answer": "daffodil(0.6172)", "verif concept answer": "daffodil(0.6081)", "verif image answer": "tulip(0.7083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314561.jpg"}, {"question": "what is the name of this baseball team", "gt answer": "blue jay(1.00)<br/>red sox(0.60)", "pred answer": "white sox", "question_id": 1409405, "best approach": "", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "cardinal(0.6202)", "verif concept answer": "yankees(0.6090)", "verif image answer": "red(0.7158)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140940.jpg"}, {"question": "what in the photo suggests the photographer likes farm things", "gt answer": "tractor(1.00)", "pred answer": "picture", "question_id": 1189045, "best approach": "image", "verif answer": "bus", "anno approach": "wiki, concept, image", "verif wiki answer": "bus(0.5017)", "verif concept answer": "locomotive(0.5192)", "verif image answer": "tractor(0.5965)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118904.jpg"}, {"question": "what is the name of the middle eastern country that the famous cartoon cat colored like this one threatened to ship his rival to", "gt answer": "abu dhabi(1.00)<br/>saudi arabia(0.60)<br/>garfield(0.60)", "pred answer": "usa", "question_id": 1595255, "best approach": "concept", "verif answer": "garfield", "anno approach": "wiki, concept, image", "verif wiki answer": "saudi arabia(0.6192)", "verif concept answer": "abu dhabi(0.6957)", "verif image answer": "legal(0.7062)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159525.jpg"}, {"question": "what is the small black portal used for", "gt answer": "cat door(1.00)", "pred answer": "water", "question_id": 3788905, "best approach": "wiki, concept", "verif answer": "water", "anno approach": "wiki, concept, image", "verif wiki answer": "cat door(0.7042)", "verif concept answer": "cat door(0.5917)", "verif image answer": "natural(0.5185)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378890.jpg"}, {"question": "what sound does this animal make", "gt answer": "neigh(1.00)<br/>moo(0.60)", "pred answer": "bark", "question_id": 2923565, "best approach": "wiki, concept, image", "verif answer": "moo", "anno approach": "wiki, concept, image", "verif wiki answer": "neigh(0.7090)", "verif concept answer": "neigh(0.6922)", "verif image answer": "neigh(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292356.jpg"}, {"question": "can you guess the car model shown shown in this picture", "gt answer": "ford(1.00)<br/>1930(0.60)", "pred answer": "dodge", "question_id": 5601235, "best approach": "wiki, concept", "verif answer": "ford", "anno approach": "wiki, concept, image", "verif wiki answer": "ford(0.7220)", "verif concept answer": "ford(0.6723)", "verif image answer": "kenworth(0.7176)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000560123.jpg"}, {"question": "what condiments are shown here", "gt answer": "ketchup and mustard(1.00)<br/>ketchup(0.60)", "pred answer": "wasabi", "question_id": 2927305, "best approach": "", "verif answer": "sauce", "anno approach": "wiki, concept, image", "verif wiki answer": "beer(0.5465)", "verif concept answer": "sauce(0.5211)", "verif image answer": "sauce(0.6848)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292730.jpg"}, {"question": "which item on the table is considered a condiment", "gt answer": "ketchup(1.00)", "pred answer": "napkin", "question_id": 1576395, "best approach": "wiki, concept", "verif answer": "ketchup", "anno approach": "wiki, concept, image", "verif wiki answer": "ketchup(0.5163)", "verif concept answer": "ketchup(0.5071)", "verif image answer": "ketchup and relish(0.5750)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157639.jpg"}, {"question": "is this person getting dressed for an interview or a pool party", "gt answer": "interview(1.00)", "pred answer": "business", "question_id": 5446235, "best approach": "wiki, image", "verif answer": "business", "anno approach": "wiki, concept, image", "verif wiki answer": "interview(0.7260)", "verif concept answer": "meet(0.7165)", "verif image answer": "interview(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544623.jpg"}, {"question": "what tools are used to make this knitted object", "gt answer": "knit needle(1.00)<br/>pin(0.60)", "pred answer": "yarn", "question_id": 5112455, "best approach": "image", "verif answer": "sew", "anno approach": "wiki, concept, image", "verif wiki answer": "cut(0.5428)", "verif concept answer": "cut(0.5912)", "verif image answer": "pin(0.6738)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511245.jpg"}, {"question": "is this cooked and how long", "gt answer": "1 hour(1.00)", "pred answer": "10 minutes", "question_id": 5629735, "best approach": "wiki, concept", "verif answer": "1 hour", "anno approach": "wiki, concept, image", "verif wiki answer": "1 hour(0.6759)", "verif concept answer": "1 hour(0.6743)", "verif image answer": "15 minutes(0.7184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000562973.jpg"}, {"question": "what is this park bench famous for", "gt answer": "sit(1.00)<br/>forest gump(0.60)", "pred answer": "water", "question_id": 3448945, "best approach": "", "verif answer": "sit", "anno approach": "wiki, concept, image", "verif wiki answer": "forrest gump(0.7277)", "verif concept answer": "forrest gump(0.7250)", "verif image answer": "forrest gump(0.6117)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344894.jpg"}, {"question": "when you fill a glass to the top you are also referring to which part of the headgear worn here", "gt answer": "brim(1.00)", "pred answer": "tag", "question_id": 3611395, "best approach": "", "verif answer": "drunk", "anno approach": "wiki, concept, image", "verif wiki answer": "kickflip(0.5752)", "verif concept answer": "180(0.5221)", "verif image answer": "drunk(0.7069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361139.jpg"}, {"question": "the man in this photo is beginning to show which male trait", "gt answer": "bald(1.00)<br/>bad(0.60)", "pred answer": "stewie", "question_id": 2122715, "best approach": "wiki, concept, image", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "bad(0.6864)", "verif concept answer": "bad(0.6220)", "verif image answer": "bad(0.7239)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212271.jpg"}, {"question": "what is a bulldog", "gt answer": "mascot(1.00)<br/>animal(0.60)", "pred answer": "build", "question_id": 158305, "best approach": "", "verif answer": "street sign", "anno approach": "wiki, concept, image", "verif wiki answer": "street sign(0.5737)", "verif concept answer": "street sign(0.5134)", "verif image answer": "street sign(0.5501)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015830.jpg"}, {"question": "is this a desktop or laptop computer", "gt answer": "laptop(1.00)", "pred answer": "desktop", "question_id": 3644855, "best approach": "", "verif answer": "desktop", "anno approach": "wiki, concept, image", "verif wiki answer": "desktop(0.6518)", "verif concept answer": "desktop(0.6525)", "verif image answer": "desktop(0.7136)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364485.jpg"}, {"question": "what sports team is this mascot for", "gt answer": "football(1.00)<br/>basketball(0.60)<br/>rat(0.60)<br/>shirt(0.60)", "pred answer": "georgia", "question_id": 1496025, "best approach": "concept, image", "verif answer": "shirt", "anno approach": "wiki, concept, image", "verif wiki answer": "soccer(0.6998)", "verif concept answer": "shirt(0.6315)", "verif image answer": "shirt(0.6976)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149602.jpg"}, {"question": "what healthy drink does he have", "gt answer": "orange juice(1.00)<br/>juice(0.60)", "pred answer": "beer", "question_id": 298015, "best approach": "wiki, concept, image", "verif answer": "orange juice", "anno approach": "wiki, concept, image", "verif wiki answer": "orange juice(0.6844)", "verif concept answer": "orange juice(0.7115)", "verif image answer": "orange juice(0.7190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029801.jpg"}, {"question": "according to nursery lore who lost a baby one of these", "gt answer": "little bo peep(1.00)<br/>little bow peep(0.60)", "pred answer": "farmer", "question_id": 3926485, "best approach": "image", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "theodore roosevelt(0.6483)", "verif concept answer": "friend(0.6759)", "verif image answer": "little bo peep(0.5145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392648.jpg"}, {"question": "what brand of backpack is being used", "gt answer": "jansport(1.00)<br/>columbia(0.60)", "pred answer": "samsonite", "question_id": 4260405, "best approach": "wiki", "verif answer": "samsonite", "anno approach": "wiki, concept, image", "verif wiki answer": "jansport(0.7125)", "verif concept answer": "samsonite(0.6989)", "verif image answer": "samsonite(0.5113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426040.jpg"}, {"question": "based on the scence what country is this photo located", "gt answer": "united kingdom(1.00)<br/>france(0.60)<br/>spain(0.60)<br/>america(0.60)", "pred answer": "england", "question_id": 4716695, "best approach": "wiki, concept", "verif answer": "europe", "anno approach": "wiki, concept, image", "verif wiki answer": "america(0.7155)", "verif concept answer": "spain(0.6463)", "verif image answer": "europe(0.7097)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471669.jpg"}, {"question": "where is the man sitting", "gt answer": "garden(1.00)<br/>wood(0.60)<br/>yard(0.60)<br/>outside(0.60)", "pred answer": "bench", "question_id": 4363025, "best approach": "wiki, concept, image", "verif answer": "wood", "anno approach": "wiki, concept, image", "verif wiki answer": "wood(0.7175)", "verif concept answer": "wood(0.6869)", "verif image answer": "wood(0.7030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436302.jpg"}, {"question": "what materials are the suitcase made out of", "gt answer": "canvas(1.00)<br/>polyester(0.60)", "pred answer": "leather", "question_id": 5072875, "best approach": "concept", "verif answer": "cotton", "anno approach": "wiki, concept, image", "verif wiki answer": "polyester(0.5453)", "verif concept answer": "canvas(0.6270)", "verif image answer": "cotton(0.6652)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507287.jpg"}, {"question": "what position is the kid playing", "gt answer": "shortstop(1.00)<br/>outfield(0.60)<br/>second base(0.60)", "pred answer": "pitcher", "question_id": 4291445, "best approach": "wiki, concept", "verif answer": "catcher", "anno approach": "wiki, concept, image", "verif wiki answer": "outfield(0.7228)", "verif concept answer": "outfield(0.7132)", "verif image answer": "second(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429144.jpg"}, {"question": "what is the traditional cheese made from this creatures milk", "gt answer": "goat cheese(1.00)<br/>brie(0.60)<br/>feta(0.60)", "pred answer": "cheddar", "question_id": 891015, "best approach": "wiki, image", "verif answer": "mozzarella", "anno approach": "wiki, concept, image", "verif wiki answer": "goat cheese(0.6287)", "verif concept answer": "brie(0.5958)", "verif image answer": "goat cheese(0.7259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089101.jpg"}, {"question": "how is the blue object on the floor usually cleaned", "gt answer": "vacuum(1.00)<br/>steam(0.60)", "pred answer": "clean", "question_id": 930485, "best approach": "image", "verif answer": "vacuum", "anno approach": "wiki, concept, image", "verif wiki answer": "mop(0.5004)", "verif concept answer": "steam(0.5005)", "verif image answer": "vacuum(0.5149)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093048.jpg"}, {"question": "what team is the man on first base playing for", "gt answer": "red sox(1.00)<br/>oriole(0.60)<br/>baseball(0.60)", "pred answer": "white sox", "question_id": 2707405, "best approach": "wiki, concept", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "red sox(0.6843)", "verif concept answer": "red sox(0.7227)", "verif image answer": "cub(0.6907)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270740.jpg"}, {"question": "what are the giraffes doing", "gt answer": "mate(1.00)<br/>run(0.60)<br/>hang out(0.60)", "pred answer": "play", "question_id": 3954325, "best approach": "wiki, concept", "verif answer": "run", "anno approach": "wiki, concept, image", "verif wiki answer": "mate(0.7143)", "verif concept answer": "mate(0.7011)", "verif image answer": "run(0.6958)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395432.jpg"}, {"question": "what is the cultural background of people with red hair", "gt answer": "irish(1.00)", "pred answer": "hispanic", "question_id": 1584205, "best approach": "", "verif answer": "indian", "anno approach": "wiki, concept, image", "verif wiki answer": "germany(0.6065)", "verif concept answer": "germany(0.5570)", "verif image answer": "germany(0.6047)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000158420.jpg"}, {"question": "what region of the world would you find this bear", "gt answer": "arctic(1.00)<br/>artic(1.00)<br/>north pole(0.60)", "pred answer": "antarctica", "question_id": 1760865, "best approach": "concept, image", "verif answer": "north pole", "anno approach": "wiki, concept, image", "verif wiki answer": "north pole(0.6317)", "verif concept answer": "artic(0.6447)", "verif image answer": "artic(0.7026)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176086.jpg"}, {"question": "what type of outfit is this man wearing", "gt answer": "suit(1.00)", "pred answer": "tuxedo", "question_id": 2016305, "best approach": "", "verif answer": "tuxedo", "anno approach": "wiki, concept, image", "verif wiki answer": "tuxedo(0.7128)", "verif concept answer": "tuxedo(0.6664)", "verif image answer": "tuxedo(0.7174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201630.jpg"}, {"question": "in what kind of vehicle is this bed located", "gt answer": "rv(1.00)<br/>boat(0.60)", "pred answer": "bus", "question_id": 833865, "best approach": "wiki", "verif answer": "airplane", "anno approach": "wiki, concept, image", "verif wiki answer": "rv(0.6969)", "verif concept answer": "boat(0.6500)", "verif image answer": "surf board(0.7094)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083386.jpg"}, {"question": "what is it called when you have no points in this sport", "gt answer": "love(1.00)<br/>foul(0.60)", "pred answer": "tennis", "question_id": 4029165, "best approach": "wiki", "verif answer": "goal", "anno approach": "wiki, concept, image", "verif wiki answer": "foul(0.6192)", "verif concept answer": "forehand(0.6145)", "verif image answer": "forehand(0.5480)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402916.jpg"}, {"question": "when was this type of vehicle with two equal sized wheels invented", "gt answer": "1850(1.00)<br/>1900(0.60)<br/>1800s(0.60)", "pred answer": "1920", "question_id": 2774705, "best approach": "wiki", "verif answer": "1900", "anno approach": "wiki, concept, image", "verif wiki answer": "1900(0.7229)", "verif concept answer": "1950s(0.6262)", "verif image answer": "1950s(0.6731)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277470.jpg"}, {"question": "what is the coloring of the lighting used here if you were a professional set designer", "gt answer": "yellow(1.00)", "pred answer": "white", "question_id": 1811365, "best approach": "wiki, concept, image", "verif answer": "white", "anno approach": "wiki, concept, image", "verif wiki answer": "yellow(0.6550)", "verif concept answer": "yellow(0.6307)", "verif image answer": "yellow(0.5851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181136.jpg"}, {"question": "where would you take these", "gt answer": "vacation(1.00)", "pred answer": "city", "question_id": 5035415, "best approach": "", "verif answer": "airport", "anno approach": "wiki, concept, image", "verif wiki answer": "airport(0.6834)", "verif concept answer": "airport(0.7203)", "verif image answer": "airport(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503541.jpg"}, {"question": "what would someone do here", "gt answer": "pray(1.00)<br/>vacation(0.60)", "pred answer": "sit", "question_id": 4424735, "best approach": "wiki, concept, image", "verif answer": "tell time", "anno approach": "wiki, concept, image", "verif wiki answer": "pray(0.7257)", "verif concept answer": "pray(0.7285)", "verif image answer": "pray(0.7159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442473.jpg"}, {"question": "what brand is this clothing accessory", "gt answer": "tie(1.00)<br/>gay(0.60)", "pred answer": "gap", "question_id": 4645935, "best approach": "image", "verif answer": "silk", "anno approach": "wiki, concept, image", "verif wiki answer": "silk(0.6077)", "verif concept answer": "silk(0.6701)", "verif image answer": "tie(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464593.jpg"}, {"question": "was it clean or do you think it left a trail", "gt answer": "trail(1.00)", "pred answer": "clean", "question_id": 3779735, "best approach": "", "verif answer": "scratch", "anno approach": "wiki, concept, image", "verif wiki answer": "stripe(0.5094)", "verif concept answer": "scratch(0.5844)", "verif image answer": "scratch(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377973.jpg"}, {"question": "what size is this women 's jacket", "gt answer": "medium(1.00)<br/>36(0.60)", "pred answer": "large", "question_id": 1060255, "best approach": "", "verif answer": "large", "anno approach": "wiki, concept, image", "verif wiki answer": "large(0.6934)", "verif concept answer": "large(0.6941)", "verif image answer": "60(0.6526)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106025.jpg"}, {"question": "which item can you not use with aluminum foil", "gt answer": "microwave(1.00)<br/>metal(0.60)", "pred answer": "towel", "question_id": 9085, "best approach": "", "verif answer": "microwave", "anno approach": "wiki, concept, image", "verif wiki answer": "glass(0.7211)", "verif concept answer": "steel(0.5841)", "verif image answer": "steel(0.6893)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000908.jpg"}, {"question": "what type of alcohol is advertised here", "gt answer": "cider(1.00)", "pred answer": "wine", "question_id": 251025, "best approach": "wiki, concept, image", "verif answer": "beer", "anno approach": "wiki, concept, image", "verif wiki answer": "cider(0.7253)", "verif concept answer": "cider(0.6297)", "verif image answer": "cider(0.5277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000025102.jpg"}, {"question": "what would this animal say if you asked", "gt answer": "meow(1.00)", "pred answer": "cat", "question_id": 3168715, "best approach": "concept", "verif answer": "purr", "anno approach": "wiki, concept, image", "verif wiki answer": "purr(0.6913)", "verif concept answer": "meow(0.7146)", "verif image answer": "purr(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316871.jpg"}, {"question": "what is healthy about this photo", "gt answer": "nothing(1.00)<br/>coconut(0.60)<br/>carbohydrate(0.60)", "pred answer": "meat", "question_id": 4035795, "best approach": "wiki, concept, image", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "coconut(0.6513)", "verif concept answer": "coconut(0.6427)", "verif image answer": "coconut(0.6975)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403579.jpg"}, {"question": "how do you make the fencing in the background", "gt answer": "lattice(1.00)", "pred answer": "chalk", "question_id": 5444755, "best approach": "", "verif answer": "chalk", "anno approach": "wiki, concept, image", "verif wiki answer": "chalk(0.6645)", "verif concept answer": "chalk(0.6279)", "verif image answer": "grass(0.5941)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544475.jpg"}, {"question": "what is the brand of jeans this man is wearing", "gt answer": "levis(1.00)", "pred answer": "denim", "question_id": 4305815, "best approach": "", "verif answer": "levi", "anno approach": "wiki, concept, image", "verif wiki answer": "levi(0.6572)", "verif concept answer": "gap(0.7021)", "verif image answer": "gap(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430581.jpg"}, {"question": "what trick is being attempted", "gt answer": "flip(1.00)<br/>kickflip(0.60)", "pred answer": "ollie", "question_id": 1344945, "best approach": "wiki", "verif answer": "ollie", "anno approach": "wiki, concept, image", "verif wiki answer": "kickflip(0.7122)", "verif concept answer": "kick flip(0.6880)", "verif image answer": "kick flip(0.6789)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134494.jpg"}, {"question": "what profession do these men seem to belong to", "gt answer": "pilot(1.00)<br/>military(0.60)", "pred answer": "police", "question_id": 3768385, "best approach": "wiki", "verif answer": "military", "anno approach": "wiki, concept, image", "verif wiki answer": "military(0.6977)", "verif concept answer": "protest(0.6285)", "verif image answer": "protest(0.6888)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376838.jpg"}, {"question": "what is the placemat on the table made from", "gt answer": "bamboo(1.00)<br/>wood(0.60)<br/>wicker(0.60)", "pred answer": "canvas", "question_id": 5114615, "best approach": "concept, image", "verif answer": "wood", "anno approach": "wiki, concept, image", "verif wiki answer": "wood(0.7110)", "verif concept answer": "bamboo(0.6184)", "verif image answer": "bamboo(0.7066)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511461.jpg"}, {"question": "where are these birds migrating to", "gt answer": "south(1.00)<br/>south america(0.60)", "pred answer": "air", "question_id": 3175575, "best approach": "concept, image", "verif answer": "south", "anno approach": "wiki, concept, image", "verif wiki answer": "west(0.7270)", "verif concept answer": "south america(0.7048)", "verif image answer": "south america(0.7262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317557.jpg"}, {"question": "what company manufactured that stove", "gt answer": "maytag(1.00)<br/>general electric(0.60)<br/>kenmore(0.60)", "pred answer": "frigidaire", "question_id": 5394045, "best approach": "wiki", "verif answer": "ge", "anno approach": "wiki, concept, image", "verif wiki answer": "general electric(0.7281)", "verif concept answer": "whirlpool(0.6930)", "verif image answer": "whirlpool(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539404.jpg"}, {"question": "what does the double yellow line on the ground signify", "gt answer": "do not pass(1.00)", "pred answer": "cross walk", "question_id": 3358715, "best approach": "", "verif answer": "cross walk", "anno approach": "wiki, concept, image", "verif wiki answer": "crosswalk(0.7255)", "verif concept answer": "crosswalk(0.6759)", "verif image answer": "crosswalk(0.7231)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335871.jpg"}, {"question": "what does the white color in the sky mean", "gt answer": "cloud(1.00)", "pred answer": "land", "question_id": 1036995, "best approach": "", "verif answer": "cirrus", "anno approach": "wiki, concept, image", "verif wiki answer": "sky(0.6952)", "verif concept answer": "cirrus(0.6523)", "verif image answer": "bird(0.6943)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103699.jpg"}, {"question": "what kind of boat is this", "gt answer": "tanker(1.00)<br/>cruise(0.60)<br/>freight(0.60)", "pred answer": "barge", "question_id": 690435, "best approach": "image", "verif answer": "cargo", "anno approach": "wiki, concept, image", "verif wiki answer": "cruise ship(0.6629)", "verif concept answer": "cargo(0.6885)", "verif image answer": "freight(0.6942)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069043.jpg"}, {"question": "which teddy bear is for girls", "gt answer": "pink 1(1.00)<br/>both(0.60)", "pred answer": "teddy", "question_id": 5755945, "best approach": "image", "verif answer": "teddy bear", "anno approach": "wiki, concept, image", "verif wiki answer": "teddy bear(0.6072)", "verif concept answer": "baby(0.5891)", "verif image answer": "both(0.6547)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575594.jpg"}, {"question": "what is the international governing body of the sport seen here", "gt answer": "fifa(1.00)", "pred answer": "soccer", "question_id": 4647895, "best approach": "wiki, concept, image", "verif answer": "team", "anno approach": "wiki, concept, image", "verif wiki answer": "fifa(0.7289)", "verif concept answer": "fifa(0.7283)", "verif image answer": "fifa(0.7016)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464789.jpg"}, {"question": "what are these two individuals celebrating", "gt answer": "marriage(1.00)<br/>anniversary(0.60)<br/>birthday(0.60)", "pred answer": "wed", "question_id": 1232015, "best approach": "", "verif answer": "wed", "anno approach": "wiki, concept, image", "verif wiki answer": "wed(0.7303)", "verif concept answer": "wed(0.7005)", "verif image answer": "wed(0.7053)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123201.jpg"}, {"question": "what types of cheeses are on the platter", "gt answer": "brie(1.00)<br/>french(0.60)", "pred answer": "mozzarella", "question_id": 5056265, "best approach": "wiki, concept", "verif answer": "american", "anno approach": "wiki, concept, image", "verif wiki answer": "brie(0.5384)", "verif concept answer": "brie(0.5074)", "verif image answer": "feta(0.5909)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505626.jpg"}, {"question": "what is this person about to do", "gt answer": "ride(1.00)", "pred answer": "horse ride", "question_id": 2272025, "best approach": "concept", "verif answer": "horse race", "anno approach": "wiki, concept, image", "verif wiki answer": "plow(0.6532)", "verif concept answer": "ride(0.5763)", "verif image answer": "plow(0.5859)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000227202.jpg"}, {"question": "which tech event is this presenter speaking at", "gt answer": "cellphone(1.00)<br/>cellular(0.60)<br/>apple(0.60)<br/>cell phone(0.60)", "pred answer": "rally", "question_id": 82845, "best approach": "image", "verif answer": "communication", "anno approach": "wiki, concept, image", "verif wiki answer": "communication(0.7017)", "verif concept answer": "communication(0.6296)", "verif image answer": "cellular(0.6442)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008284.jpg"}, {"question": "are these people young or old", "gt answer": "old(1.00)<br/>young(0.60)", "pred answer": "younger", "question_id": 1599535, "best approach": "wiki", "verif answer": "old", "anno approach": "wiki, concept, image", "verif wiki answer": "young(0.7284)", "verif concept answer": "elderly(0.6181)", "verif image answer": "elderly(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159953.jpg"}, {"question": "how much weight can this train pull", "gt answer": "ton(1.00)<br/>thousand(0.60)", "pred answer": "lot", "question_id": 1627475, "best approach": "", "verif answer": "ton", "anno approach": "wiki, concept, image", "verif wiki answer": "2 tons(0.7137)", "verif concept answer": "2 tons(0.7154)", "verif image answer": "1000(0.7218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162747.jpg"}, {"question": "where these red vegetables imported to the us or exported from the us", "gt answer": "imported(1.00)", "pred answer": "idaho", "question_id": 2257045, "best approach": "", "verif answer": "factory", "anno approach": "wiki, concept, image", "verif wiki answer": "protzmann(0.5524)", "verif concept answer": "europe(0.5648)", "verif image answer": "protzmann(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225704.jpg"}, {"question": "what famous female athlete known for this sport lost an arm to a shark attack", "gt answer": "bethany hamilton(1.00)", "pred answer": "kelly slater", "question_id": 97385, "best approach": "wiki, concept, image", "verif answer": "bethany hamilton", "anno approach": "wiki, concept, image", "verif wiki answer": "bethany hamilton(0.6428)", "verif concept answer": "bethany hamilton(0.6242)", "verif image answer": "bethany hamilton(0.5250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009738.jpg"}, {"question": "what is the name of the sandwich", "gt answer": "grilled cheese(1.00)", "pred answer": "pulled pork", "question_id": 2885565, "best approach": "", "verif answer": "toasted", "anno approach": "wiki, concept, image", "verif wiki answer": "cheesecake(0.6428)", "verif concept answer": "cheesecake(0.6963)", "verif image answer": "toasted(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288556.jpg"}, {"question": "what type of flowers are growing out of the suitcase", "gt answer": "pansy(1.00)<br/>sun(0.60)", "pred answer": "daffodil", "question_id": 4915165, "best approach": "", "verif answer": "daisy", "anno approach": "wiki, concept, image", "verif wiki answer": "daisy(0.7100)", "verif concept answer": "candle(0.7103)", "verif image answer": "daisy(0.6414)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491516.jpg"}, {"question": "what vitamin does this vegetable contain", "gt answer": "vitamin(1.00)<br/>(0.60)<br/>vitamin k(0.60)", "pred answer": "c", "question_id": 4719055, "best approach": "concept, image", "verif answer": "vitamin k", "anno approach": "wiki, concept, image", "verif wiki answer": "d(0.6734)", "verif concept answer": "vitamin(0.6562)", "verif image answer": "vitamin(0.7198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471905.jpg"}, {"question": "what is the title commonly given to the man wearing the red tie and green vest", "gt answer": "bartender(1.00)", "pred answer": "policeman", "question_id": 314345, "best approach": "", "verif answer": "goalie", "anno approach": "wiki, concept, image", "verif wiki answer": "apron(0.6014)", "verif concept answer": "goalie(0.5899)", "verif image answer": "goalie(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000031434.jpg"}, {"question": "which stop is this bus heading to next", "gt answer": "epping(1.00)", "pred answer": "london", "question_id": 4345875, "best approach": "", "verif answer": "downtown", "anno approach": "wiki, concept, image", "verif wiki answer": "downtown(0.6705)", "verif concept answer": "downtown(0.6658)", "verif image answer": "downtown(0.6952)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434587.jpg"}, {"question": "why is the cow sitting where it is", "gt answer": "shade(1.00)<br/>for shade(1.00)", "pred answer": "graze", "question_id": 3429525, "best approach": "", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "block sun(0.7204)", "verif concept answer": "block sun(0.7194)", "verif image answer": "rain(0.6512)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342952.jpg"}, {"question": "where is fizz soda manufactured", "gt answer": "factory(1.00)<br/>america(1.00)<br/>usa(0.60)", "pred answer": "united state", "question_id": 4285655, "best approach": "", "verif answer": "united state", "anno approach": "wiki, concept, image", "verif wiki answer": "china(0.6265)", "verif concept answer": "china(0.6694)", "verif image answer": "china(0.6516)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428565.jpg"}, {"question": "where is this", "gt answer": "lugg valley(1.00)<br/>europe(0.60)<br/>england(0.60)<br/>city(0.60)", "pred answer": "london", "question_id": 4042215, "best approach": "wiki, concept, image", "verif answer": "city", "anno approach": "wiki, concept, image", "verif wiki answer": "city(0.7047)", "verif concept answer": "city(0.6892)", "verif image answer": "city(0.7191)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404221.jpg"}, {"question": "what food is in the photo", "gt answer": "egg(1.00)", "pred answer": "meat", "question_id": 5290195, "best approach": "", "verif answer": "salmon", "anno approach": "wiki, concept, image", "verif wiki answer": "egg salad(0.6258)", "verif concept answer": "egg salad(0.6741)", "verif image answer": "sunny side up(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529019.jpg"}, {"question": "what software is being shown in the image", "gt answer": "excel(1.00)<br/>microsoft(0.60)", "pred answer": "dell", "question_id": 4780875, "best approach": "", "verif answer": "dell", "anno approach": "wiki, concept, image", "verif wiki answer": "macbook(0.7238)", "verif concept answer": "macbook(0.7190)", "verif image answer": "computer(0.7033)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478087.jpg"}, {"question": "what quality of memory are these large animals known to have", "gt answer": "great(1.00)<br/>large(0.60)", "pred answer": "good", "question_id": 4336625, "best approach": "image", "verif answer": "tusk", "anno approach": "wiki, concept, image", "verif wiki answer": "adult(0.6757)", "verif concept answer": "adult(0.6197)", "verif image answer": "large(0.6672)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000433662.jpg"}, {"question": "what is the wingspan of this bird", "gt answer": "3 feet(1.00)<br/>6 feet(0.60)<br/>huge(0.60)", "pred answer": "1 foot", "question_id": 2070055, "best approach": "image", "verif answer": "3 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "4 feet(0.6749)", "verif concept answer": "4 feet(0.5933)", "verif image answer": "huge(0.6985)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207005.jpg"}, {"question": "which item depicted was made with long needles", "gt answer": "hat(1.00)", "pred answer": "book", "question_id": 3477845, "best approach": "", "verif answer": "cap", "anno approach": "wiki, concept, image", "verif wiki answer": "coat(0.7156)", "verif concept answer": "bonnet(0.7265)", "verif image answer": "bonnet(0.6638)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347784.jpg"}, {"question": "the dish in this picture originates from which country", "gt answer": "belgium(1.00)<br/>france(0.60)<br/>england(0.60)<br/>us(0.60)", "pred answer": "great britain", "question_id": 3162245, "best approach": "wiki, concept", "verif answer": "france", "anno approach": "wiki, concept, image", "verif wiki answer": "belgium(0.7219)", "verif concept answer": "belgium(0.7150)", "verif image answer": "france(0.7090)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316224.jpg"}, {"question": "what sort of iconic american west hero is associated with these animals", "gt answer": "cowboy(1.00)", "pred answer": "chicago", "question_id": 856575, "best approach": "image", "verif answer": "cowboy", "anno approach": "wiki, concept, image", "verif wiki answer": "bowler(0.6637)", "verif concept answer": "levi(0.5914)", "verif image answer": "cowboy(0.5389)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085657.jpg"}, {"question": "when was this sport invented", "gt answer": "1769(1.00)<br/>1970(0.60)<br/>1960(0.60)", "pred answer": "1926", "question_id": 4032715, "best approach": "wiki, concept, image", "verif answer": "1950s", "anno approach": "wiki, concept, image", "verif wiki answer": "1769(0.7155)", "verif concept answer": "1769(0.7249)", "verif image answer": "1769(0.7223)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403271.jpg"}, {"question": "how long can an elephant go without water", "gt answer": "4 days(1.00)<br/>5 days(1.00)", "pred answer": "2 years", "question_id": 1170625, "best approach": "", "verif answer": "2 days", "anno approach": "wiki, concept, image", "verif wiki answer": "3 days(0.6513)", "verif concept answer": "2 days(0.5842)", "verif image answer": "3 days(0.7208)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117062.jpg"}, {"question": "what is connected to the pole in the picture", "gt answer": "wire(1.00)<br/>power line(0.60)", "pred answer": "rope", "question_id": 679525, "best approach": "image", "verif answer": "power line", "anno approach": "wiki, concept, image", "verif wiki answer": "barbed wire(0.7300)", "verif concept answer": "barbed wire(0.7273)", "verif image answer": "power line(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067952.jpg"}, {"question": "who owns this train", "gt answer": "amtrak(1.00)<br/>government(1.00)<br/>russia(0.60)", "pred answer": "engineer", "question_id": 4348775, "best approach": "wiki, concept, image", "verif answer": "bullet", "anno approach": "wiki, concept, image", "verif wiki answer": "government(0.7284)", "verif concept answer": "government(0.6992)", "verif image answer": "amtrak(0.7036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434877.jpg"}, {"question": "what is used to help the green plant grow", "gt answer": "fertilizer(1.00)<br/>water(0.60)", "pred answer": "chlorophyll", "question_id": 3863905, "best approach": "concept, image", "verif answer": "water", "anno approach": "wiki, concept, image", "verif wiki answer": "boogie board(0.5069)", "verif concept answer": "fertilizer(0.5525)", "verif image answer": "fertilizer(0.6360)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000386390.jpg"}, {"question": "what is the name brand of this type of transportation", "gt answer": "airfrance(1.00)<br/>boeing(1.00)<br/>airbus(0.60)", "pred answer": "delta", "question_id": 1133105, "best approach": "wiki", "verif answer": "delta", "anno approach": "wiki, concept, image", "verif wiki answer": "airfrance(0.7175)", "verif concept answer": "delta(0.7146)", "verif image answer": "airbus(0.7203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113310.jpg"}, {"question": "what is it called when a player hits a ball over the wall in this sport", "gt answer": "homerun(1.00)<br/>home run(1.00)<br/>court(0.60)", "pred answer": "fly ball", "question_id": 5531165, "best approach": "wiki, concept, image", "verif answer": "homerun", "anno approach": "wiki, concept, image", "verif wiki answer": "homerun(0.7290)", "verif concept answer": "homerun(0.7285)", "verif image answer": "homerun(0.7219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553116.jpg"}, {"question": "what part of the street is this", "gt answer": "intersection(1.00)<br/>hood(0.60)", "pred answer": "downtown", "question_id": 2666465, "best approach": "image", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "walkway(0.6629)", "verif concept answer": "walkway(0.6897)", "verif image answer": "intersection(0.6317)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266646.jpg"}, {"question": "how is this food made", "gt answer": "cooked(1.00)", "pred answer": "fried", "question_id": 3404195, "best approach": "", "verif answer": "fried", "anno approach": "wiki, concept, image", "verif wiki answer": "fried(0.7132)", "verif concept answer": "fried(0.6941)", "verif image answer": "boiled(0.6638)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340419.jpg"}, {"question": "what does the cake say in english", "gt answer": "happy birthday(1.00)", "pred answer": "o", "question_id": 1016925, "best approach": "", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "birthday(0.5651)", "verif concept answer": "birthday(0.6644)", "verif image answer": "birthday(0.5540)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000101692.jpg"}, {"question": "what is the green item on this plate for", "gt answer": "garnish(1.00)<br/>decoration(0.60)", "pred answer": "cream", "question_id": 4965135, "best approach": "wiki, concept, image", "verif answer": "sugar", "anno approach": "wiki, concept, image", "verif wiki answer": "garnish(0.7016)", "verif concept answer": "garnish(0.6899)", "verif image answer": "garnish(0.7271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496513.jpg"}, {"question": "what is the common name of the person that polices these", "gt answer": "meter maid(1.00)<br/>maid(0.60)", "pred answer": "policeman", "question_id": 2535285, "best approach": "wiki, image", "verif answer": "farmer", "anno approach": "wiki, concept, image", "verif wiki answer": "meter maid(0.6475)", "verif concept answer": "farmer(0.5684)", "verif image answer": "meter maid(0.5190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253528.jpg"}, {"question": "which meal can be eaten in this setting", "gt answer": "picnic(1.00)<br/>lunch(1.00)", "pred answer": "breakfast", "question_id": 1251885, "best approach": "concept, image", "verif answer": "breakfast", "anno approach": "wiki, concept, image", "verif wiki answer": "dinner(0.7267)", "verif concept answer": "lunch(0.7197)", "verif image answer": "lunch(0.7125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125188.jpg"}, {"question": "what kind of bird is this", "gt answer": "toucan(1.00)<br/>parrot(0.60)", "pred answer": "parakeet", "question_id": 5806525, "best approach": "", "verif answer": "finch", "anno approach": "wiki, concept, image", "verif wiki answer": "woodpecker(0.7110)", "verif concept answer": "woodpecker(0.7293)", "verif image answer": "woodpecker(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580652.jpg"}, {"question": "who is the famous cartoon version of this animal first seen in 1958", "gt answer": "yogi(1.00)", "pred answer": "baloo", "question_id": 5614485, "best approach": "", "verif answer": "thomas tank engine", "anno approach": "wiki, concept, image", "verif wiki answer": "bob(0.5008)", "verif concept answer": "bob(0.5001)", "verif image answer": "bob(0.5000)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561448.jpg"}, {"question": "what might this man collect or repair", "gt answer": "clock(1.00)", "pred answer": "tell time", "question_id": 4114925, "best approach": "", "verif answer": "tell time", "anno approach": "wiki, concept, image", "verif wiki answer": "tell time(0.7245)", "verif concept answer": "tell time(0.6889)", "verif image answer": "decor(0.6997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000411492.jpg"}, {"question": "where is the man in the boat", "gt answer": "middle(1.00)<br/>on lake(0.60)", "pred answer": "dock", "question_id": 4506085, "best approach": "wiki, concept, image", "verif answer": "dock", "anno approach": "wiki, concept, image", "verif wiki answer": "middle(0.7133)", "verif concept answer": "middle(0.7035)", "verif image answer": "middle(0.7110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450608.jpg"}, {"question": "who is in this picture", "gt answer": "old woman(1.00)<br/>women(0.60)<br/>seagull(0.60)", "pred answer": "gondolier", "question_id": 1350455, "best approach": "wiki, image", "verif answer": "bird", "anno approach": "wiki, concept, image", "verif wiki answer": "women(0.7140)", "verif concept answer": "bird(0.6266)", "verif image answer": "women(0.6308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000135045.jpg"}, {"question": "what model of toyota is shown", "gt answer": "corolla(1.00)", "pred answer": "car", "question_id": 3027135, "best approach": "", "verif answer": "van", "anno approach": "wiki, concept, image", "verif wiki answer": "jeep(0.7236)", "verif concept answer": "van(0.6797)", "verif image answer": "suv(0.6694)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302713.jpg"}, {"question": "who was the first to create one of these signs", "gt answer": "william phelps eno(1.00)", "pred answer": "garrett morgan", "question_id": 4251875, "best approach": "wiki, concept", "verif answer": "stop", "anno approach": "wiki, concept, image", "verif wiki answer": "william phelps eno(0.7276)", "verif concept answer": "william phelps eno(0.7005)", "verif image answer": "street sign(0.7046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000425187.jpg"}, {"question": "what year did this action figures first get released", "gt answer": "1977(1.00)", "pred answer": "2000", "question_id": 1036765, "best approach": "concept", "verif answer": "1990", "anno approach": "wiki, concept, image", "verif wiki answer": "1970(0.6857)", "verif concept answer": "1977(0.6631)", "verif image answer": "1970(0.7093)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103676.jpg"}, {"question": "although this is a british plane which colors shown here are also famously associated with the us", "gt answer": "red white and blue(1.00)", "pred answer": "blue", "question_id": 4663015, "best approach": "", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "winter(0.6490)", "verif concept answer": "winter(0.6758)", "verif image answer": "winter(0.7141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466301.jpg"}, {"question": "which company based in finland produces these", "gt answer": "nokia(1.00)", "pred answer": "motorola", "question_id": 1852005, "best approach": "", "verif answer": "motorola", "anno approach": "wiki, concept, image", "verif wiki answer": "motorola(0.7003)", "verif concept answer": "motorola(0.6972)", "verif image answer": "razor(0.6751)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000185200.jpg"}, {"question": "what breed of bird is pictured", "gt answer": "hornbill(1.00)", "pred answer": "duck", "question_id": 2493065, "best approach": "concept, image", "verif answer": "crow", "anno approach": "wiki, concept, image", "verif wiki answer": "crow(0.7195)", "verif concept answer": "hornbill(0.6654)", "verif image answer": "hornbill(0.6886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249306.jpg"}, {"question": "what kind of sandwich is this", "gt answer": "hoagie(1.00)<br/>sub(1.00)", "pred answer": "panini", "question_id": 899125, "best approach": "", "verif answer": "turkey", "anno approach": "wiki, concept, image", "verif wiki answer": "mcrib(0.6623)", "verif concept answer": "mcrib(0.6900)", "verif image answer": "mcrib(0.7038)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089912.jpg"}, {"question": "what do these forms of transportation run off of", "gt answer": "jet fuel(1.00)<br/>fuel(0.60)<br/>runway(0.60)", "pred answer": "airplane", "question_id": 1909645, "best approach": "wiki", "verif answer": "fuel", "anno approach": "wiki, concept, image", "verif wiki answer": "jet fuel(0.7276)", "verif concept answer": "fuel(0.6247)", "verif image answer": "runway(0.7108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190964.jpg"}, {"question": "is this pool inside or outside", "gt answer": "inside(1.00)", "pred answer": "outside", "question_id": 2584005, "best approach": "", "verif answer": "outside", "anno approach": "wiki, concept, image", "verif wiki answer": "outside(0.7272)", "verif concept answer": "outside(0.7302)", "verif image answer": "outside(0.7115)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258400.jpg"}, {"question": "what is the batter 's name", "gt answer": "fowler(1.00)<br/>dexter(0.60)", "pred answer": "sonnanstine", "question_id": 3876065, "best approach": "wiki, concept, image", "verif answer": "dexter", "anno approach": "wiki, concept, image", "verif wiki answer": "dexter(0.6771)", "verif concept answer": "dexter(0.5061)", "verif image answer": "dexter(0.5625)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387606.jpg"}, {"question": "what brand of chips are on the fridge", "gt answer": "ruffle(1.00)<br/>cracker(0.60)", "pred answer": "ge", "question_id": 5153775, "best approach": "", "verif answer": "pickle", "anno approach": "wiki, concept, image", "verif wiki answer": "pickle(0.6971)", "verif concept answer": "pickle(0.7251)", "verif image answer": "pickle(0.7196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515377.jpg"}, {"question": "what country could you find a market like this", "gt answer": "vietnam(1.00)<br/>thailand(0.60)<br/>mexico(0.60)", "pred answer": "india", "question_id": 4698515, "best approach": "wiki, concept, image", "verif answer": "mexico", "anno approach": "wiki, concept, image", "verif wiki answer": "thailand(0.6676)", "verif concept answer": "mexico(0.6730)", "verif image answer": "thailand(0.6956)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469851.jpg"}, {"question": "what is the general purpose of this cutting device", "gt answer": "cut(1.00)", "pred answer": "sew", "question_id": 3671005, "best approach": "", "verif answer": "sew", "anno approach": "wiki, concept, image", "verif wiki answer": "haircut(0.6802)", "verif concept answer": "haircut(0.7113)", "verif image answer": "haircut(0.7009)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367100.jpg"}, {"question": "how did that woman get her hair to look like the flower", "gt answer": "dye(1.00)", "pred answer": "paint", "question_id": 5157045, "best approach": "concept, image", "verif answer": "dye", "anno approach": "wiki, concept, image", "verif wiki answer": "light(0.6961)", "verif concept answer": "dye(0.6355)", "verif image answer": "dye(0.6836)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515704.jpg"}, {"question": "what jewler does the seated woman on the left have on her arm", "gt answer": "bracelet(1.00)<br/>tiffany(0.60)", "pred answer": "peace", "question_id": 919265, "best approach": "", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "man(0.5676)", "verif concept answer": "man(0.5394)", "verif image answer": "man(0.5059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000091926.jpg"}, {"question": "what type of event could this be", "gt answer": "equestrian(1.00)<br/>horse show(0.60)<br/>race(0.60)", "pred answer": "horse race", "question_id": 3839305, "best approach": "wiki, concept", "verif answer": "equestrian", "anno approach": "wiki, concept, image", "verif wiki answer": "horse show(0.6799)", "verif concept answer": "race(0.7019)", "verif image answer": "rodeo(0.7072)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383930.jpg"}, {"question": "name the type of wood used to make this sitting bench shown in this picture", "gt answer": "teak(1.00)<br/>pine(1.00)", "pred answer": "cedar", "question_id": 4841365, "best approach": "wiki", "verif answer": "cedar", "anno approach": "wiki, concept, image", "verif wiki answer": "teak(0.7266)", "verif concept answer": "cedar(0.7245)", "verif image answer": "large(0.7060)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484136.jpg"}, {"question": "what does that truck haul", "gt answer": "cement(1.00)", "pred answer": "fuel", "question_id": 5536595, "best approach": "", "verif answer": "tow", "anno approach": "wiki, concept, image", "verif wiki answer": "tow(0.7146)", "verif concept answer": "garbage truck(0.7134)", "verif image answer": "garbage truck(0.7107)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553659.jpg"}, {"question": "if these strangers had a missed connection what section of the news paper would they list it", "gt answer": "classified(1.00)<br/>person(0.60)", "pred answer": "pc gamer", "question_id": 2091325, "best approach": "", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "map(0.6546)", "verif concept answer": "map(0.7073)", "verif image answer": "map(0.6301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209132.jpg"}, {"question": "what is the distance between this couple and the mountain behind them", "gt answer": "2 miles(1.00)<br/>1 mile(1.00)", "pred answer": "30 feet", "question_id": 391375, "best approach": "wiki, concept, image", "verif answer": "1 mile", "anno approach": "wiki, concept, image", "verif wiki answer": "2 miles(0.7101)", "verif concept answer": "2 miles(0.5956)", "verif image answer": "1 mile(0.6179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039137.jpg"}, {"question": "what kind of store are these tools in", "gt answer": "hardware(1.00)<br/>hardware store(0.60)<br/>shoemaker(0.60)", "pred answer": "grocery store", "question_id": 1831005, "best approach": "wiki, concept, image", "verif answer": "store", "anno approach": "wiki, concept, image", "verif wiki answer": "hardware store(0.7302)", "verif concept answer": "hardware store(0.7149)", "verif image answer": "hardware store(0.7094)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183100.jpg"}, {"question": "what action is the person in the picture performing", "gt answer": "clean(1.00)<br/>(0.60)", "pred answer": "wash", "question_id": 1300115, "best approach": "image", "verif answer": "clean teeth", "anno approach": "wiki, concept, image", "verif wiki answer": "clean teeth(0.6535)", "verif concept answer": "clean teeth(0.6922)", "verif image answer": "(0.6540)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130011.jpg"}, {"question": "what brand of car is that", "gt answer": "buick(1.00)<br/>lincoln(1.00)<br/>mercedes(0.60)", "pred answer": "ford", "question_id": 2768945, "best approach": "concept, image", "verif answer": "mercedes", "anno approach": "wiki, concept, image", "verif wiki answer": "mercedes(0.6601)", "verif concept answer": "buick(0.7180)", "verif image answer": "lincoln(0.7226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276894.jpg"}, {"question": "who sewed the first one of these that are being carried", "gt answer": "betsy ross(1.00)", "pred answer": "dean kamen", "question_id": 4612265, "best approach": "", "verif answer": "richard trevithick", "anno approach": "wiki, concept, image", "verif wiki answer": "richard trevithick(0.7307)", "verif concept answer": "richard trevithick(0.7298)", "verif image answer": "alexander graham bell(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461226.jpg"}, {"question": "what roles would this train serve", "gt answer": "transportation(1.00)<br/>travel(0.60)<br/>transport(0.60)", "pred answer": "transport good", "question_id": 1550615, "best approach": "wiki, concept, image", "verif answer": "travel", "anno approach": "wiki, concept, image", "verif wiki answer": "transport(0.6505)", "verif concept answer": "travel(0.6568)", "verif image answer": "transport(0.6754)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155061.jpg"}, {"question": "how much rom does that laptop have", "gt answer": "1 gigabyte(1.00)<br/>8(0.60)", "pred answer": "8gb", "question_id": 3775705, "best approach": "", "verif answer": "2", "anno approach": "wiki, concept, image", "verif wiki answer": "2(0.6851)", "verif concept answer": "2(0.6596)", "verif image answer": "5(0.7137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377570.jpg"}, {"question": "is this pollution or clouds", "gt answer": "pollution(1.00)", "pred answer": "storm", "question_id": 3704175, "best approach": "", "verif answer": "cumulus", "anno approach": "wiki, concept, image", "verif wiki answer": "light(0.7216)", "verif concept answer": "light(0.7292)", "verif image answer": "light(0.6085)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370417.jpg"}, {"question": "what is this jacket made of", "gt answer": "denim(1.00)<br/>jean(0.60)", "pred answer": "silk", "question_id": 1711035, "best approach": "wiki", "verif answer": "cotton", "anno approach": "wiki, concept, image", "verif wiki answer": "denim(0.6905)", "verif concept answer": "polyester(0.5436)", "verif image answer": "cotton(0.6398)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000171103.jpg"}, {"question": "where are these people located", "gt answer": "hospital(1.00)", "pred answer": "school", "question_id": 5759295, "best approach": "wiki", "verif answer": "library", "anno approach": "wiki, concept, image", "verif wiki answer": "hospital(0.7272)", "verif concept answer": "army(0.7228)", "verif image answer": "office(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575929.jpg"}, {"question": "what does this animal produce that people use", "gt answer": "wool(1.00)<br/>milk(0.60)", "pred answer": "meat", "question_id": 1343065, "best approach": "concept, image", "verif answer": "wool", "anno approach": "wiki, concept, image", "verif wiki answer": "milk(0.6900)", "verif concept answer": "wool(0.7126)", "verif image answer": "wool(0.6880)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134306.jpg"}, {"question": "what makes an apple red instead of green", "gt answer": "ripe(1.00)<br/>beta carotene(0.60)", "pred answer": "tomato", "question_id": 214475, "best approach": "", "verif answer": "beta carotene", "anno approach": "wiki, concept, image", "verif wiki answer": "over ripe(0.7236)", "verif concept answer": "over ripe(0.7245)", "verif image answer": "over ripe(0.7140)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000021447.jpg"}, {"question": "what type of plane is this", "gt answer": "cessna(1.00)<br/>propeller(0.60)<br/>biplane(0.60)", "pred answer": "private", "question_id": 3879775, "best approach": "image", "verif answer": "propeller", "anno approach": "wiki, concept, image", "verif wiki answer": "cesna(0.7269)", "verif concept answer": "cesna(0.6851)", "verif image answer": "biplane(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387977.jpg"}, {"question": "these types of boats would work well in which type of weather", "gt answer": "windy(1.00)<br/>sunny(1.00)<br/>fish boat(0.60)", "pred answer": "rain", "question_id": 3459445, "best approach": "", "verif answer": "warm", "anno approach": "wiki, concept, image", "verif wiki answer": "warm(0.6738)", "verif concept answer": "warm(0.6726)", "verif image answer": "warm(0.7044)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345944.jpg"}, {"question": "what type of drink is probably in the glass", "gt answer": "orange juice(1.00)<br/>tea(0.60)", "pred answer": "beer", "question_id": 1068325, "best approach": "image", "verif answer": "juice", "anno approach": "wiki, concept, image", "verif wiki answer": "tea(0.6828)", "verif concept answer": "tea(0.7035)", "verif image answer": "orange juice(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106832.jpg"}, {"question": "what is the brown stuff atop the broccoli", "gt answer": "bacon(1.00)<br/>broccoli(0.60)", "pred answer": "wasabi", "question_id": 514345, "best approach": "", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "tomato(0.5743)", "verif concept answer": "tomato(0.6252)", "verif image answer": "ham(0.7223)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000051434.jpg"}, {"question": "what breed of dog is this", "gt answer": "chihuaha(1.00)<br/>chihuahua(0.60)", "pred answer": "collie", "question_id": 5815, "best approach": "wiki, image", "verif answer": "chihuahua", "anno approach": "wiki, concept, image", "verif wiki answer": "chihuahua(0.7299)", "verif concept answer": "dachshund(0.7149)", "verif image answer": "chihuahua(0.6617)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000581.jpg"}, {"question": "what is the metal apparatus seen here used for", "gt answer": "water fountain(1.00)<br/>drink water(0.60)<br/>drink(0.60)<br/>water(0.60)", "pred answer": "toilet", "question_id": 4958025, "best approach": "wiki, concept", "verif answer": "drink", "anno approach": "wiki, concept, image", "verif wiki answer": "water fountain(0.7125)", "verif concept answer": "water fountain(0.6623)", "verif image answer": "drink water(0.6422)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495802.jpg"}, {"question": "on which slope are these skiers and snowboarders", "gt answer": "mountain(1.00)<br/>alpine(0.60)", "pred answer": "snowy", "question_id": 96085, "best approach": "", "verif answer": "alp", "anno approach": "wiki, concept, image", "verif wiki answer": "alp(0.6995)", "verif concept answer": "alp(0.7159)", "verif image answer": "alp(0.7214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009608.jpg"}, {"question": "what was the engine of this vehicle made of", "gt answer": "steel(1.00)<br/>metal(1.00)<br/>iron(0.60)", "pred answer": "gas", "question_id": 4957565, "best approach": "wiki, concept", "verif answer": "steel", "anno approach": "wiki, concept, image", "verif wiki answer": "metal(0.7007)", "verif concept answer": "steel(0.6274)", "verif image answer": "bronze(0.6145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495756.jpg"}, {"question": "where is this bus going", "gt answer": "downtown(1.00)<br/>new york(0.60)", "pred answer": "tour", "question_id": 2827895, "best approach": "wiki, concept, image", "verif answer": "downtown", "anno approach": "wiki, concept, image", "verif wiki answer": "new york(0.7000)", "verif concept answer": "new york(0.6500)", "verif image answer": "new york(0.5891)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282789.jpg"}, {"question": "what kind of business is this", "gt answer": "sale(1.00)", "pred answer": "police", "question_id": 5413135, "best approach": "", "verif answer": "mall", "anno approach": "wiki, concept, image", "verif wiki answer": "competition(0.7151)", "verif concept answer": "litter(0.7168)", "verif image answer": "litter(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541313.jpg"}, {"question": "what type of picture is on the back wall", "gt answer": "caricature(1.00)", "pred answer": "map", "question_id": 3701455, "best approach": "", "verif answer": "framed", "anno approach": "wiki, concept, image", "verif wiki answer": "find nemo(0.6425)", "verif concept answer": "find nemo(0.5912)", "verif image answer": "find nemo(0.6959)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370145.jpg"}, {"question": "which type of wood is used to make this brown chair shown in this photo", "gt answer": "wicker(1.00)<br/>oak(1.00)<br/>mahogany(0.60)", "pred answer": "bamboo", "question_id": 5235715, "best approach": "image", "verif answer": "wicker", "anno approach": "wiki, concept, image", "verif wiki answer": "mahogany(0.7228)", "verif concept answer": "rattan(0.6842)", "verif image answer": "wicker(0.6856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523571.jpg"}, {"question": "what is the guy wearing a brown shirt doing", "gt answer": "photograph(0.60)<br/>take picture(1.00)<br/>drink(0.60)", "pred answer": "work", "question_id": 1819295, "best approach": "concept, image", "verif answer": "photograph", "anno approach": "wiki, concept, image", "verif wiki answer": "photography(0.7054)", "verif concept answer": "photograph(0.6614)", "verif image answer": "photograph(0.7041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181929.jpg"}, {"question": "are the carbs shown here processed or unrefined", "gt answer": "processed(1.00)", "pred answer": "fry", "question_id": 753695, "best approach": "wiki, concept", "verif answer": "both", "anno approach": "wiki, concept, image", "verif wiki answer": "processed(0.6303)", "verif concept answer": "processed(0.6522)", "verif image answer": "drunk(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075369.jpg"}, {"question": "is this person homeless or a pirate", "gt answer": "homeless(1.00)<br/>pirate(1.00)", "pred answer": "illegal", "question_id": 2142525, "best approach": "concept, image", "verif answer": "homeless", "anno approach": "wiki, concept, image", "verif wiki answer": "captain morgan(0.7227)", "verif concept answer": "homeless(0.5599)", "verif image answer": "pirate(0.7095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214252.jpg"}, {"question": "what is this structure made of", "gt answer": "steel(1.00)<br/>iron(0.60)", "pred answer": "metal", "question_id": 4636205, "best approach": "wiki, concept", "verif answer": "metal", "anno approach": "wiki, concept, image", "verif wiki answer": "steel(0.6732)", "verif concept answer": "steel(0.6500)", "verif image answer": "fiberglass(0.5858)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463620.jpg"}, {"question": "what food is this", "gt answer": "crab cake(1.00)<br/>lunch(0.60)", "pred answer": "breakfast", "question_id": 2498755, "best approach": "wiki, concept, image", "verif answer": "breakfast", "anno approach": "wiki, concept, image", "verif wiki answer": "crab cake(0.6868)", "verif concept answer": "crab cake(0.7126)", "verif image answer": "crab cake(0.7095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249875.jpg"}, {"question": "name the material used to make the cot shown in this picture", "gt answer": "metal(1.00)<br/>nylon(0.60)", "pred answer": "cotton", "question_id": 3987725, "best approach": "concept, image", "verif answer": "plastic", "anno approach": "wiki, concept, image", "verif wiki answer": "aluminum(0.5070)", "verif concept answer": "nylon(0.5102)", "verif image answer": "nylon(0.7023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398772.jpg"}, {"question": "what type of breed is this", "gt answer": "pony(1.00)<br/>shetland(0.60)<br/>mustang(0.60)", "pred answer": "horse", "question_id": 384875, "best approach": "image", "verif answer": "horse", "anno approach": "wiki, concept, image", "verif wiki answer": "arabian(0.7226)", "verif concept answer": "horse(0.7145)", "verif image answer": "shetland(0.6631)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038487.jpg"}, {"question": "what time is it on the clock face", "gt answer": "12:24(1.00)", "pred answer": "9:25", "question_id": 1641895, "best approach": "concept", "verif answer": "9:25", "anno approach": "wiki, concept, image", "verif wiki answer": "80(0.6116)", "verif concept answer": "12:24(0.5402)", "verif image answer": "9:25(0.7167)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000164189.jpg"}, {"question": "what type of car is the man driving", "gt answer": "suv(1.00)<br/>jeep(1.00)", "pred answer": "truck", "question_id": 2285195, "best approach": "wiki, concept, image", "verif answer": "jeep", "anno approach": "wiki, concept, image", "verif wiki answer": "jeep(0.7144)", "verif concept answer": "suv(0.6778)", "verif image answer": "suv(0.6895)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000228519.jpg"}, {"question": "what hairstyle here is a party in the back and business in the front", "gt answer": "mullet(1.00)", "pred answer": "ponytail", "question_id": 2433045, "best approach": "wiki, concept, image", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "mullet(0.7186)", "verif concept answer": "mullet(0.6834)", "verif image answer": "mullet(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243304.jpg"}, {"question": "what kind of shirt does the child wear", "gt answer": "tshirt(1.00)<br/>tee(0.60)<br/>t shirt(0.60)", "pred answer": "button up", "question_id": 459895, "best approach": "concept", "verif answer": "button up", "anno approach": "wiki, concept, image", "verif wiki answer": "button up(0.6832)", "verif concept answer": "tshirt(0.6916)", "verif image answer": "button up(0.6572)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045989.jpg"}, {"question": "how are the drawers of the cabinet next to the sink constructed", "gt answer": "wicker(1.00)<br/>4(0.60)<br/>rattan(0.60)<br/>basket(0.60)", "pred answer": "wood", "question_id": 5790655, "best approach": "wiki, concept, image", "verif answer": "wicker", "anno approach": "wiki, concept, image", "verif wiki answer": "rattan(0.7056)", "verif concept answer": "rattan(0.6986)", "verif image answer": "rattan(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000579065.jpg"}, {"question": "is this coffee accompaniment baked frozen or both", "gt answer": "baked(1.00)", "pred answer": "bake", "question_id": 1068305, "best approach": "concept", "verif answer": "bake", "anno approach": "wiki, concept, image", "verif wiki answer": "baked in oven(0.7164)", "verif concept answer": "baked(0.5287)", "verif image answer": "baked in oven(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106830.jpg"}, {"question": "who wouldn't eat this", "gt answer": "kid(0.60)<br/>vegan(0.60)<br/>vegetarian(1.00)", "pred answer": "human", "question_id": 282635, "best approach": "wiki", "verif answer": "hungry", "anno approach": "wiki, concept, image", "verif wiki answer": "kid(0.7270)", "verif concept answer": "hungry(0.7130)", "verif image answer": "hungry(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028263.jpg"}, {"question": "what do people use this for", "gt answer": "play game(0.60)<br/>game(1.00)<br/>video game(0.60)", "pred answer": "work", "question_id": 5610335, "best approach": "concept, image", "verif answer": "play game", "anno approach": "wiki, concept, image", "verif wiki answer": "play game(0.7071)", "verif concept answer": "game(0.7081)", "verif image answer": "game(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561033.jpg"}, {"question": "what is the length of that baseball bat", "gt answer": "42 inches(1.00)<br/>4 feet(0.60)", "pred answer": "12 inches", "question_id": 4875895, "best approach": "wiki", "verif answer": "12 inches", "anno approach": "wiki, concept, image", "verif wiki answer": "42 inches(0.7074)", "verif concept answer": "12 inches(0.6810)", "verif image answer": "12 inches(0.7153)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000487589.jpg"}, {"question": "what is the maker of this gaming system", "gt answer": "nintendo(1.00)<br/>wii(0.60)", "pred answer": "playstation", "question_id": 4015415, "best approach": "image", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "wii(0.7206)", "verif concept answer": "wii(0.7258)", "verif image answer": "nintendo(0.7275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401541.jpg"}, {"question": "what materials were used to make the rope", "gt answer": "hemp(1.00)<br/>cotton(0.60)", "pred answer": "nylon", "question_id": 3851305, "best approach": "", "verif answer": "cotton", "anno approach": "wiki, concept, image", "verif wiki answer": "bamboo(0.6208)", "verif concept answer": "bamboo(0.5886)", "verif image answer": "kale(0.5961)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385130.jpg"}, {"question": "the dog is in what part of this motorcycle", "gt answer": "sidecar(1.00)<br/>side car(0.60)<br/>back(0.60)", "pred answer": "front", "question_id": 844795, "best approach": "wiki, concept, image", "verif answer": "side car", "anno approach": "wiki, concept, image", "verif wiki answer": "side car(0.6560)", "verif concept answer": "side car(0.7262)", "verif image answer": "side car(0.5272)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084479.jpg"}, {"question": "what is the name of the famous dog competition that takes place after the superbowl every year", "gt answer": "puppy bowl(1.00)<br/>lassie(0.60)", "pred answer": "frisbee", "question_id": 1663285, "best approach": "wiki, concept", "verif answer": "frisbee", "anno approach": "wiki, concept, image", "verif wiki answer": "lassie(0.7289)", "verif concept answer": "lassie(0.6839)", "verif image answer": "frisbee(0.7221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166328.jpg"}, {"question": "what are these types of bears called", "gt answer": "sun bear(1.00)<br/>black(0.60)", "pred answer": "black bear", "question_id": 3829395, "best approach": "concept, image", "verif answer": "black bear", "anno approach": "wiki, concept, image", "verif wiki answer": "black bear(0.6908)", "verif concept answer": "sun bear(0.6927)", "verif image answer": "sun bear(0.6904)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382939.jpg"}, {"question": "what part of the plane can you see", "gt answer": "engine(1.00)", "pred answer": "propeller", "question_id": 1289575, "best approach": "concept", "verif answer": "engine", "anno approach": "wiki, concept, image", "verif wiki answer": "motor(0.5673)", "verif concept answer": "engine(0.6404)", "verif image answer": "motor(0.6757)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128957.jpg"}, {"question": "what type of milk do babies drink", "gt answer": "breast(1.00)", "pred answer": "tuna", "question_id": 2070515, "best approach": "concept", "verif answer": "milk", "anno approach": "wiki, concept, image", "verif wiki answer": "milk(0.6624)", "verif concept answer": "breast(0.6132)", "verif image answer": "milk(0.6676)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207051.jpg"}, {"question": "what is typically stored in the case the man is carrying", "gt answer": "paper(1.00)<br/>cloth(0.60)", "pred answer": "person", "question_id": 947665, "best approach": "wiki, concept", "verif answer": "cloth", "anno approach": "wiki, concept, image", "verif wiki answer": "cloth(0.6958)", "verif concept answer": "cloth(0.6486)", "verif image answer": "cotton(0.6195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094766.jpg"}, {"question": "what could you do in this", "gt answer": "bath(1.00)<br/>relax(0.60)", "pred answer": "wash hand", "question_id": 4618445, "best approach": "wiki", "verif answer": "bath", "anno approach": "wiki, concept, image", "verif wiki answer": "relax(0.7187)", "verif concept answer": "swim(0.7070)", "verif image answer": "swim(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461844.jpg"}, {"question": "where is this taken", "gt answer": "restaurant(1.00)<br/>kitchen(1.00)", "pred answer": "dine room", "question_id": 976605, "best approach": "", "verif answer": "dine room", "anno approach": "wiki, concept, image", "verif wiki answer": "dine room(0.7260)", "verif concept answer": "dine room(0.7142)", "verif image answer": "bar(0.7248)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000097660.jpg"}, {"question": "what species of bird is this", "gt answer": "parrot(1.00)", "pred answer": "parakeet", "question_id": 705585, "best approach": "", "verif answer": "parakeet", "anno approach": "wiki, concept, image", "verif wiki answer": "parakeet(0.7300)", "verif concept answer": "parakeet(0.7297)", "verif image answer": "parakeet(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070558.jpg"}, {"question": "how does the moon affect these natural phenomenon", "gt answer": "tide(1.00)<br/>wave(0.60)", "pred answer": "drown", "question_id": 1393095, "best approach": "wiki", "verif answer": "wave", "anno approach": "wiki, concept, image", "verif wiki answer": "tide(0.6851)", "verif concept answer": "wave(0.6541)", "verif image answer": "wave(0.5953)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139309.jpg"}, {"question": "what food group is mostly represented", "gt answer": "meat(1.00)<br/>protein(0.60)<br/>carrot(0.60)<br/>chicken(0.60)", "pred answer": "vegetable", "question_id": 1245775, "best approach": "image", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "steak(0.6507)", "verif concept answer": "chicken(0.7210)", "verif image answer": "meat(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000124577.jpg"}, {"question": "what is this room commonly used for", "gt answer": "live(1.00)<br/>eat(0.60)", "pred answer": "relax", "question_id": 4783065, "best approach": "image", "verif answer": "relax", "anno approach": "wiki, concept, image", "verif wiki answer": "dine(0.7036)", "verif concept answer": "relax(0.6184)", "verif image answer": "eat(0.6522)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478306.jpg"}, {"question": "what icing is used to make the cake artsy", "gt answer": "fondant(1.00)", "pred answer": "vanilla", "question_id": 4298585, "best approach": "concept", "verif answer": "vanilla", "anno approach": "wiki, concept, image", "verif wiki answer": "frost(0.7162)", "verif concept answer": "fondant(0.7271)", "verif image answer": "clay(0.7160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429858.jpg"}, {"question": "what 's passing each other in the background", "gt answer": "plane(1.00)<br/>airplane(0.60)", "pred answer": "contrail", "question_id": 2052805, "best approach": "wiki, concept, image", "verif answer": "airplane", "anno approach": "wiki, concept, image", "verif wiki answer": "plane(0.6954)", "verif concept answer": "plane(0.7031)", "verif image answer": "plane(0.6804)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000205280.jpg"}, {"question": "how would you groom these animals", "gt answer": "brush(1.00)", "pred answer": "shear", "question_id": 4760865, "best approach": "concept", "verif answer": "brush", "anno approach": "wiki, concept, image", "verif wiki answer": "brush teeth(0.7293)", "verif concept answer": "brush(0.7174)", "verif image answer": "brush teeth(0.6378)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476086.jpg"}, {"question": "what is the purpose of the vessel that is floating in the ocean", "gt answer": "drill for oil(1.00)<br/>oil(0.60)", "pred answer": "float", "question_id": 4712105, "best approach": "wiki, concept, image", "verif answer": "sail", "anno approach": "wiki, concept, image", "verif wiki answer": "drill for oil(0.7170)", "verif concept answer": "drill for oil(0.7052)", "verif image answer": "drill for oil(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471210.jpg"}, {"question": "what form of energy makes the train move", "gt answer": "electric(1.00)<br/>electricity(1.00)", "pred answer": "coal", "question_id": 2736415, "best approach": "wiki, concept, image", "verif answer": "electric", "anno approach": "wiki, concept, image", "verif wiki answer": "electric(0.6866)", "verif concept answer": "electric(0.7078)", "verif image answer": "electric(0.7096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273641.jpg"}, {"question": "what breed of dog is that", "gt answer": "bulldog(1.00)<br/>boxer(0.60)", "pred answer": "pug", "question_id": 3535045, "best approach": "", "verif answer": "pitbull", "anno approach": "wiki, concept, image", "verif wiki answer": "saint bernard(0.7126)", "verif concept answer": "pitbull(0.6505)", "verif image answer": "saint bernard(0.6868)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353504.jpg"}, {"question": "how many floors are on the cruise ship", "gt answer": "6(1.00)<br/>9(0.60)<br/>12(0.60)<br/>5(0.60)", "pred answer": "3", "question_id": 2449945, "best approach": "wiki, concept", "verif answer": "10", "anno approach": "wiki, concept, image", "verif wiki answer": "9(0.7114)", "verif concept answer": "9(0.6655)", "verif image answer": "10(0.5620)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244994.jpg"}, {"question": "how could a prism be used to create the image in the window", "gt answer": "rainbow(1.00)<br/>light(0.60)", "pred answer": "reflection", "question_id": 4465365, "best approach": "", "verif answer": "reflection", "anno approach": "wiki, concept, image", "verif wiki answer": "reflection(0.7265)", "verif concept answer": "reflection(0.6784)", "verif image answer": "reflection(0.6700)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000446536.jpg"}, {"question": "what country is the building in which this woman is standing located", "gt answer": "america(1.00)<br/>london(0.60)<br/>usa(0.60)", "pred answer": "england", "question_id": 2067545, "best approach": "", "verif answer": "usa", "anno approach": "wiki, concept, image", "verif wiki answer": "asia(0.6876)", "verif concept answer": "asia(0.7109)", "verif image answer": "asia(0.6986)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206754.jpg"}, {"question": "what type of tennis swing is this", "gt answer": "overhand(1.00)<br/>backhand(0.60)", "pred answer": "forehand", "question_id": 1237315, "best approach": "image", "verif answer": "forehand", "anno approach": "wiki, concept, image", "verif wiki answer": "backhand(0.7262)", "verif concept answer": "forehand(0.7261)", "verif image answer": "overhand(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000123731.jpg"}, {"question": "which famous breakfast item is also the first part of the name of the asian rolled edible seen here", "gt answer": "egg(1.00)", "pred answer": "breakfast", "question_id": 5784975, "best approach": "", "verif answer": "egg salad", "anno approach": "wiki, concept, image", "verif wiki answer": "egg salad(0.5106)", "verif concept answer": "egg salad(0.5921)", "verif image answer": "fish(0.5112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578497.jpg"}, {"question": "what type of plant is this", "gt answer": "bush(1.00)<br/>shrub(0.60)<br/>lime(0.60)", "pred answer": "fern", "question_id": 947535, "best approach": "", "verif answer": "tree", "anno approach": "wiki, concept, image", "verif wiki answer": "banana(0.7209)", "verif concept answer": "banana(0.7239)", "verif image answer": "tree(0.6955)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094753.jpg"}, {"question": "how many calories are in an average one of these", "gt answer": "200(1.00)<br/>300(0.60)<br/>400(0.60)", "pred answer": "500", "question_id": 1178845, "best approach": "wiki, concept", "verif answer": "500", "anno approach": "wiki, concept, image", "verif wiki answer": "400(0.7026)", "verif concept answer": "400(0.6900)", "verif image answer": "500(0.7205)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117884.jpg"}, {"question": "how do we know this is not a real bird", "gt answer": "string(1.00)", "pred answer": "wind", "question_id": 4237775, "best approach": "", "verif answer": "kite", "anno approach": "wiki, concept, image", "verif wiki answer": "kite(0.5459)", "verif concept answer": "thread(0.5722)", "verif image answer": "kite(0.6592)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000423777.jpg"}, {"question": "which famous nursery pair went rolling down an incline like this one", "gt answer": "jack and jill(1.00)", "pred answer": "thomas tank engine", "question_id": 1814635, "best approach": "concept", "verif answer": "jack and jill", "anno approach": "wiki, concept, image", "verif wiki answer": "mechanical(0.5060)", "verif concept answer": "jack and jill(0.5355)", "verif image answer": "underhand(0.6555)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181463.jpg"}, {"question": "what brand of candy is shown here", "gt answer": "mike and ike(1.00)", "pred answer": "dunkin donuts", "question_id": 2402855, "best approach": "wiki, concept, image", "verif answer": "walmart", "anno approach": "wiki, concept, image", "verif wiki answer": "mike and ike(0.6238)", "verif concept answer": "mike and ike(0.6823)", "verif image answer": "mike and ike(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240285.jpg"}, {"question": "what corporation uses these as a mascot", "gt answer": "budweiser(1.00)<br/>sport(0.60)", "pred answer": "disney", "question_id": 956115, "best approach": "image", "verif answer": "race", "anno approach": "wiki, concept, image", "verif wiki answer": "race(0.6183)", "verif concept answer": "race(0.5797)", "verif image answer": "sport(0.6464)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000095611.jpg"}, {"question": "why are the vehicles stopped", "gt answer": "red light(1.00)<br/>traffic light(0.60)", "pred answer": "turn", "question_id": 3306965, "best approach": "wiki, image", "verif answer": "stop light", "anno approach": "wiki, concept, image", "verif wiki answer": "red light(0.7296)", "verif concept answer": "no u turn(0.7176)", "verif image answer": "red light(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000330696.jpg"}, {"question": "how often will those shears need to be sharpened", "gt answer": "daily(1.00)<br/>monthly(0.60)", "pred answer": "not often", "question_id": 464925, "best approach": "", "verif answer": "not often", "anno approach": "wiki, concept, image", "verif wiki answer": "yearly(0.6676)", "verif concept answer": "twice day(0.6728)", "verif image answer": "not often(0.6593)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046492.jpg"}, {"question": "what is the hairstyle of the woman with black hair standing next to the mirrored sign called", "gt answer": "bob(1.00)<br/>bun(0.60)", "pred answer": "pony tail", "question_id": 2651585, "best approach": "concept, image", "verif answer": "pony tail", "anno approach": "wiki, concept, image", "verif wiki answer": "bang(0.6986)", "verif concept answer": "bun(0.6543)", "verif image answer": "bun(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265158.jpg"}, {"question": "what kind of pizza is this", "gt answer": "pepperoni(1.00)", "pred answer": "supreme", "question_id": 4552225, "best approach": "", "verif answer": "deep dish", "anno approach": "wiki, concept, image", "verif wiki answer": "deep dish(0.6687)", "verif concept answer": "deep dish(0.6626)", "verif image answer": "deep dish(0.5605)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455222.jpg"}, {"question": "what food served on a bun is associated with watching this game", "gt answer": "hot dog(1.00)", "pred answer": "hotdog", "question_id": 2601165, "best approach": "concept", "verif answer": "hotdog", "anno approach": "wiki, concept, image", "verif wiki answer": "hotdog(0.7161)", "verif concept answer": "hot dog(0.7020)", "verif image answer": "hotdog(0.7172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260116.jpg"}, {"question": "are these people going somewhere or just fishing", "gt answer": "go somewhere(1.00)<br/>fish(0.60)", "pred answer": "shop", "question_id": 3619395, "best approach": "wiki, image", "verif answer": "sail", "anno approach": "wiki, concept, image", "verif wiki answer": "go somewhere(0.7298)", "verif concept answer": "sail(0.6697)", "verif image answer": "go somewhere(0.7263)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361939.jpg"}, {"question": "what input devices are shown here", "gt answer": "mouse and keyboard(1.00)<br/>mouse(0.60)<br/>keyboard(0.60)", "pred answer": "computer", "question_id": 4217945, "best approach": "wiki, concept, image", "verif answer": "mouse", "anno approach": "wiki, concept, image", "verif wiki answer": "mouse(0.7012)", "verif concept answer": "mouse(0.7079)", "verif image answer": "mouse(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421794.jpg"}, {"question": "what reading based crime involving the technology featured above occurs in a vehicle", "gt answer": "text(1.00)", "pred answer": "speed", "question_id": 632095, "best approach": "", "verif answer": "camera", "anno approach": "wiki, concept, image", "verif wiki answer": "number(0.6254)", "verif concept answer": "number(0.5660)", "verif image answer": "camera(0.6476)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063209.jpg"}, {"question": "what picture is on the cup", "gt answer": "pear(1.00)", "pred answer": "paint", "question_id": 1301845, "best approach": "", "verif answer": "flower", "anno approach": "wiki, concept, image", "verif wiki answer": "painted(0.7054)", "verif concept answer": "flower(0.6400)", "verif image answer": "flower(0.6771)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130184.jpg"}, {"question": "what city in the us gets the most rain fall a year", "gt answer": "seattle(1.00)", "pred answer": "washington dc", "question_id": 4349915, "best approach": "", "verif answer": "new york city", "anno approach": "wiki, concept, image", "verif wiki answer": "boston(0.6852)", "verif concept answer": "new york city(0.6399)", "verif image answer": "cupertino(0.6804)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434991.jpg"}, {"question": "what is following the elephant", "gt answer": "baby elephant(1.00)<br/>calf(0.60)", "pred answer": "lion", "question_id": 1989975, "best approach": "wiki, concept, image", "verif answer": "giraffe", "anno approach": "wiki, concept, image", "verif wiki answer": "baby elephant(0.7286)", "verif concept answer": "baby elephant(0.7191)", "verif image answer": "baby elephant(0.7110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198997.jpg"}, {"question": "what type of writing is this called on the wall", "gt answer": "graffiti(1.00)<br/>grafitti(0.60)", "pred answer": "chalk", "question_id": 1835885, "best approach": "wiki, concept", "verif answer": "grafitti", "anno approach": "wiki, concept, image", "verif wiki answer": "grafitti(0.7119)", "verif concept answer": "grafitti(0.5127)", "verif image answer": "mural(0.5187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183588.jpg"}, {"question": "which of these items depicted grows underground", "gt answer": "potato(1.00)", "pred answer": "mushroom", "question_id": 2249295, "best approach": "wiki, concept", "verif answer": "potato", "anno approach": "wiki, concept, image", "verif wiki answer": "potato(0.7257)", "verif concept answer": "potato(0.7202)", "verif image answer": "french fry(0.5343)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224929.jpg"}, {"question": "what brand is this", "gt answer": "audi(1.00)<br/>chrysler(0.60)<br/>fiat(0.60)", "pred answer": "dodge", "question_id": 77405, "best approach": "concept, image", "verif answer": "fiat", "anno approach": "wiki, concept, image", "verif wiki answer": "honda(0.7286)", "verif concept answer": "fiat(0.6921)", "verif image answer": "fiat(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007740.jpg"}, {"question": "what parade is being celebrated in the picture", "gt answer": "christmas(1.00)<br/>mardi gras(0.60)", "pred answer": "4th of july", "question_id": 2698715, "best approach": "", "verif answer": "christmas", "anno approach": "wiki, concept, image", "verif wiki answer": "graduation(0.6499)", "verif concept answer": "graduation(0.7009)", "verif image answer": "anniversary(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269871.jpg"}, {"question": "what is the purpose of the green color of these guy 's jackets", "gt answer": "safety(1.00)<br/>art(0.60)", "pred answer": "visibility", "question_id": 1446465, "best approach": "wiki, concept, image", "verif answer": "safety", "anno approach": "wiki, concept, image", "verif wiki answer": "safety(0.6608)", "verif concept answer": "safety(0.7024)", "verif image answer": "safety(0.7090)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144646.jpg"}, {"question": "in soccer what is the term to stop the ball", "gt answer": "block(1.00)<br/>dead(0.60)", "pred answer": "goal", "question_id": 4222835, "best approach": "wiki, concept, image", "verif answer": "goal", "anno approach": "wiki, concept, image", "verif wiki answer": "block(0.6749)", "verif concept answer": "block(0.5342)", "verif image answer": "block(0.5673)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422283.jpg"}, {"question": "what do these items pull behind them", "gt answer": "car(1.00)<br/>cargo(0.60)", "pred answer": "people", "question_id": 1410085, "best approach": "wiki, concept", "verif answer": "freight", "anno approach": "wiki, concept, image", "verif wiki answer": "cargo(0.6548)", "verif concept answer": "cargo(0.7078)", "verif image answer": "freight(0.5433)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000141008.jpg"}, {"question": "what mlb team uses the same colors as the team shown", "gt answer": "cardinal(1.00)<br/>yankees(0.60)", "pred answer": "red", "question_id": 3424015, "best approach": "wiki, concept", "verif answer": "cardinal", "anno approach": "wiki, concept, image", "verif wiki answer": "cardinal(0.7066)", "verif concept answer": "cardinal(0.7095)", "verif image answer": "indians(0.7021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342401.jpg"}, {"question": "homemade or store bought playdough", "gt answer": "store bought(1.00)", "pred answer": "walmart", "question_id": 4826655, "best approach": "", "verif answer": "very", "anno approach": "wiki, concept, image", "verif wiki answer": "pitch(0.5558)", "verif concept answer": "pitch(0.6318)", "verif image answer": "paint(0.6963)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482665.jpg"}, {"question": "what kind of bread is this", "gt answer": "bagel(1.00)<br/>doughnut(1.00)<br/>sourdough(0.60)", "pred answer": "banana bread", "question_id": 4443375, "best approach": "concept", "verif answer": "sourdough", "anno approach": "wiki, concept, image", "verif wiki answer": "donut(0.6607)", "verif concept answer": "doughnut(0.7008)", "verif image answer": "donut(0.6422)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000444337.jpg"}, {"question": "is this giraffe lost or with his family", "gt answer": "lost(1.00)<br/>family(0.60)", "pred answer": "home", "question_id": 5341075, "best approach": "image", "verif answer": "family", "anno approach": "wiki, concept, image", "verif wiki answer": "family(0.7139)", "verif concept answer": "family(0.7208)", "verif image answer": "lost(0.7096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534107.jpg"}, {"question": "which vehicle could transport more people the one pictured or a car", "gt answer": "car(1.00)", "pred answer": "scooter", "question_id": 775695, "best approach": "concept", "verif answer": "motorcycle", "anno approach": "wiki, concept, image", "verif wiki answer": "vehicle(0.7247)", "verif concept answer": "car(0.6944)", "verif image answer": "vehicle(0.6628)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077569.jpg"}, {"question": "is this a table or step", "gt answer": "table(1.00)", "pred answer": "street", "question_id": 633455, "best approach": "", "verif answer": "bench", "anno approach": "wiki, concept, image", "verif wiki answer": "on table(0.6614)", "verif concept answer": "on table(0.5704)", "verif image answer": "live room(0.5015)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063345.jpg"}, {"question": "what type of bed is in the photo", "gt answer": "canopy(1.00)<br/>king(0.60)", "pred answer": "4 poster", "question_id": 5063275, "best approach": "", "verif answer": "4 poster", "anno approach": "wiki, concept, image", "verif wiki answer": "4 poster(0.7289)", "verif concept answer": "sheet(0.6635)", "verif image answer": "queen(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506327.jpg"}, {"question": "what model of tv is this", "gt answer": "flatscreen(1.00)<br/>flat screen(0.60)<br/>samsung(0.60)", "pred answer": "lg", "question_id": 5529905, "best approach": "wiki, concept, image", "verif answer": "samsung", "anno approach": "wiki, concept, image", "verif wiki answer": "samsung(0.7139)", "verif concept answer": "samsung(0.7103)", "verif image answer": "samsung(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552990.jpg"}, {"question": "what is the brand of the drink", "gt answer": "fresca(1.00)<br/>sprite(0.60)", "pred answer": "coca cola", "question_id": 460245, "best approach": "wiki, concept, image", "verif answer": "coca cola", "anno approach": "wiki, concept, image", "verif wiki answer": "sprite(0.7271)", "verif concept answer": "sprite(0.6871)", "verif image answer": "sprite(0.6977)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046024.jpg"}, {"question": "what kind of pizza is in the photo", "gt answer": "sausage(1.00)", "pred answer": "pepperoni", "question_id": 3130155, "best approach": "", "verif answer": "hotdog", "anno approach": "wiki, concept, image", "verif wiki answer": "hotdog(0.7252)", "verif concept answer": "hotdog(0.7290)", "verif image answer": "meat(0.7055)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313015.jpg"}, {"question": "what time does the clock say", "gt answer": "3:52(1.00)", "pred answer": "1:15", "question_id": 5161245, "best approach": "", "verif answer": "1:15", "anno approach": "wiki, concept, image", "verif wiki answer": "9:25(0.6840)", "verif concept answer": "9:25(0.7058)", "verif image answer": "9:25(0.7296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516124.jpg"}, {"question": "is that a bird if so what kind", "gt answer": "sparrow(1.00)<br/>owl(0.60)", "pred answer": "pigeon", "question_id": 5311795, "best approach": "concept, image", "verif answer": "sparrow", "anno approach": "wiki, concept, image", "verif wiki answer": "owl(0.7077)", "verif concept answer": "sparrow(0.7102)", "verif image answer": "sparrow(0.7034)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531179.jpg"}, {"question": "what are these utilized for", "gt answer": "firefight(1.00)<br/>put out fire(1.00)", "pred answer": "fight fire", "question_id": 1154225, "best approach": "", "verif answer": "fight fire", "anno approach": "wiki, concept, image", "verif wiki answer": "fire(0.7174)", "verif concept answer": "fire(0.6581)", "verif image answer": "fire(0.6635)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115422.jpg"}, {"question": "what are they celebrating", "gt answer": "veteran day(1.00)<br/>motorcycle(0.60)", "pred answer": "gay pride", "question_id": 418905, "best approach": "wiki, concept", "verif answer": "rally", "anno approach": "wiki, concept, image", "verif wiki answer": "veteran day(0.7012)", "verif concept answer": "veteran day(0.6701)", "verif image answer": "motorcycle(0.5763)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041890.jpg"}, {"question": "why are the men bending down", "gt answer": "to catch ball(1.00)<br/>catch(0.60)", "pred answer": "out", "question_id": 4536825, "best approach": "image", "verif answer": "catcher", "anno approach": "wiki, concept, image", "verif wiki answer": "catcher(0.6707)", "verif concept answer": "catcher(0.6353)", "verif image answer": "catch(0.6992)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453682.jpg"}, {"question": "what type of dog is this", "gt answer": "border collie(1.00)", "pred answer": "saint bernard", "question_id": 1331515, "best approach": "wiki, concept, image", "verif answer": "collie", "anno approach": "wiki, concept, image", "verif wiki answer": "border collie(0.7052)", "verif concept answer": "border collie(0.6603)", "verif image answer": "border collie(0.6651)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000133151.jpg"}, {"question": "what breed of dog is in the picture", "gt answer": "collie(1.00)<br/>mutt(0.60)<br/>border collie(0.60)", "pred answer": "beagle", "question_id": 423555, "best approach": "wiki, concept, image", "verif answer": "collie", "anno approach": "wiki, concept, image", "verif wiki answer": "border collie(0.6822)", "verif concept answer": "mutt(0.6758)", "verif image answer": "mutt(0.7223)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042355.jpg"}, {"question": "which side of the stop sign is visible", "gt answer": "back(1.00)", "pred answer": "left", "question_id": 5791765, "best approach": "wiki, concept, image", "verif answer": "front", "anno approach": "wiki, concept, image", "verif wiki answer": "back(0.7287)", "verif concept answer": "back(0.7181)", "verif image answer": "back(0.7200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000579176.jpg"}, {"question": "when was this object first invented", "gt answer": "1950s(1.00)<br/>1940s(0.60)", "pred answer": "1903", "question_id": 3337105, "best approach": "wiki, concept", "verif answer": "1930", "anno approach": "wiki, concept, image", "verif wiki answer": "1940s(0.5481)", "verif concept answer": "1940s(0.5517)", "verif image answer": "1950's(0.5856)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000333710.jpg"}, {"question": "what type of meeting is this", "gt answer": "business(1.00)", "pred answer": "political", "question_id": 4164505, "best approach": "image", "verif answer": "business", "anno approach": "wiki, concept, image", "verif wiki answer": "professional(0.7229)", "verif concept answer": "casual(0.7090)", "verif image answer": "business(0.7156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416450.jpg"}, {"question": "what technique was used to cut these carrots", "gt answer": "julienne(1.00)", "pred answer": "slice", "question_id": 791465, "best approach": "wiki, concept, image", "verif answer": "slice", "anno approach": "wiki, concept, image", "verif wiki answer": "julienne(0.7131)", "verif concept answer": "julienne(0.7290)", "verif image answer": "julienne(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079146.jpg"}, {"question": "what can this object be used for", "gt answer": "shop(1.00)", "pred answer": "bike", "question_id": 3359865, "best approach": "", "verif answer": "shop", "anno approach": "wiki, concept, image", "verif wiki answer": "relax(0.6777)", "verif concept answer": "relax(0.6905)", "verif image answer": "sell(0.6378)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335986.jpg"}, {"question": "what object would you use to wash your hands", "gt answer": "sink(1.00)", "pred answer": "vanity", "question_id": 2179585, "best approach": "image", "verif answer": "sink", "anno approach": "wiki, concept, image", "verif wiki answer": "towel(0.7264)", "verif concept answer": "towel(0.7235)", "verif image answer": "sink(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000217958.jpg"}, {"question": "what material are these toys produced out of", "gt answer": "paper(1.00)<br/>nylon(1.00)<br/>tissue(0.60)", "pred answer": "cotton", "question_id": 2161195, "best approach": "", "verif answer": "nylon", "anno approach": "wiki, concept, image", "verif wiki answer": "cloth(0.7153)", "verif concept answer": "ceramic(0.6884)", "verif image answer": "ceramic(0.7065)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216119.jpg"}, {"question": "what item crossing the ceiling has the same name as an instrument", "gt answer": "pipe(1.00)<br/>cello(0.60)", "pred answer": "wire", "question_id": 3353665, "best approach": "", "verif answer": "hose", "anno approach": "wiki, concept, image", "verif wiki answer": "hose(0.6704)", "verif concept answer": "hose(0.6205)", "verif image answer": "half pipe(0.6931)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335366.jpg"}, {"question": "what is the colloquial name for the breed of dog in this picture", "gt answer": "basset hound(1.00)<br/>hound(0.60)<br/>hotdog(0.60)", "pred answer": "beagle", "question_id": 3986325, "best approach": "", "verif answer": "beagle", "anno approach": "wiki, concept, image", "verif wiki answer": "beagle(0.7245)", "verif concept answer": "beagle(0.7134)", "verif image answer": "beagle(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000398632.jpg"}, {"question": "what kind of alcoholic beverage is being advertised on the trailer", "gt answer": "beer(1.00)", "pred answer": "wine", "question_id": 1778325, "best approach": "", "verif answer": "wine", "anno approach": "wiki, concept, image", "verif wiki answer": "vodka(0.7219)", "verif concept answer": "vodka(0.6875)", "verif image answer": "vodka(0.7150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177832.jpg"}, {"question": "which method of transport shown here is statistically the safest method of travel", "gt answer": "car(0.60)<br/>air(0.60)<br/>fly(0.60)<br/>airplane(1.00)", "pred answer": "bus", "question_id": 3021415, "best approach": "wiki, concept, image", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "fly(0.6084)", "verif concept answer": "fly(0.5296)", "verif image answer": "air(0.5624)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302141.jpg"}, {"question": "what are the small pink squares of paper called", "gt answer": "post it note(1.00)", "pred answer": "post it", "question_id": 1185505, "best approach": "", "verif answer": "post it note", "anno approach": "wiki, concept, image", "verif wiki answer": "stratus(0.7135)", "verif concept answer": "stratus(0.7261)", "verif image answer": "stratus(0.7046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118550.jpg"}, {"question": "what are these large white bears called", "gt answer": "polar bear(1.00)<br/>polar(0.60)", "pred answer": "doberman", "question_id": 3287435, "best approach": "wiki, concept, image", "verif answer": "polar", "anno approach": "wiki, concept, image", "verif wiki answer": "polar(0.7034)", "verif concept answer": "polar(0.7168)", "verif image answer": "polar(0.7141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328743.jpg"}, {"question": "who is credited with inventing the game being played here", "gt answer": "abner doubleday(1.00)<br/>women(0.60)<br/>baseball(0.60)", "pred answer": "barry bond", "question_id": 3091445, "best approach": "wiki", "verif answer": "abner doubleday", "anno approach": "wiki, concept, image", "verif wiki answer": "abner doubleday(0.6962)", "verif concept answer": "little league(0.6995)", "verif image answer": "little league(0.6916)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000309144.jpg"}, {"question": "what is wrong with this picture", "gt answer": "dog drive(1.00)", "pred answer": "black and white", "question_id": 4607025, "best approach": "concept, image", "verif answer": "color", "anno approach": "wiki, concept, image", "verif wiki answer": "color(0.7120)", "verif concept answer": "dog drive(0.6898)", "verif image answer": "dog drive(0.7194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460702.jpg"}, {"question": "what nationality are these art pieces", "gt answer": "american(1.00)<br/>japan(0.60)<br/>egyptian(0.60)", "pred answer": "indian", "question_id": 859605, "best approach": "", "verif answer": "indian", "anno approach": "wiki, concept, image", "verif wiki answer": "indian(0.7104)", "verif concept answer": "indian(0.7025)", "verif image answer": "indian(0.7289)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085960.jpg"}, {"question": "generally how clear is the water in these circumstances", "gt answer": "murky(1.00)", "pred answer": "not at all", "question_id": 1034045, "best approach": "", "verif answer": "not at all", "anno approach": "wiki, concept, image", "verif wiki answer": "not at all(0.7261)", "verif concept answer": "not at all(0.6342)", "verif image answer": "wide angle(0.7203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103404.jpg"}, {"question": "what kind of bear is this", "gt answer": "stuffed(1.00)<br/>bear(0.60)", "pred answer": "teddy", "question_id": 2227605, "best approach": "image", "verif answer": "stuffed", "anno approach": "wiki, concept, image", "verif wiki answer": "tiger(0.6146)", "verif concept answer": "bear(0.5335)", "verif image answer": "stuffed(0.5812)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222760.jpg"}, {"question": "what is found inside these doors", "gt answer": "toilet(1.00)", "pred answer": "food", "question_id": 3003925, "best approach": "wiki, concept, image", "verif answer": "toilet", "anno approach": "wiki, concept, image", "verif wiki answer": "toilet(0.7197)", "verif concept answer": "toilet(0.6956)", "verif image answer": "toilet(0.7020)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300392.jpg"}, {"question": "what utensil is on the plate", "gt answer": "spoon(1.00)", "pred answer": "fork", "question_id": 5146665, "best approach": "image", "verif answer": "fork", "anno approach": "wiki, concept, image", "verif wiki answer": "fork(0.7279)", "verif concept answer": "fork(0.7086)", "verif image answer": "spoon(0.6930)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514666.jpg"}, {"question": "what model is the model of the computer being shown", "gt answer": "desktop(1.00)<br/>dell(0.60)<br/>ibm(0.60)", "pred answer": "macbook", "question_id": 3655125, "best approach": "wiki, concept", "verif answer": "hp", "anno approach": "wiki, concept, image", "verif wiki answer": "desktop(0.6388)", "verif concept answer": "desktop(0.7064)", "verif image answer": "ibm(0.6889)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365512.jpg"}, {"question": "what is in the truck", "gt answer": "supply(1.00)<br/>water(1.00)<br/>box(0.60)", "pred answer": "food", "question_id": 3842635, "best approach": "wiki, image", "verif answer": "trailer", "anno approach": "wiki, concept, image", "verif wiki answer": "supply(0.7264)", "verif concept answer": "trailer(0.7043)", "verif image answer": "supply(0.7167)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384263.jpg"}, {"question": "horns grow on what gender of cow bull", "gt answer": "male(1.00)", "pred answer": "female", "question_id": 5545595, "best approach": "", "verif answer": "female", "anno approach": "wiki, concept, image", "verif wiki answer": "female(0.7285)", "verif concept answer": "female(0.7284)", "verif image answer": "female(0.7082)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554559.jpg"}, {"question": "where can this food be found", "gt answer": "circle k(1.00)<br/>cafe(0.60)<br/>gas station(0.60)", "pred answer": "school", "question_id": 4628035, "best approach": "concept, image", "verif answer": "bakery", "anno approach": "wiki, concept, image", "verif wiki answer": "bakery(0.7170)", "verif concept answer": "circle k(0.6348)", "verif image answer": "circle k(0.7175)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000462803.jpg"}, {"question": "what kind of get together is this", "gt answer": "tea party(1.00)<br/>dinner(0.60)<br/>birthday party(0.60)<br/>family(0.60)", "pred answer": "cupcake", "question_id": 1538245, "best approach": "wiki, concept", "verif answer": "family", "anno approach": "wiki, concept, image", "verif wiki answer": "family(0.7195)", "verif concept answer": "dinner(0.7165)", "verif image answer": "lunch(0.6808)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153824.jpg"}, {"question": "how much would this stamp be worth if it was used to mail a domestic envelop in the usa", "gt answer": ".49(1.00)", "pred answer": "ticket", "question_id": 5211125, "best approach": "", "verif answer": "1", "anno approach": "wiki, concept, image", "verif wiki answer": "$40(0.6587)", "verif concept answer": "$40(0.5817)", "verif image answer": "$40(0.6570)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521112.jpg"}, {"question": "what do you think is the reason for the decoration", "gt answer": "baby shower(1.00)<br/>birthday(0.60)<br/>celebration(0.60)", "pred answer": "paint", "question_id": 3466725, "best approach": "concept", "verif answer": "celebration", "anno approach": "wiki, concept, image", "verif wiki answer": "retirement(0.6307)", "verif concept answer": "baby shower(0.6090)", "verif image answer": "st patrick's day(0.5273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346672.jpg"}, {"question": "what kind of pattern is the chair in this photo", "gt answer": "leopard(1.00)", "pred answer": "stripe", "question_id": 2198615, "best approach": "", "verif answer": "stripe", "anno approach": "wiki, concept, image", "verif wiki answer": "stripe(0.7097)", "verif concept answer": "stripe(0.7078)", "verif image answer": "stripe(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219861.jpg"}, {"question": "what is this man doing with this plane", "gt answer": "signal(1.00)<br/>direct(0.60)", "pred answer": "relax", "question_id": 1900005, "best approach": "", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "stop light(0.6624)", "verif concept answer": "stop light(0.6880)", "verif image answer": "stop light(0.6432)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190000.jpg"}, {"question": "what 's coming out the back of this vehicle", "gt answer": "exhaust(1.00)<br/>smoke(0.60)", "pred answer": "pesticide", "question_id": 4619405, "best approach": "", "verif answer": "contrail", "anno approach": "wiki, concept, image", "verif wiki answer": "jet(0.6878)", "verif concept answer": "jet(0.7029)", "verif image answer": "jet(0.7004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461940.jpg"}, {"question": "what kitchen appliance is she reaching into", "gt answer": "oven(1.00)", "pred answer": "refrigerator", "question_id": 2229175, "best approach": "", "verif answer": "stove", "anno approach": "wiki, concept, image", "verif wiki answer": "fryer(0.7304)", "verif concept answer": "fryer(0.6836)", "verif image answer": "in oven(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222917.jpg"}, {"question": "what kind of lighting tool is the man holding", "gt answer": "reflector(1.00)<br/>mirror(0.60)<br/>flash(0.60)", "pred answer": "lamp", "question_id": 3296405, "best approach": "concept", "verif answer": "flash", "anno approach": "wiki, concept, image", "verif wiki answer": "helmet(0.5396)", "verif concept answer": "reflector(0.5302)", "verif image answer": "take picture(0.7125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329640.jpg"}, {"question": "what kind of train is this", "gt answer": "locomotive(1.00)<br/>passenger(0.60)<br/>steam(0.60)", "pred answer": "steam engine", "question_id": 3059195, "best approach": "wiki, concept", "verif answer": "steam engine", "anno approach": "wiki, concept, image", "verif wiki answer": "locomotive(0.7283)", "verif concept answer": "locomotive(0.7155)", "verif image answer": "steam(0.7123)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305919.jpg"}, {"question": "what is the name of the man who built the arc in the bible due to this natural catastrophe", "gt answer": "noah(1.00)", "pred answer": "romans", "question_id": 4424315, "best approach": "", "verif answer": "pacific", "anno approach": "wiki, concept, image", "verif wiki answer": "pacific(0.6346)", "verif concept answer": "pacific(0.6025)", "verif image answer": "pacific(0.5767)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442431.jpg"}, {"question": "what type of swing is being used", "gt answer": "bunt(1.00)<br/>homerun(0.60)", "pred answer": "bat", "question_id": 5387475, "best approach": "", "verif answer": "hit", "anno approach": "wiki, concept, image", "verif wiki answer": "foul(0.6963)", "verif concept answer": "hit(0.7151)", "verif image answer": "home run(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538747.jpg"}, {"question": "what is supposed to go here", "gt answer": "dish(1.00)<br/>laundry(0.60)<br/>cloth(0.60)", "pred answer": "bed", "question_id": 4267785, "best approach": "image", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "color(0.5356)", "verif concept answer": "color(0.5996)", "verif image answer": "cloth(0.6699)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426778.jpg"}, {"question": "what is this type of clock called", "gt answer": "analog(1.00)", "pred answer": "clock", "question_id": 3586075, "best approach": "", "verif answer": "analog", "anno approach": "wiki, concept, image", "verif wiki answer": "grandfather clock(0.7160)", "verif concept answer": "roman numeral(0.6872)", "verif image answer": "roman(0.7103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358607.jpg"}, {"question": "what is it called when the water arches like this", "gt answer": "wave(1.00)", "pred answer": "surf", "question_id": 4008296, "best approach": "", "verif answer": "wave", "anno approach": "wiki, concept, image", "verif wiki answer": "shark(0.6918)", "verif concept answer": "shark(0.6857)", "verif image answer": "shark(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400829.jpg"}, {"question": "which department in a store are these children in", "gt answer": "children(0.60)<br/>mall(0.60)<br/>toy(1.00)", "pred answer": "teddy bear", "question_id": 5260985, "best approach": "wiki", "verif answer": "children", "anno approach": "wiki, concept, image", "verif wiki answer": "children(0.6545)", "verif concept answer": "furniture store(0.6473)", "verif image answer": "walmart(0.7129)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526098.jpg"}, {"question": "is this woman travelling alone or with friends and family", "gt answer": "alone(1.00)<br/>family(0.60)", "pred answer": "friend", "question_id": 3883415, "best approach": "wiki, concept", "verif answer": "together", "anno approach": "wiki, concept, image", "verif wiki answer": "family(0.7305)", "verif concept answer": "family(0.7228)", "verif image answer": "together(0.7210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388341.jpg"}, {"question": "how many world cups has this country won", "gt answer": "0(1.00)<br/>4(0.60)<br/>3(0.60)<br/>5(0.60)", "pred answer": "thousand", "question_id": 2591985, "best approach": "concept", "verif answer": "0", "anno approach": "wiki, concept, image", "verif wiki answer": "2(0.6899)", "verif concept answer": "0(0.6940)", "verif image answer": "2(0.7273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259198.jpg"}, {"question": "what position does he play", "gt answer": "batter(1.00)<br/>hitter(0.60)", "pred answer": "catcher", "question_id": 3328125, "best approach": "", "verif answer": "batter", "anno approach": "wiki, concept, image", "verif wiki answer": "outfield(0.6797)", "verif concept answer": "outfield(0.6385)", "verif image answer": "outfield(0.5094)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332812.jpg"}, {"question": "what kind of institution are these people visiting", "gt answer": "zoo(1.00)", "pred answer": "school", "question_id": 1429535, "best approach": "image", "verif answer": "zoo", "anno approach": "wiki, concept, image", "verif wiki answer": "safety(0.6858)", "verif concept answer": "safety(0.7022)", "verif image answer": "zoo(0.7264)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142953.jpg"}, {"question": "what device are the two men in the photo using", "gt answer": "tablet(1.00)", "pred answer": "cell phone", "question_id": 1689275, "best approach": "", "verif answer": "cell phone", "anno approach": "wiki, concept, image", "verif wiki answer": "cell phone(0.7239)", "verif concept answer": "cell phone(0.6503)", "verif image answer": "cell phone(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168927.jpg"}, {"question": "where can you find this animal naturally occurring", "gt answer": "antarctica(1.00)<br/>north pole(0.60)", "pred answer": "arctic", "question_id": 4691815, "best approach": "image", "verif answer": "north pole", "anno approach": "wiki, concept, image", "verif wiki answer": "north pole(0.7264)", "verif concept answer": "north pole(0.7206)", "verif image answer": "antarctica(0.6917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469181.jpg"}, {"question": "what movie does this reference", "gt answer": "forrest gump(1.00)<br/>0(0.60)", "pred answer": "forest gump", "question_id": 4268295, "best approach": "wiki, concept", "verif answer": "forest gump", "anno approach": "wiki, concept, image", "verif wiki answer": "forrest gump(0.7287)", "verif concept answer": "forrest gump(0.7204)", "verif image answer": "star war(0.7290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426829.jpg"}, {"question": "what is the batter 's dominant hand", "gt answer": "left(1.00)<br/>right(0.60)", "pred answer": "baseball", "question_id": 5523045, "best approach": "image", "verif answer": "left", "anno approach": "wiki, concept, image", "verif wiki answer": "batter(0.6638)", "verif concept answer": "batter(0.7101)", "verif image answer": "left(0.7105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552304.jpg"}, {"question": "what is the service range of a typical modern jet liner", "gt answer": "3000 miles(1.00)", "pred answer": "very", "question_id": 4881205, "best approach": "image", "verif answer": "4300", "anno approach": "wiki, concept, image", "verif wiki answer": "air macau(0.6371)", "verif concept answer": "air macau(0.5861)", "verif image answer": "3000 miles(0.6724)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488120.jpg"}, {"question": "what is the purpose of the device the man is holding in his hand", "gt answer": "communication(1.00)<br/>cell phone(0.60)<br/>pager(0.60)", "pred answer": "text", "question_id": 2976325, "best approach": "", "verif answer": "communication", "anno approach": "wiki, concept, image", "verif wiki answer": "cellular(0.7173)", "verif concept answer": "cellular(0.7024)", "verif image answer": "cellular(0.6868)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297632.jpg"}, {"question": "when was this game sold for the first time", "gt answer": "2007(1.00)<br/>2010(0.60)<br/>2008(0.60)", "pred answer": "1990's", "question_id": 1251155, "best approach": "", "verif answer": "2008", "anno approach": "wiki, concept, image", "verif wiki answer": "1995(0.7297)", "verif concept answer": "1995(0.7011)", "verif image answer": "2004(0.7246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125115.jpg"}, {"question": "how many of this food item is sold every year", "gt answer": "20 billion(1.00)<br/>million(0.60)", "pred answer": "3", "question_id": 990085, "best approach": "wiki, concept, image", "verif answer": "thousand", "anno approach": "wiki, concept, image", "verif wiki answer": "million(0.6163)", "verif concept answer": "million(0.6720)", "verif image answer": "million(0.5960)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099008.jpg"}, {"question": "what type of designer would design this environment", "gt answer": "interior(1.00)<br/>traditional(0.60)", "pred answer": "abstract", "question_id": 5713665, "best approach": "concept", "verif answer": "television", "anno approach": "wiki, concept, image", "verif wiki answer": "traditional(0.7246)", "verif concept answer": "interior(0.6679)", "verif image answer": "television(0.6984)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571366.jpg"}, {"question": "what are the people doing", "gt answer": "talk(1.00)", "pred answer": "shake hand", "question_id": 3094545, "best approach": "", "verif answer": "shake hand", "anno approach": "wiki, concept, image", "verif wiki answer": "shake hand(0.7294)", "verif concept answer": "shake hand(0.7285)", "verif image answer": "shake hand(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000309454.jpg"}, {"question": "how far can that animal travel", "gt answer": "mile(1.00)<br/>100 miles(0.60)", "pred answer": "5 feet", "question_id": 842305, "best approach": "", "verif answer": "5 miles", "anno approach": "wiki, concept, image", "verif wiki answer": "5 miles(0.6862)", "verif concept answer": "2 hours(0.5750)", "verif image answer": "2 hours(0.6651)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084230.jpg"}, {"question": "what is another ingredient someone might add to this", "gt answer": "cheese(1.00)<br/>bacon(0.60)<br/>meat(0.60)", "pred answer": "sugar", "question_id": 2888365, "best approach": "", "verif answer": "tomato", "anno approach": "wiki, concept, image", "verif wiki answer": "steak(0.6887)", "verif concept answer": "tomato(0.7214)", "verif image answer": "tomato(0.7079)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288836.jpg"}, {"question": "what kind of service do you think this is an ad for", "gt answer": "fly(1.00)<br/>jet(0.60)", "pred answer": "air", "question_id": 623515, "best approach": "image", "verif answer": "airplane", "anno approach": "wiki, concept, image", "verif wiki answer": "airplane(0.6088)", "verif concept answer": "airplane(0.6641)", "verif image answer": "jet(0.6224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000062351.jpg"}, {"question": "what activity is this", "gt answer": "swim(1.00)<br/>surf(1.00)", "pred answer": "perch", "question_id": 1063875, "best approach": "concept, image", "verif answer": "swim", "anno approach": "wiki, concept, image", "verif wiki answer": "float(0.6863)", "verif concept answer": "surf(0.6977)", "verif image answer": "surf(0.6664)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106387.jpg"}, {"question": "what type of jet is this", "gt answer": "fighter jet(1.00)<br/>fighter(0.60)", "pred answer": "jet", "question_id": 4970335, "best approach": "wiki, concept, image", "verif answer": "jet", "anno approach": "wiki, concept, image", "verif wiki answer": "fighter jet(0.7273)", "verif concept answer": "fighter jet(0.7129)", "verif image answer": "fighter jet(0.6823)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497033.jpg"}, {"question": "what is the green round type vegetable called on this plate", "gt answer": "pea(1.00)", "pred answer": "zucchini", "question_id": 3934885, "best approach": "", "verif answer": "broccoli", "anno approach": "wiki, concept, image", "verif wiki answer": "broccoli(0.7271)", "verif concept answer": "broccoli(0.7297)", "verif image answer": "pickle(0.7056)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393488.jpg"}, {"question": "what is the official name for this breakfast item", "gt answer": "bacon(1.00)<br/>croissant(0.60)", "pred answer": "breakfast", "question_id": 4012885, "best approach": "wiki", "verif answer": "breakfast", "anno approach": "wiki, concept, image", "verif wiki answer": "bacon(0.7176)", "verif concept answer": "croissant(0.5972)", "verif image answer": "breakfast(0.7016)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401288.jpg"}, {"question": "", "gt answer": "account(0.60)", "pred answer": "office", "question_id": 1019525, "best approach": "", "verif answer": "cubicle", "anno approach": "wiki, concept, image", "verif wiki answer": "studio(0.6960)", "verif concept answer": "studio(0.7076)", "verif image answer": "studio(0.6948)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000101952.jpg"}, {"question": "is that cat real or photo shopped and if it is real is it safe", "gt answer": "photoshopped(1.00)<br/>photoshop(0.60)", "pred answer": "manmade", "question_id": 2166655, "best approach": "", "verif answer": "real", "anno approach": "wiki, concept, image", "verif wiki answer": "real(0.5202)", "verif concept answer": "real(0.5075)", "verif image answer": "real(0.5011)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216665.jpg"}, {"question": "who controls this vehicle", "gt answer": "driver(1.00)<br/>bus driver(1.00)", "pred answer": "man", "question_id": 3650305, "best approach": "wiki, concept, image", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "driver(0.7207)", "verif concept answer": "driver(0.7070)", "verif image answer": "driver(0.7244)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365030.jpg"}, {"question": "which animal shown here is associated with delivering babies", "gt answer": "stork(1.00)<br/>swan(0.60)", "pred answer": "duck", "question_id": 3616435, "best approach": "wiki, image", "verif answer": "duck", "anno approach": "wiki, concept, image", "verif wiki answer": "swan(0.7256)", "verif concept answer": "crane(0.7212)", "verif image answer": "swan(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361643.jpg"}, {"question": "what surface is the plane on", "gt answer": "tarmac(1.00)<br/>pavement(0.60)<br/>runway(0.60)", "pred answer": "asphalt", "question_id": 4994475, "best approach": "concept, image", "verif answer": "runway", "anno approach": "wiki, concept, image", "verif wiki answer": "concrete(0.6335)", "verif concept answer": "runway(0.6214)", "verif image answer": "runway(0.6849)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499447.jpg"}, {"question": "what is the person with pads doing", "gt answer": "catch(1.00)<br/>catcher(0.60)", "pred answer": "swing", "question_id": 3976055, "best approach": "wiki, concept", "verif answer": "catcher", "anno approach": "wiki, concept, image", "verif wiki answer": "catch(0.7219)", "verif concept answer": "catch(0.7262)", "verif image answer": "safety(0.7203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397605.jpg"}, {"question": "what health issues do these veggies help prevent", "gt answer": "cancer(1.00)", "pred answer": "vitamin", "question_id": 1035105, "best approach": "wiki, image", "verif answer": "vitamin", "anno approach": "wiki, concept, image", "verif wiki answer": "cancer(0.7083)", "verif concept answer": "scurvy(0.6668)", "verif image answer": "cancer(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103510.jpg"}, {"question": "what kind of dog is in the photo", "gt answer": "greyhound(1.00)", "pred answer": "beagle", "question_id": 263215, "best approach": "", "verif answer": "greyhound", "anno approach": "wiki, concept, image", "verif wiki answer": "left(0.5932)", "verif concept answer": "left(0.5866)", "verif image answer": "left(0.6612)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000026321.jpg"}, {"question": "what activity are the people taking part in", "gt answer": "horse race(1.00)<br/>chariot race(1.00)", "pred answer": "race", "question_id": 1513395, "best approach": "concept, image", "verif answer": "race", "anno approach": "wiki, concept, image", "verif wiki answer": "horse show(0.6905)", "verif concept answer": "chariot race(0.5883)", "verif image answer": "horse race(0.6792)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151339.jpg"}, {"question": "what setting was used to take this picture", "gt answer": "blurry(1.00)<br/>instagram(0.60)", "pred answer": "park", "question_id": 5153005, "best approach": "", "verif answer": "outdoor", "anno approach": "wiki, concept, image", "verif wiki answer": "outdoor(0.5653)", "verif concept answer": "outdoor(0.6919)", "verif image answer": "outdoor(0.5145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515300.jpg"}, {"question": "what is it called if you rode this horse as it 's shown", "gt answer": "bareback(1.00)", "pred answer": "kentucky derby", "question_id": 3694995, "best approach": "", "verif answer": "saddle", "anno approach": "wiki, concept, image", "verif wiki answer": "saddle(0.5596)", "verif concept answer": "saddle(0.5254)", "verif image answer": "vest(0.5007)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369499.jpg"}, {"question": "is this an organized political event or a sporting event", "gt answer": "sport event(1.00)", "pred answer": "actual", "question_id": 67805, "best approach": "wiki", "verif answer": "sale", "anno approach": "wiki, concept, image", "verif wiki answer": "sport event(0.7187)", "verif concept answer": "festival(0.7248)", "verif image answer": "sale(0.5786)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006780.jpg"}, {"question": "what was the name of the inventor that created the car company shown in this photo", "gt answer": "karl benz(1.00)", "pred answer": "wright brother", "question_id": 2467975, "best approach": "", "verif answer": "schwinn", "anno approach": "wiki, concept, image", "verif wiki answer": "schwinn(0.7218)", "verif concept answer": "schwinn(0.6860)", "verif image answer": "general electric(0.7147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246797.jpg"}, {"question": "what kind of instruments are they playing", "gt answer": "tuba(1.00)<br/>brass(1.00)", "pred answer": "rock", "question_id": 5715755, "best approach": "image", "verif answer": "wicker", "anno approach": "wiki, concept, image", "verif wiki answer": "metal(0.5911)", "verif concept answer": "4(0.5302)", "verif image answer": "tuba(0.5287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571575.jpg"}, {"question": "which company owns this plane", "gt answer": "fedex(1.00)", "pred answer": "united", "question_id": 2938625, "best approach": "wiki, concept, image", "verif answer": "american airline", "anno approach": "wiki, concept, image", "verif wiki answer": "fedex(0.6863)", "verif concept answer": "fedex(0.6821)", "verif image answer": "fedex(0.5219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000293862.jpg"}, {"question": "what other type of undergarment was replaced by the bra", "gt answer": "corset(1.00)", "pred answer": "scarf", "question_id": 3160915, "best approach": "wiki, concept, image", "verif answer": "corset", "anno approach": "wiki, concept, image", "verif wiki answer": "corset(0.5009)", "verif concept answer": "corset(0.5437)", "verif image answer": "corset(0.5049)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316091.jpg"}, {"question": "how cold is that water", "gt answer": "68 degrees(1.00)<br/>80 degrees(0.60)", "pred answer": "cold", "question_id": 5247185, "best approach": "wiki, concept, image", "verif answer": "freeze", "anno approach": "wiki, concept, image", "verif wiki answer": "68 degrees(0.6882)", "verif concept answer": "68 degrees(0.7198)", "verif image answer": "68 degrees(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000524718.jpg"}, {"question": "what is this person looking at", "gt answer": "mirror(1.00)<br/>toothpaste(0.60)", "pred answer": "shower", "question_id": 3889475, "best approach": "image", "verif answer": "bathroom", "anno approach": "wiki, concept, image", "verif wiki answer": "reflector(0.6756)", "verif concept answer": "bathroom(0.7119)", "verif image answer": "mirror(0.7017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388947.jpg"}, {"question": "what juice is made from these fruits", "gt answer": "grapefruit(1.00)<br/>juice(0.60)<br/>orange(0.60)", "pred answer": "lemonade", "question_id": 3113265, "best approach": "image", "verif answer": "juice", "anno approach": "wiki, concept, image", "verif wiki answer": "orange juice(0.6947)", "verif concept answer": "orange juice(0.6881)", "verif image answer": "grapefruit(0.7147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311326.jpg"}, {"question": "what do these umbrellas appear to be doing", "gt answer": "float(1.00)<br/>fly(0.60)", "pred answer": "shade", "question_id": 1443575, "best approach": "concept, image", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "light(0.6167)", "verif concept answer": "fly(0.5348)", "verif image answer": "fly(0.7144)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144357.jpg"}, {"question": "why does the boy in the white play baseball", "gt answer": "for fun(1.00)<br/>fun(1.00)", "pred answer": "uniform", "question_id": 1638285, "best approach": "wiki, concept, image", "verif answer": "for fun", "anno approach": "wiki, concept, image", "verif wiki answer": "fun(0.7096)", "verif concept answer": "for fun(0.6661)", "verif image answer": "for fun(0.6686)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163828.jpg"}, {"question": "name the ingredients used to make this dish in this picture", "gt answer": "flour(1.00)<br/>sugar(0.60)", "pred answer": "frost", "question_id": 3664175, "best approach": "", "verif answer": "sugar", "anno approach": "wiki, concept, image", "verif wiki answer": "chocolate(0.6282)", "verif concept answer": "chocolate(0.6648)", "verif image answer": "corn(0.6425)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000366417.jpg"}, {"question": "behind the mirrors shown here there is likely what kind of cabinet", "gt answer": "medicine(1.00)<br/>reflection(0.60)", "pred answer": "wooden", "question_id": 5754835, "best approach": "concept", "verif answer": "gothic", "anno approach": "wiki, concept, image", "verif wiki answer": "gothic(0.6953)", "verif concept answer": "reflection(0.5718)", "verif image answer": "gothic(0.7073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575483.jpg"}, {"question": "how much is the wii nun chuck", "gt answer": "$40(1.00)<br/>15(0.60)<br/>1(0.60)", "pred answer": "50", "question_id": 1951955, "best approach": "concept", "verif answer": "50", "anno approach": "wiki, concept, image", "verif wiki answer": "200(0.6815)", "verif concept answer": "$40(0.6692)", "verif image answer": "200(0.6556)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195195.jpg"}, {"question": "what do people eat for breakfast that 's made in a pan", "gt answer": "pancake(1.00)", "pred answer": "bread", "question_id": 4413825, "best approach": "wiki, concept", "verif answer": "pancake", "anno approach": "wiki, concept, image", "verif wiki answer": "pancake(0.7293)", "verif concept answer": "pancake(0.7230)", "verif image answer": "cereal(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441382.jpg"}, {"question": "what country is this street located in", "gt answer": "poland(1.00)<br/>russia(0.60)<br/>america(0.60)<br/>rome(0.60)", "pred answer": "england", "question_id": 3405235, "best approach": "wiki, concept", "verif answer": "europe", "anno approach": "wiki, concept, image", "verif wiki answer": "russia(0.7039)", "verif concept answer": "russia(0.6858)", "verif image answer": "europe(0.5925)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340523.jpg"}, {"question": "why do people typically visit this location", "gt answer": "vacation(1.00)<br/>walk(0.60)", "pred answer": "sunny", "question_id": 4052885, "best approach": "wiki, image", "verif answer": "shop", "anno approach": "wiki, concept, image", "verif wiki answer": "walk(0.5953)", "verif concept answer": "pray(0.5368)", "verif image answer": "walk(0.7277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405288.jpg"}, {"question": "what type of dog is this", "gt answer": "chihuahua(1.00)<br/>dachshund(0.60)<br/>mutt(0.60)", "pred answer": "german shepherd", "question_id": 3850665, "best approach": "image", "verif answer": "mutt", "anno approach": "wiki, concept, image", "verif wiki answer": "dachshund(0.7196)", "verif concept answer": "dachshund(0.6745)", "verif image answer": "chihuahua(0.6555)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385066.jpg"}, {"question": "why would we suspect this reader has good eyesight", "gt answer": "no glass(1.00)", "pred answer": "reflection", "question_id": 3799805, "best approach": "wiki", "verif answer": "old", "anno approach": "wiki, concept, image", "verif wiki answer": "no glass(0.7009)", "verif concept answer": "old(0.7063)", "verif image answer": "old(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379980.jpg"}, {"question": "what is faster between this animal and the bicycle", "gt answer": "bicycle(1.00)<br/>bike(0.60)", "pred answer": "bark", "question_id": 4978155, "best approach": "concept, image", "verif answer": "regular", "anno approach": "wiki, concept, image", "verif wiki answer": "regular(0.7228)", "verif concept answer": "bicycle(0.5818)", "verif image answer": "bicycle(0.6828)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497815.jpg"}, {"question": "why are cakes usually eaten at party 's", "gt answer": "celebration(1.00)", "pred answer": "birthday", "question_id": 4213155, "best approach": "", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "family reunion(0.7189)", "verif concept answer": "birthday(0.6889)", "verif image answer": "birthday(0.7005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421315.jpg"}, {"question": "what famous film about an amputee athlete features the sport in the above picture", "gt answer": "soul surfer(1.00)", "pred answer": "shawn white", "question_id": 817155, "best approach": "wiki, concept, image", "verif answer": "black and white", "anno approach": "wiki, concept, image", "verif wiki answer": "soul surfer(0.6908)", "verif concept answer": "soul surfer(0.5346)", "verif image answer": "soul surfer(0.5105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081715.jpg"}, {"question": "what company manufactures the device the woman is holding", "gt answer": "nintendo(1.00)", "pred answer": "sony", "question_id": 2222625, "best approach": "", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "atari(0.7194)", "verif concept answer": "wii(0.6895)", "verif image answer": "wii(0.7195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000222262.jpg"}, {"question": "what is the process of making this pattern on grass called", "gt answer": "mow(1.00)<br/>stripe(0.60)<br/>scratch(0.60)", "pred answer": "throw", "question_id": 3493585, "best approach": "wiki, concept, image", "verif answer": "stripe", "anno approach": "wiki, concept, image", "verif wiki answer": "stripe(0.7146)", "verif concept answer": "stripe(0.7226)", "verif image answer": "stripe(0.7154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000349358.jpg"}, {"question": "what is the battery life of that laptop", "gt answer": "8 hours(1.00)<br/>6 hours(0.60)<br/>2 hours(0.60)", "pred answer": "5 years", "question_id": 1911365, "best approach": "concept", "verif answer": "10 hours", "anno approach": "wiki, concept, image", "verif wiki answer": "10 hours(0.7119)", "verif concept answer": "8 hours(0.6647)", "verif image answer": "6 hours(0.7218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191136.jpg"}, {"question": "what is the green stick type vegetables called on this plate", "gt answer": "asparagus(1.00)<br/>fall(0.60)", "pred answer": "zucchini", "question_id": 5313745, "best approach": "", "verif answer": "broccoli", "anno approach": "wiki, concept, image", "verif wiki answer": "broccoli(0.7300)", "verif concept answer": "broccoli(0.7306)", "verif image answer": "broccoli(0.6545)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531374.jpg"}, {"question": "how many neck vertebrae does this animal have", "gt answer": "7(1.00)<br/>16(0.60)<br/>3(0.60)<br/>many(0.60)", "pred answer": "32", "question_id": 50115, "best approach": "wiki, concept", "verif answer": "16", "anno approach": "wiki, concept, image", "verif wiki answer": "16(0.6502)", "verif concept answer": "3(0.6739)", "verif image answer": "5(0.7052)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005011.jpg"}, {"question": "what is this fixture used for", "gt answer": "heat(1.00)<br/>food(0.60)<br/>cook(0.60)", "pred answer": "eat", "question_id": 4700685, "best approach": "", "verif answer": "cook", "anno approach": "wiki, concept, image", "verif wiki answer": "toaster(0.6741)", "verif concept answer": "toaster(0.7065)", "verif image answer": "toaster(0.6637)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470068.jpg"}, {"question": "is this bowl cast or molded", "gt answer": "cast(1.00)", "pred answer": "art", "question_id": 4910295, "best approach": "concept, image", "verif answer": "custom", "anno approach": "wiki, concept, image", "verif wiki answer": "dice(0.5878)", "verif concept answer": "cast(0.6553)", "verif image answer": "cast(0.6236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491029.jpg"}, {"question": "who is pictured on the banner", "gt answer": "obama(1.00)<br/>barack obama(0.60)", "pred answer": "speech", "question_id": 1339815, "best approach": "", "verif answer": "protest", "anno approach": "wiki, concept, image", "verif wiki answer": "roosevelt(0.7172)", "verif concept answer": "roosevelt(0.6577)", "verif image answer": "teddy roosevelt(0.6121)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000133981.jpg"}, {"question": "what breed of cat is this", "gt answer": "american shorthair(1.00)<br/>tabby(0.60)<br/>domestic shorthair(0.60)<br/>house cat(0.60)", "pred answer": "siamese", "question_id": 1478835, "best approach": "", "verif answer": "tabby", "anno approach": "wiki, concept, image", "verif wiki answer": "calico(0.7281)", "verif concept answer": "calico(0.7033)", "verif image answer": "calico(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147883.jpg"}, {"question": "where would you normally see this", "gt answer": "highway(1.00)", "pred answer": "city", "question_id": 5363185, "best approach": "", "verif answer": "city", "anno approach": "wiki, concept, image", "verif wiki answer": "city(0.7288)", "verif concept answer": "airport(0.7151)", "verif image answer": "city(0.7002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536318.jpg"}, {"question": "can you name this famous location", "gt answer": "beach(1.00)", "pred answer": "washington dc", "question_id": 4049645, "best approach": "", "verif answer": "california", "anno approach": "wiki, concept, image", "verif wiki answer": "california(0.6524)", "verif concept answer": "saudi arabia(0.7022)", "verif image answer": "saudi arabia(0.7118)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404964.jpg"}, {"question": "name an appliance you see in this picture", "gt answer": "wash machine(1.00)<br/>dryer(0.60)<br/>oven(0.60)", "pred answer": "tv", "question_id": 1832475, "best approach": "wiki, image", "verif answer": "dryer", "anno approach": "wiki, concept, image", "verif wiki answer": "dryer(0.5496)", "verif concept answer": "kenmore(0.5077)", "verif image answer": "dryer(0.7076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183247.jpg"}, {"question": "why is this truck driving by", "gt answer": "parade(1.00)", "pred answer": "tow", "question_id": 2956575, "best approach": "concept", "verif answer": "parade", "anno approach": "wiki, concept, image", "verif wiki answer": "circus(0.6998)", "verif concept answer": "parade(0.6699)", "verif image answer": "circus(0.6129)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295657.jpg"}, {"question": "how was that item on the leaf made", "gt answer": "poached(1.00)", "pred answer": "slice", "question_id": 1611935, "best approach": "", "verif answer": "steamed", "anno approach": "wiki, concept, image", "verif wiki answer": "steamed(0.6871)", "verif concept answer": "pan(0.6907)", "verif image answer": "pelican(0.5830)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161193.jpg"}, {"question": "what is the name for what is happening in this picture", "gt answer": "traffic jam(1.00)<br/>traffic(0.60)<br/>rush hour(0.60)", "pred answer": "transport", "question_id": 5269225, "best approach": "wiki, concept, image", "verif answer": "traffic jam", "anno approach": "wiki, concept, image", "verif wiki answer": "rush hour(0.6606)", "verif concept answer": "rush hour(0.5831)", "verif image answer": "rush hour(0.6372)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526922.jpg"}, {"question": "are these workers being hygienic or unhygienic in their work", "gt answer": "hygienic(1.00)", "pred answer": "unhealthy", "question_id": 4558745, "best approach": "", "verif answer": "unhealthy", "anno approach": "wiki, concept, image", "verif wiki answer": "unhealthy(0.7308)", "verif concept answer": "unhealthy(0.7306)", "verif image answer": "unhealthy(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455874.jpg"}, {"question": "is this artwork or practical", "gt answer": "artwork(1.00)", "pred answer": "real", "question_id": 3850165, "best approach": "", "verif answer": "art", "anno approach": "wiki, concept, image", "verif wiki answer": "art(0.7307)", "verif concept answer": "art(0.6352)", "verif image answer": "crash(0.5053)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385016.jpg"}, {"question": "which metal object did the dish run away with in the nursery rhyme", "gt answer": "spoon(1.00)", "pred answer": "fork", "question_id": 4821965, "best approach": "concept, image", "verif answer": "fork", "anno approach": "wiki, concept, image", "verif wiki answer": "fork(0.7245)", "verif concept answer": "spoon(0.7104)", "verif image answer": "spoon(0.6492)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482196.jpg"}, {"question": "what kind of material is this floor made of", "gt answer": "linoleum(1.00)<br/>tile(0.60)<br/>concrete(0.60)", "pred answer": "stone", "question_id": 1925855, "best approach": "wiki, concept, image", "verif answer": "tile", "anno approach": "wiki, concept, image", "verif wiki answer": "tile(0.7265)", "verif concept answer": "concrete(0.7098)", "verif image answer": "tile(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000192585.jpg"}, {"question": "what resturant sells this", "gt answer": "fast food(1.00)<br/>hotdog(0.60)", "pred answer": "food", "question_id": 2817485, "best approach": "concept, image", "verif answer": "hotdog", "anno approach": "wiki, concept, image", "verif wiki answer": "hot dog(0.7240)", "verif concept answer": "hotdog(0.7266)", "verif image answer": "hotdog(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281748.jpg"}, {"question": "what are these people walking through", "gt answer": "alley(1.00)<br/>street(1.00)", "pred answer": "city", "question_id": 4469715, "best approach": "image", "verif answer": "alley", "anno approach": "wiki, concept, image", "verif wiki answer": "india(0.6405)", "verif concept answer": "india(0.5552)", "verif image answer": "alley(0.5455)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000446971.jpg"}, {"question": "what is this kit used for", "gt answer": "sew(1.00)<br/>school(0.60)", "pred answer": "cut", "question_id": 842835, "best approach": "concept", "verif answer": "sew", "anno approach": "wiki, concept, image", "verif wiki answer": "knit(0.6385)", "verif concept answer": "school(0.6896)", "verif image answer": "knit(0.6456)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084283.jpg"}, {"question": "the sort of work that this man is doing could lead to trouble with what part of the body later in life", "gt answer": "back(1.00)", "pred answer": "leg", "question_id": 435005, "best approach": "", "verif answer": "feet", "anno approach": "wiki, concept, image", "verif wiki answer": "front(0.7238)", "verif concept answer": "front(0.6804)", "verif image answer": "behind(0.7171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043500.jpg"}, {"question": "what do ships do at this location", "gt answer": "dock(1.00)", "pred answer": "float", "question_id": 1941595, "best approach": "image", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "boat(0.5313)", "verif concept answer": "pier(0.5021)", "verif image answer": "dock(0.5018)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194159.jpg"}, {"question": "how long is this womans hair", "gt answer": "short(1.00)<br/>2 feet(0.60)", "pred answer": "2 inches", "question_id": 324915, "best approach": "wiki", "verif answer": "long", "anno approach": "wiki, concept, image", "verif wiki answer": "2 feet(0.6904)", "verif concept answer": "pixie(0.6832)", "verif image answer": "pixie(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032491.jpg"}, {"question": "what is pulling this wakeboarder", "gt answer": "boat(1.00)", "pred answer": "wave", "question_id": 3574155, "best approach": "image", "verif answer": "water ski", "anno approach": "wiki, concept, image", "verif wiki answer": "sail(0.7249)", "verif concept answer": "sail(0.7000)", "verif image answer": "boat(0.7242)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357415.jpg"}, {"question": "what hearty cut of meat lends itself to the name of this version of fried potatoes", "gt answer": "steak(1.00)<br/>pork(0.60)<br/>fry(0.60)", "pred answer": "hot dog", "question_id": 400065, "best approach": "concept", "verif answer": "beef", "anno approach": "wiki, concept, image", "verif wiki answer": "beef(0.7234)", "verif concept answer": "pork(0.7093)", "verif image answer": "beef(0.7299)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040006.jpg"}, {"question": "is this legal or illegal", "gt answer": "legal(1.00)", "pred answer": "illegal", "question_id": 968205, "best approach": "", "verif answer": "illegal", "anno approach": "wiki, concept, image", "verif wiki answer": "illegal(0.7284)", "verif concept answer": "illegal(0.7283)", "verif image answer": "free(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096820.jpg"}, {"question": "is this a toy or a transportation device", "gt answer": "toy(1.00)", "pred answer": "stuffed animal", "question_id": 4261185, "best approach": "image", "verif answer": "toy", "anno approach": "wiki, concept, image", "verif wiki answer": "sale(0.7020)", "verif concept answer": "mall(0.5879)", "verif image answer": "toy(0.7085)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426118.jpg"}, {"question": "what is the baseball player doing", "gt answer": "slide(1.00)<br/>steal(0.60)", "pred answer": "pitch", "question_id": 2708095, "best approach": "wiki", "verif answer": "slide", "anno approach": "wiki, concept, image", "verif wiki answer": "steal(0.7141)", "verif concept answer": "sleep(0.7227)", "verif image answer": "player(0.6355)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000270809.jpg"}, {"question": "which motorcycle would most likely be more expensive", "gt answer": "left(1.00)<br/>racer(0.60)", "pred answer": "bmw", "question_id": 2434435, "best approach": "image", "verif answer": "blue", "anno approach": "wiki, concept, image", "verif wiki answer": "blue(0.6813)", "verif concept answer": "black 1(0.7076)", "verif image answer": "racer(0.7119)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243443.jpg"}, {"question": "what is the long object that the man is holding used for", "gt answer": "hit baseball(1.00)<br/>bat(0.60)<br/>baseball bat(0.60)", "pred answer": "hit", "question_id": 1492335, "best approach": "wiki, concept, image", "verif answer": "hit", "anno approach": "wiki, concept, image", "verif wiki answer": "bat(0.6982)", "verif concept answer": "bat(0.7138)", "verif image answer": "bat(0.6055)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149233.jpg"}, {"question": "if this woman is seeking information which famous search engine might she be looking at", "gt answer": "google(1.00)", "pred answer": "friend", "question_id": 5021975, "best approach": "", "verif answer": "central park", "anno approach": "wiki, concept, image", "verif wiki answer": "central park(0.5374)", "verif concept answer": "central park(0.7289)", "verif image answer": "shadow(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502197.jpg"}, {"question": "is this a meal or snack", "gt answer": "meal(1.00)", "pred answer": "snack", "question_id": 2319965, "best approach": "", "verif answer": "snack", "anno approach": "wiki, concept, image", "verif wiki answer": "snack(0.7307)", "verif concept answer": "snack(0.7296)", "verif image answer": "snack(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231996.jpg"}, {"question": "where is the fastest one of these in the world", "gt answer": "china(1.00)<br/>japan(0.60)<br/>europe(0.60)<br/>france(0.60)", "pred answer": "amtrack", "question_id": 1279455, "best approach": "wiki", "verif answer": "japan", "anno approach": "wiki, concept, image", "verif wiki answer": "china(0.6532)", "verif concept answer": "europe(0.6272)", "verif image answer": "india(0.6865)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000127945.jpg"}, {"question": "what type of cat is this", "gt answer": "persian(1.00)<br/>tabby(0.60)", "pred answer": "domestic shorthair", "question_id": 2710025, "best approach": "wiki", "verif answer": "ragdoll", "anno approach": "wiki, concept, image", "verif wiki answer": "persian(0.6738)", "verif concept answer": "ragdoll(0.7017)", "verif image answer": "siamese(0.6902)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000271002.jpg"}, {"question": "is the larger television set in the picture an older or newer model", "gt answer": "older(1.00)", "pred answer": "old", "question_id": 1536205, "best approach": "wiki", "verif answer": "old", "anno approach": "wiki, concept, image", "verif wiki answer": "older(0.7289)", "verif concept answer": "earlier(0.7230)", "verif image answer": "earlier(0.6390)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000153620.jpg"}, {"question": "what method of cooking is used to prepare the filling in this sandwhich", "gt answer": "bbq(0.60)<br/>grill(1.00)<br/>roast(0.60)", "pred answer": "fry", "question_id": 2874005, "best approach": "image", "verif answer": "bbq", "anno approach": "wiki, concept, image", "verif wiki answer": "bbq(0.6573)", "verif concept answer": "in oven(0.5295)", "verif image answer": "grill(0.5383)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287400.jpg"}, {"question": "what do you call the item above the horses head", "gt answer": "saddle(1.00)<br/>wooden(0.60)<br/>bridle(0.60)", "pred answer": "rein", "question_id": 1550585, "best approach": "wiki, concept, image", "verif answer": "saddle", "anno approach": "wiki, concept, image", "verif wiki answer": "bridle(0.7031)", "verif concept answer": "bridle(0.7229)", "verif image answer": "bridle(0.7015)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155058.jpg"}, {"question": "what is this lady doing to this kitten", "gt answer": "pet(1.00)", "pred answer": "shear", "question_id": 329495, "best approach": "", "verif answer": "feed", "anno approach": "wiki, concept, image", "verif wiki answer": "wash(0.5693)", "verif concept answer": "wash(0.6084)", "verif image answer": "wash(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032949.jpg"}, {"question": "how is the cat in this photo keeping cool", "gt answer": "fan(1.00)", "pred answer": "reflection", "question_id": 3284375, "best approach": "image", "verif answer": "fan", "anno approach": "wiki, concept, image", "verif wiki answer": "bowl(0.5132)", "verif concept answer": "bowl(0.5333)", "verif image answer": "fan(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328437.jpg"}, {"question": "what type of dog is this", "gt answer": "dalmation(1.00)<br/>dalmatian(0.60)", "pred answer": "labrador", "question_id": 1911935, "best approach": "wiki, image", "verif answer": "labrador", "anno approach": "wiki, concept, image", "verif wiki answer": "dalmation(0.7209)", "verif concept answer": "collie(0.6964)", "verif image answer": "dalmation(0.7189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191193.jpg"}, {"question": "how many calories per piece", "gt answer": "600(1.00)<br/>2000(0.60)<br/>50(0.60)<br/>400(0.60)", "pred answer": "500", "question_id": 5105175, "best approach": "wiki", "verif answer": "500", "anno approach": "wiki, concept, image", "verif wiki answer": "600(0.6095)", "verif concept answer": "500(0.6281)", "verif image answer": "400(0.7178)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000510517.jpg"}, {"question": "what is someone who specializes in this type of tasting called", "gt answer": "sommelier(1.00)<br/>wine taster(0.60)", "pred answer": "bar", "question_id": 3314095, "best approach": "wiki", "verif answer": "wine taster", "anno approach": "wiki, concept, image", "verif wiki answer": "wine taster(0.6777)", "verif concept answer": "president(0.6490)", "verif image answer": "president(0.6219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331409.jpg"}, {"question": "what might this citizen be termed", "gt answer": "elderly(1.00)<br/>old(0.60)", "pred answer": "person", "question_id": 2105705, "best approach": "concept, image", "verif answer": "student", "anno approach": "wiki, concept, image", "verif wiki answer": "student(0.6438)", "verif concept answer": "elderly(0.5434)", "verif image answer": "elderly(0.5733)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210570.jpg"}, {"question": "how many vertebrae does this animal have", "gt answer": "7(1.00)<br/>3(0.60)<br/>100(0.60)", "pred answer": "25", "question_id": 5566225, "best approach": "wiki, concept, image", "verif answer": "3", "anno approach": "wiki, concept, image", "verif wiki answer": "3(0.6779)", "verif concept answer": "3(0.6785)", "verif image answer": "3(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556622.jpg"}, {"question": "what is the best kind of sun protection to use for this activity", "gt answer": "sun screen(1.00)<br/>sunscreen(1.00)", "pred answer": "sun", "question_id": 5351655, "best approach": "wiki, concept, image", "verif answer": "sun screen", "anno approach": "wiki, concept, image", "verif wiki answer": "sun screen(0.6883)", "verif concept answer": "sun screen(0.6587)", "verif image answer": "sun screen(0.5942)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535165.jpg"}, {"question": "what type of boat is in the picture", "gt answer": "surf board(1.00)<br/>yacht(0.60)<br/>sailboat(0.60)<br/>surfboard(0.60)", "pred answer": "sail", "question_id": 1827285, "best approach": "image", "verif answer": "sail", "anno approach": "wiki, concept, image", "verif wiki answer": "sail(0.7204)", "verif concept answer": "sail(0.6772)", "verif image answer": "surf board(0.6779)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182728.jpg"}, {"question": "what is the purpose of the green light", "gt answer": "go(1.00)<br/>move(0.60)", "pred answer": "traffic", "question_id": 322955, "best approach": "wiki, concept", "verif answer": "go", "anno approach": "wiki, concept, image", "verif wiki answer": "go(0.6994)", "verif concept answer": "go(0.6071)", "verif image answer": "move(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032295.jpg"}, {"question": "if the host of this part had it at home what section of the house would they be in", "gt answer": "backyard(1.00)<br/>outdoor(0.60)<br/>kitchen(0.60)", "pred answer": "dine room", "question_id": 1478235, "best approach": "wiki, concept, image", "verif answer": "kitchen", "anno approach": "wiki, concept, image", "verif wiki answer": "outdoor(0.7196)", "verif concept answer": "outdoor(0.6972)", "verif image answer": "kitchen(0.6806)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147823.jpg"}, {"question": "where is this animal most common", "gt answer": "africa(1.00)<br/>india(1.00)", "pred answer": "zoo", "question_id": 2441795, "best approach": "wiki, concept", "verif answer": "india", "anno approach": "wiki, concept, image", "verif wiki answer": "india(0.7088)", "verif concept answer": "africa(0.6885)", "verif image answer": "mexico(0.6536)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244179.jpg"}, {"question": "why would we suspect this is a store display and not a child 's room", "gt answer": "price(1.00)<br/>price tag(0.60)", "pred answer": "picture", "question_id": 4783285, "best approach": "", "verif answer": "picture", "anno approach": "wiki, concept, image", "verif wiki answer": "picture(0.6895)", "verif concept answer": "picture(0.6969)", "verif image answer": "picture(0.6203)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478328.jpg"}, {"question": "who invested this", "gt answer": "wright brother(1.00)<br/>company(0.60)", "pred answer": "american airline", "question_id": 2833125, "best approach": "", "verif answer": "wright brother", "anno approach": "wiki, concept, image", "verif wiki answer": "wright(0.7025)", "verif concept answer": "wright(0.5999)", "verif image answer": "wright(0.5643)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283312.jpg"}, {"question": "can you guess clock model shown in this picture", "gt answer": "antique(1.00)", "pred answer": "analog", "question_id": 3755755, "best approach": "", "verif answer": "ford", "anno approach": "wiki, concept, image", "verif wiki answer": "ford(0.6844)", "verif concept answer": "ford(0.5541)", "verif image answer": "ford(0.5914)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375575.jpg"}, {"question": "how many feet deep are these most likely dug", "gt answer": "6(1.00)", "pred answer": "50", "question_id": 1348715, "best approach": "concept", "verif answer": "6", "anno approach": "wiki, concept, image", "verif wiki answer": "12(0.6912)", "verif concept answer": "6(0.7078)", "verif image answer": "5(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134871.jpg"}, {"question": "what was the conductors name of this famous kids television show", "gt answer": "thomas(1.00)", "pred answer": "friend", "question_id": 2467005, "best approach": "", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "friend(0.7280)", "verif concept answer": "thomas train(0.7178)", "verif image answer": "thomas train(0.6269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246700.jpg"}, {"question": "what material causes those goggles to be reflective", "gt answer": "mirrored(1.00)<br/>plastic(0.60)<br/>wind(0.60)", "pred answer": "glass", "question_id": 5031505, "best approach": "wiki", "verif answer": "nylon", "anno approach": "wiki, concept, image", "verif wiki answer": "plastic(0.6696)", "verif concept answer": "nylon(0.6930)", "verif image answer": "light(0.6814)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503150.jpg"}, {"question": "what is the name of the object on the man 's wrist that tells the time", "gt answer": "watch(1.00)", "pred answer": "clock", "question_id": 3830295, "best approach": "concept, image", "verif answer": "watch", "anno approach": "wiki, concept, image", "verif wiki answer": "tell time(0.7083)", "verif concept answer": "watch(0.6929)", "verif image answer": "watch(0.6312)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000383029.jpg"}, {"question": "what is the best way to clean this", "gt answer": "brush(1.00)<br/>fast(0.60)", "pred answer": "bleach", "question_id": 2036115, "best approach": "wiki, image", "verif answer": "bleach", "anno approach": "wiki, concept, image", "verif wiki answer": "brush(0.7104)", "verif concept answer": "soap and water(0.7090)", "verif image answer": "brush(0.7282)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203611.jpg"}, {"question": "what type of dog is this", "gt answer": "bulldog(1.00)", "pred answer": "dalmation", "question_id": 1960615, "best approach": "", "verif answer": "saint bernard", "anno approach": "wiki, concept, image", "verif wiki answer": "saint bernard(0.7279)", "verif concept answer": "saint bernard(0.7269)", "verif image answer": "saint bernard(0.7167)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196061.jpg"}, {"question": "why is someone using an umbrella and no rain", "gt answer": "for sun(1.00)", "pred answer": "shade", "question_id": 3548435, "best approach": "", "verif answer": "sun protection", "anno approach": "wiki, concept, image", "verif wiki answer": "hot(0.7263)", "verif concept answer": "sun protection(0.7096)", "verif image answer": "hot(0.6763)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354843.jpg"}, {"question": "what insturments could be used while the man is singing", "gt answer": "guitar(1.00)<br/>microphone(0.60)", "pred answer": "rock", "question_id": 4308535, "best approach": "", "verif answer": "microphone", "anno approach": "wiki, concept, image", "verif wiki answer": "cello(0.7108)", "verif concept answer": "cello(0.6130)", "verif image answer": "tuba(0.7242)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430853.jpg"}, {"question": "how is the drink made", "gt answer": "brew(1.00)<br/>brewed(0.60)", "pred answer": "coffee", "question_id": 4162975, "best approach": "wiki, concept, image", "verif answer": "fermentation", "anno approach": "wiki, concept, image", "verif wiki answer": "brewed(0.6540)", "verif concept answer": "brewed(0.6869)", "verif image answer": "brewed(0.7013)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416297.jpg"}, {"question": "what is that hole in the ground for", "gt answer": "urine(1.00)<br/>toilet(0.60)", "pred answer": "bath", "question_id": 2550885, "best approach": "wiki, concept, image", "verif answer": "toilet", "anno approach": "wiki, concept, image", "verif wiki answer": "toilet(0.7280)", "verif concept answer": "toilet(0.7133)", "verif image answer": "toilet(0.6941)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255088.jpg"}, {"question": "what are these pants referred to as", "gt answer": "overall(1.00)<br/>short(0.60)", "pred answer": "jean", "question_id": 3841605, "best approach": "image", "verif answer": "jean", "anno approach": "wiki, concept, image", "verif wiki answer": "cap(0.6430)", "verif concept answer": "scarf(0.6093)", "verif image answer": "short(0.7145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000384160.jpg"}, {"question": "what type of building is this wagon parked outside of", "gt answer": "train station(1.00)<br/>stone(0.60)<br/>concrete(0.60)", "pred answer": "apartment", "question_id": 71395, "best approach": "wiki", "verif answer": "brick", "anno approach": "wiki, concept, image", "verif wiki answer": "train station(0.6239)", "verif concept answer": "stone(0.6311)", "verif image answer": "concrete(0.6819)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007139.jpg"}, {"question": "which brand of shoes are weared by the sports person in this picture", "gt answer": "nike(1.00)<br/>adidas(1.00)", "pred answer": "rawling", "question_id": 2163245, "best approach": "wiki, concept, image", "verif answer": "adidas", "anno approach": "wiki, concept, image", "verif wiki answer": "adidas(0.7041)", "verif concept answer": "adidas(0.6551)", "verif image answer": "adidas(0.6491)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000216324.jpg"}, {"question": "what type of teeth is this child missing", "gt answer": "front(1.00)<br/>baby(0.60)", "pred answer": "goatee", "question_id": 846105, "best approach": "wiki, concept", "verif answer": "baby", "anno approach": "wiki, concept, image", "verif wiki answer": "front(0.5251)", "verif concept answer": "front(0.5037)", "verif image answer": "adult(0.5075)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084610.jpg"}, {"question": "what character on the toothbrush", "gt answer": "tigger(1.00)<br/>tiger(1.00)", "pred answer": "mickey mouse", "question_id": 1627805, "best approach": "wiki, concept", "verif answer": "puma", "anno approach": "wiki, concept, image", "verif wiki answer": "tigger(0.7228)", "verif concept answer": "tigger(0.6970)", "verif image answer": "ty cobb(0.5936)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162780.jpg"}, {"question": "what part of the horse are the men touching", "gt answer": "mane(1.00)<br/>head(0.60)", "pred answer": "rein", "question_id": 617805, "best approach": "wiki", "verif answer": "head", "anno approach": "wiki, concept, image", "verif wiki answer": "mane(0.7050)", "verif concept answer": "head(0.6608)", "verif image answer": "head(0.6698)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061780.jpg"}, {"question": "what is the name of a baby that would be made by the animals", "gt answer": "calf(1.00)", "pred answer": "puppy", "question_id": 3787005, "best approach": "wiki, concept, image", "verif answer": "calf", "anno approach": "wiki, concept, image", "verif wiki answer": "calf(0.7297)", "verif concept answer": "calf(0.7032)", "verif image answer": "calf(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378700.jpg"}, {"question": "what is this device used for", "gt answer": "type(1.00)", "pred answer": "work", "question_id": 2603995, "best approach": "", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "work(0.6825)", "verif concept answer": "computer(0.6302)", "verif image answer": "video game(0.7159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260399.jpg"}, {"question": "the ice skating usedby the boy is of which metal", "gt answer": "aluminum(1.00)<br/>steel(0.60)<br/>ski(0.60)", "pred answer": "pole", "question_id": 3301875, "best approach": "concept, image", "verif answer": "fiberglass", "anno approach": "wiki, concept, image", "verif wiki answer": "fiberglass(0.7067)", "verif concept answer": "steel(0.6331)", "verif image answer": "steel(0.5838)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000330187.jpg"}, {"question": "what are the hot dogs covered in", "gt answer": "dough(1.00)<br/>pastry(1.00)", "pred answer": "cream", "question_id": 4567195, "best approach": "wiki, concept", "verif answer": "pastry", "anno approach": "wiki, concept, image", "verif wiki answer": "pastry(0.6885)", "verif concept answer": "pastry(0.6495)", "verif image answer": "sweet(0.6412)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456719.jpg"}, {"question": "what breed of cows are these", "gt answer": "holstein(1.00)", "pred answer": "dairy", "question_id": 4918505, "best approach": "wiki, image", "verif answer": "dairy", "anno approach": "wiki, concept, image", "verif wiki answer": "holstein(0.7222)", "verif concept answer": "dairy(0.7054)", "verif image answer": "holstein(0.6883)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000491850.jpg"}, {"question": "what language is the text on the bus written in", "gt answer": "english(1.00)", "pred answer": "arabic", "question_id": 4165865, "best approach": "", "verif answer": "arabic", "anno approach": "wiki, concept, image", "verif wiki answer": "french(0.6594)", "verif concept answer": "korean(0.7059)", "verif image answer": "korean(0.7161)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000416586.jpg"}, {"question": "what global issue is the stop sign referring to", "gt answer": "global warm(1.00)<br/>warm(0.60)", "pred answer": "stop", "question_id": 2186475, "best approach": "", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "climate change(0.6889)", "verif concept answer": "climate change(0.6866)", "verif image answer": "climate change(0.7196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218647.jpg"}, {"question": "does this bear appear playful or ferocious", "gt answer": "playful(1.00)", "pred answer": "herbivorous", "question_id": 3147105, "best approach": "", "verif answer": "giraffe", "anno approach": "wiki, concept, image", "verif wiki answer": "giraffe(0.7170)", "verif concept answer": "giraffe(0.7133)", "verif image answer": "giraffe(0.6729)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314710.jpg"}, {"question": "why are the buses so close together", "gt answer": "parked(1.00)<br/>park lot(0.60)<br/>storage(0.60)", "pred answer": "tour", "question_id": 2380705, "best approach": "wiki, concept, image", "verif answer": "parked", "anno approach": "wiki, concept, image", "verif wiki answer": "storage(0.7292)", "verif concept answer": "park lot(0.7046)", "verif image answer": "park lot(0.7227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238070.jpg"}, {"question": "what do you call these types of ducks", "gt answer": "geese(1.00)<br/>mallard(1.00)", "pred answer": "duck", "question_id": 5657555, "best approach": "wiki", "verif answer": "mallard", "anno approach": "wiki, concept, image", "verif wiki answer": "geese(0.6255)", "verif concept answer": "seagull(0.7023)", "verif image answer": "seagull(0.5073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000565755.jpg"}, {"question": "is this game being played on natural grass or artificial turf", "gt answer": "natural grass(1.00)<br/>turf(0.60)<br/>natural(0.60)", "pred answer": "manmade", "question_id": 2768545, "best approach": "image", "verif answer": "dirt", "anno approach": "wiki, concept, image", "verif wiki answer": "dirt(0.6204)", "verif concept answer": "dirt(0.6026)", "verif image answer": "natural grass(0.6839)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276854.jpg"}, {"question": "how do we know these two aren't opponents", "gt answer": "same side(1.00)", "pred answer": "outfit", "question_id": 3189375, "best approach": "wiki", "verif answer": "shake hand", "anno approach": "wiki, concept, image", "verif wiki answer": "same side(0.6878)", "verif concept answer": "serve(0.6523)", "verif image answer": "roger federer(0.5511)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318937.jpg"}, {"question": "which utensils did the person use to eat this food", "gt answer": "fork and knife(1.00)<br/>chopstick(0.60)", "pred answer": "fork", "question_id": 4121125, "best approach": "concept", "verif answer": "fork", "anno approach": "wiki, concept, image", "verif wiki answer": "chopstick(0.6916)", "verif concept answer": "fork and knife(0.6661)", "verif image answer": "chop stick(0.7245)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412112.jpg"}, {"question": "what airline is pictured in photo", "gt answer": "eva air(1.00)", "pred answer": "american airline", "question_id": 1007575, "best approach": "", "verif answer": "american airline", "anno approach": "wiki, concept, image", "verif wiki answer": "alaska(0.6799)", "verif concept answer": "portland timber(0.5823)", "verif image answer": "alaska(0.6076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100757.jpg"}, {"question": "what are those posters of", "gt answer": "movie(1.00)<br/>band(0.60)", "pred answer": "map", "question_id": 4520045, "best approach": "wiki", "verif answer": "map", "anno approach": "wiki, concept, image", "verif wiki answer": "movie(0.7205)", "verif concept answer": "star(0.7136)", "verif image answer": "map(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000452004.jpg"}, {"question": "where are all these boats parked", "gt answer": "marina(1.00)<br/>harbor(0.60)<br/>water(0.60)", "pred answer": "dock", "question_id": 5369295, "best approach": "wiki", "verif answer": "marina", "anno approach": "wiki, concept, image", "verif wiki answer": "marina(0.7089)", "verif concept answer": "water(0.6535)", "verif image answer": "water(0.5950)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536929.jpg"}, {"question": "what activity are they participating in", "gt answer": "horseback ride(1.00)<br/>run(0.60)<br/>race(0.60)", "pred answer": "horse race", "question_id": 2311945, "best approach": "wiki, concept, image", "verif answer": "race", "anno approach": "wiki, concept, image", "verif wiki answer": "run(0.6900)", "verif concept answer": "run(0.6950)", "verif image answer": "run(0.6978)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231194.jpg"}, {"question": "what river is this an image of", "gt answer": "mississippi(1.00)<br/>lazy(0.60)<br/>nile(0.60)<br/>amazon(0.60)", "pred answer": "river", "question_id": 3003075, "best approach": "wiki", "verif answer": "mississippi", "anno approach": "wiki, concept, image", "verif wiki answer": "mississippi(0.7236)", "verif concept answer": "idaho(0.7262)", "verif image answer": "amazon(0.7274)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000300307.jpg"}, {"question": "what is missing from beneath the mouse", "gt answer": "pad(1.00)<br/>mouse pad(1.00)<br/>mousepad(0.60)", "pred answer": "cord", "question_id": 4669675, "best approach": "wiki", "verif answer": "gun", "anno approach": "wiki, concept, image", "verif wiki answer": "mouse pad(0.6168)", "verif concept answer": "gun(0.6560)", "verif image answer": "stone(0.5043)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466967.jpg"}, {"question": "what describes that man as a office worker", "gt answer": "suit and tie(1.00)<br/>busy(0.60)<br/>suit(0.60)<br/>tie(0.60)", "pred answer": "business", "question_id": 5012995, "best approach": "wiki", "verif answer": "business", "anno approach": "wiki, concept, image", "verif wiki answer": "suit and tie(0.7240)", "verif concept answer": "suit(0.7196)", "verif image answer": "suit(0.7306)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501299.jpg"}, {"question": "how fast does a jet have to go to break the sound barrier", "gt answer": "767 mph(1.00)<br/>1000(0.60)", "pred answer": "100 mph", "question_id": 694015, "best approach": "concept, image", "verif answer": "100", "anno approach": "wiki, concept, image", "verif wiki answer": "mile(0.6858)", "verif concept answer": "1000(0.6398)", "verif image answer": "1000(0.7096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000069401.jpg"}, {"question": "what kind of food is in this mans hand", "gt answer": "sandwich(1.00)<br/>cake(0.60)<br/>burger(0.60)", "pred answer": "meat", "question_id": 2976995, "best approach": "image", "verif answer": "sandwich", "anno approach": "wiki, concept, image", "verif wiki answer": "cake(0.7239)", "verif concept answer": "burger(0.7156)", "verif image answer": "sandwich(0.7115)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000297699.jpg"}, {"question": "what are the people wearing on the lower half of their bodies", "gt answer": "short(1.00)", "pred answer": "bear costume", "question_id": 5030155, "best approach": "", "verif answer": "skirt", "anno approach": "wiki, concept, image", "verif wiki answer": "skirt(0.7229)", "verif concept answer": "pixie(0.5817)", "verif image answer": "pixie(0.6132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503015.jpg"}, {"question": "how fast can a baseball be picthed", "gt answer": "100 mph(1.00)<br/>very fast(0.60)", "pred answer": "fast", "question_id": 3394995, "best approach": "concept", "verif answer": "80 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "80 mph(0.6566)", "verif concept answer": "100 mph(0.6469)", "verif image answer": "80 mph(0.5943)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000339499.jpg"}, {"question": "what tennis move is being performed in this picture", "gt answer": "serve(1.00)", "pred answer": "backhand", "question_id": 1438115, "best approach": "", "verif answer": "backhand", "anno approach": "wiki, concept, image", "verif wiki answer": "hit ball(0.7237)", "verif concept answer": "hit ball(0.7250)", "verif image answer": "hit ball(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143811.jpg"}, {"question": "what happened to these scissors", "gt answer": "bent(1.00)<br/>broken(0.60)", "pred answer": "cut", "question_id": 828605, "best approach": "wiki, concept", "verif answer": "broken", "anno approach": "wiki, concept, image", "verif wiki answer": "broken(0.6174)", "verif concept answer": "broken(0.5604)", "verif image answer": "art(0.5216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082860.jpg"}, {"question": "what are these kids riding their skateboards through", "gt answer": "puddle(1.00)<br/>park(1.00)", "pred answer": "skate park", "question_id": 3946915, "best approach": "wiki, concept", "verif answer": "skatepark", "anno approach": "wiki, concept, image", "verif wiki answer": "park(0.7224)", "verif concept answer": "park(0.7190)", "verif image answer": "statue(0.6920)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000394691.jpg"}, {"question": "how was this sidewalk made", "gt answer": "tile(1.00)<br/>concrete(0.60)", "pred answer": "brick", "question_id": 4359085, "best approach": "image", "verif answer": "clay", "anno approach": "wiki, concept, image", "verif wiki answer": "clay(0.5955)", "verif concept answer": "clay(0.5281)", "verif image answer": "tile(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435908.jpg"}, {"question": "who were here but are now gone", "gt answer": "team(1.00)<br/>baseball player(0.60)<br/>player(0.60)", "pred answer": "human", "question_id": 1475685, "best approach": "wiki, concept", "verif answer": "team", "anno approach": "wiki, concept, image", "verif wiki answer": "team(0.6922)", "verif concept answer": "team(0.7142)", "verif image answer": "uniform(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147568.jpg"}, {"question": "what is the man holding the cats relationship status", "gt answer": "married(1.00)<br/>collar(0.60)<br/>owner(0.60)", "pred answer": "friend", "question_id": 4435, "best approach": "wiki, concept", "verif answer": "married", "anno approach": "wiki, concept, image", "verif wiki answer": "married(0.7281)", "verif concept answer": "married(0.6861)", "verif image answer": "collar(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000443.jpg"}, {"question": "the knot being tied here is commonly referred to as", "gt answer": "half windsor(1.00)<br/>bow tie(0.60)<br/>windsor(0.60)<br/>marriage(0.60)", "pred answer": "tie", "question_id": 3506445, "best approach": "concept", "verif answer": "windsor", "anno approach": "wiki, concept, image", "verif wiki answer": "marriage(0.5032)", "verif concept answer": "half windsor(0.5223)", "verif image answer": "marriage(0.5403)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350644.jpg"}, {"question": "", "gt answer": "$15(0.60)<br/>money(0.60)<br/>15(0.60)", "pred answer": "ticket", "question_id": 1113885, "best approach": "wiki, concept, image", "verif answer": "50", "anno approach": "wiki, concept, image", "verif wiki answer": "money(0.6990)", "verif concept answer": "money(0.7017)", "verif image answer": "money(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111388.jpg"}, {"question": "what is the best surface on which to prepare food in this space", "gt answer": "countertop(1.00)<br/>counter(0.60)<br/>island(0.60)<br/>table(0.60)", "pred answer": "marble", "question_id": 3853075, "best approach": "wiki", "verif answer": "table", "anno approach": "wiki, concept, image", "verif wiki answer": "countertop(0.6959)", "verif concept answer": "peninsula(0.6860)", "verif image answer": "counter(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000385307.jpg"}, {"question": "what is the specific name of the numbers shown in the picture", "gt answer": "roman numeral(1.00)<br/>numeral(0.60)<br/>hour(0.60)", "pred answer": "roman", "question_id": 5558055, "best approach": "wiki, concept", "verif answer": "roman", "anno approach": "wiki, concept, image", "verif wiki answer": "roman numeral(0.7260)", "verif concept answer": "roman numeral(0.6886)", "verif image answer": "roman(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555805.jpg"}, {"question": "what are these men in the middle of doing", "gt answer": "rugby(1.00)<br/>block(0.60)", "pred answer": "play soccer", "question_id": 992295, "best approach": "image", "verif answer": "soccer", "anno approach": "wiki, concept, image", "verif wiki answer": "soccer(0.6084)", "verif concept answer": "block(0.6607)", "verif image answer": "rugby(0.6095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099229.jpg"}, {"question": "how old is the baby", "gt answer": "1 year(1.00)<br/>1(0.60)", "pred answer": "2", "question_id": 4561615, "best approach": "concept, image", "verif answer": "1", "anno approach": "wiki, concept, image", "verif wiki answer": "1(0.6433)", "verif concept answer": "1 year(0.6747)", "verif image answer": "1 year(0.6661)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456161.jpg"}, {"question": "what type of pasta noodle is in this image", "gt answer": "penne(1.00)", "pred answer": "lo mein", "question_id": 1775165, "best approach": "wiki, concept", "verif answer": "shell", "anno approach": "wiki, concept, image", "verif wiki answer": "penne(0.7158)", "verif concept answer": "penne(0.6558)", "verif image answer": "hotdog(0.7302)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177516.jpg"}, {"question": "what kind of insects do these scooters resemble", "gt answer": "ladybug(1.00)", "pred answer": "bee", "question_id": 3470195, "best approach": "", "verif answer": "scooter", "anno approach": "wiki, concept, image", "verif wiki answer": "dolphin(0.5060)", "verif concept answer": "dolphin(0.5103)", "verif image answer": "scooter(0.5227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347019.jpg"}, {"question": "does this person have flip flops or high heels with her", "gt answer": "flip flop(1.00)<br/>high heel(0.60)", "pred answer": "topless", "question_id": 3734155, "best approach": "wiki, concept", "verif answer": "sandal", "anno approach": "wiki, concept, image", "verif wiki answer": "flip flop(0.7233)", "verif concept answer": "flip flop(0.7193)", "verif image answer": "sandal(0.7222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000373415.jpg"}, {"question": "how long has toshiba been making laptops like this", "gt answer": "year(1.00)<br/>20 years(0.60)", "pred answer": "2010", "question_id": 3723815, "best approach": "wiki", "verif answer": "1 month", "anno approach": "wiki, concept, image", "verif wiki answer": "20 years(0.6675)", "verif concept answer": "1 month(0.6442)", "verif image answer": "1 month(0.5947)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372381.jpg"}, {"question": "what type of pepper is in the picture", "gt answer": "jalapeno(1.00)<br/>green(0.60)", "pred answer": "snap pea", "question_id": 5078815, "best approach": "concept, image", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "granny smith(0.7221)", "verif concept answer": "jalapeno(0.7300)", "verif image answer": "jalapeno(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000507881.jpg"}, {"question": "what is the fence shown in this image called", "gt answer": "bat cage(1.00)<br/>chain link(0.60)", "pred answer": "fence", "question_id": 613585, "best approach": "", "verif answer": "fence", "anno approach": "wiki, concept, image", "verif wiki answer": "fence(0.6606)", "verif concept answer": "fence(0.5693)", "verif image answer": "fence(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061358.jpg"}, {"question": "what is about to happen with these two people", "gt answer": "collision(1.00)<br/>crash(0.60)<br/>fall(0.60)", "pred answer": "catch", "question_id": 1618185, "best approach": "wiki, image", "verif answer": "crash", "anno approach": "wiki, concept, image", "verif wiki answer": "crash(0.6601)", "verif concept answer": "jumped(0.7059)", "verif image answer": "crash(0.6172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161818.jpg"}, {"question": "the open area pictured here is known as what", "gt answer": "courtyard(1.00)<br/>square(1.00)", "pred answer": "city", "question_id": 2576285, "best approach": "wiki, concept, image", "verif answer": "square", "anno approach": "wiki, concept, image", "verif wiki answer": "courtyard(0.7234)", "verif concept answer": "courtyard(0.7220)", "verif image answer": "courtyard(0.7155)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257628.jpg"}, {"question": "what economic class does the wearer of these glasses belong to", "gt answer": "upper(1.00)", "pred answer": "captain", "question_id": 5554705, "best approach": "", "verif answer": "revel", "anno approach": "wiki, concept, image", "verif wiki answer": "20th(0.6518)", "verif concept answer": "revel(0.6297)", "verif image answer": "revel(0.5841)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555470.jpg"}, {"question": "what kind of fruits are there", "gt answer": "banana(1.00)", "pred answer": "fruit", "question_id": 3026345, "best approach": "", "verif answer": "fruit", "anno approach": "wiki, concept, image", "verif wiki answer": "apple(0.7245)", "verif concept answer": "apple(0.7275)", "verif image answer": "apple(0.7241)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302634.jpg"}, {"question": "where can this fruit be found", "gt answer": "tree(1.00)<br/>florida(0.60)", "pred answer": "supermarket", "question_id": 5313915, "best approach": "concept", "verif answer": "florida", "anno approach": "wiki, concept, image", "verif wiki answer": "banana(0.7194)", "verif concept answer": "florida(0.6877)", "verif image answer": "orange(0.6660)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531391.jpg"}, {"question": "what country is this", "gt answer": "ireland(1.00)<br/>england(0.60)<br/>scotland(0.60)", "pred answer": "switzerland", "question_id": 4744535, "best approach": "wiki, concept", "verif answer": "switzerland", "anno approach": "wiki, concept, image", "verif wiki answer": "ireland(0.6883)", "verif concept answer": "ireland(0.7025)", "verif image answer": "scotland(0.6981)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000474453.jpg"}, {"question": "where can i find a new seat for this", "gt answer": "hardware store(1.00)<br/>store(1.00)<br/>low(0.60)", "pred answer": "bathroom", "question_id": 963285, "best approach": "concept", "verif answer": "low", "anno approach": "wiki, concept, image", "verif wiki answer": "low(0.6886)", "verif concept answer": "hardware store(0.6283)", "verif image answer": "walmart(0.6541)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000096328.jpg"}, {"question": "what important list is this animal known to be on", "gt answer": "endangered(1.00)", "pred answer": "long neck", "question_id": 1495835, "best approach": "image", "verif answer": "thousand", "anno approach": "wiki, concept, image", "verif wiki answer": "many(0.5110)", "verif concept answer": "many(0.5142)", "verif image answer": "endangered(0.5150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149583.jpg"}, {"question": "what type of pattern are the cats on top of", "gt answer": "plaid(1.00)<br/>checkered(0.60)", "pred answer": "striped", "question_id": 5807065, "best approach": "", "verif answer": "plaid", "anno approach": "wiki, concept, image", "verif wiki answer": "kilt(0.7285)", "verif concept answer": "kilt(0.7264)", "verif image answer": "kilt(0.7135)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580706.jpg"}, {"question": "who invented the white obect the man is holding", "gt answer": "walter frederick morrison(1.00)<br/>ben franklin(0.60)", "pred answer": "morris michtom", "question_id": 3794345, "best approach": "", "verif answer": "ben franklin", "anno approach": "wiki, concept, image", "verif wiki answer": "benjamin franklin(0.7140)", "verif concept answer": "benjamin franklin(0.7184)", "verif image answer": "benjamin franklin(0.7199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379434.jpg"}, {"question": "which city can i find this storefront", "gt answer": "amsterdam(1.00)<br/>copenhagen(0.60)<br/>new york(0.60)", "pred answer": "tokyo", "question_id": 1959165, "best approach": "wiki, concept", "verif answer": "paris", "anno approach": "wiki, concept, image", "verif wiki answer": "new york(0.6362)", "verif concept answer": "new york(0.6857)", "verif image answer": "seattle(0.6797)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195916.jpg"}, {"question": "who is inside of that building", "gt answer": "priest(1.00)", "pred answer": "tourist", "question_id": 4949405, "best approach": "wiki, concept, image", "verif answer": "pope", "anno approach": "wiki, concept, image", "verif wiki answer": "priest(0.7273)", "verif concept answer": "priest(0.7226)", "verif image answer": "priest(0.6855)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000494940.jpg"}, {"question": "what movie is the elephant from", "gt answer": "dumbo(1.00)", "pred answer": "cinderella", "question_id": 2475045, "best approach": "concept", "verif answer": "dumbo", "anno approach": "wiki, concept, image", "verif wiki answer": "lion king(0.6834)", "verif concept answer": "dumbo(0.7283)", "verif image answer": "lion king(0.7307)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000247504.jpg"}, {"question": "which musical genre is often associated with this sport", "gt answer": "rock(1.00)", "pred answer": "skateboard", "question_id": 3387605, "best approach": "", "verif answer": "concrete", "anno approach": "wiki, concept, image", "verif wiki answer": "stone(0.5114)", "verif concept answer": "canvas(0.5112)", "verif image answer": "concrete(0.7108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000338760.jpg"}, {"question": "what league is this team", "gt answer": "major league(1.00)<br/>baseball(0.60)<br/>mexican(0.60)<br/>mlb(0.60)", "pred answer": "dodger", "question_id": 2296225, "best approach": "concept", "verif answer": "mexican", "anno approach": "wiki, concept, image", "verif wiki answer": "major(0.6879)", "verif concept answer": "major league(0.7158)", "verif image answer": "mlb(0.6861)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000229622.jpg"}, {"question": "what character is the man dressed as", "gt answer": "clown(1.00)", "pred answer": "blue brother", "question_id": 3322275, "best approach": "", "verif answer": "run", "anno approach": "wiki, concept, image", "verif wiki answer": "shaun white(0.6583)", "verif concept answer": "run(0.6053)", "verif image answer": "shaun white(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332227.jpg"}, {"question": "what type of boat is this called in the water below the plane above", "gt answer": "sailboat(1.00)<br/>sail(0.60)", "pred answer": "fish", "question_id": 2382905, "best approach": "wiki", "verif answer": "sail", "anno approach": "wiki, concept, image", "verif wiki answer": "sail(0.7235)", "verif concept answer": "canoe(0.7175)", "verif image answer": "pirate(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238290.jpg"}, {"question": "how does this animal get around", "gt answer": "fly(1.00)<br/>wing(0.60)", "pred answer": "migrate", "question_id": 3043145, "best approach": "concept, image", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "flight(0.7289)", "verif concept answer": "fly(0.7206)", "verif image answer": "fly(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304314.jpg"}, {"question": "what is coming out of the back of this air plane", "gt answer": "smoke(1.00)<br/>contrail(0.60)<br/>gas(0.60)", "pred answer": "air", "question_id": 5340585, "best approach": "", "verif answer": "contrail", "anno approach": "wiki, concept, image", "verif wiki answer": "fire(0.6740)", "verif concept answer": "fire(0.7058)", "verif image answer": "trail(0.6059)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534058.jpg"}, {"question": "which funny performers are found here", "gt answer": "clown(1.00)<br/>circus(0.60)", "pred answer": "elephant", "question_id": 4020415, "best approach": "wiki, image", "verif answer": "circus", "anno approach": "wiki, concept, image", "verif wiki answer": "clown(0.7056)", "verif concept answer": "dumbo(0.7236)", "verif image answer": "clown(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402041.jpg"}, {"question": "what kind of tv remote is that", "gt answer": "universal(1.00)<br/>plastic(0.60)<br/>sky(0.60)", "pred answer": "tv", "question_id": 1284315, "best approach": "concept, image", "verif answer": "led", "anno approach": "wiki, concept, image", "verif wiki answer": "led(0.6777)", "verif concept answer": "universal(0.6743)", "verif image answer": "universal(0.7158)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000128431.jpg"}, {"question": "what protective equipment should be worn during this activity", "gt answer": "glove(1.00)<br/>helmet(0.60)", "pred answer": "skiis", "question_id": 3689565, "best approach": "wiki, concept, image", "verif answer": "helmet", "anno approach": "wiki, concept, image", "verif wiki answer": "helmet(0.6819)", "verif concept answer": "helmet(0.5932)", "verif image answer": "helmet(0.6631)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000368956.jpg"}, {"question": "is this a good example of a sea creature or land creature", "gt answer": "land(1.00)<br/>sea(0.60)<br/>good(0.60)", "pred answer": "mammal", "question_id": 2257095, "best approach": "wiki, image", "verif answer": "fish", "anno approach": "wiki, concept, image", "verif wiki answer": "land(0.7010)", "verif concept answer": "fish(0.6724)", "verif image answer": "land(0.6741)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225709.jpg"}, {"question": "what caused the erosion of the ground under the animals", "gt answer": "rain(1.00)<br/>flood(0.60)<br/>walk(0.60)<br/>log(0.60)", "pred answer": "erosion", "question_id": 1207345, "best approach": "wiki", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "rain(0.6733)", "verif concept answer": "log(0.5236)", "verif image answer": "log(0.6471)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000120734.jpg"}, {"question": "what is the flavor of the liquid in this jar", "gt answer": "caramel(1.00)<br/>chocolate(1.00)", "pred answer": "tea", "question_id": 3061135, "best approach": "wiki, concept, image", "verif answer": "caramel", "anno approach": "wiki, concept, image", "verif wiki answer": "caramel(0.7145)", "verif concept answer": "caramel(0.7164)", "verif image answer": "caramel(0.7019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306113.jpg"}, {"question": "to what culture does this cuisine belong", "gt answer": "american(1.00)<br/>us(0.60)", "pred answer": "asian", "question_id": 507915, "best approach": "wiki, concept", "verif answer": "american", "anno approach": "wiki, concept, image", "verif wiki answer": "american(0.6340)", "verif concept answer": "american(0.6504)", "verif image answer": "asia(0.6915)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050791.jpg"}, {"question": "what lens is being used here", "gt answer": "wide angle(1.00)", "pred answer": "fisheye", "question_id": 5266635, "best approach": "", "verif answer": "fisheye", "anno approach": "wiki, concept, image", "verif wiki answer": "fisheye(0.7299)", "verif concept answer": "fisheye(0.7289)", "verif image answer": "fisheye(0.6887)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526663.jpg"}, {"question": "why is the man on a horse", "gt answer": "guard(1.00)<br/>show(0.60)", "pred answer": "parade", "question_id": 3488655, "best approach": "concept", "verif answer": "circus", "anno approach": "wiki, concept, image", "verif wiki answer": "herd(0.7219)", "verif concept answer": "guard(0.6861)", "verif image answer": "party(0.5873)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348865.jpg"}, {"question": "why do cats perform this action on themselves", "gt answer": "clean(1.00)", "pred answer": "play", "question_id": 123155, "best approach": "", "verif answer": "clean", "anno approach": "wiki, concept, image", "verif wiki answer": "messy(0.7226)", "verif concept answer": "messy(0.6625)", "verif image answer": "messy(0.7305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012315.jpg"}, {"question": "is this a city bus or a tour bus", "gt answer": "tour bus(1.00)<br/>tour(1.00)", "pred answer": "public", "question_id": 4968915, "best approach": "wiki, concept", "verif answer": "tourist", "anno approach": "wiki, concept, image", "verif wiki answer": "tour(0.7309)", "verif concept answer": "tour(0.7273)", "verif image answer": "double decker(0.7162)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496891.jpg"}, {"question": "who is on the computer screen", "gt answer": "newscaster(1.00)<br/>man(0.60)", "pred answer": "steve job", "question_id": 76035, "best approach": "wiki", "verif answer": "person", "anno approach": "wiki, concept, image", "verif wiki answer": "man(0.7006)", "verif concept answer": "woman(0.7021)", "verif image answer": "woman(0.6880)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007603.jpg"}, {"question": "what part of the world do these bears live", "gt answer": "alaska(1.00)<br/>north america(0.60)<br/>americas(0.60)<br/>america(0.60)", "pred answer": "africa", "question_id": 4660245, "best approach": "wiki, concept, image", "verif answer": "americas", "anno approach": "wiki, concept, image", "verif wiki answer": "americas(0.6529)", "verif concept answer": "americas(0.7007)", "verif image answer": "americas(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466024.jpg"}, {"question": "what might make this animal 's hide a coveted prize", "gt answer": "design(1.00)<br/>fly(0.60)<br/>stripe(0.60)", "pred answer": "camouflage", "question_id": 155955, "best approach": "image", "verif answer": "stripe", "anno approach": "wiki, concept, image", "verif wiki answer": "stripe(0.7188)", "verif concept answer": "reflect(0.5456)", "verif image answer": "design(0.7211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015595.jpg"}, {"question": "what are the horses wearing", "gt answer": "blanket(1.00)", "pred answer": "coat", "question_id": 1637165, "best approach": "", "verif answer": "coat", "anno approach": "wiki, concept, image", "verif wiki answer": "quilt(0.7148)", "verif concept answer": "quilt(0.7029)", "verif image answer": "quilt(0.6952)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163716.jpg"}, {"question": "what style of jet is this", "gt answer": "fighter(1.00)", "pred answer": "military", "question_id": 5814995, "best approach": "image", "verif answer": "military", "anno approach": "wiki, concept, image", "verif wiki answer": "military(0.6836)", "verif concept answer": "military(0.7051)", "verif image answer": "fighter(0.6718)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000581499.jpg"}, {"question": "what kind of trip would this meal be eaten during", "gt answer": "camp(1.00)", "pred answer": "dinner", "question_id": 3271785, "best approach": "", "verif answer": "school", "anno approach": "wiki, concept, image", "verif wiki answer": "school(0.7052)", "verif concept answer": "school(0.7129)", "verif image answer": "school(0.7196)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327178.jpg"}, {"question": "where is this person going", "gt answer": "vacation(1.00)<br/>airport(0.60)", "pred answer": "home", "question_id": 3951705, "best approach": "wiki", "verif answer": "travel", "anno approach": "wiki, concept, image", "verif wiki answer": "airport(0.6104)", "verif concept answer": "travel(0.7225)", "verif image answer": "restaurant(0.5131)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395170.jpg"}, {"question": "what shape would you call this plate", "gt answer": "square(1.00)<br/>diamond(0.60)", "pred answer": "round", "question_id": 428685, "best approach": "wiki, concept, image", "verif answer": "diamond", "anno approach": "wiki, concept, image", "verif wiki answer": "diamond(0.7263)", "verif concept answer": "diamond(0.7231)", "verif image answer": "diamond(0.6827)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042868.jpg"}, {"question": "what is the line of snow coming off behind the snowboard called", "gt answer": "wake(1.00)<br/>trail(0.60)<br/>spray(0.60)", "pred answer": "ski lift", "question_id": 3323225, "best approach": "wiki", "verif answer": "spray", "anno approach": "wiki, concept, image", "verif wiki answer": "spray(0.7236)", "verif concept answer": "spray paint(0.6832)", "verif image answer": "spray paint(0.6475)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000332322.jpg"}, {"question": "what brand is the hairdryer", "gt answer": "conair(1.00)<br/>brand(0.60)", "pred answer": "crest", "question_id": 3486975, "best approach": "wiki, concept, image", "verif answer": "bic", "anno approach": "wiki, concept, image", "verif wiki answer": "conair(0.6946)", "verif concept answer": "conair(0.5154)", "verif image answer": "conair(0.7308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000348697.jpg"}, {"question": "what kind of structure are the cats on", "gt answer": "ladder(1.00)", "pred answer": "fence", "question_id": 531135, "best approach": "concept", "verif answer": "stair", "anno approach": "wiki, concept, image", "verif wiki answer": "stair(0.6202)", "verif concept answer": "ladder(0.5494)", "verif image answer": "stair(0.7157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053113.jpg"}, {"question": "what type of animal is on this windowsill", "gt answer": "bird(1.00)<br/>pigeon(0.60)", "pred answer": "dog", "question_id": 787975, "best approach": "wiki", "verif answer": "pigeon", "anno approach": "wiki, concept, image", "verif wiki answer": "pigeon(0.7023)", "verif concept answer": "monkey(0.6837)", "verif image answer": "monkey(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078797.jpg"}, {"question": "what do these animals usually build", "gt answer": "nest(1.00)", "pred answer": "house", "question_id": 3374335, "best approach": "wiki, concept, image", "verif answer": "nest", "anno approach": "wiki, concept, image", "verif wiki answer": "nest(0.7278)", "verif concept answer": "nest(0.7130)", "verif image answer": "nest(0.5459)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337433.jpg"}, {"question": "what is the name of the airline for this plane", "gt answer": "sunexpress(1.00)", "pred answer": "united", "question_id": 3671115, "best approach": "wiki, concept", "verif answer": "united", "anno approach": "wiki, concept, image", "verif wiki answer": "sunexpress(0.6901)", "verif concept answer": "sunexpress(0.6787)", "verif image answer": "manual(0.7116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367111.jpg"}, {"question": "what can you do to the square screen", "gt answer": "watch(1.00)", "pred answer": "remote", "question_id": 2782305, "best approach": "", "verif answer": "watch tv", "anno approach": "wiki, concept, image", "verif wiki answer": "tell time(0.7254)", "verif concept answer": "help ship(0.7228)", "verif image answer": "help ship(0.7125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278230.jpg"}, {"question": "what animal is pictured", "gt answer": "dog(1.00)<br/>chihuahua(0.60)", "pred answer": "cat", "question_id": 4648715, "best approach": "wiki, concept, image", "verif answer": "dog", "anno approach": "wiki, concept, image", "verif wiki answer": "dog(0.7213)", "verif concept answer": "dog(0.7022)", "verif image answer": "dog(0.5866)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464871.jpg"}, {"question": "what hardware is this", "gt answer": "mouse(1.00)", "pred answer": "cord", "question_id": 2467945, "best approach": "concept", "verif answer": "keyboard", "anno approach": "wiki, concept, image", "verif wiki answer": "rat(0.6932)", "verif concept answer": "mouse(0.6237)", "verif image answer": "rat(0.6800)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246794.jpg"}, {"question": "why are there umbrellas in this kitchen", "gt answer": "photography(1.00)<br/>take picture(0.60)", "pred answer": "shade", "question_id": 885385, "best approach": "", "verif answer": "take picture", "anno approach": "wiki, concept, image", "verif wiki answer": "wax(0.6088)", "verif concept answer": "wax(0.5687)", "verif image answer": "take photograph(0.7012)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088538.jpg"}, {"question": "how many years does a cat live", "gt answer": "14(1.00)<br/>7(0.60)<br/>20 years(0.60)", "pred answer": "10 years", "question_id": 5054025, "best approach": "wiki, image", "verif answer": "10 years", "anno approach": "wiki, concept, image", "verif wiki answer": "7(0.6740)", "verif concept answer": "10 years(0.6202)", "verif image answer": "20 years(0.7093)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505402.jpg"}, {"question": "what is the main ingredient in this food", "gt answer": "flour(1.00)<br/>yeast(0.60)", "pred answer": "donuts", "question_id": 2480025, "best approach": "wiki", "verif answer": "flour", "anno approach": "wiki, concept, image", "verif wiki answer": "yeast(0.7029)", "verif concept answer": "sugar(0.6859)", "verif image answer": "cheese(0.6626)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248002.jpg"}, {"question": "why do people not ride this type of animal", "gt answer": "wild(1.00)", "pred answer": "zoo", "question_id": 4270135, "best approach": "wiki, image", "verif answer": "wild", "anno approach": "wiki, concept, image", "verif wiki answer": "wild(0.6907)", "verif concept answer": "danger(0.6632)", "verif image answer": "wild(0.6958)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427013.jpg"}, {"question": "who is the sponsor", "gt answer": "polo(1.00)", "pred answer": "wilson", "question_id": 1005165, "best approach": "", "verif answer": "columbia", "anno approach": "wiki, concept, image", "verif wiki answer": "columbia(0.6646)", "verif concept answer": "horse race(0.5736)", "verif image answer": "columbia(0.5277)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100516.jpg"}, {"question": "what do you have to give in exchange for the items displayed here", "gt answer": "money(1.00)<br/>nothing(0.60)<br/>surf board(0.60)", "pred answer": "online", "question_id": 1456905, "best approach": "wiki", "verif answer": "money", "anno approach": "wiki, concept, image", "verif wiki answer": "money(0.6683)", "verif concept answer": "cloth(0.6754)", "verif image answer": "nothing(0.7092)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145690.jpg"}, {"question": "this animal stays with its babies for how long until they are on their own", "gt answer": "1 year(1.00)<br/>10 months(0.60)", "pred answer": "20 years", "question_id": 733875, "best approach": "wiki, concept", "verif answer": "5 years", "anno approach": "wiki, concept, image", "verif wiki answer": "1 year(0.6369)", "verif concept answer": "1 year(0.5678)", "verif image answer": "grandma(0.5281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073387.jpg"}, {"question": "what sport is being advertised on this bench", "gt answer": "bowl(1.00)", "pred answer": "soccer", "question_id": 3011215, "best approach": "", "verif answer": "frisbee", "anno approach": "wiki, concept, image", "verif wiki answer": "wii(0.6111)", "verif concept answer": "wii(0.6532)", "verif image answer": "wii(0.5796)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301121.jpg"}, {"question": "what is a baby of this animal called", "gt answer": "kitten(1.00)", "pred answer": "puppy", "question_id": 5537195, "best approach": "wiki, image", "verif answer": "feline", "anno approach": "wiki, concept, image", "verif wiki answer": "kitten(0.7275)", "verif concept answer": "regular(0.7214)", "verif image answer": "kitten(0.7028)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553719.jpg"}, {"question": "what player is ranked highest in this sport", "gt answer": "mike trout(1.00)<br/>pitcher(0.60)", "pred answer": "batter", "question_id": 1721975, "best approach": "image", "verif answer": "batter", "anno approach": "wiki, concept, image", "verif wiki answer": "babe ruth(0.7197)", "verif concept answer": "babe ruth(0.7224)", "verif image answer": "mike trout(0.7084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000172197.jpg"}, {"question": "what is the medical term for the part of the body that is sticking out of this woman 's mouth", "gt answer": "tongue(1.00)", "pred answer": "muscle", "question_id": 3775785, "best approach": "", "verif answer": "tongue", "anno approach": "wiki, concept, image", "verif wiki answer": "mouth(0.7201)", "verif concept answer": "mouth(0.6086)", "verif image answer": "mouth(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377578.jpg"}, {"question": "what 's a land vehicle form a cartoon names thomas", "gt answer": "train(1.00)<br/>thomas train(0.60)", "pred answer": "truck", "question_id": 4810915, "best approach": "wiki", "verif answer": "transport", "anno approach": "wiki, concept, image", "verif wiki answer": "train(0.5766)", "verif concept answer": "transport(0.7055)", "verif image answer": "transport(0.6036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481091.jpg"}, {"question": "what commonly happens in this room", "gt answer": "shower(1.00)<br/>bath(0.60)", "pred answer": "wash", "question_id": 4794175, "best approach": "image", "verif answer": "bathroom", "anno approach": "wiki, concept, image", "verif wiki answer": "bathtub(0.6685)", "verif concept answer": "bath(0.6703)", "verif image answer": "shower(0.7218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479417.jpg"}, {"question": "where is this", "gt answer": "saudi arabia(1.00)<br/>desert(0.60)<br/>dubai(0.60)<br/>beach(0.60)", "pred answer": "city", "question_id": 1967235, "best approach": "wiki, concept, image", "verif answer": "beach", "anno approach": "wiki, concept, image", "verif wiki answer": "dubai(0.7090)", "verif concept answer": "beach(0.6497)", "verif image answer": "dubai(0.7098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000196723.jpg"}, {"question": "is she a mother or coach", "gt answer": "mother(1.00)<br/>coach(1.00)", "pred answer": "roger federer", "question_id": 1020245, "best approach": "concept", "verif answer": "coach", "anno approach": "wiki, concept, image", "verif wiki answer": "right(0.7286)", "verif concept answer": "coach(0.6875)", "verif image answer": "samsonite(0.5079)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000102024.jpg"}, {"question": "why are there so many dogs in one place", "gt answer": "dog walker(1.00)<br/>stray(0.60)", "pred answer": "parade", "question_id": 5441175, "best approach": "concept", "verif answer": "curious", "anno approach": "wiki, concept, image", "verif wiki answer": "curious(0.6651)", "verif concept answer": "stray(0.6150)", "verif image answer": "curious(0.7010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000544117.jpg"}, {"question": "what loony tune character is in this photo", "gt answer": "tweety(1.00)", "pred answer": "mickey mouse", "question_id": 4618785, "best approach": "wiki, concept, image", "verif answer": "john", "anno approach": "wiki, concept, image", "verif wiki answer": "tweety(0.7249)", "verif concept answer": "tweety(0.7287)", "verif image answer": "tweety(0.7303)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461878.jpg"}, {"question": "what nutrient is received when the food depicted is eaten", "gt answer": "calcium(1.00)<br/>protein(0.60)<br/>carbohydrate(0.60)", "pred answer": "vitamin c", "question_id": 2677195, "best approach": "", "verif answer": "calcium", "anno approach": "wiki, concept, image", "verif wiki answer": "vegetable(0.6698)", "verif concept answer": "vegetable(0.7056)", "verif image answer": "fiber(0.6130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000267719.jpg"}, {"question": "what positons do these baseball players play", "gt answer": "outfield(1.00)<br/>batter(0.60)", "pred answer": "dodger", "question_id": 2996795, "best approach": "wiki", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "outfield(0.6707)", "verif concept answer": "baseball(0.5815)", "verif image answer": "bat(0.6981)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000299679.jpg"}, {"question": "what does the sign in the reflection say", "gt answer": "1 way(1.00)", "pred answer": "speed limit", "question_id": 1671185, "best approach": "", "verif answer": "1 way", "anno approach": "wiki, concept, image", "verif wiki answer": "no entry(0.7301)", "verif concept answer": "no entry(0.7268)", "verif image answer": "direction(0.5315)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167118.jpg"}, {"question": "what region of the world can these animals be found", "gt answer": "arctic(1.00)<br/>norway(0.60)<br/>alaska(0.60)", "pred answer": "asia", "question_id": 3017475, "best approach": "wiki, image", "verif answer": "norway", "anno approach": "wiki, concept, image", "verif wiki answer": "alaska(0.6199)", "verif concept answer": "cold(0.6040)", "verif image answer": "norway(0.6978)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301747.jpg"}, {"question": "who manufactures this truck", "gt answer": "toyota(1.00)", "pred answer": "ford", "question_id": 3249015, "best approach": "", "verif answer": "ford", "anno approach": "wiki, concept, image", "verif wiki answer": "lexus(0.7293)", "verif concept answer": "fiat(0.7195)", "verif image answer": "fiat(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324901.jpg"}, {"question": "what ingredient in this tooth paste negatively effects memory", "gt answer": "flouride(1.00)", "pred answer": "toothpaste", "question_id": 3752085, "best approach": "concept", "verif answer": "cut", "anno approach": "wiki, concept, image", "verif wiki answer": "cut(0.5456)", "verif concept answer": "flouride(0.5396)", "verif image answer": "cut(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375208.jpg"}, {"question": "what are the people doing", "gt answer": "cycling(1.00)<br/>stand(0.60)", "pred answer": "game", "question_id": 2767215, "best approach": "wiki", "verif answer": "ride", "anno approach": "wiki, concept, image", "verif wiki answer": "stand(0.7116)", "verif concept answer": "bike(0.6429)", "verif image answer": "bike(0.7260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276721.jpg"}, {"question": "the dog is cuddling with what kind of animal", "gt answer": "stuffed(1.00)<br/>tiger(0.60)", "pred answer": "dog", "question_id": 405805, "best approach": "wiki", "verif answer": "bear", "anno approach": "wiki, concept, image", "verif wiki answer": "stuffed(0.7247)", "verif concept answer": "bear(0.7054)", "verif image answer": "bear(0.7205)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040580.jpg"}, {"question": "what is the dog in this image doing", "gt answer": "read(1.00)", "pred answer": "play", "question_id": 4602875, "best approach": "", "verif answer": "eat", "anno approach": "wiki, concept, image", "verif wiki answer": "sleep(0.7161)", "verif concept answer": "sleep(0.6991)", "verif image answer": "eat(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000460287.jpg"}, {"question": "how do the subjects pictured move from one place to another", "gt answer": "swim(1.00)<br/>fly(0.60)", "pred answer": "trunk", "question_id": 2017225, "best approach": "wiki", "verif answer": "swim", "anno approach": "wiki, concept, image", "verif wiki answer": "fly(0.7058)", "verif concept answer": "float(0.7075)", "verif image answer": "fish(0.6640)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201722.jpg"}, {"question": "what is the choking hazard in the image", "gt answer": "orange(1.00)<br/>seed(0.60)", "pred answer": "vision", "question_id": 2826925, "best approach": "concept, image", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin c(0.7078)", "verif concept answer": "orange(0.5556)", "verif image answer": "orange(0.6516)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282692.jpg"}, {"question": "what is the main attraction presented in this picture", "gt answer": "lincoln park zoo(1.00)<br/>zoo(1.00)", "pred answer": "build", "question_id": 1529135, "best approach": "image", "verif answer": "zoo", "anno approach": "wiki, concept, image", "verif wiki answer": "african(0.6648)", "verif concept answer": "african(0.6550)", "verif image answer": "zoo(0.6974)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000152913.jpg"}, {"question": "what kind of building", "gt answer": "train station(1.00)", "pred answer": "station", "question_id": 2299495, "best approach": "", "verif answer": "station", "anno approach": "wiki, concept, image", "verif wiki answer": "station(0.7300)", "verif concept answer": "station(0.7287)", "verif image answer": "india(0.6755)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000229949.jpg"}, {"question": "what group of people are known for making quilts", "gt answer": "amish(1.00)", "pred answer": "farmer", "question_id": 1105365, "best approach": "", "verif answer": "catholic", "anno approach": "wiki, concept, image", "verif wiki answer": "public(0.7251)", "verif concept answer": "public(0.7129)", "verif image answer": "catholic(0.6847)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000110536.jpg"}, {"question": "what brand is being advertised", "gt answer": "pepsi(1.00)", "pred answer": "speed stick", "question_id": 5576595, "best approach": "", "verif answer": "pepsi", "anno approach": "wiki, concept, image", "verif wiki answer": "adidas(0.7236)", "verif concept answer": "adidas(0.6909)", "verif image answer": "coke(0.6509)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557659.jpg"}, {"question": "how can you learn that sport", "gt answer": "practice(1.00)", "pred answer": "ski", "question_id": 1606245, "best approach": "", "verif answer": "carefully", "anno approach": "wiki, concept, image", "verif wiki answer": "snowboard(0.7258)", "verif concept answer": "snowboard(0.7282)", "verif image answer": "snowboard(0.7137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160624.jpg"}, {"question": "what company manufactures the devices these people are holding", "gt answer": "nintendo(1.00)<br/>wii(1.00)", "pred answer": "lg", "question_id": 1039325, "best approach": "wiki, concept, image", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "nintendo(0.6739)", "verif concept answer": "nintendo(0.7206)", "verif image answer": "nintendo(0.7069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103932.jpg"}, {"question": "what kind of flowers are these", "gt answer": "lilac(1.00)<br/>daisy(0.60)", "pred answer": "rose", "question_id": 3119885, "best approach": "", "verif answer": "tulip", "anno approach": "wiki, concept, image", "verif wiki answer": "tulip(0.7095)", "verif concept answer": "tulip(0.7188)", "verif image answer": "tulip(0.7238)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000311988.jpg"}, {"question": "is this a street bike or dirt bike", "gt answer": "dirt(1.00)<br/>dirt bike(1.00)", "pred answer": "road", "question_id": 733485, "best approach": "wiki, concept", "verif answer": "road", "anno approach": "wiki, concept, image", "verif wiki answer": "dirt(0.7290)", "verif concept answer": "dirt bike(0.7253)", "verif image answer": "bmx(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073348.jpg"}, {"question": "what sandwich is that", "gt answer": "steak(1.00)<br/>sub(0.60)", "pred answer": "egg salad", "question_id": 2834455, "best approach": "", "verif answer": "meat", "anno approach": "wiki, concept, image", "verif wiki answer": "meat(0.7013)", "verif concept answer": "meat(0.7054)", "verif image answer": "fry(0.6967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000283445.jpg"}, {"question": "what temperature is the water considered too cold for this activity", "gt answer": "60(1.00)<br/>70(0.60)", "pred answer": "cold", "question_id": 221235, "best approach": "", "verif answer": "70", "anno approach": "wiki, concept, image", "verif wiki answer": "80(0.5898)", "verif concept answer": "80(0.5730)", "verif image answer": "80(0.6949)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000022123.jpg"}, {"question": "what kind of storm threatens areas like the one pictured in the us every year in the late summer and fall", "gt answer": "hurricane(1.00)", "pred answer": "rain", "question_id": 649485, "best approach": "", "verif answer": "wind", "anno approach": "wiki, concept, image", "verif wiki answer": "wind(0.7081)", "verif concept answer": "wind(0.6337)", "verif image answer": "drown(0.7040)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064948.jpg"}, {"question": "what is the cat standing on", "gt answer": "table(1.00)", "pred answer": "bed", "question_id": 4024485, "best approach": "", "verif answer": "table", "anno approach": "wiki, concept, image", "verif wiki answer": "on table(0.7235)", "verif concept answer": "on table(0.7193)", "verif image answer": "on table(0.7057)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000402448.jpg"}, {"question": "what piece of furniture is this child in", "gt answer": "crib(1.00)", "pred answer": "bed", "question_id": 1950625, "best approach": "wiki, image", "verif answer": "bedroom", "anno approach": "wiki, concept, image", "verif wiki answer": "crib(0.7136)", "verif concept answer": "desk(0.7081)", "verif image answer": "crib(0.7181)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000195062.jpg"}, {"question": "is this legal or illegal to ride a skate board", "gt answer": "legal(1.00)", "pred answer": "illegal", "question_id": 4629445, "best approach": "", "verif answer": "illegal", "anno approach": "wiki, concept, image", "verif wiki answer": "illegal(0.7307)", "verif concept answer": "illegal(0.7284)", "verif image answer": "legally(0.6913)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000462944.jpg"}, {"question": "are these zebras free or locked up", "gt answer": "locked up(1.00)", "pred answer": "free", "question_id": 4454275, "best approach": "", "verif answer": "free", "anno approach": "wiki, concept, image", "verif wiki answer": "captivity(0.7267)", "verif concept answer": "captivity(0.7218)", "verif image answer": "lost(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000445427.jpg"}, {"question": "what is on the girl 's neck", "gt answer": "necklace(1.00)", "pred answer": "tie", "question_id": 1514865, "best approach": "", "verif answer": "necklace", "anno approach": "wiki, concept, image", "verif wiki answer": "bridle(0.6159)", "verif concept answer": "bridle(0.6580)", "verif image answer": "bridle(0.5714)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151486.jpg"}, {"question": "what day is it common for people to do the activity that the woman is doing here", "gt answer": "saturday(1.00)<br/>spring(0.60)<br/>windy day(0.60)", "pred answer": "windy", "question_id": 3427045, "best approach": "concept, image", "verif answer": "summer", "anno approach": "wiki, concept, image", "verif wiki answer": "windy day(0.7110)", "verif concept answer": "saturday(0.7226)", "verif image answer": "saturday(0.6840)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342704.jpg"}, {"question": "name the aircraft model shown in this picture", "gt answer": "boeing 737(1.00)<br/>747(0.60)<br/>boeing(0.60)", "pred answer": "glider", "question_id": 4373555, "best approach": "concept", "verif answer": "airplane", "anno approach": "wiki, concept, image", "verif wiki answer": "747(0.7047)", "verif concept answer": "boeing 737(0.7060)", "verif image answer": "boeing(0.7218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437355.jpg"}, {"question": "when this white stuff has not markings and is pristine it is called what kind of snow", "gt answer": "fresh(1.00)<br/>virgin(0.60)", "pred answer": "snow", "question_id": 5404795, "best approach": "", "verif answer": "salty", "anno approach": "wiki, concept, image", "verif wiki answer": "wild(0.5996)", "verif concept answer": "wild(0.6704)", "verif image answer": "salty(0.6457)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540479.jpg"}, {"question": "what breed of cat is this", "gt answer": "siamese(1.00)", "pred answer": "tuxedo", "question_id": 2089945, "best approach": "wiki, image", "verif answer": "siamese", "anno approach": "wiki, concept, image", "verif wiki answer": "siamese(0.6229)", "verif concept answer": "persian(0.6626)", "verif image answer": "siamese(0.6788)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208994.jpg"}, {"question": "what kind of truck is this", "gt answer": "monster truck(1.00)<br/>diesel(0.60)", "pred answer": "tow", "question_id": 958795, "best approach": "", "verif answer": "truck", "anno approach": "wiki, concept, image", "verif wiki answer": "offroading(0.7230)", "verif concept answer": "offroading(0.6987)", "verif image answer": "truck(0.6633)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000095879.jpg"}, {"question": "why would some consider this a sign of bad luck", "gt answer": "superstition(1.00)<br/>black cat(0.60)", "pred answer": "run", "question_id": 4356985, "best approach": "wiki, concept, image", "verif answer": "black cat", "anno approach": "wiki, concept, image", "verif wiki answer": "black cat(0.6128)", "verif concept answer": "black cat(0.6648)", "verif image answer": "black cat(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435698.jpg"}, {"question": "what kinds of food does this animal eat", "gt answer": "bug(1.00)", "pred answer": "seed", "question_id": 1884545, "best approach": "", "verif answer": "seed", "anno approach": "wiki, concept, image", "verif wiki answer": "seed(0.7285)", "verif concept answer": "spider(0.6448)", "verif image answer": "seed(0.7137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000188454.jpg"}, {"question": "why skates hobby or work", "gt answer": "hobby(1.00)", "pred answer": "fun", "question_id": 2039895, "best approach": "", "verif answer": "fun", "anno approach": "wiki, concept, image", "verif wiki answer": "transport(0.7184)", "verif concept answer": "transport(0.7295)", "verif image answer": "transport(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203989.jpg"}, {"question": "who invented the vehicles shown here", "gt answer": "blaise pascal(1.00)<br/>engineer(0.60)", "pred answer": "bill gate", "question_id": 218115, "best approach": "image", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "man(0.5729)", "verif concept answer": "driver(0.6378)", "verif image answer": "blaise pascal(0.6876)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000021811.jpg"}, {"question": "what brand is this cover", "gt answer": "target(1.00)<br/>quilt(0.60)", "pred answer": "gucci", "question_id": 2967605, "best approach": "", "verif answer": "rayban", "anno approach": "wiki, concept, image", "verif wiki answer": "rayban(0.7101)", "verif concept answer": "rayban(0.6962)", "verif image answer": "rayban(0.6902)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296760.jpg"}, {"question": "when do you eat this course in a five course meal", "gt answer": "first(1.00)<br/>salad(0.60)", "pred answer": "dinner", "question_id": 3794335, "best approach": "wiki, image", "verif answer": "pasta", "anno approach": "wiki, concept, image", "verif wiki answer": "first(0.6949)", "verif concept answer": "pasta(0.6497)", "verif image answer": "first(0.6898)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379433.jpg"}, {"question": "what show is this", "gt answer": "circus(1.00)<br/>ballet(0.60)", "pred answer": "elephant", "question_id": 2191695, "best approach": "concept", "verif answer": "elephant", "anno approach": "wiki, concept, image", "verif wiki answer": "elephant(0.6778)", "verif concept answer": "circus(0.6984)", "verif image answer": "elephant(0.6133)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219169.jpg"}, {"question": "which of these two people might be said to be flirting", "gt answer": "woman(1.00)<br/>man(0.60)<br/>female(0.60)<br/>both(0.60)", "pred answer": "mother and son", "question_id": 5057005, "best approach": "wiki, concept, image", "verif answer": "female", "anno approach": "wiki, concept, image", "verif wiki answer": "woman(0.7275)", "verif concept answer": "woman(0.7048)", "verif image answer": "woman(0.6550)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505700.jpg"}, {"question": "what name is on the side of the double decker bus", "gt answer": "simonds(1.00)", "pred answer": "5 star", "question_id": 2263265, "best approach": "", "verif answer": "tow", "anno approach": "wiki, concept, image", "verif wiki answer": "wheel on bus(0.7276)", "verif concept answer": "wheel on bus(0.6894)", "verif image answer": "wheel on bus(0.6996)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226326.jpg"}, {"question": "what vitamins do you get from the fruits", "gt answer": "c(1.00)<br/>vitamin c(0.60)<br/>d(0.60)", "pred answer": "beta carotene", "question_id": 4700915, "best approach": "concept", "verif answer": "beta carotene", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin c(0.7094)", "verif concept answer": "c(0.7001)", "verif image answer": "vitamin c(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470091.jpg"}, {"question": "what decade would this item have been uses", "gt answer": "1940's(1.00)<br/>1940(0.60)<br/>1930's(0.60)", "pred answer": "wwii", "question_id": 429775, "best approach": "", "verif answer": "1940's", "anno approach": "wiki, concept, image", "verif wiki answer": "1930s(0.6965)", "verif concept answer": "1800s(0.6826)", "verif image answer": "1800s(0.6746)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042977.jpg"}, {"question": "what language is on the street sign", "gt answer": "spanish(1.00)<br/>english(0.60)<br/>french(0.60)", "pred answer": "chinese", "question_id": 5389995, "best approach": "wiki", "verif answer": "french", "anno approach": "wiki, concept, image", "verif wiki answer": "english(0.6841)", "verif concept answer": "italian(0.6137)", "verif image answer": "white(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538999.jpg"}, {"question": "what event is taking place here", "gt answer": "rodeo(1.00)<br/>horse show(0.60)", "pred answer": "horse race", "question_id": 3101565, "best approach": "", "verif answer": "horse race", "anno approach": "wiki, concept, image", "verif wiki answer": "horse race(0.7283)", "verif concept answer": "horse race(0.7139)", "verif image answer": "horse race(0.7151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310156.jpg"}, {"question": "what kind of plant is being covered by the white cloth", "gt answer": "rose bush(1.00)<br/>rose(0.60)", "pred answer": "flower", "question_id": 4705395, "best approach": "wiki", "verif answer": "lily", "anno approach": "wiki, concept, image", "verif wiki answer": "rose(0.7257)", "verif concept answer": "aloe(0.6829)", "verif image answer": "aloe(0.6069)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470539.jpg"}, {"question": "what type of stone are these walls made of", "gt answer": "limestone(1.00)<br/>brick(0.60)<br/>rock(0.60)<br/>clay(0.60)", "pred answer": "stone", "question_id": 3034535, "best approach": "wiki, concept, image", "verif answer": "clay", "anno approach": "wiki, concept, image", "verif wiki answer": "clay(0.7014)", "verif concept answer": "clay(0.6833)", "verif image answer": "brick(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303453.jpg"}, {"question": "what style of columns are used here", "gt answer": "roman(1.00)<br/>greek(1.00)", "pred answer": "gothic", "question_id": 5322775, "best approach": "wiki, concept, image", "verif answer": "gothic", "anno approach": "wiki, concept, image", "verif wiki answer": "roman(0.6819)", "verif concept answer": "roman(0.6339)", "verif image answer": "greek(0.6997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532277.jpg"}, {"question": "what is this dog doing", "gt answer": "smell(1.00)<br/>urine(0.60)", "pred answer": "swim", "question_id": 2230895, "best approach": "wiki, concept, image", "verif answer": "smell", "anno approach": "wiki, concept, image", "verif wiki answer": "smell(0.7209)", "verif concept answer": "smell(0.6411)", "verif image answer": "smell(0.5128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223089.jpg"}, {"question": "what type of flowers are in the image", "gt answer": "daisy(1.00)<br/>pansy(0.60)", "pred answer": "lily", "question_id": 1313525, "best approach": "image", "verif answer": "lily", "anno approach": "wiki, concept, image", "verif wiki answer": "pansy(0.7199)", "verif concept answer": "rose(0.6959)", "verif image answer": "daisy(0.7063)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000131352.jpg"}, {"question": "this meal would be high in what kind of fat", "gt answer": "saturated(1.00)<br/>omega 3(0.60)", "pred answer": "meat", "question_id": 3404765, "best approach": "concept", "verif answer": "saturated", "anno approach": "wiki, concept, image", "verif wiki answer": "omega 3(0.6614)", "verif concept answer": "saturated(0.6465)", "verif image answer": "solid(0.6899)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340476.jpg"}, {"question": "this bench is made from wood partitions that resemble the sticks in what sweet treat", "gt answer": "popsicle(1.00)", "pred answer": "cherry", "question_id": 2877185, "best approach": "wiki, concept, image", "verif answer": "umbrella", "anno approach": "wiki, concept, image", "verif wiki answer": "popsicle(0.7289)", "verif concept answer": "popsicle(0.7261)", "verif image answer": "popsicle(0.6724)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287718.jpg"}, {"question": "what shape would you say the building is", "gt answer": "rectangle(1.00)<br/>square(0.60)", "pred answer": "triangle", "question_id": 826505, "best approach": "", "verif answer": "octagon", "anno approach": "wiki, concept, image", "verif wiki answer": "octagon(0.7256)", "verif concept answer": "octagon(0.6892)", "verif image answer": "octagon(0.7220)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082650.jpg"}, {"question": "what are the colored mushrooms from", "gt answer": "mario(1.00)", "pred answer": "disney", "question_id": 2731035, "best approach": "", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "amazon(0.6884)", "verif concept answer": "amazon(0.6737)", "verif image answer": "wii(0.7089)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273103.jpg"}, {"question": "is this a snack or meal", "gt answer": "meal(1.00)", "pred answer": "snack", "question_id": 5782615, "best approach": "", "verif answer": "snack", "anno approach": "wiki, concept, image", "verif wiki answer": "snack(0.7274)", "verif concept answer": "snack(0.7302)", "verif image answer": "snack(0.6993)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000578261.jpg"}, {"question": "what is she doing with the animal", "gt answer": "pet(1.00)<br/>wash(1.00)<br/>feed(0.60)", "pred answer": "wax", "question_id": 2630425, "best approach": "concept, image", "verif answer": "shear", "anno approach": "wiki, concept, image", "verif wiki answer": "de ice(0.7240)", "verif concept answer": "wash(0.6980)", "verif image answer": "wash(0.6546)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263042.jpg"}, {"question": "what healthy vegetable is in this picture", "gt answer": "tomato(1.00)", "pred answer": "carrot", "question_id": 5318125, "best approach": "wiki", "verif answer": "tomato", "anno approach": "wiki, concept, image", "verif wiki answer": "tomato(0.6586)", "verif concept answer": "apple(0.7072)", "verif image answer": "pepper(0.7125)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000531812.jpg"}, {"question": "what kind of store is this", "gt answer": "mattress(1.00)", "pred answer": "antique", "question_id": 4018385, "best approach": "", "verif answer": "furniture", "anno approach": "wiki, concept, image", "verif wiki answer": "furniture(0.7153)", "verif concept answer": "bed(0.6855)", "verif image answer": "bed(0.6937)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401838.jpg"}, {"question": "what creature is this kite made in the likeness of", "gt answer": "octopus(1.00)<br/>dragon(0.60)", "pred answer": "bird", "question_id": 4416195, "best approach": "", "verif answer": "bird", "anno approach": "wiki, concept, image", "verif wiki answer": "bird(0.7239)", "verif concept answer": "bird(0.7029)", "verif image answer": "bear(0.7033)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441619.jpg"}, {"question": "what fuel makes this vehicle move", "gt answer": "electricity(1.00)<br/>gas(0.60)", "pred answer": "coal", "question_id": 2484715, "best approach": "", "verif answer": "kerosene", "anno approach": "wiki, concept, image", "verif wiki answer": "kerosene(0.7199)", "verif concept answer": "kerosene(0.7191)", "verif image answer": "kerosene(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248471.jpg"}, {"question": "", "gt answer": "confused(0.60)<br/>sad(0.60)", "pred answer": "happiness", "question_id": 5181585, "best approach": "", "verif answer": "sad", "anno approach": "wiki, concept, image", "verif wiki answer": "hunger(0.6777)", "verif concept answer": "hunger(0.5944)", "verif image answer": "hunger(0.7153)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518158.jpg"}, {"question": "what animal is this lady wearing", "gt answer": "fox(1.00)", "pred answer": "dog", "question_id": 707405, "best approach": "", "verif answer": "lion", "anno approach": "wiki, concept, image", "verif wiki answer": "lion(0.7147)", "verif concept answer": "lion(0.7109)", "verif image answer": "bear(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000070740.jpg"}, {"question": "to board a train at this station you need a what", "gt answer": "ticket(1.00)<br/>pass(0.60)", "pred answer": "stop", "question_id": 205175, "best approach": "image", "verif answer": "bus", "anno approach": "wiki, concept, image", "verif wiki answer": "pass(0.6650)", "verif concept answer": "bus(0.5978)", "verif image answer": "ticket(0.6179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020517.jpg"}, {"question": "what helps direct traffic and prevent accidents", "gt answer": "traffic light(1.00)<br/>stop light(0.60)<br/>light(0.60)<br/>stoplight(0.60)", "pred answer": "streetlight", "question_id": 3065355, "best approach": "wiki, image", "verif answer": "stoplight", "anno approach": "wiki, concept, image", "verif wiki answer": "light(0.6880)", "verif concept answer": "red light(0.6828)", "verif image answer": "light(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306535.jpg"}, {"question": "what appliance is seen behind the girl", "gt answer": "stove(1.00)<br/>oven(1.00)", "pred answer": "refrigerator", "question_id": 1399945, "best approach": "wiki", "verif answer": "refrigerator", "anno approach": "wiki, concept, image", "verif wiki answer": "stove(0.7276)", "verif concept answer": "fryer(0.7227)", "verif image answer": "fryer(0.7174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139994.jpg"}, {"question": "what is the economic status of this area", "gt answer": "poor(1.00)", "pred answer": "good", "question_id": 3904945, "best approach": "wiki", "verif answer": "good", "anno approach": "wiki, concept, image", "verif wiki answer": "poor(0.6891)", "verif concept answer": "starvation(0.6210)", "verif image answer": "potassium(0.5760)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390494.jpg"}, {"question": "what activity would you wear these shoes for", "gt answer": "run(1.00)", "pred answer": "ski", "question_id": 1637155, "best approach": "wiki, concept, image", "verif answer": "run", "anno approach": "wiki, concept, image", "verif wiki answer": "run(0.6993)", "verif concept answer": "run(0.6627)", "verif image answer": "run(0.7063)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000163715.jpg"}, {"question": "what sound does this animal make", "gt answer": "moo(1.00)", "pred answer": "bark", "question_id": 2196795, "best approach": "", "verif answer": "moo", "anno approach": "wiki, concept, image", "verif wiki answer": "baa(0.7140)", "verif concept answer": "neigh(0.7221)", "verif image answer": "neigh(0.7177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219679.jpg"}, {"question": "what is this man doing", "gt answer": "blend(1.00)", "pred answer": "eat", "question_id": 2613055, "best approach": "", "verif answer": "eat", "anno approach": "wiki, concept, image", "verif wiki answer": "eat(0.6183)", "verif concept answer": "eat(0.6491)", "verif image answer": "eat(0.6565)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261305.jpg"}, {"question": "what city is replacing these the fastest", "gt answer": "new york(1.00)<br/>new york city(0.60)<br/>los angeles(0.60)", "pred answer": "washington", "question_id": 2197565, "best approach": "image", "verif answer": "new york city", "anno approach": "wiki, concept, image", "verif wiki answer": "pennsylvania(0.6889)", "verif concept answer": "pennsylvania(0.6773)", "verif image answer": "new york city(0.6707)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219756.jpg"}, {"question": "what chores are these tools commonly used for", "gt answer": "garden(1.00)", "pred answer": "craft", "question_id": 85315, "best approach": "", "verif answer": "yard", "anno approach": "wiki, concept, image", "verif wiki answer": "yard(0.6048)", "verif concept answer": "bench(0.6067)", "verif image answer": "bench(0.6341)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008531.jpg"}, {"question": "what five sided object is the man headed towards", "gt answer": "home plate(1.00)", "pred answer": "ball", "question_id": 4590785, "best approach": "wiki", "verif answer": "home plate", "anno approach": "wiki, concept, image", "verif wiki answer": "home plate(0.7232)", "verif concept answer": "outfield(0.6946)", "verif image answer": "outfield(0.5471)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459078.jpg"}, {"question": "name the type of wood used to make this table in this picture", "gt answer": "mahogany(1.00)<br/>wood(0.60)<br/>oak(0.60)", "pred answer": "cedar", "question_id": 1467605, "best approach": "wiki, concept", "verif answer": "oak", "anno approach": "wiki, concept, image", "verif wiki answer": "mahogany(0.7278)", "verif concept answer": "mahogany(0.7199)", "verif image answer": "wood(0.5386)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146760.jpg"}, {"question": "what food is this", "gt answer": "ramen(1.00)<br/>pasta(1.00)", "pred answer": "soup", "question_id": 2999685, "best approach": "", "verif answer": "soup", "anno approach": "wiki, concept, image", "verif wiki answer": "stir fry(0.7089)", "verif concept answer": "stir fry(0.7252)", "verif image answer": "lo mein(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000299968.jpg"}, {"question": "what language is this", "gt answer": "german(1.00)<br/>french(0.60)", "pred answer": "chinese", "question_id": 3350905, "best approach": "wiki", "verif answer": "english", "anno approach": "wiki, concept, image", "verif wiki answer": "german(0.6877)", "verif concept answer": "american(0.7028)", "verif image answer": "english(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000335090.jpg"}, {"question": "what is the shape of the third building from the left", "gt answer": "rectangle(1.00)", "pred answer": "round", "question_id": 4750195, "best approach": "", "verif answer": "circle", "anno approach": "wiki, concept, image", "verif wiki answer": "circle(0.7089)", "verif concept answer": "circle(0.6973)", "verif image answer": "octagon(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000475019.jpg"}, {"question": "in what desert are these horses", "gt answer": "sahara(1.00)<br/>egyptian(0.60)", "pred answer": "snow", "question_id": 5660605, "best approach": "wiki, concept", "verif answer": "europe", "anno approach": "wiki, concept, image", "verif wiki answer": "sahara(0.7115)", "verif concept answer": "sahara(0.6984)", "verif image answer": "indian(0.6172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566060.jpg"}, {"question": "what does the yellow m stand for", "gt answer": "mcdonalds(1.00)<br/>mcdonald's(0.60)", "pred answer": "stop", "question_id": 186615, "best approach": "concept", "verif answer": "mcdonalds", "anno approach": "wiki, concept, image", "verif wiki answer": "hotdog(0.5680)", "verif concept answer": "mcdonalds(0.5351)", "verif image answer": "mcdonald's(0.5527)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000018661.jpg"}, {"question": "what shape is on the women hat", "gt answer": "triangle(1.00)<br/>adidas(0.60)", "pred answer": "round", "question_id": 499335, "best approach": "image", "verif answer": "diamond", "anno approach": "wiki, concept, image", "verif wiki answer": "in half(0.7303)", "verif concept answer": "diamond(0.7268)", "verif image answer": "triangle(0.6996)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000049933.jpg"}, {"question": "where would you see this many picnic tables", "gt answer": "park(1.00)", "pred answer": "central park", "question_id": 4737055, "best approach": "wiki", "verif answer": "park", "anno approach": "wiki, concept, image", "verif wiki answer": "park(0.6935)", "verif concept answer": "skate park(0.7075)", "verif image answer": "skate park(0.7045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473705.jpg"}, {"question": "where can this meal be purchased", "gt answer": "restaurant(1.00)", "pred answer": "diner", "question_id": 4124005, "best approach": "image", "verif answer": "cafe", "anno approach": "wiki, concept, image", "verif wiki answer": "someplace fancier(0.6658)", "verif concept answer": "someplace fancier(0.6742)", "verif image answer": "restaurant(0.5483)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412400.jpg"}, {"question": "", "gt answer": "dachsund(0.60)<br/>black labrador(0.60)<br/>labrador(0.60)", "pred answer": "lab", "question_id": 792445, "best approach": "wiki, concept, image", "verif answer": "lab", "anno approach": "wiki, concept, image", "verif wiki answer": "labrador(0.6399)", "verif concept answer": "labrador(0.6116)", "verif image answer": "labrador(0.6517)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079244.jpg"}, {"question": "what emotion are the people in the photo experiencing towards each other", "gt answer": "love(1.00)", "pred answer": "happiness", "question_id": 2615215, "best approach": "", "verif answer": "happiness", "anno approach": "wiki, concept, image", "verif wiki answer": "happiness(0.7281)", "verif concept answer": "anger(0.7095)", "verif image answer": "sad(0.7030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261521.jpg"}, {"question": "what does this animal have in common with the country of thailand", "gt answer": "siamese(1.00)<br/>color(0.60)", "pred answer": "cat", "question_id": 4055415, "best approach": "concept, image", "verif answer": "color", "anno approach": "wiki, concept, image", "verif wiki answer": "sleep(0.6174)", "verif concept answer": "siamese(0.5804)", "verif image answer": "siamese(0.6778)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405541.jpg"}, {"question": "where can i buy bags like this dog is wearing", "gt answer": "amazon(1.00)<br/>store(0.60)<br/>pet store(0.60)", "pred answer": "walmart", "question_id": 3743726, "best approach": "wiki, concept", "verif answer": "pet store", "anno approach": "wiki, concept, image", "verif wiki answer": "amazon(0.7257)", "verif concept answer": "amazon(0.7286)", "verif image answer": "target(0.7213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374372.jpg"}, {"question": "how much does this creature weigh on average", "gt answer": "ton(1.00)<br/>1000(0.60)<br/>500 lbs(0.60)", "pred answer": "100 lbs", "question_id": 4646165, "best approach": "wiki", "verif answer": "ton", "anno approach": "wiki, concept, image", "verif wiki answer": "ton(0.7179)", "verif concept answer": "500 pounds(0.7044)", "verif image answer": "thousand(0.7152)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000464616.jpg"}, {"question": "what is the truck transporting", "gt answer": "garbage(1.00)<br/>furniture(0.60)<br/>good(0.60)<br/>food(0.60)", "pred answer": "trailer", "question_id": 2533325, "best approach": "wiki", "verif answer": "garbage", "anno approach": "wiki, concept, image", "verif wiki answer": "garbage(0.6958)", "verif concept answer": "food(0.6986)", "verif image answer": "good(0.7130)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253332.jpg"}, {"question": "how often do these bathrooms get cleaned", "gt answer": "never(1.00)<br/>once(0.60)<br/>rarely(0.60)", "pred answer": "not often", "question_id": 1497375, "best approach": "concept", "verif answer": "not often", "anno approach": "wiki, concept, image", "verif wiki answer": "rarely(0.6744)", "verif concept answer": "never(0.6771)", "verif image answer": "yearly(0.6878)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000149737.jpg"}, {"question": "what type of eyewear is this person wearing in this image", "gt answer": "goggle(1.00)", "pred answer": "sunglasses", "question_id": 1619585, "best approach": "", "verif answer": "sunglasses", "anno approach": "wiki, concept, image", "verif wiki answer": "helmet(0.7124)", "verif concept answer": "sunglasses(0.6192)", "verif image answer": "sunglasses(0.5948)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161958.jpg"}, {"question": "where in the supermarket would you find the vegetables depicted", "gt answer": "produce(1.00)<br/>produce department(0.60)", "pred answer": "grocery store", "question_id": 3555895, "best approach": "wiki, concept", "verif answer": "supermarket", "anno approach": "wiki, concept, image", "verif wiki answer": "produce(0.7199)", "verif concept answer": "produce(0.6671)", "verif image answer": "farmer(0.6692)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355589.jpg"}, {"question": "what country might this be", "gt answer": "vietnam(1.00)<br/>japan(0.60)", "pred answer": "china", "question_id": 4693015, "best approach": "wiki, concept", "verif answer": "china", "anno approach": "wiki, concept, image", "verif wiki answer": "japan(0.7054)", "verif concept answer": "japan(0.7063)", "verif image answer": "thailand(0.7040)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469301.jpg"}, {"question": "how is the machine in this photo operated", "gt answer": "engine(1.00)<br/>motor(0.60)<br/>gas(0.60)", "pred answer": "gasoline", "question_id": 4248205, "best approach": "wiki, image", "verif answer": "motor", "anno approach": "wiki, concept, image", "verif wiki answer": "engine(0.6748)", "verif concept answer": "track(0.6128)", "verif image answer": "engine(0.6305)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424820.jpg"}, {"question": "in what type of location is this scene", "gt answer": "farm(1.00)", "pred answer": "stable", "question_id": 2207995, "best approach": "", "verif answer": "stable", "anno approach": "wiki, concept, image", "verif wiki answer": "stable(0.7166)", "verif concept answer": "stable(0.7242)", "verif image answer": "stable(0.7093)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220799.jpg"}, {"question": "what channel is likely broadcasting this game", "gt answer": "espn(1.00)", "pred answer": "cnn", "question_id": 833325, "best approach": "image", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "youtube(0.7136)", "verif concept answer": "youtube(0.6577)", "verif image answer": "espn(0.7022)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083332.jpg"}, {"question": "in children 's readers this dog would be named spot and be accompanied by a girl and boy named what", "gt answer": "dick and jane(1.00)<br/>jack and jill(0.60)", "pred answer": "friend", "question_id": 4352945, "best approach": "", "verif answer": "puppy", "anno approach": "wiki, concept, image", "verif wiki answer": "puppy(0.7256)", "verif concept answer": "puppy(0.5859)", "verif image answer": "puppy(0.7136)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000435294.jpg"}, {"question": "what is on the laptop", "gt answer": "paper(1.00)", "pred answer": "intel", "question_id": 2197525, "best approach": "", "verif answer": "paper", "anno approach": "wiki, concept, image", "verif wiki answer": "tissue(0.6960)", "verif concept answer": "tissue(0.6649)", "verif image answer": "ceramic(0.6759)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000219752.jpg"}, {"question": "why is this a comfortable situation", "gt answer": "sunlight(1.00)<br/>warm(0.60)", "pred answer": "bed", "question_id": 5167265, "best approach": "wiki, concept", "verif answer": "sunny", "anno approach": "wiki, concept, image", "verif wiki answer": "sunlight(0.5488)", "verif concept answer": "sunlight(0.6028)", "verif image answer": "sunny(0.6712)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516726.jpg"}, {"question": "what activity did this person do to receive that item", "gt answer": "cut hair(1.00)<br/>haircut(0.60)<br/>cut(0.60)<br/>hair(0.60)", "pred answer": "sew", "question_id": 4894635, "best approach": "wiki, concept, image", "verif answer": "hair", "anno approach": "wiki, concept, image", "verif wiki answer": "cut hair(0.6395)", "verif concept answer": "cut hair(0.6745)", "verif image answer": "cut hair(0.6961)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489463.jpg"}, {"question": "where will the zookeeper place the food", "gt answer": "basket(1.00)<br/>umbrella(0.60)", "pred answer": "zoo", "question_id": 345315, "best approach": "wiki, concept, image", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "umbrella(0.6008)", "verif concept answer": "umbrella(0.6029)", "verif image answer": "umbrella(0.6490)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000034531.jpg"}, {"question": "what causes the black areas on the side of the house", "gt answer": "shadow(1.00)", "pred answer": "light", "question_id": 4133605, "best approach": "", "verif answer": "reflection", "anno approach": "wiki, concept, image", "verif wiki answer": "reflection(0.7283)", "verif concept answer": "sunset(0.6081)", "verif image answer": "sunset(0.7086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000413360.jpg"}, {"question": "what type of energy can be used for measuring the rate of a reaction", "gt answer": "microwave(1.00)<br/>kinetic(0.60)<br/>electron(0.60)<br/>electric(0.60)", "pred answer": "solar", "question_id": 4317085, "best approach": "image", "verif answer": "microwave", "anno approach": "wiki, concept, image", "verif wiki answer": "electron(0.6997)", "verif concept answer": "kinetic(0.7222)", "verif image answer": "microwave(0.7004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431708.jpg"}, {"question": "what type of pitch is he throwing", "gt answer": "overhand(1.00)<br/>fastball(1.00)", "pred answer": "baseball", "question_id": 4508605, "best approach": "concept, image", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "backhand(0.7277)", "verif concept answer": "overhand(0.7207)", "verif image answer": "fastball(0.7230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450860.jpg"}, {"question": "what is in the sky", "gt answer": "cloud(1.00)<br/>kite(0.60)<br/>bird(0.60)<br/>helicopter(0.60)", "pred answer": "storm", "question_id": 333595, "best approach": "image", "verif answer": "cloud", "anno approach": "wiki, concept, image", "verif wiki answer": "plane(0.7246)", "verif concept answer": "plane(0.7116)", "verif image answer": "helicopter(0.7154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033359.jpg"}, {"question": "what activity is happening", "gt answer": "play(1.00)<br/>dance(0.60)<br/>parade(0.60)", "pred answer": "birthday", "question_id": 3949005, "best approach": "", "verif answer": "sing", "anno approach": "wiki, concept, image", "verif wiki answer": "play game(0.7024)", "verif concept answer": "play game(0.7088)", "verif image answer": "sing(0.7090)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000394900.jpg"}, {"question": "upscale or slovenly interior", "gt answer": "upscale(1.00)", "pred answer": "casual", "question_id": 3410705, "best approach": "wiki, concept, image", "verif answer": "victorian", "anno approach": "wiki, concept, image", "verif wiki answer": "upscale(0.6606)", "verif concept answer": "upscale(0.6028)", "verif image answer": "upscale(0.5388)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000341070.jpg"}, {"question": "what type of animal is this", "gt answer": "polar bear(1.00)<br/>elephant(0.60)<br/>sheep(0.60)", "pred answer": "bear", "question_id": 5293605, "best approach": "wiki", "verif answer": "bear", "anno approach": "wiki, concept, image", "verif wiki answer": "sheep(0.7206)", "verif concept answer": "bear(0.7086)", "verif image answer": "bear(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529360.jpg"}, {"question": "what did the plane just do", "gt answer": "land(1.00)", "pred answer": "take off", "question_id": 4688465, "best approach": "", "verif answer": "take off", "anno approach": "wiki, concept, image", "verif wiki answer": "take off(0.7304)", "verif concept answer": "take off(0.7285)", "verif image answer": "he land(0.7249)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000468846.jpg"}, {"question": "what are the items called that are stuck to this fridge", "gt answer": "magnet(1.00)", "pred answer": "towel", "question_id": 1137255, "best approach": "", "verif answer": "by magnet", "anno approach": "wiki, concept, image", "verif wiki answer": "by magnet(0.5805)", "verif concept answer": "refridgerator(0.5462)", "verif image answer": "by magnet(0.7267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000113725.jpg"}, {"question": "how long does it take that seed to grow", "gt answer": "4 months(1.00)<br/>2 months(0.60)<br/>3 months(0.60)", "pred answer": "1 month", "question_id": 5734795, "best approach": "concept", "verif answer": "2 weeks", "anno approach": "wiki, concept, image", "verif wiki answer": "3 months(0.6814)", "verif concept answer": "4 months(0.6584)", "verif image answer": "2 weeks(0.6751)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000573479.jpg"}, {"question": "what kind of bear is this", "gt answer": "grizzly bear(1.00)<br/>brown bear(0.60)<br/>brown(0.60)", "pred answer": "grizzly", "question_id": 2241935, "best approach": "wiki", "verif answer": "grizzly", "anno approach": "wiki, concept, image", "verif wiki answer": "grizzly bear(0.7258)", "verif concept answer": "grizzly(0.7115)", "verif image answer": "grizzly(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000224193.jpg"}, {"question": "what type of game is being played", "gt answer": "box(1.00)<br/>wii(1.00)<br/>video(0.60)", "pred answer": "video game", "question_id": 1119225, "best approach": "concept, image", "verif answer": "video game", "anno approach": "wiki, concept, image", "verif wiki answer": "video(0.6703)", "verif concept answer": "wii(0.6539)", "verif image answer": "box(0.5847)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000111922.jpg"}, {"question": "how is this roof fastened to the ground at the four points", "gt answer": "anchor(1.00)<br/>cable(1.00)", "pred answer": "thread", "question_id": 1003195, "best approach": "image", "verif answer": "cable", "anno approach": "wiki, concept, image", "verif wiki answer": "electricity(0.6351)", "verif concept answer": "wireless(0.5763)", "verif image answer": "cable(0.5199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100319.jpg"}, {"question": "where is this taken", "gt answer": "on street(1.00)<br/>london(0.60)<br/>street(0.60)<br/>england(0.60)", "pred answer": "intersection", "question_id": 4342215, "best approach": "image", "verif answer": "england", "anno approach": "wiki, concept, image", "verif wiki answer": "city(0.7184)", "verif concept answer": "city(0.6963)", "verif image answer": "england(0.7137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434221.jpg"}, {"question": "what is in the oven", "gt answer": "doll(1.00)<br/>stuffed animal(0.60)<br/>toy(0.60)", "pred answer": "food", "question_id": 5715355, "best approach": "image", "verif answer": "baby", "anno approach": "wiki, concept, image", "verif wiki answer": "baby(0.6927)", "verif concept answer": "baby(0.6789)", "verif image answer": "doll(0.7024)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571535.jpg"}, {"question": "which dish is normally the most expensive", "gt answer": "shrimp(1.00)", "pred answer": "meat", "question_id": 1899575, "best approach": "", "verif answer": "bbq", "anno approach": "wiki, concept, image", "verif wiki answer": "pasta(0.7159)", "verif concept answer": "pasta(0.6981)", "verif image answer": "pasta(0.7015)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000189957.jpg"}, {"question": "what type of cell phone is shown in the picture", "gt answer": "flip phone(1.00)<br/>flip(0.60)<br/>sony(0.60)<br/>motorola(0.60)", "pred answer": "samsung", "question_id": 657325, "best approach": "wiki, concept, image", "verif answer": "samsung", "anno approach": "wiki, concept, image", "verif wiki answer": "flip phone(0.6698)", "verif concept answer": "flip phone(0.7163)", "verif image answer": "flip phone(0.7139)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065732.jpg"}, {"question": "what brand of pants is the man wearing", "gt answer": "levis(1.00)<br/>jean(0.60)<br/>gap(0.60)", "pred answer": "levi", "question_id": 4274945, "best approach": "concept, image", "verif answer": "levi", "anno approach": "wiki, concept, image", "verif wiki answer": "levi(0.7037)", "verif concept answer": "gap(0.7172)", "verif image answer": "jean(0.7247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427494.jpg"}, {"question": "what kind of flower is this", "gt answer": "cactus(0.60)<br/>yellow flower(1.00)", "pred answer": "daffodil", "question_id": 1678485, "best approach": "image", "verif answer": "daffodil", "anno approach": "wiki, concept, image", "verif wiki answer": "daffodil(0.7038)", "verif concept answer": "daffodil(0.7140)", "verif image answer": "yellow flower(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167848.jpg"}, {"question": "when was this sport invented", "gt answer": "1968(1.00)<br/>1948(1.00)", "pred answer": "1873", "question_id": 3055275, "best approach": "wiki, concept", "verif answer": "1968", "anno approach": "wiki, concept, image", "verif wiki answer": "1968(0.7274)", "verif concept answer": "1968(0.7258)", "verif image answer": "1898(0.7087)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305527.jpg"}, {"question": "how often does this animal need flea treatment", "gt answer": "monthly(1.00)<br/>yearly(0.60)", "pred answer": "daily", "question_id": 5324915, "best approach": "wiki, concept, image", "verif answer": "daily", "anno approach": "wiki, concept, image", "verif wiki answer": "yearly(0.6940)", "verif concept answer": "yearly(0.5981)", "verif image answer": "yearly(0.7266)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532491.jpg"}, {"question": "how many people rent one of these trucks in the us annually", "gt answer": "million(1.00)<br/>20000(0.60)", "pred answer": "fifty", "question_id": 370625, "best approach": "wiki, concept", "verif answer": "million", "anno approach": "wiki, concept, image", "verif wiki answer": "million(0.6909)", "verif concept answer": "million(0.6845)", "verif image answer": "20000(0.6756)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000037062.jpg"}, {"question": "what is this animal 's popular characteristic", "gt answer": "long neck(1.00)<br/>neck(1.00)", "pred answer": "stripe", "question_id": 4849735, "best approach": "wiki", "verif answer": "spot", "anno approach": "wiki, concept, image", "verif wiki answer": "neck(0.7295)", "verif concept answer": "be tall(0.6957)", "verif image answer": "be tall(0.5429)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000484973.jpg"}, {"question": "what is keeping the dog from sinking", "gt answer": "float(1.00)<br/>surfboard(0.60)", "pred answer": "leash", "question_id": 3134735, "best approach": "concept", "verif answer": "surfboard", "anno approach": "wiki, concept, image", "verif wiki answer": "surf board(0.5103)", "verif concept answer": "float(0.5040)", "verif image answer": "surf board(0.5030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313473.jpg"}, {"question": "why would we suspect that there is a ski lodge near by", "gt answer": "skier(1.00)", "pred answer": "mountain", "question_id": 524725, "best approach": "", "verif answer": "camera", "anno approach": "wiki, concept, image", "verif wiki answer": "camera(0.5060)", "verif concept answer": "camera(0.5034)", "verif image answer": "camera(0.6929)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052472.jpg"}, {"question": "what are the people riding on", "gt answer": "carriage(1.00)<br/>buggy(0.60)", "pred answer": "parade", "question_id": 3673755, "best approach": "wiki, concept, image", "verif answer": "carriage", "anno approach": "wiki, concept, image", "verif wiki answer": "carriage(0.7127)", "verif concept answer": "carriage(0.6995)", "verif image answer": "carriage(0.6458)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000367375.jpg"}, {"question": "what kind of machine is this", "gt answer": "speaker(1.00)<br/>radio(1.00)", "pred answer": "phone", "question_id": 5460215, "best approach": "wiki, concept", "verif answer": "phone", "anno approach": "wiki, concept, image", "verif wiki answer": "speaker(0.7291)", "verif concept answer": "speaker(0.7223)", "verif image answer": "phone(0.7238)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546021.jpg"}, {"question": "what does this horse have on its back", "gt answer": "blanket(1.00)<br/>coat(0.60)", "pred answer": "saddle", "question_id": 5276245, "best approach": "wiki, concept", "verif answer": "coat", "anno approach": "wiki, concept, image", "verif wiki answer": "coat(0.6429)", "verif concept answer": "coat(0.5279)", "verif image answer": "shirt(0.5141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527624.jpg"}, {"question": "are horses allowed or not allowed on the road like that", "gt answer": "allowed(1.00)", "pred answer": "public", "question_id": 644555, "best approach": "", "verif answer": "people", "anno approach": "wiki, concept, image", "verif wiki answer": "people(0.6853)", "verif concept answer": "people(0.7086)", "verif image answer": "1800s(0.6864)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064455.jpg"}, {"question": "what standard size bed does this look like", "gt answer": "queen(1.00)<br/>full(1.00)", "pred answer": "king", "question_id": 1382765, "best approach": "wiki, concept", "verif answer": "king", "anno approach": "wiki, concept, image", "verif wiki answer": "full(0.7268)", "verif concept answer": "full(0.7184)", "verif image answer": "double(0.7229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138276.jpg"}, {"question": "what is pulling this airplane", "gt answer": "tug(1.00)<br/>vehicle(0.60)<br/>tow(0.60)", "pred answer": "airplane", "question_id": 22585, "best approach": "concept, image", "verif answer": "truck", "anno approach": "wiki, concept, image", "verif wiki answer": "car(0.6303)", "verif concept answer": "vehicle(0.6437)", "verif image answer": "vehicle(0.7089)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000002258.jpg"}, {"question": "what does the cellphone have that current cellphones don't", "gt answer": "button(1.00)<br/>flip(0.60)", "pred answer": "text", "question_id": 1838825, "best approach": "image", "verif answer": "flip", "anno approach": "wiki, concept, image", "verif wiki answer": "flip(0.7295)", "verif concept answer": "phone(0.6657)", "verif image answer": "button(0.7080)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183882.jpg"}, {"question": "what appliance would be used to dry these clothes quickly", "gt answer": "dryer(1.00)", "pred answer": "sink", "question_id": 463565, "best approach": "wiki, concept", "verif answer": "dryer", "anno approach": "wiki, concept, image", "verif wiki answer": "dryer(0.5628)", "verif concept answer": "dryer(0.7056)", "verif image answer": "cabinet(0.6717)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046356.jpg"}, {"question": "what sort of animals would enjoy grazing on this mountainside", "gt answer": "goat(1.00)<br/>sheep(0.60)", "pred answer": "dog", "question_id": 2637705, "best approach": "wiki, concept", "verif answer": "sheep", "anno approach": "wiki, concept, image", "verif wiki answer": "goat(0.7231)", "verif concept answer": "goat(0.7050)", "verif image answer": "herd(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263770.jpg"}, {"question": "what sport is being simulated", "gt answer": "golf(1.00)<br/>cricket(0.60)", "pred answer": "box", "question_id": 4302445, "best approach": "wiki, concept", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "cricket(0.6920)", "verif concept answer": "cricket(0.6195)", "verif image answer": "frisbee(0.5765)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000430244.jpg"}, {"question": "what airline does the plane belong to", "gt answer": "air canada(1.00)", "pred answer": "american airline", "question_id": 3476525, "best approach": "", "verif answer": "american airline", "anno approach": "wiki, concept, image", "verif wiki answer": "maple leaf(0.5982)", "verif concept answer": "american airline(0.6528)", "verif image answer": "virgin(0.6435)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347652.jpg"}, {"question": "a knife that has a blade like this one is called a what kind of knife", "gt answer": "serrated(1.00)", "pred answer": "pair", "question_id": 3043845, "best approach": "concept, image", "verif answer": "pair", "anno approach": "wiki, concept, image", "verif wiki answer": "cardinal(0.6656)", "verif concept answer": "serrated(0.7285)", "verif image answer": "serrated(0.7190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304384.jpg"}, {"question": "how long will the batteries inside this remote last", "gt answer": "3 months(1.00)<br/>1 year(0.60)<br/>4 months(0.60)<br/>2 weeks(0.60)", "pred answer": "10 hours", "question_id": 196655, "best approach": "image", "verif answer": "1 year", "anno approach": "wiki, concept, image", "verif wiki answer": "4 months(0.7003)", "verif concept answer": "1 year(0.6470)", "verif image answer": "3 months(0.6963)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000019665.jpg"}, {"question": "what is the brand name of the coffee creamer are they using", "gt answer": "coffee mate(1.00)", "pred answer": "dunkin donuts", "question_id": 5490035, "best approach": "", "verif answer": "dunkin donuts", "anno approach": "wiki, concept, image", "verif wiki answer": "dunkin donuts(0.5167)", "verif concept answer": "dunkin donuts(0.5022)", "verif image answer": "dixie(0.6882)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000549003.jpg"}, {"question": "what is the approximate age of this man", "gt answer": "forty(1.00)<br/>50(1.00)<br/>45(0.60)", "pred answer": "15", "question_id": 5524615, "best approach": "wiki, concept, image", "verif answer": "50", "anno approach": "wiki, concept, image", "verif wiki answer": "50(0.5908)", "verif concept answer": "50(0.5573)", "verif image answer": "50(0.5301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000552461.jpg"}, {"question": "why might someone prefer the health impact of the bread on this sandwich to white bread", "gt answer": "whole grain(1.00)", "pred answer": "wheat", "question_id": 4013905, "best approach": "", "verif answer": "wheat", "anno approach": "wiki, concept, image", "verif wiki answer": "white(0.6974)", "verif concept answer": "white(0.7033)", "verif image answer": "white(0.7257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401390.jpg"}, {"question": "what are those buildings likely for", "gt answer": "apart(1.00)<br/>live(0.60)", "pred answer": "house", "question_id": 2993945, "best approach": "image", "verif answer": "apartment", "anno approach": "wiki, concept, image", "verif wiki answer": "apartment(0.7168)", "verif concept answer": "apartment(0.7025)", "verif image answer": "apart(0.6672)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000299394.jpg"}, {"question": "what part of this object will be raised during descent", "gt answer": "wing(0.60)<br/>flap(1.00)", "pred answer": "tail", "question_id": 84535, "best approach": "wiki, concept, image", "verif answer": "lift", "anno approach": "wiki, concept, image", "verif wiki answer": "wing(0.7176)", "verif concept answer": "wing(0.7157)", "verif image answer": "wing(0.7085)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008453.jpg"}, {"question": "the feet of animals like these are called what", "gt answer": "paw(1.00)", "pred answer": "bear", "question_id": 2953705, "best approach": "", "verif answer": "poodle", "anno approach": "wiki, concept, image", "verif wiki answer": "canine(0.7085)", "verif concept answer": "canine(0.6952)", "verif image answer": "canine(0.6920)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295370.jpg"}, {"question": "what brand is the soap on the sink", "gt answer": "dove(1.00)<br/>aloe(0.60)", "pred answer": "moen", "question_id": 4120905, "best approach": "", "verif answer": "parakeet", "anno approach": "wiki, concept, image", "verif wiki answer": "parakeet(0.6866)", "verif concept answer": "parakeet(0.7215)", "verif image answer": "robin(0.7213)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000412090.jpg"}, {"question": "what is the best way to ride one of these", "gt answer": "with saddle(1.00)<br/>gallop(0.60)<br/>saddle(0.60)", "pred answer": "cart", "question_id": 4586645, "best approach": "", "verif answer": "horse", "anno approach": "wiki, concept, image", "verif wiki answer": "run(0.7163)", "verif concept answer": "run(0.6908)", "verif image answer": "horse(0.7216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458664.jpg"}, {"question": "who invented this famous form of transportation", "gt answer": "wright brother(1.00)", "pred answer": "boeing", "question_id": 5727815, "best approach": "wiki", "verif answer": "wright brother", "anno approach": "wiki, concept, image", "verif wiki answer": "wright brother(0.7299)", "verif concept answer": "boeing(0.7021)", "verif image answer": "boeing(0.7087)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572781.jpg"}, {"question": "where can i buy this meal", "gt answer": "cafe(1.00)<br/>diner(0.60)<br/>restaurant(0.60)", "pred answer": "walmart", "question_id": 590365, "best approach": "wiki", "verif answer": "deli", "anno approach": "wiki, concept, image", "verif wiki answer": "diner(0.6996)", "verif concept answer": "bar(0.7159)", "verif image answer": "bar(0.6891)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059036.jpg"}, {"question": "how many people can this vehicle carry", "gt answer": "12(1.00)<br/>20(1.00)", "pred answer": "60", "question_id": 2073785, "best approach": "image", "verif answer": "20", "anno approach": "wiki, concept, image", "verif wiki answer": "3(0.7067)", "verif concept answer": "3(0.6287)", "verif image answer": "20(0.7096)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207378.jpg"}, {"question": "what is the name of this sporting event", "gt answer": "luge(1.00)", "pred answer": "skate", "question_id": 3952165, "best approach": "", "verif answer": "skateboard", "anno approach": "wiki, concept, image", "verif wiki answer": "dirt bike(0.7262)", "verif concept answer": "dirt bike(0.7175)", "verif image answer": "dirt bike(0.6869)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395216.jpg"}, {"question": "wow what kind of lense is this", "gt answer": "wide angle(1.00)<br/>clear(0.60)<br/>wide(0.60)", "pred answer": "fisheye", "question_id": 5288495, "best approach": "wiki, concept, image", "verif answer": "wide angle", "anno approach": "wiki, concept, image", "verif wiki answer": "wide angle(0.6917)", "verif concept answer": "wide angle(0.7148)", "verif image answer": "wide angle(0.7105)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000528849.jpg"}, {"question": "can you tell me the dishes before you are good for which parst of the body", "gt answer": "heart(1.00)", "pred answer": "brain", "question_id": 3172275, "best approach": "", "verif answer": "brain", "anno approach": "wiki, concept, image", "verif wiki answer": "brain(0.6721)", "verif concept answer": "brain(0.6974)", "verif image answer": "brain(0.7124)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317227.jpg"}, {"question": "what type of clouds are those", "gt answer": "cumulus(1.00)<br/>rain(0.60)<br/>stratus(0.60)", "pred answer": "storm", "question_id": 3623955, "best approach": "wiki, image", "verif answer": "cumulus", "anno approach": "wiki, concept, image", "verif wiki answer": "cumulus(0.7166)", "verif concept answer": "stratus(0.7195)", "verif image answer": "cumulus(0.7005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000362395.jpg"}, {"question": "what could this truck be used for", "gt answer": "military(1.00)<br/>transportation(0.60)<br/>haul(0.60)<br/>move(0.60)", "pred answer": "tow", "question_id": 4055055, "best approach": "wiki, concept, image", "verif answer": "haul", "anno approach": "wiki, concept, image", "verif wiki answer": "move(0.5730)", "verif concept answer": "haul(0.6421)", "verif image answer": "haul(0.7265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405505.jpg"}, {"question": "what is the man riding on", "gt answer": "kayak(1.00)<br/>surfboard(0.60)<br/>paddleboard(0.60)", "pred answer": "surf board", "question_id": 1679635, "best approach": "", "verif answer": "surf board", "anno approach": "wiki, concept, image", "verif wiki answer": "surf board(0.7090)", "verif concept answer": "surf board(0.6807)", "verif image answer": "surf board(0.6843)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167963.jpg"}, {"question": "what countries you can find these animals", "gt answer": "africa(1.00)", "pred answer": "kenya", "question_id": 3448175, "best approach": "concept, image", "verif answer": "kenya", "anno approach": "wiki, concept, image", "verif wiki answer": "kenya(0.7245)", "verif concept answer": "africa(0.7100)", "verif image answer": "africa(0.7239)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344817.jpg"}, {"question": "why is this person holding an umbrella", "gt answer": "rain(1.00)", "pred answer": "shade", "question_id": 155545, "best approach": "wiki, concept, image", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "rain(0.7258)", "verif concept answer": "rain(0.7131)", "verif image answer": "rain(0.6768)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015554.jpg"}, {"question": "are these people on vacation or working", "gt answer": "vacation(1.00)<br/>work(0.60)", "pred answer": "talk", "question_id": 3684395, "best approach": "", "verif answer": "study", "anno approach": "wiki, concept, image", "verif wiki answer": "cook(0.6360)", "verif concept answer": "study(0.6973)", "verif image answer": "study(0.7052)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000368439.jpg"}, {"question": "what kind of robot is this", "gt answer": "c3po(1.00)", "pred answer": "disney", "question_id": 5010565, "best approach": "wiki, concept, image", "verif answer": "shrimp", "anno approach": "wiki, concept, image", "verif wiki answer": "c3po(0.6999)", "verif concept answer": "c3po(0.6961)", "verif image answer": "c3po(0.7298)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000501056.jpg"}, {"question": "what does the rope on the end of the surfboard do", "gt answer": "attach to surfer(1.00)<br/>tie(0.60)", "pred answer": "surf", "question_id": 145465, "best approach": "wiki, concept, image", "verif answer": "flip", "anno approach": "wiki, concept, image", "verif wiki answer": "attach to surfer(0.7001)", "verif concept answer": "attach to surfer(0.6773)", "verif image answer": "attach to surfer(0.6171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000014546.jpg"}, {"question": "what job title might you give the woman in this picture", "gt answer": "cook(1.00)<br/>chef(0.60)", "pred answer": "office", "question_id": 5812835, "best approach": "", "verif answer": "chef", "anno approach": "wiki, concept, image", "verif wiki answer": "restaurant(0.6787)", "verif concept answer": "restaurant(0.6351)", "verif image answer": "restaurant(0.7044)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000581283.jpg"}, {"question": "is the window square or rectangle", "gt answer": "rectangle(1.00)<br/>square(0.60)", "pred answer": "long", "question_id": 666965, "best approach": "concept", "verif answer": "rectangle", "anno approach": "wiki, concept, image", "verif wiki answer": "diamond(0.6108)", "verif concept answer": "rectangle(0.5296)", "verif image answer": "diamond(0.5194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000066696.jpg"}, {"question": "what show is the character on the brush in", "gt answer": "high school musical(1.00)<br/>bieber(0.60)", "pred answer": "mickey mouse", "question_id": 2452045, "best approach": "concept, image", "verif answer": "alexis ohanian", "anno approach": "wiki, concept, image", "verif wiki answer": "alexis ohanian(0.6714)", "verif concept answer": "high school musical(0.5332)", "verif image answer": "high school musical(0.5415)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245204.jpg"}, {"question": "what are they making", "gt answer": "salsa(1.00)<br/>food(0.60)<br/>soup(0.60)<br/>salad(0.60)", "pred answer": "cookies", "question_id": 1181585, "best approach": "wiki, concept, image", "verif answer": "salad", "anno approach": "wiki, concept, image", "verif wiki answer": "salad(0.7256)", "verif concept answer": "salad(0.7097)", "verif image answer": "salad(0.7073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118158.jpg"}, {"question": "what vehicle is this", "gt answer": "police car(1.00)<br/>car(0.60)", "pred answer": "van", "question_id": 2767035, "best approach": "concept", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "truck(0.7168)", "verif concept answer": "car(0.6835)", "verif image answer": "truck(0.6526)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000276703.jpg"}, {"question": "what manufacture popularized very small mobile phones", "gt answer": "nokia(1.00)", "pred answer": "motorola", "question_id": 1391735, "best approach": "", "verif answer": "motorola", "anno approach": "wiki, concept, image", "verif wiki answer": "samsung(0.7056)", "verif concept answer": "motorola(0.6938)", "verif image answer": "motorola(0.6591)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000139173.jpg"}, {"question": "why are there two spoons in the bowl", "gt answer": "share(1.00)", "pred answer": "measure", "question_id": 5227045, "best approach": "", "verif answer": "spoon", "anno approach": "wiki, concept, image", "verif wiki answer": "spoon(0.6820)", "verif concept answer": "spoon(0.5196)", "verif image answer": "spoon(0.6591)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522704.jpg"}, {"question": "what sport is being shown", "gt answer": "rodeo(1.00)", "pred answer": "horse race", "question_id": 4670635, "best approach": "", "verif answer": "rodeo", "anno approach": "wiki, concept, image", "verif wiki answer": "herd(0.7047)", "verif concept answer": "herd(0.7261)", "verif image answer": "herd(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467063.jpg"}, {"question": "what is the blue colored food", "gt answer": "cabbage(1.00)<br/>eggplant(1.00)", "pred answer": "salmon", "question_id": 4822655, "best approach": "concept, image", "verif answer": "lettuce", "anno approach": "wiki, concept, image", "verif wiki answer": "spinach(0.6623)", "verif concept answer": "cabbage(0.7132)", "verif image answer": "cabbage(0.6738)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482265.jpg"}, {"question": "who are these people", "gt answer": "president(1.00)", "pred answer": "student", "question_id": 2237265, "best approach": "wiki, concept", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "president(0.6768)", "verif concept answer": "president(0.6751)", "verif image answer": "man(0.6235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000223726.jpg"}, {"question": "what are people called that watch sports from these seats", "gt answer": "fan(1.00)", "pred answer": "bleacher", "question_id": 3596865, "best approach": "wiki, concept", "verif answer": "fan", "anno approach": "wiki, concept, image", "verif wiki answer": "fan(0.6234)", "verif concept answer": "fan(0.6514)", "verif image answer": "human(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359686.jpg"}, {"question": "what age child would play with this toy", "gt answer": "3(1.00)<br/>4(1.00)<br/>6(0.60)", "pred answer": "17", "question_id": 794715, "best approach": "", "verif answer": "2", "anno approach": "wiki, concept, image", "verif wiki answer": "2(0.5099)", "verif concept answer": "2(0.5036)", "verif image answer": "2(0.5098)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000079471.jpg"}, {"question": "what kind of visual effect has been used on this picture", "gt answer": "black and white(1.00)<br/>shadow(0.60)", "pred answer": "long exposure", "question_id": 3265985, "best approach": "concept", "verif answer": "long exposure", "anno approach": "wiki, concept, image", "verif wiki answer": "long exposure(0.7121)", "verif concept answer": "black and white(0.6574)", "verif image answer": "ansel adams(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000326598.jpg"}, {"question": "what are they celebrating", "gt answer": "birthday(1.00)", "pred answer": "christmas", "question_id": 921885, "best approach": "wiki, concept", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "birthday(0.7298)", "verif concept answer": "birthday(0.7176)", "verif image answer": "birthday cake(0.6950)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000092188.jpg"}, {"question": "what was the use of that thing beside the window", "gt answer": "cat toy(1.00)<br/>cat(0.60)", "pred answer": "shade", "question_id": 1473925, "best approach": "concept", "verif answer": "bed", "anno approach": "wiki, concept, image", "verif wiki answer": "bed(0.6742)", "verif concept answer": "cat toy(0.5638)", "verif image answer": "cat(0.5376)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147392.jpg"}, {"question": "what electric instrument is shown", "gt answer": "microphone(1.00)", "pred answer": "piano", "question_id": 5150535, "best approach": "", "verif answer": "guitar", "anno approach": "wiki, concept, image", "verif wiki answer": "guitar(0.5452)", "verif concept answer": "guitar(0.7168)", "verif image answer": "guitar(0.6918)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515053.jpg"}, {"question": "what other tool may be used to style the hair", "gt answer": "comb(1.00)", "pred answer": "brush", "question_id": 1979175, "best approach": "", "verif answer": "brush", "anno approach": "wiki, concept, image", "verif wiki answer": "chimney(0.6500)", "verif concept answer": "chimney(0.5850)", "verif image answer": "bamboo(0.6666)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197917.jpg"}, {"question": "which organization owns the local land", "gt answer": "nasa(1.00)", "pred answer": "click", "question_id": 2668095, "best approach": "concept", "verif answer": "click", "anno approach": "wiki, concept, image", "verif wiki answer": "click(0.6134)", "verif concept answer": "nasa(0.7003)", "verif image answer": "navy(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266809.jpg"}, {"question": "where would you dry your wet hands here", "gt answer": "towel(1.00)", "pred answer": "bathroom", "question_id": 1787855, "best approach": "wiki, concept", "verif answer": "towel", "anno approach": "wiki, concept, image", "verif wiki answer": "towel(0.7243)", "verif concept answer": "towel(0.6712)", "verif image answer": "sponge(0.6410)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178785.jpg"}, {"question": "what does the sign depicted mean", "gt answer": "no park(1.00)<br/>no turn(0.60)", "pred answer": "stop", "question_id": 2480665, "best approach": "wiki, concept", "verif answer": "no park", "anno approach": "wiki, concept, image", "verif wiki answer": "no park(0.7297)", "verif concept answer": "no park(0.7247)", "verif image answer": "no left turn(0.7070)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000248066.jpg"}, {"question": "where is that train traveling to", "gt answer": "paris(1.00)<br/>chicago(0.60)<br/>city(0.60)", "pred answer": "station", "question_id": 3639355, "best approach": "wiki, concept, image", "verif answer": "paris", "anno approach": "wiki, concept, image", "verif wiki answer": "chicago(0.7203)", "verif concept answer": "chicago(0.7155)", "verif image answer": "chicago(0.7163)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363935.jpg"}, {"question": "how many plants are there", "gt answer": "5(1.00)<br/>0(1.00)", "pred answer": "6", "question_id": 3465475, "best approach": "", "verif answer": "3", "anno approach": "wiki, concept, image", "verif wiki answer": "10(0.6904)", "verif concept answer": "10(0.6924)", "verif image answer": "10(0.6320)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346547.jpg"}, {"question": "how fast can the machine the man is in travel", "gt answer": "5 mph(1.00)", "pred answer": "100 mph", "question_id": 4403105, "best approach": "", "verif answer": "200 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "65 mph(0.6933)", "verif concept answer": "quiet(0.6206)", "verif image answer": "not at all(0.7172)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440310.jpg"}, {"question": "what is the name of the popular confectionery named after the animal in this picture", "gt answer": "gummi bear(1.00)<br/>bear(0.60)", "pred answer": "baloo", "question_id": 1153315, "best approach": "concept", "verif answer": "bear", "anno approach": "wiki, concept, image", "verif wiki answer": "red panda(0.6491)", "verif concept answer": "gummi bear(0.5534)", "verif image answer": "bee(0.5040)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115331.jpg"}, {"question": "what breed of cat is this", "gt answer": "persian(1.00)<br/>domestic(0.60)<br/>siamese(0.60)", "pred answer": "domestic shorthair", "question_id": 3107805, "best approach": "", "verif answer": "domestic shorthair", "anno approach": "wiki, concept, image", "verif wiki answer": "tabby(0.7001)", "verif concept answer": "domestic shorthair(0.6475)", "verif image answer": "tabby(0.6941)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310780.jpg"}, {"question": "how deep is this place", "gt answer": "1 mile(1.00)", "pred answer": "8 feet", "question_id": 4783515, "best approach": "wiki, concept, image", "verif answer": "15 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "1 mile(0.6903)", "verif concept answer": "1 mile(0.6618)", "verif image answer": "1 mile(0.6799)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478351.jpg"}, {"question": "", "gt answer": "tabby(0.60)<br/>american longhair(0.60)<br/>house(0.60)", "pred answer": "ragdoll", "question_id": 4192735, "best approach": "concept", "verif answer": "persian", "anno approach": "wiki, concept, image", "verif wiki answer": "american shorthair(0.7115)", "verif concept answer": "american longhair(0.6918)", "verif image answer": "american shorthair(0.7044)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419273.jpg"}, {"question": "the babies of these animals are called what", "gt answer": "calf(1.00)", "pred answer": "ewe", "question_id": 1591965, "best approach": "wiki, concept, image", "verif answer": "foal", "anno approach": "wiki, concept, image", "verif wiki answer": "calf(0.7192)", "verif concept answer": "calf(0.7163)", "verif image answer": "calf(0.7043)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000159196.jpg"}, {"question": "what type of light bulbs are the christmas tree being lit by", "gt answer": "led(1.00)<br/>string(0.60)", "pred answer": "flash", "question_id": 2094285, "best approach": "wiki", "verif answer": "led", "anno approach": "wiki, concept, image", "verif wiki answer": "led(0.5674)", "verif concept answer": "wind(0.5454)", "verif image answer": "wind(0.5009)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209428.jpg"}, {"question": "what brand of chips are shown in the background", "gt answer": "lay(1.00)", "pred answer": "adidas", "question_id": 891475, "best approach": "", "verif answer": "ruffle", "anno approach": "wiki, concept, image", "verif wiki answer": "ruffle(0.6691)", "verif concept answer": "ruffle(0.7140)", "verif image answer": "ruffle(0.7254)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089147.jpg"}, {"question": "what long items are used to make this objects move", "gt answer": "oar(1.00)", "pred answer": "motor", "question_id": 738265, "best approach": "wiki", "verif answer": "oar", "anno approach": "wiki, concept, image", "verif wiki answer": "oar(0.7216)", "verif concept answer": "chopstick(0.7163)", "verif image answer": "chopstick(0.7055)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073826.jpg"}, {"question": "why might we suspect this plate is served at a restaurant", "gt answer": "presentation(1.00)<br/>lunch(0.60)", "pred answer": "meat", "question_id": 4276105, "best approach": "image", "verif answer": "dinner", "anno approach": "wiki, concept, image", "verif wiki answer": "supper(0.7169)", "verif concept answer": "dinner(0.6222)", "verif image answer": "presentation(0.6650)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427610.jpg"}, {"question": "how was the texture created on the glass used to make this table", "gt answer": "heat(1.00)<br/>blow(0.60)<br/>hammer(0.60)", "pred answer": "nylon", "question_id": 4318205, "best approach": "wiki, concept", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "heat(0.7269)", "verif concept answer": "heat(0.7059)", "verif image answer": "blow(0.6948)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000431820.jpg"}, {"question": "why is the man near anothers neck", "gt answer": "tie(1.00)", "pred answer": "married", "question_id": 5436635, "best approach": "wiki, concept", "verif answer": "collar", "anno approach": "wiki, concept, image", "verif wiki answer": "tie(0.6405)", "verif concept answer": "tie(0.6301)", "verif image answer": "collar(0.5635)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543663.jpg"}, {"question": "how many hours on average do these animals sleep daily", "gt answer": "16(1.00)<br/>10(0.60)", "pred answer": "3", "question_id": 1156425, "best approach": "wiki, concept", "verif answer": "12", "anno approach": "wiki, concept, image", "verif wiki answer": "16(0.6714)", "verif concept answer": "16(0.6425)", "verif image answer": "18(0.6972)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115642.jpg"}, {"question": "what train company is this", "gt answer": "canadian pacific(1.00)<br/>santa fe(0.60)", "pred answer": "amtrack", "question_id": 5156555, "best approach": "", "verif answer": "amtrack", "anno approach": "wiki, concept, image", "verif wiki answer": "amtrack(0.7274)", "verif concept answer": "amtrack(0.6220)", "verif image answer": "virgin(0.7228)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515655.jpg"}, {"question": "what is this baby dressed as", "gt answer": "lion(1.00)<br/>dog(0.60)<br/>bear(0.60)", "pred answer": "merida", "question_id": 410565, "best approach": "wiki, concept", "verif answer": "teddy bear", "anno approach": "wiki, concept, image", "verif wiki answer": "bear(0.5617)", "verif concept answer": "bear(0.5280)", "verif image answer": "teddy bear(0.5076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041056.jpg"}, {"question": "what company does this plane belong to", "gt answer": "csa(1.00)", "pred answer": "american airline", "question_id": 5749445, "best approach": "concept, image", "verif answer": "united", "anno approach": "wiki, concept, image", "verif wiki answer": "united(0.7275)", "verif concept answer": "csa(0.7284)", "verif image answer": "csa(0.7160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000574944.jpg"}, {"question": "how long does yellow fruit last before going bad", "gt answer": "4 days(1.00)<br/>1 week(1.00)", "pred answer": "2 days", "question_id": 4815155, "best approach": "image", "verif answer": "2 weeks", "anno approach": "wiki, concept, image", "verif wiki answer": "2 weeks(0.6967)", "verif concept answer": "1 month(0.6602)", "verif image answer": "4 days(0.5283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481515.jpg"}, {"question": "what are the boats tied to", "gt answer": "dock(1.00)<br/>pier(0.60)", "pred answer": "anchor", "question_id": 5669355, "best approach": "concept", "verif answer": "dock", "anno approach": "wiki, concept, image", "verif wiki answer": "perch(0.5187)", "verif concept answer": "dock(0.5503)", "verif image answer": "fish(0.7200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566935.jpg"}, {"question": "in this sport what type of shirt is this person wearing", "gt answer": "t shirt(1.00)<br/>jersey(0.60)<br/>tennis(0.60)", "pred answer": "tank top", "question_id": 1690035, "best approach": "wiki, concept, image", "verif answer": "polo", "anno approach": "wiki, concept, image", "verif wiki answer": "t shirt(0.7045)", "verif concept answer": "t shirt(0.6929)", "verif image answer": "t shirt(0.5207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000169003.jpg"}, {"question": "what shape is the shelter over the riders heads", "gt answer": "dome(1.00)<br/>arch(0.60)", "pred answer": "diamond", "question_id": 4854915, "best approach": "wiki", "verif answer": "diamond", "anno approach": "wiki, concept, image", "verif wiki answer": "arch(0.7290)", "verif concept answer": "diamond(0.7090)", "verif image answer": "diamond(0.7304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485491.jpg"}, {"question": "what is the object in the woman 's hand used for", "gt answer": "kid(0.60)<br/>comfort(1.00)", "pred answer": "read", "question_id": 158975, "best approach": "wiki, concept, image", "verif answer": "sit", "anno approach": "wiki, concept, image", "verif wiki answer": "kid(0.6978)", "verif concept answer": "kid(0.6469)", "verif image answer": "kid(0.6582)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015897.jpg"}, {"question": "cat gut is an item used to make what thing seen here", "gt answer": "tennis racket(1.00)<br/>string(0.60)", "pred answer": "umbrella", "question_id": 4539685, "best approach": "", "verif answer": "ball", "anno approach": "wiki, concept, image", "verif wiki answer": "ball(0.5423)", "verif concept answer": "racket(0.6173)", "verif image answer": "racket(0.7283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453968.jpg"}, {"question": "this speicies of animal is famous for what", "gt answer": "be tall(1.00)<br/>long neck(1.00)", "pred answer": "tusk", "question_id": 1762635, "best approach": "wiki, concept, image", "verif answer": "ivory", "anno approach": "wiki, concept, image", "verif wiki answer": "long neck(0.7089)", "verif concept answer": "long neck(0.7192)", "verif image answer": "long neck(0.7310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176263.jpg"}, {"question": "what type of flowers are in the pot", "gt answer": "pansy(0.60)<br/>daffodil(0.60)<br/>daisy(1.00)", "pred answer": "lavendar", "question_id": 2148345, "best approach": "", "verif answer": "pansy", "anno approach": "wiki, concept, image", "verif wiki answer": "marigold(0.7154)", "verif concept answer": "marigold(0.7111)", "verif image answer": "marigold(0.5465)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214834.jpg"}, {"question": "what brand is this blender", "gt answer": "oster(1.00)<br/>whirlpool(0.60)", "pred answer": "lg", "question_id": 710055, "best approach": "wiki", "verif answer": "kenmore", "anno approach": "wiki, concept, image", "verif wiki answer": "oster(0.7299)", "verif concept answer": "whirlpool(0.7068)", "verif image answer": "whirlpool(0.6791)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071005.jpg"}, {"question": "", "gt answer": "dock(0.60)<br/>fish(0.60)", "pred answer": "yacht", "question_id": 4696395, "best approach": "image", "verif answer": "dock", "anno approach": "wiki, concept, image", "verif wiki answer": "marina(0.6112)", "verif concept answer": "marina(0.5612)", "verif image answer": "dock(0.5493)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000469639.jpg"}, {"question": "what are those colorful items to be used for", "gt answer": "canoe(1.00)<br/>surf(1.00)", "pred answer": "work", "question_id": 4088545, "best approach": "wiki, concept, image", "verif answer": "surf", "anno approach": "wiki, concept, image", "verif wiki answer": "surf(0.7010)", "verif concept answer": "canoe(0.6990)", "verif image answer": "canoe(0.7111)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408854.jpg"}, {"question": "what kind of grass is the field these men are standing on called", "gt answer": "turf(1.00)<br/>park(0.60)", "pred answer": "field", "question_id": 1937095, "best approach": "wiki, concept", "verif answer": "field", "anno approach": "wiki, concept, image", "verif wiki answer": "park(0.6392)", "verif concept answer": "park(0.6800)", "verif image answer": "fern(0.7297)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193709.jpg"}, {"question": "what type of fish bait do these flying objects look like", "gt answer": "worm(1.00)", "pred answer": "sailboat", "question_id": 2401985, "best approach": "image", "verif answer": "ship", "anno approach": "wiki, concept, image", "verif wiki answer": "bug(0.5957)", "verif concept answer": "bug(0.5944)", "verif image answer": "worm(0.6976)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240198.jpg"}, {"question": "what fairy tale would you find these characters in that has a girl with goldilocks", "gt answer": "goldilocks and 3 bears(1.00)", "pred answer": "ted", "question_id": 5297955, "best approach": "wiki, concept, image", "verif answer": "ted", "anno approach": "wiki, concept, image", "verif wiki answer": "goldilocks and 3 bears(0.7171)", "verif concept answer": "goldilocks and 3 bears(0.6711)", "verif image answer": "goldilocks and 3 bears(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529795.jpg"}, {"question": "the red and white pole design seen here is also associated with which profession", "gt answer": "barber(1.00)<br/>santa(0.60)", "pred answer": "stop", "question_id": 5546885, "best approach": "wiki", "verif answer": "military", "anno approach": "wiki, concept, image", "verif wiki answer": "barber(0.6440)", "verif concept answer": "military(0.6070)", "verif image answer": "hair stylist(0.7083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554688.jpg"}, {"question": "what fruit is this beverage made from", "gt answer": "grape(1.00)", "pred answer": "lime", "question_id": 3540705, "best approach": "wiki", "verif answer": "grape", "anno approach": "wiki, concept, image", "verif wiki answer": "grape(0.7093)", "verif concept answer": "banana(0.6957)", "verif image answer": "alcohol(0.6336)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354070.jpg"}, {"question": "what sports could this man play at this location", "gt answer": "volleyball(1.00)", "pred answer": "surf", "question_id": 4787415, "best approach": "wiki, concept, image", "verif answer": "basketball", "anno approach": "wiki, concept, image", "verif wiki answer": "volleyball(0.7245)", "verif concept answer": "volleyball(0.7240)", "verif image answer": "volleyball(0.7293)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478741.jpg"}, {"question": "what does one need to fly this vehicle", "gt answer": "license(1.00)<br/>pilot(0.60)<br/>engine(0.60)", "pred answer": "fly", "question_id": 1797535, "best approach": "wiki, concept, image", "verif answer": "engine", "anno approach": "wiki, concept, image", "verif wiki answer": "engine(0.6319)", "verif concept answer": "pilot(0.6927)", "verif image answer": "engine(0.7057)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000179753.jpg"}, {"question": "the tiled area behind the stove is referred to as the what", "gt answer": "backsplash(1.00)", "pred answer": "cabinet", "question_id": 4504785, "best approach": "", "verif answer": "tile", "anno approach": "wiki, concept, image", "verif wiki answer": "tile(0.6817)", "verif concept answer": "contemporary(0.6737)", "verif image answer": "contemporary(0.7309)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450478.jpg"}, {"question": "what is the name of the bird with two legs", "gt answer": "ostrich(1.00)", "pred answer": "giraffe", "question_id": 2594465, "best approach": "wiki, concept", "verif answer": "run", "anno approach": "wiki, concept, image", "verif wiki answer": "ostrich(0.6675)", "verif concept answer": "ostrich(0.7147)", "verif image answer": "run(0.6797)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000259446.jpg"}, {"question": "how is this item prepared", "gt answer": "baked(1.00)", "pred answer": "oven", "question_id": 1786375, "best approach": "", "verif answer": "oven", "anno approach": "wiki, concept, image", "verif wiki answer": "baked in oven(0.7141)", "verif concept answer": "baked in oven(0.6653)", "verif image answer": "oven(0.7046)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178637.jpg"}, {"question": "what is the olympic version of this called", "gt answer": "slalom(1.00)<br/>downhill(0.60)<br/>cross country(0.60)", "pred answer": "ski", "question_id": 4826945, "best approach": "wiki", "verif answer": "downhill", "anno approach": "wiki, concept, image", "verif wiki answer": "slalom(0.6735)", "verif concept answer": "downhill(0.5721)", "verif image answer": "cross country(0.5917)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482694.jpg"}, {"question": "what is the gestation period of this animal", "gt answer": "13 months(1.00)<br/>10 months(0.60)<br/>year(0.60)<br/>3 months(0.60)", "pred answer": "20 years", "question_id": 4536465, "best approach": "wiki, concept", "verif answer": "2 months", "anno approach": "wiki, concept, image", "verif wiki answer": "13 months(0.6702)", "verif concept answer": "13 months(0.6203)", "verif image answer": "2 months(0.6774)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453646.jpg"}, {"question": "what is the name of the garment this individual is wearing", "gt answer": "wetsuit(1.00)", "pred answer": "wet suit", "question_id": 608735, "best approach": "", "verif answer": "wet suit", "anno approach": "wiki, concept, image", "verif wiki answer": "wet suit(0.6629)", "verif concept answer": "wet suit(0.6409)", "verif image answer": "neoprene(0.5434)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060873.jpg"}, {"question": "is this sort of carpet usually associated with the western or eastern hemisphere", "gt answer": "eastern(1.00)<br/>western(0.60)", "pred answer": "tropical", "question_id": 3026805, "best approach": "concept", "verif answer": "western", "anno approach": "wiki, concept, image", "verif wiki answer": "west(0.6145)", "verif concept answer": "eastern(0.5109)", "verif image answer": "western(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302680.jpg"}, {"question": "what comes out of the black box with the green screen", "gt answer": "music(1.00)<br/>air(0.60)<br/>cd(0.60)", "pred answer": "coin", "question_id": 5501815, "best approach": "concept", "verif answer": "headphone", "anno approach": "wiki, concept, image", "verif wiki answer": "headphone(0.7022)", "verif concept answer": "air(0.6834)", "verif image answer": "headphone(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000550181.jpg"}, {"question": "what is the weather", "gt answer": "foggy(1.00)<br/>storm(0.60)<br/>wood(0.60)", "pred answer": "rainy", "question_id": 760015, "best approach": "wiki, concept", "verif answer": "wood", "anno approach": "wiki, concept, image", "verif wiki answer": "foggy(0.6906)", "verif concept answer": "foggy(0.6711)", "verif image answer": "air(0.7150)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076001.jpg"}, {"question": "which brand of computer is this", "gt answer": "ibm(1.00)<br/>dell(0.60)<br/>mac(0.60)", "pred answer": "hp", "question_id": 5513445, "best approach": "image", "verif answer": "hp", "anno approach": "wiki, concept, image", "verif wiki answer": "hp(0.7001)", "verif concept answer": "mac(0.6646)", "verif image answer": "ibm(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000551344.jpg"}, {"question": "what is the fixture on the table used for", "gt answer": "light(1.00)", "pred answer": "sit", "question_id": 5489645, "best approach": "wiki, concept, image", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "light(0.7078)", "verif concept answer": "light(0.6671)", "verif image answer": "light(0.6801)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548964.jpg"}, {"question": "what is the man putting on", "gt answer": "cloth(1.00)<br/>coat(0.60)<br/>shirt(0.60)", "pred answer": "scarf", "question_id": 2527595, "best approach": "", "verif answer": "towel", "anno approach": "wiki, concept, image", "verif wiki answer": "towel(0.6969)", "verif concept answer": "towel(0.7056)", "verif image answer": "towel(0.7141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252759.jpg"}, {"question": "what type of flowers are in the blue flower pot", "gt answer": "daisy(0.60)<br/>rose(1.00)", "pred answer": "tulip", "question_id": 2155345, "best approach": "", "verif answer": "tulip", "anno approach": "wiki, concept, image", "verif wiki answer": "tulip(0.6117)", "verif concept answer": "tulip(0.6640)", "verif image answer": "tulip(0.7275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215534.jpg"}, {"question": "what is she doing", "gt answer": "take selfie(1.00)<br/>take picture(0.60)<br/>take photo(0.60)", "pred answer": "film", "question_id": 290415, "best approach": "wiki", "verif answer": "film", "anno approach": "wiki, concept, image", "verif wiki answer": "take selfie(0.6306)", "verif concept answer": "take picture(0.6421)", "verif image answer": "film(0.6463)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029041.jpg"}, {"question": "what kind of ethnicity are the people", "gt answer": "white(1.00)<br/>american(1.00)", "pred answer": "caucasian", "question_id": 3378825, "best approach": "wiki, concept", "verif answer": "white", "anno approach": "wiki, concept, image", "verif wiki answer": "american(0.6269)", "verif concept answer": "white(0.6351)", "verif image answer": "greek(0.5457)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337882.jpg"}, {"question": "what dairy products are in cake", "gt answer": "milk(1.00)<br/>cheese(0.60)", "pred answer": "sugar", "question_id": 5353695, "best approach": "wiki, concept", "verif answer": "milk", "anno approach": "wiki, concept, image", "verif wiki answer": "milk(0.6634)", "verif concept answer": "milk(0.5991)", "verif image answer": "bread(0.6411)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535369.jpg"}, {"question": "this floor is being fitted what type of floor do you think it is", "gt answer": "laminate(1.00)<br/>wood(1.00)<br/>hardwood(0.60)", "pred answer": "carpet", "question_id": 4674315, "best approach": "image", "verif answer": "laminate", "anno approach": "wiki, concept, image", "verif wiki answer": "mahogany(0.7050)", "verif concept answer": "hardwood(0.5345)", "verif image answer": "laminate(0.6819)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467431.jpg"}, {"question": "what is the terrain in the background called", "gt answer": "hill(1.00)<br/>mountain(0.60)", "pred answer": "desert", "question_id": 4377745, "best approach": "wiki, concept, image", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "hill(0.6816)", "verif concept answer": "hill(0.6321)", "verif image answer": "hill(0.7022)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437774.jpg"}, {"question": "what are the stack of white cups on the left used for", "gt answer": "measure(1.00)<br/>sugar(0.60)<br/>paint(0.60)", "pred answer": "decoration", "question_id": 5094825, "best approach": "wiki", "verif answer": "decoration", "anno approach": "wiki, concept, image", "verif wiki answer": "paint(0.5877)", "verif concept answer": "frost(0.5631)", "verif image answer": "frost(0.6247)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509482.jpg"}, {"question": "what team are these players playing for", "gt answer": "cardinal(1.00)", "pred answer": "red sox", "question_id": 1308165, "best approach": "wiki, concept", "verif answer": "red sox", "anno approach": "wiki, concept, image", "verif wiki answer": "cardinal(0.6418)", "verif concept answer": "cardinal(0.6541)", "verif image answer": "yankees(0.6454)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130816.jpg"}, {"question": "what chromosome is most abundant in the sex gametes of these children", "gt answer": "y(1.00)<br/>young(0.60)", "pred answer": "0", "question_id": 1474665, "best approach": "image", "verif answer": "young", "anno approach": "wiki, concept, image", "verif wiki answer": "young(0.6875)", "verif concept answer": "jack and jill(0.5659)", "verif image answer": "y(0.5514)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000147466.jpg"}, {"question": "what kind of horses are these", "gt answer": "arabian(1.00)<br/>stallion(0.60)<br/>thoroughbred(0.60)", "pred answer": "mustang", "question_id": 604525, "best approach": "wiki, image", "verif answer": "mustang", "anno approach": "wiki, concept, image", "verif wiki answer": "arabian(0.6139)", "verif concept answer": "stallion(0.6304)", "verif image answer": "arabian(0.6237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060452.jpg"}, {"question": "what type of man made structure meant for cars features similar striping", "gt answer": "road(1.00)<br/>pinstripe(0.60)", "pred answer": "fence", "question_id": 427505, "best approach": "wiki, concept", "verif answer": "asphalt", "anno approach": "wiki, concept, image", "verif wiki answer": "road(0.5274)", "verif concept answer": "road(0.6078)", "verif image answer": "highway(0.5789)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042750.jpg"}, {"question": "what is unusual about this baseball photo", "gt answer": "gum(1.00)", "pred answer": "color", "question_id": 5007405, "best approach": "wiki, image", "verif answer": "color", "anno approach": "wiki, concept, image", "verif wiki answer": "gum(0.5964)", "verif concept answer": "color(0.5938)", "verif image answer": "gum(0.5615)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000500740.jpg"}, {"question": "what is the cat lying on", "gt answer": "chair(1.00)<br/>bed(0.60)", "pred answer": "table", "question_id": 3016975, "best approach": "concept", "verif answer": "chair", "anno approach": "wiki, concept, image", "verif wiki answer": "furniture(0.6831)", "verif concept answer": "chair(0.6631)", "verif image answer": "luggage(0.7194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000301697.jpg"}, {"question": "what is this type of car called", "gt answer": "dump truck(1.00)<br/>food truck(0.60)<br/>truck(0.60)", "pred answer": "tractor trailer", "question_id": 5297875, "best approach": "", "verif answer": "garbage truck", "anno approach": "wiki, concept, image", "verif wiki answer": "ice cream(0.6949)", "verif concept answer": "garbage truck(0.6456)", "verif image answer": "garbage truck(0.5535)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529787.jpg"}, {"question": "what airline are those airplanes from", "gt answer": "alitalia(1.00)<br/>alaska(0.60)", "pred answer": "united", "question_id": 1327735, "best approach": "wiki, concept", "verif answer": "boeing", "anno approach": "wiki, concept, image", "verif wiki answer": "alitalia(0.6027)", "verif concept answer": "alitalia(0.5999)", "verif image answer": "boeing(0.6597)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000132773.jpg"}, {"question": "what vehicle is the dog inside", "gt answer": "van(1.00)<br/>truck(0.60)", "pred answer": "bus", "question_id": 4415235, "best approach": "image", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "suv(0.5790)", "verif concept answer": "cargo van(0.6280)", "verif image answer": "van(0.5287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441523.jpg"}, {"question": "is this bus for tours or leisure", "gt answer": "tour(1.00)", "pred answer": "both", "question_id": 246005, "best approach": "", "verif answer": "passenger", "anno approach": "wiki, concept, image", "verif wiki answer": "transport people(0.6228)", "verif concept answer": "downtown(0.5666)", "verif image answer": "transport people(0.5722)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000024600.jpg"}, {"question": "what fruit does that piney plant produce", "gt answer": "coconut(1.00)<br/>pineapple(0.60)", "pred answer": "apple", "question_id": 3104165, "best approach": "concept", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "pine(0.5855)", "verif concept answer": "coconut(0.5811)", "verif image answer": "orange(0.6732)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310416.jpg"}, {"question": "what is the life span of this animal", "gt answer": "15 years(1.00)<br/>70 years(0.60)<br/>25(0.60)", "pred answer": "30 years", "question_id": 2789225, "best approach": "wiki, image", "verif answer": "25 years", "anno approach": "wiki, concept, image", "verif wiki answer": "70 years(0.6549)", "verif concept answer": "9 years(0.6244)", "verif image answer": "70 years(0.6522)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278922.jpg"}, {"question": "what is the name for those pieces of wood", "gt answer": "chopstick(1.00)", "pred answer": "fruit", "question_id": 2621805, "best approach": "", "verif answer": "cherry", "anno approach": "wiki, concept, image", "verif wiki answer": "fork and knife(0.6445)", "verif concept answer": "fork and knife(0.6944)", "verif image answer": "fork and knife(0.6113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262180.jpg"}, {"question": "would your mom be happy or mad if she saw you do this", "gt answer": "mad(1.00)", "pred answer": "sad", "question_id": 396805, "best approach": "wiki", "verif answer": "sad", "anno approach": "wiki, concept, image", "verif wiki answer": "mad(0.6727)", "verif concept answer": "anger(0.5727)", "verif image answer": "anger(0.6701)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039680.jpg"}, {"question": "what is this man doing", "gt answer": "play wii(1.00)<br/>game(0.60)<br/>watch(0.60)", "pred answer": "video game", "question_id": 1642905, "best approach": "concept, image", "verif answer": "video game", "anno approach": "wiki, concept, image", "verif wiki answer": "video game(0.6612)", "verif concept answer": "watch(0.6391)", "verif image answer": "watch(0.6962)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000164290.jpg"}, {"question": "if this man was to hit a ball into the dugout that would be called a what type of ball", "gt answer": "foul(1.00)", "pred answer": "bat", "question_id": 949205, "best approach": "", "verif answer": "baseball", "anno approach": "wiki, concept, image", "verif wiki answer": "bunt(0.6360)", "verif concept answer": "bunt(0.6673)", "verif image answer": "bunt(0.6616)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094920.jpg"}, {"question": "how many wheels does this truck likely have", "gt answer": "8(1.00)<br/>18(0.60)<br/>12(0.60)<br/>6(0.60)", "pred answer": "20", "question_id": 1175145, "best approach": "wiki, concept, image", "verif answer": "12", "anno approach": "wiki, concept, image", "verif wiki answer": "18(0.6971)", "verif concept answer": "18(0.5992)", "verif image answer": "18(0.7080)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117514.jpg"}, {"question": "what recipe might you use the food on sale for", "gt answer": "banana bread(1.00)<br/>salad(0.60)", "pred answer": "fruit", "question_id": 5615945, "best approach": "concept", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "salad(0.6101)", "verif concept answer": "banana bread(0.5762)", "verif image answer": "salad(0.6683)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561594.jpg"}, {"question": "what name for a man could this picture bring to mind", "gt answer": "john(1.00)", "pred answer": "cat", "question_id": 4475525, "best approach": "", "verif answer": "revel", "anno approach": "wiki, concept, image", "verif wiki answer": "revel(0.5543)", "verif concept answer": "revel(0.6048)", "verif image answer": "revel(0.5033)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447552.jpg"}, {"question": "where would you see this", "gt answer": "ski lodge(1.00)<br/>ski resort(0.60)<br/>ski(0.60)", "pred answer": "beach", "question_id": 3047105, "best approach": "wiki, concept, image", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "ski resort(0.6899)", "verif concept answer": "ski resort(0.6284)", "verif image answer": "ski(0.6934)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304710.jpg"}, {"question": "what happened to the umbrella", "gt answer": "blew over(1.00)<br/>wind(0.60)", "pred answer": "fell", "question_id": 2573885, "best approach": "wiki, concept", "verif answer": "fell", "anno approach": "wiki, concept, image", "verif wiki answer": "blew over(0.6086)", "verif concept answer": "blew over(0.6218)", "verif image answer": "wind(0.6517)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257388.jpg"}, {"question": "how is the grass cut", "gt answer": "short(1.00)", "pred answer": "with knife", "question_id": 53125, "best approach": "", "verif answer": "long", "anno approach": "wiki, concept, image", "verif wiki answer": "long(0.6224)", "verif concept answer": "long(0.5844)", "verif image answer": "boy(0.6838)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005312.jpg"}, {"question": "what is the name of the hat on these people", "gt answer": "toque(1.00)<br/>chef(0.60)", "pred answer": "beanie", "question_id": 3423535, "best approach": "", "verif answer": "chef", "anno approach": "wiki, concept, image", "verif wiki answer": "farmer(0.5320)", "verif concept answer": "farmer(0.5633)", "verif image answer": "farmer(0.5598)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342353.jpg"}, {"question": "which airline does the plane belong to", "gt answer": "air france(1.00)<br/>american(0.60)<br/>asia(0.60)", "pred answer": "american airline", "question_id": 3084755, "best approach": "wiki", "verif answer": "asia", "anno approach": "wiki, concept, image", "verif wiki answer": "asia(0.5953)", "verif concept answer": "china(0.5792)", "verif image answer": "alaska(0.5698)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000308475.jpg"}, {"question": "one of these has approximately how many calories", "gt answer": "250(1.00)<br/>200(0.60)", "pred answer": "300", "question_id": 4508565, "best approach": "concept", "verif answer": "400", "anno approach": "wiki, concept, image", "verif wiki answer": "400(0.6053)", "verif concept answer": "250(0.5996)", "verif image answer": "200(0.5699)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450856.jpg"}, {"question": "the animal pictured here originated on what continent", "gt answer": "europe(1.00)<br/>africa(0.60)<br/>united kingdom(0.60)", "pred answer": "north america", "question_id": 1311975, "best approach": "wiki", "verif answer": "north america", "anno approach": "wiki, concept, image", "verif wiki answer": "europe(0.6273)", "verif concept answer": "united kingdom(0.6839)", "verif image answer": "united kingdom(0.6761)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000131197.jpg"}, {"question": "what is the term for the gauge on the right", "gt answer": "speedometer(1.00)", "pred answer": "roman numeral", "question_id": 482885, "best approach": "", "verif answer": "roman", "anno approach": "wiki, concept, image", "verif wiki answer": "roman(0.7035)", "verif concept answer": "roman(0.6978)", "verif image answer": "rugby(0.6598)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048288.jpg"}, {"question": "what nationality is this chair", "gt answer": "canadian(1.00)", "pred answer": "american", "question_id": 5623055, "best approach": "wiki", "verif answer": "us", "anno approach": "wiki, concept, image", "verif wiki answer": "canadian(0.5910)", "verif concept answer": "maple leaf(0.6007)", "verif image answer": "us(0.6554)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000562305.jpg"}, {"question": "why are all of these people in the same room", "gt answer": "party(1.00)", "pred answer": "storage", "question_id": 3148495, "best approach": "", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "birthday(0.6464)", "verif concept answer": "birthday party(0.6378)", "verif image answer": "birthday(0.6486)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314849.jpg"}, {"question": "what is the main ingredient of this dessert", "gt answer": "chocolate(1.00)<br/>flour(1.00)<br/>sugar(0.60)", "pred answer": "vanilla", "question_id": 2076295, "best approach": "concept", "verif answer": "flour", "anno approach": "wiki, concept, image", "verif wiki answer": "caramel(0.6115)", "verif concept answer": "flour(0.6225)", "verif image answer": "caramel(0.6672)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207629.jpg"}, {"question": "what is this cat doing", "gt answer": "sleep(1.00)", "pred answer": "work", "question_id": 5544085, "best approach": "wiki", "verif answer": "sleep", "anno approach": "wiki, concept, image", "verif wiki answer": "sleep(0.5723)", "verif concept answer": "tired(0.5615)", "verif image answer": "read(0.6541)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554408.jpg"}, {"question": "what nationality is this lady from", "gt answer": "asia(1.00)<br/>china(1.00)<br/>chinese(0.60)", "pred answer": "india", "question_id": 5575145, "best approach": "wiki, concept", "verif answer": "asian", "anno approach": "wiki, concept, image", "verif wiki answer": "china(0.6388)", "verif concept answer": "china(0.5971)", "verif image answer": "asian(0.6562)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000557514.jpg"}, {"question": "how common is this form of transportation", "gt answer": "very(1.00)", "pred answer": "common", "question_id": 60685, "best approach": "", "verif answer": "very", "anno approach": "wiki, concept, image", "verif wiki answer": "moderately(0.7149)", "verif concept answer": "moderately(0.6207)", "verif image answer": "moderately(0.6518)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006068.jpg"}, {"question": "who does he work for", "gt answer": "dixie chopper(1.00)<br/>dixie(0.60)", "pred answer": "farmer", "question_id": 3258505, "best approach": "", "verif answer": "police officer", "anno approach": "wiki, concept, image", "verif wiki answer": "police officer(0.5732)", "verif concept answer": "kingston transit(0.5351)", "verif image answer": "police(0.5437)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325850.jpg"}, {"question": "what celebration are these people attending", "gt answer": "mardi gras(1.00)<br/>graduation(0.60)", "pred answer": "rally", "question_id": 4788725, "best approach": "image", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "christmas(0.5753)", "verif concept answer": "christmas(0.5718)", "verif image answer": "graduation(0.6117)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000478872.jpg"}, {"question": "how old is the man", "gt answer": "20(1.00)<br/>22(0.60)<br/>30(0.60)<br/>25(0.60)", "pred answer": "forty", "question_id": 3614775, "best approach": "concept", "verif answer": "25", "anno approach": "wiki, concept, image", "verif wiki answer": "30(0.6499)", "verif concept answer": "20(0.6259)", "verif image answer": "22(0.6204)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361477.jpg"}, {"question": "what famous children 's cartoon featuring a boy and the above breed of dog was made into a live action movie", "gt answer": "lassie(1.00)", "pred answer": "mary poppins", "question_id": 467535, "best approach": "wiki", "verif answer": "lassie", "anno approach": "wiki, concept, image", "verif wiki answer": "lassie(0.6732)", "verif concept answer": "toy r us(0.5588)", "verif image answer": "magazine(0.5598)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046753.jpg"}, {"question": "is this television broken or working", "gt answer": "broken(1.00)", "pred answer": "play", "question_id": 4576545, "best approach": "concept", "verif answer": "broken", "anno approach": "wiki, concept, image", "verif wiki answer": "accident(0.5069)", "verif concept answer": "broken(0.5145)", "verif image answer": "bent(0.6950)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457654.jpg"}, {"question": "what type of television is this", "gt answer": "crt(1.00)<br/>old(0.60)<br/>news(0.60)", "pred answer": "analog", "question_id": 4662775, "best approach": "wiki, concept, image", "verif answer": "crt", "anno approach": "wiki, concept, image", "verif wiki answer": "crt(0.7029)", "verif concept answer": "crt(0.6541)", "verif image answer": "crt(0.6720)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000466277.jpg"}, {"question": "what wallpaper this is", "gt answer": "striped(1.00)", "pred answer": "floral", "question_id": 2958895, "best approach": "", "verif answer": "striped", "anno approach": "wiki, concept, image", "verif wiki answer": "calico(0.6422)", "verif concept answer": "calico(0.6452)", "verif image answer": "solid(0.7045)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000295889.jpg"}, {"question": "what hairstyle is this", "gt answer": "long(1.00)", "pred answer": "ponytail", "question_id": 899435, "best approach": "wiki, concept, image", "verif answer": "long", "anno approach": "wiki, concept, image", "verif wiki answer": "long(0.5992)", "verif concept answer": "long(0.5862)", "verif image answer": "long(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000089943.jpg"}, {"question": "what is leaning on the truck", "gt answer": "stick(1.00)", "pred answer": "luggage", "question_id": 5161895, "best approach": "wiki, concept, image", "verif answer": "pole", "anno approach": "wiki, concept, image", "verif wiki answer": "stick(0.5226)", "verif concept answer": "stick(0.5598)", "verif image answer": "stick(0.5191)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516189.jpg"}, {"question": "how come there are metal strips on the ground", "gt answer": "train track(1.00)<br/>train(0.60)", "pred answer": "track", "question_id": 985435, "best approach": "", "verif answer": "track", "anno approach": "wiki, concept, image", "verif wiki answer": "track(0.5138)", "verif concept answer": "track(0.6854)", "verif image answer": "bridge(0.6240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098543.jpg"}, {"question": "what kind of protein is in this dish", "gt answer": "beef(1.00)<br/>vegetable(0.60)<br/>meat(0.60)<br/>regular(0.60)", "pred answer": "shrimp", "question_id": 3276605, "best approach": "wiki, concept, image", "verif answer": "pork", "anno approach": "wiki, concept, image", "verif wiki answer": "regular(0.6481)", "verif concept answer": "regular(0.6370)", "verif image answer": "meat(0.5763)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000327660.jpg"}, {"question": "what is this decoration for", "gt answer": "christmas(1.00)", "pred answer": "halloween", "question_id": 1546375, "best approach": "concept, image", "verif answer": "christmas", "anno approach": "wiki, concept, image", "verif wiki answer": "winter(0.6451)", "verif concept answer": "christmas(0.5782)", "verif image answer": "christmas(0.7165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154637.jpg"}, {"question": "what would pose the greatest risk to a person working on this boat", "gt answer": "drown(1.00)<br/>fall(0.60)<br/>hurricane(0.60)", "pred answer": "moon", "question_id": 4995965, "best approach": "concept", "verif answer": "death", "anno approach": "wiki, concept, image", "verif wiki answer": "death(0.6764)", "verif concept answer": "drown(0.5737)", "verif image answer": "fall(0.6408)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499596.jpg"}, {"question": "", "gt answer": "wood(0.60)<br/>alaska(0.60)<br/>arctic(0.60)", "pred answer": "bear", "question_id": 3543265, "best approach": "wiki, concept, image", "verif answer": "alaska", "anno approach": "wiki, concept, image", "verif wiki answer": "wood(0.6483)", "verif concept answer": "wood(0.6278)", "verif image answer": "wood(0.5959)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354326.jpg"}, {"question": "what kind of car is this", "gt answer": "antique(1.00)<br/>vintage(0.60)<br/>ford(0.60)", "pred answer": "jeep", "question_id": 4569495, "best approach": "image", "verif answer": "honda", "anno approach": "wiki, concept, image", "verif wiki answer": "model t(0.6202)", "verif concept answer": "model t(0.6149)", "verif image answer": "ford(0.6207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456949.jpg"}, {"question": "what is in the mug", "gt answer": "coffee(1.00)", "pred answer": "tea", "question_id": 386865, "best approach": "", "verif answer": "tea", "anno approach": "wiki, concept, image", "verif wiki answer": "cocoa(0.6819)", "verif concept answer": "cocoa(0.6910)", "verif image answer": "tea(0.7187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038686.jpg"}, {"question": "what breed of dogs are pictured here", "gt answer": "labrador(1.00)<br/>lab(0.60)", "pred answer": "mutt", "question_id": 3154235, "best approach": "", "verif answer": "golden retriever", "anno approach": "wiki, concept, image", "verif wiki answer": "golden retriever(0.6195)", "verif concept answer": "golden retriever(0.5868)", "verif image answer": "black labrador(0.5658)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315423.jpg"}, {"question": "would that be considered a baby or adult lamb", "gt answer": "adult(1.00)<br/>lamb(0.60)<br/>baby(0.60)", "pred answer": "young", "question_id": 2087795, "best approach": "concept", "verif answer": "lamb", "anno approach": "wiki, concept, image", "verif wiki answer": "baby(0.6370)", "verif concept answer": "adult(0.5716)", "verif image answer": "lamb(0.7154)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208779.jpg"}, {"question": "what do the goggles protect this person from", "gt answer": "snow(1.00)<br/>glare(0.60)", "pred answer": "avalanche", "question_id": 5706945, "best approach": "wiki, image", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "glare(0.6808)", "verif concept answer": "snowy(0.5660)", "verif image answer": "glare(0.6091)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570694.jpg"}, {"question": "which tools are needed for this task", "gt answer": "camera(1.00)<br/>hammer(0.60)", "pred answer": "computer", "question_id": 943595, "best approach": "wiki, concept", "verif answer": "computer", "anno approach": "wiki, concept, image", "verif wiki answer": "hammer(0.5804)", "verif concept answer": "hammer(0.6727)", "verif image answer": "film(0.6238)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094359.jpg"}, {"question": "what company makes those shoes", "gt answer": "timberland(1.00)<br/>walmart(0.60)", "pred answer": "nike", "question_id": 4263185, "best approach": "image", "verif answer": "shoemaker", "anno approach": "wiki, concept, image", "verif wiki answer": "shoemaker(0.6849)", "verif concept answer": "shoemaker(0.5760)", "verif image answer": "timberland(0.5250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426318.jpg"}, {"question": "what kind of instrument is this", "gt answer": "piano(1.00)<br/>keyboard(1.00)", "pred answer": "guitar", "question_id": 5174925, "best approach": "wiki, concept, image", "verif answer": "piano", "anno approach": "wiki, concept, image", "verif wiki answer": "piano(0.6698)", "verif concept answer": "piano(0.6955)", "verif image answer": "keyboard(0.5891)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517492.jpg"}, {"question": "what is the nutritional value of the fruit in the picture", "gt answer": "high(1.00)<br/>good(0.60)", "pred answer": "500", "question_id": 2064275, "best approach": "wiki", "verif answer": "good", "anno approach": "wiki, concept, image", "verif wiki answer": "high(0.5813)", "verif concept answer": "high end(0.5740)", "verif image answer": "poor(0.5687)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206427.jpg"}, {"question": "how often does that clock get clean", "gt answer": "not often(1.00)<br/>monthly(0.60)", "pred answer": "daily", "question_id": 2997045, "best approach": "wiki, concept", "verif answer": "rarely", "anno approach": "wiki, concept, image", "verif wiki answer": "monthly(0.5773)", "verif concept answer": "monthly(0.6379)", "verif image answer": "rarely(0.7106)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000299704.jpg"}, {"question": "what makes that line in the sky", "gt answer": "plane(1.00)<br/>airplane(1.00)<br/>cloud(0.60)", "pred answer": "power line", "question_id": 2307415, "best approach": "wiki, concept, image", "verif answer": "cloud", "anno approach": "wiki, concept, image", "verif wiki answer": "cloud(0.6570)", "verif concept answer": "cloud(0.5997)", "verif image answer": "cloud(0.6782)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000230741.jpg"}, {"question": "what is the sauce on the side", "gt answer": "mustard(1.00)<br/>ranch dress(0.60)", "pred answer": "meat", "question_id": 2625525, "best approach": "wiki, concept, image", "verif answer": "fry", "anno approach": "wiki, concept, image", "verif wiki answer": "ranch dress(0.6558)", "verif concept answer": "ranch dress(0.6148)", "verif image answer": "ranch dress(0.7072)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262552.jpg"}, {"question": "what kind of computer is that", "gt answer": "tablet(1.00)<br/>samsung(0.60)", "pred answer": "desktop", "question_id": 1767595, "best approach": "", "verif answer": "apple", "anno approach": "wiki, concept, image", "verif wiki answer": "television(0.6343)", "verif concept answer": "television(0.6614)", "verif image answer": "television(0.7173)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176759.jpg"}, {"question": "what are these people waiting for", "gt answer": "parade(1.00)", "pred answer": "race", "question_id": 424815, "best approach": "", "verif answer": "rally", "anno approach": "wiki, concept, image", "verif wiki answer": "fence(0.6047)", "verif concept answer": "rally(0.5486)", "verif image answer": "rally(0.5776)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042481.jpg"}, {"question": "what is the role of the person who would sit in this desk", "gt answer": "student(1.00)", "pred answer": "sit", "question_id": 1300705, "best approach": "wiki", "verif answer": "student", "anno approach": "wiki, concept, image", "verif wiki answer": "student(0.5707)", "verif concept answer": "kid(0.5683)", "verif image answer": "kid(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000130070.jpg"}, {"question": "how many pounds of thrust is required for this plane to take off from the water", "gt answer": "100(1.00)<br/>1000(0.60)<br/>600(0.60)", "pred answer": "300", "question_id": 3888855, "best approach": "concept, image", "verif answer": "100", "anno approach": "wiki, concept, image", "verif wiki answer": "50 years(0.6249)", "verif concept answer": "600(0.6079)", "verif image answer": "600(0.6164)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388885.jpg"}, {"question": "what transport company owns this bus", "gt answer": "smrt(1.00)<br/>public(0.60)", "pred answer": "greyhound", "question_id": 4442355, "best approach": "concept", "verif answer": "united", "anno approach": "wiki, concept, image", "verif wiki answer": "both(0.6221)", "verif concept answer": "smrt(0.5897)", "verif image answer": "tourist(0.5461)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000444235.jpg"}, {"question": "name the dog bread shown in this picture", "gt answer": "beagle(1.00)", "pred answer": "doughnut", "question_id": 2380735, "best approach": "wiki, concept", "verif answer": "beagle", "anno approach": "wiki, concept, image", "verif wiki answer": "beagle(0.5830)", "verif concept answer": "beagle(0.6185)", "verif image answer": "collie(0.6097)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238073.jpg"}, {"question": "what should the mirrors be cleaned with", "gt answer": "windex(1.00)<br/>soap(0.60)<br/>newspaper(0.60)", "pred answer": "bleach", "question_id": 2090405, "best approach": "wiki, concept, image", "verif answer": "bleach", "anno approach": "wiki, concept, image", "verif wiki answer": "windex(0.6321)", "verif concept answer": "windex(0.6037)", "verif image answer": "windex(0.7197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209040.jpg"}, {"question": "what is the name of the boating past time pictured", "gt answer": "raft(1.00)<br/>kayak(0.60)", "pred answer": "boat", "question_id": 5466515, "best approach": "wiki, concept, image", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "kayak(0.7167)", "verif concept answer": "kayak(0.6772)", "verif image answer": "kayak(0.6842)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000546651.jpg"}, {"question": "is the scene indoors or outdoors", "gt answer": "outdoor(1.00)", "pred answer": "indoor", "question_id": 4479775, "best approach": "", "verif answer": "indoor", "anno approach": "wiki, concept, image", "verif wiki answer": "indoor(0.7077)", "verif concept answer": "indoor(0.6119)", "verif image answer": "outside(0.5527)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447977.jpg"}, {"question": "how do we know this person is in all likelihood near or far sighted", "gt answer": "glass(1.00)", "pred answer": "far", "question_id": 45785, "best approach": "", "verif answer": "wine glass", "anno approach": "wiki, concept, image", "verif wiki answer": "wine glass(0.6379)", "verif concept answer": "cane(0.5123)", "verif image answer": "plastic(0.5683)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004578.jpg"}, {"question": "apart from talk how else can these device send messages", "gt answer": "text(1.00)", "pred answer": "electricity", "question_id": 3578775, "best approach": "concept", "verif answer": "text", "anno approach": "wiki, concept, image", "verif wiki answer": "play game(0.6016)", "verif concept answer": "text(0.6457)", "verif image answer": "flip(0.6954)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357877.jpg"}, {"question": "when was the food item in this photo invented", "gt answer": "1484(1.00)<br/>1900(0.60)", "pred answer": "1903", "question_id": 3743515, "best approach": "", "verif answer": "1950s", "anno approach": "wiki, concept, image", "verif wiki answer": "1900's(0.6625)", "verif concept answer": "1900's(0.6522)", "verif image answer": "1900's(0.6479)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374351.jpg"}, {"question": "how de we know this horse is unlikely to be awaiting a rider", "gt answer": "no saddle(1.00)<br/>wild(0.60)", "pred answer": "not at all", "question_id": 313765, "best approach": "wiki", "verif answer": "wild", "anno approach": "wiki, concept, image", "verif wiki answer": "no saddle(0.5733)", "verif concept answer": "wild(0.6186)", "verif image answer": "domesticated(0.6865)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000031376.jpg"}, {"question": "what is on the kid 's elbows", "gt answer": "pad(1.00)", "pred answer": "peace", "question_id": 5657145, "best approach": "image", "verif answer": "glove", "anno approach": "wiki, concept, image", "verif wiki answer": "glove(0.6850)", "verif concept answer": "glove(0.5701)", "verif image answer": "pad(0.5896)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000565714.jpg"}, {"question": "where can a clock like this one be purchased", "gt answer": "ikea(1.00)<br/>walmart(0.60)<br/>ebay(0.60)", "pred answer": "furniture store", "question_id": 357635, "best approach": "image", "verif answer": "furniture store", "anno approach": "wiki, concept, image", "verif wiki answer": "furniture store(0.5973)", "verif concept answer": "furniture store(0.6048)", "verif image answer": "ikea(0.5758)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000035763.jpg"}, {"question": "what kind of style shirt is this woman wearing", "gt answer": "dress shirt(1.00)<br/>button up(0.60)", "pred answer": "button down", "question_id": 508175, "best approach": "wiki, concept, image", "verif answer": "button down", "anno approach": "wiki, concept, image", "verif wiki answer": "button up(0.6723)", "verif concept answer": "button up(0.7087)", "verif image answer": "button up(0.7207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000050817.jpg"}, {"question": "what kind of market is this", "gt answer": "farmer(1.00)<br/>public(0.60)<br/>produce(0.60)", "pred answer": "farmer market", "question_id": 1413425, "best approach": "wiki, image", "verif answer": "farmer market", "anno approach": "wiki, concept, image", "verif wiki answer": "public(0.6600)", "verif concept answer": "supermarket(0.6406)", "verif image answer": "produce(0.6988)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000141342.jpg"}, {"question": "what type of sugar is on top of this dish", "gt answer": "powdered(1.00)<br/>white(0.60)", "pred answer": "chocolate", "question_id": 1529145, "best approach": "", "verif answer": "jelly filled", "anno approach": "wiki, concept, image", "verif wiki answer": "jelly filled(0.6178)", "verif concept answer": "jelly filled(0.5930)", "verif image answer": "espresso(0.5678)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000152914.jpg"}, {"question": "how can i grow these myself", "gt answer": "plant garden(1.00)", "pred answer": "tree", "question_id": 148495, "best approach": "", "verif answer": "not", "anno approach": "wiki, concept, image", "verif wiki answer": "not(0.6358)", "verif concept answer": "closet(0.5922)", "verif image answer": "not(0.7136)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000014849.jpg"}, {"question": "what is usually in this drink", "gt answer": "spinach(1.00)<br/>broccoli(0.60)<br/>ice cream(0.60)<br/>sprite(0.60)", "pred answer": "juice", "question_id": 1443305, "best approach": "wiki, image", "verif answer": "ice cream", "anno approach": "wiki, concept, image", "verif wiki answer": "sprite(0.6599)", "verif concept answer": "kale(0.6417)", "verif image answer": "ice cream(0.6624)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144330.jpg"}, {"question": "what are the square objects on the walls", "gt answer": "picture(1.00)<br/>paint(0.60)", "pred answer": "light", "question_id": 5545075, "best approach": "", "verif answer": "tv", "anno approach": "wiki, concept, image", "verif wiki answer": "flower(0.5996)", "verif concept answer": "tv(0.6461)", "verif image answer": "tv(0.6916)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000554507.jpg"}, {"question": "how are these animals being contained", "gt answer": "fence(1.00)", "pred answer": "zoo", "question_id": 3458035, "best approach": "", "verif answer": "fence", "anno approach": "wiki, concept, image", "verif wiki answer": "wall(0.6197)", "verif concept answer": "wall(0.6408)", "verif image answer": "wood(0.5527)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000345803.jpg"}, {"question": "what other things does this company do", "gt answer": "phone(1.00)<br/>hotel(0.60)", "pred answer": "fly", "question_id": 5338355, "best approach": "wiki", "verif answer": "online", "anno approach": "wiki, concept, image", "verif wiki answer": "phone(0.5941)", "verif concept answer": "telephone(0.5977)", "verif image answer": "hotel(0.5275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000533835.jpg"}, {"question": "what airline is this", "gt answer": "klm(1.00)", "pred answer": "united", "question_id": 2629805, "best approach": "concept", "verif answer": "transat", "anno approach": "wiki, concept, image", "verif wiki answer": "transat(0.6118)", "verif concept answer": "klm(0.5957)", "verif image answer": "colombia(0.6973)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000262980.jpg"}, {"question": "when was the soft drink company shown first created", "gt answer": "1898(1.00)<br/>1968(0.60)", "pred answer": "1930", "question_id": 3149935, "best approach": "wiki, concept, image", "verif answer": "1970", "anno approach": "wiki, concept, image", "verif wiki answer": "1898(0.6568)", "verif concept answer": "1898(0.6557)", "verif image answer": "1898(0.7123)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314993.jpg"}, {"question": "what type of pizza is this", "gt answer": "deep dish(1.00)<br/>pepperoni(0.60)", "pred answer": "supreme", "question_id": 583385, "best approach": "wiki, concept, image", "verif answer": "pepperoni", "anno approach": "wiki, concept, image", "verif wiki answer": "pepperoni(0.7276)", "verif concept answer": "pepperoni(0.7276)", "verif image answer": "pepperoni(0.7294)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058338.jpg"}, {"question": "how long does this animals teeth grow to be", "gt answer": "2 inches(1.00)", "pred answer": "30 years", "question_id": 183855, "best approach": "", "verif answer": "4", "anno approach": "wiki, concept, image", "verif wiki answer": "2.5 cm(0.6244)", "verif concept answer": "4(0.6109)", "verif image answer": "4(0.6454)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000018385.jpg"}, {"question": "what musical instrument", "gt answer": "piano(1.00)<br/>wii(0.60)", "pred answer": "guitar", "question_id": 1766715, "best approach": "wiki, concept, image", "verif answer": "piano", "anno approach": "wiki, concept, image", "verif wiki answer": "piano(0.7294)", "verif concept answer": "piano(0.7292)", "verif image answer": "piano(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176671.jpg"}, {"question": "which popular john denver song talks about leaving on one of these", "gt answer": "leave on jet plane(1.00)<br/>california(0.60)", "pred answer": "abbey", "question_id": 805185, "best approach": "", "verif answer": "toxoplasmosis", "anno approach": "wiki, concept, image", "verif wiki answer": "usa(0.6076)", "verif concept answer": "world war 2(0.6212)", "verif image answer": "usa(0.6694)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080518.jpg"}, {"question": "where was this picture taken", "gt answer": "bathroom(1.00)", "pred answer": "house", "question_id": 4181145, "best approach": "concept", "verif answer": "bathroom", "anno approach": "wiki, concept, image", "verif wiki answer": "toilet(0.7013)", "verif concept answer": "bathroom(0.6890)", "verif image answer": "basin(0.6850)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000418114.jpg"}, {"question": "what health hazards are associated with this sport", "gt answer": "frost bite(1.00)<br/>death(0.60)<br/>frostbite(0.60)", "pred answer": "gravity", "question_id": 1269595, "best approach": "wiki, concept, image", "verif answer": "frostbite", "anno approach": "wiki, concept, image", "verif wiki answer": "frostbite(0.7156)", "verif concept answer": "frostbite(0.6666)", "verif image answer": "death(0.5314)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126959.jpg"}, {"question": "what direction will these cyclists travel in next", "gt answer": "straight(1.00)", "pred answer": "north", "question_id": 5439115, "best approach": "", "verif answer": "south", "anno approach": "wiki, concept, image", "verif wiki answer": "south(0.5779)", "verif concept answer": "south(0.6269)", "verif image answer": "merge right(0.6053)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543911.jpg"}, {"question": "after this culinary activity it 's considered a treat to be allowed to lick what", "gt answer": "spoon(1.00)<br/>bake(0.60)", "pred answer": "peanut", "question_id": 4419035, "best approach": "", "verif answer": "cake", "anno approach": "wiki, concept, image", "verif wiki answer": "baked(0.6370)", "verif concept answer": "fork(0.6062)", "verif image answer": "baked(0.6022)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441903.jpg"}, {"question": "how many inches large are these pizzas", "gt answer": "12(1.00)<br/>6(0.60)", "pred answer": "20", "question_id": 127355, "best approach": "image", "verif answer": "10", "anno approach": "wiki, concept, image", "verif wiki answer": "10(0.6025)", "verif concept answer": "10(0.5915)", "verif image answer": "6(0.6882)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012735.jpg"}, {"question": "what type of fasteners are used on this type of shoe", "gt answer": "lace(1.00)", "pred answer": "digital", "question_id": 2114065, "best approach": "image", "verif answer": "large", "anno approach": "wiki, concept, image", "verif wiki answer": "large(0.5603)", "verif concept answer": "large(0.5601)", "verif image answer": "lace(0.6913)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000211406.jpg"}, {"question": "from which culture does the food pictured originate", "gt answer": "american(1.00)<br/>french(0.60)", "pred answer": "india", "question_id": 5236695, "best approach": "concept", "verif answer": "american", "anno approach": "wiki, concept, image", "verif wiki answer": "western(0.6608)", "verif concept answer": "american(0.6131)", "verif image answer": "french(0.6773)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523669.jpg"}, {"question": "what is this activity called", "gt answer": "wind surf(1.00)<br/>parasailing(0.60)", "pred answer": "water ski", "question_id": 396865, "best approach": "concept", "verif answer": "wind surf", "anno approach": "wiki, concept, image", "verif wiki answer": "0(0.5579)", "verif concept answer": "wind surf(0.6038)", "verif image answer": "kiteboarding(0.5904)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039686.jpg"}, {"question": "what is this pot made out of", "gt answer": "clay(1.00)<br/>ceramic(0.60)", "pred answer": "metal", "question_id": 2579455, "best approach": "concept", "verif answer": "ceramic", "anno approach": "wiki, concept, image", "verif wiki answer": "porcelain(0.6156)", "verif concept answer": "clay(0.6201)", "verif image answer": "porcelain(0.6589)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000257945.jpg"}, {"question": "what breed of horse is shown", "gt answer": "mustang(1.00)<br/>black(0.60)<br/>thoroughbred(0.60)<br/>race(0.60)", "pred answer": "stallion", "question_id": 5615905, "best approach": "wiki, concept, image", "verif answer": "mustang", "anno approach": "wiki, concept, image", "verif wiki answer": "thoroughbred(0.6342)", "verif concept answer": "thoroughbred(0.6374)", "verif image answer": "thoroughbred(0.5789)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561590.jpg"}, {"question": "can you guess the laptop model shown in this picture", "gt answer": "ibm(1.00)", "pred answer": "dell", "question_id": 2782195, "best approach": "", "verif answer": "dell", "anno approach": "wiki, concept, image", "verif wiki answer": "hp(0.6647)", "verif concept answer": "hp(0.6340)", "verif image answer": "dell(0.5884)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000278219.jpg"}, {"question": "what kind of living space is this called", "gt answer": "trailer(1.00)<br/>rv(0.60)<br/>travel(0.60)<br/>bedroom(0.60)", "pred answer": "hotel", "question_id": 3916465, "best approach": "concept", "verif answer": "travel", "anno approach": "wiki, concept, image", "verif wiki answer": "rv(0.5345)", "verif concept answer": "trailer(0.6039)", "verif image answer": "travel(0.7056)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391646.jpg"}, {"question": "how many inches of snow are on the ground", "gt answer": "12(1.00)<br/>10(0.60)<br/>4(0.60)<br/>6(0.60)", "pred answer": "5", "question_id": 911235, "best approach": "concept", "verif answer": "5", "anno approach": "wiki, concept, image", "verif wiki answer": "5(0.6050)", "verif concept answer": "12(0.5822)", "verif image answer": "10(0.7122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000091123.jpg"}, {"question": "what are the round windows on the side of this vehicle called", "gt answer": "port(1.00)<br/>hole(0.60)", "pred answer": "bay", "question_id": 995195, "best approach": "concept", "verif answer": "bay", "anno approach": "wiki, concept, image", "verif wiki answer": "dock(0.6466)", "verif concept answer": "port(0.5693)", "verif image answer": "harbor(0.5292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099519.jpg"}, {"question": "on what tv channel could you watch something like this be prepared", "gt answer": "food network(1.00)<br/>cook(0.60)", "pred answer": "3", "question_id": 172165, "best approach": "", "verif answer": "beauty and beast", "anno approach": "wiki, concept, image", "verif wiki answer": "beauty and beast(0.6845)", "verif concept answer": "beauty and beast(0.6157)", "verif image answer": "beauty and beast(0.6978)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000017216.jpg"}, {"question": "what type of truck is this", "gt answer": "cement(1.00)<br/>concrete(0.60)", "pred answer": "tractor trailer", "question_id": 3700825, "best approach": "wiki", "verif answer": "concrete", "anno approach": "wiki, concept, image", "verif wiki answer": "cement(0.6300)", "verif concept answer": "concrete(0.6527)", "verif image answer": "dirt(0.5687)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370082.jpg"}, {"question": "what do you call that style of shower", "gt answer": "stall(1.00)", "pred answer": "modern", "question_id": 4573735, "best approach": "", "verif answer": "barn", "anno approach": "wiki, concept, image", "verif wiki answer": "barn(0.6276)", "verif concept answer": "gate(0.5501)", "verif image answer": "gate(0.5391)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000457373.jpg"}, {"question": "how is she attached to the toy", "gt answer": "rope(0.60)<br/>string(0.60)<br/>strap(1.00)", "pred answer": "paddle", "question_id": 4977095, "best approach": "wiki, concept", "verif answer": "paddle", "anno approach": "wiki, concept, image", "verif wiki answer": "string(0.6307)", "verif concept answer": "string(0.6154)", "verif image answer": "paddle(0.5881)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497709.jpg"}, {"question": "this kitchen is remodeled using what style", "gt answer": "contemporary(1.00)<br/>country(0.60)", "pred answer": "stone", "question_id": 4281525, "best approach": "image", "verif answer": "retro", "anno approach": "wiki, concept, image", "verif wiki answer": "victorian(0.5209)", "verif concept answer": "country(0.6478)", "verif image answer": "contemporary(0.7292)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428152.jpg"}, {"question": "which of the publications pictured sells the most copies annually", "gt answer": "pc gamer(1.00)<br/>magazine(0.60)", "pred answer": "library", "question_id": 3297625, "best approach": "concept", "verif answer": "interview", "anno approach": "wiki, concept, image", "verif wiki answer": "interview(0.7015)", "verif concept answer": "pc gamer(0.6565)", "verif image answer": "interview(0.6860)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000329762.jpg"}, {"question": "how many people is this arrangement best suited for", "gt answer": "1(1.00)<br/>2(0.60)", "pred answer": "8", "question_id": 4796475, "best approach": "concept, image", "verif answer": "3", "anno approach": "wiki, concept, image", "verif wiki answer": "3(0.5860)", "verif concept answer": "1(0.6219)", "verif image answer": "1(0.6398)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479647.jpg"}, {"question": "the trees in the background indicate this is what kind of terrain", "gt answer": "mountain(1.00)<br/>country(0.60)", "pred answer": "desert", "question_id": 2846705, "best approach": "concept, image", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "forest(0.5792)", "verif concept answer": "mountain(0.5965)", "verif image answer": "mountain(0.6373)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000284670.jpg"}, {"question": "where is this taken", "gt answer": "bedroom(1.00)<br/>home(0.60)", "pred answer": "hotel", "question_id": 3405475, "best approach": "wiki, image", "verif answer": "bedroom", "anno approach": "wiki, concept, image", "verif wiki answer": "bedroom(0.6560)", "verif concept answer": "home(0.6404)", "verif image answer": "bedroom(0.5920)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000340547.jpg"}, {"question": "are these guys amateur singers or professionals", "gt answer": "amateur(1.00)", "pred answer": "companion", "question_id": 2032165, "best approach": "concept, image", "verif answer": "professional", "anno approach": "wiki, concept, image", "verif wiki answer": "professional(0.5881)", "verif concept answer": "amateur(0.6013)", "verif image answer": "amateur(0.5124)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203216.jpg"}, {"question": "what kind of event is this", "gt answer": "fair(1.00)", "pred answer": "rally", "question_id": 5171155, "best approach": "", "verif answer": "festival", "anno approach": "wiki, concept, image", "verif wiki answer": "auction(0.5238)", "verif concept answer": "carnival(0.5652)", "verif image answer": "carnival(0.5912)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517115.jpg"}, {"question": "which country is this vase from", "gt answer": "egypt(1.00)<br/>africa(0.60)<br/>italy(0.60)", "pred answer": "england", "question_id": 33255, "best approach": "concept", "verif answer": "america", "anno approach": "wiki, concept, image", "verif wiki answer": "america(0.6993)", "verif concept answer": "italy(0.6215)", "verif image answer": "tennis(0.6313)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003325.jpg"}, {"question": "what event are they setting up for", "gt answer": "birthday party(1.00)<br/>new year(0.60)<br/>birthday(0.60)<br/>party(0.60)", "pred answer": "golf", "question_id": 521535, "best approach": "wiki, concept", "verif answer": "party", "anno approach": "wiki, concept, image", "verif wiki answer": "party(0.7002)", "verif concept answer": "new year(0.6418)", "verif image answer": "birthday cake(0.6281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052153.jpg"}, {"question": "what era was this room built", "gt answer": "1970's(1.00)<br/>1950s(0.60)<br/>1950's(0.60)<br/>70s(0.60)", "pred answer": "victorian", "question_id": 1408675, "best approach": "wiki, concept", "verif answer": "1950s", "anno approach": "wiki, concept, image", "verif wiki answer": "1950's(0.5597)", "verif concept answer": "70s(0.5696)", "verif image answer": "1970(0.5542)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140867.jpg"}, {"question": "what part of the body is this worn on", "gt answer": "torso(1.00)<br/>upper(0.60)<br/>stomach(0.60)", "pred answer": "foot", "question_id": 1996185, "best approach": "concept", "verif answer": "stomach", "anno approach": "wiki, concept, image", "verif wiki answer": "stomach(0.7158)", "verif concept answer": "torso(0.6171)", "verif image answer": "upper(0.6194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199618.jpg"}, {"question": "what type of building might this room be found in", "gt answer": "hotel(1.00)<br/>old(0.60)", "pred answer": "house", "question_id": 5124365, "best approach": "concept", "verif answer": "hotel", "anno approach": "wiki, concept, image", "verif wiki answer": "bedroom(0.5672)", "verif concept answer": "hotel(0.6168)", "verif image answer": "bedroom(0.6579)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512436.jpg"}, {"question": "does this look like a neat or messy kitchen", "gt answer": "messy(1.00)", "pred answer": "clean", "question_id": 2039755, "best approach": "", "verif answer": "clean", "anno approach": "wiki, concept, image", "verif wiki answer": "bang(0.6104)", "verif concept answer": "bang(0.5934)", "verif image answer": "clean(0.7095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203975.jpg"}, {"question": "what does this person appear to be doing", "gt answer": "dive(1.00)<br/>fall(1.00)<br/>play soccer(0.60)", "pred answer": "catch", "question_id": 421665, "best approach": "wiki", "verif answer": "kick", "anno approach": "wiki, concept, image", "verif wiki answer": "dive(0.6659)", "verif concept answer": "kick(0.5814)", "verif image answer": "kick(0.6980)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042166.jpg"}, {"question": "what is the girl sticking out", "gt answer": "tongue(1.00)", "pred answer": "toothbrush", "question_id": 4535195, "best approach": "image", "verif answer": "tongue", "anno approach": "wiki, concept, image", "verif wiki answer": "mouth(0.5721)", "verif concept answer": "top(0.5157)", "verif image answer": "tongue(0.5200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453519.jpg"}, {"question": "how does the size of the items on the tray compare to the typical item of this type", "gt answer": "larger(1.00)<br/>huge(0.60)", "pred answer": "large", "question_id": 3102895, "best approach": "wiki, concept", "verif answer": "large", "anno approach": "wiki, concept, image", "verif wiki answer": "huge(0.6641)", "verif concept answer": "huge(0.6047)", "verif image answer": "large(0.5324)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000310289.jpg"}, {"question": "what is that urn made of", "gt answer": "cemet(1.00)<br/>concrete(0.60)<br/>cement(0.60)<br/>clay(0.60)", "pred answer": "metal", "question_id": 4711565, "best approach": "wiki, concept, image", "verif answer": "stone", "anno approach": "wiki, concept, image", "verif wiki answer": "cement(0.7182)", "verif concept answer": "clay(0.6425)", "verif image answer": "clay(0.6593)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000471156.jpg"}, {"question": "what technique do these birds employ to acquire food", "gt answer": "peck(1.00)<br/>fish(0.60)", "pred answer": "fly", "question_id": 4130575, "best approach": "", "verif answer": "float", "anno approach": "wiki, concept, image", "verif wiki answer": "float(0.6341)", "verif concept answer": "float(0.5834)", "verif image answer": "float(0.6819)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000413057.jpg"}, {"question": "what ship is that in the background", "gt answer": "navy(1.00)", "pred answer": "cruise", "question_id": 1944385, "best approach": "", "verif answer": "military", "anno approach": "wiki, concept, image", "verif wiki answer": "airforce(0.6639)", "verif concept answer": "air force(0.6496)", "verif image answer": "airforce(0.7108)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194438.jpg"}, {"question": "in this form of trasportation what safety devise is lacking for the kids", "gt answer": "helmet(0.60)<br/>seat belt(1.00)", "pred answer": "unsafe", "question_id": 3961375, "best approach": "image", "verif answer": "seat belt", "anno approach": "wiki, concept, image", "verif wiki answer": "helmet(0.6164)", "verif concept answer": "yield(0.5997)", "verif image answer": "seat belt(0.6310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000396137.jpg"}, {"question": "what is this sort of traffic situation often called", "gt answer": "traffic jam(1.00)<br/>jam(0.60)", "pred answer": "rush hour", "question_id": 4034645, "best approach": "wiki", "verif answer": "rush hour", "anno approach": "wiki, concept, image", "verif wiki answer": "traffic jam(0.6159)", "verif concept answer": "rush hour(0.6625)", "verif image answer": "rush hour(0.5619)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403464.jpg"}, {"question": "which two continents does this animal live on", "gt answer": "africa and asia(1.00)<br/>asia and africa(0.60)", "pred answer": "north america", "question_id": 2967475, "best approach": "image", "verif answer": "asia and africa", "anno approach": "wiki, concept, image", "verif wiki answer": "asia(0.7254)", "verif concept answer": "museum(0.6686)", "verif image answer": "africa and asia(0.7197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296747.jpg"}, {"question": "name the male 's profession", "gt answer": "hair stylist(1.00)", "pred answer": "chef", "question_id": 292745, "best approach": "wiki, concept", "verif answer": "barber", "anno approach": "wiki, concept, image", "verif wiki answer": "hair stylist(0.6017)", "verif concept answer": "hair stylist(0.6422)", "verif image answer": "apple(0.5236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029274.jpg"}, {"question": "what is the pattern on this shirt", "gt answer": "checkered(1.00)", "pred answer": "striped", "question_id": 5332225, "best approach": "", "verif answer": "checkered", "anno approach": "wiki, concept, image", "verif wiki answer": "metal(0.5747)", "verif concept answer": "square(0.5875)", "verif image answer": "checkerboard(0.6733)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000533222.jpg"}, {"question": "which one of these food items was used as currency in the past", "gt answer": "salt(1.00)<br/>bread(0.60)", "pred answer": "potato", "question_id": 4274625, "best approach": "", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "dough(0.6806)", "verif concept answer": "fresh(0.5571)", "verif image answer": "salt and pepper(0.5806)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427462.jpg"}, {"question": "would one assume this was the home of someone older and reclusive or younger and sociable", "gt answer": "younger(1.00)", "pred answer": "healthy", "question_id": 5141565, "best approach": "concept", "verif answer": "young", "anno approach": "wiki, concept, image", "verif wiki answer": "young(0.6321)", "verif concept answer": "younger(0.5824)", "verif image answer": "herbivore(0.5122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514156.jpg"}, {"question": "is he backhanding or serving", "gt answer": "backhand(1.00)<br/>serve(1.00)", "pred answer": "hit", "question_id": 1660475, "best approach": "wiki, concept", "verif answer": "hit", "anno approach": "wiki, concept, image", "verif wiki answer": "serve(0.6606)", "verif concept answer": "serve(0.6268)", "verif image answer": "hit(0.6253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166047.jpg"}, {"question": "which rail company is named after a town in new mexico", "gt answer": "santa fe(1.00)", "pred answer": "subway", "question_id": 5706185, "best approach": "wiki, concept, image", "verif answer": "canadian pacific", "anno approach": "wiki, concept, image", "verif wiki answer": "santa fe(0.5455)", "verif concept answer": "santa fe(0.6623)", "verif image answer": "santa fe(0.5763)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570618.jpg"}, {"question": "what animal is this", "gt answer": "cow(1.00)", "pred answer": "horse", "question_id": 2885785, "best approach": "wiki", "verif answer": "horse", "anno approach": "wiki, concept, image", "verif wiki answer": "cow(0.7159)", "verif concept answer": "horse(0.6647)", "verif image answer": "bovine(0.6886)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000288578.jpg"}, {"question": "what is this white container being used for", "gt answer": "storage(1.00)", "pred answer": "heat", "question_id": 3158135, "best approach": "image", "verif answer": "cook", "anno approach": "wiki, concept, image", "verif wiki answer": "refrigeration(0.6870)", "verif concept answer": "refrigeration(0.6096)", "verif image answer": "storage(0.5757)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315813.jpg"}, {"question": "what is the natural habitat of these animals", "gt answer": "arctic(1.00)<br/>cold(0.60)<br/>alaska(0.60)", "pred answer": "north pole", "question_id": 1540115, "best approach": "", "verif answer": "north pole", "anno approach": "wiki, concept, image", "verif wiki answer": "north pole(0.7171)", "verif concept answer": "north pole(0.7027)", "verif image answer": "north pole(0.7221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000154011.jpg"}, {"question": "what are the best shoes to wear when this happens", "gt answer": "boot(1.00)", "pred answer": "dress", "question_id": 942105, "best approach": "wiki", "verif answer": "boot", "anno approach": "wiki, concept, image", "verif wiki answer": "boot(0.7158)", "verif concept answer": "flip flop(0.6749)", "verif image answer": "flip flop(0.5978)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094210.jpg"}, {"question": "how old do these live", "gt answer": "30 years(1.00)<br/>25 years(0.60)<br/>25(0.60)", "pred answer": "50 years", "question_id": 4567735, "best approach": "wiki, concept", "verif answer": "30 years", "anno approach": "wiki, concept, image", "verif wiki answer": "30 years(0.6657)", "verif concept answer": "30 years(0.6154)", "verif image answer": "10 years(0.6876)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456773.jpg"}, {"question": "what zoo are these giraffes from", "gt answer": "san diego(1.00)<br/>miami(0.60)<br/>beijing(0.60)", "pred answer": "africa", "question_id": 1148155, "best approach": "wiki, concept", "verif answer": "san diego", "anno approach": "wiki, concept, image", "verif wiki answer": "san diego(0.5554)", "verif concept answer": "san diego(0.5973)", "verif image answer": "miami(0.5826)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114815.jpg"}, {"question": "how would you order one of these from this manual", "gt answer": "online(1.00)<br/>phone(0.60)", "pred answer": "eat", "question_id": 4227825, "best approach": "", "verif answer": "online", "anno approach": "wiki, concept, image", "verif wiki answer": "store(0.5711)", "verif concept answer": "store(0.5375)", "verif image answer": "sew(0.5208)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000422782.jpg"}, {"question": "what optical effect is happening in the background", "gt answer": "rainbow(1.00)", "pred answer": "light", "question_id": 1663565, "best approach": "concept", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "in sky(0.5987)", "verif concept answer": "rainbow(0.6229)", "verif image answer": "remote(0.6353)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000166356.jpg"}, {"question": "what type of pattern is on this animal", "gt answer": "stripe(1.00)", "pred answer": "striped", "question_id": 4819095, "best approach": "", "verif answer": "stripe", "anno approach": "wiki, concept, image", "verif wiki answer": "mow(0.6256)", "verif concept answer": "fruit stripe(0.6260)", "verif image answer": "fruit stripe(0.6874)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481909.jpg"}, {"question": "what is out of place in this picture", "gt answer": "elephant(1.00)", "pred answer": "human", "question_id": 4444985, "best approach": "wiki, concept, image", "verif answer": "elephant", "anno approach": "wiki, concept, image", "verif wiki answer": "elephant(0.7231)", "verif concept answer": "elephant(0.6784)", "verif image answer": "elephant(0.7012)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000444498.jpg"}, {"question": "what maneuver is this plane performing", "gt answer": "left turn(1.00)<br/>land(0.60)<br/>turn(0.60)", "pred answer": "jump", "question_id": 4727885, "best approach": "wiki, concept, image", "verif answer": "turn", "anno approach": "wiki, concept, image", "verif wiki answer": "land(0.5799)", "verif concept answer": "land(0.5698)", "verif image answer": "turn(0.5430)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000472788.jpg"}, {"question": "how is this item cooked", "gt answer": "baked(1.00)<br/>baked in oven(0.60)<br/>grilled(0.60)", "pred answer": "oven", "question_id": 5129505, "best approach": "concept", "verif answer": "oven", "anno approach": "wiki, concept, image", "verif wiki answer": "oven(0.6735)", "verif concept answer": "baked in oven(0.6046)", "verif image answer": "fried(0.6288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512950.jpg"}, {"question": "what are the red and yellow condiments on the left side called", "gt answer": "mustard and ketchup(1.00)<br/>ketchup and mustard(0.60)<br/>sauce(0.60)", "pred answer": "vodka", "question_id": 5370905, "best approach": "wiki, image", "verif answer": "ketchup", "anno approach": "wiki, concept, image", "verif wiki answer": "sauce(0.7108)", "verif concept answer": "gravy(0.6519)", "verif image answer": "sauce(0.5217)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537090.jpg"}, {"question": "what are these people doing in the marketplace", "gt answer": "shop(1.00)<br/>sell(0.60)", "pred answer": "walk", "question_id": 5417645, "best approach": "", "verif answer": "walk", "anno approach": "wiki, concept, image", "verif wiki answer": "walk(0.5714)", "verif concept answer": "walk(0.5395)", "verif image answer": "walk(0.5086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000541764.jpg"}, {"question": "what are the light sources called in the city", "gt answer": "streetlight(1.00)<br/>street light(0.60)<br/>lamp(0.60)", "pred answer": "light", "question_id": 4075595, "best approach": "wiki", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "streetlight(0.6766)", "verif concept answer": "street light(0.5874)", "verif image answer": "street light(0.6848)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407559.jpg"}, {"question": "why is the surfboard here", "gt answer": "wait(1.00)<br/>dry(0.60)<br/>beach(0.60)", "pred answer": "storage", "question_id": 1269725, "best approach": "image", "verif answer": "wait", "anno approach": "wiki, concept, image", "verif wiki answer": "beach(0.5904)", "verif concept answer": "stand(0.6049)", "verif image answer": "wait(0.6972)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126972.jpg"}, {"question": "what holiday do you cook this", "gt answer": "thanksgiving(1.00)", "pred answer": "4th of july", "question_id": 1210465, "best approach": "", "verif answer": "4th of july", "anno approach": "wiki, concept, image", "verif wiki answer": "july 4th(0.6544)", "verif concept answer": "july 4th(0.5978)", "verif image answer": "easter(0.6980)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000121046.jpg"}, {"question": "what city is this", "gt answer": "seattle(1.00)", "pred answer": "new york", "question_id": 3140645, "best approach": "", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "cupertino(0.6586)", "verif concept answer": "cupertino(0.6548)", "verif image answer": "cupertino(0.6785)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314064.jpg"}, {"question": "what type of meat is in this delicious course", "gt answer": "chicken(1.00)", "pred answer": "shrimp", "question_id": 367395, "best approach": "concept, image", "verif answer": "chicken", "anno approach": "wiki, concept, image", "verif wiki answer": "pork(0.6036)", "verif concept answer": "chicken(0.5778)", "verif image answer": "chicken(0.6857)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000036739.jpg"}, {"question": "how are these people employed", "gt answer": "security(1.00)<br/>police(0.60)", "pred answer": "balance", "question_id": 2447485, "best approach": "", "verif answer": "police officer", "anno approach": "wiki, concept, image", "verif wiki answer": "police officer(0.6902)", "verif concept answer": "law enforcement(0.6627)", "verif image answer": "horse race(0.5501)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244748.jpg"}, {"question": "what famous teenage singer in the 21st century was famous for having the same haircut as the boy wearing the glasses", "gt answer": "justin bieber(1.00)", "pred answer": "rock", "question_id": 41805, "best approach": "", "verif answer": "boy", "anno approach": "wiki, concept, image", "verif wiki answer": "scissor(0.7295)", "verif concept answer": "scissor(0.7281)", "verif image answer": "sew machine(0.7240)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000004180.jpg"}, {"question": "in what tournament is she playing", "gt answer": "us open(1.00)<br/>tennis(1.00)", "pred answer": "wimbledon", "question_id": 2582225, "best approach": "", "verif answer": "wimbledon", "anno approach": "wiki, concept, image", "verif wiki answer": "wimbledon(0.6633)", "verif concept answer": "wimbledon(0.7049)", "verif image answer": "tennis channel(0.6229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258222.jpg"}, {"question": "what type of bread is this", "gt answer": "bagel(1.00)", "pred answer": "pita", "question_id": 1105145, "best approach": "wiki, image", "verif answer": "doughnut", "anno approach": "wiki, concept, image", "verif wiki answer": "bagel(0.6529)", "verif concept answer": "glazed(0.6234)", "verif image answer": "bagel(0.7233)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000110514.jpg"}, {"question": "what is the person in the yellow vest doing", "gt answer": "direct traffic(1.00)", "pred answer": "stand", "question_id": 564325, "best approach": "image", "verif answer": "talk", "anno approach": "wiki, concept, image", "verif wiki answer": "red light(0.6461)", "verif concept answer": "red light(0.6494)", "verif image answer": "direct traffic(0.6009)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000056432.jpg"}, {"question": "what is the beverage in the clear bottle with the green cap", "gt answer": "juice(1.00)<br/>orange(0.60)", "pred answer": "wine", "question_id": 2095375, "best approach": "image", "verif answer": "juice", "anno approach": "wiki, concept, image", "verif wiki answer": "grapefruit(0.6346)", "verif concept answer": "orange juice(0.6151)", "verif image answer": "orange(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209537.jpg"}, {"question": "why is she doing this", "gt answer": "train(1.00)<br/>ride animal(1.00)", "pred answer": "fun", "question_id": 1731965, "best approach": "wiki, concept", "verif answer": "horse race", "anno approach": "wiki, concept, image", "verif wiki answer": "train(0.6879)", "verif concept answer": "train(0.6184)", "verif image answer": "horse race(0.5301)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000173196.jpg"}, {"question": "what is the seat on the right called", "gt answer": "bidet(1.00)<br/>urinal(0.60)", "pred answer": "toilet", "question_id": 1905755, "best approach": "concept, image", "verif answer": "bidet", "anno approach": "wiki, concept, image", "verif wiki answer": "urinal(0.5532)", "verif concept answer": "bidet(0.5957)", "verif image answer": "bidet(0.5945)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000190575.jpg"}, {"question": "is that a pigeon or a duck", "gt answer": "pigeon(1.00)", "pred answer": "duck", "question_id": 4975375, "best approach": "", "verif answer": "pigeon", "anno approach": "wiki, concept, image", "verif wiki answer": "dove(0.7259)", "verif concept answer": "sparrow(0.6051)", "verif image answer": "sparrow(0.6412)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497537.jpg"}, {"question": "would this person learn more about their sport from venus williams or michael phelps", "gt answer": "venus williams(1.00)", "pred answer": "set", "question_id": 2146055, "best approach": "wiki, concept", "verif answer": "venus", "anno approach": "wiki, concept, image", "verif wiki answer": "venus williams(0.6841)", "verif concept answer": "venus williams(0.5226)", "verif image answer": "venus(0.5527)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214605.jpg"}, {"question": "this clock is referencing which european country", "gt answer": "germany(1.00)<br/>irish(0.60)<br/>paris(0.60)", "pred answer": "england", "question_id": 2774635, "best approach": "concept", "verif answer": "london", "anno approach": "wiki, concept, image", "verif wiki answer": "irish(0.6368)", "verif concept answer": "germany(0.6058)", "verif image answer": "irish(0.5746)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277463.jpg"}, {"question": "what are the items on the far left shelf made of", "gt answer": "copper(1.00)<br/>wood(0.60)", "pred answer": "metal", "question_id": 3252065, "best approach": "", "verif answer": "metal", "anno approach": "wiki, concept, image", "verif wiki answer": "aluminium(0.6412)", "verif concept answer": "aluminium(0.6189)", "verif image answer": "aluminium(0.6437)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000325206.jpg"}, {"question": "how many points do you need to win this game", "gt answer": "40(1.00)<br/>15(0.60)<br/>21(0.60)<br/>45(0.60)", "pred answer": "100", "question_id": 3035485, "best approach": "wiki, concept, image", "verif answer": "45", "anno approach": "wiki, concept, image", "verif wiki answer": "45(0.6824)", "verif concept answer": "45(0.6096)", "verif image answer": "15(0.6765)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000303548.jpg"}, {"question": "what was the hairstyle the man had called", "gt answer": "afro(1.00)", "pred answer": "bun", "question_id": 152395, "best approach": "image", "verif answer": "afro", "anno approach": "wiki, concept, image", "verif wiki answer": "ponytail(0.6475)", "verif concept answer": "crew cut(0.5976)", "verif image answer": "afro(0.5137)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015239.jpg"}, {"question": "what kind of pizza is this", "gt answer": "veggie(1.00)<br/>vegetable(0.60)<br/>square(0.60)", "pred answer": "supreme", "question_id": 5555145, "best approach": "wiki, concept", "verif answer": "supreme", "anno approach": "wiki, concept, image", "verif wiki answer": "veggie(0.6117)", "verif concept answer": "veggie(0.6289)", "verif image answer": "supreme(0.6871)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000555514.jpg"}, {"question": "what could you exit through from this picture", "gt answer": "door(1.00)<br/>bedroom(0.60)<br/>window(0.60)", "pred answer": "hall", "question_id": 4074135, "best approach": "wiki", "verif answer": "door", "anno approach": "wiki, concept, image", "verif wiki answer": "door(0.7014)", "verif concept answer": "bedroom(0.5440)", "verif image answer": "stall(0.5982)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407413.jpg"}, {"question": "what do the red lights mean", "gt answer": "brake(1.00)<br/>caution(0.60)", "pred answer": "slow down", "question_id": 3158275, "best approach": "wiki", "verif answer": "stop", "anno approach": "wiki, concept, image", "verif wiki answer": "brake(0.6306)", "verif concept answer": "stopped(0.6574)", "verif image answer": "slow(0.6927)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000315827.jpg"}, {"question": "what breed is this dog", "gt answer": "dachsund(1.00)<br/>dachshund(0.60)<br/>hound(0.60)", "pred answer": "pug", "question_id": 1502115, "best approach": "concept", "verif answer": "dachshund", "anno approach": "wiki, concept, image", "verif wiki answer": "dachshund(0.6188)", "verif concept answer": "dachsund(0.6091)", "verif image answer": "dachshund(0.6212)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000150211.jpg"}, {"question": "what is that pretzel made from", "gt answer": "dough(1.00)<br/>wheat(0.60)<br/>bread(0.60)<br/>flour(0.60)", "pred answer": "steel", "question_id": 5429845, "best approach": "wiki, concept", "verif answer": "flour", "anno approach": "wiki, concept, image", "verif wiki answer": "dough(0.7163)", "verif concept answer": "dough(0.6791)", "verif image answer": "wheat(0.7028)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542984.jpg"}, {"question": "what cooking tool is being used", "gt answer": "pizza cutter(1.00)<br/>slicer(0.60)", "pred answer": "knife", "question_id": 2515045, "best approach": "", "verif answer": "knife", "anno approach": "wiki, concept, image", "verif wiki answer": "knife(0.6693)", "verif concept answer": "spatula(0.6674)", "verif image answer": "spatula(0.6152)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251504.jpg"}, {"question": "what is the name of the object covering the animals eyes", "gt answer": "blinder(1.00)<br/>blind(0.60)<br/>saddle(0.60)", "pred answer": "sunglasses", "question_id": 2632085, "best approach": "wiki, concept, image", "verif answer": "blind", "anno approach": "wiki, concept, image", "verif wiki answer": "blind(0.6032)", "verif concept answer": "blind(0.5657)", "verif image answer": "saddle(0.5530)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000263208.jpg"}, {"question": "how fast can this transportation vehicle go", "gt answer": "very fast(1.00)<br/>100 mph(0.60)<br/>150(0.60)", "pred answer": "80 mph", "question_id": 3537235, "best approach": "wiki, concept, image", "verif answer": "100 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "100 mph(0.6426)", "verif concept answer": "150(0.6116)", "verif image answer": "150(0.6115)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353723.jpg"}, {"question": "what country is the largest exporter of this fruit", "gt answer": "south africa(1.00)<br/>us(0.60)<br/>united state(0.60)<br/>america(0.60)", "pred answer": "germany", "question_id": 2522175, "best approach": "wiki, concept, image", "verif answer": "us", "anno approach": "wiki, concept, image", "verif wiki answer": "us(0.6398)", "verif concept answer": "america(0.6548)", "verif image answer": "america(0.7004)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252217.jpg"}, {"question": "what weather conditions are shown in the image", "gt answer": "snow(1.00)", "pred answer": "cold", "question_id": 4958915, "best approach": "wiki", "verif answer": "snow", "anno approach": "wiki, concept, image", "verif wiki answer": "snow(0.7134)", "verif concept answer": "hill(0.6089)", "verif image answer": "hill(0.6891)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000495891.jpg"}, {"question": "what creates those type of clouds", "gt answer": "water vapor(1.00)", "pred answer": "rain", "question_id": 2588905, "best approach": "wiki, concept", "verif answer": "wind", "anno approach": "wiki, concept, image", "verif wiki answer": "water vapor(0.6695)", "verif concept answer": "water vapor(0.6549)", "verif image answer": "wind(0.6066)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000258890.jpg"}, {"question": "what sort of gardening philosophy is this", "gt answer": "zen(1.00)<br/>good(0.60)", "pred answer": "flower", "question_id": 3799925, "best approach": "concept, image", "verif answer": "good", "anno approach": "wiki, concept, image", "verif wiki answer": "fruit(0.5640)", "verif concept answer": "zen(0.5836)", "verif image answer": "zen(0.5361)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379992.jpg"}, {"question": "where is this airplane 's parent airline based", "gt answer": "ireland(1.00)<br/>europe(0.60)<br/>dublin(0.60)", "pred answer": "france", "question_id": 5615245, "best approach": "wiki", "verif answer": "dublin", "anno approach": "wiki, concept, image", "verif wiki answer": "ireland(0.5879)", "verif concept answer": "europe(0.6379)", "verif image answer": "dublin(0.6587)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000561524.jpg"}, {"question": "why does the object have wheels", "gt answer": "to ride(1.00)", "pred answer": "ride", "question_id": 1650465, "best approach": "concept", "verif answer": "ride", "anno approach": "wiki, concept, image", "verif wiki answer": "ride(0.6601)", "verif concept answer": "to ride(0.6017)", "verif image answer": "decor(0.6264)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000165046.jpg"}, {"question": "are these two waiting for food to be served or are they just resting", "gt answer": "food(1.00)<br/>wait(0.60)<br/>rest(0.60)", "pred answer": "relax", "question_id": 5667985, "best approach": "concept", "verif answer": "wait", "anno approach": "wiki, concept, image", "verif wiki answer": "sit(0.6487)", "verif concept answer": "rest(0.6461)", "verif image answer": "sit(0.5397)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566798.jpg"}, {"question": "what clothing item is being worn on the lower part of the baby", "gt answer": "diaper(1.00)", "pred answer": "short", "question_id": 4239325, "best approach": "wiki", "verif answer": "short", "anno approach": "wiki, concept, image", "verif wiki answer": "diaper(0.5064)", "verif concept answer": "cotton(0.5610)", "verif image answer": "costume(0.5194)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000423932.jpg"}, {"question": "is kyle a street name or a person", "gt answer": "street name(1.00)<br/>street(1.00)", "pred answer": "public", "question_id": 2107315, "best approach": "wiki", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.6361)", "verif concept answer": "road(0.6027)", "verif image answer": "road(0.6939)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210731.jpg"}, {"question": "what is this skateboarding trick called", "gt answer": "grind(1.00)<br/>stall(0.60)", "pred answer": "ollie", "question_id": 1920905, "best approach": "wiki", "verif answer": "jump", "anno approach": "wiki, concept, image", "verif wiki answer": "stall(0.6813)", "verif concept answer": "jump(0.6444)", "verif image answer": "jump(0.6900)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000192090.jpg"}, {"question": "are these kids most likely having fun or bored", "gt answer": "fun(1.00)", "pred answer": "tired", "question_id": 3567715, "best approach": "", "verif answer": "professionally", "anno approach": "wiki, concept, image", "verif wiki answer": "professionally(0.5627)", "verif concept answer": "competition(0.6118)", "verif image answer": "professionally(0.7033)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356771.jpg"}, {"question": "is this gesture good or bad", "gt answer": "good(1.00)", "pred answer": "bad", "question_id": 1772775, "best approach": "concept", "verif answer": "bad", "anno approach": "wiki, concept, image", "verif wiki answer": "zen(0.6219)", "verif concept answer": "good(0.5668)", "verif image answer": "bad(0.6042)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000177277.jpg"}, {"question": "which item in this scene has something in common with a land mass in the carribean", "gt answer": "island(1.00)<br/>light(0.60)<br/>triangle(0.60)", "pred answer": "crosswalk", "question_id": 2155865, "best approach": "image", "verif answer": "triangle", "anno approach": "wiki, concept, image", "verif wiki answer": "light(0.5272)", "verif concept answer": "fridge(0.6111)", "verif image answer": "island(0.5528)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000215586.jpg"}, {"question": "what is the average weight of this type of animal", "gt answer": "1000 lbs(1.00)", "pred answer": "60 years", "question_id": 757785, "best approach": "wiki, concept", "verif answer": "ton", "anno approach": "wiki, concept, image", "verif wiki answer": "1000 lbs(0.5656)", "verif concept answer": "1000 lbs(0.6211)", "verif image answer": "400(0.5935)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075778.jpg"}, {"question": "what shouldn't the cat use", "gt answer": "scissor(1.00)<br/>hurt(0.60)", "pred answer": "window", "question_id": 325865, "best approach": "concept", "verif answer": "ladybug", "anno approach": "wiki, concept, image", "verif wiki answer": "ladybug(0.6672)", "verif concept answer": "hurt(0.5664)", "verif image answer": "sew(0.5281)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032586.jpg"}, {"question": "what are the clips on top", "gt answer": "clothespin(1.00)", "pred answer": "cat", "question_id": 1310155, "best approach": "", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "0(0.6560)", "verif concept answer": "0(0.5864)", "verif image answer": "banana(0.5554)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000131015.jpg"}, {"question": "what is this event", "gt answer": "lunch(1.00)<br/>dinner(1.00)", "pred answer": "birthday", "question_id": 1483735, "best approach": "concept, image", "verif answer": "dinner", "anno approach": "wiki, concept, image", "verif wiki answer": "cook(0.6274)", "verif concept answer": "dinner(0.5828)", "verif image answer": "lunch(0.7005)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000148373.jpg"}, {"question": "is this in a zoo or in the wild", "gt answer": "wild(1.00)", "pred answer": "zoo", "question_id": 5485655, "best approach": "wiki, concept, image", "verif answer": "wild", "anno approach": "wiki, concept, image", "verif wiki answer": "wild(0.5563)", "verif concept answer": "wild(0.5836)", "verif image answer": "wild(0.7081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548565.jpg"}, {"question": "how does the plane land", "gt answer": "wheel(1.00)", "pred answer": "take off", "question_id": 3247785, "best approach": "", "verif answer": "engine", "anno approach": "wiki, concept, image", "verif wiki answer": "engine(0.5974)", "verif concept answer": "engine(0.5774)", "verif image answer": "air(0.6674)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324778.jpg"}, {"question": "what is in that background of this picture", "gt answer": "cloud(1.00)<br/>sky(0.60)", "pred answer": "kite", "question_id": 5722515, "best approach": "image", "verif answer": "cloud", "anno approach": "wiki, concept, image", "verif wiki answer": "sky(0.6030)", "verif concept answer": "helicopter(0.6117)", "verif image answer": "cloud(0.5430)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572251.jpg"}, {"question": "what kind of trees are shown", "gt answer": "pine(1.00)<br/>elm(0.60)<br/>large(0.60)", "pred answer": "oak", "question_id": 3505575, "best approach": "wiki, concept, image", "verif answer": "pine", "anno approach": "wiki, concept, image", "verif wiki answer": "pine(0.6467)", "verif concept answer": "pine(0.6560)", "verif image answer": "pine(0.7168)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350557.jpg"}, {"question": "how is the bike affixed to the pole", "gt answer": "chain(1.00)", "pred answer": "anchor", "question_id": 2813945, "best approach": "", "verif answer": "rope", "anno approach": "wiki, concept, image", "verif wiki answer": "bicycle(0.6024)", "verif concept answer": "nylon(0.5787)", "verif image answer": "keep dry(0.5966)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281394.jpg"}, {"question": "what would you use this type pan for usually", "gt answer": "pizza(1.00)<br/>cake(0.60)<br/>pie(0.60)", "pred answer": "cook", "question_id": 1427335, "best approach": "wiki, image", "verif answer": "pizza", "anno approach": "wiki, concept, image", "verif wiki answer": "pizza(0.6430)", "verif concept answer": "bread(0.5768)", "verif image answer": "pizza(0.6820)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000142733.jpg"}, {"question": "what a recipe for the food in this picture", "gt answer": "macaroni and cheese(1.00)", "pred answer": "potato", "question_id": 4902645, "best approach": "image", "verif answer": "potato", "anno approach": "wiki, concept, image", "verif wiki answer": "noodle(0.6047)", "verif concept answer": "bread(0.5823)", "verif image answer": "macaroni and cheese(0.6147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000490264.jpg"}, {"question": "what do you call the object the man is holding that 's behind the player with the bat", "gt answer": "glove(1.00)", "pred answer": "bat", "question_id": 3782295, "best approach": "image", "verif answer": "base", "anno approach": "wiki, concept, image", "verif wiki answer": "base(0.6803)", "verif concept answer": "catcher(0.5855)", "verif image answer": "glove(0.5218)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378229.jpg"}, {"question": "how far off the ground is the top of the red sign", "gt answer": "10 feet(1.00)<br/>7 feet(0.60)<br/>8 feet(0.60)", "pred answer": "20 feet", "question_id": 4855505, "best approach": "wiki", "verif answer": "10 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "8 feet(0.6639)", "verif concept answer": "8 inches(0.6289)", "verif image answer": "8 inches(0.6709)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485550.jpg"}, {"question": "what is the middle of this fruit called", "gt answer": "core(1.00)", "pred answer": "navel", "question_id": 1056975, "best approach": "wiki", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "core(0.6754)", "verif concept answer": "chop(0.5658)", "verif image answer": "wash it(0.7025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105697.jpg"}, {"question": "what does the bus say", "gt answer": "dog tail(1.00)", "pred answer": "tour", "question_id": 2148755, "best approach": "concept", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "mascot(0.5896)", "verif concept answer": "dog tail(0.6490)", "verif image answer": "new york(0.5476)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214875.jpg"}, {"question": "what species is this bird", "gt answer": "pelican(1.00)<br/>crane(1.00)<br/>stork(0.60)", "pred answer": "seagull", "question_id": 737275, "best approach": "wiki, concept", "verif answer": "crane", "anno approach": "wiki, concept, image", "verif wiki answer": "crane(0.6394)", "verif concept answer": "crane(0.6357)", "verif image answer": "stork(0.6308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000073727.jpg"}, {"question": "what is the job title for the man pictured here", "gt answer": "electrician(1.00)<br/>construction(0.60)", "pred answer": "cross guard", "question_id": 139445, "best approach": "concept", "verif answer": "construction", "anno approach": "wiki, concept, image", "verif wiki answer": "traffic control(0.6545)", "verif concept answer": "electrician(0.6253)", "verif image answer": "construction site(0.5556)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013944.jpg"}, {"question": "can you guess the location where this shown sport is palyed", "gt answer": "kentucky(1.00)<br/>racetrack(0.60)", "pred answer": "field", "question_id": 2609515, "best approach": "concept", "verif answer": "field", "anno approach": "wiki, concept, image", "verif wiki answer": "field(0.6797)", "verif concept answer": "racetrack(0.6485)", "verif image answer": "outside(0.7189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260951.jpg"}, {"question": "where would you normally see these objects", "gt answer": "sky(1.00)<br/>in sky(0.60)<br/>air(0.60)", "pred answer": "beach", "question_id": 5050925, "best approach": "wiki", "verif answer": "sky", "anno approach": "wiki, concept, image", "verif wiki answer": "sky(0.6347)", "verif concept answer": "cloud(0.5400)", "verif image answer": "cloud(0.7197)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505092.jpg"}, {"question": "what is the yellow wavy line", "gt answer": "mustard(1.00)", "pred answer": "crosswalk", "question_id": 1551725, "best approach": "wiki", "verif answer": "mustard", "anno approach": "wiki, concept, image", "verif wiki answer": "mustard(0.5312)", "verif concept answer": "ranch dress(0.6169)", "verif image answer": "ranch dress(0.5729)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155172.jpg"}, {"question": "what is this truck being used for", "gt answer": "tow(1.00)<br/>haul(0.60)<br/>work(0.60)<br/>transport(0.60)", "pred answer": "construction", "question_id": 201825, "best approach": "concept, image", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "work(0.7018)", "verif concept answer": "tow(0.6403)", "verif image answer": "tow(0.5358)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020182.jpg"}, {"question": "what type of race is this", "gt answer": "truck(1.00)", "pred answer": "dirt bike", "question_id": 165315, "best approach": "", "verif answer": "truck", "anno approach": "wiki, concept, image", "verif wiki answer": "vehicle(0.6817)", "verif concept answer": "vehicle(0.5997)", "verif image answer": "vehicle(0.6425)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016531.jpg"}, {"question": "what sort of dishes can be prepared from the items in the photo", "gt answer": "bread(1.00)<br/>banana split(1.00)<br/>banana bread(0.60)", "pred answer": "banana", "question_id": 1937105, "best approach": "wiki, concept, image", "verif answer": "banana", "anno approach": "wiki, concept, image", "verif wiki answer": "banana split(0.6082)", "verif concept answer": "bread(0.6093)", "verif image answer": "banana split(0.7026)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193710.jpg"}, {"question": "who invented this", "gt answer": "garrett morgan(1.00)", "pred answer": "richard trevithick", "question_id": 3430665, "best approach": "wiki, image", "verif answer": "garrett morgan", "anno approach": "wiki, concept, image", "verif wiki answer": "garrett morgan(0.6916)", "verif concept answer": "human(0.5916)", "verif image answer": "garrett morgan(0.6488)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343066.jpg"}, {"question": "what is the fastest one of these in the world", "gt answer": "bullet train(1.00)<br/>amtrack(0.60)", "pred answer": "bullet", "question_id": 2804235, "best approach": "wiki, concept", "verif answer": "bullet", "anno approach": "wiki, concept, image", "verif wiki answer": "bullet train(0.6714)", "verif concept answer": "bullet train(0.6326)", "verif image answer": "bullet(0.6713)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000280423.jpg"}, {"question": "what is for dessert", "gt answer": "cookie(1.00)", "pred answer": "cake", "question_id": 4073695, "best approach": "", "verif answer": "bun", "anno approach": "wiki, concept, image", "verif wiki answer": "very(0.7201)", "verif concept answer": "very(0.7268)", "verif image answer": "very(0.7187)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407369.jpg"}, {"question": "what is the purpose of the item below the window", "gt answer": "heat(1.00)", "pred answer": "shade", "question_id": 5058275, "best approach": "", "verif answer": "warmth", "anno approach": "wiki, concept, image", "verif wiki answer": "hammer(0.6561)", "verif concept answer": "blow(0.5787)", "verif image answer": "food(0.5501)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505827.jpg"}, {"question": "what kind of car is the green one in the parking lot", "gt answer": "porsche(1.00)<br/>pinto(0.60)", "pred answer": "sedan", "question_id": 2250875, "best approach": "image", "verif answer": "scooter", "anno approach": "wiki, concept, image", "verif wiki answer": "quarter(0.6005)", "verif concept answer": "quarter(0.6128)", "verif image answer": "porsche(0.6775)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000225087.jpg"}, {"question": "how far off the ground is this animals kneecaps", "gt answer": "3 feet(1.00)<br/>4 feet(0.60)", "pred answer": "20 feet", "question_id": 3530005, "best approach": "concept", "verif answer": "3 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "6 feet(0.5834)", "verif concept answer": "4 feet(0.5291)", "verif image answer": "yard(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000353000.jpg"}, {"question": "what brand is the mattress", "gt answer": "serta(1.00)", "pred answer": "ford", "question_id": 5201145, "best approach": "wiki, concept, image", "verif answer": "toshiba", "anno approach": "wiki, concept, image", "verif wiki answer": "serta(0.6570)", "verif concept answer": "serta(0.5833)", "verif image answer": "serta(0.5079)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520114.jpg"}, {"question": "what soft wood is used to close the tob of the container in his hand", "gt answer": "cork(1.00)", "pred answer": "oak", "question_id": 4771365, "best approach": "image", "verif answer": "wicker", "anno approach": "wiki, concept, image", "verif wiki answer": "wicker(0.5948)", "verif concept answer": "wicker(0.6365)", "verif image answer": "cork(0.6367)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000477136.jpg"}, {"question": "what is the name for the type of clouds in the sky of this photo", "gt answer": "stratus(1.00)<br/>cirrus(0.60)", "pred answer": "cumulus", "question_id": 2510265, "best approach": "image", "verif answer": "cumulus", "anno approach": "wiki, concept, image", "verif wiki answer": "cumulus(0.6067)", "verif concept answer": "cumulus(0.6204)", "verif image answer": "stratus(0.5407)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251026.jpg"}, {"question": "what city is depicted", "gt answer": "delhi(1.00)<br/>india(0.60)", "pred answer": "new york city", "question_id": 1995945, "best approach": "image", "verif answer": "chicago", "anno approach": "wiki, concept, image", "verif wiki answer": "costa rica(0.6117)", "verif concept answer": "costa rica(0.5937)", "verif image answer": "delhi(0.5870)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199594.jpg"}, {"question": "what topping on this dish is not good for pregnant women", "gt answer": "mussel(1.00)", "pred answer": "onion", "question_id": 5458445, "best approach": "", "verif answer": "onion", "anno approach": "wiki, concept, image", "verif wiki answer": "onion(0.6431)", "verif concept answer": "pepper(0.6043)", "verif image answer": "pepper(0.7030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545844.jpg"}, {"question": "which company do these characters come from", "gt answer": "disney(1.00)", "pred answer": "toy r us", "question_id": 3944045, "best approach": "wiki", "verif answer": "disney", "anno approach": "wiki, concept, image", "verif wiki answer": "disney(0.6975)", "verif concept answer": "cinderella(0.5892)", "verif image answer": "hasbro(0.6285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000394404.jpg"}, {"question": "what drink is this", "gt answer": "coffee(1.00)", "pred answer": "beer", "question_id": 4734915, "best approach": "", "verif answer": "tea", "anno approach": "wiki, concept, image", "verif wiki answer": "tea(0.6395)", "verif concept answer": "cocoa(0.6688)", "verif image answer": "milk(0.6566)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000473491.jpg"}, {"question": "is this a bakery or chinese restaurant", "gt answer": "bakery(1.00)<br/>chinese(0.60)", "pred answer": "buffet", "question_id": 843145, "best approach": "wiki, concept", "verif answer": "bakery", "anno approach": "wiki, concept, image", "verif wiki answer": "bakery(0.5429)", "verif concept answer": "bakery(0.5504)", "verif image answer": "chinese(0.5734)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000084314.jpg"}, {"question": "what is this item used for", "gt answer": "bird feeder(1.00)<br/>sit(0.60)<br/>swing(0.60)", "pred answer": "relax", "question_id": 1379645, "best approach": "wiki, concept", "verif answer": "swing", "anno approach": "wiki, concept, image", "verif wiki answer": "sit(0.6811)", "verif concept answer": "sit(0.6231)", "verif image answer": "bench(0.5732)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000137964.jpg"}, {"question": "what are animals of this kind most often used for", "gt answer": "ride(1.00)", "pred answer": "race", "question_id": 5596335, "best approach": "concept", "verif answer": "race", "anno approach": "wiki, concept, image", "verif wiki answer": "race(0.6623)", "verif concept answer": "ride(0.6236)", "verif image answer": "pony(0.6079)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000559633.jpg"}, {"question": "what position is this man sitting in", "gt answer": "recline(1.00)", "pred answer": "sit", "question_id": 4431925, "best approach": "", "verif answer": "goalie", "anno approach": "wiki, concept, image", "verif wiki answer": "goalie(0.6626)", "verif concept answer": "goalie(0.5145)", "verif image answer": "2004(0.6283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443192.jpg"}, {"question": "what geographic features in the background", "gt answer": "mountain(1.00)", "pred answer": "lake", "question_id": 1066585, "best approach": "wiki, concept", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "mountain(0.7196)", "verif concept answer": "mountain(0.6627)", "verif image answer": "colorado(0.6799)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106658.jpg"}, {"question": "what profession would be likely to use this room", "gt answer": "doctor(1.00)<br/>nurse(0.60)", "pred answer": "mechanic", "question_id": 283855, "best approach": "wiki, concept", "verif answer": "doctor", "anno approach": "wiki, concept, image", "verif wiki answer": "nurse(0.5365)", "verif concept answer": "nurse(0.5363)", "verif image answer": "fan(0.7128)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028385.jpg"}, {"question": "what band performs this hit song", "gt answer": "journey(1.00)<br/>queen(0.60)", "pred answer": "beach boy", "question_id": 4977315, "best approach": "", "verif answer": "chicago", "anno approach": "wiki, concept, image", "verif wiki answer": "chicago(0.5279)", "verif concept answer": "cumulus(0.5146)", "verif image answer": "cumulus(0.5021)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497731.jpg"}, {"question": "what school sport is this girl and her coach playing at", "gt answer": "frisby(1.00)<br/>baseball(0.60)<br/>soccer(0.60)", "pred answer": "frisbee", "question_id": 2460445, "best approach": "image", "verif answer": "frisbee", "anno approach": "wiki, concept, image", "verif wiki answer": "frisbee(0.7114)", "verif concept answer": "frisbee(0.6180)", "verif image answer": "soccer(0.6699)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246044.jpg"}, {"question": "which lane should you stay in based on the image", "gt answer": "right(1.00)", "pred answer": "left", "question_id": 5733305, "best approach": "", "verif answer": "left", "anno approach": "wiki, concept, image", "verif wiki answer": "left(0.5580)", "verif concept answer": "left(0.6059)", "verif image answer": "left(0.6160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000573330.jpg"}, {"question": "which food seen here has a country for the first part of its name", "gt answer": "french fry(1.00)", "pred answer": "chicago", "question_id": 1314985, "best approach": "image", "verif answer": "fry", "anno approach": "wiki, concept, image", "verif wiki answer": "fry(0.6015)", "verif concept answer": "fry(0.6410)", "verif image answer": "french fry(0.6683)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000131498.jpg"}, {"question": "what is another name for this kind of truck that goes with the word roach", "gt answer": "coach(1.00)<br/>food(0.60)", "pred answer": "semi", "question_id": 3905675, "best approach": "wiki, concept", "verif answer": "ice cream", "anno approach": "wiki, concept, image", "verif wiki answer": "coach(0.5504)", "verif concept answer": "coach(0.6013)", "verif image answer": "giraffe(0.6548)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390567.jpg"}, {"question": "what is the topmost item used for", "gt answer": "soda(1.00)<br/>drink(0.60)", "pred answer": "light", "question_id": 4835305, "best approach": "wiki, image", "verif answer": "drink", "anno approach": "wiki, concept, image", "verif wiki answer": "drink(0.5703)", "verif concept answer": "coca cola(0.5733)", "verif image answer": "drink(0.6190)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000483530.jpg"}, {"question": "what is the cat wearing", "gt answer": "collar(1.00)", "pred answer": "tie", "question_id": 4433495, "best approach": "wiki, image", "verif answer": "collar", "anno approach": "wiki, concept, image", "verif wiki answer": "collar(0.6519)", "verif concept answer": "tag(0.5974)", "verif image answer": "collar(0.7295)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443349.jpg"}, {"question": "where are these wind turbines located", "gt answer": "kansas(1.00)", "pred answer": "country", "question_id": 5176325, "best approach": "concept", "verif answer": "runway", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.5212)", "verif concept answer": "kansas(0.5402)", "verif image answer": "runway(0.6175)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517632.jpg"}, {"question": "what are these trucks here for", "gt answer": "camp(1.00)<br/>tow(0.60)", "pred answer": "truck", "question_id": 1022055, "best approach": "wiki, image", "verif answer": "truck", "anno approach": "wiki, concept, image", "verif wiki answer": "camp(0.6310)", "verif concept answer": "accident(0.6290)", "verif image answer": "camp(0.6760)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000102205.jpg"}, {"question": "why would they paint the bananas", "gt answer": "for fun(1.00)<br/>art(0.60)<br/>fun(0.60)", "pred answer": "ripe", "question_id": 5409335, "best approach": "wiki", "verif answer": "fun", "anno approach": "wiki, concept, image", "verif wiki answer": "fun(0.5984)", "verif concept answer": "pleasure(0.5802)", "verif image answer": "pleasure(0.6632)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540933.jpg"}, {"question": "is this a posed picture or was she caught unawares", "gt answer": "posed(1.00)", "pred answer": "candid", "question_id": 647315, "best approach": "", "verif answer": "shadow", "anno approach": "wiki, concept, image", "verif wiki answer": "shadow(0.5535)", "verif concept answer": "black and white(0.5053)", "verif image answer": "black and white(0.5326)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000064731.jpg"}, {"question": "what country do the numbers on the clock come from", "gt answer": "rome(1.00)<br/>italy(0.60)", "pred answer": "usa", "question_id": 1098355, "best approach": "concept, image", "verif answer": "spain", "anno approach": "wiki, concept, image", "verif wiki answer": "poland(0.6170)", "verif concept answer": "italy(0.6094)", "verif image answer": "italy(0.5878)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000109835.jpg"}, {"question": "why are these animals in the field", "gt answer": "graze(1.00)", "pred answer": "herd", "question_id": 3478585, "best approach": "", "verif answer": "herd", "anno approach": "wiki, concept, image", "verif wiki answer": "eat(0.7172)", "verif concept answer": "eat(0.6333)", "verif image answer": "eat(0.5706)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347858.jpg"}, {"question": "who manufactures the tractor in the picture on the wall", "gt answer": "john deere(1.00)", "pred answer": "nintendo", "question_id": 2737045, "best approach": "concept", "verif answer": "john deere", "anno approach": "wiki, concept, image", "verif wiki answer": "honda(0.6499)", "verif concept answer": "john deere(0.7024)", "verif image answer": "boeing(0.5043)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000273704.jpg"}, {"question": "which baseball team are these players from", "gt answer": "white sox(1.00)<br/>nation(0.60)<br/>yankees(0.60)", "pred answer": "red sox", "question_id": 5716485, "best approach": "image", "verif answer": "nation", "anno approach": "wiki, concept, image", "verif wiki answer": "dodger(0.6837)", "verif concept answer": "dodger(0.6760)", "verif image answer": "nation(0.7246)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000571648.jpg"}, {"question": "what is wrong with this animal", "gt answer": "dead(1.00)<br/>sleep(0.60)", "pred answer": "stripe", "question_id": 1842235, "best approach": "", "verif answer": "it ear", "anno approach": "wiki, concept, image", "verif wiki answer": "it ear(0.6767)", "verif concept answer": "it ear(0.6314)", "verif image answer": "stray(0.6619)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184223.jpg"}, {"question": "what kind of cake is this", "gt answer": "red velvet(1.00)<br/>coffee cake(0.60)", "pred answer": "cheesecake", "question_id": 687495, "best approach": "wiki, concept, image", "verif answer": "vanilla", "anno approach": "wiki, concept, image", "verif wiki answer": "coffee cake(0.6276)", "verif concept answer": "coffee cake(0.6373)", "verif image answer": "coffee cake(0.6179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000068749.jpg"}, {"question": "who is on this money", "gt answer": "queen elizabeth(1.00)", "pred answer": "artist", "question_id": 2829005, "best approach": "", "verif answer": "woman", "anno approach": "wiki, concept, image", "verif wiki answer": "king(0.5615)", "verif concept answer": "shakespeare(0.6330)", "verif image answer": "shakespeare(0.5986)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282900.jpg"}, {"question": "what is the type of diagram on the wall called", "gt answer": "calendar(1.00)", "pred answer": "computer", "question_id": 1457415, "best approach": "", "verif answer": "map", "anno approach": "wiki, concept, image", "verif wiki answer": "map(0.5148)", "verif concept answer": "map(0.6004)", "verif image answer": "caricature(0.6615)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145741.jpg"}, {"question": "what is the make of the green guitar", "gt answer": "fender(1.00)", "pred answer": "van", "question_id": 5752285, "best approach": "", "verif answer": "cello", "anno approach": "wiki, concept, image", "verif wiki answer": "cello(0.7156)", "verif concept answer": "cello(0.6746)", "verif image answer": "cello(0.6870)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000575228.jpg"}, {"question": "when was this room made", "gt answer": "1970(1.00)<br/>1960's(0.60)<br/>2000(0.60)<br/>60s(0.60)", "pred answer": "1900", "question_id": 3578125, "best approach": "concept, image", "verif answer": "1970", "anno approach": "wiki, concept, image", "verif wiki answer": "1970's(0.5868)", "verif concept answer": "2000(0.6239)", "verif image answer": "1960's(0.6756)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357812.jpg"}, {"question": "what does the train appear to be doing", "gt answer": "stop(1.00)<br/>leave(0.60)<br/>wait(0.60)", "pred answer": "track", "question_id": 1173225, "best approach": "", "verif answer": "go", "anno approach": "wiki, concept, image", "verif wiki answer": "run(0.6756)", "verif concept answer": "run(0.6917)", "verif image answer": "go(0.7227)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000117322.jpg"}, {"question": "is this an exerting or relaxing activity", "gt answer": "exert(1.00)", "pred answer": "hot", "question_id": 2491395, "best approach": "wiki, image", "verif answer": "relax", "anno approach": "wiki, concept, image", "verif wiki answer": "exert(0.6376)", "verif concept answer": "home(0.5234)", "verif image answer": "exert(0.5576)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249139.jpg"}, {"question": "what kind of office is this", "gt answer": "political(1.00)<br/>government(0.60)", "pred answer": "business", "question_id": 3994425, "best approach": "wiki", "verif answer": "political", "anno approach": "wiki, concept, image", "verif wiki answer": "political(0.6601)", "verif concept answer": "speech(0.6025)", "verif image answer": "roosevelt(0.6481)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399442.jpg"}, {"question": "where are these folks gathered", "gt answer": "stadium(1.00)", "pred answer": "festival", "question_id": 5114105, "best approach": "wiki, concept, image", "verif answer": "stadium", "anno approach": "wiki, concept, image", "verif wiki answer": "stadium(0.7210)", "verif concept answer": "stadium(0.6638)", "verif image answer": "stadium(0.6876)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000511410.jpg"}, {"question": "name the material used to make this shoe shown in this picture", "gt answer": "canvas(1.00)<br/>wood(0.60)<br/>leather(0.60)", "pred answer": "rubber", "question_id": 3052705, "best approach": "", "verif answer": "metal", "anno approach": "wiki, concept, image", "verif wiki answer": "wicker(0.6863)", "verif concept answer": "metal(0.6298)", "verif image answer": "wicker(0.6730)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305270.jpg"}, {"question": "what is this device on the wall used for", "gt answer": "tell time(1.00)<br/>time(1.00)", "pred answer": "sit", "question_id": 1022785, "best approach": "wiki", "verif answer": "time", "anno approach": "wiki, concept, image", "verif wiki answer": "time(0.6787)", "verif concept answer": "time tell(0.5372)", "verif image answer": "time tell(0.6901)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000102278.jpg"}, {"question": "what condition is the man 's hair growth an example of", "gt answer": "bald(1.00)", "pred answer": "bad", "question_id": 3449415, "best approach": "wiki, concept", "verif answer": "bad", "anno approach": "wiki, concept, image", "verif wiki answer": "bald(0.6532)", "verif concept answer": "bald(0.6294)", "verif image answer": "queen(0.7151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344941.jpg"}, {"question": "what beach is this", "gt answer": "myrtle(1.00)", "pred answer": "pacific", "question_id": 423495, "best approach": "", "verif answer": "pacific", "anno approach": "wiki, concept, image", "verif wiki answer": "beach(0.6029)", "verif concept answer": "central park(0.6029)", "verif image answer": "central park(0.6279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042349.jpg"}, {"question": "what could you cook with these ingredients", "gt answer": "banana bread(1.00)<br/>pud(0.60)", "pred answer": "bread", "question_id": 4199075, "best approach": "", "verif answer": "bread", "anno approach": "wiki, concept, image", "verif wiki answer": "banana(0.6354)", "verif concept answer": "banana(0.6422)", "verif image answer": "banana(0.6258)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000419907.jpg"}, {"question": "what is the use of that scree n afar", "gt answer": "television(1.00)<br/>tv(0.60)", "pred answer": "watch tv", "question_id": 2402525, "best approach": "", "verif answer": "watch tv", "anno approach": "wiki, concept, image", "verif wiki answer": "control(0.5534)", "verif concept answer": "control(0.5834)", "verif image answer": "control(0.6260)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240252.jpg"}, {"question": "why is there a fence here", "gt answer": "privacy(1.00)", "pred answer": "danger", "question_id": 4638305, "best approach": "wiki, concept", "verif answer": "water", "anno approach": "wiki, concept, image", "verif wiki answer": "privacy(0.5467)", "verif concept answer": "privacy(0.5352)", "verif image answer": "metal(0.6184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000463830.jpg"}, {"question": "what are they doing", "gt answer": "boat(1.00)<br/>sail(0.60)", "pred answer": "talk", "question_id": 1147325, "best approach": "concept", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "dock(0.6456)", "verif concept answer": "sail(0.6106)", "verif image answer": "bird(0.5262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000114732.jpg"}, {"question": "what are the enclosures called", "gt answer": "pen(1.00)", "pred answer": "herd", "question_id": 936215, "best approach": "image", "verif answer": "fence", "anno approach": "wiki, concept, image", "verif wiki answer": "sheep(0.7065)", "verif concept answer": "wild(0.6201)", "verif image answer": "pen(0.7102)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093621.jpg"}, {"question": "why is the child naked", "gt answer": "swim(1.00)", "pred answer": "tired", "question_id": 1916485, "best approach": "", "verif answer": "bikini", "anno approach": "wiki, concept, image", "verif wiki answer": "surf(0.6894)", "verif concept answer": "surf(0.5892)", "verif image answer": "bikini(0.6575)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191648.jpg"}, {"question": "what does a person that shoves others out of the way have in common with these vehicles", "gt answer": "boat(0.60)<br/>barge(1.00)", "pred answer": "float", "question_id": 673445, "best approach": "wiki, image", "verif answer": "barge", "anno approach": "wiki, concept, image", "verif wiki answer": "barge(0.5664)", "verif concept answer": "canal(0.5708)", "verif image answer": "barge(0.5126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067344.jpg"}, {"question": "what kind of purple flours are growing in the background", "gt answer": "lavender(1.00)", "pred answer": "daffodil", "question_id": 1153285, "best approach": "", "verif answer": "flower", "anno approach": "wiki, concept, image", "verif wiki answer": "fern(0.6040)", "verif concept answer": "violet(0.6399)", "verif image answer": "flower(0.7156)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115328.jpg"}, {"question": "what does the pole next to the bus represent", "gt answer": "bus stop(1.00)<br/>stop sign(0.60)<br/>stop(0.60)", "pred answer": "traffic", "question_id": 3572085, "best approach": "wiki", "verif answer": "stop", "anno approach": "wiki, concept, image", "verif wiki answer": "bus stop(0.6143)", "verif concept answer": "stop sign(0.6063)", "verif image answer": "downtown(0.5854)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357208.jpg"}, {"question": "how do we know this sign is meant for more than just the people approaching it", "gt answer": "all way(1.00)<br/>below(0.60)", "pred answer": "sign", "question_id": 3425615, "best approach": "concept, image", "verif answer": "stop", "anno approach": "wiki, concept, image", "verif wiki answer": "fried(0.5673)", "verif concept answer": "all way(0.6435)", "verif image answer": "all way(0.5972)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342561.jpg"}, {"question": "what do you think the trailors are for", "gt answer": "horse(1.00)", "pred answer": "race", "question_id": 3209795, "best approach": "", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "cow(0.6992)", "verif concept answer": "cow(0.6142)", "verif image answer": "cow(0.5677)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000320979.jpg"}, {"question": "is this edible or inedible", "gt answer": "inedible(1.00)", "pred answer": "vegetarian", "question_id": 2826755, "best approach": "", "verif answer": "very", "anno approach": "wiki, concept, image", "verif wiki answer": "very(0.6336)", "verif concept answer": "very(0.5360)", "verif image answer": "free(0.7251)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000282675.jpg"}, {"question": "who is a famous participant in this sport", "gt answer": "bode miller(1.00)", "pred answer": "shaun white", "question_id": 2002895, "best approach": "wiki, image", "verif answer": "bode miller", "anno approach": "wiki, concept, image", "verif wiki answer": "bode miller(0.5583)", "verif concept answer": "pole(0.5456)", "verif image answer": "bode miller(0.6404)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200289.jpg"}, {"question": "what kind of dog is this", "gt answer": "chihuahua(1.00)", "pred answer": "boxer", "question_id": 297475, "best approach": "image", "verif answer": "chihuaha", "anno approach": "wiki, concept, image", "verif wiki answer": "cat(0.5600)", "verif concept answer": "chihuaha(0.5654)", "verif image answer": "chihuahua(0.5532)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000029747.jpg"}, {"question": "what type of profession are these people in", "gt answer": "politic(1.00)", "pred answer": "cook", "question_id": 3713925, "best approach": "", "verif answer": "suit", "anno approach": "wiki, concept, image", "verif wiki answer": "suit(0.5390)", "verif concept answer": "suit(0.5918)", "verif image answer": "suit(0.6797)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371392.jpg"}, {"question": "what type of locomotive is this", "gt answer": "yellow(1.00)<br/>steam(0.60)", "pred answer": "electric", "question_id": 3178485, "best approach": "wiki, concept", "verif answer": "steam", "anno approach": "wiki, concept, image", "verif wiki answer": "steam(0.6714)", "verif concept answer": "steam(0.6385)", "verif image answer": "green(0.6381)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000317848.jpg"}, {"question": "how many bones does these living thing get", "gt answer": "206(1.00)<br/>400(0.60)", "pred answer": "32", "question_id": 1411015, "best approach": "wiki, image", "verif answer": "46", "anno approach": "wiki, concept, image", "verif wiki answer": "206(0.6068)", "verif concept answer": "46(0.6347)", "verif image answer": "206(0.5613)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000141101.jpg"}, {"question": "what train stop is this", "gt answer": "new delhi(1.00)<br/>new york city(0.60)", "pred answer": "train", "question_id": 5400825, "best approach": "wiki", "verif answer": "station", "anno approach": "wiki, concept, image", "verif wiki answer": "new delhi(0.5182)", "verif concept answer": "station(0.5804)", "verif image answer": "san francisco(0.5995)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000540082.jpg"}, {"question": "what flavors are these cakes", "gt answer": "chocolate and vanilla(1.00)<br/>vanilla(0.60)<br/>chocolate(0.60)", "pred answer": "sweet", "question_id": 780095, "best approach": "wiki, concept, image", "verif answer": "chocolate", "anno approach": "wiki, concept, image", "verif wiki answer": "chocolate(0.6164)", "verif concept answer": "chocolate(0.5811)", "verif image answer": "chocolate(0.5448)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000078009.jpg"}, {"question": "what sort of knee length plaid garment is associated with where this bus is", "gt answer": "kilt(1.00)<br/>skirt(0.60)", "pred answer": "jean", "question_id": 2464465, "best approach": "image", "verif answer": "skirt", "anno approach": "wiki, concept, image", "verif wiki answer": "maxi(0.7094)", "verif concept answer": "skirt(0.6135)", "verif image answer": "kilt(0.6446)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000246446.jpg"}, {"question": "what clock is this", "gt answer": "big ben(1.00)<br/>roman numeral(0.60)", "pred answer": "analog", "question_id": 64645, "best approach": "concept, image", "verif answer": "roman numeral", "anno approach": "wiki, concept, image", "verif wiki answer": "clock tower(0.5920)", "verif concept answer": "roman numeral(0.6004)", "verif image answer": "roman numeral(0.6132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000006464.jpg"}, {"question": "what is the rock made of", "gt answer": "granite(1.00)", "pred answer": "rock", "question_id": 2312805, "best approach": "", "verif answer": "rock", "anno approach": "wiki, concept, image", "verif wiki answer": "marble(0.6636)", "verif concept answer": "formica(0.6243)", "verif image answer": "ceramic(0.7002)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231280.jpg"}, {"question": "why are the lights on", "gt answer": "dark(1.00)", "pred answer": "sunlight", "question_id": 2969755, "best approach": "wiki", "verif answer": "shade", "anno approach": "wiki, concept, image", "verif wiki answer": "dark(0.5439)", "verif concept answer": "rain(0.5480)", "verif image answer": "shade(0.6446)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000296975.jpg"}, {"question": "what are these animals tusks made of", "gt answer": "ivory(1.00)", "pred answer": "leather", "question_id": 3805575, "best approach": "wiki, concept, image", "verif answer": "leather", "anno approach": "wiki, concept, image", "verif wiki answer": "ivory(0.7226)", "verif concept answer": "ivory(0.6760)", "verif image answer": "ivory(0.6929)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000380557.jpg"}, {"question": "what are these pieces in", "gt answer": "stew(1.00)<br/>carrot(0.60)", "pred answer": "dish", "question_id": 5638035, "best approach": "wiki, concept, image", "verif answer": "carrot", "anno approach": "wiki, concept, image", "verif wiki answer": "carrot(0.6014)", "verif concept answer": "carrot(0.6293)", "verif image answer": "carrot(0.6025)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000563803.jpg"}, {"question": "what types of trees are in the background of this photo", "gt answer": "pine(1.00)<br/>evergreen(0.60)", "pred answer": "oak", "question_id": 3477935, "best approach": "", "verif answer": "oak", "anno approach": "wiki, concept, image", "verif wiki answer": "oak(0.6317)", "verif concept answer": "oak(0.6664)", "verif image answer": "fir(0.6529)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000347793.jpg"}, {"question": "how fast is the train", "gt answer": "very fast(1.00)<br/>bullet(0.60)<br/>fast(0.60)", "pred answer": "80 mph", "question_id": 5167405, "best approach": "image", "verif answer": "bullet", "anno approach": "wiki, concept, image", "verif wiki answer": "100 mph(0.6017)", "verif concept answer": "100 mph(0.6114)", "verif image answer": "fast(0.6283)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516740.jpg"}, {"question": "what zoo is this", "gt answer": "san diego(1.00)<br/>american(0.60)<br/>penguin(0.60)", "pred answer": "zoo", "question_id": 5530385, "best approach": "wiki", "verif answer": "san diego", "anno approach": "wiki, concept, image", "verif wiki answer": "san diego(0.5566)", "verif concept answer": "american(0.6443)", "verif image answer": "american(0.5892)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553038.jpg"}, {"question": "what should you never cross for bad luck", "gt answer": "black cat(1.00)", "pred answer": "cat", "question_id": 457415, "best approach": "image", "verif answer": "cat", "anno approach": "wiki, concept, image", "verif wiki answer": "bear(0.6325)", "verif concept answer": "cat(0.5735)", "verif image answer": "black cat(0.5965)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000045741.jpg"}, {"question": "what model vehicle is this", "gt answer": "jeep(1.00)", "pred answer": "truck", "question_id": 5275875, "best approach": "", "verif answer": "pickup", "anno approach": "wiki, concept, image", "verif wiki answer": "suv(0.5605)", "verif concept answer": "suv(0.6092)", "verif image answer": "model t(0.6730)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527587.jpg"}, {"question": "where is everyone rushing", "gt answer": "train station(1.00)<br/>plane(0.60)<br/>gate(0.60)", "pred answer": "street", "question_id": 1999635, "best approach": "wiki, image", "verif answer": "sidewalk", "anno approach": "wiki, concept, image", "verif wiki answer": "train station(0.7127)", "verif concept answer": "sidewalk(0.6137)", "verif image answer": "train station(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199963.jpg"}, {"question": "", "gt answer": "20(0.60)<br/>14(0.60)", "pred answer": "10", "question_id": 5537585, "best approach": "concept", "verif answer": "14", "anno approach": "wiki, concept, image", "verif wiki answer": "20 years(0.6230)", "verif concept answer": "20(0.5934)", "verif image answer": "20 years(0.6199)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000553758.jpg"}, {"question": "what kind of boat is being sailed", "gt answer": "tug(1.00)<br/>fish(1.00)<br/>fish boat(0.60)", "pred answer": "boat", "question_id": 5393175, "best approach": "wiki, concept", "verif answer": "fish boat", "anno approach": "wiki, concept, image", "verif wiki answer": "fish boat(0.6035)", "verif concept answer": "fish boat(0.5762)", "verif image answer": "sail(0.6542)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539317.jpg"}, {"question": "what type of envelope is under the laptop", "gt answer": "manila(1.00)", "pred answer": "post it note", "question_id": 3883815, "best approach": "", "verif answer": "english", "anno approach": "wiki, concept, image", "verif wiki answer": "2004(0.5301)", "verif concept answer": "2004(0.6169)", "verif image answer": "2004(0.6979)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388381.jpg"}, {"question": "what electronic device does this items connect with", "gt answer": "computer(1.00)", "pred answer": "bluetooth", "question_id": 2812805, "best approach": "", "verif answer": "computer", "anno approach": "wiki, concept, image", "verif wiki answer": "electron(0.6891)", "verif concept answer": "laptop(0.6972)", "verif image answer": "electron(0.5894)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000281280.jpg"}, {"question": "what is the rod in the boys hand made of", "gt answer": "fiberglass(1.00)<br/>steel(0.60)<br/>aluminum(0.60)", "pred answer": "metal", "question_id": 1038395, "best approach": "concept", "verif answer": "metal", "anno approach": "wiki, concept, image", "verif wiki answer": "aluminum(0.6336)", "verif concept answer": "fiberglass(0.6549)", "verif image answer": "plastic(0.5560)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103839.jpg"}, {"question": "what color are these scissors", "gt answer": "gold(1.00)", "pred answer": "yellow", "question_id": 3773975, "best approach": "concept, image", "verif answer": "silver", "anno approach": "wiki, concept, image", "verif wiki answer": "silver(0.6354)", "verif concept answer": "gold(0.6702)", "verif image answer": "gold(0.5382)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000377397.jpg"}, {"question": "what was inside", "gt answer": "cloth(1.00)<br/>nothing(0.60)", "pred answer": "luggage", "question_id": 2852145, "best approach": "image", "verif answer": "luggage", "anno approach": "wiki, concept, image", "verif wiki answer": "book(0.5915)", "verif concept answer": "money(0.6153)", "verif image answer": "nothing(0.7155)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285214.jpg"}, {"question": "what has interesting architecture here", "gt answer": "build(1.00)", "pred answer": "city", "question_id": 165785, "best approach": "", "verif answer": "city", "anno approach": "wiki, concept, image", "verif wiki answer": "skyscraper(0.7184)", "verif concept answer": "skyscraper(0.6790)", "verif image answer": "skyscraper(0.6782)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016578.jpg"}, {"question": "what kind of job does this man have", "gt answer": "conductor(1.00)<br/>engineer(0.60)", "pred answer": "cook", "question_id": 3248705, "best approach": "wiki", "verif answer": "engineer", "anno approach": "wiki, concept, image", "verif wiki answer": "engineer(0.5912)", "verif concept answer": "train conductor(0.5906)", "verif image answer": "driver(0.6366)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324870.jpg"}, {"question": "when did this food go mainstream in north america", "gt answer": "1900(1.00)", "pred answer": "chicago", "question_id": 5239075, "best approach": "", "verif answer": "1850", "anno approach": "wiki, concept, image", "verif wiki answer": "victorian(0.6790)", "verif concept answer": "victorian(0.6144)", "verif image answer": "1850(0.5874)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000523907.jpg"}, {"question": "why are there different fruits in this picture", "gt answer": "market(1.00)<br/>store(0.60)", "pred answer": "storage", "question_id": 5067505, "best approach": "wiki", "verif answer": "farmer market", "anno approach": "wiki, concept, image", "verif wiki answer": "store(0.5505)", "verif concept answer": "farmer market(0.5462)", "verif image answer": "supermarket(0.6361)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000506750.jpg"}, {"question": "how do you make the purple object fly far", "gt answer": "throw it(1.00)<br/>throw(0.60)", "pred answer": "wind", "question_id": 427565, "best approach": "wiki, concept, image", "verif answer": "catch", "anno approach": "wiki, concept, image", "verif wiki answer": "throw it(0.6214)", "verif concept answer": "throw it(0.6658)", "verif image answer": "throw it(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042756.jpg"}, {"question": "what does the top of the tower have on it", "gt answer": "clock(1.00)", "pred answer": "star", "question_id": 3826245, "best approach": "", "verif answer": "clock", "anno approach": "wiki, concept, image", "verif wiki answer": "roman numeral(0.7096)", "verif concept answer": "roman numeral(0.6422)", "verif image answer": "telephone(0.7279)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000382624.jpg"}, {"question": "how long does it normally take to get a business like this started", "gt answer": "2 years(1.00)<br/>year(1.00)<br/>4 months(0.60)", "pred answer": "hour", "question_id": 752705, "best approach": "wiki, concept, image", "verif answer": "4 years", "anno approach": "wiki, concept, image", "verif wiki answer": "year(0.7082)", "verif concept answer": "year(0.7143)", "verif image answer": "year(0.7121)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000075270.jpg"}, {"question": "is this space crowded or spacious", "gt answer": "crowded(1.00)", "pred answer": "quiet", "question_id": 428045, "best approach": "wiki, concept", "verif answer": "parade", "anno approach": "wiki, concept, image", "verif wiki answer": "crowded(0.6761)", "verif concept answer": "crowded(0.5188)", "verif image answer": "parade(0.6895)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000042804.jpg"}, {"question": "what activity is engaged in this picture", "gt answer": "chop(1.00)<br/>dice(0.60)<br/>cut(0.60)", "pred answer": "sew", "question_id": 1970295, "best approach": "image", "verif answer": "cut", "anno approach": "wiki, concept, image", "verif wiki answer": "cut(0.6514)", "verif concept answer": "cut(0.5970)", "verif image answer": "chop(0.6830)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000197029.jpg"}, {"question": "what kind of object is this", "gt answer": "doll(1.00)", "pred answer": "stuffed animal", "question_id": 4991305, "best approach": "image", "verif answer": "stuffed animal", "anno approach": "wiki, concept, image", "verif wiki answer": "bear(0.7169)", "verif concept answer": "bear(0.6430)", "verif image answer": "doll(0.6818)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000499130.jpg"}, {"question": "what college is advertised on his shirt", "gt answer": "brevard(1.00)", "pred answer": "dodger", "question_id": 4442855, "best approach": "wiki", "verif answer": "yankees", "anno approach": "wiki, concept, image", "verif wiki answer": "brevard(0.6750)", "verif concept answer": "major(0.6070)", "verif image answer": "navy(0.5354)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000444285.jpg"}, {"question": "what makes red velvet cake red", "gt answer": "food color(1.00)<br/>strawberry(0.60)", "pred answer": "ice", "question_id": 3866695, "best approach": "wiki, image", "verif answer": "chocolate", "anno approach": "wiki, concept, image", "verif wiki answer": "strawberry(0.6975)", "verif concept answer": "rose(0.5968)", "verif image answer": "strawberry(0.6966)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000386669.jpg"}, {"question": "what type of beer is this", "gt answer": "draft(1.00)<br/>ale(0.60)", "pred answer": "budweiser", "question_id": 115045, "best approach": "", "verif answer": "budweiser", "anno approach": "wiki, concept, image", "verif wiki answer": "budweiser(0.6611)", "verif concept answer": "budweiser(0.6762)", "verif image answer": "budweiser(0.7235)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011504.jpg"}, {"question": "this fruit contains what kind of acid", "gt answer": "acidic(1.00)<br/>vitamin c(0.60)", "pred answer": "orange", "question_id": 613075, "best approach": "wiki, concept", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin c(0.7048)", "verif concept answer": "vitamin c(0.6844)", "verif image answer": "c(0.7222)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000061307.jpg"}, {"question": "", "gt answer": "vandalism(0.60)<br/>do not turn(0.60)", "pred answer": "light", "question_id": 831535, "best approach": "wiki, concept, image", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "do not turn(0.6633)", "verif concept answer": "do not turn(0.6708)", "verif image answer": "do not turn(0.6858)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083153.jpg"}, {"question": "what type of bathroom is this", "gt answer": "hotel bathroom(1.00)<br/>ceramic(0.60)<br/>modern(0.60)<br/>residential(0.60)", "pred answer": "double", "question_id": 3909965, "best approach": "wiki, concept, image", "verif answer": "residential", "anno approach": "wiki, concept, image", "verif wiki answer": "modern(0.5573)", "verif concept answer": "modern(0.5848)", "verif image answer": "residential(0.6296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000390996.jpg"}, {"question": "what model is this camera", "gt answer": "canon(1.00)", "pred answer": "digital", "question_id": 2746405, "best approach": "wiki, concept", "verif answer": "digital", "anno approach": "wiki, concept, image", "verif wiki answer": "canon(0.7252)", "verif concept answer": "canon(0.6734)", "verif image answer": "security camera(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274640.jpg"}, {"question": "can you name the boat driven in the sea", "gt answer": "yacht(1.00)<br/>speedboat(0.60)<br/>fish(0.60)", "pred answer": "dock", "question_id": 4588665, "best approach": "wiki, image", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "fish(0.5582)", "verif concept answer": "boat(0.5678)", "verif image answer": "fish(0.6111)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458866.jpg"}, {"question": "what occupation would service this area of a home for a problem", "gt answer": "plumber(1.00)", "pred answer": "janitor", "question_id": 719075, "best approach": "wiki, concept, image", "verif answer": "plumber", "anno approach": "wiki, concept, image", "verif wiki answer": "plumber(0.6487)", "verif concept answer": "plumber(0.6457)", "verif image answer": "plumber(0.5085)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071907.jpg"}, {"question": "what song did the woman most likely sing before this game", "gt answer": "national anthem(1.00)", "pred answer": "happy birthday", "question_id": 2609325, "best approach": "", "verif answer": "chirp", "anno approach": "wiki, concept, image", "verif wiki answer": "chirp(0.6734)", "verif concept answer": "chirp(0.6034)", "verif image answer": "chirp(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260932.jpg"}, {"question": "which breed of dog it this", "gt answer": "doberman(1.00)<br/>lab(0.60)", "pred answer": "mutt", "question_id": 4078095, "best approach": "image", "verif answer": "terrier", "anno approach": "wiki, concept, image", "verif wiki answer": "terrier(0.6685)", "verif concept answer": "terrier(0.6441)", "verif image answer": "doberman(0.5529)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407809.jpg"}, {"question": "what is the multi colored topping on the donut to the top left", "gt answer": "sprinkle(1.00)<br/>cinnamon(0.60)", "pred answer": "frost", "question_id": 321155, "best approach": "wiki, concept, image", "verif answer": "sprinkle", "anno approach": "wiki, concept, image", "verif wiki answer": "sprinkle(0.5863)", "verif concept answer": "sprinkle(0.5386)", "verif image answer": "sprinkle(0.6649)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000032115.jpg"}, {"question": "what type of item is this woman holding in her hand", "gt answer": "shield(1.00)<br/>book(0.60)<br/>flag(0.60)", "pred answer": "bowl", "question_id": 2517775, "best approach": "image", "verif answer": "flag", "anno approach": "wiki, concept, image", "verif wiki answer": "picture(0.6969)", "verif concept answer": "balloon(0.5986)", "verif image answer": "flag(0.5522)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251777.jpg"}, {"question": "are the scissors opened or closed", "gt answer": "closed(1.00)<br/>open(0.60)", "pred answer": "horizontal", "question_id": 2402885, "best approach": "wiki, concept, image", "verif answer": "open", "anno approach": "wiki, concept, image", "verif wiki answer": "closed(0.5747)", "verif concept answer": "closed(0.6053)", "verif image answer": "closed(0.6652)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000240288.jpg"}, {"question": "what cartoon does that animal remind you of", "gt answer": "garfield(1.00)", "pred answer": "looney tune", "question_id": 4673335, "best approach": "image", "verif answer": "garfield", "anno approach": "wiki, concept, image", "verif wiki answer": "abu dhabi(0.5745)", "verif concept answer": "tiger(0.5380)", "verif image answer": "garfield(0.5103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000467333.jpg"}, {"question": "what is the tool laying on the left side of the dirt called", "gt answer": "shovel(1.00)", "pred answer": "pipe", "question_id": 2354665, "best approach": "concept", "verif answer": "shovel", "anno approach": "wiki, concept, image", "verif wiki answer": "backpack(0.5816)", "verif concept answer": "shovel(0.5943)", "verif image answer": "plate(0.6084)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000235466.jpg"}, {"question": "what is the food in the bowl usually eaten with", "gt answer": "butter(1.00)<br/>hand(0.60)", "pred answer": "spoon", "question_id": 2204495, "best approach": "wiki, concept, image", "verif answer": "butter", "anno approach": "wiki, concept, image", "verif wiki answer": "hand(0.6829)", "verif concept answer": "hand(0.6019)", "verif image answer": "hand(0.6538)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000220449.jpg"}, {"question": "what is the lady expressing at this picnic", "gt answer": "happiness(1.00)<br/>smile(0.60)", "pred answer": "eat", "question_id": 2028555, "best approach": "", "verif answer": "smile", "anno approach": "wiki, concept, image", "verif wiki answer": "happy(0.7290)", "verif concept answer": "boredom(0.6285)", "verif image answer": "happy(0.6787)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000202855.jpg"}, {"question": "where is this photo taken", "gt answer": "miami(1.00)<br/>los angeles(0.60)<br/>florida(0.60)", "pred answer": "beach", "question_id": 94465, "best approach": "", "verif answer": "beach", "anno approach": "wiki, concept, image", "verif wiki answer": "beach(0.5884)", "verif concept answer": "beach(0.6144)", "verif image answer": "san diego(0.7269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000009446.jpg"}, {"question": "where is the man going", "gt answer": "beach(1.00)<br/>surf(0.60)", "pred answer": "shop", "question_id": 672695, "best approach": "wiki, concept", "verif answer": "beach", "anno approach": "wiki, concept, image", "verif wiki answer": "beach(0.5581)", "verif concept answer": "beach(0.6103)", "verif image answer": "hawaii(0.6747)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000067269.jpg"}, {"question": "what was the elephant 's name in tarzan", "gt answer": "tantor(1.00)", "pred answer": "zoo", "question_id": 5148715, "best approach": "wiki", "verif answer": "toy r us", "anno approach": "wiki, concept, image", "verif wiki answer": "tantor(0.6483)", "verif concept answer": "black and white(0.5425)", "verif image answer": "toy r us(0.6027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000514871.jpg"}, {"question": "what event does this food signify", "gt answer": "baptism(1.00)<br/>wed(0.60)<br/>easter(0.60)", "pred answer": "birthday", "question_id": 2722695, "best approach": "wiki, concept, image", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "wed(0.6264)", "verif concept answer": "wed(0.6681)", "verif image answer": "wed(0.7250)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000272269.jpg"}, {"question": "what type of waterboard is that", "gt answer": "surfboard(1.00)<br/>surf(0.60)", "pred answer": "longboard", "question_id": 288545, "best approach": "wiki", "verif answer": "surfboard", "anno approach": "wiki, concept, image", "verif wiki answer": "surfboard(0.6223)", "verif concept answer": "surf board(0.6400)", "verif image answer": "wood(0.6032)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000028854.jpg"}, {"question": "what will this person do with the item he is holding", "gt answer": "brush teeth(1.00)<br/>brush(1.00)", "pred answer": "cut", "question_id": 3768295, "best approach": "wiki, image", "verif answer": "brush teeth", "anno approach": "wiki, concept, image", "verif wiki answer": "brush teeth(0.6619)", "verif concept answer": "toothbrush(0.6429)", "verif image answer": "brush teeth(0.5569)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000376829.jpg"}, {"question": "what kind of chair is this", "gt answer": "desk(1.00)<br/>office(1.00)", "pred answer": "loveseat", "question_id": 1839575, "best approach": "wiki, image", "verif answer": "desk", "anno approach": "wiki, concept, image", "verif wiki answer": "desk(0.6577)", "verif concept answer": "computer(0.6415)", "verif image answer": "desk(0.6488)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000183957.jpg"}, {"question": "", "gt answer": "rattan(0.60)<br/>straw(0.60)", "pred answer": "wicker", "question_id": 1184226, "best approach": "wiki", "verif answer": "wicker", "anno approach": "wiki, concept, image", "verif wiki answer": "straw(0.6549)", "verif concept answer": "wicker(0.6238)", "verif image answer": "wicker(0.6467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000118422.jpg"}, {"question": "what team does the batter play for", "gt answer": "pirate(1.00)", "pred answer": "met", "question_id": 3365415, "best approach": "wiki", "verif answer": "met", "anno approach": "wiki, concept, image", "verif wiki answer": "pirate(0.6195)", "verif concept answer": "met(0.6035)", "verif image answer": "navy(0.5339)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000336541.jpg"}, {"question": "behind the mirror you can keep your toothbrush in the blank", "gt answer": "cabinet(1.00)", "pred answer": "bathroom", "question_id": 5152875, "best approach": "", "verif answer": "fan", "anno approach": "wiki, concept, image", "verif wiki answer": "fan(0.5418)", "verif concept answer": "grandma(0.5604)", "verif image answer": "fan(0.5116)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000515287.jpg"}, {"question": "what branch of the millitary is this boat representing", "gt answer": "navy(1.00)<br/>marine(0.60)", "pred answer": "military", "question_id": 4829545, "best approach": "", "verif answer": "army", "anno approach": "wiki, concept, image", "verif wiki answer": "air force(0.6407)", "verif concept answer": "army(0.6100)", "verif image answer": "texas(0.6428)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000482954.jpg"}, {"question": "which country does this food originate from", "gt answer": "italy(1.00)", "pred answer": "germany", "question_id": 355085, "best approach": "concept, image", "verif answer": "italy", "anno approach": "wiki, concept, image", "verif wiki answer": "mexico(0.6170)", "verif concept answer": "italy(0.6189)", "verif image answer": "italy(0.6650)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000035508.jpg"}, {"question": "what gender is the horse", "gt answer": "female(1.00)<br/>mare(0.60)", "pred answer": "male", "question_id": 3887725, "best approach": "image", "verif answer": "female", "anno approach": "wiki, concept, image", "verif wiki answer": "male(0.6878)", "verif concept answer": "women(0.6699)", "verif image answer": "female(0.7221)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000388772.jpg"}, {"question": "what shape is this pizza", "gt answer": "heart(1.00)", "pred answer": "round", "question_id": 3318715, "best approach": "", "verif answer": "heart", "anno approach": "wiki, concept, image", "verif wiki answer": "eye(0.5377)", "verif concept answer": "eye(0.5061)", "verif image answer": "eye(0.5030)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000331871.jpg"}, {"question": "what type of sunray is most dangerous that the item she is holding is attempting to block", "gt answer": "uv(1.00)", "pred answer": "shark", "question_id": 3709455, "best approach": "", "verif answer": "hannibal", "anno approach": "wiki, concept, image", "verif wiki answer": "hannibal(0.5196)", "verif concept answer": "hannibal(0.5522)", "verif image answer": "hannibal(0.5427)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370945.jpg"}, {"question": "apart from calls how else can these devices be used to communicate", "gt answer": "text(1.00)", "pred answer": "cell phone", "question_id": 3561875, "best approach": "", "verif answer": "text", "anno approach": "wiki, concept, image", "verif wiki answer": "play(0.6360)", "verif concept answer": "camera(0.5922)", "verif image answer": "clean(0.5273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356187.jpg"}, {"question": "which item in this room is reserved for cooking", "gt answer": "stove(1.00)", "pred answer": "oven", "question_id": 3365695, "best approach": "image", "verif answer": "oven", "anno approach": "wiki, concept, image", "verif wiki answer": "mixer(0.6656)", "verif concept answer": "mixer(0.6789)", "verif image answer": "stove(0.7179)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000336569.jpg"}, {"question": "what us president is named in this picture", "gt answer": "barack obama(1.00)<br/>obama(0.60)", "pred answer": "roosevelt", "question_id": 1928355, "best approach": "concept, image", "verif answer": "roosevelt", "anno approach": "wiki, concept, image", "verif wiki answer": "dexter(0.6669)", "verif concept answer": "barack obama(0.6746)", "verif image answer": "barack obama(0.6833)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000192835.jpg"}, {"question": "what country are these humans in", "gt answer": "australia(1.00)", "pred answer": "america", "question_id": 5647155, "best approach": "wiki", "verif answer": "africa", "anno approach": "wiki, concept, image", "verif wiki answer": "australia(0.6816)", "verif concept answer": "american(0.6104)", "verif image answer": "japan(0.5953)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564715.jpg"}, {"question": "what is the use of the red extrusion from the building", "gt answer": "awn(1.00)<br/>shade(0.60)<br/>fire(0.60)", "pred answer": "lighthouse", "question_id": 3185985, "best approach": "wiki, image", "verif answer": "fire", "anno approach": "wiki, concept, image", "verif wiki answer": "fire(0.6872)", "verif concept answer": "warmth(0.5552)", "verif image answer": "shade(0.5584)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000318598.jpg"}, {"question": "what kind of horses are these", "gt answer": "quarter(1.00)<br/>police(0.60)<br/>ride(0.60)", "pred answer": "stallion", "question_id": 146835, "best approach": "wiki", "verif answer": "ride", "anno approach": "wiki, concept, image", "verif wiki answer": "ride(0.6312)", "verif concept answer": "pinto(0.6450)", "verif image answer": "race(0.6491)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000014683.jpg"}, {"question": "why are these clothes folded", "gt answer": "pack(1.00)", "pred answer": "warmth", "question_id": 4098215, "best approach": "", "verif answer": "tired", "anno approach": "wiki, concept, image", "verif wiki answer": "tired(0.6714)", "verif concept answer": "tired(0.5949)", "verif image answer": "flock(0.7073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000409821.jpg"}, {"question": "what is the brand pictured on the back of this truck", "gt answer": "overnite(1.00)", "pred answer": "toyota", "question_id": 3608695, "best approach": "concept, image", "verif answer": "coca cola", "anno approach": "wiki, concept, image", "verif wiki answer": "coca cola(0.6379)", "verif concept answer": "overnite(0.6506)", "verif image answer": "overnite(0.5114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000360869.jpg"}, {"question": "do these two animals usually get along or do they fight", "gt answer": "fight(1.00)", "pred answer": "play", "question_id": 3573425, "best approach": "concept", "verif answer": "play", "anno approach": "wiki, concept, image", "verif wiki answer": "tired(0.7123)", "verif concept answer": "fight(0.6627)", "verif image answer": "tired(0.6290)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000357342.jpg"}, {"question": "what 's the tall object in the back of the photo", "gt answer": "windmill(1.00)", "pred answer": "tree", "question_id": 911355, "best approach": "", "verif answer": "kite", "anno approach": "wiki, concept, image", "verif wiki answer": "power line(0.6579)", "verif concept answer": "wind turbine(0.6028)", "verif image answer": "kite(0.6926)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000091135.jpg"}, {"question": "where is the brim on this fellows hat", "gt answer": "back(1.00)<br/>behind(0.60)", "pred answer": "front", "question_id": 1313155, "best approach": "", "verif answer": "front", "anno approach": "wiki, concept, image", "verif wiki answer": "east(0.6365)", "verif concept answer": "north(0.5930)", "verif image answer": "front(0.5944)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000131315.jpg"}, {"question": "what do you call this sport with the kite and skis", "gt answer": "kiteboarding(1.00)", "pred answer": "snowboard", "question_id": 4035205, "best approach": "concept", "verif answer": "snowboard", "anno approach": "wiki, concept, image", "verif wiki answer": "snowboard(0.6053)", "verif concept answer": "kiteboarding(0.6777)", "verif image answer": "kite(0.5866)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000403520.jpg"}, {"question": "what metal is the silver colored vase with the flowers in it made from", "gt answer": "aluminium(1.00)<br/>copper(0.60)", "pred answer": "metal", "question_id": 3260645, "best approach": "", "verif answer": "metal", "anno approach": "wiki, concept, image", "verif wiki answer": "24 gauge(0.6951)", "verif concept answer": "24 gauge(0.7017)", "verif image answer": "24 gauge(0.6596)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000326064.jpg"}, {"question": "what language is written here", "gt answer": "french(1.00)<br/>english(1.00)", "pred answer": "chinese", "question_id": 4974835, "best approach": "wiki, concept, image", "verif answer": "french", "anno approach": "wiki, concept, image", "verif wiki answer": "english(0.6272)", "verif concept answer": "french(0.6263)", "verif image answer": "french(0.7224)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000497483.jpg"}, {"question": "how long does it take to potty train this animal", "gt answer": "1 month(1.00)<br/>year(0.60)", "pred answer": "hour", "question_id": 3045235, "best approach": "", "verif answer": "10 hours", "anno approach": "wiki, concept, image", "verif wiki answer": "2 days(0.6545)", "verif concept answer": "4 months(0.6318)", "verif image answer": "4 months(0.5642)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304523.jpg"}, {"question": "is this a mixing bowl or a pour container", "gt answer": "pour(1.00)<br/>both(0.60)", "pred answer": "mug", "question_id": 945275, "best approach": "", "verif answer": "both", "anno approach": "wiki, concept, image", "verif wiki answer": "fauna(0.6185)", "verif concept answer": "predator(0.6141)", "verif image answer": "wild(0.5379)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094527.jpg"}, {"question": "who wrote a popular rap song named after this vegetable", "gt answer": "dram(1.00)", "pred answer": "van gogh", "question_id": 3788965, "best approach": "", "verif answer": "chicago", "anno approach": "wiki, concept, image", "verif wiki answer": "chicago(0.5880)", "verif concept answer": "green giant(0.5886)", "verif image answer": "green giant(0.5988)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378896.jpg"}, {"question": "what would people go into the building in the distance to do", "gt answer": "work(1.00)<br/>train(0.60)<br/>hospital(0.60)<br/>study(0.60)", "pred answer": "run", "question_id": 5355525, "best approach": "wiki", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "work(0.5193)", "verif concept answer": "study(0.5142)", "verif image answer": "office(0.5968)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535552.jpg"}, {"question": "is there an accident up ahead that is causing this traffic slow down or is it normal traffic", "gt answer": "normal(1.00)", "pred answer": "rush hour", "question_id": 395555, "best approach": "wiki, concept, image", "verif answer": "normal", "anno approach": "wiki, concept, image", "verif wiki answer": "normal(0.6274)", "verif concept answer": "normal(0.6211)", "verif image answer": "normal(0.6043)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039555.jpg"}, {"question": "what is on the persons head", "gt answer": "scarf(1.00)", "pred answer": "hat", "question_id": 3161025, "best approach": "concept", "verif answer": "scarf", "anno approach": "wiki, concept, image", "verif wiki answer": "sweater(0.7057)", "verif concept answer": "scarf(0.6460)", "verif image answer": "necklace(0.6912)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000316102.jpg"}, {"question": "what are the wood pieces hanging from ceiling called", "gt answer": "beam(1.00)", "pred answer": "light", "question_id": 1518485, "best approach": "", "verif answer": "chandelier", "anno approach": "wiki, concept, image", "verif wiki answer": "microphone(0.6855)", "verif concept answer": "power line(0.6406)", "verif image answer": "chandelier(0.6538)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000151848.jpg"}, {"question": "hotel room or tv room at home", "gt answer": "tv room at home(1.00)", "pred answer": "live room", "question_id": 3543925, "best approach": "wiki", "verif answer": "night", "anno approach": "wiki, concept, image", "verif wiki answer": "tv room at home(0.6957)", "verif concept answer": "text(0.6015)", "verif image answer": "night(0.7236)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354392.jpg"}, {"question": "what kinds of sheep are these", "gt answer": "angora(1.00)<br/>ewe(0.60)", "pred answer": "merino", "question_id": 2890305, "best approach": "concept", "verif answer": "dairy", "anno approach": "wiki, concept, image", "verif wiki answer": "sheep(0.5840)", "verif concept answer": "ewe(0.5864)", "verif image answer": "dairy(0.5636)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000289030.jpg"}, {"question": "what are these men wearing", "gt answer": "apron(1.00)", "pred answer": "tie", "question_id": 3704795, "best approach": "", "verif answer": "chef", "anno approach": "wiki, concept, image", "verif wiki answer": "chef(0.6748)", "verif concept answer": "pen(0.5742)", "verif image answer": "pen(0.5259)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000370479.jpg"}, {"question": "what kind of truck is crossing the bridge", "gt answer": "semi(1.00)<br/>industrial(0.60)", "pred answer": "pickup", "question_id": 449375, "best approach": "", "verif answer": "tractor trailer", "anno approach": "wiki, concept, image", "verif wiki answer": "tractor trailer(0.6169)", "verif concept answer": "tractor trailer(0.6753)", "verif image answer": "tractor trailer(0.5335)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000044937.jpg"}, {"question": "what other parks have similar benches as the ones listed in this picture", "gt answer": "central park(1.00)<br/>city(0.60)<br/>new york(0.60)", "pred answer": "0", "question_id": 5485325, "best approach": "concept, image", "verif answer": "central park", "anno approach": "wiki, concept, image", "verif wiki answer": "central(0.5676)", "verif concept answer": "central park(0.6075)", "verif image answer": "central park(0.7183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000548532.jpg"}, {"question": "would a five year old eat this or someone older", "gt answer": "older(1.00)", "pred answer": "healthy", "question_id": 4264455, "best approach": "", "verif answer": "old", "anno approach": "wiki, concept, image", "verif wiki answer": "clean(0.6018)", "verif concept answer": "clean(0.6005)", "verif image answer": "old(0.6807)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000426445.jpg"}, {"question": "is the number on the back odd or even", "gt answer": "even(1.00)", "pred answer": "good", "question_id": 1466265, "best approach": "", "verif answer": "night", "anno approach": "wiki, concept, image", "verif wiki answer": "night(0.5501)", "verif concept answer": "afternoon(0.5202)", "verif image answer": "filter(0.5100)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146626.jpg"}, {"question": "based off of the picture who 's birthday are they celebrating", "gt answer": "grandma(1.00)<br/>old woman(0.60)<br/>1 year(0.60)", "pred answer": "birthday", "question_id": 3556855, "best approach": "wiki, concept, image", "verif answer": "baby", "anno approach": "wiki, concept, image", "verif wiki answer": "1 year(0.6267)", "verif concept answer": "old woman(0.6165)", "verif image answer": "1 year(0.7226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355685.jpg"}, {"question": "which sisters are famous for playing this sport", "gt answer": "williams(1.00)", "pred answer": "roger federer", "question_id": 3717355, "best approach": "wiki, concept, image", "verif answer": "serena williams", "anno approach": "wiki, concept, image", "verif wiki answer": "williams(0.6360)", "verif concept answer": "williams(0.6204)", "verif image answer": "williams(0.6768)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000371735.jpg"}, {"question": "what kind of artwork is this", "gt answer": "grafitti(1.00)<br/>graffiti(0.60)<br/>mural(0.60)<br/>indian(0.60)", "pred answer": "paint", "question_id": 435585, "best approach": "wiki, concept, image", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "mural(0.5677)", "verif concept answer": "mural(0.6658)", "verif image answer": "graffiti(0.6972)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000043558.jpg"}, {"question": "what terrain is in the picture", "gt answer": "mountain(1.00)", "pred answer": "desert", "question_id": 2912905, "best approach": "concept", "verif answer": "desert", "anno approach": "wiki, concept, image", "verif wiki answer": "desert(0.7227)", "verif concept answer": "mountain(0.6558)", "verif image answer": "desert(0.6423)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000291290.jpg"}, {"question": "what kind of light item is seen in the upper part of this picture", "gt answer": "chandelier(1.00)", "pred answer": "lamp", "question_id": 32365, "best approach": "", "verif answer": "lamp", "anno approach": "wiki, concept, image", "verif wiki answer": "lamp(0.5703)", "verif concept answer": "led(0.5936)", "verif image answer": "lamp(0.7230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000003236.jpg"}, {"question": "what type of fries are in this photo", "gt answer": "curly(1.00)", "pred answer": "waffle", "question_id": 4406415, "best approach": "", "verif answer": "waffle", "anno approach": "wiki, concept, image", "verif wiki answer": "waffle(0.5302)", "verif concept answer": "toy r us(0.5273)", "verif image answer": "waffle(0.5102)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440641.jpg"}, {"question": "what daily function may be done while seated in this room", "gt answer": "defecation(1.00)<br/>shower(0.60)<br/>bathroom(0.60)", "pred answer": "wash hand", "question_id": 3758785, "best approach": "concept", "verif answer": "wash hand", "anno approach": "wiki, concept, image", "verif wiki answer": "bath(0.6449)", "verif concept answer": "defecation(0.5957)", "verif image answer": "wash hand(0.6540)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375878.jpg"}, {"question": "what 's going on in this picture", "gt answer": "tow(1.00)<br/>accident(0.60)", "pred answer": "motorcycle", "question_id": 576175, "best approach": "concept, image", "verif answer": "accident", "anno approach": "wiki, concept, image", "verif wiki answer": "police(0.6958)", "verif concept answer": "tow(0.6417)", "verif image answer": "tow(0.6712)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000057617.jpg"}, {"question": "what kind of truck is this", "gt answer": "ice cream(1.00)<br/>food truck(0.60)", "pred answer": "semi", "question_id": 2417975, "best approach": "wiki", "verif answer": "ice cream", "anno approach": "wiki, concept, image", "verif wiki answer": "ice cream(0.6852)", "verif concept answer": "icecream(0.6190)", "verif image answer": "food truck(0.5092)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241797.jpg"}, {"question": "what breed of dog is the dog on the left", "gt answer": "shepard(1.00)<br/>german shepard(0.60)<br/>beagle(0.60)<br/>german shepherd(0.60)", "pred answer": "pug", "question_id": 2447205, "best approach": "wiki, concept", "verif answer": "mixed", "anno approach": "wiki, concept, image", "verif wiki answer": "german shepard(0.6397)", "verif concept answer": "german shepherd(0.6386)", "verif image answer": "mixed(0.6412)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000244720.jpg"}, {"question": "what kind of wood is this bed made from", "gt answer": "mahogany(1.00)<br/>cherry(0.60)", "pred answer": "oak", "question_id": 4290485, "best approach": "image", "verif answer": "oak", "anno approach": "wiki, concept, image", "verif wiki answer": "wood(0.6566)", "verif concept answer": "oak(0.6425)", "verif image answer": "cherry(0.7211)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429048.jpg"}, {"question": "which british tradition comes t mind when viewing some of these articles", "gt answer": "tea(1.00)<br/>breakfast(0.60)", "pred answer": "western", "question_id": 3286795, "best approach": "image", "verif answer": "espresso", "anno approach": "wiki, concept, image", "verif wiki answer": "espresso(0.5227)", "verif concept answer": "espresso(0.5573)", "verif image answer": "tea(0.5207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328679.jpg"}, {"question": "are those leather or synthetic fabric seating", "gt answer": "synthetic(1.00)", "pred answer": "canvas", "question_id": 1414135, "best approach": "", "verif answer": "faux", "anno approach": "wiki, concept, image", "verif wiki answer": "faux(0.5941)", "verif concept answer": "faux(0.6737)", "verif image answer": "faux(0.6891)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000141413.jpg"}, {"question": "what model of phone is this", "gt answer": "razor(1.00)<br/>nokia(0.60)", "pred answer": "flip phone", "question_id": 654485, "best approach": "image", "verif answer": "samsung", "anno approach": "wiki, concept, image", "verif wiki answer": "motorola(0.6219)", "verif concept answer": "samsung(0.6221)", "verif image answer": "nokia(0.6226)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000065448.jpg"}, {"question": "how many passengers does the vehicle in the picture seat at maximum", "gt answer": "200(1.00)<br/>300(0.60)<br/>500(0.60)", "pred answer": "100", "question_id": 3921155, "best approach": "wiki, image", "verif answer": "500", "anno approach": "wiki, concept, image", "verif wiki answer": "200(0.6610)", "verif concept answer": "500(0.6161)", "verif image answer": "200(0.6113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392115.jpg"}, {"question": "will this hedgehog crawl off the shelf or will it be picked up first", "gt answer": "picked up(1.00)", "pred answer": "move", "question_id": 773465, "best approach": "", "verif answer": "money", "anno approach": "wiki, concept, image", "verif wiki answer": "free(0.6191)", "verif concept answer": "money(0.5533)", "verif image answer": "money(0.6793)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000077346.jpg"}, {"question": "how much does it cost for parking two hours", "gt answer": "$2(1.00)<br/>2(0.60)", "pred answer": "5000", "question_id": 852845, "best approach": "wiki, concept, image", "verif answer": "1", "anno approach": "wiki, concept, image", "verif wiki answer": "$2(0.6305)", "verif concept answer": "$2(0.6048)", "verif image answer": "$2(0.6489)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085284.jpg"}, {"question": "what breed of dog is this", "gt answer": "labradoodle(1.00)<br/>cocker spaniel(0.60)<br/>schnauzer(0.60)", "pred answer": "pomeranian", "question_id": 202215, "best approach": "wiki, concept, image", "verif answer": "terrier", "anno approach": "wiki, concept, image", "verif wiki answer": "schnauzer(0.5890)", "verif concept answer": "schnauzer(0.6217)", "verif image answer": "schnauzer(0.6343)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000020221.jpg"}, {"question": "what brand of vehicle is in the picture", "gt answer": "jeep(1.00)", "pred answer": "toyota", "question_id": 416065, "best approach": "", "verif answer": "pickup", "anno approach": "wiki, concept, image", "verif wiki answer": "suv(0.6207)", "verif concept answer": "suv(0.6236)", "verif image answer": "suv(0.7126)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000041606.jpg"}, {"question": "what is the purpose of the burrs on the wire", "gt answer": "security(1.00)<br/>defense(0.60)", "pred answer": "light", "question_id": 5796215, "best approach": "wiki, image", "verif answer": "watch", "anno approach": "wiki, concept, image", "verif wiki answer": "security(0.6315)", "verif concept answer": "defense(0.6655)", "verif image answer": "security(0.6976)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000579621.jpg"}, {"question": "what kind of chips are these", "gt answer": "tortilla(1.00)<br/>potato(0.60)", "pred answer": "ruffle", "question_id": 4552555, "best approach": "wiki", "verif answer": "potato", "anno approach": "wiki, concept, image", "verif wiki answer": "potato(0.6575)", "verif concept answer": "pepper(0.6096)", "verif image answer": "pita(0.6353)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455255.jpg"}, {"question": "what kind of shoes are these", "gt answer": "sneaker(1.00)<br/>nike(0.60)<br/>power(0.60)", "pred answer": "new balance", "question_id": 4819665, "best approach": "wiki", "verif answer": "sneaker", "anno approach": "wiki, concept, image", "verif wiki answer": "sneaker(0.6777)", "verif concept answer": "tennis(0.6160)", "verif image answer": "tennis(0.5837)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000481966.jpg"}, {"question": "what 's inside the donut to the very top right", "gt answer": "jelly(1.00)<br/>cream(0.60)<br/>air(0.60)<br/>chocolate(0.60)", "pred answer": "sugar", "question_id": 633785, "best approach": "concept", "verif answer": "chocolate", "anno approach": "wiki, concept, image", "verif wiki answer": "chocolate(0.5749)", "verif concept answer": "jelly(0.5646)", "verif image answer": "chocolate(0.5907)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063378.jpg"}, {"question": "what is this applianced commonly used for", "gt answer": "refrigeration(1.00)<br/>storage(0.60)", "pred answer": "food", "question_id": 5354455, "best approach": "wiki, concept", "verif answer": "keep food cold", "anno approach": "wiki, concept, image", "verif wiki answer": "refrigeration(0.6927)", "verif concept answer": "refrigeration(0.6103)", "verif image answer": "talk(0.6942)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000535445.jpg"}, {"question": "what state do these breed of cattle live", "gt answer": "texas(1.00)", "pred answer": "new york", "question_id": 832625, "best approach": "", "verif answer": "texas", "anno approach": "wiki, concept, image", "verif wiki answer": "south(0.6350)", "verif concept answer": "western(0.6186)", "verif image answer": "western(0.6486)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000083262.jpg"}, {"question": "would this child be left handed or right handed", "gt answer": "right handed(1.00)<br/>right(1.00)", "pred answer": "left", "question_id": 4723295, "best approach": "image", "verif answer": "right", "anno approach": "wiki, concept, image", "verif wiki answer": "electric(0.6641)", "verif concept answer": "electric(0.5712)", "verif image answer": "right handed(0.7147)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000472329.jpg"}, {"question": "what are the white stakes", "gt answer": "fence post(1.00)<br/>fence(0.60)<br/>marker(0.60)", "pred answer": "track", "question_id": 5583035, "best approach": "wiki, concept", "verif answer": "fence", "anno approach": "wiki, concept, image", "verif wiki answer": "fence post(0.5987)", "verif concept answer": "fence post(0.5370)", "verif image answer": "marker(0.6416)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558303.jpg"}, {"question": "which journalist and tv personality has the first name of the street", "gt answer": "anderson cooper(1.00)", "pred answer": "friend", "question_id": 4412315, "best approach": "wiki, image", "verif answer": "friend", "anno approach": "wiki, concept, image", "verif wiki answer": "anderson cooper(0.6921)", "verif concept answer": "conductor(0.5523)", "verif image answer": "anderson cooper(0.5041)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000441231.jpg"}, {"question": "what is this vehicle used for", "gt answer": "transport good(1.00)<br/>cargo(0.60)", "pred answer": "transport", "question_id": 5640315, "best approach": "", "verif answer": "transport", "anno approach": "wiki, concept, image", "verif wiki answer": "transport(0.6532)", "verif concept answer": "transport(0.6572)", "verif image answer": "freight(0.5851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000564031.jpg"}, {"question": "where doing this animal live", "gt answer": "rainforest(1.00)<br/>hawaii(0.60)<br/>amazon(0.60)", "pred answer": "tropic", "question_id": 3722195, "best approach": "image", "verif answer": "pet store", "anno approach": "wiki, concept, image", "verif wiki answer": "hawaii(0.7075)", "verif concept answer": "hawaii(0.6240)", "verif image answer": "rainforest(0.6325)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000372219.jpg"}, {"question": "what kind of dog is in the basket", "gt answer": "poodle(1.00)<br/>teddy bear(0.60)", "pred answer": "dalmatian", "question_id": 934305, "best approach": "image", "verif answer": "poodle", "anno approach": "wiki, concept, image", "verif wiki answer": "faux(0.6889)", "verif concept answer": "teddy bear(0.6136)", "verif image answer": "poodle(0.7101)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000093430.jpg"}, {"question": "what is the purpose of the purple vehicle depicted", "gt answer": "transport people(1.00)", "pred answer": "bus", "question_id": 5246795, "best approach": "wiki, concept, image", "verif answer": "transport people", "anno approach": "wiki, concept, image", "verif wiki answer": "transport people(0.6984)", "verif concept answer": "transport people(0.6211)", "verif image answer": "transport people(0.5425)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000524679.jpg"}, {"question": "which type of cars were seen in this photo", "gt answer": "truck(1.00)", "pred answer": "scooter", "question_id": 1848795, "best approach": "", "verif answer": "truck", "anno approach": "wiki, concept, image", "verif wiki answer": "semi(0.5996)", "verif concept answer": "car(0.6018)", "verif image answer": "tow(0.6355)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184879.jpg"}, {"question": "what storybook characters are illustrated here", "gt answer": "cat(1.00)", "pred answer": "garfield", "question_id": 1382995, "best approach": "", "verif answer": "feline", "anno approach": "wiki, concept, image", "verif wiki answer": "feline(0.5970)", "verif concept answer": "feline(0.5606)", "verif image answer": "feline(0.5230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138299.jpg"}, {"question": "how is the boat staying on the water", "gt answer": "float(1.00)", "pred answer": "paddle", "question_id": 1603275, "best approach": "", "verif answer": "float", "anno approach": "wiki, concept, image", "verif wiki answer": "flotation(0.6388)", "verif concept answer": "flotation(0.6080)", "verif image answer": "flotation(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000160327.jpg"}, {"question": "what is the lighting like in this room", "gt answer": "dark(1.00)", "pred answer": "night", "question_id": 3758205, "best approach": "", "verif answer": "night", "anno approach": "wiki, concept, image", "verif wiki answer": "rain(0.6500)", "verif concept answer": "rain(0.6144)", "verif image answer": "rain(0.6132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000375820.jpg"}, {"question": "what magazine is this picture from", "gt answer": "better home(1.00)", "pred answer": "magazine", "question_id": 5335685, "best approach": "", "verif answer": "magazine", "anno approach": "wiki, concept, image", "verif wiki answer": "garfield(0.6684)", "verif concept answer": "new york time(0.6541)", "verif image answer": "target(0.5829)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000533568.jpg"}, {"question": "what is this person doing", "gt answer": "study(1.00)<br/>read(0.60)", "pred answer": "work", "question_id": 9415, "best approach": "image", "verif answer": "work", "anno approach": "wiki, concept, image", "verif wiki answer": "type(0.6645)", "verif concept answer": "work(0.6188)", "verif image answer": "study(0.6764)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000000941.jpg"}, {"question": "what type of traffic control system is this", "gt answer": "street light(0.60)<br/>stop light(1.00)<br/>light(0.60)<br/>signal(0.60)", "pred answer": "traffic", "question_id": 3144365, "best approach": "wiki, concept, image", "verif answer": "signal", "anno approach": "wiki, concept, image", "verif wiki answer": "street light(0.6423)", "verif concept answer": "street light(0.5959)", "verif image answer": "street light(0.5996)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000314436.jpg"}, {"question": "how is the larger animal likely related to the smaller animal", "gt answer": "mother(1.00)", "pred answer": "calf", "question_id": 2109515, "best approach": "wiki, concept", "verif answer": "family", "anno approach": "wiki, concept, image", "verif wiki answer": "mother(0.5448)", "verif concept answer": "mother(0.6086)", "verif image answer": "family(0.7192)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000210951.jpg"}, {"question": "which part of this meal has the most carbohydrates", "gt answer": "rice(1.00)", "pred answer": "meat", "question_id": 2718905, "best approach": "", "verif answer": "egg", "anno approach": "wiki, concept, image", "verif wiki answer": "egg(0.6842)", "verif concept answer": "egg(0.6238)", "verif image answer": "egg(0.6026)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000271890.jpg"}, {"question": "in the wild is this animal more likely to be predator or prey", "gt answer": "prey(1.00)", "pred answer": "herbivore", "question_id": 5568115, "best approach": "image", "verif answer": "lion", "anno approach": "wiki, concept, image", "verif wiki answer": "lion(0.5202)", "verif concept answer": "lion(0.5738)", "verif image answer": "prey(0.7102)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556811.jpg"}, {"question": "what was that cloth she is wearing worn for", "gt answer": "swim(1.00)<br/>bikini(0.60)", "pred answer": "safety", "question_id": 126785, "best approach": "image", "verif answer": "float", "anno approach": "wiki, concept, image", "verif wiki answer": "bikini(0.7036)", "verif concept answer": "float(0.6651)", "verif image answer": "swim(0.6967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012678.jpg"}, {"question": "can you tell me the kind of plant shown in this photo", "gt answer": "cactus(1.00)", "pred answer": "fern", "question_id": 114875, "best approach": "", "verif answer": "fern", "anno approach": "wiki, concept, image", "verif wiki answer": "fern(0.6662)", "verif concept answer": "birch(0.6284)", "verif image answer": "fern(0.6400)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000011487.jpg"}, {"question": "why does the lady have an umbrella", "gt answer": "shade(1.00)<br/>sunny(0.60)<br/>block sun(0.60)", "pred answer": "rain", "question_id": 3698665, "best approach": "concept", "verif answer": "shade", "anno approach": "wiki, concept, image", "verif wiki answer": "sunny(0.6321)", "verif concept answer": "shade(0.6141)", "verif image answer": "for shade(0.6573)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000369866.jpg"}, {"question": "what is the food in the picture called", "gt answer": "calzone(1.00)<br/>pizza(0.60)", "pred answer": "sandwich", "question_id": 2498395, "best approach": "concept", "verif answer": "pizza", "anno approach": "wiki, concept, image", "verif wiki answer": "salad(0.6375)", "verif concept answer": "calzone(0.5909)", "verif image answer": "salad(0.6086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249839.jpg"}, {"question": "when is it not ideal to use this toy", "gt answer": "rainy(1.00)<br/>no wind(1.00)<br/>night(0.60)", "pred answer": "spring", "question_id": 3394895, "best approach": "concept, image", "verif answer": "windy day", "anno approach": "wiki, concept, image", "verif wiki answer": "night(0.6605)", "verif concept answer": "no wind(0.6422)", "verif image answer": "no wind(0.6921)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000339489.jpg"}, {"question": "what raw ingredient has been added to this meal", "gt answer": "spinach(1.00)<br/>kale(0.60)<br/>vegetable(0.60)<br/>pizza(0.60)", "pred answer": "cheese", "question_id": 3590815, "best approach": "image", "verif answer": "kale", "anno approach": "wiki, concept, image", "verif wiki answer": "pizza(0.6258)", "verif concept answer": "pizza(0.6098)", "verif image answer": "spinach(0.5923)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359081.jpg"}, {"question": "what is the purpose of the light blue object in this picture", "gt answer": "water(1.00)", "pred answer": "sit", "question_id": 3917715, "best approach": "", "verif answer": "water", "anno approach": "wiki, concept, image", "verif wiki answer": "lake(0.6338)", "verif concept answer": "drink water(0.5688)", "verif image answer": "bath(0.5469)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000391771.jpg"}, {"question": "what language is on the sign", "gt answer": "english(1.00)<br/>arabic(0.60)", "pred answer": "spanish", "question_id": 801405, "best approach": "concept", "verif answer": "french", "anno approach": "wiki, concept, image", "verif wiki answer": "french(0.6864)", "verif concept answer": "arabic(0.6285)", "verif image answer": "hindi(0.5321)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080140.jpg"}, {"question": "what plant is this", "gt answer": "brocoli(1.00)<br/>broccoli(0.60)", "pred answer": "aloe", "question_id": 2034065, "best approach": "", "verif answer": "orange", "anno approach": "wiki, concept, image", "verif wiki answer": "daisy(0.6434)", "verif concept answer": "orange(0.5992)", "verif image answer": "orange(0.6386)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000203406.jpg"}, {"question": "what type of boots is the person to the left of the picture wearing", "gt answer": "rain boot(1.00)<br/>rain(0.60)", "pred answer": "boot", "question_id": 1788495, "best approach": "", "verif answer": "boot", "anno approach": "wiki, concept, image", "verif wiki answer": "boot(0.6594)", "verif concept answer": "it rain(0.5960)", "verif image answer": "it rain(0.5908)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000178849.jpg"}, {"question": "why do these shirts have numbers", "gt answer": "identification(1.00)", "pred answer": "uniform", "question_id": 3597465, "best approach": "", "verif answer": "safety", "anno approach": "wiki, concept, image", "verif wiki answer": "name(0.6461)", "verif concept answer": "track(0.5893)", "verif image answer": "track(0.5629)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000359746.jpg"}, {"question": "what activities are you able to do at this place", "gt answer": "read(1.00)<br/>shop(0.60)", "pred answer": "eat", "question_id": 4374855, "best approach": "wiki, concept, image", "verif answer": "eat", "anno approach": "wiki, concept, image", "verif wiki answer": "read(0.7248)", "verif concept answer": "read(0.6267)", "verif image answer": "read(0.6776)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437485.jpg"}, {"question": "what is the record height of a surfed wave", "gt answer": "80 ft(1.00)", "pred answer": "3 feet", "question_id": 381175, "best approach": "", "verif answer": "small", "anno approach": "wiki, concept, image", "verif wiki answer": "bullet(0.6118)", "verif concept answer": "bullet(0.5909)", "verif image answer": "amtrak(0.5519)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000038117.jpg"}, {"question": "which type of wall is being showed", "gt answer": "stone(1.00)<br/>rock(0.60)", "pred answer": "concrete", "question_id": 3505965, "best approach": "wiki", "verif answer": "stone", "anno approach": "wiki, concept, image", "verif wiki answer": "stone(0.6609)", "verif concept answer": "granite(0.6215)", "verif image answer": "granite(0.5340)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000350596.jpg"}, {"question": "what are the fat grams on the green item", "gt answer": "21(1.00)<br/>15(0.60)<br/>very high(0.60)", "pred answer": "500", "question_id": 4461265, "best approach": "", "verif answer": "20", "anno approach": "wiki, concept, image", "verif wiki answer": "18(0.6634)", "verif concept answer": "18(0.5642)", "verif image answer": "18(0.5593)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000446126.jpg"}, {"question": "which part of this man 's face is sporting a look often associated with villains", "gt answer": "chin(1.00)", "pred answer": "beard", "question_id": 1829065, "best approach": "", "verif answer": "screen", "anno approach": "wiki, concept, image", "verif wiki answer": "pony(0.5091)", "verif concept answer": "back(0.6039)", "verif image answer": "pony(0.5813)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000182906.jpg"}, {"question": "which cake would you prefer to eat", "gt answer": "cheesecake(1.00)<br/>cherry(0.60)<br/>chocolate(0.60)<br/>strawberry(0.60)", "pred answer": "cupcake", "question_id": 1811035, "best approach": "wiki", "verif answer": "cherry", "anno approach": "wiki, concept, image", "verif wiki answer": "cherry(0.5618)", "verif concept answer": "icecream(0.5730)", "verif image answer": "icecream(0.7081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000181103.jpg"}, {"question": "what nationality is this food from", "gt answer": "thai(1.00)<br/>japanese(0.60)<br/>italian(0.60)", "pred answer": "india", "question_id": 882825, "best approach": "wiki, concept", "verif answer": "chinese", "anno approach": "wiki, concept, image", "verif wiki answer": "thai(0.6262)", "verif concept answer": "thai(0.6012)", "verif image answer": "japanese(0.6441)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088282.jpg"}, {"question": "what kind of perosn lives here", "gt answer": "single(1.00)<br/>fun(0.60)<br/>female(0.60)", "pred answer": "human", "question_id": 2003055, "best approach": "", "verif answer": "kid", "anno approach": "wiki, concept, image", "verif wiki answer": "kid(0.5652)", "verif concept answer": "mother(0.5592)", "verif image answer": "kid(0.6357)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200305.jpg"}, {"question": "what type of store can you purchase plastic tools like the ones shown in the photo", "gt answer": "grocery store(1.00)<br/>walmart(1.00)", "pred answer": "hardware store", "question_id": 5053095, "best approach": "wiki, concept, image", "verif answer": "grocery store", "anno approach": "wiki, concept, image", "verif wiki answer": "walmart(0.6474)", "verif concept answer": "walmart(0.7119)", "verif image answer": "grocery store(0.6344)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000505309.jpg"}, {"question": "what are these people doing", "gt answer": "sunbath(1.00)<br/>tan(0.60)<br/>relax(0.60)", "pred answer": "surf", "question_id": 487975, "best approach": "", "verif answer": "swim", "anno approach": "wiki, concept, image", "verif wiki answer": "swim(0.6398)", "verif concept answer": "swim(0.6719)", "verif image answer": "swim(0.7286)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048797.jpg"}, {"question": "what is the name of the group who based out of nas pensacola that fly in this formation", "gt answer": "blue angel(1.00)", "pred answer": "air force", "question_id": 2060015, "best approach": "wiki", "verif answer": "airshow", "anno approach": "wiki, concept, image", "verif wiki answer": "blue angel(0.5841)", "verif concept answer": "airshow(0.6568)", "verif image answer": "starbucks(0.7086)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000206001.jpg"}, {"question": "what city is pictured in the backdrop", "gt answer": "seattle(1.00)<br/>new york(0.60)", "pred answer": "san francisco", "question_id": 2509665, "best approach": "image", "verif answer": "seattle", "anno approach": "wiki, concept, image", "verif wiki answer": "new york(0.5277)", "verif concept answer": "new york city(0.5756)", "verif image answer": "seattle(0.7209)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250966.jpg"}, {"question": "what language is the sign in", "gt answer": "french(1.00)<br/>german(0.60)", "pred answer": "arabic", "question_id": 5341175, "best approach": "", "verif answer": "english", "anno approach": "wiki, concept, image", "verif wiki answer": "english(0.5878)", "verif concept answer": "english(0.5312)", "verif image answer": "english(0.5577)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534117.jpg"}, {"question": "what is the largest one of these in the world", "gt answer": "shanghai metro(1.00)<br/>japan(0.60)", "pred answer": "platform", "question_id": 851795, "best approach": "wiki, image", "verif answer": "china", "anno approach": "wiki, concept, image", "verif wiki answer": "shanghai metro(0.6594)", "verif concept answer": "japan(0.6041)", "verif image answer": "shanghai metro(0.6198)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085179.jpg"}, {"question": "what is different about this pizza", "gt answer": "egg(1.00)", "pred answer": "nothing", "question_id": 3561535, "best approach": "", "verif answer": "egg", "anno approach": "wiki, concept, image", "verif wiki answer": "sunny side up(0.5229)", "verif concept answer": "vegetable(0.5404)", "verif image answer": "vegetable(0.5405)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000356153.jpg"}, {"question": "what type of breed is this", "gt answer": "shitzu(1.00)<br/>terrier(0.60)<br/>dog(0.60)<br/>chihuahua(0.60)", "pred answer": "pug", "question_id": 4613335, "best approach": "image", "verif answer": "terrier", "anno approach": "wiki, concept, image", "verif wiki answer": "terrier(0.5559)", "verif concept answer": "terrier(0.6369)", "verif image answer": "shitzu(0.6571)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461333.jpg"}, {"question": "what festival is this", "gt answer": "carnival(1.00)<br/>banana(1.00)", "pred answer": "rally", "question_id": 2851945, "best approach": "wiki", "verif answer": "carnival", "anno approach": "wiki, concept, image", "verif wiki answer": "banana(0.5629)", "verif concept answer": "india(0.5921)", "verif image answer": "plantain(0.6015)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285194.jpg"}, {"question": "what kind of food truck is this", "gt answer": "mexican(1.00)<br/>food(0.60)<br/>taco(0.60)<br/>spanish(0.60)", "pred answer": "hotdog", "question_id": 1845435, "best approach": "wiki, concept", "verif answer": "spanish", "anno approach": "wiki, concept, image", "verif wiki answer": "spanish(0.5912)", "verif concept answer": "spanish(0.6108)", "verif image answer": "hispanic(0.6642)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184543.jpg"}, {"question": "how much memory does this laptop come with", "gt answer": "8gb(1.00)", "pred answer": "lot", "question_id": 748855, "best approach": "", "verif answer": "8 hours", "anno approach": "wiki, concept, image", "verif wiki answer": "6 months(0.6240)", "verif concept answer": "work(0.5848)", "verif image answer": "8 hours(0.5802)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000074885.jpg"}, {"question": "how can she indicate she needs to get off the vehicle", "gt answer": "pull cord(1.00)<br/>wind(0.60)", "pred answer": "sit", "question_id": 1551605, "best approach": "wiki", "verif answer": "clean", "anno approach": "wiki, concept, image", "verif wiki answer": "pull cord(0.6393)", "verif concept answer": "wind(0.5339)", "verif image answer": "wind(0.5207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155160.jpg"}, {"question": "why might we suspect that a collision occurred somewhere around this intersection", "gt answer": "bent sign(1.00)", "pred answer": "sign", "question_id": 4218045, "best approach": "wiki, concept", "verif answer": "traffic light", "anno approach": "wiki, concept, image", "verif wiki answer": "bent sign(0.5235)", "verif concept answer": "bent sign(0.5782)", "verif image answer": "red light(0.5033)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421804.jpg"}, {"question": "how much does the cat weigh", "gt answer": "10 pounds(1.00)<br/>20 pounds(0.60)", "pred answer": "ton", "question_id": 2086405, "best approach": "wiki, concept, image", "verif answer": "100 lbs", "anno approach": "wiki, concept, image", "verif wiki answer": "20 pounds(0.5706)", "verif concept answer": "20 pounds(0.5816)", "verif image answer": "20 pounds(0.5911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208640.jpg"}, {"question": "are the vegetables on the cart annual or perennial", "gt answer": "annual(1.00)", "pred answer": "poor", "question_id": 2925435, "best approach": "", "verif answer": "annual", "anno approach": "wiki, concept, image", "verif wiki answer": "chinese new year(0.5299)", "verif concept answer": "turn(0.5353)", "verif image answer": "turn(0.5095)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292543.jpg"}, {"question": "what is the name of the vertical object behind the pillows", "gt answer": "headboard(1.00)", "pred answer": "gate", "question_id": 5322675, "best approach": "wiki, concept, image", "verif answer": "fence", "anno approach": "wiki, concept, image", "verif wiki answer": "headboard(0.6462)", "verif concept answer": "headboard(0.6178)", "verif image answer": "headboard(0.6496)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000532267.jpg"}, {"question": "what are the different positions of the team that is fielding called", "gt answer": "outfield(1.00)<br/>baseball(0.60)", "pred answer": "batter", "question_id": 3749245, "best approach": "", "verif answer": "batter", "anno approach": "wiki, concept, image", "verif wiki answer": "shortstop(0.6814)", "verif concept answer": "shortstop(0.6183)", "verif image answer": "shortstop(0.7242)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000374924.jpg"}, {"question": "what did this man ride to the top of the mountain", "gt answer": "skilift(1.00)<br/>lift(0.60)<br/>ski lift(0.60)<br/>skiis(0.60)", "pred answer": "snowboard", "question_id": 3260655, "best approach": "", "verif answer": "snowboard", "anno approach": "wiki, concept, image", "verif wiki answer": "snowboard(0.7252)", "verif concept answer": "snowboard(0.7201)", "verif image answer": "snowboard(0.5548)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000326065.jpg"}, {"question": "what is happening behind the umbrella 's", "gt answer": "concert(1.00)<br/>night time(0.60)<br/>light(0.60)<br/>show(0.60)", "pred answer": "fog", "question_id": 5672875, "best approach": "wiki, concept, image", "verif answer": "show", "anno approach": "wiki, concept, image", "verif wiki answer": "night time(0.6369)", "verif concept answer": "show(0.5995)", "verif image answer": "night time(0.6223)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000567287.jpg"}, {"question": "why would we not be surprised to find that the person that works here has ocd", "gt answer": "clean(1.00)", "pred answer": "computer", "question_id": 4211025, "best approach": "", "verif answer": "clean", "anno approach": "wiki, concept, image", "verif wiki answer": "messy(0.5428)", "verif concept answer": "messy(0.5705)", "verif image answer": "messy(0.5753)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421102.jpg"}, {"question": "what type of death could result from carelessness in this environment", "gt answer": "drown(1.00)", "pred answer": "swim", "question_id": 3346305, "best approach": "", "verif answer": "drown", "anno approach": "wiki, concept, image", "verif wiki answer": "death(0.6863)", "verif concept answer": "wipeout(0.5929)", "verif image answer": "wipeout(0.5708)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334630.jpg"}, {"question": "", "gt answer": "black and white(0.60)<br/>1930s(0.60)<br/>1930's(0.60)", "pred answer": "1800s", "question_id": 3945475, "best approach": "wiki, concept, image", "verif answer": "1930's", "anno approach": "wiki, concept, image", "verif wiki answer": "black and white(0.6494)", "verif concept answer": "1930's(0.5970)", "verif image answer": "1930's(0.6090)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000394547.jpg"}, {"question": "what part of the computer is on top of the desk", "gt answer": "monitor(1.00)<br/>screen(0.60)", "pred answer": "keyboard", "question_id": 4582865, "best approach": "", "verif answer": "monitor", "anno approach": "wiki, concept, image", "verif wiki answer": "front(0.5845)", "verif concept answer": "front(0.5673)", "verif image answer": "front(0.6110)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458286.jpg"}, {"question": "why are these animals here", "gt answer": "eat(1.00)<br/>graze(0.60)", "pred answer": "fish", "question_id": 4703435, "best approach": "wiki", "verif answer": "herd", "anno approach": "wiki, concept, image", "verif wiki answer": "graze(0.6803)", "verif concept answer": "compete(0.5766)", "verif image answer": "herd(0.6990)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000470343.jpg"}, {"question": "why might we suspect that this venue is located somewhere tropical", "gt answer": "tree(1.00)<br/>umbrella(0.60)", "pred answer": "shade", "question_id": 5389385, "best approach": "", "verif answer": "palm", "anno approach": "wiki, concept, image", "verif wiki answer": "elephant(0.7122)", "verif concept answer": "palm(0.6177)", "verif image answer": "palm(0.6798)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000538938.jpg"}, {"question": "can you name the sea where these people are seen", "gt answer": "baltic(1.00)<br/>mediterranean(0.60)<br/>pacific ocean(0.60)", "pred answer": "pacific", "question_id": 4857555, "best approach": "wiki, concept", "verif answer": "atlantic", "anno approach": "wiki, concept, image", "verif wiki answer": "baltic(0.7082)", "verif concept answer": "baltic(0.6974)", "verif image answer": "mediterranean(0.7078)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000485755.jpg"}, {"question": "why does he have a knife", "gt answer": "butcher(1.00)<br/>protection(0.60)", "pred answer": "tie", "question_id": 769705, "best approach": "image", "verif answer": "cut", "anno approach": "wiki, concept, image", "verif wiki answer": "cut(0.6903)", "verif concept answer": "cut(0.5469)", "verif image answer": "butcher(0.5474)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076970.jpg"}, {"question": "where is this person cross country skiing", "gt answer": "wood(1.00)<br/>forest(0.60)<br/>outside(0.60)", "pred answer": "mountain", "question_id": 2875725, "best approach": "image", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "garden(0.6707)", "verif concept answer": "outside(0.6533)", "verif image answer": "wood(0.6335)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287572.jpg"}, {"question": "what kind of truck is this", "gt answer": "ambulance(1.00)", "pred answer": "semi", "question_id": 4508935, "best approach": "concept", "verif answer": "suv", "anno approach": "wiki, concept, image", "verif wiki answer": "car show(0.6802)", "verif concept answer": "ambulance(0.6413)", "verif image answer": "suv(0.6940)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000450893.jpg"}, {"question": "what type of furniture piece is in the corner", "gt answer": "couch(1.00)<br/>loveseat(0.60)", "pred answer": "bed", "question_id": 1896565, "best approach": "wiki", "verif answer": "couch", "anno approach": "wiki, concept, image", "verif wiki answer": "couch(0.7244)", "verif concept answer": "sofa(0.5686)", "verif image answer": "sofa(0.6360)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000189656.jpg"}, {"question": "what building might this picture have been taken in", "gt answer": "hospital(1.00)", "pred answer": "room", "question_id": 3872565, "best approach": "wiki, concept, image", "verif answer": "office", "anno approach": "wiki, concept, image", "verif wiki answer": "hospital(0.7284)", "verif concept answer": "hospital(0.7136)", "verif image answer": "hospital(0.6427)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000387256.jpg"}, {"question": "how much is the value of the food", "gt answer": "5 dollars(1.00)", "pred answer": "$50", "question_id": 2093565, "best approach": "wiki, concept", "verif answer": "5 dollars", "anno approach": "wiki, concept, image", "verif wiki answer": "5 dollars(0.6357)", "verif concept answer": "5 dollars(0.6443)", "verif image answer": "50(0.6862)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000209356.jpg"}, {"question": "statistically is the interior design of this room more resemble a horror movie or an historical film", "gt answer": "historical(1.00)", "pred answer": "forrest gump", "question_id": 4005365, "best approach": "image", "verif answer": "jaw", "anno approach": "wiki, concept, image", "verif wiki answer": "bug bunny(0.5803)", "verif concept answer": "bug bunny(0.6432)", "verif image answer": "historical(0.7291)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400536.jpg"}, {"question": "what happened just before this picture was taken", "gt answer": "takeoff(1.00)<br/>take off(0.60)", "pred answer": "land", "question_id": 3606435, "best approach": "", "verif answer": "land", "anno approach": "wiki, concept, image", "verif wiki answer": "taxi(0.6049)", "verif concept answer": "taxi(0.5768)", "verif image answer": "land(0.7159)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000360643.jpg"}, {"question": "wich kind of trees are shown in this photo", "gt answer": "redwood(1.00)<br/>oak(0.60)", "pred answer": "pine", "question_id": 480475, "best approach": "concept", "verif answer": "pine", "anno approach": "wiki, concept, image", "verif wiki answer": "oak(0.6421)", "verif concept answer": "redwood(0.6520)", "verif image answer": "oak(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000048047.jpg"}, {"question": "what is the most common name listed on one of these", "gt answer": "regent(1.00)<br/>street(0.60)", "pred answer": "1 way", "question_id": 3971875, "best approach": "concept", "verif answer": "street", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.5398)", "verif concept answer": "regent(0.5664)", "verif image answer": "street(0.5583)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000397187.jpg"}, {"question": "what person was this toy named after", "gt answer": "teddy roosevelt(1.00)<br/>theodore roosevelt(0.60)", "pred answer": "ted", "question_id": 2612025, "best approach": "wiki, image", "verif answer": "teddy roosevelt", "anno approach": "wiki, concept, image", "verif wiki answer": "teddy roosevelt(0.6454)", "verif concept answer": "theodore roosevelt(0.6152)", "verif image answer": "teddy roosevelt(0.5385)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261202.jpg"}, {"question": "what kind of mirror is that", "gt answer": "rearview(1.00)<br/>safety(0.60)<br/>round(0.60)", "pred answer": "digital", "question_id": 404495, "best approach": "wiki", "verif answer": "safety", "anno approach": "wiki, concept, image", "verif wiki answer": "rearview(0.6434)", "verif concept answer": "propeller(0.5728)", "verif image answer": "round(0.5597)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040449.jpg"}, {"question": "what is a slang name for this type of motorcycle", "gt answer": "crotch rocket(1.00)", "pred answer": "harley", "question_id": 1260755, "best approach": "", "verif answer": "harley", "anno approach": "wiki, concept, image", "verif wiki answer": "kawasaki(0.5892)", "verif concept answer": "kawasaki(0.6018)", "verif image answer": "race(0.6195)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000126075.jpg"}, {"question": "what was the first system of this kind called", "gt answer": "atari(1.00)<br/>nintendo(1.00)<br/>television(0.60)", "pred answer": "video game", "question_id": 1619295, "best approach": "concept, image", "verif answer": "wii", "anno approach": "wiki, concept, image", "verif wiki answer": "television(0.7129)", "verif concept answer": "atari(0.6355)", "verif image answer": "nintendo(0.6821)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161929.jpg"}, {"question": "how many pounds of food does this animal consume per day", "gt answer": "75(1.00)<br/>40(0.60)<br/>250(0.60)", "pred answer": "500", "question_id": 1353675, "best approach": "image", "verif answer": "75", "anno approach": "wiki, concept, image", "verif wiki answer": "hundred(0.5972)", "verif concept answer": "hundred(0.6080)", "verif image answer": "40(0.6312)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000135367.jpg"}, {"question": "what is the purpose of this vehicle", "gt answer": "transportation(1.00)<br/>transport good(0.60)<br/>transport(0.60)", "pred answer": "transport people", "question_id": 2555765, "best approach": "wiki, image", "verif answer": "transport", "anno approach": "wiki, concept, image", "verif wiki answer": "transport(0.6864)", "verif concept answer": "ride rail(0.6981)", "verif image answer": "transport good(0.6097)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000255576.jpg"}, {"question": "what types of house is in the photo", "gt answer": "spanish style(1.00)<br/>ranch(0.60)", "pred answer": "apart", "question_id": 3780125, "best approach": "concept, image", "verif answer": "stable", "anno approach": "wiki, concept, image", "verif wiki answer": "stable(0.5835)", "verif concept answer": "ranch(0.6142)", "verif image answer": "ranch(0.5722)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000378012.jpg"}, {"question": "what nutrients are found in this type of fern", "gt answer": "aloe(1.00)<br/>potassium(0.60)<br/>vitamin(0.60)<br/>water(0.60)", "pred answer": "vitamin c", "question_id": 123575, "best approach": "wiki", "verif answer": "calcium", "anno approach": "wiki, concept, image", "verif wiki answer": "vitamin(0.5789)", "verif concept answer": "calcium(0.5857)", "verif image answer": "calcium(0.6426)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000012357.jpg"}, {"question": "why would we suspect these animals haven't eaten well in a while", "gt answer": "they are skinny(1.00)", "pred answer": "herd", "question_id": 1677555, "best approach": "image", "verif answer": "eat", "anno approach": "wiki, concept, image", "verif wiki answer": "clean(0.5437)", "verif concept answer": "herbivore(0.5392)", "verif image answer": "they are skinny(0.5134)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167755.jpg"}, {"question": "what material is used to write on the board on the wall", "gt answer": "chalk(1.00)", "pred answer": "plastic", "question_id": 1323105, "best approach": "concept", "verif answer": "plastic", "anno approach": "wiki, concept, image", "verif wiki answer": "marker(0.7263)", "verif concept answer": "chalk(0.6803)", "verif image answer": "marker(0.5796)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000132310.jpg"}, {"question": "which brand of cool drinks is shown in this photo", "gt answer": "heineken(1.00)", "pred answer": "coca cola", "question_id": 1125845, "best approach": "", "verif answer": "coca cola", "anno approach": "wiki, concept, image", "verif wiki answer": "coca cola(0.6922)", "verif concept answer": "coca cola(0.6833)", "verif image answer": "ruffle(0.7253)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000112584.jpg"}, {"question": "how can you tell if these zebras are male or female", "gt answer": "genital(1.00)", "pred answer": "female", "question_id": 3463105, "best approach": "image", "verif answer": "wild", "anno approach": "wiki, concept, image", "verif wiki answer": "wild(0.6793)", "verif concept answer": "wild(0.7088)", "verif image answer": "genital(0.7061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000346310.jpg"}, {"question": "what is the the second tallest mountain in the united states", "gt answer": "mount saint elias(1.00)<br/>mt everest(0.60)<br/>mount everest(0.60)", "pred answer": "alp", "question_id": 463205, "best approach": "wiki, image", "verif answer": "mt everest", "anno approach": "wiki, concept, image", "verif wiki answer": "mount saint elias(0.6651)", "verif concept answer": "mt everest(0.6158)", "verif image answer": "mount saint elias(0.6186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000046320.jpg"}, {"question": "name the remote model shown in this picture", "gt answer": "samsung(1.00)<br/>toshiba(0.60)", "pred answer": "sony", "question_id": 1256835, "best approach": "wiki, concept", "verif answer": "sony", "anno approach": "wiki, concept, image", "verif wiki answer": "samsung(0.6374)", "verif concept answer": "samsung(0.6155)", "verif image answer": "sony(0.7077)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000125683.jpg"}, {"question": "how much horsepower does this motorcycle make", "gt answer": "150(1.00)<br/>75(0.60)", "pred answer": "2", "question_id": 4430055, "best approach": "concept, image", "verif answer": "20", "anno approach": "wiki, concept, image", "verif wiki answer": "300 mph(0.6748)", "verif concept answer": "150(0.6355)", "verif image answer": "150(0.6590)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000443005.jpg"}, {"question": "is the beige phone a land line or a wireless phone", "gt answer": "land line(1.00)<br/>landline(1.00)", "pred answer": "phone", "question_id": 4929655, "best approach": "image", "verif answer": "lcd", "anno approach": "wiki, concept, image", "verif wiki answer": "lcd(0.5528)", "verif concept answer": "scissor(0.6101)", "verif image answer": "land line(0.7123)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000492965.jpg"}, {"question": "what year was the first patent for the machine depicted in the photo", "gt answer": "1804(1.00)<br/>1920(0.60)<br/>1900(0.60)", "pred answer": "1930", "question_id": 4367595, "best approach": "image", "verif answer": "1804", "anno approach": "wiki, concept, image", "verif wiki answer": "1823(0.6633)", "verif concept answer": "1823(0.6454)", "verif image answer": "1804(0.7029)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436759.jpg"}, {"question": "who invented this type of vehicle", "gt answer": "gottlieb daimler(1.00)<br/>bob(0.60)<br/>man(0.60)", "pred answer": "dean kamen", "question_id": 2920875, "best approach": "concept", "verif answer": "man", "anno approach": "wiki, concept, image", "verif wiki answer": "walter wingfield(0.6625)", "verif concept answer": "gottlieb daimler(0.6087)", "verif image answer": "mechanic(0.5619)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000292087.jpg"}, {"question": "how much does this keyboard cost", "gt answer": "$100(1.00)<br/>$40(0.60)", "pred answer": "5000", "question_id": 3612555, "best approach": "wiki, concept, image", "verif answer": "$1200", "anno approach": "wiki, concept, image", "verif wiki answer": "$100(0.6570)", "verif concept answer": "$100(0.6678)", "verif image answer": "$100(0.7200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000361255.jpg"}, {"question": "how are effective are ear thermometers compared to other types", "gt answer": "less effective(1.00)<br/>very(0.60)", "pred answer": "easy", "question_id": 5439865, "best approach": "concept, image", "verif answer": "very", "anno approach": "wiki, concept, image", "verif wiki answer": "amateur(0.5975)", "verif concept answer": "less effective(0.5505)", "verif image answer": "less effective(0.5634)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000543986.jpg"}, {"question": "what kind of flowers are in the vase to the left of this photo", "gt answer": "rose(1.00)<br/>daisy(0.60)", "pred answer": "hydrangea", "question_id": 2874885, "best approach": "", "verif answer": "hydrangea", "anno approach": "wiki, concept, image", "verif wiki answer": "tulip(0.6776)", "verif concept answer": "hydrangea(0.6886)", "verif image answer": "hydrangea(0.7145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287488.jpg"}, {"question": "what other kind of house pet likes sleeping in the sun", "gt answer": "cat(1.00)<br/>dog(1.00)", "pred answer": "tiger", "question_id": 2533885, "best approach": "wiki", "verif answer": "cat", "anno approach": "wiki, concept, image", "verif wiki answer": "cat(0.7264)", "verif concept answer": "bear(0.6334)", "verif image answer": "chihuahua(0.7081)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253388.jpg"}, {"question": "this type of car was popular in which decade", "gt answer": "1980's(1.00)<br/>1990(0.60)", "pred answer": "1960", "question_id": 4724525, "best approach": "image", "verif answer": "70s", "anno approach": "wiki, concept, image", "verif wiki answer": "1998(0.6250)", "verif concept answer": "2000(0.6147)", "verif image answer": "1990(0.6020)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000472452.jpg"}, {"question": "what kind of food does this shop sell", "gt answer": "pastry(1.00)<br/>sweet(1.00)", "pred answer": "dessert", "question_id": 1340395, "best approach": "wiki", "verif answer": "doughnut", "anno approach": "wiki, concept, image", "verif wiki answer": "sweet(0.7026)", "verif concept answer": "vanilla(0.6440)", "verif image answer": "doughnut(0.6945)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000134039.jpg"}, {"question": "are the flying objects natural or manmade", "gt answer": "manmade(1.00)", "pred answer": "man made", "question_id": 2756085, "best approach": "wiki, concept", "verif answer": "man made", "anno approach": "wiki, concept, image", "verif wiki answer": "manmade(0.6454)", "verif concept answer": "manmade(0.6931)", "verif image answer": "man made(0.6466)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000275608.jpg"}, {"question": "when did this hobby start", "gt answer": "1800s(1.00)<br/>winter(0.60)<br/>1924(0.60)", "pred answer": "snowboard", "question_id": 5586785, "best approach": "wiki, image", "verif answer": "1924", "anno approach": "wiki, concept, image", "verif wiki answer": "1924(0.5991)", "verif concept answer": "1800(0.5887)", "verif image answer": "1924(0.7076)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000558678.jpg"}, {"question": "what is the difference between the three vehicles", "gt answer": "color(1.00)<br/>brand(0.60)", "pred answer": "common", "question_id": 1658525, "best approach": "wiki", "verif answer": "color", "anno approach": "wiki, concept, image", "verif wiki answer": "color(0.5324)", "verif concept answer": "conair(0.6157)", "verif image answer": "conair(0.7114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000165852.jpg"}, {"question": "what time of the day is it", "gt answer": "even(1.00)<br/>night(0.60)<br/>dusk(0.60)", "pred answer": "sunset", "question_id": 982325, "best approach": "image", "verif answer": "even", "anno approach": "wiki, concept, image", "verif wiki answer": "dusk(0.6547)", "verif concept answer": "sunset(0.6132)", "verif image answer": "even(0.6519)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000098232.jpg"}, {"question": "what is the helmet covering", "gt answer": "head(1.00)", "pred answer": "motorcycle", "question_id": 4137465, "best approach": "wiki, concept, image", "verif answer": "helmet", "anno approach": "wiki, concept, image", "verif wiki answer": "head(0.6853)", "verif concept answer": "head(0.5503)", "verif image answer": "head(0.5464)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000413746.jpg"}, {"question": "where was this photo taken", "gt answer": "forest(1.00)<br/>wild(0.60)", "pred answer": "wood", "question_id": 5747205, "best approach": "wiki, concept, image", "verif answer": "forest", "anno approach": "wiki, concept, image", "verif wiki answer": "forest(0.6651)", "verif concept answer": "forest(0.6357)", "verif image answer": "forest(0.6773)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000574720.jpg"}, {"question": "what does this donut cost", "gt answer": "dollar(1.00)<br/>2 dollars(0.60)", "pred answer": "1 dollar", "question_id": 1456825, "best approach": "wiki", "verif answer": "5000", "anno approach": "wiki, concept, image", "verif wiki answer": "2 dollars(0.5854)", "verif concept answer": "5000(0.6598)", "verif image answer": "200(0.6637)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000145682.jpg"}, {"question": "what is the oldest examples of the objects attached to her feet that have been discovered", "gt answer": "snowshoe(1.00)<br/>1900(0.60)<br/>200 years(0.60)", "pred answer": "ski", "question_id": 2124385, "best approach": "wiki", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "snowshoe(0.5319)", "verif concept answer": "200 years(0.6809)", "verif image answer": "200 years(0.6494)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000212438.jpg"}, {"question": "what park is this", "gt answer": "dog park(1.00)", "pred answer": "frisbee", "question_id": 4591115, "best approach": "wiki, concept, image", "verif answer": "central park", "anno approach": "wiki, concept, image", "verif wiki answer": "dog park(0.7084)", "verif concept answer": "dog park(0.6750)", "verif image answer": "dog park(0.6304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000459111.jpg"}, {"question": "what is the relationship between the two people", "gt answer": "married(1.00)<br/>mother and son(0.60)", "pred answer": "friend", "question_id": 77335, "best approach": "concept", "verif answer": "married", "anno approach": "wiki, concept, image", "verif wiki answer": "rodent(0.7251)", "verif concept answer": "married(0.6953)", "verif image answer": "marriage(0.5214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000007733.jpg"}, {"question": "what are the men doing", "gt answer": "board ship(1.00)<br/>dock(0.60)<br/>raft(0.60)", "pred answer": "ride", "question_id": 3021665, "best approach": "wiki, concept, image", "verif answer": "boat", "anno approach": "wiki, concept, image", "verif wiki answer": "raft(0.6041)", "verif concept answer": "raft(0.6033)", "verif image answer": "raft(0.6826)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302166.jpg"}, {"question": "what will he get if he falls in the ocean", "gt answer": "wet(1.00)<br/>water(0.60)", "pred answer": "wave", "question_id": 1061075, "best approach": "wiki, concept", "verif answer": "water", "anno approach": "wiki, concept, image", "verif wiki answer": "wet(0.7175)", "verif concept answer": "wet(0.6625)", "verif image answer": "water(0.6330)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106107.jpg"}, {"question": "what gear is needed for this activity", "gt answer": "skiis(1.00)<br/>helmet(0.60)", "pred answer": "ski", "question_id": 5038445, "best approach": "wiki", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "helmet(0.6865)", "verif concept answer": "ski(0.6015)", "verif image answer": "ski(0.5946)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000503844.jpg"}, {"question": "what kind of pasta is this", "gt answer": "rigatoni(1.00)", "pred answer": "lo mein", "question_id": 1409845, "best approach": "image", "verif answer": "lo mein", "anno approach": "wiki, concept, image", "verif wiki answer": "shell(0.5725)", "verif concept answer": "lo mein(0.5773)", "verif image answer": "rigatoni(0.6716)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140984.jpg"}, {"question": "what cultural icon is referenced by the red suits", "gt answer": "santa(1.00)", "pred answer": "van gogh", "question_id": 5021345, "best approach": "wiki", "verif answer": "santa", "anno approach": "wiki, concept, image", "verif wiki answer": "santa(0.7082)", "verif concept answer": "wed(0.5631)", "verif image answer": "santa hat(0.5107)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502134.jpg"}, {"question": "what type of structure would this type of room most likely occur in", "gt answer": "house(1.00)<br/>dinner(0.60)<br/>home(0.60)", "pred answer": "kitchen", "question_id": 1222165, "best approach": "concept, image", "verif answer": "house", "anno approach": "wiki, concept, image", "verif wiki answer": "hotel(0.5827)", "verif concept answer": "house(0.6424)", "verif image answer": "house(0.5979)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000122216.jpg"}, {"question": "is the animal on the bench a predator or prey", "gt answer": "predator(1.00)", "pred answer": "human", "question_id": 1754215, "best approach": "image", "verif answer": "herbivore", "anno approach": "wiki, concept, image", "verif wiki answer": "wild(0.5683)", "verif concept answer": "wild(0.6028)", "verif image answer": "predator(0.5229)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000175421.jpg"}, {"question": "what type of item is singer most known for producing", "gt answer": "sew machine(1.00)<br/>speaker(0.60)", "pred answer": "book", "question_id": 3931935, "best approach": "concept", "verif answer": "radio", "anno approach": "wiki, concept, image", "verif wiki answer": "scissor(0.5739)", "verif concept answer": "sew machine(0.5891)", "verif image answer": "sew(0.5806)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000393193.jpg"}, {"question": "why would they all be wearing the same outfit", "gt answer": "team(1.00)<br/>uniform(0.60)<br/>sport(0.60)", "pred answer": "football", "question_id": 1613335, "best approach": "concept, image", "verif answer": "sport", "anno approach": "wiki, concept, image", "verif wiki answer": "sport(0.7129)", "verif concept answer": "team(0.5933)", "verif image answer": "team(0.6112)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161333.jpg"}, {"question": "how old is the batter in the box", "gt answer": "15(1.00)<br/>14(0.60)<br/>26(0.60)", "pred answer": "16", "question_id": 814815, "best approach": "", "verif answer": "30", "anno approach": "wiki, concept, image", "verif wiki answer": "20(0.6061)", "verif concept answer": "20(0.5997)", "verif image answer": "30(0.6099)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000081481.jpg"}, {"question": "did the bus stop at rest stop or a tourist attraction", "gt answer": "tourist attraction(1.00)<br/>bus(0.60)", "pred answer": "mountain", "question_id": 3811545, "best approach": "image", "verif answer": "friendly", "anno approach": "wiki, concept, image", "verif wiki answer": "friendly(0.5801)", "verif concept answer": "friendly(0.5656)", "verif image answer": "tourist attraction(0.5401)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000381154.jpg"}, {"question": "how do we know this is a professional game", "gt answer": "sponsor(1.00)<br/>stadium(0.60)", "pred answer": "run", "question_id": 1925135, "best approach": "", "verif answer": "advertising", "anno approach": "wiki, concept, image", "verif wiki answer": "advertising(0.5117)", "verif concept answer": "advertiser(0.5144)", "verif image answer": "advertiser(0.5641)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000192513.jpg"}, {"question": "where can i find a doughnut like this", "gt answer": "dunkin donuts(1.00)<br/>krispy kreme(0.60)<br/>bakery(0.60)", "pred answer": "restaurant", "question_id": 1577075, "best approach": "concept, image", "verif answer": "bakery", "anno approach": "wiki, concept, image", "verif wiki answer": "dunkin(0.5792)", "verif concept answer": "bakery(0.6369)", "verif image answer": "krispy kreme(0.6169)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000157707.jpg"}, {"question": "what utensil is seen in the photo", "gt answer": "tong(1.00)", "pred answer": "fork", "question_id": 3191175, "best approach": "", "verif answer": "fork", "anno approach": "wiki, concept, image", "verif wiki answer": "fork(0.6052)", "verif concept answer": "fork(0.6355)", "verif image answer": "cook(0.7267)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319117.jpg"}, {"question": "what is that device used for", "gt answer": "compute(1.00)<br/>internet(1.00)", "pred answer": "type", "question_id": 4969775, "best approach": "wiki, concept, image", "verif answer": "internet", "anno approach": "wiki, concept, image", "verif wiki answer": "internet(0.6691)", "verif concept answer": "internet(0.6031)", "verif image answer": "internet(0.6851)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000496977.jpg"}, {"question": "what time is it in this photo", "gt answer": "3:40(1.00)", "pred answer": "night", "question_id": 521515, "best approach": "concept", "verif answer": "6:50", "anno approach": "wiki, concept, image", "verif wiki answer": "6:50(0.6973)", "verif concept answer": "3:40(0.6973)", "verif image answer": "6:50(0.7262)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000052151.jpg"}, {"question": "what are these people waiting for", "gt answer": "pitch(1.00)<br/>ball(0.60)", "pred answer": "bat", "question_id": 2520925, "best approach": "concept", "verif answer": "ball", "anno approach": "wiki, concept, image", "verif wiki answer": "swing(0.5691)", "verif concept answer": "ball(0.5920)", "verif image answer": "swing(0.6589)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000252092.jpg"}, {"question": "what kind of watch is this", "gt answer": "pocket watch(1.00)<br/>rolex(0.60)", "pred answer": "analog", "question_id": 2512495, "best approach": "concept", "verif answer": "old", "anno approach": "wiki, concept, image", "verif wiki answer": "flat screen(0.6530)", "verif concept answer": "rolex(0.6147)", "verif image answer": "flat screen(0.5717)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000251249.jpg"}, {"question": "what pair of brothers pioneered the vehicle in the picture", "gt answer": "wright(1.00)<br/>wright brother(0.60)", "pred answer": "engine", "question_id": 5278655, "best approach": "", "verif answer": "engine", "anno approach": "wiki, concept, image", "verif wiki answer": "boeing(0.5773)", "verif concept answer": "engine(0.6141)", "verif image answer": "engine(0.6997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000527865.jpg"}, {"question": "how old is the dog", "gt answer": "puppy(1.00)<br/>2 months(0.60)<br/>3(0.60)<br/>baby(0.60)", "pred answer": "6 months", "question_id": 882415, "best approach": "wiki", "verif answer": "3", "anno approach": "wiki, concept, image", "verif wiki answer": "puppy(0.6149)", "verif concept answer": "2 months(0.6305)", "verif image answer": "4(0.6831)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000088241.jpg"}, {"question": "what is the thickness of the strings attached to this kite", "gt answer": "1 mm(1.00)<br/>thin(1.00)", "pred answer": "20 feet", "question_id": 4881495, "best approach": "concept, image", "verif answer": "3 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "1 inch(0.5911)", "verif concept answer": "thin(0.5559)", "verif image answer": "thin(0.6463)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488149.jpg"}, {"question": "the boy has moved his skis to what kind of position", "gt answer": "snowplow(1.00)<br/>down(0.60)<br/>rest(0.60)", "pred answer": "left", "question_id": 154965, "best approach": "", "verif answer": "left", "anno approach": "wiki, concept, image", "verif wiki answer": "left(0.6893)", "verif concept answer": "left(0.6515)", "verif image answer": "left(0.6912)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015496.jpg"}, {"question": "name the type of material used to make this mask shown in this picture", "gt answer": "paper(1.00)<br/>cloth(1.00)<br/>cotton(0.60)", "pred answer": "glass", "question_id": 4425315, "best approach": "wiki, concept", "verif answer": "cotton", "anno approach": "wiki, concept, image", "verif wiki answer": "paper(0.5420)", "verif concept answer": "paper(0.6705)", "verif image answer": "cotton(0.5364)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442531.jpg"}, {"question": "how does this object move", "gt answer": "fly(1.00)", "pred answer": "engine", "question_id": 605765, "best approach": "", "verif answer": "fly", "anno approach": "wiki, concept, image", "verif wiki answer": "land(0.6308)", "verif concept answer": "take off(0.6315)", "verif image answer": "wing(0.6073)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000060576.jpg"}, {"question": "what is the being hugged in this picture", "gt answer": "baby(1.00)<br/>teddy bear(0.60)<br/>animal(0.60)<br/>dog(0.60)", "pred answer": "stuffed animal", "question_id": 5802745, "best approach": "concept", "verif answer": "animal", "anno approach": "wiki, concept, image", "verif wiki answer": "animal(0.6876)", "verif concept answer": "baby(0.6050)", "verif image answer": "teddy bear(0.6945)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580274.jpg"}, {"question": "what type of penguins are they", "gt answer": "emperor(1.00)<br/>king(0.60)", "pred answer": "black", "question_id": 2380055, "best approach": "image", "verif answer": "black", "anno approach": "wiki, concept, image", "verif wiki answer": "black(0.5725)", "verif concept answer": "black(0.5894)", "verif image answer": "king(0.6061)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000238005.jpg"}, {"question": "what happens when the lights turn 'red'", "gt answer": "stop(1.00)<br/>go(0.60)", "pred answer": "break", "question_id": 4051815, "best approach": "concept", "verif answer": "stop", "anno approach": "wiki, concept, image", "verif wiki answer": "brake(0.6553)", "verif concept answer": "stop(0.5984)", "verif image answer": "brake(0.6711)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000405181.jpg"}, {"question": "why is the lady carrying an umbrella if it isn't raining", "gt answer": "sun protection(1.00)<br/>shade(0.60)<br/>sunscreen(0.60)", "pred answer": "rain", "question_id": 562615, "best approach": "", "verif answer": "sun", "anno approach": "wiki, concept, image", "verif wiki answer": "sun(0.6535)", "verif concept answer": "for sun(0.6108)", "verif image answer": "for sun(0.6207)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000056261.jpg"}, {"question": "how would someone learn to do this activity", "gt answer": "practice(1.00)<br/>carefully(0.60)", "pred answer": "jump", "question_id": 2697885, "best approach": "", "verif answer": "fun", "anno approach": "wiki, concept, image", "verif wiki answer": "fast(0.6847)", "verif concept answer": "fun(0.6625)", "verif image answer": "fun(0.5800)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269788.jpg"}, {"question": "name the family of this animal shown in this picture", "gt answer": "goat(1.00)<br/>lamp(0.60)<br/>sheep(0.60)", "pred answer": "cow", "question_id": 3289175, "best approach": "wiki, concept, image", "verif answer": "goat", "anno approach": "wiki, concept, image", "verif wiki answer": "lamp(0.5827)", "verif concept answer": "lamp(0.5913)", "verif image answer": "lamp(0.5174)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000328917.jpg"}, {"question": "what city would this intersection be found in", "gt answer": "berlin(1.00)<br/>london(0.60)<br/>paris(0.60)", "pred answer": "new york city", "question_id": 5429915, "best approach": "image", "verif answer": "berlin", "anno approach": "wiki, concept, image", "verif wiki answer": "paris(0.5705)", "verif concept answer": "amsterdam(0.5533)", "verif image answer": "berlin(0.6910)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000542991.jpg"}, {"question": "what style is that purple dress", "gt answer": "skirt(1.00)<br/>maxi(1.00)", "pred answer": "retro", "question_id": 2012525, "best approach": "", "verif answer": "kilt", "anno approach": "wiki, concept, image", "verif wiki answer": "kilt(0.7132)", "verif concept answer": "kilt(0.7142)", "verif image answer": "kilt(0.7278)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201252.jpg"}, {"question": "where are these tourists from", "gt answer": "usa(1.00)<br/>america(1.00)<br/>united state(0.60)", "pred answer": "asia", "question_id": 273345, "best approach": "wiki, concept", "verif answer": "north america", "anno approach": "wiki, concept, image", "verif wiki answer": "united state(0.5561)", "verif concept answer": "united state(0.6138)", "verif image answer": "california(0.7206)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027334.jpg"}, {"question": "where might you find a train like this one", "gt answer": "midwest(1.00)<br/>station(0.60)<br/>usa(0.60)", "pred answer": "city", "question_id": 5342595, "best approach": "image", "verif answer": "usa", "anno approach": "wiki, concept, image", "verif wiki answer": "usa(0.6048)", "verif concept answer": "usa(0.6315)", "verif image answer": "midwest(0.6822)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534259.jpg"}, {"question": "what kind of park is this photo from", "gt answer": "skate(1.00)", "pred answer": "skate park", "question_id": 2328625, "best approach": "", "verif answer": "skate park", "anno approach": "wiki, concept, image", "verif wiki answer": "water ski(0.6269)", "verif concept answer": "skate park(0.5963)", "verif image answer": "skate park(0.7230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000232862.jpg"}, {"question": "", "gt answer": "help ship(0.60)<br/>watch(0.60)", "pred answer": "pray", "question_id": 1627705, "best approach": "wiki, concept", "verif answer": "tell time", "anno approach": "wiki, concept, image", "verif wiki answer": "help ship(0.5269)", "verif concept answer": "help ship(0.5066)", "verif image answer": "to tell time(0.5188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000162770.jpg"}, {"question": "the safety device shown in the man 's hand goes on what part of the body", "gt answer": "head(1.00)<br/>helmet(0.60)", "pred answer": "foot", "question_id": 5090985, "best approach": "wiki", "verif answer": "head", "anno approach": "wiki, concept, image", "verif wiki answer": "head(0.6247)", "verif concept answer": "hat(0.6114)", "verif image answer": "hat(0.5467)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000509098.jpg"}, {"question": "how long would these type of flowers typically last in a vase with water", "gt answer": "3 days(1.00)<br/>4 days(0.60)<br/>5 days(0.60)", "pred answer": "2 days", "question_id": 3639565, "best approach": "concept", "verif answer": "week", "anno approach": "wiki, concept, image", "verif wiki answer": "5 days(0.6680)", "verif concept answer": "3 days(0.6018)", "verif image answer": "2 weeks(0.6750)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000363956.jpg"}, {"question": "what type of machine is this tool", "gt answer": "solder gun(1.00)", "pred answer": "computer", "question_id": 829475, "best approach": "", "verif answer": "computer", "anno approach": "wiki, concept, image", "verif wiki answer": "mirror(0.6302)", "verif concept answer": "camera(0.6802)", "verif image answer": "bicycle(0.5334)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000082947.jpg"}, {"question": "what is she wearing", "gt answer": "head scarf(1.00)<br/>bonnet(0.60)", "pred answer": "hat", "question_id": 2619315, "best approach": "wiki, image", "verif answer": "tie", "anno approach": "wiki, concept, image", "verif wiki answer": "head scarf(0.6544)", "verif concept answer": "tie(0.6484)", "verif image answer": "head scarf(0.5893)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000261931.jpg"}, {"question": "what type of fireplace is in the image", "gt answer": "brick(1.00)<br/>log(0.60)<br/>gas(0.60)", "pred answer": "convection", "question_id": 1915515, "best approach": "concept", "verif answer": "log", "anno approach": "wiki, concept, image", "verif wiki answer": "gas(0.5765)", "verif concept answer": "brick(0.5799)", "verif image answer": "log(0.6846)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000191551.jpg"}, {"question": "which cosmetic is most often associated with this color and flower", "gt answer": "lipstick(1.00)", "pred answer": "sun", "question_id": 2878415, "best approach": "", "verif answer": "", "anno approach": "wiki, concept, image", "verif wiki answer": "coca cola(0.6679)", "verif concept answer": "coca cola(0.6321)", "verif image answer": "(0.6456)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000287841.jpg"}, {"question": "does the player steal 2nd or stay", "gt answer": "steal(1.00)", "pred answer": "safe", "question_id": 1405755, "best approach": "wiki, concept", "verif answer": "strike", "anno approach": "wiki, concept, image", "verif wiki answer": "steal(0.6489)", "verif concept answer": "steal(0.5854)", "verif image answer": "slide(0.6641)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000140575.jpg"}, {"question": "what kind of seat", "gt answer": "bench(1.00)", "pred answer": "sit", "question_id": 271055, "best approach": "wiki, image", "verif answer": "bench", "anno approach": "wiki, concept, image", "verif wiki answer": "bench(0.7176)", "verif concept answer": "chair(0.5927)", "verif image answer": "bench(0.6310)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027105.jpg"}, {"question": "what culture is this dish from", "gt answer": "mexican(1.00)<br/>spain(0.60)<br/>south america(0.60)<br/>hispanic(0.60)", "pred answer": "india", "question_id": 2267515, "best approach": "concept, image", "verif answer": "mexican", "anno approach": "wiki, concept, image", "verif wiki answer": "indian(0.6249)", "verif concept answer": "south america(0.6129)", "verif image answer": "south america(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000226751.jpg"}, {"question": "is the animal pictured likely to be friendly or agressive", "gt answer": "friendly(1.00)", "pred answer": "playful", "question_id": 4761045, "best approach": "", "verif answer": "unsafe", "anno approach": "wiki, concept, image", "verif wiki answer": "very(0.5530)", "verif concept answer": "mother(0.6162)", "verif image answer": "unsafe(0.7288)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000476104.jpg"}, {"question": "what is the term for the piece of matching furniture in front of this chair", "gt answer": "ottoman(1.00)", "pred answer": "couch", "question_id": 2859105, "best approach": "image", "verif answer": "couch", "anno approach": "wiki, concept, image", "verif wiki answer": "tennis(0.7106)", "verif concept answer": "tennis(0.5720)", "verif image answer": "ottoman(0.6842)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000285910.jpg"}, {"question": "what kind of parade is taking place", "gt answer": "gay(1.00)<br/>summer(0.60)<br/>gay pride(0.60)", "pred answer": "rally", "question_id": 3645905, "best approach": "concept", "verif answer": "gay pride", "anno approach": "wiki, concept, image", "verif wiki answer": "summer(0.6621)", "verif concept answer": "gay(0.5908)", "verif image answer": "gay pride(0.7122)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000364590.jpg"}, {"question": "what genus of bird is flying here", "gt answer": "hummingbird(1.00)<br/>sparrow(0.60)", "pred answer": "robin", "question_id": 2140225, "best approach": "concept", "verif answer": "robin", "anno approach": "wiki, concept, image", "verif wiki answer": "hum bird(0.5950)", "verif concept answer": "sparrow(0.5814)", "verif image answer": "hum bird(0.5782)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000214022.jpg"}, {"question": "which type of cotton is used for making this cloth", "gt answer": "yarn(1.00)<br/>egyptian(0.60)<br/>wool(0.60)", "pred answer": "white", "question_id": 3065545, "best approach": "", "verif answer": "wool", "anno approach": "wiki, concept, image", "verif wiki answer": "(0.6823)", "verif concept answer": "(0.6663)", "verif image answer": "cotton(0.6581)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000306554.jpg"}, {"question": "what breed of dog is pictured", "gt answer": "labrador(1.00)<br/>lab(1.00)<br/>rottweiler(0.60)", "pred answer": "chihuahua", "question_id": 5392635, "best approach": "concept", "verif answer": "lab", "anno approach": "wiki, concept, image", "verif wiki answer": "black labrador(0.6004)", "verif concept answer": "rottweiler(0.5875)", "verif image answer": "greyhound(0.5655)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539263.jpg"}, {"question": "what should this person be aware of", "gt answer": "wave(1.00)<br/>shark(0.60)", "pred answer": "surf", "question_id": 2942335, "best approach": "wiki", "verif answer": "wave", "anno approach": "wiki, concept, image", "verif wiki answer": "wave(0.6113)", "verif concept answer": "drown(0.6170)", "verif image answer": "drown(0.7200)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000294233.jpg"}, {"question": "what plant is in the picture", "gt answer": "fern(1.00)<br/>bamboo(0.60)<br/>lavender(0.60)<br/>grass(0.60)", "pred answer": "tree", "question_id": 1761575, "best approach": "wiki", "verif answer": "fern", "anno approach": "wiki, concept, image", "verif wiki answer": "fern(0.6372)", "verif concept answer": "cactus(0.6363)", "verif image answer": "cactus(0.7249)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000176157.jpg"}, {"question": "what kind of material are these stairs made of", "gt answer": "stone(1.00)<br/>brick(0.60)", "pred answer": "wood", "question_id": 2363895, "best approach": "wiki", "verif answer": "stone", "anno approach": "wiki, concept, image", "verif wiki answer": "brick(0.7267)", "verif concept answer": "rock(0.6546)", "verif image answer": "rock(0.7058)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000236389.jpg"}, {"question": "what type of motorcycle is this", "gt answer": "sidecar(1.00)", "pred answer": "harley", "question_id": 5208985, "best approach": "", "verif answer": "harley", "anno approach": "wiki, concept, image", "verif wiki answer": "back(0.6059)", "verif concept answer": "back(0.6069)", "verif image answer": "scooter(0.5880)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000520898.jpg"}, {"question": "when do people put this kind of this tape on a wall", "gt answer": "paint(1.00)", "pred answer": "clean", "question_id": 2490585, "best approach": "", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "picture(0.5984)", "verif concept answer": "glaze(0.6180)", "verif image answer": "glaze(0.7170)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000249058.jpg"}, {"question": "what food is this", "gt answer": "smoothie(1.00)", "pred answer": "tea", "question_id": 156845, "best approach": "", "verif answer": "smoothies", "anno approach": "wiki, concept, image", "verif wiki answer": "juice(0.6234)", "verif concept answer": "juice(0.5587)", "verif image answer": "juice(0.7160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015684.jpg"}, {"question": "what kind of material is used for making this yellow pillars balanced by the boy", "gt answer": "cement(1.00)<br/>concrete(1.00)", "pred answer": "metal", "question_id": 1064195, "best approach": "", "verif answer": "stone", "anno approach": "wiki, concept, image", "verif wiki answer": "cemet(0.5767)", "verif concept answer": "stone(0.6566)", "verif image answer": "asphalt(0.7027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106419.jpg"}, {"question": "what type of land is shown in this photo", "gt answer": "island(1.00)<br/>peninsula(0.60)<br/>hill(0.60)", "pred answer": "desert", "question_id": 768475, "best approach": "concept", "verif answer": "mountain", "anno approach": "wiki, concept, image", "verif wiki answer": "peninsula(0.6456)", "verif concept answer": "island(0.5862)", "verif image answer": "mountain(0.6706)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000076847.jpg"}, {"question": "between two vehicles in the image which one has a higher retail price", "gt answer": "blue(1.00)<br/>black 1(0.60)<br/>left(0.60)", "pred answer": "motorcycle", "question_id": 861835, "best approach": "image", "verif answer": "left", "anno approach": "wiki, concept, image", "verif wiki answer": "left(0.6464)", "verif concept answer": "red(0.6197)", "verif image answer": "blue(0.5270)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086183.jpg"}, {"question": "in what state was this man a senator", "gt answer": "illinois(1.00)<br/>chicago(0.60)", "pred answer": "washington", "question_id": 5396315, "best approach": "wiki", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "chicago(0.6722)", "verif concept answer": "roosevelt(0.5780)", "verif image answer": "london(0.5165)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000539631.jpg"}, {"question": "what kind of streetcar is in the picture", "gt answer": "trolly(1.00)<br/>bus(0.60)<br/>trolley(0.60)<br/>electric(0.60)", "pred answer": "passenger", "question_id": 4293535, "best approach": "image", "verif answer": "passenger train", "anno approach": "wiki, concept, image", "verif wiki answer": "bus(0.6498)", "verif concept answer": "passenger train(0.6453)", "verif image answer": "trolly(0.6762)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000429353.jpg"}, {"question": "is this used for public or commercial transportation", "gt answer": "commercial(1.00)<br/>both(0.60)", "pred answer": "public", "question_id": 4376075, "best approach": "image", "verif answer": "public", "anno approach": "wiki, concept, image", "verif wiki answer": "passenger(0.5767)", "verif concept answer": "public(0.6155)", "verif image answer": "commercial(0.5936)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000437607.jpg"}, {"question": "what is the highest jump with this vehicle", "gt answer": "100 feet(1.00)<br/>20 feet(0.60)", "pred answer": "jump", "question_id": 3922095, "best approach": "", "verif answer": "20 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "2000 feet(0.6585)", "verif concept answer": "2000 feet(0.6575)", "verif image answer": "wave(0.5845)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000392209.jpg"}, {"question": "how fast do these wings beat", "gt answer": "80 beats per second(1.00)", "pred answer": "fast", "question_id": 3526755, "best approach": "", "verif answer": "slow", "anno approach": "wiki, concept, image", "verif wiki answer": "65 mph(0.6066)", "verif concept answer": "65 mph(0.6022)", "verif image answer": "far(0.6397)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000352675.jpg"}, {"question": "what is used to make the container of that food", "gt answer": "cardboard(1.00)<br/>paper(0.60)<br/>sauce(0.60)", "pred answer": "metal", "question_id": 4364405, "best approach": "wiki, concept, image", "verif answer": "paper", "anno approach": "wiki, concept, image", "verif wiki answer": "sauce(0.6435)", "verif concept answer": "sauce(0.6392)", "verif image answer": "sauce(0.6332)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000436440.jpg"}, {"question": "what kind of bird is this", "gt answer": "hawk(1.00)<br/>falcon(0.60)<br/>owl(0.60)<br/>finch(0.60)", "pred answer": "sparrow", "question_id": 1151445, "best approach": "wiki, image", "verif answer": "hawk", "anno approach": "wiki, concept, image", "verif wiki answer": "hawk(0.6455)", "verif concept answer": "falcon(0.6043)", "verif image answer": "hawk(0.6419)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000115144.jpg"}, {"question": "what are they doing", "gt answer": "ride(1.00)<br/>walk(0.60)", "pred answer": "stand", "question_id": 5265925, "best approach": "", "verif answer": "plow", "anno approach": "wiki, concept, image", "verif wiki answer": "plow(0.5951)", "verif concept answer": "plow(0.5972)", "verif image answer": "cycling(0.6503)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000526592.jpg"}, {"question": "what flag does the kite colors represent", "gt answer": "canada(1.00)<br/>japan(0.60)", "pred answer": "british", "question_id": 4552115, "best approach": "", "verif answer": "usa", "anno approach": "wiki, concept, image", "verif wiki answer": "america(0.6179)", "verif concept answer": "france(0.6284)", "verif image answer": "france(0.6967)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455211.jpg"}, {"question": "what is the name of the clothing she is wearing to protect their clothing while cooking", "gt answer": "apron(1.00)<br/>fire(0.60)", "pred answer": "hat", "question_id": 866765, "best approach": "wiki", "verif answer": "apron", "anno approach": "wiki, concept, image", "verif wiki answer": "apron(0.5902)", "verif concept answer": "fire(0.5607)", "verif image answer": "chef(0.5749)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000086676.jpg"}, {"question": "what is holding the burrito together", "gt answer": "tortilla(1.00)", "pred answer": "meat", "question_id": 1679955, "best approach": "", "verif answer": "egg salad", "anno approach": "wiki, concept, image", "verif wiki answer": "pita(0.6467)", "verif concept answer": "pita(0.5899)", "verif image answer": "pita(0.5544)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000167995.jpg"}, {"question": "what movie features small monsters that live in these", "gt answer": "ghoulies(1.00)", "pred answer": "lion", "question_id": 5684245, "best approach": "concept", "verif answer": "forrest gump", "anno approach": "wiki, concept, image", "verif wiki answer": "forrest gump(0.5379)", "verif concept answer": "ghoulies(0.5721)", "verif image answer": "chimney(0.5026)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000568424.jpg"}, {"question": "the upper portion of this white kitchen fixture for food storage is called a what", "gt answer": "freezer(1.00)", "pred answer": "refrigerator", "question_id": 4114505, "best approach": "", "verif answer": "freezer", "anno approach": "wiki, concept, image", "verif wiki answer": "skyscraper(0.6877)", "verif concept answer": "skyscraper(0.6505)", "verif image answer": "french(0.5938)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000411450.jpg"}, {"question": "this object has its own day in nations capitalwhat 's the day called", "gt answer": "kite day(1.00)<br/>kite(0.60)", "pred answer": "kite fly", "question_id": 2432345, "best approach": "concept, image", "verif answer": "kite", "anno approach": "wiki, concept, image", "verif wiki answer": "kite(0.6368)", "verif concept answer": "kite day(0.5831)", "verif image answer": "kite day(0.6959)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243234.jpg"}, {"question": "what are these signs for", "gt answer": "street(1.00)<br/>street name(1.00)<br/>street sign(0.60)", "pred answer": "direct", "question_id": 582505, "best approach": "wiki, image", "verif answer": "street name", "anno approach": "wiki, concept, image", "verif wiki answer": "street(0.6288)", "verif concept answer": "crossroad(0.5877)", "verif image answer": "street name(0.6709)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000058250.jpg"}, {"question": "", "gt answer": "flipped(0.60)<br/>accident(0.60)", "pred answer": "broken", "question_id": 1619245, "best approach": "", "verif answer": "broken", "anno approach": "wiki, concept, image", "verif wiki answer": "broken(0.6080)", "verif concept answer": "tow(0.5566)", "verif image answer": "tow(0.6060)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000161924.jpg"}, {"question": "what brand of paper towels do they own", "gt answer": "bounty(1.00)", "pred answer": "kleenex", "question_id": 3227685, "best approach": "", "verif answer": "ruffle", "anno approach": "wiki, concept, image", "verif wiki answer": "krispy kreme(0.7059)", "verif concept answer": "krispy kreme(0.6931)", "verif image answer": "krispy kreme(0.5706)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000322768.jpg"}, {"question": "what is uncomfortable about this situation", "gt answer": "crowded(1.00)<br/>ski(0.60)", "pred answer": "people", "question_id": 309955, "best approach": "image", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "ski(0.6503)", "verif concept answer": "ski(0.6196)", "verif image answer": "crowded(0.5160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000030995.jpg"}, {"question": "what 's covering the horse 's face", "gt answer": "blinder(1.00)<br/>bridle(0.60)", "pred answer": "blanket", "question_id": 2432145, "best approach": "", "verif answer": "rein", "anno approach": "wiki, concept, image", "verif wiki answer": "saddle(0.7042)", "verif concept answer": "rein(0.6779)", "verif image answer": "rein(0.7146)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000243214.jpg"}, {"question": "why isn't the sky blue", "gt answer": "even(0.60)<br/>filter(1.00)", "pred answer": "sunset", "question_id": 137145, "best approach": "", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "black and white(0.6418)", "verif concept answer": "sephia(0.6114)", "verif image answer": "black and white(0.6834)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000013714.jpg"}, {"question": "what is the name of the city in this skyline", "gt answer": "miami(1.00)", "pred answer": "san francisco", "question_id": 1435305, "best approach": "", "verif answer": "new york", "anno approach": "wiki, concept, image", "verif wiki answer": "new york(0.5713)", "verif concept answer": "new york(0.5682)", "verif image answer": "seattle(0.6519)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143530.jpg"}, {"question": "is this a hotel room or a room in a private house", "gt answer": "private house(1.00)<br/>house(0.60)<br/>private(0.60)", "pred answer": "bedroom", "question_id": 2215925, "best approach": "concept", "verif answer": "private", "anno approach": "wiki, concept, image", "verif wiki answer": "home(0.6683)", "verif concept answer": "private house(0.5507)", "verif image answer": "house(0.5559)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221592.jpg"}, {"question": "is it dark out or is it going to rain", "gt answer": "rain(1.00)<br/>dark(1.00)<br/>both(0.60)", "pred answer": "day", "question_id": 5764805, "best approach": "wiki", "verif answer": "rain", "anno approach": "wiki, concept, image", "verif wiki answer": "rain(0.7072)", "verif concept answer": "storm(0.5429)", "verif image answer": "both(0.5160)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000576480.jpg"}, {"question": "what do these items appear to be used for in the kitchen", "gt answer": "measure(1.00)", "pred answer": "cook", "question_id": 1433345, "best approach": "concept", "verif answer": "measure", "anno approach": "wiki, concept, image", "verif wiki answer": "cut(0.6262)", "verif concept answer": "measure(0.5734)", "verif image answer": "chop(0.7151)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000143334.jpg"}, {"question": "are these diners in doors or outdoors", "gt answer": "outdoor(1.00)", "pred answer": "outside", "question_id": 3652845, "best approach": "concept", "verif answer": "outdoor", "anno approach": "wiki, concept, image", "verif wiki answer": "indoor(0.7284)", "verif concept answer": "outdoor(0.7135)", "verif image answer": "indoor(0.7287)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000365284.jpg"}, {"question": "what is it called when two players are on the same team when playing this sport", "gt answer": "double(1.00)", "pred answer": "tennis", "question_id": 4083735, "best approach": "image", "verif answer": "tennis", "anno approach": "wiki, concept, image", "verif wiki answer": "jack and jill(0.5376)", "verif concept answer": "jack and jill(0.5362)", "verif image answer": "double(0.6144)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000408373.jpg"}, {"question": "what skate trick is this", "gt answer": "grind(1.00)<br/>kick flip(0.60)", "pred answer": "ollie", "question_id": 2864925, "best approach": "wiki, image", "verif answer": "kick flip", "anno approach": "wiki, concept, image", "verif wiki answer": "grind(0.6948)", "verif concept answer": "kick flip(0.6276)", "verif image answer": "grind(0.5932)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000286492.jpg"}, {"question": "what channel has these games in it", "gt answer": "espn(1.00)<br/>bmx(0.60)<br/>ride(0.60)<br/>youtube(0.60)", "pred answer": "game show", "question_id": 17745, "best approach": "wiki, concept", "verif answer": "espn", "anno approach": "wiki, concept, image", "verif wiki answer": "espn(0.7206)", "verif concept answer": "espn(0.6223)", "verif image answer": "bmx(0.6437)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000001774.jpg"}, {"question": "what is the man reading", "gt answer": "phone(1.00)<br/>smartphone(0.60)", "pred answer": "cell phone", "question_id": 3241075, "best approach": "image", "verif answer": "cell phone", "anno approach": "wiki, concept, image", "verif wiki answer": "cell phone(0.6132)", "verif concept answer": "cell(0.5615)", "verif image answer": "phone(0.5451)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000324107.jpg"}, {"question": "what is the name of the president of the united states form of this transportation", "gt answer": "air force 1(1.00)", "pred answer": "george washington", "question_id": 2273635, "best approach": "", "verif answer": "george washington", "anno approach": "wiki, concept, image", "verif wiki answer": "george washington(0.6674)", "verif concept answer": "private jet(0.6800)", "verif image answer": "george washington(0.5630)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000227363.jpg"}, {"question": "what part of the pictures seems to show the most thermal energy", "gt answer": "center(1.00)<br/>door(0.60)", "pred answer": "window", "question_id": 2505335, "best approach": "wiki, image", "verif answer": "light", "anno approach": "wiki, concept, image", "verif wiki answer": "door(0.5851)", "verif concept answer": "light(0.6083)", "verif image answer": "door(0.5691)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250533.jpg"}, {"question": "what do you think this person 's ethnicity is", "gt answer": "hispanic(1.00)<br/>indian(0.60)", "pred answer": "white", "question_id": 3554585, "best approach": "concept", "verif answer": "indian", "anno approach": "wiki, concept, image", "verif wiki answer": "hindu(0.6717)", "verif concept answer": "hispanic(0.6225)", "verif image answer": "spanish(0.5969)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355458.jpg"}, {"question": "what is it called when this system runs underground", "gt answer": "subway(1.00)", "pred answer": "train", "question_id": 3192665, "best approach": "wiki", "verif answer": "train", "anno approach": "wiki, concept, image", "verif wiki answer": "subway(0.6219)", "verif concept answer": "train(0.5386)", "verif image answer": "chicago(0.6219)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000319266.jpg"}, {"question": "what event is happening with this photo", "gt answer": "watch tv(1.00)<br/>birthday(0.60)", "pred answer": "rally", "question_id": 4077055, "best approach": "concept, image", "verif answer": "birthday", "anno approach": "wiki, concept, image", "verif wiki answer": "sleepover(0.6471)", "verif concept answer": "birthday(0.5603)", "verif image answer": "birthday(0.6911)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000407705.jpg"}, {"question": "what type of road or intersection is this sign making you aware of", "gt answer": "roundabout(1.00)<br/>circle(0.60)", "pred answer": "crosswalk", "question_id": 1052525, "best approach": "wiki", "verif answer": "direction", "anno approach": "wiki, concept, image", "verif wiki answer": "roundabout(0.6254)", "verif concept answer": "rectangle(0.5490)", "verif image answer": "direction(0.6491)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000105252.jpg"}, {"question": "the switch from horse drawn machines and transportation to engine based is commonly referred to as what revolution", "gt answer": "industrial(1.00)<br/>mechanical(0.60)", "pred answer": "boat", "question_id": 3584625, "best approach": "concept", "verif answer": "mechanical", "anno approach": "wiki, concept, image", "verif wiki answer": "wwii(0.5975)", "verif concept answer": "mechanical(0.6018)", "verif image answer": "wwii(0.5257)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000358462.jpg"}, {"question": "is this a study area or play area", "gt answer": "study(1.00)", "pred answer": "office", "question_id": 4005925, "best approach": "image", "verif answer": "study", "anno approach": "wiki, concept, image", "verif wiki answer": "read(0.6282)", "verif concept answer": "work(0.5199)", "verif image answer": "study(0.6269)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400592.jpg"}, {"question": "how high off the ground does this bed appear to be", "gt answer": "1 foot(1.00)<br/>8 inches(0.60)<br/>foot(0.60)", "pred answer": "very", "question_id": 4391415, "best approach": "concept", "verif answer": "1 foot", "anno approach": "wiki, concept, image", "verif wiki answer": "8 inches(0.6485)", "verif concept answer": "1 foot(0.5981)", "verif image answer": "foot(0.5528)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439141.jpg"}, {"question": "how fast does this mode of transportation go", "gt answer": "200 mph(1.00)<br/>300 mph(0.60)<br/>200(0.60)", "pred answer": "80 mph", "question_id": 394035, "best approach": "image", "verif answer": "200 mph", "anno approach": "wiki, concept, image", "verif wiki answer": "300 mph(0.6435)", "verif concept answer": "300 mph(0.6181)", "verif image answer": "200 mph(0.6868)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039403.jpg"}, {"question": "what kind of rocks are on the beach", "gt answer": "boulder(1.00)<br/>calcium(0.60)<br/>limestone(0.60)", "pred answer": "rock", "question_id": 4793325, "best approach": "concept", "verif answer": "rock", "anno approach": "wiki, concept, image", "verif wiki answer": "hill(0.6217)", "verif concept answer": "calcium(0.5541)", "verif image answer": "hill(0.5680)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000479332.jpg"}, {"question": "what type of hat is the woman in this picture wearing", "gt answer": "fedora(1.00)<br/>cloth(0.60)", "pred answer": "beanie", "question_id": 2417205, "best approach": "wiki, concept", "verif answer": "fedora", "anno approach": "wiki, concept, image", "verif wiki answer": "fedora(0.6337)", "verif concept answer": "fedora(0.6468)", "verif image answer": "bowler(0.5354)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000241720.jpg"}, {"question": "the orange flowers are called what", "gt answer": "lily(1.00)", "pred answer": "orange", "question_id": 3547665, "best approach": "", "verif answer": "rose", "anno approach": "wiki, concept, image", "verif wiki answer": "orchid(0.6569)", "verif concept answer": "rose(0.6281)", "verif image answer": "rose(0.6655)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000354766.jpg"}, {"question": "what type of the suit is the anchor wearing", "gt answer": "3 piece(1.00)", "pred answer": "suit", "question_id": 2505695, "best approach": "concept", "verif answer": "suit", "anno approach": "wiki, concept, image", "verif wiki answer": "black and white(0.6961)", "verif concept answer": "3 piece(0.6234)", "verif image answer": "modern(0.7031)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000250569.jpg"}, {"question": "why is this animal resting on a computer", "gt answer": "it want attention(1.00)<br/>tired(0.60)<br/>warmth(0.60)", "pred answer": "rest", "question_id": 263595, "best approach": "wiki", "verif answer": "rest", "anno approach": "wiki, concept, image", "verif wiki answer": "warmth(0.6259)", "verif concept answer": "to eat(0.5853)", "verif image answer": "rest(0.6749)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000026359.jpg"}, {"question": "who would be most suited to live in this type of room", "gt answer": "student(1.00)<br/>college student(1.00)", "pred answer": "child", "question_id": 4009665, "best approach": "wiki, image", "verif answer": "college student", "anno approach": "wiki, concept, image", "verif wiki answer": "college student(0.6985)", "verif concept answer": "chef(0.6523)", "verif image answer": "college student(0.6171)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000400966.jpg"}, {"question": "what kind of dog is this", "gt answer": "pug(1.00)", "pred answer": "terrier", "question_id": 4132455, "best approach": "", "verif answer": "terrier", "anno approach": "wiki, concept, image", "verif wiki answer": "shitzu(0.6394)", "verif concept answer": "terrier(0.5756)", "verif image answer": "shitzu(0.7177)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000413245.jpg"}, {"question": "what kind of shoes are these women wearing", "gt answer": "sandal(1.00)", "pred answer": "boot", "question_id": 4424515, "best approach": "", "verif answer": "boot", "anno approach": "wiki, concept, image", "verif wiki answer": "flip flop(0.7170)", "verif concept answer": "flip flop(0.6645)", "verif image answer": "boot(0.6984)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000442451.jpg"}, {"question": "what company made the stuffed animal in the red shirt", "gt answer": "build bear(1.00)", "pred answer": "ty", "question_id": 2291315, "best approach": "wiki, concept, image", "verif answer": "toy r us", "anno approach": "wiki, concept, image", "verif wiki answer": "build bear(0.6280)", "verif concept answer": "build bear(0.6283)", "verif image answer": "build bear(0.7285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000229131.jpg"}, {"question": "why won't this luggage close", "gt answer": "too full(1.00)<br/>too small(0.60)", "pred answer": "broken", "question_id": 166605, "best approach": "", "verif answer": "too small", "anno approach": "wiki, concept, image", "verif wiki answer": "dead(0.6419)", "verif concept answer": "dead(0.5883)", "verif image answer": "short(0.6523)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000016660.jpg"}, {"question": "name the type of wood that can be used to make this bench in this picture", "gt answer": "cedar(1.00)<br/>teak(0.60)<br/>oak(0.60)", "pred answer": "pine", "question_id": 3994325, "best approach": "wiki, concept", "verif answer": "pine", "anno approach": "wiki, concept, image", "verif wiki answer": "oak(0.6646)", "verif concept answer": "oak(0.6345)", "verif image answer": "wood(0.7114)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000399432.jpg"}, {"question": "what company does this plane belong to", "gt answer": "delta(1.00)", "pred answer": "american airline", "question_id": 4586405, "best approach": "", "verif answer": "delta", "anno approach": "wiki, concept, image", "verif wiki answer": "boeing(0.5457)", "verif concept answer": "dell(0.5648)", "verif image answer": "dell(0.6050)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458640.jpg"}, {"question": "what species of birds are known to migrate", "gt answer": "geese(1.00)<br/>duck(0.60)", "pred answer": "seagull", "question_id": 4218235, "best approach": "", "verif answer": "seagull", "anno approach": "wiki, concept, image", "verif wiki answer": "seagull(0.7008)", "verif concept answer": "seagull(0.7095)", "verif image answer": "seagull(0.6971)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000421823.jpg"}, {"question": "who is the manufacturer of these stuffed animals", "gt answer": "build bear(1.00)<br/>disney(0.60)<br/>hasbro(0.60)", "pred answer": "ty", "question_id": 913975, "best approach": "concept, image", "verif answer": "toy r us", "anno approach": "wiki, concept, image", "verif wiki answer": "toy r us(0.6765)", "verif concept answer": "build bear(0.6548)", "verif image answer": "build bear(0.5599)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000091397.jpg"}, {"question": "what airport is this", "gt answer": "jfk(1.00)<br/>northern(0.60)", "pred answer": "las vegas", "question_id": 1684755, "best approach": "", "verif answer": "las vegas", "anno approach": "wiki, concept, image", "verif wiki answer": "san diego(0.6405)", "verif concept answer": "san diego(0.6544)", "verif image answer": "las vegas(0.5515)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168475.jpg"}, {"question": "what is the origin of this type of food", "gt answer": "french(1.00)<br/>italy(0.60)", "pred answer": "asian", "question_id": 3376285, "best approach": "wiki", "verif answer": "french", "anno approach": "wiki, concept, image", "verif wiki answer": "italy(0.6967)", "verif concept answer": "cheese(0.6255)", "verif image answer": "germany(0.6103)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000337628.jpg"}, {"question": "is this a pc or mac", "gt answer": "pc(1.00)", "pred answer": "mac", "question_id": 5223605, "best approach": "", "verif answer": "mac", "anno approach": "wiki, concept, image", "verif wiki answer": "mac(0.5795)", "verif concept answer": "hp(0.6275)", "verif image answer": "hp(0.7261)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522360.jpg"}, {"question": "what kind of bus is this", "gt answer": "tour(1.00)<br/>passenger(0.60)", "pred answer": "double decker", "question_id": 2533235, "best approach": "wiki", "verif answer": "tour", "anno approach": "wiki, concept, image", "verif wiki answer": "passenger(0.6704)", "verif concept answer": "transport people(0.6752)", "verif image answer": "transport people(0.7201)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253323.jpg"}, {"question": "did it rain a short or long time ago", "gt answer": "long(1.00)<br/>short(0.60)", "pred answer": "30 years", "question_id": 2790255, "best approach": "concept", "verif answer": "long", "anno approach": "wiki, concept, image", "verif wiki answer": "loveseat(0.6115)", "verif concept answer": "short(0.6130)", "verif image answer": "brown(0.7017)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000279025.jpg"}, {"question": "what this train is used for", "gt answer": "cargo(1.00)<br/>transportation(0.60)<br/>travel(0.60)<br/>transport(0.60)", "pred answer": "passenger", "question_id": 2088385, "best approach": "wiki, concept, image", "verif answer": "travel", "anno approach": "wiki, concept, image", "verif wiki answer": "travel(0.6268)", "verif concept answer": "transport(0.6388)", "verif image answer": "travel(0.6716)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000208838.jpg"}, {"question": "what should this catcher be using", "gt answer": "glove(1.00)", "pred answer": "bat", "question_id": 84945, "best approach": "", "verif answer": "base", "anno approach": "wiki, concept, image", "verif wiki answer": "oven mitt(0.6977)", "verif concept answer": "oven mitt(0.6157)", "verif image answer": "oven mitt(0.6237)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000008494.jpg"}, {"question": "which type of materails are used for building this ship shown in this picture", "gt answer": "fiberglass(1.00)<br/>steel(0.60)", "pred answer": "boat", "question_id": 536415, "best approach": "wiki, concept, image", "verif answer": "plastic", "anno approach": "wiki, concept, image", "verif wiki answer": "fiberglass(0.6789)", "verif concept answer": "fiberglass(0.6800)", "verif image answer": "fiberglass(0.6466)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000053641.jpg"}, {"question": "is that paint or real blood", "gt answer": "paint(1.00)", "pred answer": "real", "question_id": 5186475, "best approach": "", "verif answer": "paint", "anno approach": "wiki, concept, image", "verif wiki answer": "pain(0.5445)", "verif concept answer": "pain(0.6134)", "verif image answer": "pain(0.5853)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000518647.jpg"}, {"question": "what type of flower is this", "gt answer": "tulip(1.00)<br/>pink(0.60)", "pred answer": "rose", "question_id": 1947015, "best approach": "", "verif answer": "rose", "anno approach": "wiki, concept, image", "verif wiki answer": "rose(0.6337)", "verif concept answer": "rose(0.6407)", "verif image answer": "rose(0.6846)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000194701.jpg"}, {"question": "what is this animal called when it is young", "gt answer": "puppy(1.00)", "pred answer": "dog", "question_id": 5722545, "best approach": "wiki, image", "verif answer": "dog", "anno approach": "wiki, concept, image", "verif wiki answer": "puppy(0.7286)", "verif concept answer": "baby(0.5609)", "verif image answer": "puppy(0.7284)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000572254.jpg"}, {"question": "how do we call the kind of jacket worn by the man on the left", "gt answer": "suit(1.00)", "pred answer": "flannel", "question_id": 990625, "best approach": "", "verif answer": "formal", "anno approach": "wiki, concept, image", "verif wiki answer": "formal(0.6925)", "verif concept answer": "tie(0.6702)", "verif image answer": "tuxedo(0.5580)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000099062.jpg"}, {"question": "where is the coffee in the picture located", "gt answer": "upper right(1.00)<br/>right(0.60)<br/>cup(0.60)", "pred answer": "factory", "question_id": 2538345, "best approach": "wiki, concept, image", "verif answer": "cup", "anno approach": "wiki, concept, image", "verif wiki answer": "cup(0.5604)", "verif concept answer": "cup(0.6006)", "verif image answer": "right(0.6446)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000253834.jpg"}, {"question": "what type of boats are these", "gt answer": "canoes(1.00)<br/>canoe(0.60)<br/>fish boat(0.60)", "pred answer": "row boat", "question_id": 858475, "best approach": "wiki, concept, image", "verif answer": "canoes", "anno approach": "wiki, concept, image", "verif wiki answer": "canoes(0.6438)", "verif concept answer": "canoes(0.6242)", "verif image answer": "canoes(0.6023)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000085847.jpg"}, {"question": "what kind of pizza is this", "gt answer": "spinach(1.00)<br/>margarita(0.60)", "pred answer": "supreme", "question_id": 3866835, "best approach": "", "verif answer": "kale", "anno approach": "wiki, concept, image", "verif wiki answer": "basil(0.6028)", "verif concept answer": "basil(0.6045)", "verif image answer": "basil(0.6145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000386683.jpg"}, {"question": "is the animal shown a mammal or a reptile", "gt answer": "mammal(1.00)", "pred answer": "feline", "question_id": 1004495, "best approach": "image", "verif answer": "feline", "anno approach": "wiki, concept, image", "verif wiki answer": "feline(0.7167)", "verif concept answer": "feline(0.5845)", "verif image answer": "mammal(0.5703)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000100449.jpg"}, {"question": "what kind of necks do these animals have", "gt answer": "long(1.00)", "pred answer": "neck", "question_id": 2745625, "best approach": "wiki, concept", "verif answer": "long", "anno approach": "wiki, concept, image", "verif wiki answer": "long(0.6961)", "verif concept answer": "long(0.5515)", "verif image answer": "sport(0.7188)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000274562.jpg"}, {"question": "what kind of license do you need to drive on of these", "gt answer": "driver(1.00)<br/>0(0.60)<br/>cart(0.60)<br/>commercial(0.60)", "pred answer": "carriage", "question_id": 3046935, "best approach": "", "verif answer": "commercial", "anno approach": "wiki, concept, image", "verif wiki answer": "cdl(0.7038)", "verif concept answer": "cdl(0.6603)", "verif image answer": "cdl(0.6435)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000304693.jpg"}, {"question": "what fuels this vehicle", "gt answer": "diesel(1.00)<br/>gasoline(0.60)<br/>gas(0.60)", "pred answer": "fuel", "question_id": 4540865, "best approach": "wiki, concept", "verif answer": "diesel", "anno approach": "wiki, concept, image", "verif wiki answer": "diesel(0.6942)", "verif concept answer": "diesel(0.6169)", "verif image answer": "engine(0.5423)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000454086.jpg"}, {"question": "is this a hallway or living room", "gt answer": "hallway(1.00)", "pred answer": "bathroom", "question_id": 5560215, "best approach": "", "verif answer": "bathroom", "anno approach": "wiki, concept, image", "verif wiki answer": "live room(0.7227)", "verif concept answer": "live room(0.6601)", "verif image answer": "live room(0.7232)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000556021.jpg"}, {"question": "what is the name of the son of the cartoon character on the box", "gt answer": "bart(1.00)<br/>bart simpson(1.00)", "pred answer": "yogi", "question_id": 3024975, "best approach": "concept, image", "verif answer": "cowboy", "anno approach": "wiki, concept, image", "verif wiki answer": "cowboy(0.6695)", "verif concept answer": "bart(0.5485)", "verif image answer": "bart(0.5065)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000302497.jpg"}, {"question": "what year was this resturaunt founded", "gt answer": "1965(1.00)<br/>1969(0.60)<br/>1980(0.60)<br/>1995(0.60)", "pred answer": "1950", "question_id": 1462745, "best approach": "concept", "verif answer": "1990", "anno approach": "wiki, concept, image", "verif wiki answer": "1969(0.6006)", "verif concept answer": "1965(0.6241)", "verif image answer": "1995(0.7034)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146274.jpg"}, {"question": "which slice of pizza has veggies", "gt answer": "bottom(1.00)<br/>yellow(0.60)", "pred answer": "tomato", "question_id": 2664365, "best approach": "", "verif answer": "onion", "anno approach": "wiki, concept, image", "verif wiki answer": "day(0.5908)", "verif concept answer": "day(0.5635)", "verif image answer": "day(0.5711)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000266436.jpg"}, {"question": "what is the white on the cake known as", "gt answer": "frost(1.00)<br/>fondant(0.60)<br/>cherry(0.60)", "pred answer": "ice", "question_id": 2189415, "best approach": "image", "verif answer": "ice", "anno approach": "wiki, concept, image", "verif wiki answer": "ice(0.6670)", "verif concept answer": "ice(0.6667)", "verif image answer": "fondant(0.7161)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218941.jpg"}, {"question": "what city does this player represent", "gt answer": "boston(1.00)<br/>new york(1.00)", "pred answer": "baltimore", "question_id": 1930905, "best approach": "wiki, concept", "verif answer": "boston", "anno approach": "wiki, concept, image", "verif wiki answer": "boston(0.5833)", "verif concept answer": "boston(0.6100)", "verif image answer": "new york city(0.5529)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000193090.jpg"}, {"question": "where in london is famous for this sport", "gt answer": "wimbledon(1.00)", "pred answer": "tennis court", "question_id": 1101365, "best approach": "", "verif answer": "tennis", "anno approach": "wiki, concept, image", "verif wiki answer": "jack and jill(0.6885)", "verif concept answer": "jack and jill(0.6492)", "verif image answer": "us open(0.7072)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000110136.jpg"}, {"question": "what sport are these participants engaged in", "gt answer": "basketball(1.00)", "pred answer": "hockey", "question_id": 4553395, "best approach": "concept, image", "verif answer": "basketball", "anno approach": "wiki, concept, image", "verif wiki answer": "football(0.6206)", "verif concept answer": "basketball(0.6370)", "verif image answer": "basketball(0.5900)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000455339.jpg"}, {"question": "what is the name of the bus company", "gt answer": "5 star(1.00)", "pred answer": "greyhound", "question_id": 1442985, "best approach": "", "verif answer": "trailways", "anno approach": "wiki, concept, image", "verif wiki answer": "double decker(0.7184)", "verif concept answer": "double decker(0.6776)", "verif image answer": "double decker(0.5127)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000144298.jpg"}, {"question": "which item on this plate is often regarded as smelling distasteful", "gt answer": "broccoli(1.00)<br/>meat(0.60)", "pred answer": "potato", "question_id": 5369735, "best approach": "concept, image", "verif answer": "bacon", "anno approach": "wiki, concept, image", "verif wiki answer": "bacon(0.6247)", "verif concept answer": "meat(0.5610)", "verif image answer": "meat(0.5320)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000536973.jpg"}, {"question": "what is the distinct characteristic of this animal", "gt answer": "trunk(1.00)<br/>tusk(1.00)", "pred answer": "long neck", "question_id": 1997195, "best approach": "", "verif answer": "trunk", "anno approach": "wiki, concept, image", "verif wiki answer": "elephant(0.6824)", "verif concept answer": "brain(0.5805)", "verif image answer": "brain(0.5285)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000199719.jpg"}, {"question": "what is this man doing", "gt answer": "tie tie(1.00)", "pred answer": "cut", "question_id": 4887455, "best approach": "", "verif answer": "play", "anno approach": "wiki, concept, image", "verif wiki answer": "talk(0.6691)", "verif concept answer": "shake hand(0.6769)", "verif image answer": "shake hand(0.6398)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000488745.jpg"}, {"question": "the animal in the sign is what color", "gt answer": "gray(1.00)<br/>grey(1.00)", "pred answer": "white", "question_id": 1849655, "best approach": "", "verif answer": "grey", "anno approach": "wiki, concept, image", "verif wiki answer": "ragdoll(0.6302)", "verif concept answer": "black and white(0.6395)", "verif image answer": "ragdoll(0.5433)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000184965.jpg"}, {"question": "what type of objects are put through this slot", "gt answer": "mail(1.00)<br/>towel(0.60)", "pred answer": "dish", "question_id": 5024795, "best approach": "wiki, concept", "verif answer": "towel", "anno approach": "wiki, concept, image", "verif wiki answer": "towel(0.7223)", "verif concept answer": "towel(0.7015)", "verif image answer": "trailer(0.5802)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000502479.jpg"}, {"question": "what breed of cat is shown", "gt answer": "tuxedo(1.00)<br/>calico(0.60)", "pred answer": "tabby", "question_id": 334455, "best approach": "concept", "verif answer": "calico", "anno approach": "wiki, concept, image", "verif wiki answer": "calico(0.7091)", "verif concept answer": "tuxedo(0.6951)", "verif image answer": "calico(0.6765)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000033445.jpg"}, {"question": "what is the object that the dog is holding used for", "gt answer": "brush hair(1.00)<br/>brush(0.60)", "pred answer": "sleep", "question_id": 52885, "best approach": "image", "verif answer": "brush teeth", "anno approach": "wiki, concept, image", "verif wiki answer": "brush(0.6088)", "verif concept answer": "brush teeth(0.6313)", "verif image answer": "brush hair(0.6897)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000005288.jpg"}, {"question": "what are the black objects depicted used for", "gt answer": "walk(1.00)<br/>feet(0.60)", "pred answer": "call", "question_id": 5454095, "best approach": "wiki", "verif answer": "walk", "anno approach": "wiki, concept, image", "verif wiki answer": "walk(0.6818)", "verif concept answer": "feet(0.6375)", "verif image answer": "bike(0.7268)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000545409.jpg"}, {"question": "what is one reason people might wear this type of head covering", "gt answer": "religion(1.00)", "pred answer": "safety", "question_id": 711385, "best approach": "image", "verif answer": "pollution", "anno approach": "wiki, concept, image", "verif wiki answer": "snow(0.6516)", "verif concept answer": "pollution(0.5914)", "verif image answer": "religion(0.6546)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000071138.jpg"}, {"question": "how much does this type of vehicle cost to build", "gt answer": "million(1.00)<br/>5 million(0.60)", "pred answer": "5000", "question_id": 2772925, "best approach": "", "verif answer": "thousand", "anno approach": "wiki, concept, image", "verif wiki answer": "1500(0.6090)", "verif concept answer": "1500(0.6777)", "verif image answer": "thousand(0.6860)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000277292.jpg"}, {"question": "what type of food is this", "gt answer": "turkey(1.00)<br/>asian(0.60)<br/>vegetarian(0.60)", "pred answer": "meat", "question_id": 4133005, "best approach": "concept", "verif answer": "vegetable", "anno approach": "wiki, concept, image", "verif wiki answer": "vegetable(0.6393)", "verif concept answer": "vegetarian(0.6018)", "verif image answer": "vegetable(0.6010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000413300.jpg"}, {"question": "which apple product is this", "gt answer": "ipod(1.00)", "pred answer": "apple", "question_id": 2186255, "best approach": "", "verif answer": "green", "anno approach": "wiki, concept, image", "verif wiki answer": "green(0.6242)", "verif concept answer": "game control(0.6250)", "verif image answer": "computer(0.5877)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218625.jpg"}, {"question": "what is overflowing in this picture", "gt answer": "trash(1.00)<br/>pool(0.60)<br/>garbage can(0.60)", "pred answer": "umbrella", "question_id": 5627125, "best approach": "wiki, concept, image", "verif answer": "trash", "anno approach": "wiki, concept, image", "verif wiki answer": "pool(0.6829)", "verif concept answer": "garbage can(0.6159)", "verif image answer": "garbage can(0.6053)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000562712.jpg"}, {"question": "is this a commercial or military plane", "gt answer": "commercial(1.00)", "pred answer": "private", "question_id": 1385475, "best approach": "concept", "verif answer": "private", "anno approach": "wiki, concept, image", "verif wiki answer": "cdl(0.5634)", "verif concept answer": "commercial(0.5363)", "verif image answer": "private(0.6106)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000138547.jpg"}, {"question": "what type of dog is this", "gt answer": "dachshund(1.00)<br/>dachsund(0.60)", "pred answer": "boxer", "question_id": 1681345, "best approach": "", "verif answer": "hound", "anno approach": "wiki, concept, image", "verif wiki answer": "hound(0.6248)", "verif concept answer": "hound(0.6237)", "verif image answer": "hound(0.6530)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000168134.jpg"}, {"question": "what type of tree is this", "gt answer": "maple(1.00)<br/>elm(0.60)", "pred answer": "pine", "question_id": 3444425, "best approach": "concept, image", "verif answer": "pine", "anno approach": "wiki, concept, image", "verif wiki answer": "pine(0.5894)", "verif concept answer": "maple(0.6116)", "verif image answer": "maple(0.5853)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344442.jpg"}, {"question": "what language does this country speak", "gt answer": "hindi(1.00)<br/>hindu(0.60)<br/>arabic(0.60)", "pred answer": "chinese", "question_id": 4341355, "best approach": "image", "verif answer": "chinese", "anno approach": "wiki, concept, image", "verif wiki answer": "chinese(0.6326)", "verif concept answer": "hindu(0.6222)", "verif image answer": "hindi(0.6431)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000434135.jpg"}, {"question": "what type of cows are these", "gt answer": "holstein(1.00)<br/>dairy(1.00)<br/>bull(0.60)", "pred answer": "dairy cow", "question_id": 1314905, "best approach": "wiki, concept", "verif answer": "dairy", "anno approach": "wiki, concept, image", "verif wiki answer": "dairy(0.6386)", "verif concept answer": "dairy(0.6106)", "verif image answer": "milk(0.7019)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000131490.jpg"}, {"question": "what activity is this contraption used for", "gt answer": "windsurf(1.00)<br/>wind surf(0.60)<br/>parasailing(0.60)<br/>surf(0.60)", "pred answer": "water ski", "question_id": 4614435, "best approach": "concept", "verif answer": "wind surf", "anno approach": "wiki, concept, image", "verif wiki answer": "wind surf(0.5541)", "verif concept answer": "windsurf(0.5812)", "verif image answer": "surf(0.6819)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000461443.jpg"}, {"question": "what is the name of the nursery rhyme girl that lost one of these animals", "gt answer": "little bow peep(1.00)<br/>sheep(0.60)<br/>little bo peep(0.60)", "pred answer": "friend", "question_id": 149285, "best approach": "", "verif answer": "little bo peep", "anno approach": "wiki, concept, image", "verif wiki answer": "shear(0.6699)", "verif concept answer": "shear(0.6181)", "verif image answer": "shear(0.5210)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000014928.jpg"}, {"question": "what should he have on", "gt answer": "life vest(1.00)<br/>helmet(0.60)<br/>sunscreen(0.60)", "pred answer": "ski", "question_id": 4270355, "best approach": "wiki", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "sunscreen(0.7143)", "verif concept answer": "ski(0.5731)", "verif image answer": "safe(0.5997)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427035.jpg"}, {"question": "when was this transportation first used", "gt answer": "1804(1.00)<br/>1800's(0.60)", "pred answer": "1900", "question_id": 2453775, "best approach": "", "verif answer": "1800s", "anno approach": "wiki, concept, image", "verif wiki answer": "1800s(0.6728)", "verif concept answer": "1800(0.6465)", "verif image answer": "1800(0.7036)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000245377.jpg"}, {"question": "to make this vehicle go its rider must do what", "gt answer": "pedal(1.00)", "pred answer": "jump", "question_id": 4471505, "best approach": "", "verif answer": "bike", "anno approach": "wiki, concept, image", "verif wiki answer": "feet(0.5956)", "verif concept answer": "feet(0.5263)", "verif image answer": "feet(0.5296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000447150.jpg"}, {"question": "how does this move in a circle", "gt answer": "engine(1.00)<br/>motor(0.60)<br/>wheel(0.60)", "pred answer": "gallop", "question_id": 4326375, "best approach": "wiki", "verif answer": "motor", "anno approach": "wiki, concept, image", "verif wiki answer": "engine(0.6352)", "verif concept answer": "wheel(0.6396)", "verif image answer": "wheel(0.6216)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000432637.jpg"}, {"question": "why is she eating carbohydrates", "gt answer": "energy(1.00)<br/>race(0.60)", "pred answer": "hungry", "question_id": 4238325, "best approach": "", "verif answer": "run", "anno approach": "wiki, concept, image", "verif wiki answer": "night(0.6013)", "verif concept answer": "night(0.5566)", "verif image answer": "run(0.6457)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000423832.jpg"}, {"question": "how tall do these animals grow to be", "gt answer": "5 feet(1.00)<br/>4 feet(0.60)", "pred answer": "20 feet", "question_id": 1060795, "best approach": "wiki", "verif answer": "4 feet", "anno approach": "wiki, concept, image", "verif wiki answer": "5 feet(0.5925)", "verif concept answer": "8 feet(0.5696)", "verif image answer": "8 feet(0.6895)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000106079.jpg"}, {"question": "what us agency regulates vehicles like this", "gt answer": "faa(1.00)", "pred answer": "pilot", "question_id": 2341625, "best approach": "wiki, image", "verif answer": "pigtail", "anno approach": "wiki, concept, image", "verif wiki answer": "faa(0.6193)", "verif concept answer": "pigtail(0.6299)", "verif image answer": "faa(0.6507)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000234162.jpg"}, {"question": "what breed of the first horse", "gt answer": "appaloosa(1.00)<br/>pinto(0.60)<br/>mustang(0.60)", "pred answer": "stallion", "question_id": 3439845, "best approach": "image", "verif answer": "pinto", "anno approach": "wiki, concept, image", "verif wiki answer": "palomino(0.6374)", "verif concept answer": "palomino(0.6444)", "verif image answer": "appaloosa(0.7186)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000343984.jpg"}, {"question": "when was this game first invented", "gt answer": "1873(1.00)<br/>1800's(0.60)<br/>1902(0.60)<br/>1800s(0.60)", "pred answer": "1948", "question_id": 5296245, "best approach": "wiki, concept, image", "verif answer": "1902", "anno approach": "wiki, concept, image", "verif wiki answer": "1873(0.7044)", "verif concept answer": "1873(0.5926)", "verif image answer": "1873(0.6689)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529624.jpg"}, {"question": "what is being worn here", "gt answer": "wetsuit(1.00)<br/>wet suit(0.60)", "pred answer": "surfboard", "question_id": 2005505, "best approach": "wiki, image", "verif answer": "wetsuit", "anno approach": "wiki, concept, image", "verif wiki answer": "wetsuit(0.6930)", "verif concept answer": "wet suit(0.5493)", "verif image answer": "wetsuit(0.6304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000200550.jpg"}, {"question": "what kind of noodles are used in this dish", "gt answer": "udon(1.00)<br/>thai(0.60)<br/>egg(0.60)", "pred answer": "lo mein", "question_id": 2111645, "best approach": "wiki, concept", "verif answer": "egg", "anno approach": "wiki, concept, image", "verif wiki answer": "udon(0.6453)", "verif concept answer": "udon(0.5974)", "verif image answer": "egg(0.6191)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000211164.jpg"}, {"question": "what type of outerwear is being worn", "gt answer": "snowsuit(1.00)<br/>ski suit(0.60)", "pred answer": "coat", "question_id": 5771905, "best approach": "concept", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "ski(0.7083)", "verif concept answer": "snowsuit(0.6445)", "verif image answer": "clydesdale(0.6319)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000577190.jpg"}, {"question": "is the water for flushing or drinking", "gt answer": "flush(1.00)<br/>drink(0.60)", "pred answer": "unhygienic", "question_id": 1557465, "best approach": "image", "verif answer": "flush", "anno approach": "wiki, concept, image", "verif wiki answer": "wash hand(0.5866)", "verif concept answer": "take picture(0.5368)", "verif image answer": "flush(0.5844)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000155746.jpg"}, {"question": "what is the name of the winter behavior engaged in by the animal in the photo", "gt answer": "hibernation(1.00)", "pred answer": "play dead", "question_id": 4243265, "best approach": "wiki", "verif answer": "bear", "anno approach": "wiki, concept, image", "verif wiki answer": "hibernation(0.6857)", "verif concept answer": "goldilocks(0.6274)", "verif image answer": "bear(0.6138)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000424326.jpg"}, {"question": "what breed of dog is that", "gt answer": "shepherd(1.00)<br/>collie(0.60)", "pred answer": "german shepherd", "question_id": 5707755, "best approach": "wiki", "verif answer": "collie", "anno approach": "wiki, concept, image", "verif wiki answer": "shepherd(0.5930)", "verif concept answer": "mutt(0.6166)", "verif image answer": "collie(0.6522)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000570775.jpg"}, {"question": "who is that in the painting on the wall", "gt answer": "jesus(1.00)<br/>woman(0.60)", "pred answer": "van gogh", "question_id": 2865115, "best approach": "image", "verif answer": "van gogh", "anno approach": "wiki, concept, image", "verif wiki answer": "man(0.5608)", "verif concept answer": "ben franklin(0.5943)", "verif image answer": "woman(0.5308)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000286511.jpg"}, {"question": "what activity will you do at this location", "gt answer": "shop(1.00)", "pred answer": "eat", "question_id": 3558945, "best approach": "", "verif answer": "sell", "anno approach": "wiki, concept, image", "verif wiki answer": "sell(0.7206)", "verif concept answer": "walk(0.6520)", "verif image answer": "walk(0.5784)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000355894.jpg"}, {"question": "what type of dog is laying on the street", "gt answer": "pit bull(1.00)<br/>doberman(0.60)<br/>rottweiler(0.60)<br/>sick(0.60)", "pred answer": "pug", "question_id": 1806415, "best approach": "concept, image", "verif answer": "lab", "anno approach": "wiki, concept, image", "verif wiki answer": "doberman(0.6200)", "verif concept answer": "pit bull(0.6056)", "verif image answer": "pit bull(0.5275)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180641.jpg"}, {"question": "when people that engage in this sport need to keep warm they wear what", "gt answer": "wetsuit(1.00)<br/>surf(0.60)", "pred answer": "wet suit", "question_id": 4535675, "best approach": "wiki, concept, image", "verif answer": "wetsuit", "anno approach": "wiki, concept, image", "verif wiki answer": "wetsuit(0.7070)", "verif concept answer": "wetsuit(0.5915)", "verif image answer": "wetsuit(0.6795)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000453567.jpg"}, {"question": "why am i doing this", "gt answer": "clean teeth(1.00)", "pred answer": "clean", "question_id": 4620675, "best approach": "", "verif answer": "clean", "anno approach": "wiki, concept, image", "verif wiki answer": "brush teeth(0.6621)", "verif concept answer": "teeth(0.6058)", "verif image answer": "brush teeth(0.7157)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000462067.jpg"}, {"question": "", "gt answer": "contain(0.60)<br/>safety(0.60)", "pred answer": "to catch ball", "question_id": 5171385, "best approach": "", "verif answer": "contain", "anno approach": "wiki, concept, image", "verif wiki answer": "talk(0.5694)", "verif concept answer": "talk(0.5620)", "verif image answer": "talk(0.5638)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000517138.jpg"}, {"question": "what food truck are the people standing in line for", "gt answer": "taco(1.00)<br/>mexican(1.00)", "pred answer": "hotdog", "question_id": 472215, "best approach": "concept, image", "verif answer": "food", "anno approach": "wiki, concept, image", "verif wiki answer": "food(0.6908)", "verif concept answer": "mexican(0.5619)", "verif image answer": "mexican(0.7027)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000047221.jpg"}, {"question": "where is this located", "gt answer": "india(1.00)", "pred answer": "street", "question_id": 5341955, "best approach": "", "verif answer": "india", "anno approach": "wiki, concept, image", "verif wiki answer": "china(0.6758)", "verif concept answer": "thailand(0.6329)", "verif image answer": "china(0.5613)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000534195.jpg"}, {"question": "what is the object atop the skier 's head used for", "gt answer": "protection(1.00)<br/>go pro(0.60)<br/>accident(0.60)", "pred answer": "balance", "question_id": 3441805, "best approach": "concept, image", "verif answer": "protection", "anno approach": "wiki, concept, image", "verif wiki answer": "turn(0.6382)", "verif concept answer": "protection(0.5995)", "verif image answer": "protection(0.6679)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000344180.jpg"}, {"question": "which sixties movie famously made use of a road trip with this vehicle and featured jack nicholson", "gt answer": "easy rider(1.00)<br/>taxi(0.60)", "pred answer": "chip", "question_id": 4580255, "best approach": "image", "verif answer": "motorcycle", "anno approach": "wiki, concept, image", "verif wiki answer": "bmx(0.5905)", "verif concept answer": "bmx(0.5567)", "verif image answer": "easy rider(0.5189)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000458025.jpg"}, {"question": "what is the process required to create the drink shown in this photo", "gt answer": "fermentation(1.00)<br/>brew(0.60)", "pred answer": "drunk", "question_id": 4891955, "best approach": "wiki, concept, image", "verif answer": "drunk", "anno approach": "wiki, concept, image", "verif wiki answer": "fermentation(0.6126)", "verif concept answer": "fermentation(0.6629)", "verif image answer": "fermentation(0.6529)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489195.jpg"}, {"question": "what tournament is this tennis playing playing in", "gt answer": "us open(1.00)<br/>master(0.60)", "pred answer": "wimbledon", "question_id": 4409845, "best approach": "", "verif answer": "wimbledon", "anno approach": "wiki, concept, image", "verif wiki answer": "wimbledon(0.5617)", "verif concept answer": "wimbledon(0.6882)", "verif image answer": "bedroom(0.7113)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000440984.jpg"}, {"question": "why is the water where it is", "gt answer": "tide(1.00)<br/>ocean(0.60)", "pred answer": "rain", "question_id": 3053155, "best approach": "image", "verif answer": "swim", "anno approach": "wiki, concept, image", "verif wiki answer": "land(0.5959)", "verif concept answer": "swim(0.5886)", "verif image answer": "tide(0.6883)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000305315.jpg"}, {"question": "who wrote the book on the desk", "gt answer": "irma s rombauer(1.00)", "pred answer": "samuel fox", "question_id": 2310915, "best approach": "wiki, concept", "verif answer": "ben franklin", "anno approach": "wiki, concept, image", "verif wiki answer": "irma s rombauer(0.5138)", "verif concept answer": "irma s rombauer(0.5667)", "verif image answer": "ben franklin(0.5184)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000231091.jpg"}, {"question": "what passenger class is the train", "gt answer": "commuter(1.00)<br/>bullet(0.60)<br/>first(0.60)", "pred answer": "passenger", "question_id": 398595, "best approach": "image", "verif answer": "commuter", "anno approach": "wiki, concept, image", "verif wiki answer": "steam(0.6171)", "verif concept answer": "steam(0.5937)", "verif image answer": "first(0.5364)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000039859.jpg"}, {"question": "does this game involve a shuttlecock or ball", "gt answer": "ball(1.00)", "pred answer": "tennis ball", "question_id": 4040245, "best approach": "", "verif answer": "tennis ball", "anno approach": "wiki, concept, image", "verif wiki answer": "serve(0.6753)", "verif concept answer": "tennis ball(0.5675)", "verif image answer": "baseball(0.7107)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000404024.jpg"}, {"question": "what is the dog doing with stuffed animal", "gt answer": "chew(1.00)", "pred answer": "smell", "question_id": 5805255, "best approach": "wiki", "verif answer": "teddy bear", "anno approach": "wiki, concept, image", "verif wiki answer": "chew(0.5808)", "verif concept answer": "4(0.5494)", "verif image answer": "teddy bear(0.5646)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000580525.jpg"}, {"question": "what is the model of this plane", "gt answer": "boeing(1.00)<br/>airbus(0.60)", "pred answer": "747", "question_id": 5228205, "best approach": "wiki, concept, image", "verif answer": "boeing", "anno approach": "wiki, concept, image", "verif wiki answer": "airbus(0.6664)", "verif concept answer": "airbus(0.6041)", "verif image answer": "airbus(0.6509)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000522820.jpg"}, {"question": "what vitamins do you get from the fruits", "gt answer": "potassium(1.00)", "pred answer": "c", "question_id": 2187345, "best approach": "", "verif answer": "c", "anno approach": "wiki, concept, image", "verif wiki answer": "c(0.6246)", "verif concept answer": "c(0.6335)", "verif image answer": "c(0.6351)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000218734.jpg"}, {"question": "what is dispensed here", "gt answer": "money(1.00)", "pred answer": "trash", "question_id": 3077295, "best approach": "", "verif answer": "coin", "anno approach": "wiki, concept, image", "verif wiki answer": "restock(0.6193)", "verif concept answer": "coin(0.6276)", "verif image answer": "coin(0.6624)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000307729.jpg"}, {"question": "is the bigger animal more likely a mother or a father", "gt answer": "mother(1.00)<br/>leaf(0.60)", "pred answer": "calf", "question_id": 2078805, "best approach": "", "verif answer": "coach", "anno approach": "wiki, concept, image", "verif wiki answer": "coach(0.6304)", "verif concept answer": "friendly(0.6768)", "verif image answer": "coach(0.7273)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000207880.jpg"}, {"question": "to what type of business does that white car belong", "gt answer": "taxi(1.00)<br/>police(0.60)", "pred answer": "construction", "question_id": 409305, "best approach": "concept", "verif answer": "police", "anno approach": "wiki, concept, image", "verif wiki answer": "tow(0.5717)", "verif concept answer": "police(0.5765)", "verif image answer": "tow(0.5947)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000040930.jpg"}, {"question": "how far can this bird fly without landing", "gt answer": "5 miles(1.00)<br/>mile(0.60)", "pred answer": "far", "question_id": 3795585, "best approach": "concept, image", "verif answer": "0", "anno approach": "wiki, concept, image", "verif wiki answer": "very(0.5597)", "verif concept answer": "mile(0.6149)", "verif image answer": "mile(0.6510)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379558.jpg"}, {"question": "where is this beach located", "gt answer": "hawaii(1.00)", "pred answer": "beach", "question_id": 5210055, "best approach": "", "verif answer": "beach", "anno approach": "wiki, concept, image", "verif wiki answer": "beach(0.5873)", "verif concept answer": "beach(0.5757)", "verif image answer": "usa(0.7252)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000521005.jpg"}, {"question": "what is this form of expression", "gt answer": "art(1.00)<br/>warm(0.60)", "pred answer": "sad", "question_id": 2607165, "best approach": "concept, image", "verif answer": "bent", "anno approach": "wiki, concept, image", "verif wiki answer": "broken(0.6230)", "verif concept answer": "warm(0.5954)", "verif image answer": "warm(0.5656)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000260716.jpg"}, {"question": "what is the paper in the sink", "gt answer": "paper towel(1.00)<br/>towel(1.00)", "pred answer": "dishwasher", "question_id": 1461865, "best approach": "", "verif answer": "towel", "anno approach": "wiki, concept, image", "verif wiki answer": "cup(0.5822)", "verif concept answer": "paper(0.6610)", "verif image answer": "mail(0.5373)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000146186.jpg"}, {"question": "what type of dog is in the picture", "gt answer": "poodle(1.00)", "pred answer": "pomeranian", "question_id": 3426395, "best approach": "", "verif answer": "poodle", "anno approach": "wiki, concept, image", "verif wiki answer": "faux(0.7245)", "verif concept answer": "faux(0.6474)", "verif image answer": "faux(0.6230)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000342639.jpg"}, {"question": "what nutrients does the fruit depicted provide", "gt answer": "potassium(1.00)<br/>vitamin c(0.60)", "pred answer": "calcium", "question_id": 5663555, "best approach": "concept, image", "verif answer": "vitamin c", "anno approach": "wiki, concept, image", "verif wiki answer": "calcium(0.6368)", "verif concept answer": "vitamin c(0.6502)", "verif image answer": "vitamin c(0.5977)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000566355.jpg"}, {"question": "what corrective device is the man standing up wearing", "gt answer": "glass(1.00)<br/>cane(0.60)", "pred answer": "tie", "question_id": 802465, "best approach": "image", "verif answer": "glass", "anno approach": "wiki, concept, image", "verif wiki answer": "wine glass(0.6551)", "verif concept answer": "leather(0.5361)", "verif image answer": "glass(0.5778)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000080246.jpg"}, {"question": "how many calories are in this donut", "gt answer": "200(1.00)<br/>500(0.60)", "pred answer": "300", "question_id": 1755405, "best approach": "wiki, image", "verif answer": "300", "anno approach": "wiki, concept, image", "verif wiki answer": "200(0.5948)", "verif concept answer": "300(0.5871)", "verif image answer": "200(0.6304)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000175540.jpg"}, {"question": "what base is the runner headed to", "gt answer": "first(1.00)<br/>1st(0.60)<br/>first base(0.60)<br/>home(0.60)", "pred answer": "second", "question_id": 5375435, "best approach": "wiki, concept", "verif answer": "1st", "anno approach": "wiki, concept, image", "verif wiki answer": "1st(0.7045)", "verif concept answer": "1st(0.6244)", "verif image answer": "main(0.6074)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000537543.jpg"}, {"question": "this pattern also famously found in business suits is called what", "gt answer": "pinstripe(1.00)", "pred answer": "stripe", "question_id": 3095525, "best approach": "", "verif answer": "retro", "anno approach": "wiki, concept, image", "verif wiki answer": "pigtail(0.5951)", "verif concept answer": "road(0.6551)", "verif image answer": "open(0.7214)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000309552.jpg"}, {"question": "when was this sport invented", "gt answer": "1873(1.00)<br/>1800(0.60)", "pred answer": "1948", "question_id": 3368745, "best approach": "wiki, image", "verif answer": "1800s", "anno approach": "wiki, concept, image", "verif wiki answer": "1873(0.6398)", "verif concept answer": "1800s(0.6336)", "verif image answer": "1873(0.7083)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000336874.jpg"}, {"question": "how fast is that firetruck going", "gt answer": "0 mph(1.00)<br/>35(0.60)", "pred answer": "30mph", "question_id": 271755, "best approach": "wiki, concept", "verif answer": "fast", "anno approach": "wiki, concept, image", "verif wiki answer": "0 mph(0.6106)", "verif concept answer": "0 mph(0.5997)", "verif image answer": "fast(0.6727)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000027175.jpg"}, {"question": "how much calorie does this vegetable have", "gt answer": "fifty(1.00)<br/>50(0.60)<br/>100(0.60)", "pred answer": "500", "question_id": 940845, "best approach": "image", "verif answer": "200", "anno approach": "wiki, concept, image", "verif wiki answer": "200(0.6647)", "verif concept answer": "200(0.6058)", "verif image answer": "50(0.7050)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000094084.jpg"}, {"question": "what brand are the brown and pink suit cases", "gt answer": "coach(1.00)<br/>samsonite(1.00)", "pred answer": "levis", "question_id": 3952595, "best approach": "wiki, concept", "verif answer": "columbia", "anno approach": "wiki, concept, image", "verif wiki answer": "samsonite(0.7164)", "verif concept answer": "samsonite(0.6092)", "verif image answer": "columbia(0.7010)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000395259.jpg"}, {"question": "why are the people standing there", "gt answer": "watch plane(1.00)", "pred answer": "wait", "question_id": 2680845, "best approach": "", "verif answer": "airplane", "anno approach": "wiki, concept, image", "verif wiki answer": "plane(0.6987)", "verif concept answer": "wright brother(0.6015)", "verif image answer": "plane(0.5901)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268084.jpg"}, {"question": "what is the dog doing", "gt answer": "catch(1.00)<br/>frisbee(0.60)", "pred answer": "jump", "question_id": 1207035, "best approach": "", "verif answer": "fetch", "anno approach": "wiki, concept, image", "verif wiki answer": "fetch(0.6590)", "verif concept answer": "fetch(0.5504)", "verif image answer": "fetch(0.6786)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000120703.jpg"}, {"question": "what should a car do when it passes this sign", "gt answer": "yield(1.00)<br/>slow down(0.60)<br/>stop(0.60)", "pred answer": "look", "question_id": 2216805, "best approach": "wiki, concept, image", "verif answer": "slow down", "anno approach": "wiki, concept, image", "verif wiki answer": "slow down(0.6146)", "verif concept answer": "slow down(0.6366)", "verif image answer": "slow down(0.5383)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000221680.jpg"}, {"question": "what family member is part of the name of this clock", "gt answer": "grandfather(1.00)<br/>0(0.60)<br/>grandfather clock(0.60)", "pred answer": "amish", "question_id": 638865, "best approach": "wiki, concept, image", "verif answer": "kid", "anno approach": "wiki, concept, image", "verif wiki answer": "grandfather clock(0.5214)", "verif concept answer": "grandfather clock(0.6145)", "verif image answer": "grandfather clock(0.7132)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000063886.jpg"}, {"question": "what city are these streets located in", "gt answer": "berlin(1.00)<br/>beijing(0.60)", "pred answer": "washington dc", "question_id": 4270695, "best approach": "concept", "verif answer": "paris", "anno approach": "wiki, concept, image", "verif wiki answer": "london(0.5652)", "verif concept answer": "berlin(0.5612)", "verif image answer": "paris(0.5513)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000427069.jpg"}, {"question": "what breed of dog is on the boat", "gt answer": "german shepard(1.00)<br/>german shepherd(0.60)<br/>retriever(0.60)", "pred answer": "lab", "question_id": 2999595, "best approach": "concept", "verif answer": "german shepherd", "anno approach": "wiki, concept, image", "verif wiki answer": "beagle(0.6900)", "verif concept answer": "german shepard(0.6170)", "verif image answer": "husky(0.6530)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000299959.jpg"}, {"question": "what natural disaster would require the object to the left", "gt answer": "fire(1.00)<br/>flood(0.60)", "pred answer": "water", "question_id": 1035645, "best approach": "wiki", "verif answer": "flood", "anno approach": "wiki, concept, image", "verif wiki answer": "fire(0.6656)", "verif concept answer": "fire department(0.6651)", "verif image answer": "flood(0.7145)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000103564.jpg"}, {"question": "what is being done on this road", "gt answer": "construction(1.00)<br/>dig(0.60)<br/>work(0.60)", "pred answer": "traffic", "question_id": 1983195, "best approach": "wiki, concept, image", "verif answer": "construction", "anno approach": "wiki, concept, image", "verif wiki answer": "dig(0.7025)", "verif concept answer": "work(0.5890)", "verif image answer": "work(0.6008)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000198319.jpg"}, {"question": "when was this time telling method invented", "gt answer": "1656(1.00)", "pred answer": "1800s", "question_id": 3137275, "best approach": "image", "verif answer": "1850", "anno approach": "wiki, concept, image", "verif wiki answer": "1850(0.6893)", "verif concept answer": "1850(0.6091)", "verif image answer": "1656(0.5707)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000313727.jpg"}, {"question": "are these trees evergreen or deciduous", "gt answer": "deciduous(1.00)", "pred answer": "oak", "question_id": 2291555, "best approach": "", "verif answer": "oak", "anno approach": "wiki, concept, image", "verif wiki answer": "elm(0.5858)", "verif concept answer": "elm(0.5893)", "verif image answer": "oak(0.6296)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000229155.jpg"}, {"question": "what useful craft supply used to be made of this animal", "gt answer": "glue(1.00)", "pred answer": "saddle", "question_id": 152495, "best approach": "", "verif answer": "horse", "anno approach": "wiki, concept, image", "verif wiki answer": "calcium(0.5599)", "verif concept answer": "horse(0.6141)", "verif image answer": "restock(0.6368)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000015249.jpg"}, {"question": "if this stuffed animal was experiencing an emotion what would it be", "gt answer": "happiness(1.00)<br/>smile(0.60)<br/>happy(0.60)", "pred answer": "love", "question_id": 3343105, "best approach": "wiki, concept", "verif answer": "smile", "anno approach": "wiki, concept, image", "verif wiki answer": "smile(0.6519)", "verif concept answer": "smile(0.5443)", "verif image answer": "boredom(0.7141)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000334310.jpg"}, {"question": "what is the name of this dish", "gt answer": "bundt cake(1.00)", "pred answer": "cake", "question_id": 3797355, "best approach": "wiki, concept, image", "verif answer": "cake", "anno approach": "wiki, concept, image", "verif wiki answer": "bundt cake(0.6952)", "verif concept answer": "bundt cake(0.6911)", "verif image answer": "bundt cake(0.7234)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000379735.jpg"}, {"question": "what breed of chicken is on the right", "gt answer": "rhode island red(1.00)<br/>rooster(0.60)", "pred answer": "heihei", "question_id": 4390895, "best approach": "wiki", "verif answer": "rooster", "anno approach": "wiki, concept, image", "verif wiki answer": "rooster(0.6445)", "verif concept answer": "idaho(0.5965)", "verif image answer": "king(0.5949)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000439089.jpg"}, {"question": "what do the signs in this image indicate to road users", "gt answer": "no entry(1.00)<br/>1 way(0.60)", "pred answer": "no park", "question_id": 2688045, "best approach": "wiki", "verif answer": "no turn", "anno approach": "wiki, concept, image", "verif wiki answer": "no entry(0.6393)", "verif concept answer": "no turn(0.6522)", "verif image answer": "no turn(0.5526)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000268804.jpg"}, {"question": "how big will these animals get when full grown", "gt answer": "15 pounds(1.00)<br/>small(0.60)", "pred answer": "10 years", "question_id": 1864835, "best approach": "wiki, concept, image", "verif answer": "6 inches", "anno approach": "wiki, concept, image", "verif wiki answer": "small(0.5623)", "verif concept answer": "small(0.5786)", "verif image answer": "small(0.6111)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000186483.jpg"}, {"question": "can you guess the laptop model shown in this picture", "gt answer": "hp(1.00)<br/>intel(0.60)<br/>window(0.60)", "pred answer": "dell", "question_id": 1745735, "best approach": "wiki", "verif answer": "dell", "anno approach": "wiki, concept, image", "verif wiki answer": "hp(0.6173)", "verif concept answer": "dell(0.5872)", "verif image answer": "window(0.7152)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000174573.jpg"}, {"question": "what organization might help this individual", "gt answer": "salvation army(1.00)<br/>aspca(0.60)", "pred answer": "spca", "question_id": 2645145, "best approach": "", "verif answer": "spca", "anno approach": "wiki, concept, image", "verif wiki answer": "boy scout(0.6836)", "verif concept answer": "spca(0.5846)", "verif image answer": "spca(0.5582)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000264514.jpg"}, {"question": "what are they attempting to make", "gt answer": "cupcake(1.00)", "pred answer": "cake", "question_id": 5128925, "best approach": "concept", "verif answer": "cake", "anno approach": "wiki, concept, image", "verif wiki answer": "cake(0.6013)", "verif concept answer": "cupcake(0.6213)", "verif image answer": "pastry(0.5560)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000512892.jpg"}, {"question": "which item of jewellery is in this photo", "gt answer": "necklace(1.00)", "pred answer": "glass", "question_id": 4013815, "best approach": "", "verif answer": "scarf", "anno approach": "wiki, concept, image", "verif wiki answer": "wed(0.5332)", "verif concept answer": "wed(0.6705)", "verif image answer": "scarf(0.6546)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000401381.jpg"}, {"question": "what type of bread is used to make this sandwich", "gt answer": "rye(1.00)", "pred answer": "whole grain", "question_id": 2653295, "best approach": "", "verif answer": "sourdough", "anno approach": "wiki, concept, image", "verif wiki answer": "sourdough(0.6781)", "verif concept answer": "sourdough(0.6741)", "verif image answer": "french(0.6777)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000265329.jpg"}, {"question": "what country are they driving in", "gt answer": "sweden(1.00)<br/>netherlands(0.60)<br/>united state(0.60)<br/>switzerland(0.60)", "pred answer": "ireland", "question_id": 2695975, "best approach": "wiki, concept", "verif answer": "netherlands", "anno approach": "wiki, concept, image", "verif wiki answer": "netherlands(0.6072)", "verif concept answer": "netherlands(0.6405)", "verif image answer": "norway(0.6123)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000269597.jpg"}, {"question": "what is usually around this animal 's neck", "gt answer": "bell(1.00)<br/>collar(1.00)", "pred answer": "tie", "question_id": 1801685, "best approach": "wiki, image", "verif answer": "tie", "anno approach": "wiki, concept, image", "verif wiki answer": "bell(0.5815)", "verif concept answer": "tie(0.5408)", "verif image answer": "bell(0.6265)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000180168.jpg"}, {"question": "what kind of plane is in the photo", "gt answer": "crop duster(1.00)<br/>glider(0.60)<br/>fire fighter(0.60)", "pred answer": "cessna", "question_id": 5248235, "best approach": "image", "verif answer": "fire fighter", "anno approach": "wiki, concept, image", "verif wiki answer": "fighter jet(0.6733)", "verif concept answer": "glider(0.5993)", "verif image answer": "crop duster(0.6784)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000524823.jpg"}, {"question": "what activity do people do on the green area in this picture for fitness and fun", "gt answer": "golf(1.00)<br/>ski(0.60)<br/>hike(1.00)", "pred answer": "walk", "question_id": 2017145, "best approach": "concept, image", "verif answer": "ski", "anno approach": "wiki, concept, image", "verif wiki answer": "camp(0.7148)", "verif concept answer": "ski(0.5521)", "verif image answer": "ski(0.6271)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000201714.jpg"}, {"question": "what do you call the type of vehicle in this image", "gt answer": "sedan(1.00)<br/>car(1.00)<br/>electric(0.60)", "pred answer": "van", "question_id": 593845, "best approach": "wiki, image", "verif answer": "car", "anno approach": "wiki, concept, image", "verif wiki answer": "car(0.6390)", "verif concept answer": "bmw(0.6411)", "verif image answer": "car(0.5922)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000059384.jpg"}, {"question": "what river is this", "gt answer": "ganges(1.00)<br/>nile(1.00)", "pred answer": "amazon", "question_id": 4566025, "best approach": "", "verif answer": "amazon", "anno approach": "wiki, concept, image", "verif wiki answer": "major(0.6682)", "verif concept answer": "amazon(0.6589)", "verif image answer": "major(0.6662)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000456602.jpg"}, {"question": "what kind of drums are seen here", "gt answer": "bongo(1.00)<br/>0(0.60)", "pred answer": "boat", "question_id": 4284405, "best approach": "image", "verif answer": "sailboat", "anno approach": "wiki, concept, image", "verif wiki answer": "snare(0.5679)", "verif concept answer": "sailboat(0.6010)", "verif image answer": "0(0.6399)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000428440.jpg"}, {"question": "what kind of cover is this", "gt answer": "green(1.00)<br/>fender(0.60)", "pred answer": "light", "question_id": 5497845, "best approach": "wiki", "verif answer": "leaf", "anno approach": "wiki, concept, image", "verif wiki answer": "green(0.6188)", "verif concept answer": "fender(0.6111)", "verif image answer": "leaf(0.7182)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000549784.jpg"}, {"question": "what part of a tree has something in common with this animal", "gt answer": "bark(1.00)<br/>trunk(0.60)<br/>fir(0.60)", "pred answer": "shadow", "question_id": 5298795, "best approach": "wiki", "verif answer": "bark", "anno approach": "wiki, concept, image", "verif wiki answer": "bark(0.5262)", "verif concept answer": "oak(0.5529)", "verif image answer": "pine(0.6707)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000529879.jpg"}, {"question": "what brand of apple 's is that", "gt answer": "mcintosh(1.00)<br/>fuji(0.60)", "pred answer": "apple", "question_id": 5654765, "best approach": "wiki, concept", "verif answer": "fuji", "anno approach": "wiki, concept, image", "verif wiki answer": "mcintosh(0.6009)", "verif concept answer": "mcintosh(0.6036)", "verif image answer": "gala(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000565476.jpg"}, {"question": "what is this truck used for", "gt answer": "delivery(1.00)<br/>ship(0.60)", "pred answer": "fire", "question_id": 662835, "best approach": "wiki", "verif answer": "delivery", "anno approach": "wiki, concept, image", "verif wiki answer": "delivery(0.6592)", "verif concept answer": "deliver(0.6025)", "verif image answer": "ship(0.6852)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000066283.jpg"}, {"question": "a animated movie came out with which of these objects as the main character", "gt answer": "beauty and beast(0.60)<br/>find nemo(0.60)<br/>hot dog(1.00)<br/>hotdog(0.60)", "pred answer": "chip", "question_id": 5164555, "best approach": "wiki, concept, image", "verif answer": "hot dog", "anno approach": "wiki, concept, image", "verif wiki answer": "hot dog(0.6535)", "verif concept answer": "hot dog(0.5723)", "verif image answer": "hot dog(0.7280)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000516455.jpg"}, {"question": "what small animal with a tail could this cat be hunting in the house", "gt answer": "mouse(1.00)", "pred answer": "cat", "question_id": 4896065, "best approach": "wiki, concept, image", "verif answer": "mice", "anno approach": "wiki, concept, image", "verif wiki answer": "mouse(0.6652)", "verif concept answer": "mouse(0.6179)", "verif image answer": "mouse(0.7183)", "image_url": "http://images.cocodataset.org/train2014/COCO_train2014_000000489606.jpg"}]